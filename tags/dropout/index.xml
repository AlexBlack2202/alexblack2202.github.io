<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>dropout on Phạm Duy Tùng Machine Learning Blog</title>
    <link>/tags/dropout/</link>
    <description>Recent content in dropout on Phạm Duy Tùng Machine Learning Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 May 2019 00:12:00 +0300</lastBuildDate>
    
	<atom:link href="/tags/dropout/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tìm hiểu mạng AlexNet, mô hình giành chiến thắng tại cuộc thi ILSVRC 2012</title>
      <link>/blog/2019-05-27-alexnet/</link>
      <pubDate>Mon, 27 May 2019 00:12:00 +0300</pubDate>
      
      <guid>/blog/2019-05-27-alexnet/</guid>
      <description>Trong bài viết này, chúng ta sẽ tìm hiểu mô hình AlexNet từ nhóm của giáo sư Hinton. Tới thời điểm hiện tại (2019-05-27), bài viết của giáo sư đã có hơn 40316 lượt trích dẫn. Bài báo này có bước đóng góp cực kỳ quan trọng, là một đột phá lớn trong lĩnh vực deep learning, mở đầu cho sự quay lại của mạng neural network và đóng góp trực tiếp vào thành công của những chương trình trí tuệ nhân tạo tại thời điểm hiện tại.</description>
    </item>
    
    <item>
      <title>Tìm hiểu về dropout trong deep learning, machine learning</title>
      <link>/blog/2019-05-05-deep-learning-dropout/</link>
      <pubDate>Sun, 05 May 2019 00:12:00 +0300</pubDate>
      
      <guid>/blog/2019-05-05-deep-learning-dropout/</guid>
      <description>1. Dropout là gì, nó có ý nghĩa gì trong mạng neural network Theo Wikipedia, thuật ngữ &amp;ldquo;dropout&amp;rdquo; đề cập đến việc bỏ qua các đơn vị (unit) (cả hai hidden unit và visible unit) trong mạng neural network.
Hiểu đơn giản là, trong mạng neural network, kỹ thuật dropout là việc chúng ta sẽ bỏ qua một vài unit trong suốt quá trình train trong mô hình, những unit bị bỏ qua được lựa chọn ngẫu nhiên.</description>
    </item>
    
  </channel>
</rss>