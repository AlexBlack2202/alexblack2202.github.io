<!doctype html><html lang="en" data-palette="blue"
   data-mode="dark">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Tìm hiểu về mạng neural network AlexNet - Phạm Duy Tùng Machine Learning Blog</title><link rel="apple-touch-icon" href="/images/icons/icon-180x180.png" sizes="180x180">
<link rel="icon" href="/images/icons/icon-32x32.png" sizes="32x32" type="image/png">
<link rel="icon" href="/images/icons/icon-16x16.png" sizes="16x16" type="image/png">
<link rel="icon" href="/images/icons/favicon.ico">
<link rel="manifest" href="/manifest.json">
<meta name="keywords" content="" />
<meta name="description" content="Bài viết này được mình lược dịch từ nguồn của tác giả SUNITA NAYAK. Nội dung chủ yếu là tìm hiểu sâu về kiến trúc mạng AlexNet." /><meta name="robots" content="index, follow" /><meta itemprop="name" content="Tìm hiểu về mạng neural network AlexNet">
<meta itemprop="description" content="Bài viết này được mình lược dịch từ nguồn của tác giả SUNITA NAYAK. Nội dung chủ yếu là tìm hiểu sâu về kiến trúc mạng AlexNet."><meta itemprop="datePublished" content="2018-06-15T00:19:00+03:00" />
<meta itemprop="dateModified" content="2018-06-15T00:19:00+03:00" />
<meta itemprop="wordCount" content="2322">
<meta itemprop="keywords" content="Machine learning,Deeplearning,AlexNet," /><meta property="og:title" content="Tìm hiểu về mạng neural network AlexNet" />
<meta property="og:description" content="Bài viết này được mình lược dịch từ nguồn của tác giả SUNITA NAYAK. Nội dung chủ yếu là tìm hiểu sâu về kiến trúc mạng AlexNet." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/2018-06-15-understanding-alexnet/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2018-06-15T00:19:00+03:00" />
<meta property="article:modified_time" content="2018-06-15T00:19:00+03:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Tìm hiểu về mạng neural network AlexNet"/>
<meta name="twitter:description" content="Bài viết này được mình lược dịch từ nguồn của tác giả SUNITA NAYAK. Nội dung chủ yếu là tìm hiểu sâu về kiến trúc mạng AlexNet."/>
<meta property="og:image" content="/images/logo.png"/>
  <meta name="twitter:image" content="/images/logo.png"/><link rel="stylesheet" href="/css/main.min.507afbe6e4670fa3e961a0b35816b5daeb36029866fd6bd7b9d7871fcf88faa5.css" integrity="sha256-UHr75uRnD6PpYaCzWBa12us2Aphm/WvXudeHH8&#43;I&#43;qU=" crossorigin="anonymous"><link rel="stylesheet" href="/css/katex.min.d080a89e03e1eb850f547d835c186b4273f69879aa497eb8b0e88c1578bf1f0b.css" integrity="sha256-0ICongPh64UPVH2DXBhrQnP2mHmqSX64sOiMFXi/Hws=" crossorigin="anonymous">
<link rel="stylesheet" href="/css/viewer.min.3d228794bcedbbfa0412beb8fbc1ec6973202945e42af7004f742a4d7bd620ab.css" integrity="sha256-PSKHlLztu/oEEr64&#43;8HsaXMgKUXkKvcAT3QqTXvWIKs=" crossorigin="anonymous"></head>
  <body><script>const items=['mode','palette'];items.forEach(function(a){const b=localStorage.getItem('hbs-'+a);b&&document.body.parentElement.setAttribute('data-'+a,b)})</script><header><nav class="navbar top-app-bar top-app-bar-expand-lg fixed-top">
  <div class="container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <i class="fas fa-bars"></i>
    </button><a class="navbar-brand flex-grow-1 flex-lg-grow-0 text-center text-lg-start mx-auto me-lg-3" href="/"><img class="logo" alt="Logo" src="/images/logo.webp" loading="lazy"
   width="400" height="400"
   />
HOME
    </a>
    <div class="offcanvas offcanvas-bottom surface" tabindex="-1" id="offcanvasSocialShare" aria-labelledby="offcanvasSocialShare">
  <div class="offcanvas-header">
    <h3 class="offcanvas-title">Share</h3>
    <button type="button" class="btn btn-sm btn-outline-primary" data-bs-dismiss="offcanvas" aria-label="Close">
      <i class="fas fa-times"></i>
    </button>
  </div>
  <div class="offcanvas-body">
    <a class="btn btn-sm btn-outline-primary social-share-button" rel="noopener noreferrer" aria-label="Twitter Share Button"
      target="_blank" href="https://twitter.com/intent/tweet?title=T%c3%acm%20hi%e1%bb%83u%20v%e1%bb%81%20m%e1%ba%a1ng%20neural%20network%20AlexNet&url=%2fblog%2f2018-06-15-understanding-alexnet%2f">
      <i class="fab fa-fw fa-twitter"></i> Twitter
    </a>
    <a class="btn btn-sm btn-outline-primary social-share-button" rel="noopener noreferrer" aria-label="Facebook Share Button"
      target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=%2fblog%2f2018-06-15-understanding-alexnet%2f">
      <i class="fab fa-fw fa-facebook-f"></i> Facebook
    </a>
  </div>
</div>
    <button class="navbar-settings" type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvasSettings"
  aria-controls="offcanvasSettings" aria-label="Toggle settings">
  <i class="fas fa-ellipsis-v"></i>
</button>

<div class="offcanvas offcanvas-end surface h-100" tabindex="-1" id="offcanvasSettings" aria-labelledby="offcanvasSettings">
  <div class="offcanvas-header">
    <h3 class="offcanvas-title">Settings</h3>
    <button type="button" class="btn btn-sm btn-outline-primary" data-bs-dismiss="offcanvas" aria-label="Close">
      <i class="fas fa-times"></i>
    </button>
  </div>
  <div class="offcanvas-body d-flex flex-column">



<section class="setting">
  <form class="font-size-switcher-form row">
    <div class="col-auto">
      <label for="fontSize" class="form-label"><i class="fas fa-fw fa-font"></i> Font Size</label>
    </div>
    <div class="col-auto ms-auto">
      <input type="range" class="form-range" min="-2" max="2" id="fontSize">
    </div>
  </form>
</section>


<section class="setting palettes">
  <form class="row">
    <div class="col-auto">
      <label><i class="fas fa-fw fa-palette"></i> Palette</label>
    </div>
    <div class="col-auto ms-auto">
      <a id="btnPalette" class="btn btn-sm btn-outline-primary" role="button" aria-label="palettePicker">
        <i class="fas fa-eye-dropper"></i>
      </a>
    </div>
  </form>
  <div class="mt-2 d-flex justify-content-between visually-hidden" id="palettePicker"><button type="button" id="palette-blue" aria-label="Blue"
        class="btn btn-sm w-100 palette" data-palette="blue">
      </button><button type="button" id="palette-blue-gray" aria-label="Blue Gray"
        class="btn btn-sm w-100 palette" data-palette="blue-gray">
      </button><button type="button" id="palette-brown" aria-label="Brown"
        class="btn btn-sm w-100 palette" data-palette="brown">
      </button><button type="button" id="palette-cyan" aria-label="Cyan"
        class="btn btn-sm w-100 palette" data-palette="cyan">
      </button><button type="button" id="palette-green" aria-label="Green"
        class="btn btn-sm w-100 palette" data-palette="green">
      </button><button type="button" id="palette-indigo" aria-label="Indigo"
        class="btn btn-sm w-100 palette" data-palette="indigo">
      </button><button type="button" id="palette-orange" aria-label="Orange"
        class="btn btn-sm w-100 palette" data-palette="orange">
      </button><button type="button" id="palette-pink" aria-label="Pink"
        class="btn btn-sm w-100 palette" data-palette="pink">
      </button><button type="button" id="palette-purple" aria-label="Purple"
        class="btn btn-sm w-100 palette" data-palette="purple">
      </button><button type="button" id="palette-red" aria-label="Red"
        class="btn btn-sm w-100 palette" data-palette="red">
      </button><button type="button" id="palette-teal" aria-label="Teal"
        class="btn btn-sm w-100 palette" data-palette="teal">
      </button><button type="button" id="palette-yellow" aria-label="Yellow"
        class="btn btn-sm w-100 palette" data-palette="yellow">
      </button></div>
</section>
<section class="setting actions d-flex justify-content-around mt-auto overflow-auto">
  <a role="button" class="action action-go-back" href="javascript: window.history.back();">
    <span class="action-icon"><i class="fas fa-2x fa-arrow-left"></i></span> Go back
  </a>
  <a role="button" class="action action-reload-page">
    <span class="action-icon"><i class="fas fa-2x fa-redo-alt"></i></span> Reload
  </a>
  <a role="button" class="action action-copy-url">
    <span class="action-icon"><i class="fas fa-2x fa-link"></i></span> Copy URL
  </a><a class="action action-social-share" type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvasSocialShare"
    aria-controls="offcanvasSocialShare" aria-label="Toggle social share">
    <span class="action-icon"><i class="fas fa-2x fa-share-alt"></i></span> Share
  </a></section>

</div>
</div>

    <div class="collapse navbar-collapse" tabindex="-1" id="navbarSupportedContent" aria-labelledby="navbarSupportedContent">
      <form class="search-bar my-1" action="/search">
  <div class="input-group input-group-sm">
    <span class="btn btn-search disabled position-absolute left-0"><i class="fas fa-fw fa-search"></i></span>
    <input class="form-control rounded-pill" name="q" type="search" aria-label="Search">
  </div>
</form>
      <ul class="navbar-nav ms-auto"><li class="nav-item">
          <a class="nav-link" href="/series/">
            <i class="fas fa-fw fa-columns"></i>Series
          </a>
        </li><li class="nav-item">
          <a class="nav-link" href="/archives/">
            <i class="fas fa-fw fa-file-archive"></i>Archives
          </a>
        </li><li class="nav-item">
          <a class="nav-link" href="/categories/">
            <i class="fas fa-fw fa-folder"></i>Categories
          </a>
        </li><li class="nav-item">
          <a class="nav-link" href="/tools/">
            <i class="fas fa-fw fa-folder"></i>Tools
          </a>
        </li><li class="nav-item">
          <a class="nav-link" href="/tags/">
            <i class="fas fa-fw fa-tags"></i>Tags
          </a>
        </li><li class="nav-item dropdown">
          <a class="nav-link" id="navbarDropdownSupport" role="button" data-bs-toggle="dropdown" aria-expanded="false">
            <i class="fas fa-fw fa-chevron-circle-down"></i>Support
          </a>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdownSupport"><li>
              <a class="dropdown-item"
                href="https://www.facebook.com/groups/1354425091720104" target="_blank" rel="noopener noreferrer">
                Repository
              </a>
            </li><li>
              <a class="dropdown-item"
                href="https://www.facebook.com/groups/1354425091720104" target="_blank" rel="noopener noreferrer">
                Discussions
              </a>
            </li><li>
              <a class="dropdown-item"
                href="https://www.facebook.com/groups/1354425091720104" target="_blank" rel="noopener noreferrer">
                Features Request
              </a>
            </li><li><hr class="dropdown-divider"></li><li>
              <a class="dropdown-item"
                href="/faq/">
                FAQs
              </a>
            </li></ul>
        </li></ul>
    </div>
  </div>
</nav>
</header>
<main role="main" class="container">
      <div class="row content">
<div class="col-lg-8">
  <div class="container"><nav class="row card component" aria-label="breadcrumb">
  <div class="card-body">
    <ol class="breadcrumb "><li class="breadcrumb-item"><a href="/">Home</a></li><li class="breadcrumb-item"><a href="/blog/">Blogs</a></li><li class="breadcrumb-item active">Tìm Hiểu Về Mạng Neural Network AlexNet</li></ol>
  </div>
</nav>
<div class="post-panel-wrapper">
  <div class="d-flex flex-column component rounded post-panel">
    
    <a class="action action-panel-toggler" role="button" title="Panel toggler">
      <i class="fas fa-fw fa-chevron-circle-down"></i>
    </a>
    <a id="sidebarToggler" class="action d-none d-lg-block" role="button" title="Sidebar toggler">
  <i class="fas fa-fw fa-expand-alt" data-fa-transform="rotate-45"></i>
</a>

    

    
    
    <a class="action" href="#post-comments" role="button" aria-label="Comments" title="Comments">
  <i class="fas fa-fw fa-comments"></i>
</a>
    <a class="action" href="#postTOC" aria-controls="Table of contents" role="button" title="Table of contents">
  <i class="fas fa-fw fa-list-alt"></i>
</a>
    
  </div>
</div>
<article class="row card component mb-4 post">
  <div class="card-header ">
    <h1 class="card-title post-title">Tìm Hiểu Về Mạng Neural Network AlexNet
</h1>
  </div>
  <div class="card-body"><div class="post-meta">
  <span class="post-date" title="created on 2018-06-15 04:19:00 &#43;0700 &#43;07.">
    Jun 15, 2018
  </span><span class="post-reading-time">
    11 min read
  </span><span class="post-taxonomies"><a href="/tags/machine-learning/" class="badge post-taxonomy">Machine learning</a><a href="/tags/deeplearning/" class="badge post-taxonomy">Deeplearning</a><a href="/tags/alexnet/" class="badge post-taxonomy">AlexNet</a></span>
</div>
<div class="post-content mb-3"><h2 id="lời-mở-đầu">Lời mở đầu<a class="anchor ms-1" href="#lời-mở-đầu"><i class="fas fa-link"></i></a></h2>
<p>Tỷ phú Peter Thiel đã từng đưa ra câu hỏi tréo ngoe như thế này: &ldquo;What important truth do very few people agree with you on?&rdquo;</p>
<p>Nếu bạn đem câu này hỏi giáo sư Geoffrey Hinton vào năm 2010, ông ấy sẽ trả lời rằng mạng Convolutional Neural Networks (CNN) sẽ có bước đột phá lớn và giúp chúng ta giải quyết hoàn toàn bài toán phân loại ảnh. Tại thời điểm năm 2010, các nhà nghiên cứu trong lĩnh vực phân loại ảnh đều không nghĩ như giáo sư Geoffrey Hinton. Và Deep Learning tại thời điểm đó chưa thật sự giải quyết được bài toán này.</p>
<p>Năm 2010 cũng là năm ra đời của cuộc thi ImageNet Large Scale Visual Recognition Challenge. Tập dữ liệu ảnh trong cuộc thi bao gồm khoảng 1.2 triệu ảnh thuộc 1000 lớp khác nhau, người thắng cuộc là người tạo ra mô hình làm cho độ lỗi trên tập dữ liệu trên là nhỏ nhất.</p>
<p>Hai năm sau, trong bài báo &ldquo;ImageNet Classification with Deep Convolutional Neural Networks&rdquo; của nhóm tác giả Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton, Geoffrey và các cộng sự của mình đã chứng minh điều ông ấy nói hai năm trước là hoàn toàn chính xác.
Ở bài báo này, nhóm tác giả đã huấn luyện mạng CNN và và đạt độ lỗi top-5 error rate là 15.3% (nhóm tác giả đã giành hạng nhất), cách biệt khá xa so với kết quả của nhóm đứng thứ hai(độ lỗi 26.2%). Trong các năm tiếp theo, rất nhiều nhóm đã nghiên cứu, cải tiến kiến trúc của mô hình CNN để đạt được kết quả tốt hơn, thậm chí hơn luôn khả năng nhận biết của con người.</p>
<p>Kiến trúc mạng CNN được sử dụng vào năm 2012 được cộng đồng nghiên cứu gọi với tên gọi thân thương là AlexNet do tác giả chính của nhóm nghiên cứu là Alex Krizhevsky. Ở trong bài viết này, chúng ta sẽ đi sâu vào tìm hiểu kiến trúc AlexNet và đóng góp chính của nó trong CNN.</p>
<h2 id="đầu-vào">Đầu vào<a class="anchor ms-1" href="#đầu-vào"><i class="fas fa-link"></i></a></h2>
<p>Như đã đề cập ở phần trên, mạng AlexNet đã thắng hạng nhất trong cuộc thi ILSVRC năm 2012. Mô hình giải quyết bài toán phân lớp một bức ảnh vào 1 lớp trong 1000 lớp khác nhau (vd gà, chó, mèo &hellip; ). Đầu ra của mô hình là một vector có 1000 phần tử. Phần tử thứ i của vector đại diện cho xác suất bức ảnh thuộc về lớp thứ i. Do đó, tổng của các phần tử trong vector là 1.</p>
<p>Đầu vào của mạng AlexNet là một bức ảnh RGB có kích thước 256x256 pixel. Toàn bộ các bức ảnh của tập train và tập test đều có cùng kích thước là 256x256. Nếu một bức ảnh nào đó không có kích thước 256x256, bức ảnh đó sẽ được chuyển về kích thước đúng 256x256. Những bức hình có kích thước nhỏ hơn 256 thì sẽ được phóng bự lên đến kích thước 256, những bức hình nào có kích thước lớn hơn 256 thì sẽ được cắt loại phần thừa để nhận được bức hình có kích thước 256x256. Hình ảnh ở dưới là một ví dụ về việc điều chỉnh bức ảnh về kích thước 256x256.</p>
<p><img class="img-fluid" alt="Hình ảnh" src="/blog/2018-06-15-understanding-alexnet/alexnet-resize-crop-input.jpg" loading="lazy"
  
   />

</p>
<p>Nếu ảnh đầu vào là ảnh xám (grayscale), bức ảnh trên sẽ được chuyển đổi thành định dạng RGB bằng cách tạo ra 3 layer kênh màu giống nhau từ ảnh xám.</p>
<p>Sau khi chuẩn hoá hết tất cả các ảnh về dạng 256x256x3, nhóm tác giả chỉ sử dụng một phần của bức ảnh có kích thước 227x227x3 của một bức ảnh làm đầu vào cho mạng neural network. Trong bài báo nhóm tác giả ghi là 224x224, nhưng đây là một lỗi nhỏ của nhóm tác giả, và kích thước thực tế đầu vào của bức ảnh là 227x227.</p>
<h2 id="kiến-trúc-alexnet">Kiến trúc AlexNet<a class="anchor ms-1" href="#kiến-trúc-alexnet"><i class="fas fa-link"></i></a></h2>
<p>Kiến trúc AlexNet lớn hơn nhiều so với các kiến trúc CNNs được sử dụng trong thị giác máy tính trước kia (trước năm 2010), vd kiến trúc LeNet của Yann LeCun năm 1998. Nó có 60 triệu tham số và 650000 neural và tốn khoảng từ năm đến sáu ngày huấn luyện trên hai GPU GTX 580 3GB. Ngày nay, với sự tiến bộ vượt bật của GPU, chúng ta có nhiều kiến trúc CNN có cấu trúc phức tạp hơn, và hoạt động rất hiệu quả trên những tập dữ liệu phức tạp. Nhưng tại thời điểm năm 2012 thì việc huấn luyện mô hình với lượng tham số và neural lớn như vậy là một vấn đề cực kỳ khó khăn. Nhìn kỹ vào hình bên dưới để hiểu rõ hơn về kiến trúc AlexNet.
<img class="img-fluid" alt="Kiến trúc AlexNet" src="/blog/2018-06-15-understanding-alexnet/AlexNet-1.png" loading="lazy"
  
   />

</p>
<p>AlexNet bao gồm 5 convolution Layer và 3 Fully connected Layers.</p>
<p>Những convolution layer ( hay còn gọi với tên khác là các filter) rút trích các thông tin hữu ích trong các bức ảnh. Trong một convolution layer bất kỳ thường bao gồm nhiều kernel có cùng kích thước. Ví dụ như convolution layer đầu tiên của AlexNet chứa 96 kernel có kích thước 11x11x3. Thông thường thì width và height của một kernel bằng nhau, và độ sâu (depth) thường bằng số lượng kênh màu.</p>
<p>Convolutional 1 và convolution 2 kết nối với nhau qua một Overlapping Max Pooling ở giữa. Tương tự như vậy giữa convolution 2 và convolution 3. Convolutional 3, convolution 4, convolution 5 kết nối trực tiếp với nhau, không thông qua trung gian. Convolutional 5 kết nối fully connected layter 1 thông qua một Overlapping Max pooling, tiếp theo mà một fully connected layter nữa. Và cuối cùng là một bộ phân lớp softmax với 1000 lớp nhãn (các bạn có thể xem hình kiến trúc mạng AlexNet ở trên để có cái nhìn tổng quát hơn).</p>
<p>ReLU nonlinerity được sử dụng sau tất các các convolution và fully connected layer. Trước đây, ReLU nonlinerity của lớp convolution 1 và 2 thường theo sau bởi một bước chuẩn hoá cục bộ (local normalization) rồi mới thực hiện pooling. Tuy nhiên, các nghiên cứu sau đó nhận thấy rằng việc sử dụng normalization không thật sự hữu ích. Do vậy chúng ta sẽ không đi chi tiết về vấn đề đó.</p>
<h2 id="overlapping-max-pooling">Overlapping Max Pooling<a class="anchor ms-1" href="#overlapping-max-pooling"><i class="fas fa-link"></i></a></h2>
<p>Max Pooling layer thường được sử dụng để giảm chiều rộng và chiều dài của một tensor nhưng vẫn giữ nguyên chiều sâu. Overlapping Max Pool layter cũng tương tự như Max Pool layter, ngoại trừ việc là một window của bước này sẽ có một phần chồng lên window của bước tiếp theo. Tác giả sử dụng pooling có kích thước 3x3 và bước nhảy là 2 giữa các pooling. Nghĩa là giữa pooling này và pooling khác sẽ overlapping với nhau 1 pixel. Các thí nghiệm thực tế đã chứng minh rằng việc sử dụng overlapping giữa các pooling giúp giảm độ lỗi top-1 error 0.4% và top-5 error là 0.3% khi so với việc sử dụng pooling có kích thước 2x2 và bước nhảy 2 (vector output của cả hai đều có số chiều bằng nhau).</p>
<h2 id="relu-nonlinearity">ReLu Nonlinearity<a class="anchor ms-1" href="#relu-nonlinearity"><i class="fas fa-link"></i></a></h2>
<p>Một cải tiến quan trọng khác của AlexNet là việc sử dụng hàm phi tuyến ReLU. Trước đây, các nhóm nghiên cứu khác thường sử dụng hàm kích hoạt là hàm Tanh hoặc hàm Sigmoid để huấn luyên mô hình neural network. AlexNet chỉ ra rằng, khi sử dụng ReLU, mô hình deep CNN sẽ huấn luyện nhanh hơn so với viêc sử dụng tanh hoặc sigmoid. Hình bên dưới được rút ra từ bài báo chỉ ra rằng với việc sử dụng ReLU (đường nét liền trong hình), AlexNet đạt độ lỗi 25% trên tập huấn luyện và nhanh hơn gấp 6 lần so với mô hình tương tự nhưng sử dụng Tanh (đường nét đứt trong hình). Thí nghiệm trên sử dụng tập dữ liệu CIFAR-10 để huấn luyện.</p>
<p><img class="img-fluid" alt="Tốc độ hội tụ của mạng AlexNet" src="/blog/2018-06-15-understanding-alexnet/ReluNonlinearity-768x635.png" loading="lazy"
  
   />

</p>
<p>Để hiểu rõ hơn lý do vì sao ReLU lại nhanh hơn so với các hàm khác, chúng ta hãy đối sánh hình dạng giá trị output của các hàm trên.</p>
<p>Công thức của ReLU là: f(X) = max(0,x)</p>
<p><img class="img-fluid" alt="Hàm kích hoạt của ReLU và tanh" src="/blog/2018-06-15-understanding-alexnet/Tanh-300x238.png" loading="lazy"
  
   />

</p>
<p>Nhìn kỹ vào hình trên, ta có nhận xét rằng: hàm tanh đạt giá trị bão hoà khi giá trị z &gt;2.5 và z &lt; -2.5 (số 2.5 là số cảm tính của mình). Và tại vùng |z|&gt;2.5, thì độ dốc của hàm hầu như gần như bằng 0, |z| càng lớn thì độ dốc càng gần 0 hơn. Vì lý do này nên gradient descent sẽ hội tụ chậm. Còn đối với hàm ReLU, với giá trị z dương thì độ dốc của hàm không gần bằng 0 như hàm tanh. Điều này giúp cho việc hội tụ xảy ra nhanh hơn. Với giá trị z âm, độ dốc bằng 0, tuy nhiên, hầu hết các giá trị của các neural trong mạng thường có giá trị dương, nên trường hợp âm ít (hiếm) khi xảy ra. ReLU huấn luyện nhanh hơn so với sigmoid cũng bởi lý do tương tự.</p>
<h2 id="reducing-overfitting">Reducing overfitting<a class="anchor ms-1" href="#reducing-overfitting"><i class="fas fa-link"></i></a></h2>
<h3 id="overfitting-là-gì">Overfitting là gì?<a class="anchor ms-1" href="#overfitting-là-gì"><i class="fas fa-link"></i></a></h3>
<p>Khi bạn dạy một đứa trẻ từ 2-5 tuổi về việc cộng hai số, chúng sẽ học rất nhanh và trả lời đúng hầu hết các câu hỏi mà chúng ta đã dạy chúng. Tuy nhiên, chúng sẽ trả lời sai đối với những câu hỏi hơi lắc léo một chút (câu hỏi tương tự câu chúng ta đã dạy, nhưng thêm một xíu thông tin đòi hỏi trẻ phải suy nghĩ), hoặc các câu hỏi chưa được dạy. Lý do chúng trả lời sai những câu hỏi đó là khi trả lời những câu hỏi được dạy, chúng thường nhớ lại câu trả lời, chứ không thực sự hiểu câu hỏi. Cái này ở Việt Nam ta gọi là học vẹt.</p>
<p>Tương tự vậy, Neural network chính bản thân nó có khả năng học được những gì được dạy, tuy nhiên, nếu quá trình huấn luyện của bạn không tốt, mô hình có khả năng sẽ giống như những đứa trẻ trên kia, hồi tưởng lại những gì đã dạy cho chúng mà không hiểu bản chất. Và kết quả Neural Network sẽ hoạt động tốt trên tập huấn luyện ( nhưng chúng không rút ra được bản chất chính của vấn đề), và kết quả trên tập test tệ. Người ta gọi trường hợp trên là <strong>overfitting</strong>.</p>
<p>Nhóm nghiên cứu AlexNet sử dụng nhiều phương pháp khác nhau để giảm overfitting.</p>
<h3 id="data-augmentation">Data Augmentation<a class="anchor ms-1" href="#data-augmentation"><i class="fas fa-link"></i></a></h3>
<p>Việc sử dụng nhiều biến thể khác nhau của một bức hình có thể giúp ngăn mô hình không bị overfitting. Với việc sử dụng nhiều biến thể của 1 bức hình, bạn bắt ép mô hình không học vẹt dữ liệu. Có nhiều cách khác nhau để sinh ra dữ liệu mới dựa vào dữ liệu có sẵn. Một vài các mà nhóm AlexNet đã sử dụng là.</p>
<h4 id="data-augmentation-by-mirroring">Data Augmentation by Mirroring<a class="anchor ms-1" href="#data-augmentation-by-mirroring"><i class="fas fa-link"></i></a></h4>
<p>Ý tưởng của việc này là lấy ảnh trong gương của một bức hình (ảnh ảo). Nhìn vào ảnh bên dưới, bên trái là hình gốc của con mèo trong tập huấn luyện, bên phải là ảnh của con mèo khi thêm hiệu ứng hình qua gương (đơn giản là xoay qua trục y là được )
<img class="img-fluid" alt="Tái tạo ảnh sử dụng phản ảnh" src="/blog/2018-06-15-understanding-alexnet/AlexNet-Data-Augmentation-Mirror-Image.jpg" loading="lazy"
  
   />

</p>
<h4 id="data-augmentation-by-random-crops">Data Augmentation by Random Crops<a class="anchor ms-1" href="#data-augmentation-by-random-crops"><i class="fas fa-link"></i></a></h4>
<p>Việc lựa chọn vị trí ảnh gốc một cách ngẫu nhiên cũng giúp chúng ta có thêm một ảnh khác so với ảnh gốc ban đầu.</p>
<p>Nhóm tác giả của AlexNet rút trích ngẫu nhiên bức ảnh có kích thước 227x227 từ bức ảnh 256x256 ban đầu làm input dầu vào cho mô hình. Bằng cách này, chúng ta có thể tăng số lượng dữ liệu lên gấp 2048 lần bằng việc sử dụng cách này.</p>
<p><img class="img-fluid" alt="radom select" src="/blog/2018-06-15-understanding-alexnet/AlexNet-Data-Augmentation-Random-Crops.jpg" loading="lazy"
  
   />

</p>
<p>Bốn bức ảnh được crop ngẫu nhiên ở trên thoạt nhìn có vẻ giống nhau, nhưng thực chất không phải như vậy.</p>
<p>Với việc sử dụng Data Augmentation, chúng ta đang bố gắng dạy cho mô hình rằng với việc nhìn hình con mèo qua gương, nó vẫn là con mèo, hoặc hình hình con mèo ở bất kỳ góc độ nào thì nó vẫn là nó.</p>
<h3 id="dropout">Dropout<a class="anchor ms-1" href="#dropout"><i class="fas fa-link"></i></a></h3>
<p>Với gần 60 triệu tham số trong tập huấn luyện, việc overfitting xảy ra là điều dễ hiểu. Các tác giả của AlexNet đã thực nghiệm nhiều cách nữa để giảm overfitting. Họ sử dụng một kỹ thuật gọi là dropout - kỹ thuật này được giới thiệu ở bài báo khác của G.E. Hintol vào năm 2012. Kỹ thuật này khá đơn giản, một neural sẽ có xác suất bị loại khỏi mô hình là 0.5. Khi một neural bị loại khỏi mô hình, nó sẽ không được tham qia vào quá trình lan truyền tiến hoặc lan truyền ngược. Cho nên, mỗi giá trị input sẽ đi qua một kiến trúc mạng khác nhau. Như mô tả ở hình động ở dưới, kết quả là giá trị của tham số trọng số sẽ tốt hơn và khó bị overfitting hơn. Trong quá trình test, toàn bộ network được sử dụng, không có dropout, tuy nhiên, giá trị output sẽ scaled bởi tham số 0.5 tương ứng với những neural không sử dụng trong quá trình trainning. Với việc sử dụng dropout, chúng ta sẽ tăng gấp đôi lần lặp cần thiết để đạt được độ hội tụ, nhưng khi không sử dụng dropout, mạng AlexNet rất dễ bị overfitting.</p>
<p><img class="img-fluid" alt="drop out" src="/blog/2018-06-15-understanding-alexnet/dropoutAnimation.gif" loading="lazy"
  
   />

</p>
<p>Ngày nay, chuẩn hoá dropout là một yếu tố không thể thiếu và các mô hình sử dụng nó thường có kết quả tốt hơn so với mô hình tương tự không sử dụng dropout. Chúng ta sẽ bàn sâu hơn về dropout ở một bài khác trong tương lai.</p>
<p>Tham khảo</p>
<p>ImageNet Classification with Deep Convolutional Neural Networks  by Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton, 2012</p>
<p><a href="https://www.learnopencv.com/understanding-alexnet/" target="_blank" rel="noopener noreferrer">https://www.learnopencv.com/understanding-alexnet/</a></p>
</div></div>
  <div class="card-footer"><div class="post-navs d-flex justify-content-evenly"><div class="post-nav post-next">
    <a href="/blog/2018-10-01-buiding-a-movie-model/">Xây Dựng Chương Trình Gợi Ý Phim Dựa Vào Tập Dữ Liệu Movie Len
</a>
    <i class="fas fa-fw fa-chevron-right"></i>
  </div></div></div>
</article><div class="card component row post-comments" id="post-comments">
  <div class="card-header">
    <h2 class="card-title">Comments</h2>
  </div>
  <div class="card-body"><script src="https://utteranc.es/client.js"
  repo="AlexBlack2202/utterances"
  issue-term="pathname"
  label="comment"
  theme="github-light"
  crossorigin="anonymous"
  async>
</script></div>
</div></div>
</div><aside class="col-lg-4 sidebar d-flex">
  <div class="container d-flex flex-column">
    
    <section class="card row text-center profile component">
  <div class="card-body">
    <div class="col-12 d-flex align-items-center justify-content-center"><img class="profile-avatar rounded-circle" alt="Đặng Thị Hằng | Phạm Duy Tùng" src="/images/profile.webp" loading="lazy"
   width="736" height="920"
   />
</div>
    <div class="col-12 profile-meta"><div class="profile-name">Đặng Thị Hằng | Phạm Duy Tùng</div><div class="profile-bio">Gopher, CShaper, Pythoner, Full Stack Engineer.</div><div class="profile-company"><i class="fas fa-fw fa-building"></i>MWG</div><div class="profile-location"><i class="fas fa-fw fa-map-marker-alt"></i>Earth</div><div class="profile-about"><i class="fas fa-fw fa-user"></i><a href="/about/">About</a></div><div class="profile-contact"><i class="fas fa-fw fa-question-circle"></i><a href="/contact/">Contact Us</a></div>
</div>
  </div>
</section>
  <div class="post-toc row mb-4 card component" id="postTOC">
  <div class="card-header">
    <h2 class="card-title">Contents</h2>
  </div>
  <div class="card-body">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#lời-mở-đầu">Lời mở đầu</a></li>
    <li><a href="#đầu-vào">Đầu vào</a></li>
    <li><a href="#kiến-trúc-alexnet">Kiến trúc AlexNet</a></li>
    <li><a href="#overlapping-max-pooling">Overlapping Max Pooling</a></li>
    <li><a href="#relu-nonlinearity">ReLu Nonlinearity</a></li>
    <li><a href="#reducing-overfitting">Reducing overfitting</a>
      <ul>
        <li><a href="#overfitting-là-gì">Overfitting là gì?</a></li>
        <li><a href="#data-augmentation">Data Augmentation</a></li>
        <li><a href="#dropout">Dropout</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div><section class="recent-posts row card component">
  <div class="card-header">
    <h2 class="card-title">Recent Posts</h2>
  </div>
  <div class="card-body">
    <ul class="post-list"><li>
        <a href="/blog/2021-11-06-some-way-make-momey-from-web-scrapping/">Một Số Cách Kiếm Thêm Thu Nhập Từ Cách Cào Dữ Liệu
</a>
      </li><li>
        <a href="/blog/2021-08-12-china_chess_alpha_beta_ai/">Xây Dựng Chương Trình AI Đơn Giản Cho Game Cờ Tướng
</a>
      </li><li>
        <a href="/blog/2021-07-28-pycaret-flaskapi/">Tìm Hiểu Package PyCaret Trong Python
</a>
      </li><li>
        <a href="/blog/2021-07-02-mo-hinh-phan-quyen/">Mô Hình Phân Quyền - Access Control
</a>
      </li><li>
        <a href="/blog/2021-05-30-upgrade-wls-to-wls2/">Nâng Cấp WSL Lên Bản WSL 2 Trên Window 10
</a>
      </li></ul>
  </div>
</section><section class="series-taxonomies row card component">
      <div class="card-header">
        <h2 class="card-title">
          <a href="/series">Series</a>
        </h2>
      </div>
      <div class="card-body">
        <div class="py-2"><a href="/series/kh%C3%B3a-h%E1%BB%8Dc-c&#43;&#43;-c%C4%83n-b%E1%BA%A3n/" class="badge rounded post-taxonomy" title="Khóa học c&#43;&#43; căn bản">
            Khóa học c&#43;&#43; căn bản<span class="badge badge-sm text-white bg-accent ms-1">3</span></a><a href="/series/machine-learning-dataset/" class="badge rounded post-taxonomy" title="Machine learning dataset">
            Machine learning dataset<span class="badge badge-sm text-white bg-accent ms-1">2</span></a><a href="/series/tools/" class="badge rounded post-taxonomy" title="tools">
            tools<span class="badge badge-sm text-white bg-accent ms-1">2</span></a><a href="/series/kh%C3%B3a-h%E1%BB%8Dc-python-c%C4%83n-b%E1%BA%A3n/" class="badge rounded post-taxonomy" title="Khóa học python căn bản">
            Khóa học python căn bản<span class="badge badge-sm text-white bg-accent ms-1">1</span></a></div>
      </div>
    </section><section class="categories-taxonomies row card component">
      <div class="card-header">
        <h2 class="card-title">
          <a href="/categories">Categories</a>
        </h2>
      </div>
      <div class="card-body">
        <div class="py-2"><a href="/categories/c&#43;&#43;/" class="badge rounded post-taxonomy" title="c&#43;&#43;">
            c&#43;&#43;<span class="badge badge-sm text-white bg-accent ms-1">3</span></a><a href="/categories/dataset/" class="badge rounded post-taxonomy" title="dataset">
            dataset<span class="badge badge-sm text-white bg-accent ms-1">2</span></a><a href="/categories/tools/" class="badge rounded post-taxonomy" title="tools">
            tools<span class="badge badge-sm text-white bg-accent ms-1">2</span></a><a href="/categories/python/" class="badge rounded post-taxonomy" title="python">
            python<span class="badge badge-sm text-white bg-accent ms-1">1</span></a></div>
      </div>
    </section><section class="tags-taxonomies row card component">
      <div class="card-header">
        <h2 class="card-title">
          <a href="/tags">Tags</a>
        </h2>
      </div>
      <div class="card-body">
        <div class="py-2"><a href="/tags/machine-learning/" class="badge rounded post-taxonomy" title="Machine learning">
            Machine learning<span class="badge badge-sm text-white bg-accent ms-1">38</span></a><a href="/tags/deeplearning/" class="badge rounded post-taxonomy" title="Deeplearning">
            Deeplearning<span class="badge badge-sm text-white bg-accent ms-1">20</span></a><a href="/tags/deep-learning/" class="badge rounded post-taxonomy" title="Deep learning">
            Deep learning<span class="badge badge-sm text-white bg-accent ms-1">15</span></a><a href="/tags/python/" class="badge rounded post-taxonomy" title="python">
            python<span class="badge badge-sm text-white bg-accent ms-1">10</span></a><a href="/tags/opencv/" class="badge rounded post-taxonomy" title="opencv">
            opencv<span class="badge badge-sm text-white bg-accent ms-1">5</span></a><a href="/tags/c&#43;&#43;/" class="badge rounded post-taxonomy" title="c&#43;&#43;">
            c&#43;&#43;<span class="badge badge-sm text-white bg-accent ms-1">4</span></a><a href="/tags/object-detector/" class="badge rounded post-taxonomy" title="object detector">
            object detector<span class="badge badge-sm text-white bg-accent ms-1">4</span></a><a href="/tags/alexnet/" class="badge rounded post-taxonomy" title="AlexNet">
            AlexNet<span class="badge badge-sm text-white bg-accent ms-1">3</span></a><a href="/tags/d%E1%BB%B1-%C4%91o%C3%A1n/" class="badge rounded post-taxonomy" title="dự đoán">
            dự đoán<span class="badge badge-sm text-white bg-accent ms-1">3</span></a><a href="/tags/forecast/" class="badge rounded post-taxonomy" title="forecast">
            forecast<span class="badge badge-sm text-white bg-accent ms-1">3</span></a></div>
      </div>
    </section>
    
  </div>
</aside>
</div>
    </main><footer class="footer mt-auto py-3 text-center container"><ul class="nav justify-content-between footer-memu mb-3"><li class="nav-item"><ul class="nav flex-column align-items-start">
      <li class="nav-item">
        <a class="nav-link fw-bold" target="_blank" rel="noopener noreferrer">Support
</a>
      </li><li class="nav-item">
            <a class="nav-link" href="https://www.facebook.com/groups/1354425091720104" target="_blank" rel="noopener noreferrer"><i class="fab fa-fw fa-github"></i>Repository
</a>
        </li><li class="nav-item">
            <a class="nav-link" href="https://www.facebook.com/groups/1354425091720104" target="_blank" rel="noopener noreferrer"><i class="fas fa-fw fa-comments"></i>Discussions
</a>
        </li><li class="nav-item">
            <a class="nav-link" href="https://www.facebook.com/groups/1354425091720104" target="_blank" rel="noopener noreferrer">Features Request
</a>
        </li><li class="nav-item">
            <a class="nav-link" href="https://www.facebook.com/groups/1354425091720104" target="_blank" rel="noopener noreferrer">Bug Report
</a>
        </li><li class="nav-item">
            <a class="nav-link" href="/contact/"><i class="fas fa-fw fa-info-circle"></i>Contact Us
</a>
        </li><li class="nav-item">
            <a class="nav-link" href="/faq/"><i class="fas fa-fw fa-question-circle"></i>FAQs
</a>
        </li></ul></li><li class="nav-item"><li class="nav-item">
      <a class="nav-link" target="_blank" rel="noopener noreferrer">Docs
</a>
    </li></li><li class="nav-item"><li class="nav-item">
      <a class="nav-link" target="_blank" rel="noopener noreferrer">Features
</a>
    </li></li><li class="nav-item"><ul class="nav flex-column align-items-start">
      <li class="nav-item">
        <a class="nav-link fw-bold" target="_blank" rel="noopener noreferrer">Demo
</a>
      </li><li class="nav-item">
            <a class="nav-link" href="https://www.facebook.com/groups/1354425091720104" target="_blank" rel="noopener noreferrer">Netlify
</a>
        </li><li class="nav-item">
            <a class="nav-link" href="https://www.facebook.com/groups/1354425091720104" target="_blank" rel="noopener noreferrer">China
</a>
        </li></ul></li></ul>
<div class="copyright mb-2">
  Copyright © 2016-2022 Phạm Duy Tùng. All Rights Reserved.
</div>
<div class="powered-by mb-2">
  Website chia sẻ kiến thức của Phạm Duy Tùng và Đặng Thị Hằng. Vui lòng liên hệ email alexblack2202@gmail.com nếu bạn có thông tin cần trao đổi.
</div></footer>
<script src="/js/main.0f06b653e090cf5f3e595cc4f3150328397d377ee5b405d0803057801eb4f3e5.js" integrity="sha256-Dwa2U&#43;CQz18&#43;WVzE8xUDKDl9N37ltAXQgDBXgB608&#43;U=" crossorigin="anonymous" defer></script><script src="/js/icons.min.8ddcaafc364ff0296c2209c5495287f0de039b852da9b24847f94c198b7639b6.js" integrity="sha256-jdyq/DZP8ClsIgnFSVKH8N4Dm4UtqbJIR/lMGYt2ObY=" crossorigin="anonymous" defer></script>
<script>
if ('serviceWorker' in navigator) {
  window.addEventListener('load', () => {
    navigator.serviceWorker.register('\/service-worker.js').then(function(reg) {
      console.log('Successfully registered service worker', reg);
    }).catch(function(err) {
      console.warn('Error whilst registering service worker', err);
    });
  });
}
</script><script src="/js/viewer.min.652118a9fbf3403cdfde4026209f97ace22f9e334f0b45a33431a221b3db46a8.js" integrity="sha256-ZSEYqfvzQDzf3kAmIJ&#43;XrOIvnjNPC0WjNDGiIbPbRqg=" crossorigin="anonymous" defer></script><script defer src="/js/katex.min.a575e93a07f02f7e58ee9002aea3b4e75163d4fa8ea3a627e90e7fafd5c718fa.js" integrity="sha256-pXXpOgfwL35Y7pACrqO051Fj1PqOo6Yn6Q5/r9XHGPo=" crossorigin="anonymous"></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-114911596-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</body>
</html>
