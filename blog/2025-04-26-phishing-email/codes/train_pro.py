# Import th∆∞ vi·ªán c·∫ßn thi·∫øt
import os
import json
import joblib
import logging
import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split, ParameterGrid, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tqdm import tqdm

# Kh·ªüi t·∫°o h·ªá th·ªëng logging
def initLogging(logFile="train.log"):
    logging.basicConfig(
        filename=logFile,
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
    )
    logging.info("üöÄ B·∫Øt ƒë·∫ßu ghi log cho qu√° tr√¨nh hu·∫•n luy·ªán...")

# H√†m l∆∞u best params ra file JSON
def saveBestParams(params, filePath):
    try:
        with open(filePath, "w") as f:
            json.dump(params, f, indent=4)
        logging.info(f"üìù Best Params ƒë√£ l∆∞u t·∫°i {filePath}")
    except Exception as e:
        logging.error(f"‚ùå L·ªói khi l∆∞u best params: {e}")

# H√†m load best params n·∫øu c√≥
def loadBestParams(filePath):
    try:
        if os.path.exists(filePath):
            with open(filePath, "r") as f:
                params = json.load(f)
            logging.info(f"‚úÖ Load Best Params t·ª´ {filePath}")
            return params
    except Exception as e:
        logging.error(f"‚ùå L·ªói khi load best params: {e}")
    return None

def trainSingleModel(X_train, y_train, X_test, y_test, modelName, basePipeline, paramGrid, modelDirectory):
    """
    Hu·∫•n luy·ªán 1 m√¥ h√¨nh duy nh·∫•t theo t√™n modelName, pipeline, paramGrid
    """
    print(f"üîµ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh {modelName}...")
    bestScore = -np.inf
    noImproveRounds = 0
    earlyStoppingRounds = 5
    bestModel = None

    # File l∆∞u best params
    bestParamsPath = os.path.join(modelDirectory, f"{modelName}_best_params.json")

    # Check n·∫øu ƒë√£ c√≥ best_params th√¨ kh√¥ng c·∫ßn GridSearch n·ªØa
    loadedParams = loadBestParams(bestParamsPath)
    if loadedParams:
        try:
            bestModel = basePipeline.set_params(**loadedParams)
            bestModel.fit(X_train, y_train)
            print(f"‚úÖ ƒê√£ load tham s·ªë t·ªëi ∆∞u, kh√¥ng c·∫ßn train l·∫°i {modelName}.")
        except Exception as e:
            logging.error(f"‚ùå L·ªói khi load v√† fit m√¥ h√¨nh t·ª´ best params: {e}")
            loadedParams = None

    if not loadedParams:
        paramList = list(ParameterGrid(paramGrid))

        with tqdm(total=len(paramList), desc=f"Training {modelName} + EarlyStopping") as pbar:
            for params in paramList:
                try:
                    tempPipeline = basePipeline.set_params(**params)
                    scores = cross_val_score(tempPipeline, X_train, y_train, cv=5, scoring="accuracy", n_jobs=-1)
                    meanScore = scores.mean()

                    if meanScore > bestScore:
                        bestScore = meanScore
                        bestParams = params
                        noImproveRounds = 0

                        # Fit m√¥ h√¨nh t·ªët nh·∫•t lu√¥n
                        bestModel = tempPipeline.fit(X_train, y_train)
                        # Save checkpoint
                        checkpointPath = os.path.join(modelDirectory, f"{modelName}_checkpoint.pkl")
                        joblib.dump(bestModel, checkpointPath)
                        logging.info(f"üíæ C·∫≠p nh·∫≠t checkpoint {modelName} t·∫°i {checkpointPath}")
                    else:
                        noImproveRounds += 1

                    pbar.set_postfix({"Best Score": f"{bestScore:.4f}"})
                    pbar.update(1)

                    if noImproveRounds >= earlyStoppingRounds:
                        print(f"‚èπÔ∏è EarlyStopping cho {modelName} sau {earlyStoppingRounds} l·∫ßn kh√¥ng c·∫£i thi·ªán.")
                        break
                except Exception as e:
                    logging.error(f"‚ùå L·ªói khi hu·∫•n luy·ªán v·ªõi tham s·ªë {params}: {e}")
                    continue

        # Save best params ra file
        if bestParams:
            saveBestParams(bestParams, bestParamsPath)

    # ƒê√°nh gi√° m√¥ h√¨nh
    if bestModel:
        yPred = bestModel.predict(X_test)
        acc = accuracy_score(y_test, yPred)
        precision = precision_score(y_test, yPred, average='weighted')
        recall = recall_score(y_test, yPred, average='weighted')
        f1 = f1_score(y_test, yPred, average='weighted')

        print(f"üéØ {modelName} - Accuracy tr√™n t·∫≠p test: {acc * 100:.2f}%")
        print(f"üéØ {modelName} - Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}")
        logging.info(f"üéØ {modelName} - Test Metrics: Accuracy={acc:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}")

        # L∆∞u final model
        finalModelPath = os.path.join(modelDirectory, f"{modelName}_final.pkl")
        joblib.dump(bestModel, finalModelPath)
        logging.info(f"üíæ M√¥ h√¨nh {modelName} ƒë√£ l∆∞u t·∫°i {finalModelPath}")

def trainEnsemblePhishingModels():
    """
    H√†m ch√≠nh ƒë·ªÉ hu·∫•n luy·ªán nhi·ªÅu m√¥ h√¨nh ensemble.
    """

    # B∆∞·ªõc 1: Setup th∆∞ m·ª•c + logging
    modelDirectory = "model"
    os.makedirs(modelDirectory, exist_ok=True)
    initLogging(os.path.join(modelDirectory, "train.log"))

    # B∆∞·ªõc 2: Load d·ªØ li·ªáu
    try:
        df = pd.read_csv("data/Phishing_Email.csv")
        if "Email Text" not in df.columns or "Email Type" not in df.columns:
            raise ValueError("D·ªØ li·ªáu kh√¥ng ch·ª©a c√°c c·ªôt c·∫ßn thi·∫øt.")
        X = df["Email Text"].fillna("")
        y = df["Email Type"]
    except Exception as e:
        logging.error(f"‚ùå L·ªói khi load d·ªØ li·ªáu: {e}")
        return

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # B∆∞·ªõc 3: ƒê·ªãnh nghƒ©a c√°c pipelines
    pipelines = {
        "LogisticRegressionModel": Pipeline([
            ("tfidf", TfidfVectorizer(stop_words="english")),
            ("clf", LogisticRegression(solver="liblinear", max_iter=1000))
        ]),
        "RandomForestModel": Pipeline([
            ("tfidf", TfidfVectorizer(stop_words="english")),
            ("clf", RandomForestClassifier(n_jobs=-1, random_state=42))
        ])
    }

    # B∆∞·ªõc 4: C√°c t·∫≠p tham s·ªë t∆∞∆°ng ·ª©ng
    paramGrids = {
        "LogisticRegressionModel": {
            "tfidf__ngram_range": [(1,1), (1,2)],
            "tfidf__max_df": [0.8, 1.0],
            "clf__C": [0.1, 1.0, 10],
            "clf__class_weight": [None, "balanced"]
        },
        "RandomForestModel": {
            "tfidf__max_features": [None, 10000],
            "tfidf__ngram_range": [(1,1)],
            "clf__n_estimators": [100, 200],
            "clf__max_depth": [None, 10, 20],
            "clf__min_samples_split": [2, 5]
        }
    }

    # B∆∞·ªõc 5: Hu·∫•n luy·ªán t·ª´ng model
    for modelName, pipeline in pipelines.items():
        paramGrid = paramGrids[modelName]
        trainSingleModel(X_train, y_train, X_test, y_test, modelName, pipeline, paramGrid, modelDirectory)

if __name__ == "__main__":
    trainEnsemblePhishingModels()