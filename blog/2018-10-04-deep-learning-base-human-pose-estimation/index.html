<!DOCTYPE HTML>

<html>
    <head>
        <script type="application/ld+json">
    {
        "@context" : "http://schema.org",
        "@type" : "BlogPosting",
        "mainEntityOfPage": {
             "@type": "WebPage",
             "@id": "/"
        },
        "articleSection" : "blog",
        "name" : "Deep Learning based Human Pose Estimation using OpenCV",
        "headline" : "Deep Learning based Human Pose Estimation using OpenCV",
        "description" : "Ở bài viết này, chúng ta đề cập đến vấn đề sử dụng Deep Neural Net trong việc thực hiện Human Pose Estimation.",
        "inLanguage" : "en",
        "author" : "",
        "creator" : "",
        "publisher": "",
        "accountablePerson" : "",
        "copyrightHolder" : "",
        "copyrightYear" : "2018",
        "datePublished": "2018-10-04 00:19:00 &#43;0300 &#43;0300",
        "dateModified" : "2018-10-04 00:19:00 &#43;0300 &#43;0300",
        "url" : "/blog/2018-10-04-deep-learning-base-human-pose-estimation/",
        "wordCount" : "1229",
        "keywords" : [ "Machine learning","Deeplearning","pose estimation","Blog" ]
    }
    </script>
        
            
                <title>Deep Learning based Human Pose Estimation using OpenCV</title>
            
        

        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        
		<meta name="generator" content="Phạm Duy Tùng" />
        
  
    
  

  

  
  
  
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content='/favicon/mstile.png'>
  <meta name="application-name" content="Phạm Duy Tùng Machine Learning Blog">
  <meta name="msapplication-tooltip" content="Blog ML của Phạm Duy Tùng và Đặng Thị Hằng">
   
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">



        
        
            <meta name="description" content="Ở bài viết này, chúng ta đề cập đến vấn đề sử dụng Deep Neural Net trong việc thực hiện Human Pose Estimation.">
        

        <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Deep Learning based Human Pose Estimation using OpenCV"/>
<meta name="twitter:description" content="Ở bài viết này, chúng ta đề cập đến vấn đề sử dụng Deep Neural Net trong việc thực hiện Human Pose Estimation."/>
<meta name="twitter:site" content="@example"/>

        <meta property="og:title" content="Deep Learning based Human Pose Estimation using OpenCV" />
<meta property="og:description" content="Ở bài viết này, chúng ta đề cập đến vấn đề sử dụng Deep Neural Net trong việc thực hiện Human Pose Estimation." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/2018-10-04-deep-learning-base-human-pose-estimation/" /><meta property="article:published_time" content="2018-10-04T00:19:00&#43;03:00"/>
<meta property="article:modified_time" content="2018-10-04T00:19:00&#43;03:00"/>

        <meta property="og:image" content="//images/logo.png">
        <meta property="og:image:type" content="image/png">
        <meta property="og:image:width" content="512">
        <meta property="og:image:height" content="512">
        
<meta itemprop="name" content="Deep Learning based Human Pose Estimation using OpenCV">
<meta itemprop="description" content="Ở bài viết này, chúng ta đề cập đến vấn đề sử dụng Deep Neural Net trong việc thực hiện Human Pose Estimation.">


<meta itemprop="datePublished" content="2018-10-04T00:19:00&#43;03:00" />
<meta itemprop="dateModified" content="2018-10-04T00:19:00&#43;03:00" />
<meta itemprop="wordCount" content="1229">



<meta itemprop="keywords" content="Machine learning,Deeplearning,pose estimation," />

        

        
            
        

        
        
          
			
			 <link rel="stylesheet" href="/css/font-awesome.min.css">
			 <link rel="stylesheet" href="/css/bootstrap.min.css">


          
            <link rel="stylesheet" href="/css/academicons.min.css">
        

        
            
                
            
        


  
    
    <link href='//cdn.bootcss.com/highlight.js/9.15.8/styles/xcode.min.css' rel='stylesheet' type='text/css' />
  


      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-114911596-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

	  
	  <style>
	  
	  body{
font-family: Helvetica,Arial,sans-serif;
}

.card{
	margin-bottom: 10px;
}

#disqus_thread{
padding: 0 5px;
}

.item-header{
padding: 0;
}

.single-content-img{
width: 100%;
    max-height: 450px !important;
    background-size: cover;
    display: block;
    background-position: center;
}

.thumbnail {
    position: relative;
}

.caption {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
	background: rgba(0, 0, 0, 0.25);
	text-align:left;
}

.caption .title{
	font-size: 1.6em;
    line-height: 1.4em;
    top: 0;
	margin-left:20px;
	margin-top:20px;
	
}

.caption .title-caption{
margin-left:10px;
}

#content p{
text-align: justify;
    line-height: 1.9;
    font-size: 12pt;
}

#content img{
	display: block;
    margin-left: auto;
margin-right: auto;
max-width:98%;
}

img + strong {
    font-style: normal;
    display: inherit;
    text-align: center;
}
.img-news{
max-height:150px;
width:100%;
}

.news-tittle{
	padding-top:15px;
	text-align:justify;
}

.author{
	color: orange;
}
.author-inline{
	color: orange;
}

.adv{
height:18px;
}


.hljs{
    white-space: pre-wrap;
    white-space: -moz-pre-wrap;
    white-space: -pre-wrap;
    white-space: -o-pre-wrap;
    word-wrap: break-word;}
.titledetail {
    display: block;
    overflow: hidden;
    line-height: 53px;
    font-size: 45px;
    font-family: 'Roboto Condensed',sans-serif;
    font-weight: 600;
    width: 800px;
    margin: auto;
	padding: 0 ;
}

.newsrelate {
    display: block;
    overflow: hidden;
	 list-style:none;
}
a ,a:hover{
    text-decoration: none;
}
.newsrelate li {
    float: left;
    overflow: hidden;
    width: 30%;
    margin-left: 2.5%;
    margin-bottom: 15px;
}

.newsrelate li a {
    display: block;
    overflow: hidden;
}

.userdetail {
    display: block;
    overflow: hidden;
    margin: 0 10px 0 0;
    padding: 15px 0;
}
.newsrelate li h3 {
    display: block;
    overflow: hidden;
    line-height: 1.3em;
    font-size: 16pt;
    line-height: 22px;
    font-weight: 300;
    font-family: Arial,Helvetica,sans-serif;
    width: auto;
    margin: 5px auto;
}

.titlerelate {
    overflow: hidden;
    font-size: 18px;
    font-weight: 600;
    font-family: 'Roboto Condensed',sans-serif;
    line-height: 32px;
    text-transform: uppercase;
}
article .captionnews {
    color: #999;
    font-size: 14px;
    font-style: italic;
    padding: 10px;
    text-align: center;
    margin-bottom: 15px;
}

	  </style>

<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-P62ZZPB');</script>


<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-P62ZZPB"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    </head>
    <body>
<script>
  window.fbAsyncInit = function() {
    FB.init({
      appId      : '1546237302193677',
      xfbml      : true,
      version    : 'v5.0'
    });
    FB.AppEvents.logPageView();
  };

  (function(d, s, id){
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) {return;}
     js = d.createElement(s); js.id = id;
     js.src = "https://connect.facebook.net/en_US/sdk.js";
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script>
<div id="fb-root"></div>
<script async defer crossorigin="anonymous" src="https://connect.facebook.net/vi_VN/sdk.js#xfbml=1&version=v5.0&appId=1853483258232756&autoLogAppEvents=1"></script>
      
      

    
    
<header id="header"  style="background: #790014; color: hsla(0,0%,100%,1);">
<div class="container">
    <nav class="navbar navbar-expand-md navbar-dark">
	
	<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
        <ul class="navbar-nav mr-auto">
            
                <li class="nav-item">
                    <a class='nav-link' href="/blog">
                            <i class="fa fa-home active">&nbsp;</i>Home
                    </a>
                </li>
            
                <li class="nav-item">
                    <a class='nav-link' href="/news/">
                            <i class="fa fa-list">&nbsp;</i>News
                    </a>
                </li>
            
                <li class="nav-item">
                    <a class='nav-link' href="/xem-truyen/">
                            <i class="fa fa-id-card-o">&nbsp;</i>Truyện
                    </a>
                </li>
            
        </ul>
    </nav>
    </div></div>
</header>


   
    
	<div class="container">
	<div class="adv"></div>
	<div>
    <main role="main" >
	
        
        
        <article class="col-md-10 col-lg-9 mx-auto">
  


        
		 <div class="">
            <h1 class="titledetail">Deep Learning based Human Pose Estimation using OpenCV</h1>
			
			
			<div class="userdetail">
			 
			  <time class="published"
            datetime='2018-10-04'>
            04/10/2018</time>
		 - 
			   <span class="author"></span>
			   
			</div>
		<div class="thumbnail text-center">
		 <img class="img-fluid single-content-img lazy" src="../../post_image/post_estimator_shark.gif" />
		<div class="captionnews">Ở bài viết này, chúng ta đề cập đến vấn đề sử dụng Deep Neural Net trong việc thực hiện Human Pose Estimation.</div>
			</div>
			 <div class="col-md-12">
            
        
       



  

  

  <div id="content" class="mx-auto">
    

<h3 id="lời-mở-đầu">Lời mở đầu</h3>

<p>Để sử dụng được các mô hình trong bài viết này, bạn phải sử dụng phiên bản opencv &gt; 3.4.1.</p>

<h2 id="pose-estimation-là-gì">Pose Estimation là gì?</h2>

<p><a href="http://www.youtube.com/watch?v=ohX-wkLYhdM"><img src="http://img.youtube.com/vi/ohX-wkLYhdM/0.jpg" alt="POST ESTIMATION EXAMPLE - Make by Phạm Duy Tùng" /></a></p>

<p>Post Estimation ( đôi khi được dùng với thuật ngữ Keypoint Detection) là một vấn đề khá phổ biến trong lĩnh vực xử lý ảnh khi chúng ta cần xác định vị trí và hướng của một đối tượng. Mức ý nghĩa ở đây là chúng ta phải rút ra được những đặc điểm chính, những đặc điểm đó là những đặc trưng của đối tượng ( có thể mô tả được đối tượng).</p>

<p>Ví dụ, trong bài toán face pose estimation ( có tên khác là facial landmark detection), chúng ta cần xác định được đâu là vị trí của những điểm landmark trên khuôn mặt người.</p>

<p>Một bài toán có liên quan đến bài toán trên là head pose estimation. Chúng ta cần xác định những điểm landmark để mô hình hoá lại được mô hình 3D của đầu người.</p>

<p>Ở trong bài viết này, chúng ta đề cập đến bài toán human pose estimation, công việc chính là xác định và chỉ ra được một phần/ toàn bộ các phần chính của cơ thể con người (vd vai, khuỷu tay, cổ tay, đầu gối v.v).</p>

<p>Trong bài viết này, chúng ta sẽ sử dụng mô hình được huấn luyện sẵn để chỉ ra các phần chính của cơ thể con người. Kết quả cơ bản của phần nhận diện này sẽ gần giống như hình bên dưới.</p>

<p><img src="/post_image/midu_pose_estimation.png" alt="Hình ảnh rút trích những thành phần quan trọng trên cơ thể con người" /></p>

<h2 id="sử-dụng-pretrain-model-trong-bài-toán-pose-estimation">Sử dụng pretrain model trong bài toán Pose Estimation</h2>

<p>Vào nằm 2016, 2017, Phòng thí nghiệm Perceptual Computing của trường đại học Carnegie Mellon University đã công bố một bài báo có liên quan đến chủ đề Multi-Person Pose Estimation. Và đến nay, họ đã công bố mô hình huấn luyện cho chúng ta sử dụng. Các bạn có nhu cầu tìm hiểu sâu hơn có thể đọc kỹ nguồn dữ liệu của họ công bố ở link <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose">https://github.com/CMU-Perceptual-Computing-Lab/openpose</a>.</p>

<p>Trong bài post này, mình sẽ không đề cập kỹ đến phần kiến trúc mạng neural net họ sử dụng bên dưới, thay vào đó, mình sẽ tập trung hơn vào cách thức sử dụng mô hình để thu được kết quả cần thiết.</p>

<p>Trước khi bắt đầu vào thực hành, mình sẽ mô tả một chút về mô hình pretrain có sẵn. Ở đây, họ cung cấp cho chúng ta 2 mô hình là MPII model và COCO  model. Đó chính là tên của hai bộ database mà họ sử dụng để đào tạo mô hình. Kết quả trả về của mỗ bộ database là khác nhau hoàn toàn.</p>

<p>Với bộ COCO dataset, kết quả trả về là 18 đặc trưng gồm các thông tin:</p>

<pre><code class="language-python">Nose – 0, Neck – 1, Right Shoulder – 2, Right Elbow – 3, Right Wrist – 4,
Left Shoulder – 5, Left Elbow – 6, Left Wrist – 7, Right Hip – 8,
Right Knee – 9, Right Ankle – 10, Left Hip – 11, Left Knee – 12,
LAnkle – 13, Right Eye – 14, Left Eye – 15, Right Ear – 16,
Left Ear – 17, Background – 18
</code></pre>

<p>Với bộ MPII, kết quả trả về là 15 đặc trưng gồm các thông tin:</p>

<pre><code class="language-python">Head – 0, Neck – 1, Right Shoulder – 2, Right Elbow – 3, Right Wrist – 4,
Left Shoulder – 5, Left Elbow – 6, Left Wrist – 7, Right Hip – 8,
Right Knee – 9, Right Ankle – 10, Left Hip – 11, Left Knee – 12,
Left Ankle – 13, Chest – 14, Background – 15
</code></pre>

<p>Trong phần này, chúng ta sẽ tập trung vào mô hình MPII, mô hình COCO sử dụng tương tự, chỉ việc thay lại đường dẫn file mô hình là được.</p>

<h2 id="bắt-đầu-code">Bắt đầu code.</h2>

<p>Bước 1: Download mô hình.</p>

<p>Nhóm tác giả sử dụng caffe để huấn luyện mô hình, do đó, để sử dụng được, chúng ta cần download file mô hình ở đường dẫn <a href="http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_iter_160000.caffemodel">http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_iter_160000.caffemodel</a> và file cấu hình ở đường dẫn <a href="http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_deploy_linevec.prototxt">http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_deploy_linevec.prototxt</a>. Các bạn có thể để đâu đó tuỳ thích, ở đây tôi để trong thư mục pose/mpi để dễ dàng nhận biết với các mô hình khác.</p>

<p>Bước 2: Load mô hình.</p>

<p>Để load mô hình lên bộ nhớ chính, đơn giản là chúng ta thực hiện câu lệnh sau trong python</p>

<pre><code class="language-python">import cv2
# Specify the paths for the 2 files
protoFile = &quot;pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt&quot;
weightsFile = &quot;pose/mpi/pose_iter_160000.caffemodel&quot;
 
# Read the network into Memory
net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)

</code></pre>

<p>Đơn giản quá phải không các bạn :).</p>

<p>Bước 3: Đọc ảnh và đưa ảnh vào trong mô hình.</p>

<pre><code class="language-python">
# Read image
frame = cv2.imread(&quot;img2.jpg&quot;)

frameCopy = np.copy(frame)
frameWidth = frame.shape[1]
frameHeight = frame.shape[0]
t = time.time()
# Specify the input image dimensions
inWidth = 368
inHeight = 368
 
# Prepare the frame to be fed to the network
inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)
 
# Set the prepared object as the input blob of the network
net.setInput(inpBlob)
</code></pre>

<p>Chắc không cần phải nói gì thêm, phần comment chú thích đã mô tả khá đầy đủ chức năng của từng phần trong này rồi.</p>

<p>Bước 4: Thu thập kết quả và trích xuất điểm đặc trưng</p>

<pre><code class="language-python">
frameCopy = frame.copy()

output = net.forward()
print(&quot;time taken by network : {:.3f}&quot;.format(time.time() - t))
H = output.shape[2]
W = output.shape[3]

nPoints = 15
POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]


threshold = 0.01
# Empty list to store the detected keypoints
points = []
for i in range(nPoints):
    # confidence map of corresponding body's part.
    probMap = output[0, i, :, :]
 
    # Find global maxima of the probMap.
    minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)
     
    # Scale the point to fit on the original image
    x = (frameWidth * point[0]) / W
    y = (frameHeight * point[1]) / H

    print(prob)
 
    if prob &gt; threshold : 
        cv2.circle(frame, (int(x), int(y)), 15, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)
        cv2.putText(frame, &quot;{}&quot;.format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 2, lineType=cv2.LINE_AA)
 
        # Add the point to the list if the probability is greater than the threshold
        points.append((int(x), int(y)))
    else :
        points.append(None)
 
# cv2.imshow(&quot;Output-Keypoints&quot;,frame)
# cv2.waitKey(0)
# cv2.destroyAllWindows()

cv2.imwrite(&quot;dot_keypoint.png&quot;,frame)

# Draw Skeleton
for pair in POSE_PAIRS:
    partA = pair[0]
    partB = pair[1]

    if points[partA] and points[partB]:
        cv2.line(frameCopy, points[partA], points[partB], (0, 255, 255), 2)
        cv2.circle(frameCopy, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)
        cv2.circle(frameCopy, points[partB], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)


cv2.imwrite(&quot;line_keypoint.png&quot;,frameCopy)

</code></pre>

<p>Kết quả của giá trị output là một ma trận 4D, với ý nghĩa của mỗi chiều như sau:</p>

<ul>
<li>Chiều đầu tiên là image ID (định danh ảnh trong trường hợp bạn truyền nhiều ảnh vào mạng)</li>
<li>Chiều thứ 2 là chỉ số của các điểm đặc trưng. Tập MPI trả về tập gồm 44 điểm dữ liệu, ta chỉ sử dụng một vài điểm dữ liệu tương ứng với vị trí các điểm đặc trưng mà chúng ta quan tâm.</li>
<li>Chiều thứ 3 là height của output map.</li>
<li>Chiều thứ 4 là width của output map.
Một lưu ý ở đây là tôi có sử dụng đặt giá trị chặn dưới threshold để giảm thiểu sự sai sót do nhận diện sai. Và kết quả đạt được là hai hình bên dưới:</li>
</ul>

<p><img src="/post_image/midu_pose_estimation_keypoint.png" alt="Hình nhữn điểm đặc trưng" /></p>

<p><img src="/post_image/midu_pose_estimation.png" alt="Hình khung xương" /></p>

<p>Hẹn gặp lại các bạn ở những bài viết tiếp theo.</p>

  </div>
  
			</div>
  <footer class="col-md-10  mx-auto">
  <div >
  <div class="fb-like" data-share="true"  data-width="450"  data-show-faces="true">
</div> </p></div>
    <ul class="stats list-unstyled">
 
    
  <li class="tags">
    <ul class="list-inline">
       
            
            
                <i class="fa fa-tags"></i>
                
                
                <li class="list-inline-item"><a class="article-category-link" href="/tags/machine-learning">Machine learning</a></li>
                
                
                <li class="list-inline-item"><a class="article-category-link" href="/tags/deeplearning">Deeplearning</a></li>
                
                
                <li class="list-inline-item"><a class="article-category-link" href="/tags/pose-estimation">pose estimation</a></li>
                
            
        
    </ul>
  </li>
  
</ul>

	</div>
  </footer>
  <hr/>
<div class="titlerelate">Bài viết khác</div>
<div class="infinite-container featured-task">
<div class="card-deck card-break infinite-item">



    
        <div class="card">
		<a href="/blog/2018-10-02-understanding-epoch-batchsize-iterations/"
                class="button big previous">
		
		<img class="card-img-top lazy" src="../../post_image/epoch_batchsize_iteration.png" width="100" />
		<div class="card-body">
		<h5 class="card-title">
		Phân biệt Epoch - Batch size và Iterations
				</h5>
				</div>
				</a>
				</div>
    

    
        <div class="card">
		<a href="/blog/2018-10-05-deep-learning-base-multiple-human-pose-estimation/"
                class="button big previous">
		
		<img class="card-img-top lazy" src="../../post_image/post_estimator_shark.gif" width="100" />
		
		<div class="card-body">
		<h5 class="card-title">
		Deep Learning based Multiple Human Pose Estimation using OpenCV
				</h5>
				</div>
				</a>
				</div>
    

</div>
</div>



<div class="fb-comments" data-href="" data-width="" data-numposts="5"></div>

    <article class="post">
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "phamduytung" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </article>



</article>


		
    </main>
    
	</div>
	</div>
    
	<hr>
  <footer class="footer">
  <div class="container text-center">
    
    <p class="copyright">
      
        &copy; 2020
        
          Phạm Duy Tùng Machine Learning Blog
        
      
     
    </p>
	</div>
  </footer>
    
    

    
      
    

    
      
      
      
        <script src="//cdn.bootcss.com/highlight.js/9.15.8/highlight.min.js"></script>
        
        
        
        <script src="//cdn.bootcss.com/highlight.js/9.15.8/languages/python.min.js"></script>
        <script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>
      
    
    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/skel/3.0.1/skel.min.js"></script>
     

   <script src="/js/jquery-3.3.1.min.js"></script>
   
    <script src="/js/bootstrap.min.js"></script>
      <script src="/js/util.js"></script>
      <script src="/js/main.js"></script>
     
    

    
      
        
      
    
	
    
    
      
<script async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


	  
	  
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114911596-1"  data-cfasync="false"></script>
<script  data-cfasync="false">
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-114911596-1');
</script>
<script src="https://cdn.jsdelivr.net/npm/intersection-observer@0.5.1/intersection-observer.js"  data-cfasync="false"></script>
<script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@12.0.0/dist/lazyload.min.js"  data-cfasync="false"></script>
	   <script  type="text/javascript"  data-cfasync="false">

  function getcontent(){
 

   

             var myLazyLoad = new LazyLoad({
    elements_selector: ".lazy"
});
                }
            
			
			$(document).ready(function(){
      getcontent();
      
      const calander = document.querySelector('#calander');
      if (window.Worker) {
if (calander){
        var calanderworker = new Worker('/js/worker.js');
        calanderworker.onmessage = (event) => { calander.innerHTML = event.data; }
        calanderworker.postMessage(calander.textContent);
      }
}
			}); 
</script>


  </body>
</html>

