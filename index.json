[{"categories":null,"content":" PhiÃªn báº£n basic Train vá»›i ultimate pro BÃ i táº­p hÃ´m nay lÃ  train mÃ´ hÃ¬nh Ä‘á»ƒ nháº­n dáº¡ng email lá»«a Ä‘áº£o Phishing Email. ÄÃ¢y Ä‘Æ°á»£c xem nhÆ° lÃ  bÃ i táº­p nháº­p mÃ´n machine learning.\nTrong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ train mÃ´ hÃ¬nh vÃ  viáº¿t má»™t web api nho nhá» báº±ng fastapi Ä‘á»ƒ hosting model lÃªn. CÃ¡c bÆ°á»›c thá»±c hiá»‡n nhÆ° sau:\nNguyÃªn liá»‡u chÃ­nh: data phishing email Ä‘Æ°á»£c download á»Ÿ https://www.kaggle.com/datasets/subhajournal/phishingemails/data\nCÃ i cÃ¡c thÆ° viá»‡n cÆ¡ báº£n\n1python3 -m venv venv 2 3source venv/bin/activate 4pip install fastapi uvicorn redis joblib scikit-learn fastapi: Framework Ä‘á»ƒ xÃ¢y dá»±ng API. uvicorn: Server ASGI Ä‘á»ƒ cháº¡y á»©ng dá»¥ng FastAPI. redis: ThÆ° viá»‡n Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i Redis. joblib: ThÆ° viá»‡n Ä‘á»ƒ lÆ°u vÃ  táº£i mÃ´ hÃ¬nh há»c mÃ¡y. scikit-learn: ThÆ° viá»‡n Ä‘á»ƒ huáº¥n luyá»‡n vÃ  triá»ƒn khai mÃ´ hÃ¬nh. PhiÃªn báº£n basic Train mÃ´ hÃ¬nh\n1# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t 2import os 3import joblib 4import pandas as pd 5from sklearn.feature_extraction.text import TfidfVectorizer 6from sklearn.linear_model import LogisticRegression 7from sklearn.model_selection import train_test_split 8from sklearn.pipeline import Pipeline 9from sklearn.metrics import accuracy_score 10 11def trainPhishingEmailModel(): 12 \u0026#34;\u0026#34;\u0026#34; 13 HÃ m thá»±c hiá»‡n: 14 - Äá»c dá»¯ liá»‡u email tá»« file CSV 15 - Tiá»n xá»­ lÃ½, chia dá»¯ liá»‡u train/test 16 - XÃ¢y dá»±ng pipeline (TF-IDF + Logistic Regression) 17 - Huáº¥n luyá»‡n mÃ´ hÃ¬nh 18 - ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test 19 - LÆ°u mÃ´ hÃ¬nh Ä‘Ã£ train vÃ o thÆ° má»¥c model/ 20 \u0026#34;\u0026#34;\u0026#34; 21 22 # BÆ°á»›c 1: Äá»c dá»¯ liá»‡u tá»« file CSV 23 dataFrame = pd.read_csv(\u0026#34;data/Phishing_Email.csv\u0026#34;) # Cáº§n Ä‘áº£m báº£o Ä‘Æ°á»ng dáº«n file chÃ­nh xÃ¡c 24 25 # BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘áº§u vÃ o (features) vÃ  nhÃ£n (labels) 26 emailTexts = dataFrame[\u0026#34;Email Text\u0026#34;].fillna(\u0026#34;\u0026#34;) # Thay tháº¿ giÃ¡ trá»‹ null báº±ng chuá»—i rá»—ng 27 emailLabels = dataFrame[\u0026#34;Email Type\u0026#34;] # Label: loáº¡i email (vÃ­ dá»¥: phishing hoáº·c legit) 28 29 # BÆ°á»›c 3: Chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm tra 30 emailTextsTrain, emailTextsTest, emailLabelsTrain, emailLabelsTest = train_test_split( 31 emailTexts, 32 emailLabels, 33 test_size=0.2, # 20% dá»¯ liá»‡u dÃ¹ng Ä‘á»ƒ kiá»ƒm tra 34 random_state=42 # Äáº£m báº£o chia dá»¯ liá»‡u ngáº«u nhiÃªn nhÆ°ng cÃ³ thá»ƒ tÃ¡i láº­p 35 ) 36 37 # BÆ°á»›c 4: XÃ¢y dá»±ng pipeline: 38 # - TfidfVectorizer: chuyá»ƒn vÄƒn báº£n thÃ nh vector Ä‘áº·c trÆ°ng 39 # - LogisticRegression: mÃ´ hÃ¬nh phÃ¢n loáº¡i tuyáº¿n tÃ­nh 40 phishingDetectionPipeline = Pipeline([ 41 (\u0026#34;tfidfVectorizer\u0026#34;, TfidfVectorizer(stop_words=\u0026#34;english\u0026#34;)), # Loáº¡i bá» tá»« dá»«ng tiáº¿ng Anh 42 (\u0026#34;logisticClassifier\u0026#34;, LogisticRegression(solver=\u0026#34;liblinear\u0026#34;)) # Sá»­ dá»¥ng solver phÃ¹ há»£p vá»›i táº­p nhá» 43 ]) 44 45 # BÆ°á»›c 5: Huáº¥n luyá»‡n pipeline trÃªn táº­p huáº¥n luyá»‡n 46 phishingDetectionPipeline.fit(emailTextsTrain, emailLabelsTrain) 47 48 # BÆ°á»›c 6: ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p kiá»ƒm tra 49 emailLabelsPredicted = phishingDetectionPipeline.predict(emailTextsTest) 50 accuracy = accuracy_score(emailLabelsTest, emailLabelsPredicted) 51 print(f\u0026#34;ğŸ¯ Äá»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trÃªn táº­p kiá»ƒm tra: {accuracy * 100:.2f}%\u0026#34;) 52 53 # BÆ°á»›c 7: Táº¡o thÆ° má»¥c lÆ°u mÃ´ hÃ¬nh náº¿u chÆ°a tá»“n táº¡i 54 modelDirectory = \u0026#34;model\u0026#34; 55 if not os.path.exists(modelDirectory): 56 os.makedirs(modelDirectory) 57 58 # BÆ°á»›c 8: LÆ°u mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n vÃ o thÆ° má»¥c model/ 59 modelPath = os.path.join(modelDirectory, \u0026#34;phishingModel.pkl\u0026#34;) 60 joblib.dump(phishingDetectionPipeline, modelPath) 61 print(f\u0026#34;âœ… MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  lÆ°u thÃ nh cÃ´ng táº¡i \u0026#39;{modelPath}\u0026#39;.\u0026#34;) 62 63# Äiá»ƒm báº¯t Ä‘áº§u chÆ°Æ¡ng trÃ¬nh 64if __name__ == \u0026#34;__main__\u0026#34;: 65 trainPhishingEmailModel() Káº¿t quáº£\n1 2ğŸ¯ Äá»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trÃªn táº­p kiá»ƒm tra: 97.24% 3âœ… MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  lÆ°u thÃ nh cÃ´ng táº¡i \u0026#39;model/phishingModel.pkl\u0026#39;. Pháº§n code triá»ƒn khai fast api khÃ¡ Ä‘Æ¡n giáº£n\n1# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t 2import asyncio 3import json 4import joblib 5from fastapi import FastAPI 6from pydantic import BaseModel 7 8# BÆ°á»›c 1: Load mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n (Ä‘á»“ng bá»™) 9model = joblib.load(\u0026#34;model/phishingModel.pkl\u0026#34;) # Äáº£m báº£o Ä‘Æ°á»ng dáº«n Ä‘Ãºng 10 11# BÆ°á»›c 2: Khá»Ÿi táº¡o FastAPI app 12app = FastAPI() 13 14# BÆ°á»›c 3: Äá»‹nh nghÄ©a lá»›p dá»¯ liá»‡u vÃ o (request) vÃ  dá»¯ liá»‡u ra (response) 15class PredictionRequest(BaseModel): 16 text: str # VÄƒn báº£n email cáº§n phÃ¢n loáº¡i 17 18class PredictionResponse(BaseModel): 19 prediction: str # Káº¿t quáº£ phÃ¢n loáº¡i (vÃ­ dá»¥: \u0026#34;Phishing\u0026#34; hoáº·c \u0026#34;Legit\u0026#34;) 20 probability: float # XÃ¡c suáº¥t dá»± Ä‘oÃ¡n cao nháº¥t 21 22# BÆ°á»›c 4: Äá»‹nh nghÄ©a API endpoint cho viá»‡c dá»± Ä‘oÃ¡n 23@app.post(\u0026#34;/predict\u0026#34;, response_model=PredictionResponse) 24async def predictEmail(data: PredictionRequest): 25 \u0026#34;\u0026#34;\u0026#34; 26 Nháº­n vÄƒn báº£n email tá»« client, cháº¡y mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n, 27 vÃ  tráº£ vá» káº¿t quáº£ cÃ¹ng xÃ¡c suáº¥t dá»± Ä‘oÃ¡n. 28 \u0026#34;\u0026#34;\u0026#34; 29 30 # Cháº¡y dá»± Ä‘oÃ¡n mÃ´ hÃ¬nh trong thread riÃªng Ä‘á»ƒ khÃ´ng block event loop 31 prediction = await asyncio.to_thread(model.predict, [data.text]) 32 probability = await asyncio.to_thread(lambda: model.predict_proba([data.text])[0].max()) 33 34 # ÄÃ³ng gÃ³i káº¿t quáº£ tráº£ vá» 35 result = { 36 \u0026#34;prediction\u0026#34;: str(prediction[0]), 37 \u0026#34;probability\u0026#34;: float(probability) 38 } 39 40 return result 41 42# BÆ°á»›c 5: Cháº¡y server FastAPI vá»›i uvicorn khi file Ä‘Æ°á»£c thá»±c thi trá»±c tiáº¿p 43if __name__ == \u0026#34;__main__\u0026#34;: 44 import uvicorn 45 uvicorn.run(app, host=\u0026#34;0.0.0.0\u0026#34;, port=8000) MÃ¬nh thá»­ láº¡i vá»›i cÃ¡c test case sau nha\n1 2curl \u0026#39;http://localhost:8000/predict\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;text\u0026#34;:\u0026#34;Hi There, Watch your customer engagement soar with custom, branded messaging experience powered by artificial intelligence. Improve customer retention, conversion and satisfaction with Sendbirdâ€™s award winning communications platform. Schedule a Custom Demo at your convenience. Cheers, Natalie\u0026#34;}\u0026#39; 3 4curl \u0026#39;http://localhost:8000/predict\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{ 5 \u0026#34;text\u0026#34;: \u0026#34;Hi, We noticed a login from a device you don\u0026#39;\\\u0026#39;\u0026#39;t usually use: android device Lagos, Nigeria If this was you, you can safely disregard this email.\u0026#34; 6}\u0026#39; 7 8curl \u0026#39;http://localhost:8000/predict\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;text\u0026#34;:\u0026#34;STARTING AT $40 ($80) (50% OFF APPLIED FOR LIMITED TIME) If you are looking to learn in-demand skills and apply them directly at your workplace then Premium Courses by Great Learning Academy are a great way to get started! Learn industry-relevant skills in Data Science and AI through a combination of expert-led hands-on projects, interactive exercises, and advanced AI support tools. These courses empower you to apply your skills effectively at work and grow in your current role or take on new projects with confidence.\u0026#34;}\u0026#39; 9 10 11curl \u0026#39;http://localhost:8000/predict\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;text\u0026#34;:\u0026#34;I spend most of my time building and improving Retrieval Augmented Generation (RAG) apps. I trust RAGs are perhaps the most popular application of AI. Itâ€™s everywhere, from chatbots to document summaries. I also believe that most of these apps ultimately go undeployed for various reasons, many of which are not technical. However, I wish I had known a few technical aspects to create more effective RAGs.\u0026#34;}\u0026#39; Káº¿t quáº£ nhÆ° sau\n1{\u0026#34;prediction\u0026#34;:\u0026#34;Phishing Email\u0026#34;,\u0026#34;probability\u0026#34;:0.6649311587527311}{\u0026#34;prediction\u0026#34;:\u0026#34;Phishing Email\u0026#34;,\u0026#34;probability\u0026#34;:0.5568319143944104}{\u0026#34;prediction\u0026#34;:\u0026#34;Phishing Email\u0026#34;,\u0026#34;probability\u0026#34;:0.5126072633692877} 2{\u0026#34;prediction\u0026#34;:\u0026#34;Safe Email\u0026#34;,\u0026#34;probability\u0026#34;:0.5550190678745507} ÄÃ¢y lÃ  cÃ¡c email tháº­t mÃ¬nh láº¥y ra tá»« gmail cÃ¡ nhÃ¢n cá»§a mÃ¬nh, Ä‘Ã£ Ä‘Æ°á»£c google phÃ¢n loáº¡i. Káº¿t quáº£ cá»§a mÃ¬nh ra khá»›p 100% vá»›i google nhá»‰. hi hi.\nTrain vá»›i ultimate pro Model chá»‰ Ä‘Ãºng vá»›i 97% á»Ÿ táº­p train, khÃ¡ cÃ¹i nhá»‰. ChÃºng ta sáº½ bá»• sung auto grid search Ä‘á»ƒ turning tham sá»‘, chá»n ra best_params, thÃªm EarlyStopping, thÃªm Auto Save Checkpoint, Ä‘á»•i mÃ´ hÃ¬nh sang random forest \u0026hellip; CÃ¡c chá»©c nÄƒng xá»‹n sÃ² hÆ¡n nhá»‰\nCÃ¡c báº¡n thá»­ coding thá»­, xem nhÆ° lÃ  bÃ i táº­p.\nCáº£m Æ¡n báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\n","date":"Apr 26, 2025","img":"https://unsplash.it/1920/1080?image=232","permalink":"/blog/2025-04-26-phishing-email/","series":null,"tags":["marketing"],"title":"Machine Learning - Train MÃ´ HÃ¬nh Nháº­n Dáº¡ng Email Lá»«a Äáº£o"},{"categories":null,"content":" I. KhÃ¡i niá»‡m Heavy Buyer vÃ  Light Buyer 1. Heavy Buyer lÃ  gÃ¬? 2. Light Buyer lÃ  gÃ¬? II. CÃ¡c Ä‘iá»ƒm chÃ­nh cá»‘t lÃµi khi phÃ¡t triá»ƒn mÃ´ hÃ¬nh marketing, phÃ¢n tÃ­ch hÃ ng vi mua sáº¯m cá»§a ngÆ°á»i dÃ¹ng 1. Sá»± TÄƒng TrÆ°á»Ÿng Äáº¿n Tá»« KhÃ¡ch HÃ ng Má»›i 2. Nhá»¯ng Niá»m Tin Sai Láº§m Vá» Sá»± Trung ThÃ nh Cá»§a KhÃ¡ch HÃ ng 3. NhÃ³m Light Buyers Ráº¥t, Ráº¥t Quan Trá»ng 4. Thay Äá»•i CÃ¡c Quan Äiá»ƒm Marketing Truyá»n Thá»‘ng 5. Nhá»¯ng BÃ i Há»c Thá»±c Tiá»…n: LÃ m Tháº¿ NÃ o Äá»ƒ Ãp Dá»¥ng Nhá»¯ng PhÃ¡t Hiá»‡n Tá»« Cuá»‘n SÃ¡ch? III. Chiáº¿n lá»±c táº­n dá»¥ng Light Buyers cho nhÃ³m doanh nghiá»‡p Chiáº¿n lÆ°á»£c cho doanh nghiá»‡p nhá» Chiáº¿n lÆ°á»£c cho doanh nghiá»‡p lá»›n Lá»i ngÆ°á»i viáº¿t: trong quÃ¡ trÃ¬nh lÆ°á»›t lÆ°á»›t web, tÃ´i vÃ´ tÃ¬nh báº¯t gáº·p 2 tá»« khoÃ¡ Heavy Buyer vÃ  Light Buyer. CÃ¡ch phÃ¢n nhÃ³m khÃ¡ch hÃ ng dá»±a vÃ o hÃ nh vi mua sáº¯m, Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ xÃ¢y dá»±ng chiáº¿n lÆ°á»£c marketing vÃ  tÄƒng trÆ°á»Ÿng doanh thu. TÃ¬m hiá»ƒu sÃ¢u hÆ¡n, tá»± nhiÃªn láº¡i lÃ²i ra quyá»ƒn sÃ¡ch How Brands Grow vá»›i nhiá»u thá»‘ng kÃª nghiÃªn cá»©u , Ä‘á» cáº­p trÃªn dá»¯ liá»‡u FMCG ( nhÃ³m hÃ ng mÃ  tÃ´i Ä‘Ã£ phÃ¢n tÃ­ch , vÃ  hiá»‡n táº¡i váº«n Ä‘ang phÃ¢n tÃ­ch). Tá»« Ä‘Ã³, cÃ³ bÃ i viáº¿t nÃ y.\nI. KhÃ¡i niá»‡m Heavy Buyer vÃ  Light Buyer 1. Heavy Buyer lÃ  gÃ¬? Heavy Buyers lÃ  nhá»¯ng ngÆ°á»i mua hÃ ng thÆ°á»ng xuyÃªn, chiáº¿m má»™t tá»· lá»‡ nhá» (khoáº£ng 20%) nhÆ°ng láº¡i Ä‘Ã³ng gÃ³p pháº§n lá»›n vÃ o doanh thu cá»§a doanh nghiá»‡p (lÃªn tá»›i 80% doanh thu) . Há» cÃ³ xu hÆ°á»›ng trung thÃ nh vá»›i má»™t thÆ°Æ¡ng hiá»‡u hoáº·c sáº£n pháº©m cá»¥ thá»ƒ vÃ  cÃ³ gu tiÃªu dÃ¹ng riÃªng. VÃ­ dá»¥, nhá»¯ng ngÆ°á»i Ä‘i cafe 2-3 láº§n/tuáº§n Ä‘Æ°á»£c coi lÃ  Heavy Buyers .\n2. Light Buyer lÃ  gÃ¬? Light Buyers lÃ  nhá»¯ng ngÆ°á»i mua hÃ ng Ã­t thÆ°á»ng xuyÃªn hÆ¡n, chiáº¿m Ä‘a sá»‘ trong tá»•ng sá»‘ khÃ¡ch hÃ ng (khoáº£ng 80%), nhÆ°ng chá»‰ Ä‘Ã³ng gÃ³p má»™t pháº§n nhá» vÃ o doanh thu (vÃ­ dá»¥: 20%). Há» thÆ°á»ng mua khi cÃ³ nhu cáº§u Ä‘áº·c biá»‡t hoáº·c dá»‹p Ä‘áº·c biá»‡t nhÆ° gáº·p báº¡n bÃ¨ hay Ä‘á»‘i tÃ¡c . NhÃ³m nÃ y khÃ´ng trung thÃ nh vá»›i má»™t thÆ°Æ¡ng hiá»‡u cá»¥ thá»ƒ vÃ  dá»… bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi cÃ¡c yáº¿u tá»‘ bÃªn ngoÃ i nhÆ° khuyáº¿n mÃ£i hoáº·c quáº£ng cÃ¡o .\nII. CÃ¡c Ä‘iá»ƒm chÃ­nh cá»‘t lÃµi khi phÃ¡t triá»ƒn mÃ´ hÃ¬nh marketing, phÃ¢n tÃ­ch hÃ ng vi mua sáº¯m cá»§a ngÆ°á»i dÃ¹ng 1. Sá»± TÄƒng TrÆ°á»Ÿng Äáº¿n Tá»« KhÃ¡ch HÃ ng Má»›i Má»™t trong nhá»¯ng phÃ¡t hiá»‡n gÃ¢y tranh cÃ£i nhÆ°ng cÅ©ng Ä‘áº§y thuyáº¿t phá»¥c, Ä‘Ã³ lÃ : thÆ°Æ¡ng hiá»‡u tÄƒng trÆ°á»Ÿng chá»§ yáº¿u báº±ng cÃ¡ch thu hÃºt khÃ¡ch hÃ ng má»›i, thay vÃ¬ chá»‰ táº­p trung vÃ o viá»‡c giá»¯ chÃ¢n khÃ¡ch hÃ ng hiá»‡n táº¡i . Äiá»u nÃ y cÃ³ thá»ƒ trÃ¡i ngÆ°á»£c vá»›i suy nghÄ© cá»§a nhiá»u ngÆ°á»i lÃ m marketing, khi há» thÆ°á»ng cho ráº±ng viá»‡c duy trÃ¬ lÃ²ng trung thÃ nh cá»§a khÃ¡ch hÃ ng hiá»‡n táº¡i lÃ  chÃ¬a khÃ³a cho sá»± thÃ nh cÃ´ng. Tuy nhiÃªn, nghiÃªn cá»©u cá»§a Byron Sharp Ä‘Ã£ chá»©ng minh ráº±ng háº§u háº¿t sá»± tÄƒng trÆ°á»Ÿng cá»§a thÆ°Æ¡ng hiá»‡u Ä‘áº¿n tá»« viá»‡c má»Ÿ rá»™ng tá»‡p khÃ¡ch hÃ ng, Ä‘áº·c biá»‡t lÃ  nhÃ³m khÃ¡ch hÃ ng mua sáº¯m khÃ´ng thÆ°á»ng xuyÃªn (light buyers).\nÄá»ƒ hiá»ƒu rÃµ hÆ¡n, hÃ£y láº¥y vÃ­ dá»¥ vá» Coca-Cola. Há» khÃ´ng chá»‰ hÆ°á»›ng Ä‘áº¿n nhá»¯ng ngÆ°á»i uá»‘ng Coca-Cola má»—i ngÃ y mÃ  cÃ²n tÃ¬m cÃ¡ch thu hÃºt cáº£ nhá»¯ng ngÆ°á»i chá»‰ thá»‰nh thoáº£ng uá»‘ng nÆ°á»›c ngá»t. Theo nghiÃªn cá»©u trong sÃ¡ch, nhÃ³m khÃ¡ch hÃ ng khÃ´ng mua thÆ°á»ng xuyÃªn (light buyers) chiáº¿m pháº§n lá»›n doanh sá»‘ bÃ¡n hÃ ng cá»§a báº¥t ká»³ thÆ°Æ¡ng hiá»‡u nÃ o. ÄÃ¢y má»›i thá»±c sá»± lÃ  Ä‘á»™ng lá»±c chÃ­nh thÃºc Ä‘áº©y sá»± phÃ¡t triá»ƒn cá»§a thÆ°Æ¡ng hiá»‡u .\nTuy nhiÃªn, Ä‘iá»u Ä‘Ã¡ng chÃº Ã½ á»Ÿ Ä‘Ã¢y lÃ  viá»‡c thu hÃºt khÃ¡ch hÃ ng má»›i khÃ´ng Ä‘á»“ng nghÄ©a vá»›i viá»‡c bá» qua khÃ¡ch hÃ ng hiá»‡n táº¡i. Thay vÃ o Ä‘Ã³, nÃ³ nháº¥n máº¡nh táº§m quan trá»ng cá»§a viá»‡c cÃ¢n báº±ng giá»¯a hai má»¥c tiÃªu: vá»«a duy trÃ¬ má»‘i quan há»‡ vá»›i khÃ¡ch hÃ ng hiá»‡n táº¡i, vá»«a má»Ÿ rá»™ng pháº¡m vi tiáº¿p cáº­n. VÃ­ dá»¥, má»™t thÆ°Æ¡ng hiá»‡u nhÆ° Apple khÃ´ng ngá»«ng cáº£i tiáº¿n sáº£n pháº©m Ä‘á»ƒ Ä‘Ã¡p á»©ng nhu cáº§u cá»§a ngÆ°á»i dÃ¹ng trung thÃ nh, nhÆ°ng há» cÅ©ng liÃªn tá»¥c quáº£ng bÃ¡ sáº£n pháº©m Ä‘áº¿n nhá»¯ng ngÆ°á»i chÆ°a tá»«ng sá»­ dá»¥ng iPhone hoáº·c iPad. Chiáº¿n lÆ°á»£c nÃ y giÃºp há» vá»«a duy trÃ¬ Ä‘Æ°á»£c lÃ²ng trung thÃ nh cá»§a khÃ¡ch hÃ ng cÅ©, vá»«a má»Ÿ rá»™ng Ä‘Æ°á»£c thá»‹ trÆ°á»ng má»›i .\nThÃªm vÃ o Ä‘Ã³, cÃ¡c thÆ°Æ¡ng hiá»‡u cáº§n nhá»› ráº±ng khÃ¡ch hÃ ng má»›i khÃ´ng pháº£i lÃºc nÃ o cÅ©ng dá»… dÃ ng trá»Ÿ thÃ nh khÃ¡ch hÃ ng trung thÃ nh ngay láº­p tá»©c. VÃ¬ váº­y, viá»‡c xÃ¢y dá»±ng má»‘i quan há»‡ lÃ¢u dÃ i vá»›i há» Ä‘Ã²i há»i sá»± kiÃªn nháº«n vÃ  chiáº¿n lÆ°á»£c phÃ¹ há»£p. Má»™t vÃ­ dá»¥ Ä‘iá»ƒn hÃ¬nh lÃ  Netflix. Ban Ä‘áº§u, há» thu hÃºt ngÆ°á»i dÃ¹ng báº±ng cÃ¡c chÆ°Æ¡ng trÃ¬nh khuyáº¿n mÃ£i miá»…n phÃ­ trong má»™t thÃ¡ng. Sau Ä‘Ã³, há» dáº§n dáº§n biáº¿n nhá»¯ng ngÆ°á»i dÃ¹ng thá»­ thÃ nh khÃ¡ch hÃ ng tráº£ phÃ­ thÃ´ng qua viá»‡c cung cáº¥p ná»™i dung Ä‘á»™c quyá»n vÃ  tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng tá»‘t nháº¥t .\n2. Nhá»¯ng Niá»m Tin Sai Láº§m Vá» Sá»± Trung ThÃ nh Cá»§a KhÃ¡ch HÃ ng Nhiá»u doanh nghiá»‡p thÆ°á»ng tin ráº±ng khÃ¡ch hÃ ng trung thÃ nh lÃ  yáº¿u tá»‘ quyáº¿t Ä‘á»‹nh sá»± thÃ nh cÃ´ng cá»§a thÆ°Æ¡ng hiá»‡u. Tuy nhiÃªn, cuá»‘n sÃ¡ch Ä‘Ã£ Ä‘Æ°a ra má»™t gÃ³c nhÃ¬n khÃ¡c: sá»± trung thÃ nh cá»§a khÃ¡ch hÃ ng thÆ°á»ng bá»‹ thá»•i phá»“ng quÃ¡ má»©c. Thá»±c táº¿, ngay cáº£ nhá»¯ng khÃ¡ch hÃ ng Ä‘Æ°á»£c coi lÃ  â€œtrung thÃ nhâ€ cÅ©ng thÆ°á»ng xuyÃªn thá»­ nghiá»‡m cÃ¡c thÆ°Æ¡ng hiá»‡u khÃ¡c náº¿u cÃ³ cÆ¡ há»™i .\nVÃ­ dá»¥, má»™t ngÆ°á»i luÃ´n mua sá»¯a cá»§a Vinamilk cÃ³ thá»ƒ dá»… dÃ ng chuyá»ƒn sang TH True Milk náº¿u sáº£n pháº©m nÃ y xuáº¥t hiá»‡n á»Ÿ má»i cá»­a hÃ ng hoáº·c cÃ³ chÆ°Æ¡ng trÃ¬nh khuyáº¿n mÃ£i háº¥p dáº«n. Äiá»u nÃ y cho tháº¥y ráº±ng khÃ´ng cÃ³ gÃ¬ Ä‘áº£m báº£o ráº±ng khÃ¡ch hÃ ng sáº½ luÃ´n gáº¯n bÃ³ vá»›i má»™t thÆ°Æ¡ng hiá»‡u duy nháº¥t. Do Ä‘Ã³, thay vÃ¬ cá»‘ gáº¯ng biáº¿n khÃ¡ch hÃ ng thÃ nh â€œtÃ­n Ä‘á»“â€ cá»§a thÆ°Æ¡ng hiá»‡u, cÃ¡c doanh nghiá»‡p nÃªn táº­p trung vÃ o hai yáº¿u tá»‘ quan trá»ng: Ä‘á»™ nháº­n biáº¿t (mental availability) vÃ  kháº£ nÄƒng tiáº¿p cáº­n (physical availability).\nÄá»™ nháº­n biáº¿t (mental availability): ÄÃ¢y lÃ  kháº£ nÄƒng thÆ°Æ¡ng hiá»‡u xuáº¥t hiá»‡n trong tÃ¢m trÃ­ khÃ¡ch hÃ ng khi há» cáº§n má»™t sáº£n pháº©m hoáº·c dá»‹ch vá»¥ cá»¥ thá»ƒ. VÃ­ dá»¥, náº¿u ai Ä‘Ã³ muá»‘n mua kem Ä‘Ã¡nh rÄƒng, Colgate thÆ°á»ng lÃ  cÃ¡i tÃªn Ä‘áº§u tiÃªn xuáº¥t hiá»‡n trong tÃ¢m trÃ­ nhá» chiáº¿n lÆ°á»£c quáº£ng cÃ¡o máº¡nh máº½ vÃ  nháº¥t quÃ¡n. Äiá»u nÃ y khÃ´ng chá»‰ dá»±a vÃ o viá»‡c quáº£ng cÃ¡o ráº§m rá»™ mÃ  cÃ²n phá»¥ thuá»™c vÃ o cÃ¡ch thÆ°Æ¡ng hiá»‡u xÃ¢y dá»±ng hÃ¬nh áº£nh vÃ  giÃ¡ trá»‹ cá»§a mÃ¬nh trong máº¯t khÃ¡ch hÃ ng . Má»™t thÆ°Æ¡ng hiá»‡u nhÆ° Nike Ä‘Ã£ thÃ nh cÃ´ng trong viá»‡c táº¡o ra sá»± liÃªn tÆ°á»Ÿng máº¡nh máº½ giá»¯a sáº£n pháº©m cá»§a há» vÃ  lá»‘i sá»‘ng nÄƒng Ä‘á»™ng, khá»e khoáº¯n. Khi nháº¯c Ä‘áº¿n giÃ y thá»ƒ thao, ngÆ°á»i ta thÆ°á»ng nghÄ© ngay Ä‘áº¿n Nike, dÃ¹ há» khÃ´ng pháº£i lÃ  thÆ°Æ¡ng hiá»‡u duy nháº¥t trÃªn thá»‹ trÆ°á»ng.\nKháº£ nÄƒng tiáº¿p cáº­n (physical availability): ÄÃ¢y lÃ  kháº£ nÄƒng khÃ¡ch hÃ ng cÃ³ thá»ƒ dá»… dÃ ng mua Ä‘Æ°á»£c sáº£n pháº©m á»Ÿ báº¥t ká»³ Ä‘Ã¢u. Má»™t thÆ°Æ¡ng hiá»‡u nhÆ° Coca-Cola thÃ nh cÃ´ng nhá» viá»‡c phÃ¢n phá»‘i sáº£n pháº©m rá»™ng kháº¯p, tá»« siÃªu thá»‹ lá»›n Ä‘áº¿n cÃ¡c cá»­a hÃ ng táº¡p hÃ³a nhá» . Tuy nhiÃªn, Ä‘iá»u nÃ y khÃ´ng chá»‰ Ä‘Æ¡n giáº£n lÃ  viá»‡c Ä‘áº·t sáº£n pháº©m á»Ÿ má»i nÆ¡i. NÃ³ cÃ²n Ä‘Ã²i há»i thÆ°Æ¡ng hiá»‡u pháº£i Ä‘áº£m báº£o ráº±ng sáº£n pháº©m luÃ´n sáºµn cÃ³ khi khÃ¡ch hÃ ng cáº§n. VÃ­ dá»¥, trong mÃ¹a hÃ¨, cÃ¡c thÆ°Æ¡ng hiá»‡u nÆ°á»›c giáº£i khÃ¡t thÆ°á»ng tÄƒng cÆ°á»ng phÃ¢n phá»‘i sáº£n pháº©m á»Ÿ cÃ¡c khu vá»±c bÃ£i biá»ƒn, cÃ´ng viÃªn, hoáº·c cÃ¡c Ä‘iá»ƒm du lá»‹ch. Äiá»u nÃ y giÃºp há» táº­n dá»¥ng tá»‘i Ä‘a nhu cáº§u tÄƒng cao trong mÃ¹a nÃ³ng.\n3. NhÃ³m Light Buyers Ráº¥t, Ráº¥t Quan Trá»ng Cáº§n nháº¥n máº¡nh ráº±ng nhÃ³m khÃ¡ch hÃ ng khÃ´ng mua thÆ°á»ng xuyÃªn (light buyers) Ä‘Ã³ng vai trÃ² quan trá»ng hÆ¡n nhiá»u so vá»›i nhÃ³m khÃ¡ch hÃ ng trung thÃ nh. LÃ½ do ráº¥t Ä‘Æ¡n giáº£n: nhÃ³m light buyers chiáº¿m sá»‘ lÆ°á»£ng lá»›n hÆ¡n Ä‘Ã¡ng ká»ƒ. Há» cÃ³ thá»ƒ khÃ´ng mua sáº£n pháº©m thÆ°á»ng xuyÃªn, nhÆ°ng tá»•ng sá»‘ lÆ°á»£ng giao dá»‹ch cá»§a há» váº«n vÆ°á»£t xa nhÃ³m khÃ¡ch hÃ ng trung thÃ nh .\nHÃ£y tÆ°á»Ÿng tÆ°á»£ng báº¡n Ä‘ang Ä‘iá»u hÃ nh má»™t thÆ°Æ¡ng hiá»‡u cÃ  phÃª. Thay vÃ¬ chá»‰ chÄƒm chÄƒm vÃ o nhá»¯ng ngÆ°á»i uá»‘ng cÃ  phÃª má»—i sÃ¡ng, báº¡n nÃªn Ä‘áº§u tÆ° vÃ o viá»‡c thu hÃºt nhá»¯ng ngÆ°á»i chá»‰ thá»‰nh thoáº£ng uá»‘ng cÃ  phÃª â€“ vÃ­ dá»¥ nhÆ° khi Ä‘i gáº·p gá»¡ báº¡n bÃ¨ hoáº·c trong nhá»¯ng dá»‹p Ä‘áº·c biá»‡t. Khi nhÃ³m khÃ¡ch hÃ ng nÃ y cáº£m tháº¥y hÃ i lÃ²ng, há» sáº½ dáº§n trá»Ÿ thÃ nh khÃ¡ch hÃ ng thÆ°á»ng xuyÃªn hÆ¡n .\nÄá»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u nÃ y, cÃ¡c thÆ°Æ¡ng hiá»‡u cáº§n Ã¡p dá»¥ng chiáº¿n lÆ°á»£c marketing Ä‘áº¡i trÃ  (mass marketing) thay vÃ¬ chá»‰ táº­p trung vÃ o má»™t nhÃ³m nhá» khÃ¡ch hÃ ng trung thÃ nh. VÃ­ dá»¥, má»™t thÆ°Æ¡ng hiá»‡u nhÆ° Starbucks khÃ´ng chá»‰ quáº£ng cÃ¡o sáº£n pháº©m cá»§a mÃ¬nh Ä‘áº¿n nhá»¯ng ngÆ°á»i yÃªu thÃ­ch cÃ  phÃª mÃ  cÃ²n hÆ°á»›ng Ä‘áº¿n nhá»¯ng ngÆ°á»i chá»‰ thá»‰nh thoáº£ng uá»‘ng Ä‘á»“ uá»‘ng cÃ³ hÆ°Æ¡ng vá»‹ Ä‘áº·c biá»‡t. Há» thÆ°á»ng xuyÃªn tung ra cÃ¡c dÃ²ng sáº£n pháº©m má»›i, cháº³ng háº¡n nhÆ° Ä‘á»“ uá»‘ng theo mÃ¹a (Pumpkin Spice Latte), Ä‘á»ƒ thu hÃºt sá»± chÃº Ã½ cá»§a nhÃ³m khÃ¡ch hÃ ng nÃ y .\n4. Thay Äá»•i CÃ¡c Quan Äiá»ƒm Marketing Truyá»n Thá»‘ng Marketing Cá»• Äiá»ƒn CÃ³ Thá»ƒ Sai Láº§m :) hi hi. TÃ´i khÃ´ng biáº¿t, nhÆ°ng. Theo Byron Sharp, ráº¥t nhiá»u chiáº¿n lÆ°á»£c marketing hiá»‡n Ä‘áº¡i dá»±a trÃªn niá»m tin sai láº§m ráº±ng cÃ¡c thÆ°Æ¡ng hiá»‡u cáº§n táº¡o ra sá»± khÃ¡c biá»‡t rÃµ rá»‡t so vá»›i Ä‘á»‘i thá»§ cáº¡nh tranh Ä‘á»ƒ thu hÃºt khÃ¡ch hÃ ng . Tuy nhiÃªn, nghiÃªn cá»©u thá»±c táº¿ Ä‘Ã£ chá»‰ ra ráº±ng Ä‘iá»u nÃ y khÃ´ng hoÃ n toÃ n chÃ­nh xÃ¡c.\nTrong thá»±c táº¿, khÃ¡ch hÃ ng thÆ°á»ng khÃ´ng nháº­n ra sá»± khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ giá»¯a cÃ¡c thÆ°Æ¡ng hiá»‡u trong cÃ¹ng má»™t ngÃ nh hÃ ng. HÃ£y láº¥y vÃ­ dá»¥ vá» ngÃ nh hÃ ng nÆ°á»›c giáº£i khÃ¡t. Náº¿u há»i má»™t ngÆ°á»i tiÃªu dÃ¹ng bÃ¬nh thÆ°á»ng, há» cÃ³ thá»ƒ khÃ³ nÃ³i Ä‘Æ°á»£c sá»± khÃ¡c biá»‡t cá»¥ thá»ƒ giá»¯a Coca-Cola vÃ  Pepsi, hoáº·c giá»¯a Red Bull vÃ  Monster Energy. Äiá»u nÃ y cho tháº¥y ráº±ng niá»m tin vÃ o viá»‡c xÃ¢y dá»±ng sá»± khÃ¡c biá»‡t Ä‘á»™c Ä‘Ã¡o giá»¯a cÃ¡c thÆ°Æ¡ng hiá»‡u thÆ°á»ng bá»‹ phÃ³ng Ä‘áº¡i. KhÃ¡ch hÃ ng khÃ´ng dÃ nh quÃ¡ nhiá»u thá»i gian Ä‘á»ƒ phÃ¢n tÃ­ch ká»¹ lÆ°á»¡ng tá»«ng Ä‘áº·c Ä‘iá»ƒm sáº£n pháº©m; thay vÃ o Ä‘Ã³, há» thÆ°á»ng quyáº¿t Ä‘á»‹nh mua sáº¯m dá»±a trÃªn yáº¿u tá»‘ quen thuá»™c (brand familiarity) vÃ  tÃ­nh sáºµn cÃ³ (availability) .\nCáº§n nháº¥n máº¡nh ráº±ng viá»‡c cá»‘ gáº¯ng lÃ m ná»•i báº­t tÃ­nh Ä‘á»™c Ä‘Ã¡o cá»§a sáº£n pháº©m Ä‘Ã´i khi khÃ´ng hiá»‡u quáº£ nhÆ° mong Ä‘á»£i, Ä‘áº·c biá»‡t khi ngÃ¢n sÃ¡ch marketing bá»‹ háº¡n cháº¿. VÃ­ dá»¥, má»™t thÆ°Æ¡ng hiá»‡u nhá» trong ngÃ nh má»¹ pháº©m cÃ³ thá»ƒ táº­p trung vÃ o viá»‡c quáº£ng cÃ¡o ráº±ng sáº£n pháº©m cá»§a há» \u0026ldquo;100% tá»± nhiÃªn\u0026rdquo; hoáº·c \u0026ldquo;khÃ´ng chá»©a hÃ³a cháº¥t Ä‘á»™c háº¡i\u0026rdquo;. Tuy nhiÃªn, náº¿u thÆ°Æ¡ng hiá»‡u nÃ y khÃ´ng Ä‘áº§u tÆ° vÃ o viá»‡c tÄƒng Ä‘á»™ nháº­n biáº¿t vÃ  kháº£ nÄƒng tiáº¿p cáº­n, thÃ¬ nhá»¯ng thÃ´ng Ä‘iá»‡p vá» sá»± khÃ¡c biá»‡t nÃ y sáº½ khÃ³ cÃ³ thá»ƒ cháº¡m tá»›i khÃ¡ch hÃ ng tiá»m nÄƒng. Thay vÃ¬ cá»‘ gáº¯ng trá»Ÿ nÃªn \u0026ldquo;Ä‘á»™c nháº¥t vÃ´ nhá»‹\u0026rdquo;, cÃ¡c thÆ°Æ¡ng hiá»‡u nÃªn táº­p trung vÃ o viá»‡c xÃ¢y dá»±ng sá»± hiá»‡n diá»‡n máº¡nh máº½ trong tÃ¢m trÃ­ khÃ¡ch hÃ ng thÃ´ng qua viá»‡c láº·p láº¡i liÃªn tá»¥c vÃ  nháº¥t quÃ¡n . Quáº£ng cÃ¡o TVC cá»§a má»™t thÆ°Æ¡ng hiá»‡u bÃ¡n láº» sá»‘ 1 Viá»‡t Nam cÃ¡ch Ä‘Ã¢y vÃ i nÄƒm mÃ  tÃ´i khÃ´ng tiá»‡n nÃªu tÃªn lÃ  má»™t vÃ­ dá»¥.\nHÃ£y nghÄ© Ä‘áº¿n cÃ¡c thÆ°Æ¡ng hiá»‡u lá»›n nhÆ° McDonaldâ€™s hay Nike â€“ há» khÃ´ng cáº§n pháº£i thay Ä‘á»•i thÃ´ng Ä‘iá»‡p quÃ¡ nhiá»u, mÃ  chá»‰ cáº§n duy trÃ¬ sá»± nháº¥t quÃ¡n trong cÃ¡ch truyá»n táº£i giÃ¡ trá»‹ thÆ°Æ¡ng hiá»‡u. McDonaldâ€™s luÃ´n gáº¯n liá»n vá»›i hÃ¬nh áº£nh cá»§a nhá»¯ng bá»¯a Äƒn nhanh, tiá»‡n lá»£i vÃ  vui váº». DÃ¹ menu cá»§a há» cÃ³ thay Ä‘á»•i theo tá»«ng quá»‘c gia, thÃ´ng Ä‘iá»‡p cá»‘t lÃµi váº«n luÃ´n Ä‘Æ°á»£c giá»¯ nguyÃªn. TÆ°Æ¡ng tá»±, Nike khÃ´ng ngá»«ng nháº¯c nhá»Ÿ khÃ¡ch hÃ ng vá» kháº©u hiá»‡u \u0026ldquo;Just Do It\u0026rdquo; vÃ  hÃ¬nh áº£nh gáº¯n liá»n vá»›i lá»‘i sá»‘ng nÄƒng Ä‘á»™ng, khá»e khoáº¯n. Äiá»u nÃ y giÃºp há» duy trÃ¬ vá»‹ tháº¿ dáº«n Ä‘áº§u trong tÃ¢m trÃ­ khÃ¡ch hÃ ng mÃ  khÃ´ng cáº§n pháº£i liÃªn tá»¥c Ä‘á»•i má»›i thÃ´ng Ä‘iá»‡p .\nDo Ä‘Ã³, thay vÃ¬ cá»‘ gáº¯ng táº¡o ra sá»± khÃ¡c biá»‡t quÃ¡ má»©c, cÃ¡c thÆ°Æ¡ng hiá»‡u nÃªn táº­p trung vÃ o viá»‡c tÄƒng cÆ°á»ng Ä‘á»™ nháº­n biáº¿t (mental availability) vÃ  kháº£ nÄƒng tiáº¿p cáº­n (physical availability). ÄÃ¢y lÃ  hai yáº¿u tá»‘ quan trá»ng giÃºp thÆ°Æ¡ng hiá»‡u xuáº¥t hiá»‡n Ä‘Ãºng lÃºc, Ä‘Ãºng nÆ¡i vÃ  dá»… dÃ ng tiáº¿p cáº­n khÃ¡ch hÃ ng tiá»m nÄƒng .\n5. Nhá»¯ng BÃ i Há»c Thá»±c Tiá»…n: LÃ m Tháº¿ NÃ o Äá»ƒ Ãp Dá»¥ng Nhá»¯ng PhÃ¡t Hiá»‡n Tá»« Cuá»‘n SÃ¡ch? Lá»i khuyÃªn quan trá»ng nháº¥t lÃ  Ä‘á»«ng lÃ£ng phÃ­ nguá»“n lá»±c vÃ o viá»‡c cá»‘ gáº¯ng giá»¯ chÃ¢n khÃ¡ch hÃ ng trung thÃ nh. Thay vÃ o Ä‘Ã³, hÃ£y Ä‘áº§u tÆ° vÃ o viá»‡c má»Ÿ rá»™ng Ä‘á»™ phá»§ sÃ³ng cá»§a thÆ°Æ¡ng hiá»‡u vÃ  cáº£i thiá»‡n kháº£ nÄƒng tiáº¿p cáº­n sáº£n pháº©m. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ chiáº¿n lÆ°á»£c cá»¥ thá»ƒ mÃ  cÃ¡c doanh nghiá»‡p cÃ³ thá»ƒ Ã¡p dá»¥ng:\na. Quáº£ng cÃ¡o rá»™ng rÃ£i hÆ¡n: Äáº£m báº£o thÆ°Æ¡ng hiá»‡u xuáº¥t hiá»‡n á»Ÿ má»i nÆ¡i Äá»ƒ tÄƒng Ä‘á»™ nháº­n biáº¿t (mental availability), cÃ¡c thÆ°Æ¡ng hiá»‡u cáº§n Ä‘áº£m báº£o ráº±ng há» xuáº¥t hiá»‡n á»Ÿ má»i nÆ¡i mÃ  khÃ¡ch hÃ ng tiá»m nÄƒng cÃ³ thá»ƒ nhÃ¬n tháº¥y. Äiá»u nÃ y khÃ´ng chá»‰ giá»›i háº¡n á»Ÿ cÃ¡c kÃªnh quáº£ng cÃ¡o truyá»n thá»‘ng nhÆ° TV, bÃ¡o chÃ­, mÃ  cÃ²n bao gá»“m cáº£ cÃ¡c ná»n táº£ng ká»¹ thuáº­t sá»‘ nhÆ° máº¡ng xÃ£ há»™i, YouTube, vÃ  cÃ¡c á»©ng dá»¥ng di Ä‘á»™ng. VÃ­ dá»¥, má»™t thÆ°Æ¡ng hiá»‡u nhÆ° Coca-Cola khÃ´ng ngá»«ng quáº£ng bÃ¡ sáº£n pháº©m cá»§a mÃ¬nh thÃ´ng qua cÃ¡c chiáº¿n dá»‹ch quáº£ng cÃ¡o toÃ n cáº§u, tá»« Super Bowl Ä‘áº¿n cÃ¡c sá»± kiá»‡n thá»ƒ thao lá»›n nhÆ° World Cup. Nhá» Ä‘Ã³, há» duy trÃ¬ Ä‘Æ°á»£c sá»± hiá»‡n diá»‡n máº¡nh máº½ trong tÃ¢m trÃ­ khÃ¡ch hÃ ng .\nTuy nhiÃªn, quáº£ng cÃ¡o rá»™ng rÃ£i khÃ´ng Ä‘á»“ng nghÄ©a vá»›i viá»‡c \u0026ldquo;lÃ m á»“n Ã o\u0026rdquo; mÃ  khÃ´ng cÃ³ chiáº¿n lÆ°á»£c. CÃ¡c thÆ°Æ¡ng hiá»‡u cáº§n Ä‘áº£m báº£o ráº±ng thÃ´ng Ä‘iá»‡p quáº£ng cÃ¡o cá»§a há» nháº¥t quÃ¡n vÃ  phÃ¹ há»£p vá»›i giÃ¡ trá»‹ cá»‘t lÃµi cá»§a thÆ°Æ¡ng hiá»‡u. VÃ­ dá»¥, Apple luÃ´n gáº¯n liá»n vá»›i hÃ¬nh áº£nh cá»§a sá»± sÃ¡ng táº¡o, Ä‘áº³ng cáº¥p vÃ  cÃ´ng nghá»‡ tiÃªn tiáº¿n. DÃ¹ quáº£ng cÃ¡o trÃªn báº¥t ká»³ ná»n táº£ng nÃ o, thÃ´ng Ä‘iá»‡p cá»§a há» váº«n luÃ´n xoay quanh nhá»¯ng giÃ¡ trá»‹ nÃ y .\nb. Má»Ÿ rá»™ng máº¡ng lÆ°á»›i phÃ¢n phá»‘i: Äáº£m báº£o sáº£n pháº©m cÃ³ máº·t á»Ÿ táº¥t cáº£ cÃ¡c kÃªnh bÃ¡n hÃ ng Kháº£ nÄƒng tiáº¿p cáº­n (physical availability) lÃ  yáº¿u tá»‘ quan trá»ng thá»© hai mÃ  cÃ¡c thÆ°Æ¡ng hiá»‡u cáº§n chÃº trá»ng. Má»™t sáº£n pháº©m dÃ¹ tá»‘t Ä‘áº¿n Ä‘Ã¢u cÅ©ng sáº½ khÃ´ng thá»ƒ thÃ nh cÃ´ng náº¿u khÃ¡ch hÃ ng khÃ´ng thá»ƒ dá»… dÃ ng mua Ä‘Æ°á»£c nÃ³. Do Ä‘Ã³, cÃ¡c thÆ°Æ¡ng hiá»‡u cáº§n má»Ÿ rá»™ng máº¡ng lÆ°á»›i phÃ¢n phá»‘i Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng sáº£n pháº©m cá»§a há» cÃ³ máº·t á»Ÿ táº¥t cáº£ cÃ¡c kÃªnh bÃ¡n hÃ ng, tá»« cá»­a hÃ ng truyá»n thá»‘ng Ä‘áº¿n cÃ¡c ná»n táº£ng thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ .\nVÃ­ dá»¥, má»™t thÆ°Æ¡ng hiá»‡u nhÆ° Unilever Ä‘Ã£ xÃ¢y dá»±ng máº¡ng lÆ°á»›i phÃ¢n phá»‘i rá»™ng kháº¯p, tá»« siÃªu thá»‹ lá»›n nhÆ° Big C, Lotte Mart Ä‘áº¿n cÃ¡c cá»­a hÃ ng táº¡p hÃ³a nhá» á»Ÿ vÃ¹ng nÃ´ng thÃ´n. Äiá»u nÃ y giÃºp há» tiáº¿p cáº­n Ä‘Æ°á»£c cáº£ nhÃ³m khÃ¡ch hÃ ng thÃ nh thá»‹ vÃ  nÃ´ng thÃ´n, tá»« Ä‘Ã³ tÄƒng doanh sá»‘ bÃ¡n hÃ ng má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ. TÆ°Æ¡ng tá»±, cÃ¡c thÆ°Æ¡ng hiá»‡u Ä‘á»“ uá»‘ng nhÆ° Coca-Cola hoáº·c Pepsi luÃ´n Ä‘áº£m báº£o ráº±ng sáº£n pháº©m cá»§a há» cÃ³ máº·t á»Ÿ má»i nÆ¡i, tá»« mÃ¡y bÃ¡n hÃ ng tá»± Ä‘á»™ng táº¡i sÃ¢n bay Ä‘áº¿n cÃ¡c quÃ¡n cÃ  phÃª nhá» .\nc. Tá»‘i Æ°u hÃ³a tráº£i nghiá»‡m mua sáº¯m cá»§a khÃ¡ch hÃ ng: ÄÆ¡n giáº£n hÃ³a quy trÃ¬nh mua hÃ ng BÃªn cáº¡nh viá»‡c quáº£ng cÃ¡o rá»™ng rÃ£i vÃ  má»Ÿ rá»™ng máº¡ng lÆ°á»›i phÃ¢n phá»‘i, cÃ¡c thÆ°Æ¡ng hiá»‡u cÅ©ng cáº§n chÃº trá»ng Ä‘áº¿n viá»‡c tá»‘i Æ°u hÃ³a tráº£i nghiá»‡m mua sáº¯m cá»§a khÃ¡ch hÃ ng. Äiá»u nÃ y bao gá»“m viá»‡c Ä‘Æ¡n giáº£n hÃ³a quy trÃ¬nh mua hÃ ng, cung cáº¥p dá»‹ch vá»¥ khÃ¡ch hÃ ng tá»‘t nháº¥t cÃ³ thá»ƒ, vÃ  Ä‘áº£m báº£o ráº±ng sáº£n pháº©m luÃ´n Ä‘Ã¡p á»©ng Ä‘Æ°á»£c nhu cáº§u cá»§a khÃ¡ch hÃ ng. VÃ­ dá»¥, Amazon Ä‘Ã£ thÃ nh cÃ´ng nhá» viá»‡c tá»‘i Æ°u hÃ³a tráº£i nghiá»‡m mua sáº¯m trá»±c tuyáº¿n, tá»« viá»‡c cung cáº¥p giao diá»‡n dá»… sá»­ dá»¥ng Ä‘áº¿n dá»‹ch vá»¥ giao hÃ ng nhanh chÃ³ng vÃ  chÃ­nh xÃ¡c. Äiá»u nÃ y giÃºp há» thu hÃºt vÃ  giá»¯ chÃ¢n Ä‘Æ°á»£c lÆ°á»£ng lá»›n khÃ¡ch hÃ ng .\nNgoÃ i ra, cÃ¡c thÆ°Æ¡ng hiá»‡u cÅ©ng cáº§n chÃº Ã½ Ä‘áº¿n pháº£n há»“i cá»§a khÃ¡ch hÃ ng Ä‘á»ƒ khÃ´ng ngá»«ng cáº£i thiá»‡n sáº£n pháº©m vÃ  dá»‹ch vá»¥. VÃ­ dá»¥, Netflix thÆ°á»ng xuyÃªn thu tháº­p pháº£n há»“i tá»« ngÆ°á»i dÃ¹ng Ä‘á»ƒ cáº£i thiá»‡n ná»™i dung vÃ  tráº£i nghiá»‡m xem phim. Há» cÅ©ng liÃªn tá»¥c tung ra cÃ¡c dÃ²ng sáº£n pháº©m má»›i, cháº³ng háº¡n nhÆ° chÆ°Æ¡ng trÃ¬nh gá»‘c (original series), Ä‘á»ƒ thu hÃºt sá»± chÃº Ã½ cá»§a khÃ¡ch hÃ ng .\nd. XÃ¢y dá»±ng thÆ°Æ¡ng hiá»‡u dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿ VÃ­ dá»¥, má»™t thÆ°Æ¡ng hiá»‡u nhÆ° Google thÆ°á»ng xuyÃªn sá»­ dá»¥ng dá»¯ liá»‡u ngÆ°á»i dÃ¹ng Ä‘á»ƒ cáº£i thiá»‡n sáº£n pháº©m vÃ  dá»‹ch vá»¥ cá»§a mÃ¬nh. Há» phÃ¢n tÃ­ch hÃ nh vi tÃ¬m kiáº¿m cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ Ä‘Æ°a ra cÃ¡c Ä‘á» xuáº¥t phÃ¹ há»£p vÃ  cÃ¡ nhÃ¢n hÃ³a tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng .\nIII. Chiáº¿n lá»±c táº­n dá»¥ng Light Buyers cho nhÃ³m doanh nghiá»‡p Chiáº¿n lÆ°á»£c cho doanh nghiá»‡p nhá» Doanh nghiá»‡p nhá» thÆ°á»ng cÃ³ nguá»“n lá»±c háº¡n cháº¿, vÃ¬ váº­y cáº§n táº­p trung vÃ o Light Buyers Ä‘á»ƒ tá»‘i Æ°u hÃ³a chi phÃ­ vÃ  má»Ÿ rá»™ng tá»‡p khÃ¡ch hÃ ng tiá»m nÄƒng. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ gá»£i Ã½:\nTÄƒng sá»± nháº­n diá»‡n thÆ°Æ¡ng hiá»‡u: Doanh nghiá»‡p nhá» nÃªn táº­p trung vÃ o viá»‡c tiáº¿p cáº­n nhiá»u khÃ¡ch hÃ ng má»›i, bao gá»“m cáº£ Light Buyers, thÃ´ng qua cÃ¡c chiáº¿n dá»‹ch quáº£ng cÃ¡o sÃ¡ng táº¡o vÃ  ná»™i dung phÃ¹ há»£p. Äiá»u nÃ y giÃºp gia tÄƒng cÆ¡ há»™i bÃ¡n hÃ ng tá»« nhá»¯ng ngÆ°á»i chÆ°a tá»«ng mua sáº£n pháº©m .\nKhuyáº¿n mÃ£i vÃ  tráº£i nghiá»‡m thá»­: Sá»­ dá»¥ng cÃ¡c chÆ°Æ¡ng trÃ¬nh khuyáº¿n mÃ£i, giáº£m giÃ¡ hoáº·c dÃ¹ng thá»­ miá»…n phÃ­ Ä‘á»ƒ thu hÃºt Light Buyers. NhÃ³m nÃ y thÆ°á»ng nháº¡y cáº£m vá»›i giÃ¡ cáº£ vÃ  dá»… bá»‹ thu hÃºt bá»Ÿi cÃ¡c Æ°u Ä‘Ã£i háº¥p dáº«n .\nXÃ¢y dá»±ng lÃ²ng tin: ThÃ´ng qua dá»‹ch vá»¥ chÄƒm sÃ³c khÃ¡ch hÃ ng tá»‘t vÃ  sáº£n pháº©m cháº¥t lÆ°á»£ng, doanh nghiá»‡p nhá» cÃ³ thá»ƒ chuyá»ƒn Ä‘á»•i má»™t sá»‘ Light Buyers thÃ nh Heavy Buyers, tá»« Ä‘Ã³ tÄƒng doanh thu lÃ¢u dÃ i .\nChiáº¿n lÆ°á»£c cho doanh nghiá»‡p lá»›n Doanh nghiá»‡p lá»›n cÃ³ nguá»“n lá»±c dá»“i dÃ o hÆ¡n, vÃ¬ váº­y cÃ³ thá»ƒ Ã¡p dá»¥ng chiáº¿n lÆ°á»£c song song giá»¯a Heavy Buyers vÃ  Light Buyers:\nDuy trÃ¬ má»‘i quan há»‡ vá»›i Heavy Buyers: Táº­p trung vÃ o viá»‡c giá»¯ chÃ¢n nhÃ³m khÃ¡ch hÃ ng trung thÃ nh báº±ng cÃ¡ch cung cáº¥p cÃ¡c chÆ°Æ¡ng trÃ¬nh Æ°u Ä‘Ã£i Ä‘áº·c biá»‡t, quÃ  táº·ng VIP hoáº·c dá»‹ch vá»¥ cÃ¡ nhÃ¢n hÃ³a. Nhá»¯ng ná»— lá»±c nÃ y giÃºp Ä‘áº£m báº£o ráº±ng Heavy Buyers tiáº¿p tá»¥c Ä‘Ã³ng gÃ³p Ä‘Ã¡ng ká»ƒ vÃ o doanh thu .\nMá»Ÿ rá»™ng thá»‹ trÆ°á»ng vá»›i Light Buyers: TÆ°Æ¡ng tá»± nhÆ° doanh nghiá»‡p nhá», doanh nghiá»‡p lá»›n cÅ©ng cáº§n chÃº trá»ng Ä‘áº¿n viá»‡c thu hÃºt thÃªm Light Buyers. Tuy nhiÃªn, á»Ÿ quy mÃ´ lá»›n, há» cÃ³ thá»ƒ Ä‘áº§u tÆ° vÃ o cÃ¡c chiáº¿n dá»‹ch quáº£ng cÃ¡o toÃ n diá»‡n, vÃ­ dá»¥ nhÆ° truyá»n thÃ´ng Ä‘áº¡i chÃºng (TV, bÃ¡o chÃ­) hoáº·c digital marketing trÃªn nhiá»u ná»n táº£ng khÃ¡c nhau .\nÄa dáº¡ng hÃ³a sáº£n pháº©m vÃ  dá»‹ch vá»¥: ÄÆ°a ra cÃ¡c dÃ²ng sáº£n pháº©m má»›i nháº±m Ä‘Ã¡p á»©ng nhu cáº§u cá»§a cáº£ hai nhÃ³m khÃ¡ch hÃ ng. VÃ­ dá»¥, náº¿u kinh doanh quÃ¡n cafe, cÃ³ thá»ƒ phÃ¡t triá»ƒn cÃ¡c loáº¡i Ä‘á»“ uá»‘ng dÃ nh riÃªng cho dá»‹p Ä‘áº·c biá»‡t (thu hÃºt Light Buyers) hoáº·c gÃ³i Æ°u Ä‘Ã£i cho khÃ¡ch hÃ ng thÆ°á»ng xuyÃªn (phá»¥c vá»¥ Heavy Buyers) .\nBÃ i viáº¿t dÆ°á»›i gÃ³c nhÃ¬n cá»§a má»™t con IT quÃ¨n, tháº±ng IT lá», viáº¿t vá» má»™t váº¥n Ä‘á» kinh táº¿, bÃ  con chuyÃªn ngÃ nh tháº¥y sai thÃ¬ hoan há»‰ cÃ²m mÃªn nháº¹ nhÃ ng, Ä‘á»«ng buÃ´n lá»i cay Ä‘áº¯ng.\nCáº£m Æ¡n báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\nNguá»“n tham kháº£o\ncuá»‘n sÃ¡ch How Brands Grow cá»§a tÃ¡c giáº£ Byron Sharp vÃ  Jenni Romaniuk\nBáº£n dá»‹ch tiáº¿ng viá»‡t Con Ä‘Æ°á»ng tÄƒng trÆ°á»Ÿng thÆ°Æ¡ng hiá»‡u\n","date":"Apr 26, 2025","img":"https://unsplash.it/1920/1080?image=231","permalink":"/blog/2025-04-26-how-brands-grow/","series":null,"tags":["marketing"],"title":"KhÃ¡m PhÃ¡ BÃ­ Máº­t Äáº±ng Sau Sá»± ThÃ nh CÃ´ng Cá»§a CÃ¡c ThÆ°Æ¡ng Hiá»‡u"},{"categories":null,"content":" CÃ¡c bÆ°á»›c thá»±c hiá»‡n ChÆ°Æ¡ng 1 â€“ Tuyáº¿t GiÃ¡c TrÃºc LÃ¢m ChÆ°Æ¡ng 2 â€“ TÃ¢m Ma KÃ½ á»¨c ChÆ°Æ¡ng 3 â€“ Huyáº¿t TÃ¢m LiÃªn Hoa ChÆ°Æ¡ng 4 â€“ Tuyáº¿t Giao Chiáº¿n ChÆ°Æ¡ng 5 â€“ Tháº¿ Lá»±c Bá»‹ XÃ© RÃ¡ch ChÆ°Æ¡ng 6 â€“ Ma TÃ´n Äáº¡i Tháº¯ng ChÆ°Æ¡ng 7 â€“ Lá»— Há»•ng KhÃ´ng Gian LÃ  má»™t fan cá»§a tiá»ƒu thuyáº¿t tu tiÃªn, tu tiÃªn giáº£ Ä‘á»i Ä‘áº§u, bá»™ truyá»‡n Ä‘áº§u tiÃªn mÃ¬nh Ä‘á»c lÃ  Tru tiÃªn cá»§a TiÃªu Äá»‰nh. HÃ´m nay, mÃ¬nh chá»£t náº£y ra Ã½ tÆ°á»Ÿng, dÃ¹ng AI, káº¿t há»£p hÃ¬nh tÆ°á»£ng bÄƒng thanh ngá»c khiáº¿t cá»§a Lá»¥c Tuyáº¿t Ká»³, káº¿t há»£p vá»›i má»™t nhÃ¢n váº­t ná»¯ Ä‘á»™c Ä‘oÃ¡n váº¡n cá»— Liá»…u NhÆ° YÃªn, vÃ  Ä‘áº¡i sÆ° huynh diá»‡p thiÃªn Ä‘áº¿ Diá»‡p Tháº§n, thÃ nh má»™t cÃ¢u truyá»‡n má»›i Tuyáº¿t GiÃ¡c TrÃºc LÃ¢m\nCÃ¡c bÆ°á»›c thá»±c hiá»‡n Äá»ƒ cÃ³ thá»ƒ táº¡o Ä‘Æ°á»£c má»™t bá»™ truyá»‡n, chÃºng ta cáº§n nguyÃªn liá»‡u lÃ  bá»‘ cá»¥c cÃ¢u truyá»‡n vÃ  xÃ¢y dá»±ng tÃ­nh cÃ¡ch nhÃ¢n váº­t. NhÃ¢n váº­t chÃ­nh mÃ¬nh cÃ³ rá»“i, giá» chá»‰ cáº§n nhá» AI xÃ¢y dá»±ng bá»‘ cá»¥c dá»±a vÃ o vÃ i gá»£i Ã½, vÃ­ dá»¥ 2 cÃ´ gÃ¡i cÃ¹ng yÃªu Ä‘áº¡i sÆ° huynh ( dáº¡ng cáº©u huyáº¿t) , hoáº·c lÃ  Diá»‡p Tháº§n káº¿t há»£p vá»›i Lá»¥c Tuyáº¿t Ká»³ vÃ  Liá»…u NhÆ° YÃªn phÃ¡ Ä‘Ã¡m \u0026hellip; Chá»‰ cáº§n báº¡n cÃ³ Ã½ tÆ°á»Ÿng, AI sáº½ hoÃ n thÃ nh nÃ³ cho báº¡n.\nvÃ­ dá»¥, tiá»ƒu thyáº¿t ngáº¯n mÃ¬nh yÃªu cáº§u AI viáº¿t nhÆ° sau:\nThá»ƒ loáº¡i: TiÃªn hiá»‡p â€“ Huyá»n huyá»…n â€“ Cá»• trang â€“ TÃ¬nh cáº£m â€“ ChÃ­nh tÃ  lÆ°á»¡ng lá»™\nTuyáº¿n nhÃ¢n váº­t trung tÃ¢m:\nLá»¥c Tuyáº¿t Ká»³ â€“ ná»¯ tu Thanh VÃ¢n MÃ´n, láº¡nh lÃ¹ng, kiÃªn Ä‘á»‹nh, nghÄ©a khÃ­\nLiá»…u NhÆ° YÃªn â€“ truyá»n nhÃ¢n Cáº§m Má»™ng Cá»‘c, Ã´n nhu, ná»™i tÃ¢m sÃ¢u sáº¯c\nDiá»‡p Tháº§n â€“ tá»«ng lÃ  thiÃªn tÃ i tu Ä‘áº¡o, sau bá»‹ káº¿t tá»™i ma tu, nhÃ¢n váº­t trung gian giá»¯a chÃ­nh vÃ  tÃ \nTháº¿ giá»›i: 9 Ä‘áº¡i tiÃªn mÃ´n â€“ 3 vá»±c Ma giá»›i â€“ 1 giá»›i â€œNgoáº¡i vá»±câ€ cá»• xÆ°a bá»‹ phong áº¥n\nCá»‘t truyá»‡n chÃ­nh: HÃ nh trÃ¬nh truy tÃ¬m bÃ­ áº©n vá» BÃ­ch Láº¡c cá»• tÃ´ng, â€œHuyáº¿t TÃ¢m HÃ n LiÃªnâ€ chá»‰ lÃ  khá»Ÿi Ä‘áº§u. BÃ­ máº­t vá» quÃ¡ khá»© Diá»‡p Tháº§n, má»‘i liÃªn há»‡ giá»¯a Tuyáº¿t Ká»³ â€“ NhÆ° YÃªn, vÃ  tháº¿ lá»±c cá»• xÆ°a Ä‘ang dáº§n thá»©c tá»‰nh.\nSau Ä‘Ã³ , chÃºng ta sáº½ yÃªu cáº§u AI lÃªn ká»‹ch báº£n sá»‘ chÆ°Æ¡ng, tiÃªu Ä‘á» má»—i chÆ°Æ¡ng, vÃ  viáº¿t thÃ´i\nTruyá»‡n nÃ y mÃ¬nh yÃªu cáº§u AI viáº¿t hÆ¡n 100 chÆ°Æ¡ng, mÃ¬nh post 7 chÆ°Æ¡ng, cÃ³ ai há»©ng thÃº xem thÃ¬ mÃ¬nh cÃ²m men Ä‘á»ƒ mÃ¬nh post thÃªm, cÃ²n khÃ´ng cÃ³ ai há»©ng thÃº thÃ¬ coi nhÆ° AI viáº¿t dá»Ÿ , he he.\nChÆ°Æ¡ng 1 â€“ Tuyáº¿t GiÃ¡c TrÃºc LÃ¢m Tuyáº¿t rÆ¡i tráº¯ng xÃ³a trá»i.\nTrÃªn Ä‘á»‰nh Tuyáº¿t GiÃ¡c, giá»¯a rá»«ng trÃºc ngÃºt ngÃ n bÄƒng giÃ¡, tá»«ng cÆ¡n giÃ³ thÃ©t gÃ o rÃ­t qua tá»«ng káº½ lÃ¡. TrÃºc xanh phá»§ tuyáº¿t báº¡c, Ä‘áº¥t trá»i nhÆ° hÃ³a thÃ nh bá»©c tranh má»±c tÃ u láº¡nh láº½o vÃ  tá»‹ch má»‹ch.\nGiá»¯a biá»ƒn tráº¯ng mÃªnh mÃ´ng áº¥y, hai bÃ³ng ngÆ°á»i cÃ¹ng lÃºc Ä‘Ã¡p xuá»‘ng Ä‘áº¥t.\nMá»™t ngÆ°á»i khoÃ¡c trÆ°á»ng sam mÃ u lam nháº¡t, thÃ¢n hÃ¬nh thanh máº£nh, cáº§m trong tay má»™t thanh kiáº¿m báº¡c dÃ i gáº§n ba thÆ°á»›c. MÃ¡i tÃ³c nÃ ng dÃ i Ä‘áº¿n eo, Ä‘Æ°á»£c cá»™t báº±ng dÃ¢y lá»¥a tráº¯ng. DÆ°á»›i lá»›p khÄƒn che má»ng, Ã¡nh máº¯t nÃ ng nhÆ° sÆ°Æ¡ng tuyáº¿t nghÃ¬n nÄƒm, láº·ng láº½ vÃ  sáº¯c bÃ©n nhÆ° kiáº¿m Ä‘Ã£ rÃºt khá»i vá».\nLá»¥c Tuyáº¿t Ká»³ â€“ Ä‘á»‡ tá»­ chÃ¢n truyá»n Thanh VÃ¢n MÃ´n, Kiáº¿m TÃ¢m khÃ´ng dao Ä‘á»™ng, lÃ  má»™t trong bá»‘n ngÆ°á»i Ä‘Æ°á»£c truyá»n thá»¥ kiáº¿m Ä‘áº¡o tá»‘i cao cá»§a tÃ´ng mÃ´n.\nÄá»‘i diá»‡n nÃ ng lÃ  má»™t thiáº¿u ná»¯ trong bá»™ cáº§m y tÃ­m nháº¡t, bÃªn hÃ´ng mang má»™t á»‘ng trÃºc xanh. Má»—i bÆ°á»›c Ä‘i cá»§a nÃ ng nháº¹ nhÆ° tiáº¿ng giÃ³ lÆ°á»›t qua lÃ¡ trÃºc, mÆ¡ há»“ nhÆ° má»™ng. ÄÃ´i máº¯t nÃ ng nhÆ° Ä‘ang cÆ°á»i, nhÆ°ng trong ná»¥ cÆ°á»i áº¥y láº¡i chá»©a chÃºt buá»“n cháº³ng thá»ƒ nÃ³i thÃ nh lá»i.\nLiá»…u NhÆ° YÃªn â€“ truyá»n nhÃ¢n duy nháº¥t cá»§a Cáº§m Má»™ng Cá»‘c, ná»•i danh vá»›i cáº§m Ä‘áº¡o cÃ³ thá»ƒ hÃ³a tÃ¢m, thá»©c tá»‰nh linh trÃ­, cháº¿ ngá»± tÃ  niá»‡m.\nHai ngÆ°á»i Ä‘á»u Ä‘áº¿n nÆ¡i nÃ y â€“ vÃ¬ má»™t lÃ½ do.\nMá»™t ngÆ°á»i Ä‘á»ƒ tÃ¬m linh váº­t Huyáº¿t TÃ¢m HÃ n LiÃªn, mong cá»©u má»™t sinh má»‡nh Ä‘ang háº¥p há»‘i. Má»™t ngÆ°á»i vÃ¬ linh tráº­n cá»• tÃ´ng, cÅ©ng lÃ  Ä‘á»ƒ tráº£ láº¡i má»™t má»‘i nghi hoáº·c Ä‘Ã£ Ä‘Ã¨ náº·ng trong lÃ²ng nhiá»u nÄƒm.\nVÃ  cáº£ hai\u0026hellip; Ä‘á»u vÃ¬ má»™t cÃ¡i tÃªn.\nDiá»‡p Tháº§n.\nChÃ ng tá»«ng lÃ  sÆ° huynh cá»§a Tuyáº¿t Ká»³, lÃ  ngÆ°á»i nÃ ng ngÆ°á»¡ng má»™, cÅ©ng lÃ  káº» pháº£n bá»™i mÃ´n quy nÄƒm nÄƒm trÆ°á»›c, bá»‹ Thanh VÃ¢n MÃ´n truy sÃ¡t. ChÃ ng cÅ©ng lÃ  ngÆ°á»i tá»«ng cá»©u máº¡ng NhÆ° YÃªn trong chuyáº¿n chu du nÄƒm áº¥y, Ä‘á»ƒ láº¡i khÃºc â€œPhong Tuyáº¿t HÃ nhâ€ khiáº¿n nÃ ng kháº¯c cá»‘t ghi tÃ¢m.\nMÃ  giá» Ä‘Ã¢y, chÃ ng Ä‘ang cáº­n ká» sinh tá»­ â€“ bá»Ÿi Ma Há»a TÃ¢m ChÃº pháº£n phá»‡, náº¿u khÃ´ng cÃ³ Huyáº¿t TÃ¢m HÃ n LiÃªn, cháº¯c cháº¯n há»“n phi phÃ¡ch tÃ¡n.\nTráº­n phÃ¡p giá»¯a rá»«ng trÃºc báº¯t Ä‘áº§u khá»Ÿi Ä‘á»™ng. DÆ°á»›i Ä‘áº¥t, cÃ¡c phÃ¹ vÄƒn phÃ¡t sÃ¡ng Ä‘á» nhÆ° mÃ¡u, tá»«ng cá»™t sÃ¡ng báº¯n tháº³ng lÃªn khÃ´ng trung, hÃ¬nh thÃ nh má»™t vÃ²ng linh tráº­n bao phá»§ kháº¯p ngá»n Ä‘á»“i.\nâ€œNgÆ°Æ¡i cÅ©ng vÃ¬ háº¯n mÃ  Ä‘áº¿n?â€ â€“ Liá»…u NhÆ° YÃªn lÃªn tiáº¿ng trÆ°á»›c, giá»ng nháº¹ nhÆ° giÃ³ tuyáº¿t.\nLá»¥c Tuyáº¿t Ká»³ khÃ´ng Ä‘Ã¡p. Ãnh máº¯t nÃ ng nhÃ¬n vÃ o tÃ¢m tráº­n, nÆ¡i hoa sen mÃ¡u váº«n chÆ°a hiá»‡n hÃ¬nh, nhÆ° Ä‘ang cá»‘ che giáº¥u Ä‘iá»u gÃ¬ trong Ã¡nh nhÃ¬n bÃ¬nh tÄ©nh áº¥y.\nâ€œTa khÃ´ng trÃ¡ch ngÆ°Æ¡i.â€ â€“ NhÆ° YÃªn láº¡i nÃ³i, â€œNÄƒm Ä‘Ã³â€¦ ai trong chÃºng ta cÅ©ng khÃ´ng Ä‘á»§ dÅ©ng khÃ­.â€\nTuyáº¿t Ká»³ kháº½ siáº¿t tay cáº§m kiáº¿m.\nNÄƒm nÄƒm trÆ°á»›c, khi Diá»‡p Tháº§n bá»‹ nghi ngá» tu luyá»‡n ma phÃ¡p, nÃ ng lÃ  ngÆ°á»i Ä‘Æ°á»£c phÃ¡i Ä‘áº¿n Ä‘á»ƒ tra xÃ©t. NhÆ°ng lÃºc Ä‘á»‘i máº·t, nÃ ng khÃ´ng giáº¿t chÃ ng â€“ cÅ©ng khÃ´ng báº£o vá»‡ chÃ ng. NÃ ng chá»‰ Ä‘á»©ng nhÃ¬n, Ä‘á»ƒ máº·c sÆ° huynh khÃ¡c ra tay, Ä‘á»ƒ máº·c chÃ ng rÆ¡i xuá»‘ng vá»±c sÃ¢u.\nNgÃ y Ä‘Ã³, nÃ ng tÆ°á»Ÿng mÃ¬nh Ä‘Ã£ cháº·t Ä‘á»©t Ä‘Æ°á»£c má»i tÆ¡ vÆ°Æ¡ng.\nNhÆ°ng Ä‘Ãªm qua, khi NhÆ° YÃªn tÃ¬m Ä‘áº¿n, nÃ³i ráº±ng chÃ ng váº«n sá»‘ng, vÃ  Ä‘ang háº¥p há»‘iâ€¦ lÃ²ng nÃ ng láº¡i rung lÃªn má»™t nhá»‹p â€“ nhÆ° tiáº¿ng kiáº¿m cháº¥n Ä‘á»™ng trong vá» kiáº¿m láº¡nh.\náº¦m!\nLinh tráº­n phÃ¡t ra Ã¢m thanh tráº§m Ä‘á»¥c. DÆ°á»›i máº·t Ä‘áº¥t, má»™t Ä‘oÃ¡ sen Ä‘á» rá»±c tá»« tá»« trá»“i lÃªn giá»¯a tÃ¢m tráº­n â€“ Huyáº¿t TÃ¢m HÃ n LiÃªn.\nNÃ³ Ä‘áº¹p Ä‘áº¿n mÃª há»“n, má»—i cÃ¡nh hoa nhÆ° Ä‘Æ°á»£c Ä‘iÃªu kháº¯c tá»« mÃ¡u ngá»c, tá»a ra hÃ n khÃ­ láº¡ lÃ¹ng.\nNhÆ°ng vá»«a khi hai ngÆ°á»i Ä‘á»‹nh bÆ°á»›c vÃ o, má»™t áº£o áº£nh Ä‘á»™t nhiÃªn hiá»‡n ra â€“ TÃ¢m Ma Giá»›i khá»Ÿi Ä‘á»™ng!\nKhung cáº£nh thay Ä‘á»•i ngay láº­p tá»©c.\nTuyáº¿t Ká»³ tháº¥y mÃ¬nh Ä‘á»©ng giá»¯a sÃ¢n luyá»‡n kiáº¿m Thanh VÃ¢n. Diá»‡p Tháº§n quay Ä‘áº§u láº¡i nhÃ¬n nÃ ng, Ã¡nh máº¯t Ä‘áº§y tháº¥t vá»ng.\nâ€œNáº¿u nÄƒm Ä‘Ã³ ngÆ°Æ¡i tin ta má»™t cÃ¢u, ta Ä‘Ã£ khÃ´ng rÆ¡i vÃ o ma Ä‘áº¡o.â€\nNÃ ng Ä‘Æ°a tay ra, nhÆ°ng chá»‰ cháº¡m vÃ o hÆ° khÃ´ng.\nCÃ²n Liá»…u NhÆ° YÃªn, trong áº£o áº£nh, tháº¥y Diá»‡p Tháº§n má»‰m cÆ°á»i, rá»“i xoay ngÆ°á»i rá»i Ä‘i.\nâ€œNÃ ng lÃ  ngÆ°á»i duy nháº¥t khiáº¿n ta muá»‘n sá»‘ng tiáº¿p. NhÆ°ng\u0026hellip; ta khÃ´ng xá»©ng.â€\nMá»™t khÃºc nháº¡c cáº§m vang lÃªn giá»¯a hÆ° khÃ´ng, nÃ ng báº­t khÃ³c trong cáº£nh giá»›i má»™ng áº£o.\nKhi hai ngÆ°á»i cÃ¹ng phÃ¡ vá»¡ Ä‘Æ°á»£c tÃ¢m ma, áº£o cáº£nh tan biáº¿n, cÅ©ng lÃ  lÃºc Huyáº¿t TÃ¢m HÃ n LiÃªn ná»Ÿ rá»™.\nâ€œLinh váº­t chá»‰ cÃ³ má»™t,â€ â€“ NhÆ° YÃªn nÃ³i kháº½, â€œChÃºng ta\u0026hellip; khÃ´ng thá»ƒ chia.â€\nTuyáº¿t Ká»³ cÃºi Ä‘áº§u nhÃ¬n Ä‘oÃ¡ hoa trong tay, há»“i lÃ¢u má»›i Ä‘Ã¡p:\nâ€œTa khÃ´ng thá»ƒ cá»©u háº¯n má»™t mÃ¬nh.â€\nNhÆ° YÃªn má»‰m cÆ°á»i, nghiÃªng Ä‘áº§u nhÃ¬n nÃ ng:\nâ€œVáº­y thÃ¬\u0026hellip; cÃ¹ng nhau Ä‘i.â€\nTuyáº¿t Ká»³ kháº½ gáº­t Ä‘áº§u.\nTuyáº¿t váº«n rÆ¡i, nhÆ°ng giá»¯a rá»«ng trÃºc, Ä‘Ã£ cÃ³ hai bÃ³ng ngÆ°á»i cÃ¹ng sÃ³ng vai.\nVÃ¬ má»™t ngÆ°á»i. VÃ¬ má»™t tÃ­n niá»‡m xÆ°a cÅ©. VÃ  vÃ¬ má»™t con Ä‘Æ°á»ng â€“ mÃ  tá»« hÃ´m nay, cáº£ hai Ä‘á»u khÃ´ng thá»ƒ quay Ä‘áº§u.\nChÆ°Æ¡ng 2 â€“ TÃ¢m Ma KÃ½ á»¨c BÃªn dÆ°á»›i Tuyáº¿t GiÃ¡c sÆ¡n, má»™t hang Ä‘á»™ng nhá» chÃ¬m trong Ã¡nh lam nháº¡t cá»§a bÄƒng tinh, tá»«ng giá»t nÆ°á»›c nhá» xuá»‘ng, vang vá»ng nhÆ° tiáº¿ng Ä‘Ã n Ä‘Ã¡ láº·ng láº½ ngÃ¢n vang.\nDiá»‡p Tháº§n náº±m báº¥t Ä‘á»™ng trÃªn má»™t bá»‡ ngá»c hÃ n tháº¡ch, sáº¯c máº·t tÃ¡i nhá»£t, mi tÃ¢m áº©n hiá»‡n háº¯c phÃ¹ láº¥p lÃ¡nh. HÆ¡i thá»Ÿ yáº¿u á»›t nhÆ° sáº¯p táº¯t.\nLiá»…u NhÆ° YÃªn ngá»“i bÃªn cáº¡nh, tay Ä‘áº·t lÃªn Ä‘Ã n ngá»c xanh lá»¥c. Má»™t báº£n cáº§m khÃºc dá»‹u dÃ ng vang lÃªn, dáº«n dáº¯t linh khÃ­ nháº­p thá»ƒ cho Diá»‡p Tháº§n. Má»—i ná»‘t Ä‘Ã n lÃ  má»™t Ä‘áº¡o cáº§m Ã½, hÃ²a vÃ o hÆ° khÃ´ng, giá»¯ láº¥y há»“n phÃ¡ch Diá»‡p Tháº§n khá»i tan biáº¿n.\nLá»¥c Tuyáº¿t Ká»³ Ä‘á»©ng xa hÆ¡n, tay váº«n giá»¯ láº¥y Huyáº¿t TÃ¢m HÃ n LiÃªn chÆ°a giao ra.\nNÃ ng Ä‘ang do dá»±.\nNáº¿u dÃ¹ng linh váº­t nÃ yâ€¦ chÃ­nh lÃ  káº¿t ná»‘i sinh má»‡nh báº£n thÃ¢n vá»›i Diá»‡p Tháº§n. Má»™t pháº§n há»“n lá»±c sáº½ vÄ©nh viá»…n bá»‹ phong áº¥n Ä‘á»ƒ giá»¯ máº¡ng cho ngÆ°á»i kia.\nKhÃ´ng chá»‰ lÃ  má»™t láº§n cá»©u â€“ mÃ  lÃ  rÃ ng buá»™c giá»¯a hai sinh má»‡nh.\nNÃ ng xiáº¿t cháº·t bÃ n tay.\nHÃ¬nh áº£nh trong TÃ¢m Ma Giá»›i váº«n cÃ²n Ä‘Ã³. Giá»ng nÃ³i Diá»‡p Tháº§n nhÆ° dao cá»©a trong tim nÃ ng.\nâ€œNáº¿u nÄƒm Ä‘Ã³ ngÆ°Æ¡i tin ta má»™t cÃ¢u, ta Ä‘Ã£ khÃ´ng rÆ¡i vÃ o ma Ä‘áº¡o.â€\nNÃ ng muá»‘n nÃ³i ráº±ng\u0026hellip; nÃ ng Ä‘Ã£ tin. NhÆ°ng nÃ ng khÃ´ng Ä‘á»§ can Ä‘áº£m. Thanh VÃ¢n MÃ´n lÃ  tÃ­n ngÆ°á»¡ng cáº£ Ä‘á»i nÃ ng, lÃ m sao nÃ ng dÃ¡m nghiÃªng lÃ²ng vá» má»™t káº» bá»‹ xem lÃ  pháº£n Ä‘á»“?\nNhÆ° YÃªn nháº¹ nhÃ ng nÃ³i:\nâ€œTa sáº½ dÃ¹ng Ä‘Ã n giá»¯ há»“n. NhÆ°ng náº¿u muá»‘n cá»©u tháº­t, cáº§n cÃ³ linh váº­t há»£p má»‡nh.â€\nTuyáº¿t Ká»³ khÃ´ng Ä‘Ã¡p, cháº­m rÃ£i bÆ°á»›c tá»›i. Tay nÃ ng Ä‘áº·t lÃªn mi tÃ¢m Diá»‡p Tháº§n. Trong phÃºt chá»‘c, hai luá»“ng khÃ­ tá»©c va cháº¡m â€“ má»™t láº¡nh nhÆ° bÄƒng tuyáº¿t, má»™t há»—n loáº¡n Ã¢m dÆ°Æ¡ng.\nâ€œTa khÃ´ng tinâ€¦ huynh lÃ  ngÆ°á»i háº¡i sÆ° huynh TrÃ¡c DÆ°Æ¡ng.â€ â€“ nÃ ng thÃ¬ tháº§m, â€œNhÆ°ng huynh khÃ´ng giáº£i thÃ­ch.â€\nÃnh sÃ¡ng tá»« Huyáº¿t TÃ¢m HÃ n LiÃªn tá»« tá»« nháº­p thá»ƒ vÃ o Diá»‡p Tháº§n. CÃ¡nh hoa ráº¡n ná»©t tá»«ng chÃºt, tá»«ng cÃ¡nh rÆ¡i xuá»‘ng, hÃ³a thÃ nh tinh linh rá»±c Ä‘á» nháº­p vÃ o máº¡ch khÃ­.\nGiÃ³ thá»•i qua. KhÃ´ng cÃ²n lÃ  giÃ³ láº¡nh Tuyáº¿t GiÃ¡c â€“ mÃ  lÃ  tiáº¿ng thÃ¬ tháº§m nhÆ° vá»ng tá»« nÄƒm xÆ°a.\nNÄƒm nÄƒm trÆ°á»›c.\nTáº¡i Thanh VÃ¢n SÆ¡n, ngÃ y Diá»‡p Tháº§n bá»‹ truy sÃ¡t, trá»i cÅ©ng Ä‘á»• tuyáº¿t.\nTuyáº¿t Ká»³ khi áº¥y chá»‰ Ä‘á»©ng bÃªn vÃ¡ch nÃºi, nhÃ¬n ngÆ°á»i sÆ° huynh tá»«ng dáº¡y nÃ ng kiáº¿m phÃ¡p quá»³ gá»‘i, má»™t thÃ¢n mÃ¡u tÆ°Æ¡i, trÆ°á»›c máº·t cÃ¡c trÆ°á»Ÿng lÃ£o.\nTrÃ¡c DÆ°Æ¡ng â€“ sÆ° huynh cá»§a há» â€“ Ä‘Ã£ cháº¿t, phÃ¡p báº£o bá»‹ há»§y. Má»i chá»©ng cá»© Ä‘á»u chá»‰ vá» Diá»‡p Tháº§n.\nâ€œTa khÃ´ng giáº¿t háº¯n.â€ â€“ Diá»‡p Tháº§n chá»‰ nÃ³i má»™t cÃ¢u.\nNhÆ°ng khÃ´ng ai tin.\nTuyáº¿t Ká»³ khÃ´ng bÆ°á»›c ra. NÃ ng chá»‰ náº¯m cháº·t thanh kiáº¿m bÃªn hÃ´ng, nhÃ¬n theo bÃ³ng ngÆ°á»i rÆ¡i xuá»‘ng vá»±c sÃ¢u giá»¯a trá»i tuyáº¿t tráº¯ng.\nNá»—i sá»£ khi Ä‘Ã³ khÃ´ng pháº£i vÃ¬ Diá»‡p Tháº§n â€“ mÃ  vÃ¬ báº£n thÃ¢n nÃ ng. Sá»£ ráº±ng náº¿u nÃ ng lÃªn tiáº¿ng, nÃ ng sáº½ bá»‹ tÃ´ng mÃ´n xem lÃ  pháº£n bá»™i.\nSau nÃ y, nÃ ng khÃ´ng dÃ¡m cáº§m láº¡i thanh kiáº¿m ngÃ y áº¥y.\nLinh lá»±c trong cÆ¡ thá»ƒ Diá»‡p Tháº§n dáº§n á»•n Ä‘á»‹nh. Háº¯c phÃ¹ trÃªn trÃ¡n tan Ä‘i, thay vÃ o Ä‘Ã³ lÃ  má»™t váº§ng sÃ¡ng Ä‘á» nháº¡t Ä‘ang Ä‘áº­p nhÆ° nhá»‹p tim.\nâ€œÄÃ£ káº¿t ná»‘i linh máº¡ch.â€ â€“ NhÆ° YÃªn thá»Ÿ nháº¹. â€œGiá»\u0026hellip; chá»‰ cÃ²n chá» háº¯n tá»‰nh láº¡i.â€\nTuyáº¿t Ká»³ quay Ä‘i, Ä‘á»©ng nhÃ¬n ra tuyáº¿t tráº¯ng.\nGiÃ³ thá»•i tung dáº£i lá»¥a trÃªn tÃ³c nÃ ng. Trong lÃ²ng, má»™t tia Ã¡y nÃ¡y khÃ´ng tÃªn dáº§n káº¿t thÃ nh háº¡t bÄƒng nhá» â€“ nhÆ°ng cÅ©ng láº·ng láº½ tan cháº£y.\ná» phÃ­a sau, NhÆ° YÃªn chá»£t cáº¥t tiáº¿ng:\nâ€œCÃ´ Ä‘Ã£ tá»«ng thÃ­ch háº¯n, Ä‘Ãºng khÃ´ng?â€\nTuyáº¿t Ká»³ khá»±ng láº¡i.\nâ€œTa khÃ´ng rÃµ Ä‘Ã³ cÃ³ gá»i lÃ  â€˜thÃ­châ€™ khÃ´ng.â€ â€“ nÃ ng Ä‘Ã¡p, â€œNhÆ°ng ta ná»£ háº¯n má»™t lá»i xin lá»—i.â€\nâ€œVáº­yâ€¦ náº¿u láº§n nÃ y háº¯n tá»‰nh láº¡i, cÃ´ cÃ³ Ä‘á»‹nh bÃ¹ Ä‘áº¯p khÃ´ng?â€ â€“ NhÆ° YÃªn cÆ°á»i nháº¹, nhÆ°ng trong máº¯t nÃ ng lÃ  thá»© Ã¡nh sÃ¡ng ráº¥t khÃ³ phÃ¢n Ä‘á»‹nh giá»¯a dá»‹u dÃ ng vÃ  kiÃªn quyáº¿t.\nTuyáº¿t Ká»³ khÃ´ng Ä‘Ã¡p.\nNÃ ng chá»‰ nhÃ¬n tuyáº¿t rÆ¡i, lÃ²ng tháº§m nghÄ©:\nNáº¿u Diá»‡p Tháº§n tá»‰nh láº¡iâ€¦ ta sáº½ khÃ´ng im láº·ng nhÆ° nÄƒm xÆ°a ná»¯a.\ná» bá»‡ ngá»c, mi máº¯t Diá»‡p Tháº§n kháº½ Ä‘á»™ng.\nMá»™t lÃ n khÃ­ Ä‘á» nháº¡t tá»a ra tá»« tim chÃ ng, dung há»£p giá»¯a bÄƒng hÃ n cá»§a Tuyáº¿t Ká»³ vÃ  tá»‹nh Ã¢m cá»§a cáº§m Ä‘áº¡o NhÆ° YÃªn.\nChÃ ng sáº¯p tá»‰nh.\nNhÆ°ng\u0026hellip; cÅ©ng Ä‘Ãºng lÃºc áº¥y, trong sÃ¢u tháº³m linh há»“n Diá»‡p Tháº§n, má»™t giá»ng nÃ³i vang lÃªn:\nâ€œNgÆ°Æ¡i tÆ°á»Ÿng thoÃ¡t rá»“i sao? Ngoáº¡i Vá»±c váº«n Ä‘ang nhÃ¬n ngÆ°Æ¡i. VÃ  khi ngÆ°Æ¡i má»Ÿ máº¯t\u0026hellip; má»i thá»© má»›i chá»‰ báº¯t Ä‘áº§u.â€\nChÆ°Æ¡ng 3 â€“ Huyáº¿t TÃ¢m LiÃªn Hoa Ãnh lá»­a há»“ng nhÃ n nháº¡t láº¥p lÃ³e trong hÃ n Ä‘á»™ng nhÆ° máº¡ch mÃ¡u Ä‘ang Ä‘áº­p giá»¯a lÃ²ng bÄƒng tuyáº¿t.\nDiá»‡p Tháº§n má»Ÿ máº¯t.\nMáº¯t chÃ ng vá»‘n Ä‘en tuyá»n, nhÆ°ng giá» Ä‘Ã¢y bÃªn trong áº©n hiá»‡n má»™t vá»‡t Ä‘á» mÆ¡ há»“ â€“ tÃ n dÆ° cá»§a Ma Há»a TÃ¢m ChÃº, nhÆ°ng láº¡i tráº§m á»•n Ä‘áº¿n ká»³ láº¡, khÃ´ng cÃ²n cuá»“ng loáº¡n nhÆ° trÆ°á»›c.\nCáº£m giÃ¡c Ä‘áº§u tiÃªn lÃ \u0026hellip; láº¡nh. Láº¡nh tá»« xÆ°Æ¡ng tá»§y.\nSau Ä‘Ã³ lÃ \u0026hellip; Ã¢m thanh.\nMá»™t khÃºc cáº§m nháº¹ nhÃ ng vá»— vá» tÃ¢m trÃ­, tá»«ng ná»‘t nhÆ° xoa dá»‹u linh há»“n rÃ¡ch nÃ¡t cá»§a chÃ ng, dáº«n lá»‘i chÃ ng tá»« bÃ³ng tá»‘i quay láº¡i thá»±c táº¡i.\nDiá»‡p Tháº§n nhÃ¬n quanh, kháº½ cá»±a mÃ¬nh. Ãnh máº¯t mÆ¡ há»“ dáº§n rÃµ rÃ ng â€“ vÃ  rá»“i\u0026hellip; Ã¡nh máº¯t áº¥y dá»«ng láº¡i.\nLÃ  nÃ ng.\nLiá»…u NhÆ° YÃªn.\nTÃ³c nÃ ng rá»‘i nháº¹ vÃ¬ giÃ³ trong Ä‘á»™ng, ngÃ³n tay váº«n Ä‘áº·t trÃªn dÃ¢y Ä‘Ã n. Khi Ã¡nh máº¯t há» cháº¡m nhau, nÃ ng kháº½ cÆ°á»i.\nâ€œChÃ ng tá»‰nh rá»“i.â€\nChÃ ng chÆ°a ká»‹p Ä‘Ã¡p lá»i, thÃ¬ má»™t giá»ng khÃ¡c vang lÃªn â€“ láº¡nh vÃ  sáº¯c nhÆ° kiáº¿m:\nâ€œNgÆ°Æ¡i\u0026hellip; cÃ²n nhá»› ta khÃ´ng?â€\nDiá»‡p Tháº§n quay sang, nhÃ¬n tháº¥y Lá»¥c Tuyáº¿t Ká»³. NÃ ng Ä‘á»©ng Ä‘Ã³, Ã¡nh máº¯t láº¡nh lÃ¹ng, nhÆ°ng bÃªn trong giáº¥u má»™t tia cháº¥n Ä‘á»™ng khÃ´ng thá»ƒ che giáº¥u.\nCáº£ hai Ä‘á»u im láº·ng má»™t lÃºc.\nRá»“i Diá»‡p Tháº§n cáº¥t giá»ng, khÃ n khÃ n:\nâ€œKhÃ´ng nghÄ©\u0026hellip; cÃ²n cÃ³ thá»ƒ tháº¥y cÃ¡c ngÆ°Æ¡i.â€\nGiá»ng nÃ³i khÃ´ng oÃ¡n háº­n, cÅ©ng khÃ´ng dá»‹u dÃ ng. Chá»‰ nhÆ° má»™t káº» tá»«ng cháº¿t Ä‘i má»™t láº§n, giá» quay vá», cháº³ng cÃ²n tha thiáº¿t truy cá»©u quÃ¡ khá»©.\nTuyáº¿t Ká»³ nhÃ­u mÃ y.\nNhÆ° YÃªn nháº¹ nhÃ ng tiáº¿p lá»i:\nâ€œChÃºng ta tÃ¬m tháº¥y Huyáº¿t TÃ¢m HÃ n LiÃªn, cá»©u Ä‘Æ°á»£c chÃ ng\u0026hellip; nhÆ°ng chá»‰ lÃ  táº¡m thá»i. Há»a chÃº trong tÃ¢m máº¡ch cá»§a chÃ ng váº«n chÆ°a hoÃ n toÃ n bá»‹ Ã©p lui.â€\nDiá»‡p Tháº§n tráº§m máº·c, rá»“i ngá»“i dáº­y, dá»±a lÆ°ng vÃ o bá»‡ ngá»c. MÃ¡i tÃ³c Ä‘en dÃ i rÅ© xuá»‘ng, chÃ ng nhÃ¬n vÃ o lÃ²ng bÃ n tay mÃ¬nh â€“ nÆ¡i cÃ³ má»™t váº¿t Ä‘á» nháº¡t váº«n cÃ²n Ä‘ang chá»›p Ä‘á»™ng.\nâ€œVáº­y lÃ \u0026hellip; ta váº«n chÆ°a trá»‘n khá»i Ä‘Æ°á»£c nÃ³.â€\nTuyáº¿t Ká»³ há»i, â€œNÃ³ lÃ  gÃ¬?â€\nDiá»‡p Tháº§n cháº­m rÃ£i Ä‘Ã¡p:\nâ€œKhÃ´ng pháº£i ma phÃ¡p. CÅ©ng khÃ´ng pháº£i tÃ  thuáº­t. ÄÃ³ lÃ  káº¿t áº¥n tá»« Ngoáº¡i Vá»±c.â€\nCÃ¢u nÃ³i nhÆ° sÃ©t Ä‘Ã¡nh ngang tai.\nLiá»…u NhÆ° YÃªn biáº¿n sáº¯c.\nâ€œNgoáº¡i Vá»±c?\u0026hellip; Láº½ nÃ o lÃ \u0026hellip; vá»±c ngoáº¡i chÃ¢n ma trong truyá»n thuyáº¿t?â€ â€“ nÃ ng há»i.\nDiá»‡p Tháº§n gáº­t Ä‘áº§u.\nâ€œNÄƒm Ä‘Ã³ ta khÃ´ng pháº£n bá»™i TrÃ¡c DÆ°Æ¡ng. LÃ  háº¯n, vÃ¬ tÃ¬m kiáº¿m bÃ­ thuáº­t Ä‘á»ƒ tÄƒng tu vi, Ä‘Ã£ má»Ÿ ra má»™t khe ná»©t linh há»“n, dáº«n linh thá»©c cá»§a Ngoáº¡i Vá»±c xÃ¢m nháº­p. Ta ngÄƒn khÃ´ng ká»‹p. TrÆ°á»›c khi cháº¿t, háº¯n Ä‘Ã£ cáº¥y máº§m há»a áº¥n vÃ o ta, muá»‘n kÃ©o ta cÃ¹ng xuá»‘ng Ä‘á»‹a ngá»¥c.â€\nÃnh máº¯t Tuyáº¿t Ká»³ run lÃªn. MÃ´i nÃ ng kháº½ mÃ­m láº¡i.\nâ€œVÃ¬ sao\u0026hellip; lÃºc Ä‘Ã³ khÃ´ng nÃ³i?â€\nDiá»‡p Tháº§n cÆ°á»i nháº¡t.\nâ€œNÃ³i? CÃ¡c ngÆ°Æ¡i cÃ³ ai tin? Ngay cáº£ nÃ ng\u0026hellip; cÅ©ng khÃ´ng bÆ°á»›c ra.â€\nCÃ¢u nÃ³i áº¥y khÃ´ng náº·ng giá»ng, nhÆ°ng má»—i chá»¯ nhÆ° chÃ¢m lá»­a trong tim Tuyáº¿t Ká»³. NÃ ng quay máº·t Ä‘i, khÃ´ng Ä‘Ã¡p.\nNhÆ° YÃªn dá»‹u giá»ng há»i:\nâ€œVáº­y bÃ¢y giá» thÃ¬ sao? Káº¿t áº¥n áº¥yâ€¦ cÃ²n tá»“n táº¡i trong tÃ¢m máº¡ch, liá»‡u cÃ³ bá»™c phÃ¡t láº§n ná»¯a?â€\nDiá»‡p Tháº§n tráº§m ngÃ¢m.\nâ€œNáº¿u Ä‘á»ƒ máº·c, sau ba nÄƒm\u0026hellip; ta sáº½ trá»Ÿ thÃ nh váº­t dáº«n cho Ã½ chÃ­ Ngoáº¡i Vá»±c. KhÃ´ng cÃ²n lÃ  ta ná»¯a.â€\nLáº·ng im bao trÃ¹m.\nBa ngÆ°á»i, má»—i ngÆ°á»i mang theo má»™t tÃ¢m sá»±, giá» pháº£i cÃ¹ng Ä‘á»‘i diá»‡n vá»›i tai há»a lá»›n hÆ¡n há» tá»«ng tÆ°á»Ÿng tÆ°á»£ng.\nRá»“i báº¥t ngá» â€“ áº¦m!\nCáº£ sÆ¡n Ä‘á»™ng rung chuyá»ƒn.\nMá»™t Ä‘áº¡o khÃ­ tá»©c khá»•ng lá»“ tá»« bÃªn ngoÃ i Ã¡p xuá»‘ng. Tuyáº¿t rÆ¡i dá»“n dáº­p nhÆ° bá»‹ thá»© gÃ¬ quÃ©t qua. Tá»« sÃ¢u trong rá»«ng trÃºc, má»™t bÃ³ng Ä‘en khá»•ng lá»“ Ä‘ang tá»« tá»« tiáº¿n Ä‘áº¿n â€“ Kim Äan yÃªu thÃº â€“ Tuyáº¿t Giao!\nâ€œLÃ  do linh khÃ­ Huyáº¿t TÃ¢m HÃ n LiÃªn háº¥p dáº«n!â€ â€“ Diá»‡p Tháº§n kháº½ rÃ­t.\nTuyáº¿t Ká»³ rÃºt kiáº¿m, Ã¡nh sÃ¡ng báº¡c rá»±c lÃªn nhÆ° sáº¥m chá»›p giá»¯a Ä‘Ãªm tuyáº¿t. NhÆ° YÃªn vá»™i Ä‘áº·t Ä‘Ã n trÆ°á»›c máº·t, chuáº©n bá»‹ thá»§ cáº§m tráº­n.\nDiá»‡p Tháº§n nháº¯m máº¯t, thÃºc Ä‘áº©y linh lá»±c cÃ²n láº¡i â€“ nhÆ°ng khÃ­ máº¡ch chÆ°a thÃ´ng hoÃ n toÃ n, há»a áº¥n láº¡i báº¯t Ä‘áº§u rá»¥c rá»‹ch.\nBa ngÆ°á»i â€“ giá» Ä‘Ã¢y pháº£i cÃ¹ng chiáº¿n Ä‘áº¥u.\nKhÃ´ng pháº£i vÃ¬ thÃ¹, khÃ´ng vÃ¬ quÃ¡ khá»©. MÃ  vÃ¬\u0026hellip; táº¥t cáº£ Ä‘á»u Ä‘á»©ng trÆ°á»›c má»™t hiá»ƒm há»a chung.\nVÃ  Ä‘Ã³\u0026hellip; lÃ  bÆ°á»›c Ä‘áº§u tiÃªn, Ä‘Ã¡nh dáº¥u sá»± trá»Ÿ láº¡i cá»§a Diá»‡p Tháº§n, káº» mang trong mÃ¬nh má»™t pháº§n Ã½ chÃ­ cá»§a Ngoáº¡i Vá»±c â€“ nhÆ°ng láº¡i Ä‘á»©ng á»Ÿ láº±n ranh giá»¯a thÃ¡nh nhÃ¢n vÃ  ma chá»§ tÆ°Æ¡ng lai.\nChÆ°Æ¡ng 4 â€“ Tuyáº¿t Giao Chiáº¿n Tuyáº¿t váº«n khÃ´ng ngá»«ng rÆ¡i, nhÆ°ng khÃ´ng gian trong sÆ¡n Ä‘á»™ng lÃºc nÃ y láº¡i trá»Ÿ nÃªn ngá»™t ngáº¡t. Linh khÃ­ xung quanh Ä‘ang bá»‹ xÃ© rÃ¡ch bá»Ÿi má»™t luá»“ng sá»©c máº¡nh khá»§ng khiáº¿p, khÃ´ng pháº£i tá»« Ä‘áº¥t trá»i, mÃ  tá»« chÃ­nh trong Tuyáº¿t Giao â€“ má»™t yÃªu thÃº Ä‘Ã£ Ä‘áº¡t Ä‘áº¿n cáº£nh giá»›i Kim Äan, khÃ­ tá»©c máº¡nh máº½ nhÆ° cuá»“ng phong.\nTá»«ng bÆ°á»›c chÃ¢n cá»§a nÃ³ vang vá»ng, máº¡nh máº½ vÃ  cuá»“ng loáº¡n. ÄÃ´i máº¯t Ä‘á» nhÆ° mÃ¡u phÃ¡t ra nhá»¯ng tia sÃ¡ng sáº¯c láº¡nh, cáº·p sá»«ng cong Ä‘en nhÃ¡nh vÆ°Æ¡n cao nhÆ° mÅ©i kiáº¿m.\nâ€œCáº©n tháº­n.â€ â€“ Tuyáº¿t Ká»³ nÃ³i, máº¯t Ã¡nh lÃªn váº» nghiÃªm tÃºc.\nNhÆ° YÃªn gáº­t Ä‘áº§u, tay nÃ ng kÃ©o nháº¹ dÃ¢y Ä‘Ã n. Má»™t lÃ n sÃ³ng nháº¡c cáº§m dá»‹u dÃ ng nhÆ°ng áº©n chá»©a sá»©c máº¡nh mÃ£nh liá»‡t lan tá»a. NÃ³ táº¡o ra má»™t lá»›p vá» báº£o vá»‡ linh há»“n, ngÄƒn cháº·n nhá»¯ng sÃ³ng Ã¢m cÃ³ thá»ƒ xÃ¢m nháº­p vÃ o tÃ¢m trÃ­ ba ngÆ°á»i.\nDiá»‡p Tháº§n, Ä‘á»©ng giá»¯a, máº¯t chÃ ng váº«n chÆ°a hoÃ n toÃ n tá»‰nh tÃ¡o. Máº·c dÃ¹ linh khÃ­ Ä‘ang á»•n Ä‘á»‹nh hÆ¡n sau khi dÃ¹ng Huyáº¿t TÃ¢m HÃ n LiÃªn, nhÆ°ng há»a chÃº Ngoáº¡i Vá»±c trong cÆ¡ thá»ƒ váº«n khiáº¿n linh máº¡ch cá»§a chÃ ng khÃ´ng hoÃ n toÃ n thÃ´ng suá»‘t. Cáº£m giÃ¡c nhÆ° cÃ³ ngá»n lá»­a Ã¢m á»‰ trong cÆ¡ thá»ƒ, cá»© chÃ¡y mÃ£i, khÃ´ng dá»©t.\nTuyáº¿t Giao tiáº¿n láº¡i gáº§n, má»—i bÆ°á»›c Ä‘i giá»‘ng nhÆ° má»™t cÆ¡n sÃ³ng máº¡nh xÃ´ vÃ o bá». GiÃ³ máº¡nh máº½ xoÃ¡y vÃ o khÃ´ng khÃ­, khiáº¿n tuyáº¿t bay cuá»“n cuá»™n.\nDiá»‡p Tháº§n láº·ng láº½ Ä‘á»©ng Ä‘Ã³, Ä‘Ã´i máº¯t Ä‘á» nháº¡t nhÃ¬n chÄƒm chÃº vÃ o yÃªu thÃº. Máº·c dÃ¹ chÆ°a hoÃ n toÃ n cÃ³ Ä‘á»§ sá»©c máº¡nh, nhÆ°ng má»™t linh cáº£m ká»³ láº¡ dÃ¢ng lÃªn trong lÃ²ng háº¯n. ChÃ ng khÃ´ng thá»ƒ lÃ¹i bÆ°á»›c. ÄÃ¢y chÃ­nh lÃ  cuá»™c chiáº¿n Ä‘á»ƒ kháº³ng Ä‘á»‹nh láº¡i báº£n thÃ¢n, Ä‘á»ƒ khÃ´ng bá»‹ chi phá»‘i bá»Ÿi ngoáº¡i lá»±c.\nTuyáº¿t Ká»³ rÃºt kiáº¿m, thanh kiáº¿m báº¡c sÃ¡ng lÃªn nhÆ° Ã¡nh sÃ¡ng cá»§a trÄƒng ráº±m. NÃ ng lao vá» phÃ­a Tuyáº¿t Giao vá»›i tá»‘c Ä‘á»™ cá»±c nhanh, kiáº¿m phÃ¡p máº¡nh máº½ vÃ  sáº¯c bÃ©n, má»—i Ä‘Ã²n Ä‘á»u nháº±m vÃ o Ä‘iá»ƒm yáº¿u cá»§a yÃªu thÃº.\nNhÆ° YÃªn Ä‘á»©ng phÃ­a sau, tay cáº§m Ä‘Ã n, nÃ ng váº©y nháº¹ tá»«ng ngÃ³n tay, phÃ³ng ra tá»«ng Ä‘á»£t sÃ³ng Ã¢m cá»±c ká»³ uy lá»±c, cá»‘ gáº¯ng ngÄƒn cáº£n bÆ°á»›c Ä‘i cá»§a yÃªu thÃº, khiáº¿n nÃ³ loáº¡ng choáº¡ng. Tuy nhiÃªn, Tuyáº¿t Giao lÃ  má»™t sinh váº­t cá»±c ká»³ cÆ°á»ng Ä‘áº¡i. Nhá»¯ng Ä‘á»£t sÃ³ng Ã¢m cá»§a NhÆ° YÃªn chá»‰ khiáº¿n nÃ³ dao Ä‘á»™ng má»™t chÃºt, nhÆ°ng khÃ´ng há» lÃ m cháº­m bÆ°á»›c tiáº¿n cá»§a nÃ³.\nTuyáº¿t Ká»³ táº­n dá»¥ng cÆ¡ há»™i, lao vÃ o gáº§n hÆ¡n, thanh kiáº¿m chÃ©m tháº³ng vÃ o thÃ¢n thá»ƒ cá»§a yÃªu thÃº. NhÆ°ng Tuyáº¿t Giao pháº£n á»©ng nhanh chÃ³ng, vung cáº·p vuá»‘t sáº¯c nhá»n vá» phÃ­a nÃ ng.\nChá»‰ trong khoáº£nh kháº¯c, má»™t tia sÃ¡ng báº¡c chá»›p lÃªn. Tuyáº¿t Ká»³ Ä‘Ã£ nÃ© trÃ¡nh ká»‹p thá»i, nhÆ°ng cáº·p vuá»‘t cá»§a Tuyáº¿t Giao Ä‘Ã£ xÃ© rÃ¡ch má»™t máº£ng Ã¡o cá»§a nÃ ng, Ä‘á»ƒ lá»™ ra má»™t váº¿t thÆ°Æ¡ng nháº¹ trÃªn cÃ¡nh tay.\nâ€œCáº©n tháº­n!â€ â€“ NhÆ° YÃªn kÃªu lÃªn, nhÆ°ng Tuyáº¿t Ká»³ chá»‰ nháº¿ch mÃ´i, tiáº¿p tá»¥c lao vÃ o.\nDiá»‡p Tháº§n nhÃ¬n tháº¥y táº¥t cáº£. Trong phÃºt chá»‘c, linh lá»±c trong ngÆ°á»i chÃ ng nhÆ° bá»«ng tá»‰nh, nhÆ°ng láº¡i bá»‹ há»a chÃº Ä‘Ã¨ nÃ©n. ChÃ ng khÃ´ng thá»ƒ sá»­ dá»¥ng toÃ n bá»™ sá»©c máº¡nh.\nNhÆ°ng cÃ³ má»™t Ä‘iá»u ká»³ láº¡.\nNgay khi Ã¡nh máº¯t cá»§a Diá»‡p Tháº§n cháº¡m vÃ o Tuyáº¿t Giao, chÃ ng cáº£m nháº­n Ä‘Æ°á»£c má»™t luá»“ng khÃ­ Ã¢m hÃ n kÃ¬ láº¡ tá»« con yÃªu thÃº. ÄÃ³ lÃ  thá»© mÃ  chÃ ng chÆ°a tá»«ng gáº·p pháº£i trong suá»‘t quÃ¡ trÃ¬nh tu luyá»‡n.\nNgoáº¡i Vá»±c â€“ khÃ´ng pháº£i lÃ  má»™t tháº¿ giá»›i tÄ©nh láº·ng, mÃ  lÃ  má»™t cÆ¡n bÃ£o há»—n loáº¡n, Ä‘áº§y mÆ¡ há»“ vÃ  trÃ n Ä‘áº§y tÃ  khÃ­. Tuyáº¿t Giao\u0026hellip; cÃ³ má»™t sá»± liÃªn káº¿t ká»³ láº¡ vá»›i nguá»“n nÄƒng lÆ°á»£ng áº¥y.\nDiá»‡p Tháº§n rá»‘t cuá»™c cÅ©ng khÃ´ng thá»ƒ Ä‘á»©ng yÃªn. ChÃ ng váº­n dá»¥ng linh khÃ­ cÃ²n láº¡i, quyáº¿t Ä‘á»‹nh lÃ m má»™t viá»‡c mÃ  trÆ°á»›c giá» chÆ°a tá»«ng lÃ m.\nHáº¯n khÃ´ng trá»±c tiáº¿p táº¥n cÃ´ng. Thay vÃ o Ä‘Ã³, háº¯n káº¿t ná»‘i vá»›i linh khÃ­ cá»§a Tuyáº¿t Giao, xÃ¢m nháº­p vÃ o tiá»m thá»©c cá»§a nÃ³, dÃ¹ng má»™t pháº§n Ã½ chÃ­ cá»§a mÃ¬nh Ä‘á»ƒ khuáº¥t phá»¥c con thÃº hoang dÃ£ nÃ y.\nâ€œTuyáº¿t Giao!â€ â€“ Diá»‡p Tháº§n hÃ©t lÃªn. â€œNgÆ°Æ¡i khÃ´ng pháº£i lÃ  káº» thÃ¹ cá»§a chÃºng ta. Äá»«ng Ä‘á»ƒ nhá»¯ng kÃ½ á»©c cá»§a Ngoáº¡i Vá»±c lÃ m ngÆ°Æ¡i máº¥t Ä‘i báº£n tÃ­nh!â€\nMá»™t cÆ¡n sÃ³ng Ã¢m tá»« Diá»‡p Tháº§n vá»¡ ra, hÃ²a vÃ o khÃ´ng khÃ­, truyá»n tháº³ng vÃ o tÃ¢m trÃ­ Tuyáº¿t Giao. NhÆ°ng ngay láº­p tá»©c, má»™t luá»“ng pháº£n khÃ¡ng máº¡nh máº½ bÃ¹ng lÃªn tá»« con yÃªu thÃº, lÃ m cho khÃ´ng khÃ­ trong Ä‘á»™ng náº·ng ná» Ä‘áº¿n má»©c gáº§n nhÆ° ngháº¹t thá»Ÿ.\nTuyáº¿t Giao gáº§m lÃªn, lÆ°ng nÃ³ cong láº¡i nhÆ° má»™t cung tÃªn, sá»«ng Ä‘en quÃ©t qua khÃ´ng gian.\nNhÆ°ng rá»“i, má»™t tiáº¿ng cáº§m khÃºc vang lÃªn. NhÆ° YÃªn phÃ¡t ra má»™t Ä‘á»£t Ã¢m thanh máº¡nh máº½, khiáº¿n linh há»“n Tuyáº¿t Giao dao Ä‘á»™ng. Báº±ng Ã¢m thanh, nÃ ng Ä‘Ã£ káº¿t ná»‘i Ä‘Æ°á»£c vá»›i tÃ¢m há»“n cá»§a yÃªu thÃº, khiáº¿n nÃ³ táº¡m thá»i chá»¯ng láº¡i.\nLÃºc nÃ y, Tuyáº¿t Ká»³ nhanh chÃ³ng lao Ä‘áº¿n, kiáº¿m phÃ¡p chuáº©n xÃ¡c, chÃ©m má»™t Ä‘Ã²n chÃ­ máº¡ng vÃ o yáº¿u huyá»‡t cá»§a yÃªu thÃº.\nTuyáº¿t Giao gáº§m lÃªn má»™t tiáº¿ng Ä‘au Ä‘á»›n, thÃ¢n hÃ¬nh to lá»›n ngÃ£ gá»¥c xuá»‘ng, tuyáº¿t quanh ngÆ°á»i tan cháº£y, táº¡o thÃ nh nhá»¯ng vÅ©ng nÆ°á»›c láº¡nh giÃ¡.\nLÃºc nÃ y, ba ngÆ°á»i má»›i thá»Ÿ phÃ o nháº¹ nhÃµm, nhÆ°ng chÆ°a ká»‹p vui má»«ng, má»™t tiáº¿ng gáº§m thÃ©t vang lÃªn tá»« xa.\nDiá»‡p Tháº§n nhÃ¬n lÃªn, Ã¡nh máº¯t háº¯n sáº§m láº¡i. Má»™t tháº¿ lá»±c khá»§ng khiáº¿p khÃ¡c Ä‘ang Ä‘áº¿n gáº§n.\nÄÃ¢y má»›i chá»‰ lÃ  khá»Ÿi Ä‘áº§u.\nChÆ°Æ¡ng 5 â€“ Tháº¿ Lá»±c Bá»‹ XÃ© RÃ¡ch GiÃ³ bÃ£o cuá»‘n Ä‘áº¿n tá»« phÆ°Æ¡ng xa, nhá»¯ng Ä‘Ã¡m mÃ¢y Ä‘en ká»‹t nhÆ° bá»‘c chÃ¡y trÃªn báº§u trá»i cao, hÃ²a láº«n vá»›i lá»›p tuyáº¿t tráº¯ng, táº¡o nÃªn má»™t cáº£nh tÆ°á»£ng hÃ£i hÃ¹ng nhÆ° má»™t tháº¿ giá»›i bá»‹ xÃ© nÃ¡t.\nDiá»‡p Tháº§n, Tuyáº¿t Ká»³ vÃ  NhÆ° YÃªn Ä‘ang Ä‘á»©ng táº¡i trung tÃ¢m cá»§a tráº­n chiáº¿n vá»«a qua. Tuyáº¿t Giao, yÃªu thÃº Kim Äan, giá» Ä‘Ã£ gá»¥c xuá»‘ng, nhÆ°ng khÃ´ng pháº£i vÃ¬ hoÃ n toÃ n bá»‹ tiÃªu diá»‡t. NÃ³ váº«n cÃ²n hÆ¡i thá»Ÿ yáº¿u á»›t, thá»‰nh thoáº£ng phÃ¡t ra nhá»¯ng tiáº¿ng gáº§m tháº¥p tá»« trong cá»• há»ng.\nDiá»‡p Tháº§n cáº£m nháº­n rÃµ sá»± thay Ä‘á»•i trong khÃ´ng khÃ­. Má»™t luá»“ng khÃ­ u Ã¡m Ä‘en tá»‘i Ä‘ang ngÃ y cÃ ng tiáº¿n láº¡i gáº§n, nhÆ° cÃ³ thá»© gÃ¬ Ä‘Ã³ Ä‘ang xÃ© toáº¡c khÃ´ng gian.\nâ€œCÃ³ cáº£m giÃ¡c gÃ¬ khÃ´ng?â€ â€“ Tuyáº¿t Ká»³ nhÃ¬n Diá»‡p Tháº§n, há»i.\nChÃ ng nhÃ­u mÃ y, Ä‘Ã´i máº¯t Ä‘á» nháº¡t dáº§n Ã¡nh lÃªn sá»± chÃº Ã½.\nâ€œLinh khÃ­ xung quanhâ€¦ cÃ³ gÃ¬ Ä‘Ã³ khÃ´ng á»•n,â€ â€“ Diá»‡p Tháº§n nÃ³i, giá»ng nghiÃªm trá»ng. â€œCáº£m giÃ¡c nhÆ° cÃ³ ai Ä‘Ã³ Ä‘ang Ã©p khÃ´ng gian nÃ y váº·n váº¹o.â€\nNhÆ° YÃªn, Ä‘ang ngá»“i bÃªn cáº¡nh, Ä‘Æ°a tay lÃªn cáº£m nháº­n khÃ´ng khÃ­. â€œÄÃºng váº­y. Linh khÃ­ loáº¡n Ä‘á»™ng, nhÆ° cÃ³ má»™t khe há»Ÿ vÃ´ hÃ¬nh trong khÃ´ng gian.â€\nTuyáº¿t Ká»³ khÃ´ng nÃ³i gÃ¬, chá»‰ láº³ng láº·ng nhÃ¬n vá» phÃ­a chÃ¢n trá»i, nÆ¡i mÃ n tuyáº¿t dÃ y Ä‘áº·c Ä‘ang khÃ´ng ngá»«ng cuá»“n cuá»™n.\nÄá»™t nhiÃªn, má»™t tiáº¿ng gáº§m vang lÃªn, xÃ© tan sá»± tÄ©nh láº·ng.\nDiá»‡p Tháº§n giáº­t mÃ¬nh quay láº¡i. Tá»« trong mÃ n tuyáº¿t má» má»‹t, má»™t bÃ³ng Ä‘en khá»•ng lá»“ Ä‘ang lao tá»›i, phÃ¡t ra nhá»¯ng tiáº¿ng thÃ©t rÃ¹ng rá»£n. ÄÃ³ lÃ  má»™t con ThÃº Cá»• Tháº§n, Ä‘Ã£ lÃ¢u khÃ´ng xuáº¥t hiá»‡n trong sá»­ sÃ¡ch cá»§a tu tiÃªn giá»›i.\nNÃ³ cÃ³ thÃ¢n hÃ¬nh khá»•ng lá»“, bao phá»§ lá»›p lÃ´ng Ä‘en dÃ y, hai cáº·p máº¯t Ä‘á» rá»±c nhÆ° lá»­a. ÄÃ´i sá»«ng vÆ°Æ¡n dÃ i nhÆ° mÅ©i kiáº¿m, vÃ  má»—i bÆ°á»›c Ä‘i cá»§a nÃ³ khiáº¿n máº·t Ä‘áº¥t rung chuyá»ƒn.\nâ€œLÃ  ThÃº Cá»• Tháº§n â€“ sinh váº­t Ä‘Ã£ bá»‹ phong áº¥n trong nhá»¯ng ngá»n nÃºi cao hÃ ng nghÃ¬n nÄƒm!â€ â€“ NhÆ° YÃªn thá»‘t lÃªn.\nTuyáº¿t Ká»³ rÃºt thanh kiáº¿m báº¡c ra, Ã¡nh máº¯t láº¡nh lÃ¹ng. â€œNáº¿u nÃ³ Ä‘Ã£ Ä‘áº¿n Ä‘Ã¢yâ€¦ thÃ¬ cÃ³ thá»ƒ lÃ  dáº¥u hiá»‡u cho sá»± trá»—i dáº­y cá»§a má»™t tháº¿ lá»±c khÃ¡c.â€\nDiá»‡p Tháº§n Ä‘á»©ng vá»¯ng, tay náº¯m cháº·t, cáº£m nháº­n sá»©c máº¡nh Ã¢m á»‰ trong cÆ¡ thá»ƒ mÃ¬nh. DÃ¹ há»a chÃº Ngoáº¡i Vá»±c váº«n Ä‘Ã¨ nÃ©n linh lá»±c cá»§a háº¯n, nhÆ°ng chÃ ng biáº¿t, náº¿u Ä‘á»ƒ con ThÃº Cá»• Tháº§n nÃ y hoÃ nh hÃ nh, cáº£ Tuyáº¿t GiÃ¡c SÆ¡n sáº½ bá»‹ tÃ n phÃ¡.\nâ€œChÃºng ta khÃ´ng thá»ƒ Ä‘á»ƒ nÃ³ Ä‘áº¿n gáº§n khu vá»±c dÃ¢n cÆ°.â€ â€“ Tuyáº¿t Ká»³ nÃ³i. â€œDiá»‡p Tháº§n, dÃ¹ tháº¿ nÃ o, ngÆ°Æ¡i pháº£i giÃºp chÃºng ta ngÄƒn cháº·n nÃ³!â€\nDiá»‡p Tháº§n gáº­t Ä‘áº§u, máº¯t sÃ¡ng lÃªn má»™t tia sáº¯c bÃ©n.\nâ€œTa biáº¿t. ChÃºng ta pháº£i Ä‘Ã¡nh báº¡i nÃ³ trÆ°á»›c khi nÃ³ kÃªu gá»i thÃªm Ä‘á»“ng bá»n.â€\nThÃº Cá»• Tháº§n vung má»™t cÃ¡nh tay khá»•ng lá»“, táº¥n cÃ´ng vá» phÃ­a ba ngÆ°á»i, vÃ  khi nÃ³ vung tay, má»™t cÆ¡n sÃ³ng Ã¢m nhÆ° vá»¡ nÃ¡t khÃ´ng gian lao tá»›i, cuá»‘n theo má»™t Ä‘á»£t khÃ­ láº¡nh tÃª buá»‘t.\nNhÆ° YÃªn láº­p tá»©c phÃ³ng ra má»™t Ä‘á»£t sÃ³ng Ã¢m tá»« Ä‘Ã n ngá»c, nhÆ°ng Ä‘á»‘i vá»›i má»™t sinh váº­t máº¡nh máº½ nhÆ° ThÃº Cá»• Tháº§n, sÃ³ng Ã¢m áº¥y chá»‰ nhÆ° cÆ¡n giÃ³ nháº¹. NÃ³ khÃ´ng há» bá»‹ áº£nh hÆ°á»Ÿng.\nâ€œKiáº¿m phÃ¡p cá»§a ta!â€ â€“ Tuyáº¿t Ká»³ hÃ©t lÃªn, lao vá» phÃ­a ThÃº Cá»• Tháº§n, nhÆ°ng thanh kiáº¿m cá»§a nÃ ng chá»‰ cáº¯t má»™t vá»‡t sÃ¡ng loÃ¡ng trÆ°á»›c máº·t yÃªu thÃº, khÃ´ng thá»ƒ lÃ m tá»•n thÆ°Æ¡ng nÃ³.\nDiá»‡p Tháº§n, cáº£m nháº­n tháº¥y sá»± nguy hiá»ƒm ngÃ y cÃ ng tÄƒng, quyáº¿t Ä‘á»‹nh kÃ­ch hoáº¡t má»™t máº£nh linh lá»±c máº¡nh máº½ nháº¥t mÃ  chÃ ng cÃ³ thá»ƒ sá»­ dá»¥ng trong lÃºc nÃ y.\nHáº¯n khÃ´ng trá»±c tiáº¿p táº¥n cÃ´ng ThÃº Cá»• Tháº§n, mÃ  thay vÃ o Ä‘Ã³, háº¯n káº¿t ná»‘i linh há»“n cá»§a mÃ¬nh vá»›i Ngá»c TÃ¢m PhÃ¡p TÆ°á»ng â€“ má»™t phÃ¡p thuáº­t cá»• xÆ°a cÃ³ kháº£ nÄƒng Ä‘iá»u khiá»ƒn lá»±c lÆ°á»£ng há»§y diá»‡t.\nMá»™t dÃ²ng cháº£y nÄƒng lÆ°á»£ng khá»•ng lá»“ báº¯t Ä‘áº§u tá»« cÆ¡ thá»ƒ Diá»‡p Tháº§n, tá»a ra nhÆ° má»™t cÆ¡n lá»‘c. Tuy nhiÃªn, linh lá»±c cá»§a chÃ ng khÃ´ng Ä‘á»§ máº¡nh máº½ Ä‘á»ƒ Ä‘Ã¡nh báº¡i ThÃº Cá»• Tháº§n ngay láº­p tá»©c, chá»‰ cÃ³ thá»ƒ táº¡o ra má»™t táº¥m khiÃªn báº£o vá»‡ táº¡m thá»i.\nâ€œNgÆ°Æ¡i váº«n chÆ°a Ä‘á»§ sá»©c!â€ â€“ má»™t giá»ng nÃ³i láº¡nh lÃ¹ng vang lÃªn tá»« phÃ­a xa.\nÄÃ³ lÃ  giá»ng cá»§a má»™t ngÆ°á»i mÃ  Diá»‡p Tháº§n khÃ´ng bao giá» quÃªn: Ma TÃ´n.\nMá»™t bÃ³ng Ä‘en xuáº¥t hiá»‡n tá»« trong mÃ n tuyáº¿t, má»™t lÃ£o nhÃ¢n máº·c Ã¡o bÃ o Ä‘en vá»›i Ä‘Ã´i máº¯t Ä‘á» ngáº§u. LÃ£o ta bay Ä‘áº¿n gáº§n, vung tay lÃªn, táº¡o ra má»™t cÆ¡n cuá»“ng phong máº¡nh máº½.\nâ€œÄÃ¢y má»›i lÃ  sá»©c máº¡nh tháº­t sá»±!â€ â€“ Ma TÃ´n quÃ¡t lá»›n.\nLÃ£o vÆ°Æ¡n tay, khiáº¿n ThÃº Cá»• Tháº§n dá»«ng láº¡i. Má»™t luá»“ng khÃ­ tÃ  ma khá»•ng lá»“ tá»« tay lÃ£o báº¯n ra, cuá»‘n theo má»™t cÆ¡n sÃ³ng Ä‘en tá»‘i phá»§ lÃªn má»i thá»©.\nDiá»‡p Tháº§n cáº£m nháº­n Ä‘Æ°á»£c má»™t sá»©c máº¡nh khá»§ng khiáº¿p. ChÃ­nh lÃ  Ma TÃ´n â€“ ngÆ°á»i Ä‘á»©ng sau má»i tháº¿ lá»±c tÃ  Ã¡c trong tháº¿ giá»›i tu tiÃªn. Háº¯n Ä‘Ã£ quay láº¡i.\nâ€œLáº½ nÃ o ngÆ°Æ¡i Ä‘Ã£ khÃ´ng cháº¿t?â€ â€“ Diá»‡p Tháº§n rÃ­t lÃªn, cáº£m nháº­n sá»± láº¡nh láº½o trong lÃ²ng.\nâ€œCháº¿t? Ta Ä‘Ã£ trá»‘n thoÃ¡t khá»i cÃ¡i cháº¿t, vÃ  giá» Ä‘Ã¢y, ngÆ°Æ¡i sáº½ lÃ  cÃ´ng cá»¥ cho sá»± phá»¥c sinh cá»§a ta!â€ â€“ Ma TÃ´n cÆ°á»i láº¡nh, Ä‘Ã´i máº¯t Ä‘á» ngáº§u nhÃ¬n vÃ o Diá»‡p Tháº§n.\nTrong khoáº£nh kháº¯c, linh máº¡ch cá»§a Diá»‡p Tháº§n báº¯t Ä‘áº§u bá»‹ rÃºt kiá»‡t, nhÆ° cÃ³ má»™t sá»£i dÃ¢y vÃ´ hÃ¬nh siáº¿t cháº·t láº¥y trÃ¡i tim vÃ  linh há»“n cá»§a háº¯n.\nTuyáº¿t Ká»³ vÃ  NhÆ° YÃªn Ä‘á»©ng ngÃ¢y ngÆ°á»i, khÃ´ng ká»‹p pháº£n á»©ng.\nLÃ£o ta sáº½ khÃ´ng bao giá» buÃ´ng tha Diá»‡p Tháº§n.\nNhÆ°ng Diá»‡p Tháº§n, vá»›i má»™t tia quyáº¿t tÃ¢m trong Ã¡nh máº¯t, tháº§m nghÄ©:\nKhÃ´ng thá»ƒ thua.\nChÆ°Æ¡ng 6 â€“ Ma TÃ´n Äáº¡i Tháº¯ng KhÃ´ng khÃ­ nhÆ° Ä‘áº·c láº¡i, tÄ©nh má»‹ch nhÆ°ng láº¡i Ä‘áº§y cÄƒng tháº³ng. Má»™t luá»“ng tÃ  khÃ­ Ä‘en ká»‹t tá»« Ma TÃ´n phÃ³ng ra, bao trÃ¹m lÃªn táº¥t cáº£. Sá»©c máº¡nh tÃ  Ã¡c nhÆ° Ä‘ang Ã©p cháº·t má»i linh khÃ­ trong khÃ´ng gian, khiáº¿n ba ngÆ°á»i cáº£m tháº¥y ngháº¹t thá»Ÿ, khÃ³ khÄƒn trong viá»‡c duy trÃ¬ linh lá»±c.\nDiá»‡p Tháº§n cáº£m nháº­n rÃµ sá»± Ã¡p bá»©c tá»« Ma TÃ´n. CÃ¡i cáº£m giÃ¡c nÃ y, chÃ­nh lÃ  thá»© mÃ  háº¯n Ä‘Ã£ cháº¡y trá»‘n suá»‘t bao nÄƒm qua. Ma TÃ´n khÃ´ng chá»‰ lÃ  má»™t Ä‘á»‘i thá»§ máº¡nh máº½ vá» tu vi, mÃ  cÃ²n lÃ  má»™t káº» Ä‘iá»u khiá»ƒn bÃ³ng tá»‘i, thao tÃºng linh há»“n vÃ  tÃ¢m trÃ­ ngÆ°á»i khÃ¡c.\nâ€œNgÆ°Æ¡i khÃ´ng thá»ƒ tháº¯ng Ä‘Æ°á»£c ta.â€ â€“ Ma TÃ´n cÆ°á»i láº¡nh, bÆ°á»›c tá»«ng bÆ°á»›c vá» phÃ­a Diá»‡p Tháº§n. â€œLinh lá»±c cá»§a ngÆ°Æ¡i Ä‘Ã£ bá»‹ ta phong áº¥n. NgÆ°Æ¡i chá»‰ lÃ  má»™t con rá»‘i mÃ  ta Ä‘iá»u khiá»ƒn.â€\nDiá»‡p Tháº§n khÃ´ng tráº£ lá»i, chá»‰ náº¯m cháº·t tay, cáº£m nháº­n sá»± Ä‘au Ä‘á»›n tá»« há»a chÃº Ngoáº¡i Vá»±c váº«n Ä‘ang xÃ¢m chiáº¿m thÃ¢n thá»ƒ. NhÆ°ng trong lÃºc tuyá»‡t vá»ng nháº¥t, háº¯n cÅ©ng cáº£m nháº­n Ä‘Æ°á»£c má»™t Ä‘iá»u.\nSá»©c máº¡nh trong báº£n thÃ¢n mÃ¬nh váº«n chÆ°a hoÃ n toÃ n máº¥t Ä‘i.\nChÃ ng táº­p trung vÃ o nhá»¯ng gÃ¬ cÃ²n sÃ³t láº¡i trong cÆ¡ thá»ƒ, Ã©p linh lá»±c tá»‰nh dáº­y. Tá»«ng tia sÃ¡ng, tá»«ng sá»£i linh khÃ­ báº¯t Ä‘áº§u cuá»™n trÃ o trong cÆ¡ thá»ƒ, máº·c cho Ma TÃ´n Ä‘ang cá»‘ gáº¯ng kiá»m hÃ£m.\nNhÆ°ng, khÃ´ng pháº£i táº¥t cáº£ sá»©c máº¡nh Ä‘á»u náº±m trong cÆ¡ thá»ƒ Diá»‡p Tháº§n. ChÃ ng biáº¿t, sá»± thay Ä‘á»•i nÃ y lÃ  tá»« Ngoáº¡i Vá»±c â€“ chÃ­nh lÃ  sá»± káº¿t ná»‘i mÃ  Ma TÃ´n Ä‘Ã£ khÆ¡i dáº­y, vÃ  giá» Ä‘Ã¢y, Diá»‡p Tháº§n pháº£i tÃ¬m cÃ¡ch táº­n dá»¥ng chÃ­nh sá»©c máº¡nh Ä‘Ã³ Ä‘á»ƒ chiáº¿n tháº¯ng.\nâ€œNgÆ°Æ¡i sáº½ khÃ´ng bao giá» tháº¯ng!â€ â€“ Ma TÃ´n láº¡i quÃ¡t lá»›n, tay vung lÃªn, má»™t luá»“ng ma khÃ­ Ä‘en Ä‘áº·c phÃ³ng tháº³ng vÃ o Diá»‡p Tháº§n.\nCáº£ ba ngÆ°á»i â€“ Tuyáº¿t Ká»³, NhÆ° YÃªn vÃ  Diá»‡p Tháº§n â€“ Ä‘á»u láº­p tá»©c bá»‹ bao phá»§ trong má»™t cÆ¡n sÃ³ng Ä‘en tá»‘i. Linh há»“n cá»§a há» dÆ°á»ng nhÆ° bá»‹ xÃ© nÃ¡t dÆ°á»›i Ã¡p lá»±c khá»§ng khiáº¿p.\nNhÆ°ng Diá»‡p Tháº§n, máº·c cho sá»± Ä‘au Ä‘á»›n tháº¥u xÆ°Æ¡ng, váº«n khÃ´ng khuáº¥t phá»¥c. Háº¯n Ä‘Æ°a tay ra, khÃ´ng pháº£i Ä‘á»ƒ cháº·n láº¡i, mÃ  Ä‘á»ƒ hÃºt vÃ o trong mÃ¬nh táº¥t cáº£ nhá»¯ng gÃ¬ Ma TÃ´n Ä‘ang phÃ³ng ra.\nâ€œNgÆ°Æ¡i khÃ´ng thá»ƒ lÃ m Ä‘Æ°á»£c Ä‘Ã¢u!â€ â€“ Ma TÃ´n nghiáº¿n rÄƒng, máº¯t Ä‘á» ngáº§u nhÆ° mÃ¡u, trá»«ng máº¯t nhÃ¬n Diá»‡p Tháº§n. â€œKhÃ´ng thá»ƒ chá»‘ng láº¡i Ä‘Æ°á»£c sá»©c máº¡nh cá»§a ta!â€\nNhÆ°ng Diá»‡p Tháº§n khÃ´ng Ä‘Ã¡p láº¡i. Háº¯n cáº£m nháº­n tháº¥y má»™t tia sÃ¡ng má»ng manh tá»« trong bÃ³ng tá»‘i. CÃ¡i bÃ³ng tá»‘i áº¥y, chÃ­nh lÃ  má»™t pháº§n trong mÃ¬nh.\nHáº¯n báº¯t Ä‘áº§u xÃ© rÃ¡ch sá»©c máº¡nh tÃ  ma cá»§a Ma TÃ´n, Ä‘iá»u khiá»ƒn linh lá»±c Ä‘á»ƒ quay láº¡i vÃ  pháº£n cÃ´ng. Má»™t tia sÃ¡ng Ä‘á» bÃ¹ng lÃªn tá»« trong cÆ¡ thá»ƒ Diá»‡p Tháº§n, nhÆ° má»™t ngá»n lá»­a diá»…m lá»‡ trong Ä‘Ãªm tá»‘i.\nChá»‰ trong khoáº£nh kháº¯c, Ma TÃ´n cáº£m tháº¥y sá»± cháº¥n Ä‘á»™ng máº¡nh máº½ tá»« Diá»‡p Tháº§n, nhÆ° cÃ³ má»™t cÆ¡n sÃ³ng tháº§n tá»« trong ngÆ°á»i háº¯n trÃ o ra, cuá»‘n phÄƒng táº¥t cáº£ nhá»¯ng gÃ¬ Ma TÃ´n vá»«a tung ra.\nâ€œCÃ¡i gÃ¬?â€ â€“ Ma TÃ´n kÃªu lÃªn Ä‘áº§y báº¥t ngá», nhÃ¬n tháº¥y má»™t lÆ°á»£ng nÄƒng lÆ°á»£ng mÃ  háº¯n khÃ´ng ngá» tá»›i. ÄÃ´i máº¯t lÃ£o ta má»Ÿ to, kinh ngáº¡c trÆ°á»›c sá»± thay Ä‘á»•i trong Diá»‡p Tháº§n.\nNhÆ°ng rá»“i, Diá»‡p Tháº§n khÃ´ng dá»«ng láº¡i. Háº¯n cháº¥n Ä‘á»™ng lá»±c lÆ°á»£ng cá»§a Ngoáº¡i Vá»±c trong cÆ¡ thá»ƒ mÃ¬nh, váº­n dá»¥ng nÃ³ Ä‘á»ƒ táº¡o thÃ nh má»™t tháº¿ tráº­n linh há»“n máº¡nh máº½, khiáº¿n cho Ma TÃ´n pháº£i lÃ¹i láº¡i má»™t bÆ°á»›c.\nTuyáº¿t Ká»³ vÃ  NhÆ° YÃªn, chá»©ng kiáº¿n sá»©c máº¡nh nÃ y, khÃ´ng dÃ¡m tin vÃ o máº¯t mÃ¬nh.\nâ€œDiá»‡p Tháº§n\u0026hellip; lÃ m sao cÃ³ thá»ƒ?â€ â€“ Tuyáº¿t Ká»³ thÃ¬ tháº§m.\nâ€œÄÃ³ lÃ \u0026hellip; sá»©c máº¡nh tá»« Ngoáº¡i Vá»±c,â€ â€“ NhÆ° YÃªn mÃ­m mÃ´i, rá»“i quay sang Tuyáº¿t Ká»³. â€œDiá»‡p Tháº§n Ä‘Ã£ tÃ¬m cÃ¡ch Ä‘iá»u khiá»ƒn nÃ³!â€\nNhÆ°ng Ma TÃ´n khÃ´ng pháº£i káº» dá»… dÃ ng bá»‹ Ä‘Ã¡nh báº¡i. LÃ£o ta thÃ©t lÃªn, Ä‘Ã´i máº¯t Ä‘áº§y thÃ¹ háº­n, bÃ n tay vung lÃªn, vÃ  má»™t hÃ o quang Ä‘en xuáº¥t hiá»‡n, bao phá»§ láº¥y táº¥t cáº£.\nâ€œKhÃ´ng thá»ƒ nÃ o\u0026hellip;â€ â€“ Ma TÃ´n cÆ°á»i kháº©y. â€œNgÆ°Æ¡i chá»‰ lÃ  má»™t con cá». KhÃ´ng thá»ƒ vÆ°á»£t qua Ä‘Æ°á»£c sá»©c máº¡nh cá»§a ta!â€\nCÆ¡n cuá»“ng phong Ä‘en tá»‘i tá»« bÃ n tay Ma TÃ´n báº¯t Ä‘áº§u bao trÃ¹m, nhÆ°ng Diá»‡p Tháº§n khÃ´ng lÃ¹i bÆ°á»›c. Háº¯n náº¯m cháº·t tay, má»™t láº§n ná»¯a váº­n sá»©c máº¡nh Ngoáº¡i Vá»±c.\n\u0026ldquo;Tháº§n Há»a!\u0026rdquo;\nLá»­a Ä‘á» bÃ¹ng lÃªn, bao trÃ¹m láº¥y thÃ¢n thá»ƒ Ma TÃ´n. Sá»©c máº¡nh há»§y diá»‡t cá»§a Ngoáº¡i Vá»±c bÃ¹ng phÃ¡t máº¡nh máº½, nhÆ° má»™t tráº­n cuá»“ng phong thá»•i bay má»i thá»©. Ma TÃ´n chá»‰ ká»‹p hÃ©t lÃªn má»™t tiáº¿ng tháº£m thiáº¿t, nhÆ°ng rá»“i hÃ¬nh bÃ³ng lÃ£o ta bá»‹ ngá»n lá»­a áº¥y nuá»‘t chá»­ng.\nMá»™t tiáº¿ng ná»• lá»›n vang lÃªn.\nCáº£ khÃ´ng gian sá»¥p Ä‘á»•, nhÆ° vá»¡ nÃ¡t dÆ°á»›i sá»©c máº¡nh cá»§a Diá»‡p Tháº§n. Ma TÃ´n, ngÆ°á»i Ä‘Ã£ gieo ráº¯c bao nhiÃªu tá»™i Ã¡c, giá» Ä‘Ã£ bá»‹ há»§y diá»‡t hoÃ n toÃ n.\nNhÆ°ng khÃ´ng pháº£i táº¥t cáº£ Ä‘á»u yÃªn á»•n. Nhá»¯ng tia sÃ¡ng tá»« vá»¥ ná»• báº¯t Ä‘áº§u ná»Ÿ ra thÃ nh nhá»¯ng lá»— há»•ng khÃ´ng gian, lÃ m cho linh khÃ­ cÃ ng thÃªm rá»‘i loáº¡n.\nâ€œÄÃ¢y khÃ´ng pháº£i lÃ  káº¿t thÃºc.â€ â€“ Diá»‡p Tháº§n thá»Ÿ dÃ i, má»‡t má»i, nhÆ°ng Ã¡nh máº¯t váº«n sÃ¡ng rá»±c lÃªn. â€œChÃºng ta má»›i chá»‰ Ä‘á»‘i máº·t vá»›i nhá»¯ng gÃ¬ cÃ²n sÃ³t láº¡i cá»§a Ma TÃ´n.â€\nNhÆ° YÃªn vÃ  Tuyáº¿t Ká»³ nhÃ¬n nhau, cáº£ hai Ä‘á»u biáº¿t ráº±ng cuá»™c chiáº¿n má»›i chá»‰ báº¯t Ä‘áº§u.\nChÆ°Æ¡ng 7 â€“ Lá»— Há»•ng KhÃ´ng Gian Váº¿t ná»©t khÃ´ng gian khÃ´ng ngá»«ng lan rá»™ng ra tá»« trung tÃ¢m tráº­n chiáº¿n, nÆ¡i Diá»‡p Tháº§n vá»«a Ä‘Ã¡nh báº¡i Ma TÃ´n. Cáº£ ba ngÆ°á»i Ä‘á»©ng báº¥t Ä‘á»™ng, nhÃ¬n nhá»¯ng váº¿t ná»©t má»ng manh nhÆ° tÆ¡ vÃ ng lan tá»a trong khÃ´ng khÃ­, táº¡o thÃ nh má»™t máº¡ng lÆ°á»›i ká»³ láº¡, u Ã¡m.\nMáº·t Ä‘áº¥t dÆ°á»›i chÃ¢n há» ráº¡n ná»©t, vÃ  tá»«ng Ä‘á»£t sÃ³ng nÄƒng lÆ°á»£ng tá»« nhá»¯ng váº¿t ná»©t áº¥y xÃ´ng vÃ o khÃ´ng gian, nhÆ° muá»‘n xÃ© toáº¡c linh khÃ­ Ä‘ang duy trÃ¬ sá»± cÃ¢n báº±ng trong tháº¿ giá»›i nÃ y.\nDiá»‡p Tháº§n náº¯m cháº·t tay, cáº£m nháº­n Ä‘Æ°á»£c sá»± chuyá»ƒn Ä‘á»™ng báº¥t thÆ°á»ng trong khÃ´ng gian. â€œKhÃ´ng á»•n. Nhá»¯ng lá»— há»•ng nÃ y cÃ³ thá»ƒ phÃ¡ vá»¡ khÃ´ng chá»‰ cÆ¡ thá»ƒ chÃºng ta mÃ  cÃ²n lÃ m vá»¡ Ä‘i cáº£ linh máº¡ch cá»§a tháº¿ giá»›i nÃ y.â€\nTuyáº¿t Ká»³ Ä‘á»©ng gáº§n bÃªn, Ã¡nh máº¯t nghiÃªm nghá»‹. â€œÄÃ¢y lÃ  háº­u quáº£ cá»§a sá»± can thiá»‡p cá»§a Ma TÃ´n vÃ o khÃ´ng gian. Nhá»¯ng lá»— há»•ng nÃ y khÃ´ng thá»ƒ cá»© Ä‘á»ƒ tá»“n táº¡i. ChÃºng sáº½ kÃ©o theo nhá»¯ng cÆ¡n cuá»“ng phong, tháº­m chÃ­ lÃ  nhá»¯ng tháº¿ lá»±c tá»« Ngoáº¡i Vá»±c.â€\nNhÆ° YÃªn cÃºi Ä‘áº§u, nháº¹ nhÃ ng láº©m báº©m: â€œNgoáº¡i Vá»±câ€¦ nhá»¯ng gÃ¬ ta Ä‘Ã£ nghe tá»« tá»• tiÃªn. Nhá»¯ng váº¿t ná»©t nÃ y chÃ­nh lÃ  dáº¥u hiá»‡u cá»§a sá»± xÃ¢m lÆ°á»£c tá»« nÆ¡i Ä‘Ã³.â€\nDiá»‡p Tháº§n nhÃ¬n vá» phÃ­a nhá»¯ng váº¿t ná»©t, rá»“i quay láº¡i nhÃ¬n hai ngÆ°á»i báº¡n. â€œChÃºng ta khÃ´ng thá»ƒ Ä‘á»ƒ nhá»¯ng lá»— há»•ng nÃ y tá»“n táº¡i. KhÃ´ng gian nÃ y Ä‘ang bá»‹ ráº¡n ná»©t, vÃ  chá»‰ cÃ³ chÃºng ta má»›i cÃ³ thá»ƒ ngÄƒn cháº·n nÃ³.â€\nTuyáº¿t Ká»³ rÃºt thanh kiáº¿m báº¡c tá»« bÃªn hÃ´ng, Ã¡nh sÃ¡ng tá»« thanh kiáº¿m pháº£n chiáº¿u lÃªn gÆ°Æ¡ng máº·t nÃ ng, trÃ´ng kiÃªn Ä‘á»‹nh vÃ  láº¡nh lÃ¹ng. â€œChÃºng ta sáº½ pháº£i Ä‘Ã³ng cÃ¡c lá»— há»•ng láº¡i, báº±ng cÃ¡ch nÃ o Ä‘Ã³. NhÆ°ng lÃ m tháº¿ nÃ o, chÃºng ta khÃ´ng thá»ƒ biáº¿t chÃ­nh xÃ¡c.â€\nNhÆ° YÃªn nhÃ¬n vá» nhá»¯ng váº¿t ná»©t khÃ´ng gian, Ä‘Ã´i máº¯t nÃ ng toÃ¡t lÃªn váº» lo Ã¢u. â€œTá»• tiÃªn ta Ä‘Ã£ tá»«ng nÃ³i vá» má»™t cÃ¡nh cá»­a vÃ´ hÃ¬nh, nÆ¡i mÃ  linh khÃ­ tá»« tháº¿ giá»›i nÃ y cÃ³ thá»ƒ khÃ©p láº¡i cÃ¡c váº¿t ná»©t. NhÆ°ng cÃ¡nh cá»­a áº¥yâ€¦ Ä‘Ã£ bá»‹ phong áº¥n tá»« lÃ¢u.â€\nDiá»‡p Tháº§n náº¯m cháº·t tay, máº¯t sÃ¡ng rá»±c. â€œPhong áº¥n cÃ³ thá»ƒ bá»‹ phÃ¡ vá»¡. Má»—i váº¿t ná»©t nÃ y Ä‘á»u mang má»™t nguá»“n sá»©c máº¡nh tá»« Ngoáº¡i Vá»±c, vÃ  cÃ³ thá»ƒ, chá»‰ cÃ³ cÃ¡ch sá»­ dá»¥ng linh lá»±c tá»« cáº£ ba chÃºng ta má»›i cÃ³ thá»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u Ä‘Ã³.â€\nTuyáº¿t Ká»³ vÃ  NhÆ° YÃªn Ä‘á»u gáº­t Ä‘áº§u. Cáº£ ba ngÆ°á»i Ä‘á»u nháº­n ra ráº±ng Ä‘Ã¢y khÃ´ng pháº£i lÃ  má»™t nhiá»‡m vá»¥ dá»… dÃ ng. Má»—i lá»— há»•ng trong khÃ´ng gian nÃ y khÃ´ng chá»‰ Ä‘e dá»a sá»± á»•n Ä‘á»‹nh cá»§a tháº¿ giá»›i mÃ  cÃ²n cÃ³ thá»ƒ lÃ  dáº¥u hiá»‡u cho sá»± trá»—i dáº­y cá»§a má»™t tháº¿ lá»±c hÃ¹ng máº¡nh, tá»«ng bá»‹ phong áº¥n tá»« ráº¥t lÃ¢u.\nâ€œChÃºng ta khÃ´ng thá»ƒ cháº§n chá»«. Má»—i phÃºt giÃ¢y trÃ´i qua Ä‘á»u cÃ³ thá»ƒ lÃ  lÃºc tháº¿ giá»›i nÃ y bá»‹ xÃ© nÃ¡t.â€ â€“ Diá»‡p Tháº§n nÃ³i, giá»ng quyáº¿t Ä‘oÃ¡n.\nBa ngÆ°á»i báº¯t Ä‘áº§u táº­p trung, má»—i ngÆ°á»i má»™t hÆ°á»›ng, cá»‘ gáº¯ng cáº£m nháº­n vÃ  thu tháº­p nÄƒng lÆ°á»£ng tá»« nhá»¯ng lá»— há»•ng Ä‘ang lan ra.\nTuyáº¿t Ká»³, vá»›i thanh kiáº¿m báº¡c, báº¯t Ä‘áº§u váº½ lÃªn nhá»¯ng kÃ½ tá»± tu tiÃªn trong khÃ´ng gian, cá»‘ gáº¯ng táº¡o ra má»™t lÃ¡ cháº¯n linh lá»±c báº£o vá»‡. Tuy nhiÃªn, má»—i kÃ½ tá»± nÃ ng váº½ ra láº¡i bá»‹ tÃ n phÃ¡ bá»Ÿi sá»± khuáº¥y Ä‘á»™ng cá»§a nhá»¯ng váº¿t ná»©t khÃ´ng gian, khiáº¿n nÃ ng pháº£i táº­p trung cao Ä‘á»™.\nNhÆ° YÃªn, Ä‘á»©ng bÃªn cáº¡nh, sá»­ dá»¥ng Ä‘Ã n ngá»c cá»§a mÃ¬nh Ä‘á»ƒ phÃ³ng ra nhá»¯ng Ã¢m thanh thanh thoÃ¡t, nhá»¯ng giai Ä‘iá»‡u dá»‹u dÃ ng nhÆ°ng Ä‘áº§y máº¡nh máº½, táº¡o ra sÃ³ng Ã¢m chá»‘ng láº¡i sá»± rá»‘i loáº¡n cá»§a linh khÃ­. Má»—i tiáº¿ng Ä‘Ã n nÃ ng phÃ¡t ra lÃ  má»™t ná»— lá»±c Ä‘á»ƒ lÃ m dá»‹u sá»± xung Ä‘á»™t trong khÃ´ng gian, nhÆ°ng nÃ³ chá»‰ cÃ³ thá»ƒ ngá»«ng Ä‘Æ°á»£c má»™t pháº§n nhá» trong dÃ²ng cháº£y nÄƒng lÆ°á»£ng há»§y diá»‡t.\nDiá»‡p Tháº§n Ä‘á»©ng giá»¯a, cáº£m nháº­n vÃ  truyá»n linh lá»±c cá»§a mÃ¬nh vÃ o nhá»¯ng váº¿t ná»©t, Ä‘á»“ng thá»i kÃ­ch hoáº¡t Ngoáº¡i Vá»±c Ä‘á»ƒ Ä‘á»‘i khÃ¡ng láº¡i sá»± can thiá»‡p cá»§a cÃ¡c tháº¿ lá»±c tá»« bÃªn ngoÃ i. NhÆ°ng sá»©c máº¡nh cá»§a Ngoáº¡i Vá»±c Ä‘ang Ã©p cháº·t linh há»“n cá»§a háº¯n, khiáº¿n cÆ¡ thá»ƒ Diá»‡p Tháº§n cáº£m tháº¥y Ä‘au Ä‘á»›n vÃ´ cÃ¹ng.\nMá»—i lá»— há»•ng khÃ´ng gian má»Ÿ rá»™ng thÃªm má»™t chÃºt, vÃ  tá»« trong Ä‘Ã³, nhá»¯ng sinh váº­t ká»³ láº¡ báº¯t Ä‘áº§u xuáº¥t hiá»‡n. Nhá»¯ng bÃ³ng ma váº·n váº¹o, nhá»¯ng tinh linh quÃ¡i dá»‹ tá»« Ngoáº¡i Vá»±c báº¯t Ä‘áº§u trÃ n vÃ o, mang theo nhá»¯ng cÆ¡n sÃ³ng Ä‘en cá»§a nÄƒng lÆ°á»£ng tÃ  Ã¡c.\nâ€œChÃºng ta khÃ´ng thá»ƒ kÃ©o dÃ i lÃ¢u hÆ¡n!â€ â€“ Diá»‡p Tháº§n gáº§m lÃªn, máº¯t Ä‘á» ngáº§u vÃ¬ sá»± Ä‘au Ä‘á»›n tá»« linh lá»±c cá»§a háº¯n.\nBÃªn cáº¡nh Ä‘Ã³, Tuyáº¿t Ká»³ vÃ  NhÆ° YÃªn cÅ©ng khÃ´ng thá»ƒ giá»¯ ná»•i sá»©c máº¡nh cá»§a mÃ¬nh lÃ¢u. Há» nhÃ¬n nhau, biáº¿t ráº±ng náº¿u khÃ´ng lÃ m gÃ¬ Ä‘Ã³ ngay láº­p tá»©c, cáº£ tháº¿ giá»›i sáº½ bá»‹ xÃ© rÃ¡ch.\nâ€œÄiá»u gÃ¬ Ä‘Ã£ xáº£y ra vá»›i cÃ¡nh cá»­a phong áº¥n?â€ â€“ Tuyáº¿t Ká»³ há»i, giá»ng Ä‘áº§y lo láº¯ng.\nNhÆ° YÃªn nhÃ¬n vá» phÃ­a Diá»‡p Tháº§n, rá»“i nháº¹ nhÃ ng nÃ³i: â€œTa biáº¿t nÆ¡i cÃ¡nh cá»­a phong áº¥n náº±m. NhÆ°ng chá»‰ cÃ³ má»™t trong chÃºng ta cÃ³ thá»ƒ bÆ°á»›c vÃ o. Náº¿u khÃ´ng, chÃºng ta sáº½ bá»‹ kÃ©o vÃ o Ngoáº¡i Vá»±c.â€\nDiá»‡p Tháº§n quay sang NhÆ° YÃªn, Ã¡nh máº¯t Ä‘áº§y kiÃªn quyáº¿t. â€œVáº­y ta sáº½ Ä‘i. ÄÃ¢y lÃ  trÃ¡ch nhiá»‡m cá»§a ta.â€\nNhÆ°ng NhÆ° YÃªn láº¯c Ä‘áº§u. â€œKhÃ´ng. NgÆ°Æ¡i Ä‘Ã£ chá»‹u quÃ¡ nhiá»u Ä‘au Ä‘á»›n tá»« Ngoáº¡i Vá»±c. Ta sáº½ Ä‘i, vÃ  ngÆ°Æ¡i pháº£i á»Ÿ láº¡i Ä‘á»ƒ báº£o vá»‡ tháº¿ giá»›i nÃ y.â€\nDiá»‡p Tháº§n nhÃ¬n vÃ o máº¯t NhÆ° YÃªn, Ã¡nh máº¯t Ä‘áº§y cáº£m kÃ­ch. Cáº£ ba ngÆ°á»i Ä‘á»u hiá»ƒu ráº±ng Ä‘Ã¢y lÃ  má»™t quyáº¿t Ä‘á»‹nh quan trá»ng, khÃ´ng thá»ƒ quay láº¡i. NhÆ°ng náº¿u há» khÃ´ng hÃ nh Ä‘á»™ng ngay lÃºc nÃ y, tháº¿ giá»›i nÃ y sáº½ pháº£i Ä‘á»‘i máº·t vá»›i má»™t tháº£m há»a khá»§ng khiáº¿p.\nğŸ’  Háº¿t chÆ°Æ¡ng 7\nChÆ°Æ¡ng 8: CÃ¡nh Cá»­a Phong áº¤n khi NhÆ° YÃªn bÆ°á»›c vÃ o cÃ¡nh cá»­a vÃ  pháº£i Ä‘á»‘i máº·t vá»›i thá»­ thÃ¡ch, hay báº¡n muá»‘n Diá»‡p Tháº§n vÃ  Tuyáº¿t Ká»³ sáº½ pháº£i tÃ¬m cÃ¡ch ngÄƒn cháº·n nhá»¯ng sinh váº­t Ngoáº¡i Vá»±c?\nHáº¿t rá»“i, cÃ¡c báº¡n cÃ³ há»©ng Ä‘á»c thÃ¬ comment hoáº·c gá»­i email Ä‘á»ƒ mÃ¬nh post thÃªm nhÃ©.\nCáº£m Æ¡n báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\n","date":"Apr 20, 2025","img":"https://unsplash.it/1920/1080?image=231","permalink":"/blog/2025-04-20-ai-viet-truyen-tuyet-giac-truc-lam/","series":null,"tags":["story"],"title":"Tuyáº¿t GiÃ¡c TrÃºc LÃ¢m - Truyá»‡n AI"},{"categories":null,"content":" CÃ¢n báº±ng Nash: KhÃ¡i niá»‡m vÃ  á»©ng dá»¥ng á»¨ng dá»¥ng chia thÆ°á»Ÿng cho nhÃ¢n viÃªn CÃ¢n báº±ng Nash: KhÃ¡i niá»‡m vÃ  á»©ng dá»¥ng 1. CÃ¢n báº±ng Nash lÃ  gÃ¬? CÃ¢n báº±ng Nash (Nash Equilibrium) lÃ  má»™t khÃ¡i niá»‡m trong lÃ½ thuyáº¿t trÃ² chÆ¡i (game theory), Ä‘Æ°á»£c Ä‘áº·t theo tÃªn cá»§a nhÃ  toÃ¡n há»c John Nash, ngÆ°á»i Ä‘Ã£ chá»©ng minh sá»± tá»“n táº¡i cá»§a cÃ¢n báº±ng nÃ y trong cÃ¡c trÃ² chÆ¡i khÃ´ng há»£p tÃ¡c (non-cooperative games). CÃ¢n báº±ng Nash mÃ´ táº£ má»™t tráº¡ng thÃ¡i mÃ  má»—i ngÆ°á»i chÆ¡i trong trÃ² chÆ¡i Ä‘á»u chá»n chiáº¿n lÆ°á»£c tá»‘i Æ°u nháº¥t cho mÃ¬nh, dá»±a trÃªn giáº£ Ä‘á»‹nh ráº±ng cÃ¡c Ä‘á»‘i thá»§ sáº½ khÃ´ng thay Ä‘á»•i chiáº¿n lÆ°á»£c cá»§a há».\nÄá»‹nh nghÄ©a chÃ­nh xÃ¡c: Má»™t táº­p há»£p cÃ¡c chiáº¿n lÆ°á»£c cá»§a táº¥t cáº£ ngÆ°á»i chÆ¡i Ä‘Æ°á»£c gá»i lÃ  cÃ¢n báº±ng Nash náº¿u khÃ´ng cÃ³ báº¥t ká»³ ngÆ°á»i chÆ¡i nÃ o cÃ³ thá»ƒ cáº£i thiá»‡n káº¿t quáº£ cá»§a mÃ¬nh báº±ng cÃ¡ch Ä‘Æ¡n phÆ°Æ¡ng thay Ä‘á»•i chiáº¿n lÆ°á»£c cá»§a riÃªng mÃ¬nh. 2. Äáº·c Ä‘iá»ƒm cá»§a cÃ¢n báº±ng Nash TÃ­nh á»•n Ä‘á»‹nh: Trong tráº¡ng thÃ¡i cÃ¢n báº±ng Nash, khÃ´ng ai cÃ³ Ä‘á»™ng lá»±c Ä‘á»ƒ thay Ä‘á»•i hÃ nh vi cá»§a mÃ¬nh vÃ¬ há» Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c lá»£i Ã­ch tá»‘t nháº¥t cÃ³ thá»ƒ. KhÃ´ng pháº£i luÃ´n tá»‘i Æ°u Pareto: CÃ¢n báº±ng Nash khÃ´ng nháº¥t thiáº¿t pháº£i lÃ  giáº£i phÃ¡p tá»‘t nháº¥t cho táº¥t cáº£ má»i ngÆ°á»i. ÄÃ´i khi, nÃ³ cÃ³ thá»ƒ dáº«n Ä‘áº¿n \u0026ldquo;káº¿t cá»¥c bi ká»‹ch\u0026rdquo; (tragedy of the commons) hoáº·c \u0026ldquo;hiá»‡u á»©ng tÃ¹ nhÃ¢n\u0026rdquo; (Prisoner\u0026rsquo;s Dilemma). Sá»± tá»“n táº¡i: Theo Ä‘á»‹nh lÃ½ cá»§a Nash, má»i trÃ² chÆ¡i há»¯u háº¡n vá»›i sá»‘ lÆ°á»£ng ngÆ°á»i chÆ¡i vÃ  chiáº¿n lÆ°á»£c há»¯u háº¡n Ä‘á»u cÃ³ Ã­t nháº¥t má»™t cÃ¢n báº±ng Nash (cÃ³ thá»ƒ á»Ÿ dáº¡ng há»—n há»£p, tá»©c lÃ  sá»­ dá»¥ng chiáº¿n lÆ°á»£c ngáº«u nhiÃªn). 3. VÃ­ dá»¥ vá» cÃ¢n báº±ng Nash VÃ­ dá»¥ 1: TrÃ² chÆ¡i \u0026ldquo;Chicken Game\u0026rdquo; (TrÃ² chÆ¡i GÃ  con)\nHai tÃ i xáº¿ lÃ¡i xe lao tháº³ng vÃ o nhau. Náº¿u cáº£ hai tá»« chá»‘i nhÆ°á»ng Ä‘Æ°á»ng, há» sáº½ Ä‘Ã¢m nhau vÃ  thiá»‡t háº¡i náº·ng ná». Náº¿u má»™t ngÆ°á»i nhÆ°á»ng Ä‘Æ°á»ng (cháº¡y thoÃ¡t), ngÆ°á»i kia sáº½ tháº¯ng cuá»™c.\nBáº£ng tráº£ thÆ°á»Ÿng:\nNgÆ°á»i B nhÆ°á»ng NgÆ°á»i B khÃ´ng nhÆ°á»ng NgÆ°á»i A nhÆ°á»ng (0, 0) (-1, +1) NgÆ°á»i A khÃ´ng nhÆ°á»ng (+1, -1) (-10, -10) Náº¿u cáº£ hai chá»n \u0026ldquo;khÃ´ng nhÆ°á»ng\u0026rdquo;, há» rÆ¡i vÃ o tÃ¬nh huá»‘ng tá»‡ nháº¥t (-10, -10). ÄÃ¢y khÃ´ng pháº£i lÃ  cÃ¢n báº±ng Nash. Náº¿u má»™t ngÆ°á»i chá»n \u0026ldquo;nhÆ°á»ng\u0026rdquo; vÃ  ngÆ°á»i kia chá»n \u0026ldquo;khÃ´ng nhÆ°á»ng\u0026rdquo;, thÃ¬ ngÆ°á»i khÃ´ng nhÆ°á»ng sáº½ cÃ³ lá»£i (+1). Tuy nhiÃªn, Ä‘Ã¢y cÅ©ng khÃ´ng pháº£i lÃ  cÃ¢n báº±ng Nash vÃ¬ ngÆ°á»i nhÆ°á»ng cÃ³ thá»ƒ thay Ä‘á»•i chiáº¿n lÆ°á»£c Ä‘á»ƒ trÃ¡nh thiá»‡t háº¡i. CÃ¢n báº±ng Nash xáº£y ra khi má»™t ngÆ°á»i nhÆ°á»ng vÃ  ngÆ°á»i kia khÃ´ng nhÆ°á»ng, vÃ­ dá»¥: (NgÆ°á»i A nhÆ°á»ng, NgÆ°á»i B khÃ´ng nhÆ°á»ng) hoáº·c ngÆ°á»£c láº¡i. VÃ­ dá»¥ 2: TrÃ² chÆ¡i \u0026ldquo;Prisonerâ€™s Dilemma\u0026rdquo; (Dilemma cá»§a TÃ¹ nhÃ¢n)\nHai tÃ¹ nhÃ¢n bá»‹ báº¯t giá»¯ vÃ  bá»‹ tháº©m váº¥n riÃªng biá»‡t. Há» cÃ³ hai lá»±a chá»n: \u0026ldquo;há»£p tÃ¡c\u0026rdquo; (giá»¯ im láº·ng) hoáº·c \u0026ldquo;pháº£n bá»™i\u0026rdquo; (tá»‘ cÃ¡o ngÆ°á»i kia).\nBáº£ng tráº£ thÆ°á»Ÿng:\nNgÆ°á»i B há»£p tÃ¡c NgÆ°á»i B pháº£n bá»™i NgÆ°á»i A há»£p tÃ¡c (-1, -1) (-10, 0) NgÆ°á»i A pháº£n bá»™i (0, -10) (-5, -5) Náº¿u cáº£ hai há»£p tÃ¡c, há» nháº­n Ã¡n nháº¹ (-1, -1). Náº¿u má»™t ngÆ°á»i pháº£n bá»™i vÃ  ngÆ°á»i kia há»£p tÃ¡c, ngÆ°á»i pháº£n bá»™i Ä‘Æ°á»£c tá»± do (0) cÃ²n ngÆ°á»i há»£p tÃ¡c chá»‹u Ã¡n náº·ng (-10). CÃ¢n báº±ng Nash xáº£y ra khi cáº£ hai pháº£n bá»™i (-5, -5), vÃ¬ dÃ¹ bÃªn kia lÃ m gÃ¬, pháº£n bá»™i váº«n lÃ  chiáº¿n lÆ°á»£c tá»‘i Æ°u cÃ¡ nhÃ¢n. 4. á»¨ng dá»¥ng cá»§a cÃ¢n báº±ng Nash CÃ¢n báº±ng Nash cÃ³ nhiá»u á»©ng dá»¥ng trong cÃ¡c lÄ©nh vá»±c khÃ¡c nhau, bao gá»“m:\n4.1. Kinh táº¿ há»c Äáº¥u giÃ¡ vÃ  cáº¡nh tranh thá»‹ trÆ°á»ng: CÃ¡c cÃ´ng ty trong thá»‹ trÆ°á»ng cáº¡nh tranh thÆ°á»ng tÃ¬m cÃ¡ch Ä‘áº¡t Ä‘Æ°á»£c cÃ¢n báº±ng Nash báº±ng cÃ¡ch Ä‘Æ°a ra má»©c giÃ¡ vÃ  sáº£n lÆ°á»£ng tá»‘i Æ°u Ä‘á»ƒ tá»‘i Ä‘a hÃ³a lá»£i nhuáº­n. Chiáº¿n lÆ°á»£c Ä‘á»‹nh giÃ¡: CÃ¡c cÃ´ng ty lá»›n nhÆ° Amazon, Walmart, hay cÃ¡c hÃ£ng hÃ ng khÃ´ng thÆ°á»ng sá»­ dá»¥ng cÃ¢n báº±ng Nash Ä‘á»ƒ dá»± Ä‘oÃ¡n hÃ nh vi cá»§a Ä‘á»‘i thá»§ vÃ  Ä‘iá»u chá»‰nh chiáº¿n lÆ°á»£c cá»§a mÃ¬nh. 4.2. ChÃ­nh trá»‹ vÃ  quan há»‡ quá»‘c táº¿ ÄÃ m phÃ¡n vÃ  xung Ä‘á»™t: CÃ¢n báº±ng Nash giÃºp phÃ¢n tÃ­ch cÃ¡c tÃ¬nh huá»‘ng Ä‘Ã m phÃ¡n giá»¯a cÃ¡c quá»‘c gia hoáº·c cÃ¡c bÃªn trong xung Ä‘á»™t, vÃ­ dá»¥ nhÆ° thá»a thuáº­n cáº¯t giáº£m vÅ© khÃ­ háº¡t nhÃ¢n. Chiáº¿n tranh láº¡nh: CÃ¢n báº±ng Nash giáº£i thÃ­ch táº¡i sao cÃ¡c siÃªu cÆ°á»ng nhÆ° Má»¹ vÃ  LiÃªn XÃ´ duy trÃ¬ tráº¡ng thÃ¡i \u0026ldquo;cÃ¢n báº±ng khá»§ng bá»‘\u0026rdquo; (Mutually Assured Destruction - MAD), nÆ¡i khÃ´ng bÃªn nÃ o dÃ¡m táº¥n cÃ´ng trÆ°á»›c. 4.3. Sinh há»c tiáº¿n hÃ³a HÃ nh vi cá»§a Ä‘á»™ng váº­t: CÃ¢n báº±ng Nash Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giáº£i thÃ­ch cÃ¡c hÃ nh vi tiáº¿n hÃ³a cá»§a Ä‘á»™ng váº­t, cháº³ng háº¡n nhÆ° viá»‡c chá»n báº¡n Ä‘á»i hoáº·c phÃ¢n bá»• nguá»“n lá»±c trong mÃ´i trÆ°á»ng sá»‘ng. 4.4. CÃ´ng nghá»‡ vÃ  máº¡ng mÃ¡y tÃ­nh Giao thÃ´ng máº¡ng: CÃ¢n báº±ng Nash giÃºp tá»‘i Æ°u hÃ³a lÆ°u lÆ°á»£ng máº¡ng, Ä‘áº£m báº£o ráº±ng cÃ¡c luá»“ng dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n phá»‘i hiá»‡u quáº£ vÃ  trÃ¡nh táº¯c ngháº½n. Blockchain: Trong cÃ¡c giao dá»‹ch tiá»n Ä‘iá»‡n tá»­, cÃ¢n báº±ng Nash Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng cÃ¡c nÃºt máº¡ng hoáº¡t Ä‘á»™ng trung thá»±c vÃ  khÃ´ng phÃ¡ vá»¡ há»‡ thá»‘ng. 4.5. TÃ¢m lÃ½ há»c vÃ  xÃ£ há»™i há»c Quyáº¿t Ä‘á»‹nh cÃ¡ nhÃ¢n: CÃ¢n báº±ng Nash cung cáº¥p má»™t khung lÃ½ thuyáº¿t Ä‘á»ƒ hiá»ƒu cÃ¡ch con ngÆ°á»i Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh trong cÃ¡c tÃ¬nh huá»‘ng tÆ°Æ¡ng tÃ¡c xÃ£ há»™i phá»©c táº¡p. 5. Háº¡n cháº¿ cá»§a cÃ¢n báº±ng Nash KhÃ´ng duy nháº¥t: Má»™t trÃ² chÆ¡i cÃ³ thá»ƒ cÃ³ nhiá»u cÃ¢n báº±ng Nash, khiáº¿n viá»‡c dá»± Ä‘oÃ¡n káº¿t quáº£ trá»Ÿ nÃªn khÃ³ khÄƒn. KhÃ´ng pháº£i luÃ´n cÃ´ng báº±ng: CÃ¢n báº±ng Nash Ä‘Ã´i khi dáº«n Ä‘áº¿n káº¿t quáº£ khÃ´ng mong muá»‘n hoáº·c khÃ´ng hiá»‡u quáº£ vá» máº·t xÃ£ há»™i (vÃ­ dá»¥: Prisoner\u0026rsquo;s Dilemma). Giáº£ Ä‘á»‹nh lÃ½ tÃ­nh: CÃ¢n báº±ng Nash giáº£ Ä‘á»‹nh ráº±ng táº¥t cáº£ ngÆ°á»i chÆ¡i Ä‘á»u hÃ nh Ä‘á»™ng há»£p lÃ½ vÃ  biáº¿t rÃµ chiáº¿n lÆ°á»£c cá»§a Ä‘á»‘i thá»§, Ä‘iá»u nÃ y khÃ´ng pháº£i lÃºc nÃ o cÅ©ng Ä‘Ãºng trong thá»±c táº¿. á»¨ng dá»¥ng chia thÆ°á»Ÿng cho nhÃ¢n viÃªn ChÃºng ta sáº½ phÃ¢n tÃ­ch má»™t tÃ¬nh huá»‘ng cá»¥ thá»ƒ trong doanh nghiá»‡p, nÆ¡i trÆ°á»Ÿng phÃ²ng cáº§n quyáº¿t Ä‘á»‹nh cÃ¡ch chia thÆ°á»Ÿng giá»¯a cÃ¡c nhÃ¢n viÃªn dá»±a trÃªn hiá»‡u suáº¥t lÃ m viá»‡c. Äiá»u nÃ y liÃªn quan Ä‘áº¿n lÃ½ thuyáº¿t trÃ² chÆ¡i vÃ  cÃ¢n báº±ng Nash khi cÃ¡c nhÃ¢n viÃªn cÃ³ thá»ƒ Ä‘iá»u chá»‰nh hÃ nh vi cá»§a mÃ¬nh Ä‘á»ƒ tá»‘i Ä‘a hÃ³a lá»£i Ã­ch cÃ¡ nhÃ¢n.\nTÃ¬nh huá»‘ng Má»™t trÆ°á»Ÿng phÃ²ng quáº£n lÃ½ hai nhÃ¢n viÃªn (A vÃ  B). TrÆ°á»Ÿng phÃ²ng cÃ³ má»™t khoáº£n tiá»n thÆ°á»Ÿng cá»‘ Ä‘á»‹nh lÃ  10 triá»‡u Ä‘á»“ng Ä‘á»ƒ chia cho hai nhÃ¢n viÃªn dá»±a trÃªn má»©c Ä‘á»™ Ä‘Ã³ng gÃ³p cá»§a há» vÃ o dá»± Ã¡n. Tuy nhiÃªn, trÆ°á»Ÿng phÃ²ng khÃ´ng thá»ƒ giÃ¡m sÃ¡t hoÃ n toÃ n nÄƒng suáº¥t thá»±c táº¿ cá»§a tá»«ng ngÆ°á»i, mÃ  chá»‰ cÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ qua káº¿t quáº£ bÃ¡o cÃ¡o cá»§a há».\nChiáº¿n lÆ°á»£c cá»§a nhÃ¢n viÃªn:\nLÃ m viá»‡c chÄƒm chá»‰ (C): ÄÃ²i há»i ná»— lá»±c cao nhÆ°ng cÃ³ kháº£ nÄƒng Ä‘áº¡t káº¿t quáº£ tá»‘t. LÃ m viá»‡c lÆ°á»i biáº¿ng (L): Tiáº¿t kiá»‡m cÃ´ng sá»©c nhÆ°ng káº¿t quáº£ kÃ©m hÆ¡n. Quy táº¯c chia thÆ°á»Ÿng:\nNáº¿u cáº£ hai cÃ¹ng lÃ m viá»‡c chÄƒm chá»‰ (C, C), má»—i ngÆ°á»i nháº­n Ä‘Æ°á»£c 5 triá»‡u Ä‘á»“ng. Náº¿u má»™t ngÆ°á»i lÃ m viá»‡c chÄƒm chá»‰ vÃ  ngÆ°á»i kia lÆ°á»i biáº¿ng (C, L hoáº·c L, C), ngÆ°á»i lÃ m viá»‡c chÄƒm chá»‰ nháº­n 3 triá»‡u Ä‘á»“ng, ngÆ°á»i lÆ°á»i biáº¿ng nháº­n 7 triá»‡u Ä‘á»“ng (do ngÆ°á»i lÆ°á»i biáº¿ng \u0026ldquo;lá»£i dá»¥ng\u0026rdquo; káº¿t quáº£ cá»§a ngÆ°á»i khÃ¡c). Náº¿u cáº£ hai Ä‘á»u lÆ°á»i biáº¿ng (L, L), má»—i ngÆ°á»i chá»‰ nháº­n Ä‘Æ°á»£c 2 triá»‡u Ä‘á»“ng (do káº¿t quáº£ dá»± Ã¡n kÃ©m). Ma tráº­n tráº£ thÆ°á»Ÿng Báº£ng tráº£ thÆ°á»Ÿng (Ä‘Æ¡n vá»‹: triá»‡u Ä‘á»“ng):\nNhÃ¢n viÃªn B: ChÄƒm chá»‰ (C) NhÃ¢n viÃªn B: LÆ°á»i biáº¿ng (L) NhÃ¢n viÃªn A: ChÄƒm chá»‰ (C) (5, 5) (3, 7) NhÃ¢n viÃªn A: LÆ°á»i biáº¿ng (L) (7, 3) (2, 2) PhÃ¢n tÃ­ch cÃ¢n báº±ng Nash ChÃºng ta sáº½ xÃ¡c Ä‘á»‹nh chiáº¿n lÆ°á»£c tá»‘i Æ°u cho tá»«ng nhÃ¢n viÃªn:\nNáº¿u nhÃ¢n viÃªn B chá»n \u0026ldquo;ChÄƒm chá»‰ (C)\u0026rdquo;:\nNáº¿u A chá»n \u0026ldquo;ChÄƒm chá»‰ (C)\u0026rdquo;, A nháº­n 5 triá»‡u. Náº¿u A chá»n \u0026ldquo;LÆ°á»i biáº¿ng (L)\u0026rdquo;, A nháº­n 7 triá»‡u. =\u0026gt; A sáº½ chá»n \u0026ldquo;LÆ°á»i biáº¿ng (L)\u0026rdquo; vÃ¬ 7 \u0026gt; 5. Náº¿u nhÃ¢n viÃªn B chá»n \u0026ldquo;LÆ°á»i biáº¿ng (L)\u0026rdquo;:\nNáº¿u A chá»n \u0026ldquo;ChÄƒm chá»‰ (C)\u0026rdquo;, A nháº­n 3 triá»‡u. Náº¿u A chá»n \u0026ldquo;LÆ°á»i biáº¿ng (L)\u0026rdquo;, A nháº­n 2 triá»‡u. =\u0026gt; A sáº½ chá»n \u0026ldquo;LÆ°á»i biáº¿ng (L)\u0026rdquo; vÃ¬ 2 \u0026lt; 3. Káº¿t luáº­n: DÃ¹ B chá»n gÃ¬, A luÃ´n cÃ³ Ä‘á»™ng lá»±c chá»n \u0026ldquo;LÆ°á»i biáº¿ng (L)\u0026rdquo;. TÆ°Æ¡ng tá»±, náº¿u phÃ¢n tÃ­ch ngÆ°á»£c láº¡i tá»« gÃ³c Ä‘á»™ cá»§a B, B cÅ©ng sáº½ chá»n \u0026ldquo;LÆ°á»i biáº¿ng (L)\u0026rdquo;.\n=\u0026gt; CÃ¢n báº±ng Nash xáº£y ra khi cáº£ A vÃ  B Ä‘á»u chá»n \u0026ldquo;LÆ°á»i biáº¿ng (L)\u0026rdquo;, dáº«n Ä‘áº¿n má»—i ngÆ°á»i nháº­n 2 triá»‡u Ä‘á»“ng.\nÃ nghÄ©a trong doanh nghiá»‡p Hiá»‡u quáº£ tháº¥p: Máº·c dÃ¹ cáº£ hai nhÃ¢n viÃªn Ä‘á»u cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c 5 triá»‡u Ä‘á»“ng náº¿u cÃ¹ng lÃ m viá»‡c chÄƒm chá»‰, há» láº¡i rÆ¡i vÃ o tráº¡ng thÃ¡i cÃ¢n báº±ng Nash vá»›i káº¿t quáº£ tá»‡ hÆ¡n (2 triá»‡u Ä‘á»“ng má»—i ngÆ°á»i). ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ Ä‘iá»ƒn hÃ¬nh cá»§a \u0026ldquo;Dilemma cá»§a TÃ¹ nhÃ¢n\u0026rdquo; (Prisoner\u0026rsquo;s Dilemma). NguyÃªn nhÃ¢n: Do thiáº¿u sá»± phá»‘i há»£p vÃ  lÃ²ng tin giá»¯a cÃ¡c nhÃ¢n viÃªn, má»—i ngÆ°á»i chá»‰ nghÄ© Ä‘áº¿n lá»£i Ã­ch cÃ¡ nhÃ¢n thay vÃ¬ lá»£i Ã­ch táº­p thá»ƒ. Giáº£i phÃ¡p: TrÆ°á»Ÿng phÃ²ng cÃ³ thá»ƒ Ã¡p dá»¥ng cÃ¡c biá»‡n phÃ¡p nhÆ°: XÃ¢y dá»±ng há»‡ thá»‘ng giÃ¡m sÃ¡t: Äáº£m báº£o ráº±ng nÄƒng suáº¥t thá»±c táº¿ cá»§a nhÃ¢n viÃªn Ä‘Æ°á»£c Ä‘o lÆ°á»ng chÃ­nh xÃ¡c. Khuyáº¿n khÃ­ch tinh tháº§n Ä‘á»“ng Ä‘á»™i: Táº¡o mÃ´i trÆ°á»ng lÃ m viá»‡c khuyáº¿n khÃ­ch há»£p tÃ¡c vÃ  chia sáº» lá»£i Ã­ch. ThÆ°á»Ÿng theo nhÃ³m: Thay vÃ¬ chia thÆ°á»Ÿng cÃ¡ nhÃ¢n, trÆ°á»Ÿng phÃ²ng cÃ³ thá»ƒ thÆ°á»Ÿng dá»±a trÃªn káº¿t quáº£ chung cá»§a cáº£ nhÃ³m, giáº£m Ä‘á»™ng cÆ¡ lÆ°á»i biáº¿ng cÃ¡ nhÃ¢n. BÃ i viáº¿t dÆ°á»›i gÃ³c nhÃ¬n cá»§a má»™t con IT quÃ¨n, tháº±ng IT lá», viáº¿t vá» má»™t váº¥n Ä‘á» kinh táº¿, bÃ  con chuyÃªn ngÃ nh tháº¥y sai thÃ¬ hoan há»‰ cÃ²m mÃªn nháº¹ nhÃ ng, Ä‘á»«ng buÃ´n lá»i cay Ä‘áº¯ng.\nCáº£m Æ¡n báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\nNguá»“n tham kháº£o\ngÃµ tá»« khoÃ¡ Nash Equilibrium\nNash, John F. (1950). \u0026ldquo;Equilibrium Points in N-Person Games.\u0026rdquo; Proceedings of the National Academy of Sciences . -\u0026gt; BÃ i bÃ¡o cá»§a John Nash, giá»›i thiá»‡u khÃ¡i niá»‡m cÃ¢n báº±ng Nash.\nMyerson, Roger B. (1997). Game Theory: Analysis of Conflict. Harvard University Press. SÃ¡ch giÃ¡o khoa\nOsborne, Martin J., \u0026amp; Rubinstein, Ariel. (1994). A Course in Game Theory. MIT Press. SÃ¡ch giÃ¡o khoa\nGibbons, Robert. (1992). A Primer in Game Theory. Pearson Education. - SÃ¡ch vá» lÃ½ thuyáº¿t trÃ² chÆ¡i, vá»›i nhiá»u vÃ­ dá»¥ thá»±c táº¿, thÃ­ch há»£p cho ngÆ°á»i má»›i tÃ¬m hiá»ƒu .\n","date":"Apr 11, 2025","img":"https://unsplash.it/1920/1080?image=230","permalink":"/blog/2025-04-11-hash-equilibrium/","series":null,"tags":["Game Theory"],"title":"CÃ¢n Báº±ng Nash - Nash Equilibrium"},{"categories":null,"content":" Giá»›i thiá»‡u vá» Prisonerâ€™s Dilemma (Song Ä‘á» tÃ¹ nhÃ¢n) á»¨ng dá»¥ng cá»§a Prisonerâ€™s Dilemma á»¨ng dá»¥ng Chia thÆ°á»Ÿng giá»¯a cÃ¡c nhÃ¢n viÃªn* á»¨ng dá»¥ng thá»±c táº¿ trong doanh nghiá»‡p: Ã nghÄ©a tá»•ng quÃ¡t Giá»›i thiá»‡u vá» Prisonerâ€™s Dilemma (Song Ä‘á» tÃ¹ nhÃ¢n) Prisonerâ€™s Dilemma lÃ  má»™t trong nhá»¯ng khÃ¡i niá»‡m quan trá»ng nháº¥t trong lÃ½ thuyáº¿t trÃ² chÆ¡i (Game Theory), Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi hai nhÃ  toÃ¡n há»c Merrill Flood vÃ  Melvin Dresher vÃ o nÄƒm 1950, vÃ  sau Ä‘Ã³ Ä‘Æ°á»£c Albert W. Tucker Ä‘áº·t tÃªn vÃ  minh há»a báº±ng cÃ¢u chuyá»‡n vá» hai tÃ¹ nhÃ¢n.\nCÃ¢u chuyá»‡n Ä‘iá»ƒn hÃ¬nh cá»§a Prisonerâ€™s Dilemma Hai nghi pháº¡m (A vÃ  B) bá»‹ báº¯t vÃ¬ liÃªn quan Ä‘áº¿n má»™t vá»¥ Ã¡n. Cáº£nh sÃ¡t khÃ´ng cÃ³ Ä‘á»§ báº±ng chá»©ng Ä‘á»ƒ káº¿t tá»™i cáº£ hai náº¿u há» khÃ´ng khai bÃ¡o gÃ¬. Do Ä‘Ã³, cáº£nh sÃ¡t tÃ¡ch há» ra vÃ  Ä‘Æ°a ra cÃ¡c lá»±a chá»n nhÆ° sau:\nNáº¿u cáº£ hai im láº·ng (há»£p tÃ¡c vá»›i nhau), má»—i ngÆ°á»i sáº½ chá»‰ pháº£i ngá»“i tÃ¹ 1 nÄƒm vÃ¬ má»™t tá»™i nháº¹. Náº¿u má»™t ngÆ°á»i khai bÃ¡o (pháº£n bá»™i) vÃ  ngÆ°á»i kia im láº·ng, ngÆ°á»i khai bÃ¡o sáº½ Ä‘Æ°á»£c miá»…n Ã¡n tÃ¹ (0 nÄƒm) trong khi ngÆ°á»i im láº·ng sáº½ chá»‹u Ã¡n 3 nÄƒm. Náº¿u cáº£ hai cÃ¹ng khai bÃ¡o (cáº£ hai pháº£n bá»™i nhau), má»—i ngÆ°á»i sáº½ pháº£i chá»‹u Ã¡n 2 nÄƒm. Káº¿t quáº£ nÃ y Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng ma tráº­n thÆ°á»Ÿng pháº¡t:\nB Im Láº·ng B Khai BÃ¡o A Im Láº·ng (-1, -1) (-3, 0) A Khai BÃ¡o (0, -3) (-2, -2) Trong Ä‘Ã³, sá»‘ Ä‘áº§u tiÃªn lÃ  sá»‘ nÄƒm tÃ¹ cá»§a A, sá»‘ thá»© hai lÃ  sá»‘ nÄƒm tÃ¹ cá»§a B.\nPhÃ¢n tÃ­ch chiáº¿n lÆ°á»£c Chiáº¿n lÆ°á»£c há»£p tÃ¡c (Im láº·ng): Cáº£ hai Ä‘á»u im láº·ng vÃ  nháº­n 1 nÄƒm tÃ¹. Chiáº¿n lÆ°á»£c pháº£n bá»™i (Khai bÃ¡o): Má»™t ngÆ°á»i pháº£n bá»™i vÃ  ngÆ°á»i kia há»£p tÃ¡c â†’ ngÆ°á»i pháº£n bá»™i Ä‘Æ°á»£c tá»± do, ngÆ°á»i há»£p tÃ¡c chá»‹u Ã¡n náº·ng. Cáº£ hai pháº£n bá»™i: Cáº£ hai Ä‘á»u nháº­n Ã¡n 2 nÄƒm tÃ¹. Náº¿u xÃ©t tá»« gÃ³c Ä‘á»™ cÃ¡ nhÃ¢n:\nMá»—i ngÆ°á»i Ä‘á»u cÃ³ Ä‘á»™ng lá»±c Ä‘á»ƒ khai bÃ¡o (pháº£n bá»™i) vÃ¬ Ä‘iá»u nÃ y mang láº¡i lá»£i Ã­ch cÃ¡ nhÃ¢n tá»‘t hÆ¡n (miá»…n Ã¡n hoáº·c Ã­t nháº¥t lÃ  2 nÄƒm tÃ¹ thay vÃ¬ 3 nÄƒm). Tuy nhiÃªn, náº¿u cáº£ hai cÃ¹ng pháº£n bá»™i, káº¿t quáº£ cuá»‘i cÃ¹ng (2 nÄƒm tÃ¹ cho má»—i ngÆ°á»i) láº¡i tá»“i tá»‡ hÆ¡n so vá»›i trÆ°á»ng há»£p cáº£ hai cÃ¹ng há»£p tÃ¡c (1 nÄƒm tÃ¹). ÄÃ¢y chÃ­nh lÃ  \u0026ldquo;dilemma\u0026rdquo; (song Ä‘á»): lá»£i Ã­ch cÃ¡ nhÃ¢n dáº«n Ä‘áº¿n káº¿t quáº£ táº­p thá»ƒ kÃ©m hiá»‡u quáº£.\ná»¨ng dá»¥ng cá»§a Prisonerâ€™s Dilemma Prisonerâ€™s Dilemma khÃ´ng chá»‰ lÃ  má»™t bÃ i toÃ¡n lÃ½ thuyáº¿t mÃ  cÃ²n cÃ³ nhiá»u á»©ng dá»¥ng thá»±c táº¿ trong cÃ¡c lÄ©nh vá»±c khÃ¡c nhau:\n1. Kinh táº¿ vÃ  Kinh doanh Cáº¡nh tranh giÃ¡ cáº£: Hai cÃ´ng ty cáº¡nh tranh cÃ³ thá»ƒ chá»n giá»¯a viá»‡c giá»¯ giÃ¡ cao (há»£p tÃ¡c) hoáº·c giáº£m giÃ¡ Ä‘á»ƒ giÃ nh thá»‹ pháº§n (pháº£n bá»™i). Náº¿u cáº£ hai giáº£m giÃ¡, lá»£i nhuáº­n cá»§a cáº£ hai sáº½ giáº£m sÃºt. Quáº£ng cÃ¡o: Hai cÃ´ng ty cÃ³ thá»ƒ chá»n chi nhiá»u tiá»n cho quáº£ng cÃ¡o (pháº£n bá»™i) hoáº·c cÃ¹ng háº¡n cháº¿ ngÃ¢n sÃ¡ch quáº£ng cÃ¡o (há»£p tÃ¡c). Náº¿u cáº£ hai cÃ¹ng tÄƒng chi tiÃªu, lá»£i nhuáº­n rÃ²ng cÃ³ thá»ƒ giáº£m. OPEC vÃ  sáº£n lÆ°á»£ng dáº§u má»: CÃ¡c quá»‘c gia thÃ nh viÃªn OPEC cÃ³ thá»ƒ chá»n tuÃ¢n thá»§ thá»a thuáº­n cáº¯t giáº£m sáº£n lÆ°á»£ng (há»£p tÃ¡c) hoáº·c tÄƒng sáº£n lÆ°á»£ng Ä‘á»ƒ kiáº¿m lá»£i nhuáº­n cÃ¡ nhÃ¢n (pháº£n bá»™i). Náº¿u táº¥t cáº£ tÄƒng sáº£n lÆ°á»£ng, giÃ¡ dáº§u sáº½ giáº£m, gÃ¢y thiá»‡t háº¡i chung. 2. ChÃ­nh trá»‹ vÃ  Ngoáº¡i giao Giáº£i trá»« vÅ© khÃ­ háº¡t nhÃ¢n: CÃ¡c quá»‘c gia cÃ³ thá»ƒ chá»n giá»¯a giáº£i trá»« vÅ© khÃ­ (há»£p tÃ¡c) hoáº·c tiáº¿p tá»¥c phÃ¡t triá»ƒn vÅ© khÃ­ (pháº£n bá»™i). Náº¿u má»™t nÆ°á»›c pháº£n bá»™i, há» cÃ³ lá»£i tháº¿ quÃ¢n sá»±; náº¿u cáº£ hai cÃ¹ng phÃ¡t triá»ƒn, nguy cÆ¡ chiáº¿n tranh tÄƒng lÃªn. Hiá»‡p Ä‘á»‹nh mÃ´i trÆ°á»ng: CÃ¡c quá»‘c gia cÃ³ thá»ƒ há»£p tÃ¡c Ä‘á»ƒ giáº£m phÃ¡t tháº£i khÃ­ nhÃ  kÃ­nh hoáº·c tiáº¿p tá»¥c phÃ¡t triá»ƒn cÃ´ng nghiá»‡p mÃ  khÃ´ng quan tÃ¢m Ä‘áº¿n mÃ´i trÆ°á»ng. Náº¿u táº¥t cáº£ pháº£n bá»™i, biáº¿n Ä‘á»•i khÃ­ háº­u sáº½ trá»Ÿ nÃªn nghiÃªm trá»ng hÆ¡n. 3. XÃ£ há»™i vÃ  TÃ¢m lÃ½ há»c HÃ nh vi xÃ£ há»™i: Trong cÃ¡c má»‘i quan há»‡ cÃ¡ nhÃ¢n, ngÆ°á»i ta thÆ°á»ng Ä‘á»‘i máº·t vá»›i lá»±a chá»n giá»¯a há»£p tÃ¡c (giÃºp Ä‘á»¡ ngÆ°á»i khÃ¡c) hoáº·c pháº£n bá»™i (tá»± báº£o vá»‡ lá»£i Ã­ch cÃ¡ nhÃ¢n). VÃ­ dá»¥: Ä‘Ã³ng gÃ³p vÃ o quá»¹ cá»™ng Ä‘á»“ng hay giá»¯ tiá»n cho báº£n thÃ¢n. Tin tÆ°á»Ÿng vÃ  lÃ²ng trung thÃ nh: Song Ä‘á» tÃ¹ nhÃ¢n giÃºp giáº£i thÃ­ch táº¡i sao con ngÆ°á»i Ä‘Ã´i khi chá»n há»£p tÃ¡c dÃ¹ cÃ³ nguy cÆ¡ bá»‹ pháº£n bá»™i â€“ Ä‘iá»u nÃ y liÃªn quan Ä‘áº¿n xÃ¢y dá»±ng niá»m tin lÃ¢u dÃ i. 4. Sinh há»c vÃ  Tiáº¿n hÃ³a Há»£p tÃ¡c trong tá»± nhiÃªn: Trong sinh há»c tiáº¿n hÃ³a, cÃ¡c loÃ i Ä‘á»™ng váº­t cÃ³ thá»ƒ há»£p tÃ¡c Ä‘á»ƒ sÄƒn má»“i hoáº·c báº£o vá»‡ lÃ£nh thá»•. Tuy nhiÃªn, hÃ nh vi pháº£n bá»™i (Äƒn trá»™m thá»©c Äƒn cá»§a Ä‘á»“ng loáº¡i) cÅ©ng tá»“n táº¡i. Lá»±a chá»n di truyá»n: CÃ¡c cÃ¡ thá»ƒ trong má»™t quáº§n thá»ƒ cÃ³ thá»ƒ chá»n há»£p tÃ¡c Ä‘á»ƒ Ä‘áº£m báº£o sá»± sá»‘ng cÃ²n cá»§a cáº£ nhÃ³m hoáº·c cáº¡nh tranh Ä‘á»ƒ tá»‘i Ä‘a hÃ³a kháº£ nÄƒng sinh sáº£n cÃ¡ nhÃ¢n. 5. CÃ´ng nghá»‡ vÃ  An ninh máº¡ng PhÃ²ng chá»‘ng táº¥n cÃ´ng máº¡ng: Hai tá»• chá»©c cÃ³ thá»ƒ há»£p tÃ¡c Ä‘á»ƒ báº£o vá»‡ há»‡ thá»‘ng máº¡ng hoáº·c cá»‘ gáº¯ng tiáº¿t kiá»‡m chi phÃ­ báº±ng cÃ¡ch bá» qua cÃ¡c biá»‡n phÃ¡p an ninh. Náº¿u cáº£ hai Ä‘á»u bá» qua, cáº£ hai Ä‘á»u dá»… bá»‹ táº¥n cÃ´ng. Chia sáº» thÃ´ng tin: CÃ¡c cÃ´ng ty cÃ´ng nghá»‡ cÃ³ thá»ƒ chá»n chia sáº» dá»¯ liá»‡u Ä‘á»ƒ cáº£i thiá»‡n sáº£n pháº©m hoáº·c giá»¯ bÃ­ máº­t Ä‘á»ƒ duy trÃ¬ lá»£i tháº¿ cáº¡nh tranh. 6. TrÃ² chÆ¡i láº·p Ä‘i láº·p láº¡i (Iterated Prisonerâ€™s Dilemma) Trong phiÃªn báº£n láº·p Ä‘i láº·p láº¡i cá»§a song Ä‘á» tÃ¹ nhÃ¢n, cÃ¡c bÃªn tÆ°Æ¡ng tÃ¡c nhiá»u láº§n. Äiá»u nÃ y má»Ÿ ra cÆ¡ há»™i Ä‘á»ƒ xÃ¢y dá»±ng niá»m tin vÃ  Ã¡p dá»¥ng chiáº¿n lÆ°á»£c há»£p tÃ¡c lÃ¢u dÃ i. Má»™t chiáº¿n lÆ°á»£c ná»•i tiáº¿ng lÃ  \u0026ldquo;Tit-for-Tat\u0026rdquo; (Äƒn miáº¿ng tráº£ miáº¿ng):\nBáº¯t Ä‘áº§u báº±ng viá»‡c há»£p tÃ¡c. Sau Ä‘Ã³, lÃ m theo hÃ nh Ä‘á»™ng cá»§a Ä‘á»‘i phÆ°Æ¡ng á»Ÿ vÃ²ng trÆ°á»›c. Chiáº¿n lÆ°á»£c nÃ y Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  ráº¥t hiá»‡u quáº£ trong viá»‡c khuyáº¿n khÃ­ch há»£p tÃ¡c. á»¨ng dá»¥ng Chia thÆ°á»Ÿng giá»¯a cÃ¡c nhÃ¢n viÃªn* HÃ£y tÆ°á»Ÿng tÆ°á»£ng má»™t tÃ¬nh huá»‘ng trong má»™t cÃ´ng ty, nÆ¡i Ã´ng trÆ°á»Ÿng phÃ²ng cáº§n chia thÆ°á»Ÿng dá»±a trÃªn hiá»‡u suáº¥t lÃ m viá»‡c cá»§a hai nhÃ¢n viÃªn (A vÃ  B). Tiá»n thÆ°á»Ÿng cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n bá»• theo cÃ¡ch há»£p tÃ¡c hoáº·c cáº¡nh tranh, tÃ¹y thuá»™c vÃ o hÃ nh vi cá»§a hai nhÃ¢n viÃªn. Äiá»u nÃ y táº¡o ra má»™t tÃ¬nh huá»‘ng tÆ°Æ¡ng tá»± nhÆ° Prisonerâ€™s Dilemma.\nTÃ¬nh huá»‘ng cá»¥ thá»ƒ: Ã”ng trÆ°á»Ÿng phÃ²ng thÃ´ng bÃ¡o ráº±ng sáº½ cÃ³ má»™t khoáº£n tiá»n thÆ°á»Ÿng lá»›n cho nhÃ³m náº¿u cáº£ hai nhÃ¢n viÃªn cÃ¹ng há»£p tÃ¡c Ä‘á»ƒ hoÃ n thÃ nh má»™t dá»± Ã¡n quan trá»ng. Tuy nhiÃªn, náº¿u má»™t ngÆ°á»i cá»‘ gáº¯ng \u0026ldquo;pháº£n bá»™i\u0026rdquo; báº±ng cÃ¡ch chá»‰ táº­p trung vÃ o lá»£i Ã­ch cÃ¡ nhÃ¢n (cháº³ng háº¡n, lÃ m viá»‡c Ã­t hÆ¡n nhÆ°ng váº«n cá»‘ gáº¯ng nháº­n pháº§n thÆ°á»Ÿng lá»›n), thÃ¬ ngÆ°á»i kia sáº½ chá»‹u thiá»‡t thÃ²i. Náº¿u cáº£ hai cÃ¹ng pháº£n bá»™i (cáº£ hai Ä‘á»u lÆ°á»i biáº¿ng hoáº·c khÃ´ng há»£p tÃ¡c), dá»± Ã¡n sáº½ tháº¥t báº¡i vÃ  cáº£ hai Ä‘á»u khÃ´ng nháº­n Ä‘Æ°á»£c thÆ°á»Ÿng. Ma tráº­n thÆ°á»Ÿng pháº¡t: ChÃºng ta cÃ³ thá»ƒ biá»ƒu diá»…n tÃ¬nh huá»‘ng nÃ y dÆ°á»›i dáº¡ng ma tráº­n thÆ°á»Ÿng pháº¡t:\nB Há»£p TÃ¡c B KhÃ´ng Há»£p TÃ¡c A Há»£p TÃ¡c (5 triá»‡u, 5 triá»‡u) (1 triá»‡u, 8 triá»‡u) A KhÃ´ng Há»£p TÃ¡c (8 triá»‡u, 1 triá»‡u) (2 triá»‡u, 2 triá»‡u) Trong Ä‘Ã³:\nSá»‘ Ä‘áº§u tiÃªn lÃ  sá»‘ tiá»n thÆ°á»Ÿng cá»§a A. Sá»‘ thá»© hai lÃ  sá»‘ tiá»n thÆ°á»Ÿng cá»§a B. PhÃ¢n tÃ­ch chiáº¿n lÆ°á»£c: Cáº£ hai há»£p tÃ¡c:\nCáº£ A vÃ  B Ä‘á»u lÃ m viá»‡c chÄƒm chá»‰ vÃ  hoÃ n thÃ nh dá»± Ã¡n tá»‘t. Má»—i ngÆ°á»i nháº­n Ä‘Æ°á»£c 5 triá»‡u Ä‘á»“ng. ÄÃ¢y lÃ  káº¿t quáº£ tá»‘i Æ°u cho cáº£ hai. Má»™t ngÆ°á»i há»£p tÃ¡c, ngÆ°á»i kia khÃ´ng há»£p tÃ¡c:\nNáº¿u A há»£p tÃ¡c vÃ  B khÃ´ng há»£p tÃ¡c: A nháº­n 1 triá»‡u (do pháº£i gÃ¡nh vÃ¡c pháº§n viá»‡c cá»§a B), trong khi B nháº­n 8 triá»‡u (vÃ¬ khÃ´ng lÃ m gÃ¬ nhÆ°ng váº«n Ä‘Æ°á»£c thÆ°á»Ÿng). NgÆ°á»£c láº¡i, náº¿u B há»£p tÃ¡c vÃ  A khÃ´ng há»£p tÃ¡c: B nháº­n 1 triá»‡u, A nháº­n 8 triá»‡u. Cáº£ hai khÃ´ng há»£p tÃ¡c:\nDá»± Ã¡n tháº¥t báº¡i vÃ¬ cáº£ hai Ä‘á»u lÆ°á»i biáº¿ng. Má»—i ngÆ°á»i chá»‰ nháº­n Ä‘Æ°á»£c 2 triá»‡u Ä‘á»“ng. Song Ä‘á» trong tÃ¬nh huá»‘ng nÃ y: Náº¿u xÃ©t tá»« gÃ³c Ä‘á»™ cÃ¡ nhÃ¢n:\nMá»—i nhÃ¢n viÃªn Ä‘á»u cÃ³ Ä‘á»™ng lá»±c Ä‘á»ƒ khÃ´ng há»£p tÃ¡c (pháº£n bá»™i) vÃ¬ Ä‘iá»u nÃ y mang láº¡i lá»£i Ã­ch cÃ¡ nhÃ¢n cao hÆ¡n trong ngáº¯n háº¡n (8 triá»‡u so vá»›i 5 triá»‡u náº¿u há»£p tÃ¡c). Tuy nhiÃªn, náº¿u cáº£ hai cÃ¹ng khÃ´ng há»£p tÃ¡c, káº¿t quáº£ cuá»‘i cÃ¹ng (2 triá»‡u cho má»—i ngÆ°á»i) láº¡i kÃ©m hÆ¡n nhiá»u so vá»›i trÆ°á»ng há»£p cáº£ hai cÃ¹ng há»£p tÃ¡c (5 triá»‡u cho má»—i ngÆ°á»i). Tá»« gÃ³c Ä‘á»™ táº­p thá»ƒ:\nKáº¿t quáº£ tá»‘t nháº¥t cho cáº£ nhÃ³m lÃ  cáº£ hai cÃ¹ng há»£p tÃ¡c, nhÆ°ng Ä‘á»™ng cÆ¡ cÃ¡ nhÃ¢n khiáº¿n há» dá»… dÃ ng rÆ¡i vÃ o tÃ¬nh tráº¡ng khÃ´ng há»£p tÃ¡c. á»¨ng dá»¥ng thá»±c táº¿ trong doanh nghiá»‡p: Khuyáº¿n khÃ­ch há»£p tÃ¡c:\nÃ”ng trÆ°á»Ÿng phÃ²ng cÃ³ thá»ƒ thiáº¿t káº¿ há»‡ thá»‘ng thÆ°á»Ÿng sao cho viá»‡c há»£p tÃ¡c trá»Ÿ nÃªn háº¥p dáº«n hÆ¡n. VÃ­ dá»¥: ThÆ°á»Ÿng thÃªm náº¿u cáº£ nhÃ³m hoÃ n thÃ nh má»¥c tiÃªu chung. Ãp dá»¥ng hÃ¬nh pháº¡t náº¿u má»™t ngÆ°á»i khÃ´ng Ä‘Ã³ng gÃ³p Ä‘á»§ (vÃ­ dá»¥: giáº£m lÆ°Æ¡ng hoáº·c cáº¯t thÆ°á»Ÿng cÃ¡ nhÃ¢n). XÃ¢y dá»±ng lÃ²ng tin:\nNáº¿u hai nhÃ¢n viÃªn Ä‘Ã£ tá»«ng há»£p tÃ¡c thÃ nh cÃ´ng trong quÃ¡ khá»©, há» sáº½ cÃ³ xu hÆ°á»›ng tin tÆ°á»Ÿng nhau hÆ¡n vÃ  tiáº¿p tá»¥c há»£p tÃ¡c trong tÆ°Æ¡ng lai. Minh báº¡ch hÃ³a quy trÃ¬nh:\nCÃ´ng khai má»©c Ä‘á»™ Ä‘Ã³ng gÃ³p cá»§a tá»«ng ngÆ°á»i Ä‘á»ƒ trÃ¡nh tÃ¬nh tráº¡ng \u0026ldquo;Äƒn bÃ¡m\u0026rdquo; hoáº·c lá»£i dá»¥ng ngÆ°á»i khÃ¡c. Ãp dá»¥ng chiáº¿n lÆ°á»£c dÃ i háº¡n (Iterated Prisonerâ€™s Dilemma):\nNáº¿u hai nhÃ¢n viÃªn pháº£i lÃ m viá»‡c cÃ¹ng nhau nhiá»u láº§n, há» sáº½ nháº­n ra ráº±ng há»£p tÃ¡c lÃ¢u dÃ i mang láº¡i lá»£i Ã­ch lá»›n hÆ¡n. Äiá»u nÃ y khuyáº¿n khÃ­ch há» chá»n há»£p tÃ¡c thay vÃ¬ pháº£n bá»™i. Ã nghÄ©a tá»•ng quÃ¡t Prisonerâ€™s Dilemma lÃ  má»™t mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n nhÆ°ng sÃ¢u sáº¯c, giÃºp chÃºng ta hiá»ƒu rÃµ sá»± xung Ä‘á»™t giá»¯a lá»£i Ã­ch cÃ¡ nhÃ¢n vÃ  lá»£i Ã­ch táº­p thá»ƒ. NÃ³ giáº£i thÃ­ch táº¡i sao con ngÆ°á»i vÃ  tá»• chá»©c thÆ°á»ng khÃ³ Ä‘áº¡t Ä‘Æ°á»£c há»£p tÃ¡c hoÃ n háº£o, ngay cáº£ khi Ä‘iá»u Ä‘Ã³ cÃ³ lá»£i cho táº¥t cáº£. Äá»“ng thá»i, nÃ³ cÅ©ng gá»£i Ã½ ráº±ng cÃ¡c cÆ¡ cháº¿ khuyáº¿n khÃ­ch há»£p tÃ¡c (nhÆ° thá»a thuáº­n, luáº­t phÃ¡p, hoáº·c lÃ²ng tin) lÃ  cáº§n thiáº¿t Ä‘á»ƒ vÆ°á»£t qua nhá»¯ng tÃ¬nh huá»‘ng tÆ°Æ¡ng tá»± trong cuá»™c sá»‘ng.\nBÃ i viáº¿t dÆ°á»›i gÃ³c nhÃ¬n cá»§a má»™t con IT quÃ¨n, tháº±ng IT lá», viáº¿t vá» má»™t váº¥n Ä‘á» kinh táº¿, bÃ  con chuyÃªn ngÃ nh tháº¥y sai thÃ¬ hoan há»‰ cÃ²m mÃªn nháº¹ nhÃ ng, Ä‘á»«ng buÃ´n lá»i cay Ä‘áº¯ng.\nCáº£m Æ¡n báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\nNguá»“n tham kháº£o\ngÃµ tá»« khoÃ¡ Prisonerâ€™s Dilemma\nAxelrod, Robert. (1984). The Evolution of Cooperation . Basic Books. - SÃ¡ch kinh Ä‘iá»ƒn, nÃªn Ä‘á»c\nDixit, Avinash K., \u0026amp; Nalebuff, Barry J. (2008). The Art of Strategy: A Game Theorist\u0026rsquo;s Guide to Success in Business and Life . W.W. Norton \u0026amp; Company. - SÃ¡ch chá»©a nhiá»u vÃ­ dá»¥ thá»±c táº¿ , cÃ³ thá»ƒ Ã¡p dá»¥ng vÃ o kinh doanh vÃ  cuá»™c sá»‘ng.\nOsborne, Martin J. (2003). An Introduction to Game Theory . Oxford University Press. - GiÃ¡o trÃ¬nh lÃ½ thuyáº¿t toÃ n diá»‡n, phÃ¢n tÃ­ch chi tiáº¿t, vÃ  cÃ¡c mÃ´ hÃ¬nh Má»™t giÃ¡o trÃ¬nh toÃ n diá»‡n vá» lÃ½ thuyáº¿t trÃ² chÆ¡i, bao gá»“m phÃ¢n tÃ­ch chi tiáº¿t vá» Prisonerâ€™s Dilemma vÃ  cÃ¡c mÃ´ hÃ¬nh liÃªn quan.\nPoundstone, William. (1992). Prisonerâ€™s Dilemma: John von Neumann, Game Theory, and the Puzzle of the Bomb . Anchor Books. - lá»‹ch sá»­ vÃ  Ã½ nghÄ©a cá»§a Prisonerâ€™s Dilemma,káº¿t ná»‘i vá»›i cÃ¡c váº¥n Ä‘á» chÃ­nh trá»‹ vÃ  xÃ£ há»™i.\n","date":"Apr 10, 2025","img":"https://unsplash.it/1920/1080?image=230","permalink":"/blog/2025-04-10-prisoner-dilemma/","series":null,"tags":["Game Theory"],"title":"Prisonerâ€™s Dilemma - Song Äá» TÃ¹ NhÃ¢n"},{"categories":null,"content":" 1. Äá» bÃ i 2. Káº¿t quáº£ 2.1. Vá» hiá»‡u suáº¥t 2.2. Vá» chuyÃªn mÃ´n 2.3. Vá» tÃ­nh cá»™ng Ä‘á»“ng 2.4. Káº¿t quáº£ ná»•i báº­t khÃ¡c: 1. Äá» bÃ i CÃ´ng ty Procter \u0026amp; Gamble (P\u0026amp;G), má»™t cÃ´ng ty hÃ ng tiÃªu dÃ¹ng Ä‘Ã³ng gÃ³i toÃ n cáº§u. CÃ´ng ty cÃ³ khoáº£ng 7,000 chuyÃªn gia R\u0026amp;D trÃªn toÃ n tháº¿ giá»›i, hoáº¡t Ä‘á»™ng cá»§a cÃ´ng ty bao gá»“m phÃ¡t triá»ƒn sáº£n pháº©m tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i (R\u0026amp;D to product), cÃ³ quy trÃ¬nh R\u0026amp;D cÃ³ cáº¥u trÃºc tá»‘t vÃ  lá»±c lÆ°á»£ng lao Ä‘á»™ng cÃ³ ká»¹ nÄƒng cao\nÄá» tÃ i cÃ´ng ty Ä‘áº·t ra: \u0026ldquo;ÄÃ¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a TrÃ­ tuá»‡ nhÃ¢n táº¡o tháº¿ há»‡ má»›i (GenAI) Ä‘áº¿n hiá»‡u quáº£ há»£p tÃ¡c nhÃ³m trong mÃ´i trÆ°á»ng lÃ m viá»‡c tri thá»©c, táº­p trung vÃ o ba khÃ­a cáº¡nh chÃ­nh: hiá»‡u suáº¥t lÃ m viá»‡c, chia sáº» chuyÃªn mÃ´n vÃ  tÆ°Æ¡ng tÃ¡c cá»™ng Ä‘á»“ng .\u0026rdquo; hay nÃ³i cÃ¡ch khÃ¡c, ThÃ­ nghiá»‡m nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ kiá»ƒm tra tÃ¡c Ä‘á»™ng cá»§a AI Ä‘áº¿n ba khÃ­a cáº¡nh chÃ­nh cá»§a teamwork: hiá»‡u suáº¥t, chia sáº» chuyÃªn mÃ´n vÃ  tÆ°Æ¡ng tÃ¡c cá»™ng Ä‘á»“ng trong bá»‘i cáº£nh lÃ m viá»‡c thá»±c táº¿\nCá»¥ thá»ƒ, nghiÃªn cá»©u nÃ y nháº±m tráº£ lá»i cÃ¡c cÃ¢u há»i chÃ­nh sau:\nLiá»‡u GenAI cÃ³ thá»ƒ cung cáº¥p nhá»¯ng lá»£i Ã­ch vá» hiá»‡u suáº¥t so vá»›i cÃ¡ch lÃ m truyá»n thá»‘ng cá»§a teamwork hay khÃ´ng?\nGenAI cÃ³ giÃºp má»Ÿ rá»™ng pháº¡m vi chuyÃªn mÃ´n cá»§a nhÃ¢n viÃªn ngay cáº£ khi há» thiáº¿u má»™t sá»‘ kiáº¿n thá»©c vÃ  ká»¹ nÄƒng chuyÃªn mÃ´n nháº¥t Ä‘á»‹nh khÃ´ng?\nGenAI cÃ³ thá»ƒ cung cáº¥p loáº¡i hÃ¬nh tÆ°Æ¡ng tÃ¡c cá»™ng Ä‘á»“ng nÃ o mÃ  chÃºng ta thÆ°á»ng liÃªn tÆ°á»Ÿng Ä‘áº¿n sá»± há»£p tÃ¡c giá»¯a con ngÆ°á»i khÃ´ng?\nQuy mÃ´ cÃ´ng ty thá»±c hiá»‡n thÃ­ nghiá»‡m Ä‘Æ°á»£c mÃ´ táº£ nhÆ° sau:\nSá»‘ lÆ°á»£ng ngÆ°á»i tham gia: 811 nhÃ¢n viÃªn P\u0026amp;G\nNgÆ°á»i tham gia lÃ  cÃ¡c chuyÃªn gia tá»« hai lÄ©nh vá»±c: R\u0026amp;D vÃ  Commercial\nÄÆ°á»£c phÃ¢n ngáº«u nhiÃªn vÃ o cÃ¡c Ä‘iá»u kiá»‡n thÃ­ nghiá»‡m\nPhÃ¢n bá»•:\n776 ngÆ°á»i Ä‘Æ°á»£c phÃ¢n ngáº«u nhiÃªn vÃ o 4 Ä‘iá»u kiá»‡n thÃ­ nghiá»‡m\n35 ngÆ°á»i khÃ´ng Ä‘Æ°á»£c phÃ¢n ngáº«u nhiÃªn do vÃ o muá»™n hoáº·c cáº¥p báº­c cao hÆ¡n band 3\nCÃ¡c nhÃ³m lÃ m viá»‡c tá»« xa qua Microsoft Teams\nChia lÃ m 4 nhÃ³m:\nCÃ¡ nhÃ¢n khÃ´ng sá»­ dá»¥ng AI\nNhÃ³m 2 ngÆ°á»i khÃ´ng sá»­ dá»¥ng AI\nCÃ¡ nhÃ¢n sá»­ dá»¥ng AI\nNhÃ³m 2 ngÆ°á»i sá»­ dá»¥ng AI\nCÃ´ng cá»¥ AI Ä‘Æ°á»£c sá»­ dá»¥ng:\nDá»±a trÃªn GPT-4 vÃ  truy cáº­p thÃ´ng qua Microsoft Azure\nNgÆ°á»i tham gia á»Ÿ Ä‘iá»u kiá»‡n cÃ³ AI Ä‘Æ°á»£c Ä‘Ã o táº¡o 1 giá» vá» cÃ¡ch tÆ°Æ¡ng tÃ¡c vá»›i cÃ´ng cá»¥ GenAI\nPháº¡m vi tá»• chá»©c:\nÄÆ°á»£c thá»±c hiá»‡n á»Ÿ 4 Ä‘Æ¡n vá»‹ kinh doanh: ChÄƒm sÃ³c tráº» em, ChÄƒm sÃ³c phá»¥ ná»¯, ChÄƒm sÃ³c cÃ¡ nhÃ¢n vÃ  ChÄƒm sÃ³c rÄƒng miá»‡ng Táº¡i 2 khu vá»±c Ä‘á»‹a lÃ½: ChÃ¢u Ã‚u vÃ  ChÃ¢u Má»¹ Viá»‡c chá»n P\u0026amp;G vá»›i quy mÃ´ lá»›n vÃ  pháº¡m vi toÃ n cáº§u nhÆ° váº­y giÃºp tÄƒng tÃ­nh Ä‘áº¡i diá»‡n vÃ  Ä‘á»™ tin cáº­y cá»§a káº¿t quáº£ nghiÃªn cá»©u. Thá»i gian:\nThÃ­ nghiá»‡m Ä‘Æ°á»£c thá»±c hiá»‡n trong khoáº£ng thá»i gian tá»« thÃ¡ng 5 Ä‘áº¿n thÃ¡ng 7 nÄƒm 2024 DÆ°á»›i hÃ¬nh thá»©c há»™i tháº£o phÃ¡t triá»ƒn sáº£n pháº©m áº£o kÃ©o dÃ i má»™t ngÃ y CÃ¡ch thá»©c thu tháº­p dá»¯ liá»‡u:\nThu tháº­p trÆ°á»›c thÃ­ nghiá»‡m: thÃ´ng tin cÃ¡ nhÃ¢n ngÆ°á»i tham gia Trong quÃ¡ trÃ¬nh: ghi láº¡i táº¥t cáº£ cÃ¡c lá»‡nh vÃ  pháº£n há»“i cá»§a GenAI, báº£n ghi tÆ°Æ¡ng tÃ¡c nhÃ³m Sau thÃ­ nghiá»‡m: kháº£o sÃ¡t vÃ  phá»ng váº¥n má»™t sá»‘ ngÆ°á»i tham gia Biáº¿n sá»‘ Ä‘o lÆ°á»ng:\nHiá»‡u suáº¥t: Cháº¥t lÆ°á»£ng giáº£i phÃ¡p (thang Ä‘iá»ƒm 1-10) ChuyÃªn mÃ´n: TÃ­nh ká»¹ thuáº­t cá»§a giáº£i phÃ¡p (thang Ä‘iá»ƒm 1-7) TÃ­nh cá»™ng Ä‘á»“ng : Cáº£m xÃºc tÃ­ch cá»±c vÃ  tiÃªu cá»±c (thang Ä‘iá»ƒm 1-7) 2. Káº¿t quáº£ Má»™t vÃ i káº¿t quáº£ mÃ¬nh rÃºt ra khi Ä‘á»c bÃ i viáº¿t\n2.1. Vá» hiá»‡u suáº¥t NhÃ³m khÃ´ng AI cáº£i thiá»‡n 0.24 Ä‘á»™ lá»‡ch chuáº©n so vá»›i cÃ¡ nhÃ¢n khÃ´ng AI (p \u0026lt; 0.05) CÃ¡ nhÃ¢n cÃ³ AI cáº£i thiá»‡n 0.37 Ä‘á»™ lá»‡ch chuáº©n so vá»›i cÃ¡ nhÃ¢n khÃ´ng AI (p \u0026lt; 0.01) NhÃ³m cÃ³ AI cáº£i thiá»‡n 0.39 Ä‘á»™ lá»‡ch chuáº©n so vá»›i cÃ¡ nhÃ¢n khÃ´ng AI (p \u0026lt; 0.01) CÃ¡ nhÃ¢n cÃ³ AI vÃ  nhÃ³m cÃ³ AI cÃ³ cháº¥t lÆ°á»£ng giáº£i phÃ¡p tÆ°Æ¡ng Ä‘Æ°Æ¡ng CÃ¡ nhÃ¢n cÃ³ AI giáº£m 16.4% thá»i gian hoÃ n thÃ nh nhiá»‡m vá»¥ NhÃ³m cÃ³ AI giáº£m 12.7% thá»i gian hoÃ n thÃ nh nhiá»‡m vá»¥ NhÃ³m cÃ³ AI táº¡o ra giáº£i phÃ¡p dÃ i hÆ¡n Ä‘Ã¡ng ká»ƒ 2.2. Vá» chuyÃªn mÃ´n NhÃ¢n viÃªn lÃ m viá»‡c má»™t mÃ¬nh vá»›i AI Ä‘áº¡t hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhÃ³m cÃ³ Ã­t nháº¥t má»™t nhÃ¢n viÃªn core-job ( 1 ká»¹ thuáº­t + 1 chuyÃªn mÃ´n) AI giÃºp xÃ³a nhÃ²a ranh giá»›i giá»¯a Ã½ tÆ°á»Ÿng ká»¹ thuáº­t vÃ  thÆ°Æ¡ng máº¡i Sá»± khÃ¡c biá»‡t vá» tÃ­nh ká»¹ thuáº­t/thÆ°Æ¡ng máº¡i giá»¯a nhÃ¢n viÃªn R\u0026amp;D vÃ  Commercial biáº¿n máº¥t khi sá»­ dá»¥ng AI KhÃ´ng cÃ³ sá»± khÃ¡c biá»‡t vá» Ä‘iá»ƒm cháº¥t lÆ°á»£ng dá»±a trÃªn Ä‘á»‹nh hÆ°á»›ng ká»¹ thuáº­t cá»§a giáº£i phÃ¡p 2.3. Vá» tÃ­nh cá»™ng Ä‘á»“ng CÃ¡ nhÃ¢n sá»­ dá»¥ng AI tÄƒng 0.457 Ä‘á»™ lá»‡ch chuáº©n cáº£m xÃºc tÃ­ch cá»±c (p \u0026lt; 0.01) NhÃ³m sá»­ dá»¥ng AI tÄƒng 0.635 Ä‘á»™ lá»‡ch chuáº©n cáº£m xÃºc tÃ­ch cá»±c (p \u0026lt; 0.01) CÃ¡ nhÃ¢n sá»­ dá»¥ng AI giáº£m 0.233 Ä‘á»™ lá»‡ch chuáº©n cáº£m xÃºc tiÃªu cá»±c (p \u0026lt; 0.05) NhÃ³m sá»­ dá»¥ng AI giáº£m 0.235 Ä‘á»™ lá»‡ch chuáº©n cáº£m xÃºc tiÃªu cá»±c (p \u0026lt; 0.05) 2.4. Káº¿t quáº£ ná»•i báº­t khÃ¡c: NhÃ³m cÃ³ AI cÃ³ kháº£ nÄƒng táº¡o ra giáº£i phÃ¡p trong top 10% cao hÆ¡n 9.2 Ä‘iá»ƒm pháº§n trÄƒm so vá»›i nhÃ³m kiá»ƒm soÃ¡t PhÃ¢n phá»‘i Ã½ tÆ°á»Ÿng cá»§a nhÃ³m cÃ³ AI cÃ¢n báº±ng hÆ¡n, giáº£m áº£nh hÆ°á»Ÿng thá»‘ng trá»‹ Nhiá»u ngÆ°á»i tham gia giá»¯ láº¡i hÆ¡n 75% ná»™i dung do AI táº¡o ra trong giáº£i phÃ¡p cuá»‘i cÃ¹ng Má»™t vÃ i thÃ´ng sá»‘ trong bÃ i bÃ¡o\nCÃ²n nhiá»u thÃ´ng sá»‘ quan trá»ng khÃ¡c, cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c bÃ i bÃ¡o Ä‘á»ƒ cÃ³ thÃ´ng tin chi tiáº¿t.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ Ä‘á»c bÃ i, háº¹n gáº·p láº¡i cÃ¡c báº¡n á»Ÿ bÃ i viáº¿t tiáº¿p theo\nNguá»“n tham kháº£o\nhttps://www.hbs.edu/faculty/Pages/item.aspx?num=67197\nhttps://www.nber.org/papers/w33641\n","date":"Apr 7, 2025","img":"https://unsplash.it/1920/1080?image=228","permalink":"/blog/2025-04-07-generative-ai-expertise-teamwork/","series":null,"tags":["Artificial intelligence","Teamwork","Human-machine interaction","Productivity","Skills","Innovation","Field experiment"],"title":"Song Kiáº¿m Há»£p BÃ­ch Giá»¯a Generative Ai VÃ  ChuyÃªn ViÃªn. Náº¥c Thang LÃªn ThiÃªn ÄÆ°á»ng"},{"categories":null,"content":" LÃ½ thuyáº¿t vÃ  bá»‘i cáº£nh ra Ä‘á»i cá»§a The Dictator Game 7. VÃ­ dá»¥ trong doanh nghiá»‡p Bá»‘i cáº£nh CÃ¡c ká»‹ch báº£n phÃ¢n bá»• tiá»n thÆ°á»Ÿng PhÃ¢n tÃ­ch hÃ nh vi cá»§a Ã´ng trÆ°á»Ÿng phÃ²ng á»¨ng dá»¥ng cá»§a vÃ­ dá»¥ nÃ y trong doanh nghiá»‡p 8. So sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c LÃ½ thuyáº¿t vÃ  bá»‘i cáº£nh ra Ä‘á»i cá»§a The Dictator Game 1. LÃ½ thuyáº¿t ná»n táº£ng The Dictator Game lÃ  má»™t biáº¿n thá»ƒ Ä‘Æ¡n giáº£n cá»§a cÃ¡c mÃ´ hÃ¬nh thá»­ nghiá»‡m trong lÃ½ thuyáº¿t trÃ² chÆ¡i (Game Theory), má»™t lÄ©nh vá»±c nghiÃªn cá»©u vá» cÃ¡ch con ngÆ°á»i Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh trong cÃ¡c tÃ¬nh huá»‘ng tÆ°Æ¡ng tÃ¡c chiáº¿n lÆ°á»£c. LÃ½ thuyáº¿t trÃ² chÆ¡i táº­p trung vÃ o viá»‡c phÃ¢n tÃ­ch cÃ¡c lá»±a chá»n mÃ  con ngÆ°á»i thá»±c hiá»‡n khi káº¿t quáº£ khÃ´ng chá»‰ phá»¥ thuá»™c vÃ o hÃ nh Ä‘á»™ng cá»§a há» mÃ  cÃ²n phá»¥ thuá»™c vÃ o hÃ nh Ä‘á»™ng cá»§a nhá»¯ng ngÆ°á»i khÃ¡c.\nTrong The Dictator Game, trá»ng tÃ¢m lÃ  nghiÃªn cá»©u hÃ nh vi vá»‹ tha (altruism) vÃ  sá»± cÃ´ng báº±ng (fairness) â€“ hai yáº¿u tá»‘ quan trá»ng trong kinh táº¿ há»c hÃ nh vi (Behavioral Economics). Máº·c dÃ¹ lÃ½ thuyáº¿t kinh táº¿ truyá»n thá»‘ng giáº£ Ä‘á»‹nh ráº±ng con ngÆ°á»i luÃ´n hÃ nh Ä‘á»™ng vÃ¬ lá»£i Ã­ch cÃ¡ nhÃ¢n tá»‘i Ä‘a (rational self-interest), cÃ¡c thÃ­ nghiá»‡m nhÆ° The Dictator Game Ä‘Ã£ chá»©ng minh ráº±ng con ngÆ°á»i thÆ°á»ng cÃ³ xu hÆ°á»›ng quan tÃ¢m Ä‘áº¿n lá»£i Ã­ch cá»§a ngÆ°á»i khÃ¡c hoáº·c tuÃ¢n theo cÃ¡c chuáº©n má»±c xÃ£ há»™i.\n2. Bá»‘i cáº£nh ra Ä‘á»i The Dictator Game Ä‘Æ°á»£c phÃ¡t triá»ƒn tá»« Ultimatum Game, má»™t mÃ´ hÃ¬nh thá»­ nghiá»‡m ná»•i tiáº¿ng trong lÃ½ thuyáº¿t trÃ² chÆ¡i. Ultimatum Game yÃªu cáº§u hai ngÆ°á»i chÆ¡i tham gia: má»™t ngÆ°á»i Ä‘á» xuáº¥t cÃ¡ch chia sáº» má»™t khoáº£n tiá»n (Proposer) vÃ  ngÆ°á»i kia cÃ³ quyá»n cháº¥p nháº­n hoáº·c tá»« chá»‘i Ä‘á» xuáº¥t Ä‘Ã³ (Responder). Náº¿u Responder tá»« chá»‘i, cáº£ hai sáº½ khÃ´ng nháº­n Ä‘Æ°á»£c gÃ¬.\nTuy nhiÃªn, Ultimatum Game cÃ³ má»™t nhÆ°á»£c Ä‘iá»ƒm lá»›n: pháº£n á»©ng cá»§a Responder cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n quyáº¿t Ä‘á»‹nh cá»§a Proposer, dáº«n Ä‘áº¿n viá»‡c Proposer Ä‘Æ°a ra cÃ¡c Ä‘á» xuáº¥t \u0026ldquo;cÃ´ng báº±ng\u0026rdquo; hÆ¡n Ä‘á»ƒ trÃ¡nh bá»‹ tá»« chá»‘i. Äiá»u nÃ y lÃ m phá»©c táº¡p viá»‡c Ä‘Ã¡nh giÃ¡ liá»‡u hÃ nh vi cá»§a Proposer cÃ³ xuáº¥t phÃ¡t tá»« lÃ²ng vá»‹ tha tháº­t sá»± hay chá»‰ lÃ  má»™t chiáº¿n lÆ°á»£c Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu cÃ¡ nhÃ¢n.\nÄá»ƒ kháº¯c phá»¥c váº¥n Ä‘á» nÃ y, Daniel Kahneman, Jack Knetsch vÃ  Richard Thaler Ä‘Ã£ giá»›i thiá»‡u The Dictator Game vÃ o Ä‘áº§u nhá»¯ng nÄƒm 1980. TrÃ² chÆ¡i nÃ y loáº¡i bá» vai trÃ² cá»§a Responder, khiáº¿n quyáº¿t Ä‘á»‹nh cá»§a ngÆ°á»i cho (Dictator) trá»Ÿ nÃªn hoÃ n toÃ n tá»± do vÃ  khÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi Ã¡p lá»±c xÃ£ há»™i hoáº·c kháº£ nÄƒng bá»‹ tá»« chá»‘i.\n3. CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng: Hai ngÆ°á»i chÆ¡i Ä‘Æ°á»£c chá»n: NgÆ°á»i cho (Dictator) vÃ  NgÆ°á»i nháº­n (Recipient). NgÆ°á»i cho Ä‘Æ°á»£c trao má»™t sá»‘ tiá»n cá»‘ Ä‘á»‹nh (vÃ­ dá»¥: 100 USD). NgÆ°á»i cho cÃ³ quyá»n quyáº¿t Ä‘á»‹nh cÃ¡ch phÃ¢n chia sá»‘ tiá»n nÃ y giá»¯a mÃ¬nh vÃ  ngÆ°á»i nháº­n. NgÆ°á»i nháº­n khÃ´ng cÃ³ quyá»n pháº£n há»“i, thÆ°Æ¡ng lÆ°á»£ng hay tá»« chá»‘i. Káº¿t quáº£ cuá»‘i cÃ¹ng phá»¥ thuá»™c hoÃ n toÃ n vÃ o quyáº¿t Ä‘á»‹nh cá»§a ngÆ°á»i cho. VÃ­ dá»¥:\nNáº¿u ngÆ°á»i cho quyáº¿t Ä‘á»‹nh giá»¯ 80 USD vÃ  táº·ng 20 USD cho ngÆ°á»i nháº­n, thÃ¬ káº¿t quáº£ lÃ  ngÆ°á»i cho giá»¯ 80% tÃ i sáº£n, ngÆ°á»i nháº­n giá»¯ 20%. Náº¿u ngÆ°á»i cho quyáº¿t Ä‘á»‹nh giá»¯ toÃ n bá»™ sá»‘ tiá»n, ngÆ°á»i nháº­n sáº½ khÃ´ng nháº­n Ä‘Æ°á»£c gÃ¬. 4. Má»¥c tiÃªu nghiÃªn cá»©u ban Ä‘áº§u Má»¥c tiÃªu chÃ­nh cá»§a The Dictator Game lÃ  kiá»ƒm tra:\nLÃ²ng vá»‹ tha tháº­t sá»±: Liá»‡u con ngÆ°á»i cÃ³ sáºµn sÃ ng chia sáº» tÃ i sáº£n vá»›i ngÆ°á»i khÃ¡c ngay cáº£ khi khÃ´ng cÃ³ báº¥t ká»³ Ã¡p lá»±c nÃ o? áº¢nh hÆ°á»Ÿng cá»§a chuáº©n má»±c xÃ£ há»™i: HÃ nh vi cá»§a con ngÆ°á»i cÃ³ bá»‹ chi phá»‘i bá»Ÿi cÃ¡c quy táº¯c vÄƒn hÃ³a, Ä‘áº¡o Ä‘á»©c hoáº·c xÃ£ há»™i khÃ´ng? Sá»± cÃ´ng báº±ng trong phÃ¢n phá»‘i tÃ i sáº£n: Con ngÆ°á»i cÃ³ xu hÆ°á»›ng Æ°u tiÃªn sá»± cÃ´ng báº±ng hay lá»£i Ã­ch cÃ¡ nhÃ¢n? Káº¿t quáº£ ban Ä‘áº§u tá»« cÃ¡c thÃ­ nghiá»‡m cho tháº¥y ráº±ng:\nPháº§n lá»›n ngÆ°á»i chÆ¡i váº«n chia sáº» má»™t pháº§n tÃ i sáº£n vá»›i ngÆ°á»i nháº­n, máº·c dÃ¹ há» khÃ´ng báº¯t buá»™c pháº£i lÃ m váº­y. Tuy nhiÃªn, má»©c Ä‘á»™ chia sáº» thÆ°á»ng Ã­t hÆ¡n so vá»›i Ultimatum Game, Ä‘iá»u nÃ y cho tháº¥y ráº±ng má»™t pháº§n hÃ nh vi vá»‹ tha trong Ultimatum Game cÃ³ thá»ƒ xuáº¥t phÃ¡t tá»« Ã¡p lá»±c xÃ£ há»™i. 5. ThÃ­ nghiá»‡m ThÃ­ nghiá»‡m The Dictator Game ban Ä‘áº§u Ä‘Æ°á»£c thá»±c hiá»‡n táº¡i Hoa Ká»³ vÃ  Canada lÃ  nhá»¯ng quá»‘c gia phÃ¡t triá»ƒn vá»›i ná»n vÄƒn hÃ³a cÃ¡ nhÃ¢n chá»§ nghÄ©a (individualistic culture), phÃ¹ há»£p Ä‘á»ƒ kiá»ƒm tra giáº£ thuyáº¿t vá» lá»£i Ã­ch cÃ¡ nhÃ¢n tá»‘i Ä‘a. V á»›i táº­p máº«u chá»§ yáº¿u lÃ  sinh viÃªn Ä‘áº¡i há»c Princeton vÃ  University of British Columbia.\nSau Ä‘Ã³, thÃ­ nghiá»‡m Ä‘Æ°á»£c má»Ÿ rá»™ng sang nhiá»u quá»‘c gia trÃªn tháº¿ giá»›i, bao gá»“m cÃ¡c nÆ°á»›c phÃ¡t triá»ƒn vÃ  Ä‘ang phÃ¡t triá»ƒn, Ä‘á»ƒ nghiÃªn cá»©u rá»™ng hÆ¡n vá» sá»± áº£nh hÆ°á»Ÿng cá»§a vÄƒn hÃ³a, kinh táº¿ vÃ  tÃ´n giÃ¡o.\nMá»Ÿ rá»™ng sang cÃ¡c khu vá»±c khÃ¡c NghiÃªn cá»©u toÃ n cáº§u: Sau khi thÃ­ nghiá»‡m trá»Ÿ nÃªn phá»• biáº¿n, cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã£ tiáº¿n hÃ nh nÃ³ á»Ÿ nhiá»u quá»‘c gia khÃ¡c nhau, bao gá»“m cáº£ cÃ¡c nÆ°á»›c Ä‘ang phÃ¡t triá»ƒn. Má»™t sá»‘ vÃ­ dá»¥ ná»•i báº­t:\nChÃ¢u Ã‚u: CÃ¡c nghiÃªn cá»©u táº¡i Anh, Äá»©c, HÃ  Lan nháº±m so sÃ¡nh hÃ nh vi vá»‹ tha giá»¯a cÃ¡c ná»n vÄƒn hÃ³a TÃ¢y Ã‚u. ChÃ¢u Ã: Nháº­t Báº£n, Trung Quá»‘c, áº¤n Äá»™ Ä‘Æ°á»£c nghiÃªn cá»©u Ä‘á»ƒ xem xÃ©t tÃ¡c Ä‘á»™ng cá»§a vÄƒn hÃ³a táº­p thá»ƒ (collectivist culture). ChÃ¢u Phi vÃ  Má»¹ Latinh: CÃ¡c nghiÃªn cá»©u táº¡i Kenya, Uganda, Brazil nháº±m tÃ¬m hiá»ƒu hÃ nh vi chia sáº» trong cÃ¡c cá»™ng Ä‘á»“ng cÃ³ thu nháº­p tháº¥p. PhÃ¡t hiá»‡n vá» sá»± khÃ¡c biá»‡t vÄƒn hÃ³a:\nTáº¡i cÃ¡c nÆ°á»›c cÃ¡ nhÃ¢n chá»§ nghÄ©a (nhÆ° Hoa Ká»³, Canada), tá»· lá»‡ chia sáº» thÆ°á»ng tháº¥p hÆ¡n, pháº£n Ã¡nh xu hÆ°á»›ng Æ°u tiÃªn lá»£i Ã­ch cÃ¡ nhÃ¢n. Táº¡i cÃ¡c nÆ°á»›c táº­p thá»ƒ chá»§ nghÄ©a (nhÆ° Nháº­t Báº£n, Trung Quá»‘c), tá»· lá»‡ chia sáº» thÆ°á»ng cao hÆ¡n, do áº£nh hÆ°á»Ÿng cá»§a chuáº©n má»±c xÃ£ há»™i vÃ  giÃ¡ trá»‹ cá»™ng Ä‘á»“ng. NghiÃªn cá»©u trong cÃ¡c cá»™ng Ä‘á»“ng Ä‘áº·c thÃ¹ Cá»™ng Ä‘á»“ng nÃ´ng thÃ´n vÃ  Ä‘Ã´ thá»‹:\nCÃ¡c nghiÃªn cá»©u so sÃ¡nh hÃ nh vi cá»§a ngÆ°á»i dÃ¢n sá»‘ng á»Ÿ nÃ´ng thÃ´n vÃ  Ä‘Ã´ thá»‹, nháº±m Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a mÃ´i trÆ°á»ng sá»‘ng. Káº¿t quáº£ cho tháº¥y ráº±ng ngÆ°á»i dÃ¢n nÃ´ng thÃ´n thÆ°á»ng chia sáº» nhiá»u hÆ¡n, do má»©c Ä‘á»™ gáº¯n káº¿t cá»™ng Ä‘á»“ng cao hÆ¡n. Cá»™ng Ä‘á»“ng thu nháº­p tháº¥p:\nCÃ¡c thÃ­ nghiá»‡m táº¡i cÃ¡c quá»‘c gia Ä‘ang phÃ¡t triá»ƒn hoáº·c khu vá»±c nghÃ¨o khÃ³ thÆ°á»ng cho tháº¥y tá»· lá»‡ chia sáº» cao hÆ¡n, dÃ¹ sá»‘ tiá»n ban Ä‘áº§u ráº¥t nhá». Äiá»u nÃ y pháº£n Ã¡nh vai trÃ² cá»§a lÃ²ng tá»‘t vÃ  sá»± tÆ°Æ¡ng trá»£ trong cÃ¡c cá»™ng Ä‘á»“ng khÃ³ khÄƒn. 6. Káº¿t quáº£ áº¢nh hÆ°á»Ÿng cá»§a vÄƒn hÃ³a: VÄƒn hÃ³a Ä‘Ã³ng vai trÃ² quan trá»ng trong viá»‡c Ä‘á»‹nh hÃ¬nh hÃ nh vi cá»§a Dictator. VÃ­ dá»¥:\ná» cÃ¡c quá»‘c gia TÃ¢y phÆ°Æ¡ng (cÃ¡ nhÃ¢n chá»§ nghÄ©a), Dictator thÆ°á»ng giá»¯ láº¡i pháº§n lá»›n tÃ i sáº£n. á» cÃ¡c quá»‘c gia ÄÃ´ng phÆ°Æ¡ng (táº­p thá»ƒ chá»§ nghÄ©a), Dictator cÃ³ xu hÆ°á»›ng chia sáº» nhiá»u hÆ¡n. áº¢nh hÆ°á»Ÿng cá»§a kinh táº¿: Thu nháº­p bÃ¬nh quÃ¢n Ä‘áº§u ngÆ°á»i cÅ©ng áº£nh hÆ°á»Ÿng Ä‘áº¿n hÃ nh vi chia sáº». Trong cÃ¡c cá»™ng Ä‘á»“ng thu nháº­p tháº¥p, lÃ²ng vá»‹ tha thÆ°á»ng cao hÆ¡n do sá»± tÆ°Æ¡ng trá»£ láº«n nhau lÃ  yáº¿u tá»‘ sá»‘ng cÃ²n.\náº¢nh hÆ°á»Ÿng cá»§a tÃ´n giÃ¡o: CÃ¡c nghiÃªn cá»©u táº¡i cÃ¡c quá»‘c gia cÃ³ truyá»n thá»‘ng tÃ´n giÃ¡o máº¡nh máº½ (vÃ­ dá»¥: Há»“i giÃ¡o, Pháº­t giÃ¡o) thÆ°á»ng cho tháº¥y tá»· lá»‡ chia sáº» cao hÆ¡n, do cÃ¡c giÃ¡ trá»‹ Ä‘áº¡o Ä‘á»©c khuyáº¿n khÃ­ch lÃ²ng tá»‘t vÃ  sá»± cÃ´ng báº±ng.\nKinh táº¿ há»c cá»• Ä‘iá»ƒn giáº£ Ä‘á»‹nh ráº±ng con ngÆ°á»i luÃ´n hÃ nh Ä‘á»™ng vÃ¬ lá»£i Ã­ch cÃ¡ nhÃ¢n tá»‘i Ä‘a, nhÆ°ng cÃ¡c nghiÃªn cá»©u thá»±c nghiá»‡m nhÆ° The Dictator Game Ä‘Ã£ chá»‰ ra ráº±ng con ngÆ°á»i thÆ°á»ng hÃ nh xá»­ theo cÃ¡ch phi lÃ½ trÃ­ (irrational) hoáº·c chá»‹u áº£nh hÆ°á»Ÿng bá»Ÿi cÃ¡c yáº¿u tá»‘ xÃ£ há»™i, cáº£m xÃºc vÃ  Ä‘áº¡o Ä‘á»©c.\nNhá»¯ng phÃ¡t hiá»‡n tá»« The Dictator Game Ä‘Ã£ gÃ³p pháº§n cá»§ng cá»‘ ná»n táº£ng cho cÃ¡c lÄ©nh vá»±c nhÆ°:\nKinh táº¿ há»c hÃ nh vi: NghiÃªn cá»©u cÃ¡ch con ngÆ°á»i Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh trong thá»±c táº¿, thay vÃ¬ dá»±a trÃªn cÃ¡c giáº£ Ä‘á»‹nh lÃ½ thuyáº¿t. TÃ¢m lÃ½ há»c xÃ£ há»™i: Hiá»ƒu rÃµ hÆ¡n vá» Ä‘á»™ng lá»±c thÃºc Ä‘áº©y lÃ²ng vá»‹ tha, sá»± cÃ´ng báº±ng vÃ  lÃ²ng tham. ChÃ­nh sÃ¡ch cÃ´ng: Thiáº¿t káº¿ cÃ¡c chÆ°Æ¡ng trÃ¬nh phÃºc lá»£i vÃ  há»— trá»£ xÃ£ há»™i phÃ¹ há»£p vá»›i hÃ nh vi thá»±c táº¿ cá»§a con ngÆ°á»i. 7. VÃ­ dá»¥ trong doanh nghiá»‡p HÃ£y tÆ°á»Ÿng tÆ°á»£ng má»™t tÃ¬nh huá»‘ng thá»±c táº¿ trong má»™t doanh nghiá»‡p, nÆ¡i Ã´ng trÆ°á»Ÿng phÃ²ng (giáº£ sá»­ tÃªn lÃ  Ã´ng A) Ä‘Æ°á»£c giao quyá»n quyáº¿t Ä‘á»‹nh phÃ¢n bá»• má»™t khoáº£n tiá»n thÆ°á»Ÿng (vÃ­ dá»¥: 100 triá»‡u Ä‘á»“ng) cho nhÃ³m nhÃ¢n viÃªn cá»§a mÃ¬nh. ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ Ä‘iá»ƒn hÃ¬nh cÃ³ thá»ƒ Ä‘Æ°á»£c so sÃ¡nh vá»›i The Dictator Game, trong Ä‘Ã³ Ã´ng trÆ°á»Ÿng phÃ²ng Ä‘Ã³ng vai trÃ² lÃ  \u0026ldquo;Dictator\u0026rdquo; vÃ  cÃ¡c nhÃ¢n viÃªn lÃ  \u0026ldquo;Recipient\u0026rdquo;.\nBá»‘i cáº£nh Khoáº£n tiá»n thÆ°á»Ÿng: 100 triá»‡u Ä‘á»“ng. NgÆ°á»i quyáº¿t Ä‘á»‹nh: Ã”ng trÆ°á»Ÿng phÃ²ng A. NhÃ³m nhÃ¢n viÃªn: Gá»“m 5 ngÆ°á»i (B, C, D, E, F). Má»¥c tiÃªu cá»§a doanh nghiá»‡p: Khoáº£n tiá»n thÆ°á»Ÿng nháº±m ghi nháº­n Ä‘Ã³ng gÃ³p cá»§a nhÃ³m trong dá»± Ã¡n vá»«a qua. Quyá»n lá»±c cá»§a Ã´ng A: Ã”ng A cÃ³ toÃ n quyá»n quyáº¿t Ä‘á»‹nh cÃ¡ch phÃ¢n bá»• khoáº£n tiá»n nÃ y mÃ  khÃ´ng cáº§n tham kháº£o Ã½ kiáº¿n cá»§a nhÃ¢n viÃªn. CÃ¡c ká»‹ch báº£n phÃ¢n bá»• tiá»n thÆ°á»Ÿng Ká»‹ch báº£n 1: PhÃ¢n bá»• cÃ´ng báº±ng Ã”ng A quyáº¿t Ä‘á»‹nh chia Ä‘á»u khoáº£n tiá»n cho 5 nhÃ¢n viÃªn:\nMá»—i ngÆ°á»i nháº­n 20 triá»‡u Ä‘á»“ng. LÃ½ do: Ã”ng A muá»‘n Ä‘áº£m báº£o sá»± cÃ´ng báº±ng vÃ  trÃ¡nh xung Ä‘á»™t ná»™i bá»™. Ã”ng tin ráº±ng viá»‡c chia Ä‘á»u sáº½ táº¡o Ä‘á»™ng lá»±c lÃ m viá»‡c cho cáº£ nhÃ³m trong tÆ°Æ¡ng lai. Ká»‹ch báº£n 2: PhÃ¢n bá»• theo Ä‘Ã³ng gÃ³p Ã”ng A Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ Ä‘Ã³ng gÃ³p cá»§a tá»«ng nhÃ¢n viÃªn vÃ  quyáº¿t Ä‘á»‹nh phÃ¢n bá»• nhÆ° sau:\nNhÃ¢n viÃªn B: 30 triá»‡u Ä‘á»“ng (Ä‘Ã³ng gÃ³p nhiá»u nháº¥t).\nNhÃ¢n viÃªn C: 25 triá»‡u Ä‘á»“ng (Ä‘Ã³ng gÃ³p quan trá»ng nhÆ°ng Ã­t hÆ¡n B).\nNhÃ¢n viÃªn D: 20 triá»‡u Ä‘á»“ng (Ä‘Ã³ng gÃ³p trung bÃ¬nh).\nNhÃ¢n viÃªn E: 15 triá»‡u Ä‘á»“ng (Ä‘Ã³ng gÃ³p Ã­t hÆ¡n).\nNhÃ¢n viÃªn F: 10 triá»‡u Ä‘á»“ng (Ä‘Ã³ng gÃ³p Ã­t nháº¥t).\nLÃ½ do: Ã”ng A muá»‘n khuyáº¿n khÃ­ch nhÃ¢n viÃªn lÃ m viá»‡c chÄƒm chá»‰ hÆ¡n báº±ng cÃ¡ch khen thÆ°á»Ÿng nhá»¯ng ngÆ°á»i cÃ³ Ä‘Ã³ng gÃ³p lá»›n.\nKá»‹ch báº£n 3: Giá»¯ láº¡i pháº§n lá»›n cho mÃ¬nh Ã”ng A quyáº¿t Ä‘á»‹nh giá»¯ láº¡i 60 triá»‡u Ä‘á»“ng cho báº£n thÃ¢n vÃ  chá»‰ chia 40 triá»‡u Ä‘á»“ng cÃ²n láº¡i cho nhÃ³m:\nNhÃ¢n viÃªn B, C, D: Má»—i ngÆ°á»i nháº­n 10 triá»‡u Ä‘á»“ng.\nNhÃ¢n viÃªn E, F: Má»—i ngÆ°á»i nháº­n 5 triá»‡u Ä‘á»“ng.\nLÃ½ do: Ã”ng A cho ráº±ng mÃ¬nh lÃ  ngÆ°á»i quáº£n lÃ½ dá»± Ã¡n vÃ  chá»‹u trÃ¡ch nhiá»‡m chÃ­nh nÃªn xá»©ng Ä‘Ã¡ng nháº­n pháº§n lá»›n tiá»n thÆ°á»Ÿng.\nKá»‹ch báº£n 4: Chia sáº» hoÃ n toÃ n Ã”ng A quyáº¿t Ä‘á»‹nh táº·ng toÃ n bá»™ 100 triá»‡u Ä‘á»“ng cho nhÃ³m vÃ  khÃ´ng giá»¯ láº¡i báº¥t ká»³ khoáº£n nÃ o:\nMá»—i nhÃ¢n viÃªn nháº­n 20 triá»‡u Ä‘á»“ng. LÃ½ do: Ã”ng A muá»‘n thá»ƒ hiá»‡n lÃ²ng vá»‹ tha vÃ  xÃ¢y dá»±ng tinh tháº§n Ä‘oÃ n káº¿t trong nhÃ³m. Ã”ng tin ráº±ng viá»‡c Ä‘áº§u tÆ° vÃ o nhÃ¢n viÃªn sáº½ mang láº¡i lá»£i Ã­ch lÃ¢u dÃ i cho doanh nghiá»‡p. PhÃ¢n tÃ­ch hÃ nh vi cá»§a Ã´ng trÆ°á»Ÿng phÃ²ng Náº¿u Ã´ng A chá»n Ká»‹ch báº£n 1 hoáº·c 4:\nHÃ nh vi cá»§a Ã´ng A pháº£n Ã¡nh lÃ²ng vá»‹ tha vÃ  mong muá»‘n duy trÃ¬ sá»± cÃ´ng báº±ng trong nhÃ³m. Äiá»u nÃ y cÃ³ thá»ƒ giÃºp tÄƒng cÆ°á»ng niá»m tin vÃ  Ä‘á»™ng lá»±c lÃ m viá»‡c cá»§a nhÃ¢n viÃªn, vÃ¬ há» cáº£m tháº¥y Ä‘Æ°á»£c tÃ´n trá»ng vÃ  ghi nháº­n. Náº¿u Ã´ng A chá»n Ká»‹ch báº£n 2:\nHÃ nh vi cá»§a Ã´ng A pháº£n Ã¡nh sá»± cÃ´ng báº±ng dá»±a trÃªn Ä‘Ã³ng gÃ³p. CÃ¡ch phÃ¢n bá»• nÃ y cÃ³ thá»ƒ khuyáº¿n khÃ­ch nhÃ¢n viÃªn lÃ m viá»‡c chÄƒm chá»‰ hÆ¡n trong tÆ°Æ¡ng lai, nhÆ°ng cÅ©ng cÃ³ thá»ƒ gÃ¢y ra xung Ä‘á»™t náº¿u nhÃ¢n viÃªn cáº£m tháº¥y Ä‘Ã¡nh giÃ¡ khÃ´ng cÃ´ng báº±ng. Náº¿u Ã´ng A chá»n Ká»‹ch báº£n 3:\nHÃ nh vi cá»§a Ã´ng A pháº£n Ã¡nh lá»£i Ã­ch cÃ¡ nhÃ¢n tá»‘i Ä‘a. Äiá»u nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n báº¥t mÃ£n trong nhÃ³m nhÃ¢n viÃªn, giáº£m tinh tháº§n lÃ m viá»‡c vÃ  tháº­m chÃ­ gÃ¢y ra thÃ¡i Ä‘á»™ tiÃªu cá»±c Ä‘á»‘i vá»›i Ã´ng A vÃ  doanh nghiá»‡p. á»¨ng dá»¥ng cá»§a vÃ­ dá»¥ nÃ y trong doanh nghiá»‡p ÄÃ¡nh giÃ¡ nÄƒng lá»±c lÃ£nh Ä‘áº¡o:\nCÃ¡ch Ã´ng A phÃ¢n bá»• tiá»n thÆ°á»Ÿng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ phong cÃ¡ch lÃ£nh Ä‘áº¡o cá»§a Ã´ng. VÃ­ dá»¥: Má»™t nhÃ  lÃ£nh Ä‘áº¡o cÃ´ng báº±ng vÃ  vá»‹ tha thÆ°á»ng Ä‘Æ°á»£c nhÃ¢n viÃªn yÃªu máº¿n vÃ  tÃ´n trá»ng. Má»™t nhÃ  lÃ£nh Ä‘áº¡o Ã­ch ká»· cÃ³ thá»ƒ gÃ¢y ra xung Ä‘á»™t ná»™i bá»™ vÃ  lÃ m giáº£m hiá»‡u suáº¥t lÃ m viá»‡c cá»§a nhÃ³m. XÃ¢y dá»±ng vÄƒn hÃ³a doanh nghiá»‡p:\nNáº¿u doanh nghiá»‡p khuyáº¿n khÃ­ch sá»± cÃ´ng báº±ng vÃ  há»£p tÃ¡c, cÃ¡c nhÃ  quáº£n lÃ½ nÃªn há»c há»i tá»« Ká»‹ch báº£n 1 hoáº·c 4. NgÆ°á»£c láº¡i, náº¿u doanh nghiá»‡p táº­p trung vÃ o hiá»‡u suáº¥t cÃ¡ nhÃ¢n, Ká»‹ch báº£n 2 cÃ³ thá»ƒ phÃ¹ há»£p hÆ¡n. TÄƒng cÆ°á»ng lÃ²ng trung thÃ nh cá»§a nhÃ¢n viÃªn:\nKhi nhÃ¢n viÃªn cáº£m tháº¥y Ä‘Æ°á»£c ghi nháº­n vÃ  Ä‘á»‘i xá»­ cÃ´ng báº±ng, há» cÃ³ xu hÆ°á»›ng gáº¯n bÃ³ lÃ¢u dÃ i vá»›i doanh nghiá»‡p. Kiá»ƒm tra tÃ­nh minh báº¡ch:\nDoanh nghiá»‡p cÃ³ thá»ƒ sá»­ dá»¥ng tÃ¬nh huá»‘ng nÃ y Ä‘á»ƒ kiá»ƒm tra má»©c Ä‘á»™ minh báº¡ch vÃ  cÃ´ng báº±ng trong cÃ¡c chÃ­nh sÃ¡ch lÆ°Æ¡ng thÆ°á»Ÿng. VÃ­ dá»¥ vá» viá»‡c Ã´ng trÆ°á»Ÿng phÃ²ng chia thÆ°á»Ÿng cho nhÃ¢n viÃªn lÃ  má»™t minh há»a rÃµ rÃ ng cho The Dictator Game trong bá»‘i cáº£nh doanh nghiá»‡p. CÃ¡ch Ã´ng trÆ°á»Ÿng phÃ²ng phÃ¢n bá»• tiá»n thÆ°á»Ÿng khÃ´ng chá»‰ áº£nh hÆ°á»Ÿng Ä‘áº¿n má»‘i quan há»‡ giá»¯a Ã´ng vÃ  nhÃ¢n viÃªn mÃ  cÃ²n tÃ¡c Ä‘á»™ng Ä‘áº¿n vÄƒn hÃ³a vÃ  hiá»‡u suáº¥t lÃ m viá»‡c cá»§a cáº£ nhÃ³m.\n8. So sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c Ultimatum Game vs. The Dictator Game Äáº·c Ä‘iá»ƒm Ultimatum Game The Dictator Game Sá»‘ ngÆ°á»i tham gia 2 (Proposer vÃ  Responder) 2 (Dictator vÃ  Recipient) Quyá»n lá»±c cá»§a Responder CÃ³ quyá»n cháº¥p nháº­n hoáº·c tá»« chá»‘i KhÃ´ng cÃ³ quyá»n pháº£n há»“i Ãp lá»±c xÃ£ há»™i CÃ³ (Proposer sá»£ bá»‹ tá»« chá»‘i) KhÃ´ng Káº¿t quáº£ ThÆ°á»ng cÃ´ng báº±ng hÆ¡n ThÆ°á»ng Ã­t cÃ´ng báº±ng hÆ¡n BÃ i viáº¿t dÆ°á»›i gÃ³c nhÃ¬n cá»§a má»™t con IT quÃ¨n, tháº±ng IT lá», viáº¿t vá» má»™t váº¥n Ä‘á» kinh táº¿, bÃ  con chuyÃªn ngÃ nh tháº¥y sai thÃ¬ hoan há»‰ cÃ²m mÃªn nháº¹ nhÃ ng, Ä‘á»«ng buÃ´n lá»i cay Ä‘áº¯ng.\nCáº£m Æ¡n báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\nNguá»“n tham kháº£o\ngÃµ tá»« khoÃ¡ The Dictator Game vÃ  tÃ¬m cÃ¡c cuá»‘n sau, má»—i cuá»‘n thÃ¬ tÃ¡c giáº£ sáº½ sá»­ dá»¥ng lÃ½ thuyáº¿t cho cÃ¡c táº­p máº«u khÃ¡c nhau vÃ  Ä‘Æ°a ra káº¿t luáº­n, máº¥y sÃ¡ch Ä‘Ã³ toÃ n cÃ³ báº£n quyá»n nÃªn hÆ¡i khÃ³ kiáº¿m. CÃ³ thá»ƒ tÃ¬m qua ResearchGate hoáº·c gá»­i liÃªn há»‡ vá»›i tÃ¡c giáº£.\nDaniel Kahneman, Jack Knetsch vÃ  Richard Thaler (1986) Fairness and the Assumptions of Economics.\nErnst Fehr vÃ  Klaus Schmidt (1999) Ernst Fehr vÃ  Klaus Schmidt (1999) A Theory of Fairness, Competition, and Cooperation\nJoseph Henrich at el. (2005) Economic Man\u0026rsquo; in Cross-Cultural Perspective: Behavioral Experiments in 15 Small-Scale Societies.\nColin Camerer (2003) Behavioral Game Theory: Experiments in Strategic Interaction\nRichard Thaler (2015) Misbehaving: The Making of Behavioral Economics\nHerbert Gintis (2000) Game Theory Evolving: A Problem-Centered Introduction to Modeling Strategic Interaction\nDan Ariely (2008) Predictably Irrational: The Hidden Forces That Shape Our Decisions . HarperCollins.\n","date":"Apr 7, 2025","img":"https://unsplash.it/1920/1080?image=229","permalink":"/blog/2025-04-07-the-dictator-game/","series":null,"tags":["Game Theory"],"title":"The Dictator Game - TrÃ² ChÆ¡i Äá»™c TÃ i"},{"categories":null,"content":" 1. Lá»‹ch sá»­ hÃ¬nh thÃ nh \u0026amp; phÃ¡t triá»ƒn 2. NgÃ´n ngá»¯ láº­p trÃ¬nh 3. PhÃ¢n tÃ­ch Æ¯u vÃ  NhÆ°á»£c Ä‘iá»ƒm 4. So sÃ¡nh kiáº¿n trÃºc 5. Gá»£i Ã½ nÃªn sá»­ dá»¥ng loáº¡i nÃ o? 6. CÃ¡c con sá»‘ biáº¿t nÃ³i 1. Lá»‹ch sá»­ hÃ¬nh thÃ nh \u0026 phÃ¡t triá»ƒn Redis\nLá»‹ch sá»­: ÄÆ°á»£c phÃ¡t triá»ƒn láº§n Ä‘áº§u bá»Ÿi Salvatore Sanfilippo (antirez) vÃ o nÄƒm 2009. Tá»« Ä‘Ã³, Redis nhanh chÃ³ng trá»Ÿ thÃ nh má»™t trong nhá»¯ng há»‡ thá»‘ng lÆ°u trá»¯ dá»¯ liá»‡u trong bá»™ nhá»› phá»• biáº¿n nháº¥t nhá» hiá»‡u suáº¥t cao vÃ  tÃ­nh linh hoáº¡t trong viá»‡c xá»­ lÃ½ cÃ¡c cáº¥u trÃºc dá»¯ liá»‡u phong phÃº. Äá»™i ngÅ© phÃ¡t triá»ƒn: Ban Ä‘áº§u do antirez táº¡o ra, hiá»‡n nay Ä‘Æ°á»£c duy trÃ¬ vÃ  phÃ¡t triá»ƒn bá»Ÿi Redis Labs cÃ¹ng vá»›i sá»± Ä‘Ã³ng gÃ³p máº¡nh máº½ tá»« cá»™ng Ä‘á»“ng mÃ£ nguá»“n má»Ÿ. DragonflyDB\nLá»‹ch sá»­: Ra Ä‘á»i khoáº£ng nÄƒm 2022, DragonflyDB Ä‘Æ°á»£c xÃ¢y dá»±ng nháº±m kháº¯c phá»¥c má»™t sá»‘ háº¡n cháº¿ cá»§a Redis (nhÆ° kiáº¿n trÃºc Ä‘Æ¡n luá»“ng) báº±ng cÃ¡ch táº­n dá»¥ng sá»©c máº¡nh cá»§a cÃ¡c CPU Ä‘a lÃµi vÃ  tá»‘i Æ°u hÃ³a viá»‡c quáº£n lÃ½ bá»™ nhá»›. Äá»™i ngÅ© phÃ¡t triá»ƒn: ÄÆ°á»£c phÃ¡t triá»ƒn bá»Ÿi DragonflyDB Inc., vá»›i sá»± lÃ£nh Ä‘áº¡o cá»§a Itamar Haber vÃ  Ä‘á»™i ngÅ© chuyÃªn sÃ¢u vá» tá»‘i Æ°u hÃ³a hiá»‡u nÄƒng vÃ  kháº£ nÄƒng má»Ÿ rá»™ng. Valkey\nLá»‹ch sá»­: Xuáº¥t hiá»‡n vÃ o khoáº£ng nÄƒm 2023 dÆ°á»›i dáº¡ng má»™t fork cá»§a Redis. Valkey Ä‘Æ°á»£c táº¡o ra nháº±m duy trÃ¬ cam káº¿t hoÃ n toÃ n mÃ£ nguá»“n má»Ÿ sau khi Redis cÃ³ nhá»¯ng thay Ä‘á»•i vá» giáº¥y phÃ©p, Ä‘áº£m báº£o tÃ­nh tÆ°Æ¡ng thÃ­ch API vá»›i Redis. Äá»™i ngÅ© phÃ¡t triá»ƒn: ÄÆ°á»£c há»— trá»£ chá»§ yáº¿u bá»Ÿi Linux Foundation cÃ¹ng vá»›i sá»± Ä‘Ã³ng gÃ³p cá»§a cá»™ng Ä‘á»“ng mÃ£ nguá»“n má»Ÿ, táº¡o nÃªn má»™t ná»n táº£ng thay tháº¿ Ä‘Ã¡ng tin cáº­y cho Redis. 2. NgÃ´n ngá»¯ láº­p trÃ¬nh Redis: ÄÆ°á»£c viáº¿t chá»§ yáº¿u báº±ng C, cho phÃ©p tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t á»Ÿ má»©c há»‡ thá»‘ng. DragonflyDB: PhÃ¡t triá»ƒn báº±ng C++, nháº±m táº­n dá»¥ng kiáº¿n trÃºc Ä‘a luá»“ng vÃ  cáº£i thiá»‡n hiá»‡u nÄƒng trÃªn há»‡ thá»‘ng Ä‘a lÃµi. Valkey: Giá»¯ nguyÃªn cÃ´ng nghá»‡ cá»§a Redis, Ä‘Æ°á»£c viáº¿t báº±ng C, giÃºp dá»… dÃ ng duy trÃ¬ sá»± tÆ°Æ¡ng thÃ­ch vá»›i API cá»§a Redis. 3. PhÃ¢n tÃ­ch Æ¯u vÃ  NhÆ°á»£c Ä‘iá»ƒm Redis Æ¯u Ä‘iá»ƒm: MÃ£ nguá»“n trÆ°á»Ÿng thÃ nh vÃ  á»•n Ä‘á»‹nh: ÄÆ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong nhiá»u á»©ng dá»¥ng sáº£n xuáº¥t vá»›i há»‡ sinh thÃ¡i phong phÃº (nhiá»u module, cÃ´ng cá»¥ há»— trá»£, thÆ° viá»‡nâ€¦). Hiá»‡u suáº¥t cao: Máº·c dÃ¹ sá»­ dá»¥ng kiáº¿n trÃºc Ä‘Æ¡n luá»“ng, Redis váº«n Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u nÄƒng áº¥n tÆ°á»£ng nhá» tá»‘i Æ°u hÃ³a cho cÃ¡c tÃ¡c vá»¥ I/O. Äá»™ tin cáº­y: ÄÆ°á»£c kiá»ƒm chá»©ng qua thá»i gian vá»›i cá»™ng Ä‘á»“ng ngÆ°á»i dÃ¹ng lá»›n vÃ  nhiá»u tÃ i liá»‡u há»— trá»£. NhÆ°á»£c Ä‘iá»ƒm: Kiáº¿n trÃºc Ä‘Æ¡n luá»“ng: Háº¡n cháº¿ kháº£ nÄƒng táº­n dá»¥ng tá»‘i Ä‘a sá»©c máº¡nh cá»§a cÃ¡c CPU Ä‘a lÃµi, Ä‘áº·c biá»‡t dÆ°á»›i táº£i cao. Cluster phá»©c táº¡p: Viá»‡c cáº¥u hÃ¬nh vÃ  quáº£n lÃ½ cÃ¡c cá»¥m Redis Ä‘Ã´i khi khÃ¡ phá»©c táº¡p. ThÃ¡ch thá»©c giáº¥y phÃ©p: Nhá»¯ng thay Ä‘á»•i vá» giáº¥y phÃ©p trong cÃ¡c phiÃªn báº£n gáº§n Ä‘Ã¢y Ä‘Ã£ gÃ¢y lo ngáº¡i cho má»™t bá»™ pháº­n ngÆ°á»i dÃ¹ng. DragonflyDB Æ¯u Ä‘iá»ƒm: Kiáº¿n trÃºc Ä‘a luá»“ng: Táº­n dá»¥ng tá»‘i Ä‘a sá»©c máº¡nh cá»§a CPU Ä‘a lÃµi, mang láº¡i hiá»‡u suáº¥t xá»­ lÃ½ truy váº¥n vÃ  giáº£m Ä‘á»™ trá»… Ä‘Ã¡ng ká»ƒ. Quáº£n lÃ½ bá»™ nhá»› hiá»‡u quáº£: CÃ¡c thuáº­t toÃ¡n tá»‘i Æ°u giÃºp giáº£m má»©c tiÃªu thá»¥ bá»™ nhá»› dÆ°á»›i táº£i cao. Triá»ƒn khai Ä‘Æ¡n giáº£n: KhÃ´ng cáº§n cáº¥u hÃ¬nh clustering phá»©c táº¡p nhÆ° Redis, phÃ¹ há»£p vá»›i nhá»¯ng á»©ng dá»¥ng cáº§n hiá»‡u nÄƒng cao mÃ  khÃ´ng muá»‘n Ä‘áº§u tÆ° quÃ¡ nhiá»u vÃ o háº¡ táº§ng. NhÆ°á»£c Ä‘iá»ƒm: Má»›i trÃªn thá»‹ trÆ°á»ng: Há»‡ sinh thÃ¡i, tÃ i liá»‡u vÃ  cá»™ng Ä‘á»“ng há»— trá»£ váº«n Ä‘ang trong quÃ¡ trÃ¬nh phÃ¡t triá»ƒn. ChÆ°a kiá»ƒm chá»©ng rá»™ng rÃ£i: Cáº§n thÃªm thá»i gian Ä‘á»ƒ chá»©ng minh tÃ­nh á»•n Ä‘á»‹nh vÃ  kháº£ nÄƒng má»Ÿ rá»™ng trong mÃ´i trÆ°á»ng production. Háº¡n cháº¿ vá» clustering: Má»™t sá»‘ tÃ­nh nÄƒng clustering chÆ°a Ä‘áº¡t Ä‘áº¿n má»©c Ä‘á»™ hoÃ n thiá»‡n nhÆ° Redis. Valkey Æ¯u Ä‘iá»ƒm: TÆ°Æ¡ng thÃ­ch API vá»›i Redis: GiÃºp chuyá»ƒn Ä‘á»•i dá»… dÃ ng tá»« Redis mÃ  khÃ´ng cáº§n thay Ä‘á»•i mÃ£ nguá»“n. HoÃ n toÃ n má»Ÿ nguá»“n: KhÃ´ng gáº·p rÃ ng buá»™c vá» giáº¥y phÃ©p thÆ°Æ¡ng máº¡i, phÃ¹ há»£p vá»›i cÃ¡c tá»• chá»©c Æ°u tiÃªn giáº£i phÃ¡p mÃ£ nguá»“n má»Ÿ. á»”n Ä‘á»‹nh tá»« ná»n táº£ng Redis: Dá»±a trÃªn cÃ´ng nghá»‡ Ä‘Ã£ Ä‘Æ°á»£c kiá»ƒm chá»©ng qua thá»i gian, Ä‘áº£m báº£o tÃ­nh á»•n Ä‘á»‹nh. NhÆ°á»£c Ä‘iá»ƒm: Ãt cáº£i tiáº¿n vá» hiá»‡u suáº¥t: KhÃ´ng cÃ³ nhiá»u cáº£i tiáº¿n vÆ°á»£t trá»™i so vá»›i Redis, chá»‰ táº­p trung vÃ o viá»‡c duy trÃ¬ tÃ­nh má»Ÿ nguá»“n. Cá»™ng Ä‘á»“ng nhá»: Há»‡ sinh thÃ¡i vÃ  tÃ i liá»‡u hÆ°á»›ng dáº«n váº«n chÆ°a phong phÃº báº±ng Redis hoáº·c cÃ¡c giáº£i phÃ¡p má»›i nhÆ° DragonflyDB. Sá»± cáº¡nh tranh khá»‘c liá»‡t: Pháº£i Ä‘á»‘i máº·t vá»›i cÃ¡c dá»± Ã¡n cáº£i tiáº¿n khÃ¡c nháº±m tá»‘i Æ°u hiá»‡u nÄƒng vÃ  kháº£ nÄƒng má»Ÿ rá»™ng. 4. So sÃ¡nh kiáº¿n trÃºc DÆ°á»›i Ä‘Ã¢y lÃ  báº£ng so sÃ¡nh cÃ¡c Ä‘iá»ƒm má»›i trong thiáº¿t káº¿ há»‡ thá»‘ng cá»§a DragonflyDB so vá»›i Valkey vÃ  Redis: ChÃ o báº¡n,\nDÆ°á»›i Ä‘Ã¢y lÃ  báº£ng so sÃ¡nh cÃ¡c Ä‘iá»ƒm má»›i trong thiáº¿t káº¿ há»‡ thá»‘ng cá»§a DragonflyDB so vá»›i Valkey vÃ  Redis, vá»›i cá»™t \u0026ldquo;Äáº·c Ä‘iá»ƒm\u0026rdquo; Ä‘Æ°á»£c tÃ¡ch riÃªng:\nÄáº·c Ä‘iá»ƒm DragonflyDB (Äiá»ƒm má»›i) Valkey Redis (Hiá»‡n táº¡i) Kiáº¿n trÃºc xá»­ lÃ½ â€“ XÃ¢y dá»±ng theo kiáº¿n trÃºc Ä‘a luá»“ng toÃ n diá»‡n, táº­n dá»¥ng tá»‘i Ä‘a sá»©c máº¡nh cá»§a CPU Ä‘a lÃµi.\nâ€“ Xá»­ lÃ½ song song nhiá»u truy váº¥n cÃ¹ng lÃºc, giáº£m Ä‘á»™ trá»… dÆ°á»›i táº£i cao. - Sá»­ dá»¥ng Multi-threaded vá»›i kiáº¿n trÃºc \u0026ldquo;shared-nothing\u0026rdquo;, chia dá»¯ liá»‡u thÃ nh cÃ¡c shard Ä‘á»™c láº­p, má»—i shard xá»­ lÃ½ bá»Ÿi má»™t thread riÃªng, giáº£m tranh cháº¥p lock â€“ Ãp dá»¥ng kiáº¿n trÃºc Ä‘a luá»“ng cáº£i tiáº¿n cho xá»­ lÃ½ I/O vÃ  thá»±c thi lá»‡nh.\nâ€“ Cho phÃ©p xá»­ lÃ½ song song nhiá»u yÃªu cáº§u, cáº£i thiá»‡n throughput vÃ  giáº£m Ä‘á»™ trá»…. â€“ Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Æ¡n luá»“ng vá»›i event loop.\nâ€“ Xá»­ lÃ½ tuáº§n tá»±, táº­n dá»¥ng I/O phi Ä‘á»“ng bá»™ nhÆ°ng khÃ´ng xá»­ lÃ½ song song nhiá»u lá»‡nh cÃ¹ng lÃºc. - Dá»… gÃ¢y ngháº½n cá»• chai khi táº£i cao Quáº£n lÃ½ bá»™ nhá»› â€“ Ãp dá»¥ng cÃ¡c cáº¥u trÃºc dá»¯ liá»‡u tá»‘i Æ°u ( DashTable thay tháº¿ Redis Dictionary, giáº£m metadata) vÃ  thuáº­t toÃ¡n caching tiÃªn tiáº¿n, giáº£m má»©c tiÃªu thá»¥ bá»™ nhá»›.\nâ€“ Hiá»‡u quáº£ khi xá»­ lÃ½ khá»‘i lÆ°á»£ng dá»¯ liá»‡u lá»›n. â€“ Cáº£i tiáº¿n cáº¥u trÃºc tá»« Ä‘iá»ƒn ná»™i bá»™ Ä‘á»ƒ sá»­ dá»¥ng bá»™ nhá»› hiá»‡u quáº£ hÆ¡n.\nâ€“ Giáº£m chi phÃ­ tÃ i nguyÃªn vÃ  Ä‘áº£m báº£o hiá»‡u nÄƒng dÆ°á»›i táº£i cao. â€“ Sá»­ dá»¥ng cÃ¡c cáº¥u trÃºc dá»¯ liá»‡u truyá»n thá»‘ng trong C.\nâ€“ Hoáº¡t Ä‘á»™ng tá»‘t nhÆ°ng Ã­t tá»‘i Æ°u cho mÃ´i trÆ°á»ng Ä‘a luá»“ng vÃ  xá»­ lÃ½ táº£i cao. Xá»­ lÃ½ I/O â€“ Há»— trá»£ I/O báº¥t Ä‘á»“ng bá»™ káº¿t há»£p vá»›i batching, giáº£m overhead khi chuyá»ƒn Ä‘á»•i ngá»¯ cáº£nh giá»¯a cÃ¡c luá»“ng. â€“ Sá»­ dá»¥ng kiáº¿n trÃºc Ä‘a luá»“ng trong xá»­ lÃ½ I/O, cáº£i thiá»‡n hiá»‡u suáº¥t vÃ  giáº£m Ä‘á»™ trá»…. â€“ Dá»±a vÃ o I/O báº¥t Ä‘á»“ng bá»™ qua event loop, xá»­ lÃ½ tá»«ng lá»‡nh má»™t, dáº«n Ä‘áº¿n giá»›i háº¡n khi Ä‘á»‘i máº·t vá»›i táº£i lá»›n. Triá»ƒn khai \u0026amp; Má»Ÿ rá»™ng â€“ Thiáº¿t káº¿ Ä‘á»ƒ Ä‘Æ¡n giáº£n hÃ³a viá»‡c triá»ƒn khai trÃªn single node vá»›i hiá»‡u nÄƒng cao, háº¡n cháº¿ sá»± phá»©c táº¡p cá»§a cluster.\nâ€“ Dá»… dÃ ng má»Ÿ rá»™ng quy mÃ´ nhá» vÃ o kiáº¿n trÃºc Ä‘a luá»“ng ná»™i bá»™. - vertical scale â€“ TÃ­ch há»£p cÃ¡c cáº£i tiáº¿n vá» clustering nhÆ° tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i dá»± phÃ²ng vÃ  phÃ¢n bá»• dá»¯ liá»‡u thÃ´ng minh.\nâ€“ Dá»… dÃ ng má»Ÿ rá»™ng quy mÃ´ trong mÃ´i trÆ°á»ng phÃ¢n tÃ¡n. â€“ Há»— trá»£ Redis Cluster vÃ  Sentinel, nhÆ°ng yÃªu cáº§u cáº¥u hÃ¬nh vÃ  quáº£n lÃ½ khÃ¡ phá»©c táº¡p. - horizontal scale CÃ´ng nghá»‡ \u0026amp; NgÃ´n ngá»¯ â€“ ÄÆ°á»£c xÃ¢y dá»±ng báº±ng C++ hiá»‡n Ä‘áº¡i, cho phÃ©p táº­n dá»¥ng cÃ¡c tÃ­nh nÄƒng tá»‘i Æ°u tá»« ngÃ´n ngá»¯ vÃ  thÆ° viá»‡n tiÃªn tiáº¿n. â€“ ÄÆ°á»£c viáº¿t báº±ng C, giá»¯ nguyÃªn giáº¥y phÃ©p BSD 3-clause, Ä‘áº£m báº£o tÃ­nh má»Ÿ nguá»“n hoÃ n toÃ n.\nâ€“ Táº­p trung vÃ o hiá»‡u nÄƒng vÃ  kháº£ nÄƒng má»Ÿ rá»™ng. â€“ ÄÆ°á»£c viáº¿t báº±ng C, mang láº¡i Ä‘á»™ á»•n Ä‘á»‹nh cao nhÆ°ng háº¡n cháº¿ má»™t sá»‘ tá»‘i Æ°u hÃ³a hiá»‡n Ä‘áº¡i. Nhá»¯ng cáº£i tiáº¿n trÃªn giÃºp DragonflyDB vÃ  Valkey nÃ¢ng cao hiá»‡u nÄƒng, tá»‘i Æ°u hÃ³a viá»‡c sá»­ dá»¥ng tÃ i nguyÃªn vÃ  giáº£m Ä‘á»™ trá»…, phá»¥c vá»¥ tá»‘t hÆ¡n cho cÃ¡c á»©ng dá»¥ng thá»i gian thá»±c vÃ  xá»­ lÃ½ táº£i lá»›n. Tuy nhiÃªn, má»—i há»‡ thá»‘ng cÃ³ nhá»¯ng Ä‘áº·c Ä‘iá»ƒm riÃªng, phÃ¹ há»£p vá»›i cÃ¡c nhu cáº§u vÃ  mÃ´i trÆ°á»ng triá»ƒn khai khÃ¡c nhau.\nValkey lÃ  má»™t dá»± Ã¡n mÃ£ nguá»“n má»Ÿ, Ä‘Æ°á»£c phÃ¡t triá»ƒn nhÆ° má»™t fork cá»§a Redis sau khi Redis chuyá»ƒn sang giáº¥y phÃ©p nguá»“n má»Ÿ cÃ³ Ä‘iá»u kiá»‡n. Valkey giá»¯ nguyÃªn giáº¥y phÃ©p BSD 3-clause, Ä‘áº£m báº£o tÃ­nh má»Ÿ nguá»“n hoÃ n toÃ n. DragonflyDB Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi má»™t cÃ´ng ty thÆ°Æ¡ng máº¡i vÃ  sá»­ dá»¥ng giáº¥y phÃ©p nguá»“n má»Ÿ cÃ³ Ä‘iá»u kiá»‡n, cho phÃ©p sá»­ dá»¥ng miá»…n phÃ­ nhÆ°ng háº¡n cháº¿ viá»‡c cung cáº¥p nhÆ° má»™t dá»‹ch vá»¥ Ä‘Ã¡m mÃ¢y thÆ°Æ¡ng máº¡i. Redis, ban Ä‘áº§u Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Salvatore Sanfilippo, hiá»‡n Ä‘Ã£ chuyá»ƒn sang giáº¥y phÃ©p nguá»“n má»Ÿ cÃ³ Ä‘iá»u kiá»‡n, háº¡n cháº¿ viá»‡c sá»­ dá»¥ng trong má»™t sá»‘ trÆ°á»ng há»£p thÆ°Æ¡ng máº¡i.\n5. Gá»£i Ã½ nÃªn sá»­ dá»¥ng loáº¡i nÃ o? Náº¿u báº¡n cáº§n má»™t giáº£i phÃ¡p Ä‘Ã£ Ä‘Æ°á»£c kiá»ƒm chá»©ng, vá»›i há»‡ sinh thÃ¡i rá»™ng lá»›n vÃ  sá»± há»— trá»£ tá»« cá»™ng Ä‘á»“ng máº¡nh máº½: Redis lÃ  lá»±a chá»n phÃ¹ há»£p, Ä‘áº·c biá»‡t vá»›i cÃ¡c á»©ng dá»¥ng truyá»n thá»‘ng vá» bá»™ nhá»› Ä‘á»‡m, quáº£n lÃ½ phiÃªn vÃ  xá»­ lÃ½ dá»¯ liá»‡u thá»i gian thá»±c. Tuy nhiÃªn, náº¿u báº¡n khÃ´ng ngáº¡i giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n cáº¥u hÃ¬nh cluster hoáº·c má»™t sá»‘ háº¡n cháº¿ vá» kiáº¿n trÃºc Ä‘Æ¡n luá»“ng, Redis váº«n lÃ  lá»±a chá»n Ä‘Ã¡ng tin cáº­y.\nNáº¿u hiá»‡u nÄƒng, kháº£ nÄƒng táº­n dá»¥ng CPU Ä‘a lÃµi vÃ  triá»ƒn khai Ä‘Æ¡n giáº£n lÃ  Æ°u tiÃªn hÃ ng Ä‘áº§u cá»§a báº¡n: DragonflyDB cÃ³ thá»ƒ lÃ  lá»±a chá»n tá»‘i Æ°u. NÃ³ Ä‘em láº¡i tá»‘c Ä‘á»™ xá»­ lÃ½ vÆ°á»£t trá»™i vÃ  quáº£n lÃ½ bá»™ nhá»› hiá»‡u quáº£, phÃ¹ há»£p vá»›i cÃ¡c á»©ng dá»¥ng cáº§n tá»‘c Ä‘á»™ cao mÃ  khÃ´ng muá»‘n phá»©c táº¡p vá»›i viá»‡c cáº¥u hÃ¬nh cluster.\nNáº¿u báº¡n Æ°u tiÃªn hoÃ n toÃ n mÃ£ nguá»“n má»Ÿ vÃ  muá»‘n trÃ¡nh cÃ¡c rÃ ng buá»™c giáº¥y phÃ©p thÆ°Æ¡ng máº¡i, Ä‘á»“ng thá»i váº«n cáº§n sá»± tÆ°Æ¡ng thÃ­ch vá»›i Redis: Valkey lÃ  giáº£i phÃ¡p Ä‘Ã¡ng cÃ¢n nháº¯c. Máº·c dÃ¹ vá» hiá»‡u nÄƒng cÃ³ thá»ƒ khÃ´ng cáº£i thiá»‡n vÆ°á»£t trá»™i so vá»›i Redis, nhÆ°ng Valkey mang láº¡i sá»± an tÃ¢m vá» máº·t phÃ¡p lÃ½ vÃ  há»— trá»£ cá»™ng Ä‘á»“ng má»Ÿ.\nViá»‡c lá»±a chá»n giá»¯a Redis, DragonflyDB vÃ  Valkey cÃ²n phá»¥ thuá»™c vÃ o yÃªu cáº§u cá»¥ thá»ƒ cá»§a dá»± Ã¡n:\nRedis phÃ¹ há»£p vá»›i nhá»¯ng á»©ng dá»¥ng cáº§n sá»± á»•n Ä‘á»‹nh, há»— trá»£ Ä‘a dáº¡ng tá»« cá»™ng Ä‘á»“ng vÃ  má»™t há»‡ sinh thÃ¡i phong phÃº. DragonflyDB lÃ  giáº£i phÃ¡p tiÃªn tiáº¿n, táº­n dá»¥ng cÃ´ng nghá»‡ Ä‘a luá»“ng Ä‘á»ƒ cung cáº¥p hiá»‡u nÄƒng vÆ°á»£t trá»™i trÃªn há»‡ thá»‘ng Ä‘a lÃµi, thÃ­ch há»£p vá»›i cÃ¡c á»©ng dá»¥ng má»›i Ä‘Ã²i há»i tá»‘c Ä‘á»™ cao. Valkey lÃ  lá»±a chá»n lÃ½ tÆ°á»Ÿng náº¿u báº¡n muá»‘n duy trÃ¬ hoÃ n toÃ n tÃ­nh má»Ÿ nguá»“n vÃ  tÆ°Æ¡ng thÃ­ch API vá»›i Redis, máº·c dÃ¹ cÃ³ thá»ƒ thiáº¿u nhá»¯ng cáº£i tiáº¿n vÆ°á»£t trá»™i vá» máº·t hiá»‡u nÄƒng. 6. CÃ¡c con sá»‘ biáº¿t nÃ³i Trong thá»­ nghiá»‡m cÃ¹ng pháº§n cá»©ng EC2 c6gn.16xlarge DragonflyDB Ä‘áº¡t thÃ´ng lÆ°á»£ng 3,8 triá»‡u yÃªu cáº§u má»—i giÃ¢y, cao hÆ¡n ráº¥t nhiá»u so vá»›i redis\nTrong cÃ¡c thá»­ nghiá»‡m vá»›i dung lÆ°á»£ng lÆ°u trá»¯ 5GB, DragonflyDB yÃªu cáº§u Ã­t hÆ¡n 30% bá»™ nhá»› so vá»›i Redis\nHy vá»ng vá»›i báº£ng so sÃ¡nh vÃ  phÃ¢n tÃ­ch trÃªn, báº¡n cÃ³ thá»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh phÃ¹ há»£p nháº¥t cho nhu cáº§u dá»± Ã¡n cá»§a mÃ¬nh.\nNguá»“n tham kháº£o:\nhttps://medium.com/%40mohitdehuliya/dragonflydb-vs-redis-a-deep-dive-towards-the-next-gen-caching-infrastructure-23186397b3d3\nhttps://www.dragonflydb.io/guides/valkey-vs-redis?utm_source=phamduytung.com\nhttps://redisson.org/articles/valkey-vs-redis-comparision.html?utm_source=phamduytung.com\nhttps://en.wikipedia.org/wiki/Valkey?utm_source=phamduytung.com\nhttps://db-engines.com/en/system/Dragonfly%3BKeyDB%3BValkey?utm_source=phamduytung.com\n","date":"Feb 17, 2025","img":"https://unsplash.it/1920/1080?image=206","permalink":"/blog/2025-02-17-redis-dragonflydb-valkey/","series":null,"tags":["DragonflyDB","Redis","Valkey"],"title":"Compare DragonflyDB vs Redis vs Valkey"},{"categories":null,"content":" 1. Há»— trá»£ torch.compile cho Python 3.13 2. Giá»›i thiá»‡u torch.compiler.set_stance 3. TÄƒng cÆ°á»ng AOTInductor 4. Há»— trá»£ FP16 trÃªn CPU X86 5. Cáº£i thiá»‡n tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng PyTorch trÃªn GPU Intel 6. Giá»›i thiá»‡u torch.library.triton_op 7. FlexAttention cho LLMs trÃªn CPU X86 8. Dim.AUTO 9. Thay Ä‘á»•i trong tham sá»‘ weights_only cá»§a torch.load 10. Ngá»«ng há»— trá»£ kÃªnh Anaconda chÃ­nh thá»©c cá»§a PyTorch Káº¿t luáº­n TÃ i liá»‡u tham kháº£o PyTorch 2.6, Ä‘Æ°á»£c phÃ¡t hÃ nh vÃ o ngÃ y 29 thÃ¡ng 1 nÄƒm 2025, mang Ä‘áº¿n nhiá»u cáº£i tiáº¿n vÃ  tÃ­nh nÄƒng má»›i so vá»›i cÃ¡c phiÃªn báº£n trÆ°á»›c Ä‘Ã³. DÆ°á»›i Ä‘Ã¢y lÃ  tá»•ng quan vá» nhá»¯ng Ä‘iá»ƒm ná»•i báº­t trong phiÃªn báº£n nÃ y:\n1. Há»— trá»£ torch.compile cho Python 3.13 TrÆ°á»›c Ä‘Ã¢y, torch.compile chá»‰ há»— trá»£ Ä‘áº¿n phiÃªn báº£n Python 3.12. Trong phiÃªn báº£n 2.6, PyTorch Ä‘Ã£ má»Ÿ rá»™ng há»— trá»£ cho Python 3.13, cho phÃ©p ngÆ°á»i dÃ¹ng tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh vá»›i torch.compile trÃªn phiÃªn báº£n Python má»›i nháº¥t.\nÄÃ¡nh giÃ¡: Viá»‡c má»Ÿ rá»™ng nÃ y giÃºp cá»™ng Ä‘á»“ng ngÆ°á»i dÃ¹ng Python cáº­p nháº­t vÃ  sá»­ dá»¥ng cÃ¡c tÃ­nh nÄƒng má»›i nháº¥t cá»§a ngÃ´n ngá»¯ mÃ  khÃ´ng gáº·p trá»Ÿ ngáº¡i vá» tÆ°Æ¡ng thÃ­ch vá»›i PyTorch.\n2. Giá»›i thiá»‡u torch.compiler.set_stance TÃ­nh nÄƒng nÃ y cho phÃ©p ngÆ°á»i dÃ¹ng chá»‰ Ä‘á»‹nh cÃ¡c hÃ nh vi khÃ¡c nhau (\u0026ldquo;stances\u0026rdquo;) mÃ  torch.compile cÃ³ thá»ƒ thá»±c hiá»‡n giá»¯a cÃ¡c láº§n gá»i hÃ m Ä‘Ã£ biÃªn dá»‹ch. Má»™t trong nhá»¯ng stance, cháº³ng háº¡n nhÆ° \u0026ldquo;eager_on_recompile\u0026rdquo;, hÆ°á»›ng dáº«n PyTorch thá»±c thi eagerly khi cáº§n biÃªn dá»‹ch láº¡i, tÃ¡i sá»­ dá»¥ng mÃ£ Ä‘Ã£ biÃªn dá»‹ch Ä‘Æ°á»£c lÆ°u trong bá»™ nhá»› cache khi cÃ³ thá»ƒ.\nÄÃ¡nh giÃ¡: TÃ­nh nÄƒng nÃ y cung cáº¥p sá»± linh hoáº¡t cho ngÆ°á»i dÃ¹ng trong viá»‡c kiá»ƒm soÃ¡t quÃ¡ trÃ¬nh biÃªn dá»‹ch, giÃºp tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t vÃ  quáº£n lÃ½ tÃ i nguyÃªn hiá»‡u quáº£ hÆ¡n.\n3. TÄƒng cÆ°á»ng AOTInductor PhiÃªn báº£n 2.6 giá»›i thiá»‡u má»™t Ä‘á»‹nh dáº¡ng gÃ³i má»›i, \u0026ldquo;PT2 archive\u0026rdquo;, chá»©a táº¥t cáº£ cÃ¡c tá»‡p cáº§n thiáº¿t cho AOTInductor, cho phÃ©p ngÆ°á»i dÃ¹ng gá»­i má»i thá»© cáº§n thiáº¿t Ä‘áº¿n cÃ¡c mÃ´i trÆ°á»ng khÃ¡c. NgoÃ i ra, cÃ²n cÃ³ chá»©c nÄƒng Ä‘Ã³ng gÃ³i nhiá»u mÃ´ hÃ¬nh vÃ o má»™t artifact vÃ  lÆ°u trá»¯ thÃªm metadata bÃªn trong gÃ³i.\nÄÃ¡nh giÃ¡: Nhá»¯ng cáº£i tiáº¿n nÃ y giÃºp viá»‡c triá»ƒn khai vÃ  phÃ¢n phá»‘i mÃ´ hÃ¬nh trá»Ÿ nÃªn dá»… dÃ ng vÃ  linh hoáº¡t hÆ¡n, Ä‘áº·c biá»‡t há»¯u Ã­ch trong cÃ¡c mÃ´i trÆ°á»ng sáº£n xuáº¥t vÃ  khi lÃ m viá»‡c vá»›i nhiá»u mÃ´ hÃ¬nh.\n4. Há»— trá»£ FP16 trÃªn CPU X86 Má»™t Ä‘iá»ƒm ná»•i báº­t khÃ¡c cá»§a phiÃªn báº£n nÃ y lÃ  há»— trá»£ FP16 trÃªn CPU X86, má»Ÿ rá»™ng kháº£ nÄƒng tÃ­nh toÃ¡n sá»‘ há»c dáº¥u pháº©y Ä‘á»™ng 16-bit trÃªn cÃ¡c CPU phá»• biáº¿n.\nÄÃ¡nh giÃ¡: Äiá»u nÃ y cÃ³ thá»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cho cÃ¡c mÃ´ hÃ¬nh yÃªu cáº§u tÃ­nh toÃ¡n dáº¥u pháº©y Ä‘á»™ng 16-bit, Ä‘áº·c biá»‡t há»¯u Ã­ch cho cÃ¡c á»©ng dá»¥ng yÃªu cáº§u hiá»‡u suáº¥t cao trÃªn pháº§n cá»©ng CPU.\n5. Cáº£i thiá»‡n tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng PyTorch trÃªn GPU Intel PhiÃªn báº£n 2.6 mang láº¡i tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c cáº£i thiá»‡n trÃªn GPU Intel, Ä‘áº·c biá»‡t trÃªn Windows. Äiá»u nÃ y bao gá»“m thiáº¿t láº­p pháº§n má»m dá»… dÃ ng hÆ¡n, cÃ¡c binary Windows Ä‘Æ°á»£c cáº£i thiá»‡n vÃ  má»Ÿ rá»™ng pháº¡m vi cá»§a cÃ¡c toÃ¡n tá»­ Aten trÃªn GPU Intel vá»›i cÃ¡c kernel SYCL.\nÄÃ¡nh giÃ¡: Nhá»¯ng cáº£i tiáº¿n nÃ y lÃ m cho PyTorch trá»Ÿ nÃªn thÃ¢n thiá»‡n hÆ¡n vá»›i ngÆ°á»i dÃ¹ng sá»­ dá»¥ng GPU Intel, má»Ÿ rá»™ng pháº¡m vi pháº§n cá»©ng Ä‘Æ°á»£c há»— trá»£ vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t trÃªn cÃ¡c thiáº¿t bá»‹ nÃ y.\n6. Giá»›i thiá»‡u torch.library.triton_op torch.library.triton_op cung cáº¥p má»™t cÃ¡ch tiÃªu chuáº©n Ä‘á»ƒ táº¡o cÃ¡c toÃ¡n tá»­ tÃ¹y chá»‰nh Ä‘Æ°á»£c há»— trá»£ bá»Ÿi cÃ¡c kernel triton do ngÆ°á»i dÃ¹ng Ä‘á»‹nh nghÄ©a. Khi ngÆ°á»i dÃ¹ng chuyá»ƒn cÃ¡c kernel triton do há» Ä‘á»‹nh nghÄ©a thÃ nh cÃ¡c toÃ¡n tá»­ tÃ¹y chá»‰nh, torch.library.triton_op cho phÃ©p torch.compile xem xÃ©t vÃ o viá»‡c triá»ƒn khai, cho phÃ©p torch.compile tá»‘i Æ°u hÃ³a kernel triton bÃªn trong nÃ³.\nÄÃ¡nh giÃ¡: TÃ­nh nÄƒng nÃ y má»Ÿ ra kháº£ nÄƒng má»Ÿ rá»™ng vÃ  tÃ¹y chá»‰nh cao hÆ¡n cho ngÆ°á»i dÃ¹ng, cho phÃ©p há» tÃ­ch há»£p cÃ¡c kernel triton tÃ¹y chá»‰nh má»™t cÃ¡ch liá»n máº¡ch vÃ  tá»‘i Æ°u hÃ³a chÃºng trong quÃ¡ trÃ¬nh biÃªn dá»‹ch.\n7. FlexAttention cho LLMs trÃªn CPU X86 PyTorch 2.6 giá»›i thiá»‡u FlexAttention, má»™t cáº£i tiáº¿n Ä‘Ã¡ng ká»ƒ cho viá»‡c xá»­ lÃ½ mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs) trÃªn CPU X86. FlexAttention giÃºp tá»‘i Æ°u hÃ³a viá»‡c tÃ­nh toÃ¡n attention, giáº£m Ä‘á»™ trá»… vÃ  tÄƒng tá»‘c Ä‘á»™ suy luáº­n cho cÃ¡c mÃ´ hÃ¬nh Transformer trÃªn pháº§n cá»©ng CPU. Äiá»u nÃ y Ä‘áº·c biá»‡t quan trá»ng Ä‘á»‘i vá»›i nhá»¯ng há»‡ thá»‘ng khÃ´ng cÃ³ GPU máº¡nh hoáº·c cáº§n cháº¡y mÃ´ hÃ¬nh trÃªn cÃ¡c mÃ´i trÆ°á»ng tiáº¿t kiá»‡m chi phÃ­.\nCá»¥ thá»ƒ, FlexAttention táº­n dá»¥ng cÃ¡c tá»‘i Æ°u hÃ³a vá» pháº§n cá»©ng trÃªn kiáº¿n trÃºc X86, giÃºp cáº£i thiá»‡n viá»‡c quáº£n lÃ½ bá»™ nhá»› Ä‘á»‡m (cache) vÃ  tÄƒng hiá»‡u quáº£ xá»­ lÃ½ ma tráº­n trong cÆ¡ cháº¿ attention. Nhá»¯ng cáº£i tiáº¿n nÃ y giÃºp giáº£m Ä‘Ã¡ng ká»ƒ thá»i gian suy luáº­n cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n nhÆ° GPT, LLaMA khi cháº¡y trÃªn CPU.\nÄÃ¡nh giÃ¡: Viá»‡c há»— trá»£ FlexAttention trÃªn CPU X86 lÃ  má»™t bÆ°á»›c tiáº¿n quan trá»ng, giÃºp má»Ÿ rá»™ng kháº£ nÄƒng cháº¡y mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n mÃ  khÃ´ng cáº§n phá»¥ thuá»™c vÃ o GPU. Äiá»u nÃ y mang láº¡i lá»£i Ã­ch lá»›n cho cÃ¡c doanh nghiá»‡p vÃ  nhÃ  nghiÃªn cá»©u muá»‘n triá»ƒn khai AI trong mÃ´i trÆ°á»ng háº¡n cháº¿ tÃ i nguyÃªn. Tuy nhiÃªn, Ä‘á»ƒ Ä‘áº¡t hiá»‡u suáº¥t tá»‘i Æ°u, ngÆ°á»i dÃ¹ng váº«n cáº§n tinh chá»‰nh cÃ¡c tham sá»‘ mÃ´ hÃ¬nh phÃ¹ há»£p vá»›i pháº§n cá»©ng cá»¥ thá»ƒ cá»§a mÃ¬nh.\n8. Dim.AUTO PyTorch 2.6 giá»›i thiá»‡u Dim.AUTO, má»™t tÃ­nh nÄƒng má»›i giÃºp ngÆ°á»i dÃ¹ng viáº¿t mÃ£ linh hoáº¡t hÆ¡n khi lÃ m viá»‡c vá»›i tensor cÃ³ kÃ­ch thÆ°á»›c Ä‘á»™ng. Thay vÃ¬ pháº£i chá»‰ Ä‘á»‹nh rÃµ kÃ­ch thÆ°á»›c cá»§a má»™t chiá»u (dimension) trong má»™t sá»‘ trÆ°á»ng há»£p nháº¥t Ä‘á»‹nh, Dim.AUTO cho phÃ©p PyTorch tá»± Ä‘á»™ng xÃ¡c Ä‘á»‹nh kÃ­ch thÆ°á»›c phÃ¹ há»£p dá»±a trÃªn ngá»¯ cáº£nh.\nÄÃ¡nh giÃ¡: ÄÃ¢y lÃ  má»™t cáº£i tiáº¿n nhá» nhÆ°ng há»¯u Ã­ch, giÃºp Ä‘Æ¡n giáº£n hÃ³a mÃ£ nguá»“n vÃ  giáº£m thiá»ƒu lá»—i do viá»‡c xá»­ lÃ½ kÃ­ch thÆ°á»›c tensor phá»©c táº¡p, Ä‘áº·c biá»‡t trong cÃ¡c kiáº¿n trÃºc máº¡ng sÃ¢u cÃ³ cáº¥u trÃºc Ä‘á»™ng.\n9. Thay Ä‘á»•i trong tham sá»‘ weights_only cá»§a torch.load TrÆ°á»›c Ä‘Ã¢y, torch.load cÃ³ tham sá»‘ weights_only=True, giÃºp ngÆ°á»i dÃ¹ng chá»‰ táº£i trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh, bá» qua cÃ¡c metadata khÃ¡c. Tuy nhiÃªn, trong PyTorch 2.6, giÃ¡ trá»‹ máº·c Ä‘á»‹nh cá»§a tham sá»‘ nÃ y Ä‘Æ°á»£c thay Ä‘á»•i Ä‘á»ƒ trÃ¡nh lá»—i tiá»m áº©n khi táº£i mÃ´ hÃ¬nh.\nÄÃ¡nh giÃ¡: Viá»‡c Ä‘iá»u chá»‰nh giÃ¡ trá»‹ máº·c Ä‘á»‹nh giÃºp Ä‘áº£m báº£o tÃ­nh nháº¥t quÃ¡n khi táº£i mÃ´ hÃ¬nh, trÃ¡nh cÃ¡c trÆ°á»ng há»£p máº¥t metadata quan trá»ng. Tuy nhiÃªn, Ä‘iá»u nÃ y cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n má»™t sá»‘ pipeline Ä‘Ã£ sá»­ dá»¥ng weights_only=True trong cÃ¡c phiÃªn báº£n trÆ°á»›c.\n10. Ngá»«ng há»— trá»£ kÃªnh Anaconda chÃ­nh thá»©c cá»§a PyTorch PyTorch 2.6 chÃ­nh thá»©c thÃ´ng bÃ¡o ngá»«ng cung cáº¥p gÃ³i cÃ i Ä‘áº·t thÃ´ng qua kÃªnh Anaconda chÃ­nh thá»©c. Thay vÃ o Ä‘Ã³, ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c khuyáº¿n nghá»‹ sá»­ dá»¥ng pip hoáº·c conda-forge Ä‘á»ƒ cÃ i Ä‘áº·t PyTorch.\nÄÃ¡nh giÃ¡: ÄÃ¢y lÃ  má»™t thay Ä‘á»•i quan trá»ng áº£nh hÆ°á»Ÿng Ä‘áº¿n ngÆ°á»i dÃ¹ng Anaconda, Ä‘áº·c biá»‡t lÃ  nhá»¯ng ai quen vá»›i viá»‡c cÃ i Ä‘áº·t PyTorch tá»« kÃªnh chÃ­nh thá»©c. Tuy nhiÃªn, quyáº¿t Ä‘á»‹nh nÃ y giÃºp táº­p trung vÃ o cÃ¡c phÆ°Æ¡ng thá»©c cÃ i Ä‘áº·t phá»• biáº¿n hÆ¡n, Ä‘áº£m báº£o tÃ­nh nháº¥t quÃ¡n vÃ  cáº­p nháº­t nhanh hÆ¡n.\nKáº¿t luáº­n PyTorch 2.6 mang láº¡i nhiá»u cáº£i tiáº¿n Ä‘Ã¡ng chÃº Ã½, bao gá»“m há»— trá»£ Python 3.13, cáº£i thiá»‡n hiá»‡u suáº¥t trÃªn GPU Intel, há»— trá»£ FP16 trÃªn CPU X86, vÃ  giá»›i thiá»‡u cÃ¡c tÃ­nh nÄƒng má»›i nhÆ° Dim.AUTO, torch.compiler.set_stance, hay torch.library.triton_op. Nhá»¯ng thay Ä‘á»•i nÃ y giÃºp PyTorch trá»Ÿ nÃªn linh hoáº¡t hÆ¡n, tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t tá»‘t hÆ¡n, vÃ  há»— trá»£ máº¡nh máº½ hÆ¡n cho cÃ¡c mÃ´ hÃ¬nh AI/ML.\nDÃ¹ cÃ³ má»™t sá»‘ thay Ä‘á»•i cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡ch cÃ i Ä‘áº·t vÃ  sá»­ dá»¥ng PyTorch (nhÆ° viá»‡c ngá»«ng há»— trá»£ Anaconda), háº§u háº¿t cÃ¡c cáº­p nháº­t Ä‘á»u mang láº¡i lá»£i Ã­ch lá»›n cho cá»™ng Ä‘á»“ng ngÆ°á»i dÃ¹ng.\nTÃ i liá»‡u tham kháº£o PyTorch 2.6 Release Notes Phoronix: PyTorch 2.6 Features GitHub: PyTorch Release 2.6 BÃ i viáº¿t trÃªn Ä‘Ã£ tá»•ng há»£p vÃ  phÃ¢n tÃ­ch cÃ¡c Ä‘iá»ƒm má»›i trong PyTorch 2.6 so vá»›i cÃ¡c phiÃªn báº£n trÆ°á»›c, giÃºp báº¡n Ä‘á»c hiá»ƒu rÃµ hÆ¡n vá» nhá»¯ng thay Ä‘á»•i quan trá»ng. Náº¿u báº¡n cÃ³ báº¥t ká»³ cÃ¢u há»i hoáº·c Ã½ kiáº¿n nÃ o, hÃ£y Ä‘á»ƒ láº¡i bÃ¬nh luáº­n bÃªn dÆ°á»›i!\n","date":"Jan 31, 2025","img":"https://unsplash.it/1920/1080?image=222","permalink":"/blog/2025-01-31-pytorch2.6/","series":null,"tags":["pytorch"],"title":"Pytorch 2.6"},{"categories":null,"content":" Ngá»¯ cáº£nh, cháº©n bá»‹ dá»¯ liá»‡u giáº£ láº­p MÃ´ táº£ dá»¯ liá»‡u: MÃ´ táº£ Dá»¯ Liá»‡u Thiáº¿u: Code máº«u báº±ng python PhÆ°Æ¡ng PhÃ¡p tÃ¡i táº¡o Dá»¯ Liá»‡u Dá»±a TrÃªn Decision Tree Regession ÄÃ¡nh giÃ¡ hiá»‡u quáº£ cá»§a viá»‡c tÃ¡i táº¡o dá»¯ liá»‡u 1.Statistical Comparison - So sÃ¡nh thá»‘ng kÃª 2.Autocorrelation 3. PhÃ¢n tÃ­ch xu hÆ°á»›ng vÃ  mÃ¹a vá»¥ - STL Decomposition (Trend and Seasonality) So SÃ¡nh Xu HÆ°á»›ng (Trend Comparison) So SÃ¡nh TÃ­nh MÃ¹a Vá»¥ (Seasonality Comparison) Háº¡n Cháº¿ Cá»§a tÃ¡i táº¡o Dá»¯ Liá»‡u Báº±ng Há»“i Quy Tuyáº¿n TÃ­nh Káº¿t luáº­n TÃ i liá»‡u tham kháº£o á» pháº§n trÆ°á»›c Ä‘Ã³, chÃºng ta Ä‘Ã£ nÃªu lÃªn bÃ i toÃ¡n dá»¯ liá»‡u chuá»—i thá»i gian cÃ³ 10% data bá»‹ NA vÃ  sá»­ dá»¥ng linear regression Ä‘á»ƒ tÃ¡i táº¡o cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u NA trÃªn. á» bÃ i toÃ¡n nÃ y, chÃºng ta Ä‘i vÃ o luÃ´n phÃ¢n tÃ­ch sá»­ dá»¥ng Decision Tree Regression thay tháº¿ cho liner regression vÃ  xem thá»­ viá»‡c thay tháº¿ nÃ o cÃ³ mang cho dá»¯ liá»‡u cá»§a chÃºng ta tá»‘t hÆ¡n hay khÃ´ng\nNgá»¯ cáº£nh, cháº©n bá»‹ dá»¯ liá»‡u giáº£ láº­p MÃ´ táº£ dá»¯ liá»‡u: Má»™t chuá»—i thá»i gian tá»« ngÃ y 1 thÃ¡ng 1 nÄƒm 2025 Ä‘áº¿n ngÃ y 30 thÃ¡ng 4 nÄƒm 2025 Ä‘Æ°á»£c táº¡o ra vá»›i cÃ¡c khoáº£ng thá»i gian 10 phÃºt. chuá»—i thá»i gian cÃ³ chu ká»³ ngÃ y-Ä‘Ãªm: cao vÃ o ban ngÃ y (tá»« 6 AM Ä‘áº¿n 6 PM) vÃ  tháº¥p vÃ o ban Ä‘Ãªm. MÃ´ táº£ Dá»¯ Liá»‡u Thiáº¿u: 10% giÃ¡ trá»‹ nÄƒng lÆ°á»£ng Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn vÃ  thay tháº¿ báº±ng NaN Ä‘á»ƒ mÃ´ phá»ng dá»¯ liá»‡u bá»‹ thiáº¿u. Code máº«u báº±ng python 1import pandas as pd 2import numpy as np 3from datetime import datetime 4import matplotlib.pyplot as plt 5 6# Simulate mock energy production dataset 7def simulate_energy_data(start_date, end_date, freq=\u0026#39;10min\u0026#39;): 8 # Create a datetime index with 10-minute intervals 9 datetime_index = pd.date_range(start=start_date, end=end_date, freq=freq) 10 11 # Simulate energy production with day-night cycles 12 np.random.seed(42) # For reproducibility 13 hours = datetime_index.hour 14 day_energy = np.random.normal(loc=300, scale=30, size=len(hours)) 15 night_energy = np.random.normal(loc=50, scale=15, size=len(hours)) 16 energy_values = np.where((hours \u0026gt;= 6) \u0026amp; (hours \u0026lt;= 18), day_energy, night_energy) 17 18 # Introduce missing values (10% of the dataset) 19 num_missing = int(0.1 * len(energy_values)) # 10% of data will be missing 20 missing_indices = np.random.choice(len(energy_values), num_missing, replace=False) 21 energy_values[missing_indices] = np.nan # Set randomly selected indices to NaN 22 23 # Create DataFrame with the simulated energy data 24 energy_data = pd.DataFrame({ 25 \u0026#39;Datetime\u0026#39;: datetime_index, 26 \u0026#39;Energy_Production\u0026#39;: energy_values 27 }) 28 29 return energy_data 30 31 32def plot_origin_data(energy_data_with_missing): 33 plt.figure(figsize=(24, 6)) 34 plt.plot(energy_data_with_missing[\u0026#39;Datetime\u0026#39;], energy_data_with_missing[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Energy Production\u0026#39;) 35 plt.xlabel(\u0026#39;Datetime\u0026#39;) 36 plt.ylabel(\u0026#39;Energy Production\u0026#39;) 37 plt.title(\u0026#39;Simulated Energy Production Over Time\u0026#39;) 38 plt.legend() 39 40 plt.grid(True) 41 plt.show() 42# Main script 43if __name__ == \u0026#34;__main__\u0026#34;: 44 start_date = datetime(2025, 1, 1) 45 end_date = datetime(2025, 4, 40) 46 47 # Generate the simulated dataset 48 energy_data_with_missing = simulate_energy_data(start_date, end_date) 49 50 # Display the first few rows of the dataset 51 print(energy_data_with_missing.head()) 52 53 54 plot_origin_data(energy_data_with_missing) PhÆ°Æ¡ng PhÃ¡p tÃ¡i táº¡o Dá»¯ Liá»‡u Dá»±a TrÃªn Decision Tree Regession 1 2from sklearn.tree import DecisionTreeRegressor 3 4# Impute missing values using linear regression 5def impute_missing_values(data): 6 # Extract the non-missing data 7 non_missing_data = data.dropna() 8 9 # Prepare the features (X) and target (y) 10 X = non_missing_data.index.values.reshape(-1, 1) 11 y = non_missing_data[\u0026#39;Energy_Production\u0026#39;].values 12 13 # Fit the linear regression model 14 model = DecisionTreeRegressor(max_depth=5, random_state=42) 15 model.fit(X, y) 16 17 # Predict the missing values 18 missing_data = data[data[\u0026#39;Energy_Production\u0026#39;].isna()] 19 X_missing = missing_data.index.values.reshape(-1, 1) 20 predicted_values = model.predict(X_missing) 21 22 # Create a DataFrame for the imputed data 23 imputed_data = data.copy() 24 imputed_data.loc[data[\u0026#39;Energy_Production\u0026#39;].isna(), \u0026#39;Energy_Production\u0026#39;] = predicted_values 25 26 return imputed_data 27 28 29def plot_full_data(energy_data_imputed,energy_data_with_missing): 30 plt.figure(figsize=(24, 6)) 31 32 plt.plot(energy_data_imputed[\u0026#39;Datetime\u0026#39;], energy_data_imputed[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Imputed Data using Decision regression\u0026#39;, color=\u0026#39;blue\u0026#39; ) 33 plt.plot(energy_data_with_missing[\u0026#39;Datetime\u0026#39;], energy_data_with_missing[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 34 plt.xlabel(\u0026#39;Datetime\u0026#39;) 35 plt.ylabel(\u0026#39;Energy Production\u0026#39;) 36 plt.title(\u0026#39;Simulated Energy Production Over Time (Original vs Imputed)\u0026#39;) 37 plt.legend() 38 plt.grid(True) 39 plt.show() 40 41# Main script 42if __name__ == \u0026#34;__main__\u0026#34;: 43 44 start_date = datetime(2024, 1, 1) 45 end_date = datetime(2024, 4, 30) 46 47 # Generate the simulated dataset 48 energy_data_with_missing = simulate_energy_data(start_date, end_date) 49 50 51 plot_origin_data(energy_data_with_missing) 52 53 54 # Impute the missing values 55 energy_data_imputed = impute_missing_values(energy_data_with_missing.copy()) 56 57 # Display the first few rows of the dataset 58 print(energy_data_imputed.head()) 59 60 plot_full_data(energy_data_imputed,energy_data_with_missing) NhÃ¬n Ä‘á»“ thá»‹, chÃºng ta tháº¥y ráº±ng giÃ¡ trá»‹ cá»§a cÃ¡c dá»¯ liá»‡u tÃ¡i táº¡o khÃ¡ tÆ°Æ¡ng Ä‘á»“ng vá»›i dá»¯ liá»‡u gá»‘c. Má»™t sá»‘ khoáº£ng trá»‘ng Ä‘Æ°á»£c tÃ¡i táº¡o tá»‘t, má»™t sá»‘ dá»¯ liá»‡u á»Ÿ Ä‘iá»ƒm cá»±c trá»‹ cÅ©ng Ä‘Æ°á»£c tÃ¡i táº¡o. Cáº§n cÃ¡c phÃ¢n tÃ­ch chuyÃªn sÃ¢u hÆ¡n\nÄÃ¡nh giÃ¡ hiá»‡u quáº£ cá»§a viá»‡c tÃ¡i táº¡o dá»¯ liá»‡u 1.Statistical Comparison - So sÃ¡nh thá»‘ng kÃª So sÃ¡nh cÃ¡c chá»‰ sá»‘ thá»‘ng kÃª (trung bÃ¬nh, Ä‘á»™ lá»‡ch chuáº©n, giÃ¡ trá»‹ nhá» nháº¥t, giÃ¡ trá»‹ lá»›n nháº¥t) Ä‘á»ƒ Ä‘áº£m báº£o dá»¯ liá»‡u tÃ¡i táº¡o phÃ¹ há»£p vá»›i phÃ¢n phá»‘i dá»¯ liá»‡u gá»‘c.\n1 2# Statistical comparison function using describe 3def statistical_comparison(original_data, imputed_data): 4 original_stats = original_data[\u0026#39;Energy_Production\u0026#39;].describe() 5 imputed_stats = imputed_data[\u0026#39;Energy_Production\u0026#39;].describe() 6 comparison = pd.DataFrame({ 7 \u0026#39;Metric\u0026#39;: original_stats.index, 8 \u0026#39;Original Data\u0026#39;: original_stats.values, 9 \u0026#39;Imputed Data\u0026#39;: imputed_stats.values 10 }) 11 return comparison 12 13comparison = statistical_comparison(energy_data_with_missing.dropna(), energy_data_imputed) 14print(comparison) Káº¿t quáº£\n1 Metric Original Data Imputed Data 20 count 15553.000000 17281.000000 31 mean 185.155737 185.170568 42 std 127.062030 120.682665 53 min -16.984058 -16.984058 64 25% 51.260972 53.345570 75 50% 257.313693 185.457881 86 75% 302.393653 298.754461 97 max 415.581945 415.581945 So sÃ¡nh vá»›i Linear Regression á»Ÿ bÃ i trÆ°á»›c Ä‘Ã³\n1 Metric Original Data Imputed Data Linear Regression 20 count 15553.000000 17281.000000 31 mean 185.155737 185.155865 42 std 127.062030 120.541640 53 min -16.984058 -16.984058 64 25% 51.260972 53.436820 75 50% 257.313693 185.404682 86 75% 302.393653 298.653209 97 max 415.581945 415.581945 Tá»« báº£ng so sÃ¡nh thá»‘ng kÃª á»Ÿ trÃªn , chÃºng ta cÃ³ thá»ƒ rÃºt ra nhá»¯ng káº¿t luáº­n sau:\nSá»‘ LÆ°á»£ng (Count): Bá»™ dá»¯ liá»‡u tÃ¡i táº¡o chá»©a nhiá»u Ä‘iá»ƒm dá»¯ liá»‡u hÆ¡n, 17281, so vá»›i bá»™ dá»¯ liá»‡u gá»‘c, 15553, do viá»‡c tÃ¡i táº¡o cÃ¡c giÃ¡ trá»‹ thiáº¿u Ä‘á»ƒ Ä‘áº£m báº£o dá»¯ liá»‡u Ä‘áº§y Ä‘á»§.\nTrung BÃ¬nh (Mean): Trung bÃ¬nh cá»§a dá»¯ liá»‡u tÃ¡i táº¡o lÃ  185.17, gáº§n giá»‘ng vá»›i giÃ¡ trá»‹ trung bÃ¬nh cá»§a dá»¯ liá»‡u gá»‘c 185.15, Ä‘iá»u nÃ y cÃ³ nghÄ©a lÃ  xu hÆ°á»›ng trung tÃ¢m cá»§a dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c duy trÃ¬ trong quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u. Tuy nhiÃªn, Linear Regression cho giÃ¡ trá»‹ trung bÃ¬nh gáº§n vá»›i táº­p dá»¯ liá»‡u gá»‘c hÆ¡n.\nÄá»™ Lá»‡ch Chuáº©n (Standard Deviation): Dá»¯ liá»‡u tÃ¡i táº¡o cÃ³ sá»± phÃ¢n tÃ¡n tháº¥p hÆ¡n (Ä‘á»™ lá»‡ch chuáº©n = 120.6 so vá»›i 127.06 cá»§a dá»¯ liá»‡u gá»‘c). Äiá»u nÃ y cÃ³ thá»ƒ cho tháº¥y ráº±ng trong quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u, cÃ¡c giÃ¡ trá»‹ Ä‘Ã£ trá»Ÿ nÃªn mÆ°á»£t mÃ  hÆ¡n, giáº£m bá»›t sá»± phÃ¢n tÃ¡n\nGiÃ¡ Trá»‹ Tá»‘i Thiá»ƒu vÃ  Tá»‘i Äa: GiÃ¡ trá»‹ tá»‘i thiá»ƒu (-16.984058) vÃ  tá»‘i Ä‘a (415.581945) lÃ  giá»‘ng nhau, Ä‘iá»u nÃ y gá»£i Ã½ ráº±ng quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u khÃ´ng táº¡o ra cÃ¡c giÃ¡ trá»‹ ngoáº¡i lai cá»±c Ä‘oan hoáº·c khÃ´ng Ä‘i ra ngoÃ i pháº¡m vi cá»§a dá»¯ liá»‡u gá»‘c.\nCÃ¡c PhÃ¢n Vá»‹ (Quartiles 25%, 50%, 75%):\nPhÃ¢n vá»‹ thá»© 25 (quartile tháº¥p) cao hÆ¡n má»™t chÃºt trong dá»¯ liá»‡u tÃ¡i táº¡o , 53.345570 so vá»›i 51.26 cá»§a dá»¯ liá»‡u gá»‘c, cho tháº¥y cÃ¡c giÃ¡ trá»‹ tÃ¡i táº¡o Ä‘Ã£ láº¥p Ä‘áº§y nhiá»u khoáº£ng trá»‘ng á»Ÿ pháº¡m vi tháº¥p.\nTrung vá»‹ (50%) Ä‘Ã£ thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ tá»« 257.31 trong dá»¯ liá»‡u gá»‘c thÃ nh 185.45 trong dá»¯ liá»‡u tÃ¡i táº¡o , cho tháº¥y cÃ¡c giÃ¡ trá»‹ tÃ¡i táº¡o Ä‘Ã£ giáº£m Ä‘á»™ lá»‡ch dá»¯ liá»‡u cá»§a cÃ¡c pháº§n tá»­ dá»¯ liá»‡u cao.\nPhÃ¢n vá»‹ thá»© 75 (quartile cao) 302.39 vÃ  298.75 , gáº§n nhÆ° tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhau, pháº£n Ã¡nh ráº±ng cÃ¡c giÃ¡ trá»‹ cao Ä‘Ã£ Ä‘Æ°á»£c báº£o tá»“n tá»‘t.\nKáº¿t luáº­n: PhÆ°Æ¡ng phÃ¡p há»“i quy Decision Tree Ä‘Ã£ báº£o tá»“n phÃ¢n phá»‘i tá»•ng thá»ƒ vÃ  pháº¡m vi cá»§a dá»¯ liá»‡u, trong khi lÃ m giáº£m sá»± biáº¿n thiÃªn vÃ  lÃ m mÆ°á»£t dá»¯ liá»‡u má»™t chÃºt.\n2.Autocorrelation Kiá»ƒm tra xem tá»± tÆ°Æ¡ng quan cá»§a chuá»—i cÃ³ Ä‘Æ°á»£c duy trÃ¬ sau khi tÃ¡i táº¡o dá»¯ liá»‡u hay khÃ´ng.\n1 2 3# Autocorrelation analysis function 4def autocorrelation_analysis(original_data, imputed_data): 5 fig, axes = plt.subplots(1, 2, figsize=(15, 6)) 6 plot_acf(original_data[\u0026#39;Energy_Production\u0026#39;].dropna(), ax=axes[0], title=\u0026#39;ACF of Original Data\u0026#39;) 7 plot_acf(imputed_data[\u0026#39;Energy_Production\u0026#39;], ax=axes[1], title=\u0026#39;ACF of Imputed Data\u0026#39;) 8 plt.tight_layout() 9 plt.show() Quan sÃ¡t Ä‘á»“ thá»‹ ACF trÃªn, chÃºng ta cÃ³ thá»ƒ rÃºt ra cÃ¡c Ã½ chÃ­nh sau\nBáº£o Tá»“n CÃ¡c Phá»¥ Thuá»™c - Preservation of Temporal Dependencies:\nHÃ¬nh dáº¡ng vÃ  sá»± suy giáº£m cá»§a ACF trong dá»¯ liá»‡u tÃ¡i táº¡o cÃ³ sá»± tÆ°Æ¡ng Ä‘á»“ng Ä‘Ã¡ng ká»ƒ vá»›i dá»¯ liá»‡u gá»‘c. Äiá»u nÃ y cho tháº¥y ráº±ng cÃ¡c phá»¥ thuá»™c thá»i gian Ä‘Ã£ Ä‘Æ°á»£c báº£o tá»“n khÃ¡ tá»‘t sau quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u.\nHiá»‡u á»¨ng LÃ m Má»‹n - Slight Smoothing Effect:\nACF trÃªn dá»¯ liá»‡u tÃ¡i táº¡o cho tháº¥y giÃ¡ trá»‹ á»Ÿ má»™t sá»‘ Ä‘á»™ trá»… (lags) tháº¥p hÆ¡n so vá»›i dá»¯ liá»‡u gá»‘c. Äiá»u nÃ y cÃ³ thá»ƒ lÃ  do mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh lÃ m má»‹n cÃ¡c cá»±c trá»‹, dáº«n Ä‘áº¿n giáº£m nháº¹ má»©c Ä‘á»™ biáº¿n Ä‘á»™ng.\nCÃ¡c Máº«u Chu Ká»³ Trong ACF - Cyclic Patterns:\nCÃ¡c Ä‘á»‰nh chu ká»³ trong ACF, cháº³ng háº¡n nhÆ° tÃ­nh mÃ¹a vá»¥ hÃ ng ngÃ y, dÆ°á»ng nhÆ° Ä‘Æ°á»£c duy trÃ¬ giá»¯a dá»¯ liá»‡u gá»‘c vÃ  dá»¯ liá»‡u tÃ¡i táº¡o . Äiá»u nÃ y cho tháº¥y ráº±ng quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u Ä‘Ã£ báº£o tá»“n cÃ¡c hÃ nh vi tuáº§n hoÃ n trong táº­p dá»¯ liá»‡u.\nTÃ­nh á»”n Äá»‹nh Chung:\nSá»± tÆ°Æ¡ng Ä‘á»“ng giá»¯a hai biá»ƒu Ä‘á»“ ACF lÃ  má»™t dáº¥u hiá»‡u tÃ­ch cá»±c, cho tháº¥y phÆ°Æ¡ng phÃ¡p tÃ¡i táº¡o dá»¯ liá»‡u báº±ng há»“i quy tuyáº¿n tÃ­nh Ä‘Ã£ giá»¯ láº¡i tá»‘t cáº¥u trÃºc cá»‘t lÃµi trong dá»¯ liá»‡u.\nKáº¿t Luáº­n:\nPhÆ°Æ¡ng phÃ¡p há»“i quy tuyáº¿n tÃ­nh khÃ´ng chá»‰ báº£o tá»“n má»‘i liÃªn há»‡ thá»i gian trong dá»¯ liá»‡u mÃ  cÃ²n duy trÃ¬ cÃ¡c máº«u chu ká»³, máº·c dÃ¹ cÃ³ má»™t chÃºt hiá»‡u á»©ng lÃ m má»‹n.\n3. PhÃ¢n tÃ­ch xu hÆ°á»›ng vÃ  mÃ¹a vá»¥ - STL Decomposition (Trend and Seasonality) So SÃ¡nh Xu HÆ°á»›ng (Trend Comparison) 1 2# STL decomposition function to extract and plot trend component 3def stl_decomposition_trend(original_data, imputed_data, period): 4 stl_original = STL(original_data[\u0026#39;Energy_Production\u0026#39;] , period=period) 5 result_original = stl_original.fit() 6 trend_original = result_original.trend 7 8 stl_imputed = STL(imputed_data[\u0026#39;Energy_Production\u0026#39;], period=period) 9 result_imputed = stl_imputed.fit() 10 trend_imputed = result_imputed.trend 11 12 plt.figure(figsize=(24, 6)) 13 plt.plot(original_data[\u0026#39;Datetime\u0026#39;], trend_original, label=\u0026#39;Trend of Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 14 plt.plot(imputed_data[\u0026#39;Datetime\u0026#39;], trend_imputed, label=\u0026#39;Trend of Imputed Data\u0026#39;, color=\u0026#39;blue\u0026#39;) 15 plt.xlabel(\u0026#39;Datetime\u0026#39;) 16 plt.ylabel(\u0026#39;Trend\u0026#39;) 17 plt.title(\u0026#39;STL Decomposition Trend of Original and Imputed Data\u0026#39;) 18 plt.legend() 19 plt.grid(True) 20 plt.show() 21 22stl_decomposition_trend(energy_data_with_missing.dropna(), energy_data_imputed, period=144) # Daily seasonality (144 10-min intervals in a day) Báº£o Tá»“n Xu HÆ°á»›ng DÃ i Háº¡n:\nÄÆ°á»ng Xu hÆ°á»›ng tÃ¡i táº¡o (mÃ u xanh dÆ°Æ¡ng) nhÃ¬n chung phÃ¹ há»£p vá»›i xu hÆ°á»›ng gá»‘c (mÃ u Ä‘á»), cho tháº¥y phÆ°Æ¡ng phÃ¡p tÃ¡i táº¡o há»“i quy tuyáº¿n tÃ­nh Ä‘Ã£ báº£o tá»“n Ä‘Æ°á»£c chuyá»ƒn Ä‘á»™ng dÃ i háº¡n trong dá»¯ liá»‡u.\nHiá»‡u á»¨ng LÃ m Má»‹n:\nÄÆ°á»ng Xu hÆ°á»›ng tÃ¡i táº¡o mÆ°á»£t mÃ  hÆ¡n so vá»›i xu hÆ°á»›ng gá»‘c, Ä‘áº·c biá»‡t á»Ÿ nhá»¯ng nÆ¡i xu hÆ°á»›ng gá»‘c cÃ³ nhiá»u biáº¿n Ä‘á»™ng. Äiá»u nÃ y lÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a há»“i quy tuyáº¿n tÃ­nh, vá»‘n cÃ³ xu hÆ°á»›ng khÃ´ng pháº£n Ã¡nh tá»‘t cÃ¡c biáº¿n Ä‘á»™ng máº¡nh vÃ  lÃ m má»‹n cÃ¡c cá»±c trá»‹.\nSo SÃ¡nh TÃ­nh MÃ¹a Vá»¥ (Seasonality Comparison) 1 2 3def stl_decomposition_seasonality(original_data, imputed_data, period): 4 stl_original = STL(original_data[\u0026#39;Energy_Production\u0026#39;], period=period) 5 result_original = stl_original.fit() 6 seasonality_original = result_original.seasonal 7 8 stl_imputed = STL(imputed_data[\u0026#39;Energy_Production\u0026#39;], period=period) 9 result_imputed = stl_imputed.fit() 10 seasonality_imputed = result_imputed.seasonal 11 12 plt.figure(figsize=(24, 6)) 13 plt.plot(original_data[\u0026#39;Datetime\u0026#39;], seasonality_original, label=\u0026#39;Seasonality of Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 14 plt.plot(imputed_data[\u0026#39;Datetime\u0026#39;], seasonality_imputed, label=\u0026#39;Seasonality of Imputed Data\u0026#39;, color=\u0026#39;blue\u0026#39;) 15 plt.xlabel(\u0026#39;Datetime\u0026#39;) 16 plt.ylabel(\u0026#39;Seasonality\u0026#39;) 17 plt.title(\u0026#39;STL Decomposition Seasonality of Original and Imputed Data\u0026#39;) 18 plt.legend() 19 plt.grid(True) 20 plt.show() 21stl_decomposition_seasonality(energy_data_with_missing.dropna(), energy_data_imputed, period=144) # Daily seasonality (144 10-min intervals in a day) Báº£o Tá»“n tÃ­nh Chu Ká»³:\nÄÆ°á»ng mÃ¹a vá»¥ tÃ¡i táº¡o thá»ƒ hiá»‡n ra cÃ¡c máº«u chu ká»³ tÆ°Æ¡ng Ä‘á»‘i gáº§n giá»‘ng vá»›i chu ká»³ cá»§a Ä‘Æ°á»ng mÃ¹a vá»¥ gá»‘c, pháº£n Ã¡nh ráº±ng dá»¯ liá»‡u cÃ¡c chu ká»³ sáº£n xuáº¥t ngÃ y-Ä‘Ãªm Ä‘Ã£ Ä‘Æ°á»£c duy trÃ¬ khÃ¡ tá»‘t.\nGiáº£m BiÃªn Äá»™ Chu Ká»³:\nBiÃªn Ä‘á»™ cá»§a Ä‘Æ°á»ng mÃ¹a vá»¥ tÃ¡i táº¡o bá»‹ giáº£m nháº¹ so vá»›i gá»‘c, Ä‘áº·c biá»‡t táº¡i cÃ¡c Ä‘á»‰nh vÃ  Ä‘Ã¡y. Äiá»u nÃ y cho tháº¥y quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u Ä‘Ã£ lÃ m cho cÃ¡c biáº¿n Ä‘á»™ng chu ká»³ á»Ÿ cá»±c trá»‹ trá»Ÿ nÃªn Ã­t máº¡nh máº½ hÆ¡n.\nHáº¡n Cháº¿ Cá»§a tÃ¡i táº¡o Dá»¯ Liá»‡u Báº±ng Há»“i Quy Tuyáº¿n TÃ­nh LÃ m Má»‹n CÃ¡c cá»±c trá»‹:\nTá»« so sÃ¡nh thá»‘ng kÃª, Ä‘á»™ lá»‡ch chuáº©n tháº¥p hÆ¡n á»Ÿ dá»¯ liá»‡u tÃ¡i táº¡o cho tháº¥y tÃ­nh biáº¿n Ä‘á»™ng Ä‘Ã£ bá»‹ giáº£m.\nTá»« so sÃ¡nh xu hÆ°á»›ng, xu hÆ°á»›ng tÃ¡i táº¡o mÆ°á»£t hÆ¡n vÃ  thiáº¿u má»™t sá»‘ biáº¿n Ä‘á»™ng gá»‘c trong cÃ¡c máº«u dÃ i háº¡n.\nGiáº£ Äá»‹nh Tuyáº¿n TÃ­nh:\nHiá»‡u á»©ng lÃ m má»‹n trong so sÃ¡nh xu hÆ°á»›ng cho tháº¥y phÆ°Æ¡ng phÃ¡p nÃ y khÃ³ báº¯t ká»‹p cÃ¡c thay Ä‘á»•i phi tuyáº¿n tÃ­nh trong dá»¯ liá»‡u, Ä‘áº·c biá»‡t táº¡i cÃ¡c giai Ä‘oáº¡n cÃ³ sá»± thay Ä‘á»•i Ä‘á»™t ngá»™t. Giáº£m BiÃªn Äá»™ MÃ¹a Vá»¥:\nSo sÃ¡nh tÃ­nh mÃ¹a vá»¥ cho tháº¥y biÃªn Ä‘á»™ chu ká»³ tÃ¡i táº¡o tháº¥p hÆ¡n so vá»›i gá»‘c, vá»›i cÃ¡c Ä‘á»‰nh vÃ  Ä‘Ã¡y bá»‹ lÃ m má»‹n. Äiá»u nÃ y phÃ¹ há»£p vá»›i xu hÆ°á»›ng cá»§a há»“i quy trong viá»‡c kÃ©o cÃ¡c giÃ¡ trá»‹ cá»±c Ä‘oan vá» trung bÃ¬nh. Káº¿t luáº­n PhÆ°Æ¡ng phÃ¡p tÃ¡i táº¡o há»“i quy tuyáº¿n tÃ­nh báº£o tá»“n Ä‘Æ°á»£c cÃ¡c xu hÆ°á»›ng tá»•ng thá»ƒ vÃ  cÃ¡c máº«u chu ká»³, nhÆ°ng lÃ m giáº£m tÃ­nh biáº¿n Ä‘á»™ng vÃ  lÃ m má»‹n cÃ¡c giÃ¡ trá»‹ cá»±c Ä‘oan. NgoÃ i ra, nÃ³ thá»ƒ hiá»‡n sá»± giáº£m nháº¹ cÆ°á»ng Ä‘á»™ cá»§a cÃ¡c chu ká»³ mÃ¹a vá»¥, Ä‘iá»u nÃ y Ä‘Æ°á»£c pháº£n Ã¡nh trong cáº£ phÃ¢n tÃ­ch thá»‘ng kÃª vÃ  phÃ¢n rÃ£ dá»¯ liá»‡u.\nTrong bÃ i toÃ¡n nÃ y, sá»± khÃ¡c biá»‡t cá»§a Decision Tree vÃ  linear regression khÃ´ng rÃµ rÃ ng láº¯m, cáº£ hai Ä‘á»u Ä‘Ã¡p á»©ng tá»‘t nhu cáº§u tÃ¡i táº¡o dá»¯ liá»‡u.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t. Xin cáº£m Æ¡n vÃ  háº¹n gáº·p láº¡i.\nTÃ i liá»‡u tham kháº£o https://www.geeksforgeeks.org/managing-missing-data-in-linear-regression/\nhttps://towardsdatascience.com/missing-data-in-time-series-machine-learning-techniques-6b2273ff8b45\nhttps://www.geeksforgeeks.org/dataset-for-linear-regression/\nhttps://www.geeksforgeeks.org/ml-handling-missing-values/\nhttps://codezup.com/mastering-linear-regression-time-series-forecasting/\n","date":"Jan 12, 2025","img":"https://unsplash.it/1920/1080?image=204","permalink":"/blog/2025-01-12-data-missing-time-serial-decision-tree-regression/","series":null,"tags":["Missing data","time-serials"],"title":"Xá»­ LÃ½ Dá»¯ Liá»‡u Khiáº¿m Khuyáº¿t Trong Dá»¯ Liá»‡u Chuá»—i Thá»i Gian Sá»­ Dá»¥ng PhÆ°Æ¡ng PhÃ¡p Decision Tree Regression - Machine Learning Techniques for Mising Data in Time-Serials Using Decision Tree Regression"},{"categories":null,"content":" Sá»­ Dá»¥ng Há»c MÃ¡y Cho Viá»‡c tÃ¡i táº¡o Dá»¯ Liá»‡u Thiáº¿u Trong Chuá»—i Thá»i Gian Khi NÃ o sá»­ dá»¥ng há»c mÃ¡y 1. Máº«u dá»¯ liá»‡u Phi Tuyáº¿n TÃ­nh: 2. Bá»™ Dá»¯ Liá»‡u CÃ³ Nhiá»u Chiá»u: 3. Khoáº£ng Trá»‘ng Lá»›n Trong Dá»¯ Liá»‡u: 4. Dá»¯ Liá»‡u bá»‹ Thiáº¿u KhÃ´ng Ngáº«u NhiÃªn: 5. TÃ­nh Cháº¯c Cháº¯n: Nhá»¯ng ÄÃ¡nh Äá»•i khi sá»­ dá»¥ng há»c mÃ¡y thay cho cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng: Ngá»¯ cáº£nh, cháº©n bá»‹ dá»¯ liá»‡u giáº£ láº­p MÃ´ táº£ dá»¯ liá»‡u: MÃ´ táº£ Dá»¯ Liá»‡u Thiáº¿u: Code máº«u báº±ng python PhÆ°Æ¡ng PhÃ¡p tÃ¡i táº¡o Dá»¯ Liá»‡u Dá»±a TrÃªn Há»“i Quy ÄÃ¡nh giÃ¡ hiá»‡u quáº£ cá»§a viá»‡c tÃ¡i táº¡o dá»¯ liá»‡u 1.Statistical Comparison - So sÃ¡nh thá»‘ng kÃª 2.Autocorrelation 3. PhÃ¢n tÃ­ch xu hÆ°á»›ng vÃ  mÃ¹a vá»¥ - STL Decomposition (Trend and Seasonality) So SÃ¡nh Xu HÆ°á»›ng (Trend Comparison) So SÃ¡nh TÃ­nh MÃ¹a Vá»¥ (Seasonality Comparison) Háº¡n Cháº¿ Cá»§a tÃ¡i táº¡o Dá»¯ Liá»‡u Báº±ng linear regression Káº¿t luáº­n TÃ i liá»‡u tham kháº£o Dá»¯ liá»‡u bá»‹ thiáº¿u trong phÃ¢n tÃ­ch chuá»—i thá»i gian lÃ  má»™t thÃ¡ch thá»©c phá»• biáº¿n, thÆ°á»ng xáº£y ra do cáº£m biáº¿n há»ng, lá»—i truyá»n dá»¯ liá»‡u hoáº·c cÃ¡c váº¥n Ä‘á» báº£o trÃ¬. Nhá»¯ng khoáº£ng trá»‘ng trong dá»¯ liá»‡u nÃ y cÃ³ thá»ƒ lÃ m giÃ¡n Ä‘oáº¡n dá»± bÃ¡o vÃ  lÃ m lá»‡ch káº¿t quáº£ phÃ¢n tÃ­ch, khiáº¿n cho thÃ´ng tin trá»Ÿ nÃªn khÃ´ng Ä‘Ã¡ng tin cáº­y.\nCÃ¡c ká»¹ thuáº­t Ä‘Æ¡n giáº£n nhÆ° forward fill hoáº·c interpolation thÆ°á»ng lÃ  giáº£i phÃ¡p máº·c Ä‘á»‹nh Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u. Tuy nhiÃªn, khi Ä‘á»‘i máº·t vá»›i cÃ¡c máº«u dá»¯ liá»‡u phá»©c táº¡p, xu hÆ°á»›ng phi tuyáº¿n tÃ­nh hoáº·c Ä‘á»™ biáº¿n thiÃªn cao, cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y thÆ°á»ng tháº¥t báº¡i vÃ  táº¡o ra káº¿t quáº£ khÃ´ng á»•n Ä‘á»‹nh.\nSá»­ Dá»¥ng Há»c MÃ¡y Cho Viá»‡c tÃ¡i táº¡o Dá»¯ Liá»‡u Thiáº¿u Trong Chuá»—i Thá»i Gian Há»c mÃ¡y (ML) cung cáº¥p má»™t phÆ°Æ¡ng phÃ¡p máº¡nh máº½ Ä‘á»ƒ tÃ¡i táº¡o dá»¯ liá»‡u thiáº¿u báº±ng cÃ¡ch nháº­n diá»‡n cÃ¡c máº«u vÃ  má»‘i quan há»‡ trong dá»¯ liá»‡u. KhÃ¡c vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng thÆ°á»ng dá»±a vÃ o cÃ¡c giáº£ Ä‘á»‹nh vá» xu hÆ°á»›ng tuyáº¿n tÃ­nh, há»c mÃ¡y cÃ³ thá»ƒ phÃ¡t hiá»‡n cÃ¡c má»‘i quan há»‡ phi tuyáº¿n tÃ­nh vÃ  Ä‘a biáº¿n phá»©c táº¡p, dáº«n Ä‘áº¿n viá»‡c tÃ¡i táº¡o dá»¯ liá»‡u thiáº¿u chÃ­nh xÃ¡c hÆ¡n.\nKhi NÃ o sá»­ dá»¥ng há»c mÃ¡y 1. Máº«u dá»¯ liá»‡u Phi Tuyáº¿n TÃ­nh: CÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng thÆ°á»ng giáº£ Ä‘á»‹nh ráº±ng dá»¯ liá»‡u cÃ³ xu hÆ°á»›ng tuyáº¿n tÃ­nh, nhÆ°ng nhiá»u bá»™ dá»¯ liá»‡u chuá»—i thá»i gian thá»±c táº¿ cÃ³ cÃ¡c máº«u phi tuyáº¿n mÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y khÃ´ng thá»ƒ náº¯m báº¯t. CÃ¡c thuáº­t toÃ¡n há»c mÃ¡y cÃ³ thá»ƒ há»c vÃ  mÃ´ hÃ¬nh hÃ³a nhá»¯ng máº«u phá»©c táº¡p nÃ y, cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a viá»‡c tÃ¡i táº¡o dá»¯ liá»‡u thiáº¿u.\n2. Bá»™ Dá»¯ Liá»‡u CÃ³ Nhiá»u Chiá»u: Khi lÃ m viá»‡c vá»›i cÃ¡c bá»™ dá»¯ liá»‡u cÃ³ nhiá»u Ä‘áº·c trÆ°ng hoáº·c biáº¿n sá»‘, cÃ¡c phÆ°Æ¡ng phÃ¡p tÃ¡i táº¡o dá»¯ liá»‡u truyá»n thá»‘ng cÃ³ thá»ƒ gáº·p khÃ³ khÄƒn. CÃ¡c ká»¹ thuáº­t há»c mÃ¡y cÃ³ thá»ƒ táº­n dá»¥ng cÃ¡c Ä‘áº·c trÆ°ng bá»• sung trong bá»™ dá»¯ liá»‡u cÃ³ nhiá»u chiá»u, giÃºp tÃ¡i táº¡o dá»¯ liá»‡u thiáº¿u hiá»‡u quáº£ hÆ¡n báº±ng cÃ¡ch xem xÃ©t Ä‘á»“ng thá»i nhiá»u biáº¿n.\n3. Khoáº£ng Trá»‘ng Lá»›n Trong Dá»¯ Liá»‡u: Äá»‘i vá»›i cÃ¡c bá»™ dá»¯ liá»‡u cÃ³ khoáº£ng trá»‘ng lá»›n, cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n nhÆ° tÃ¡i táº¡o giÃ¡ trá»‹ trÆ°á»›c cÃ³ thá»ƒ khÃ´ng Ä‘á»§ hiá»‡u quáº£. Há»c mÃ¡y cÃ³ thá»ƒ há»c Ä‘Æ°á»£c xu hÆ°á»›ng tá»•ng thá»ƒ vÃ  cÃ¡c máº«u trong dá»¯ liá»‡u, giÃºp tÃ¡i táº¡o cÃ¡c khoáº£ng trá»‘ng lá»›n má»™t cÃ¡ch cÃ³ Ã½ nghÄ©a vÃ  chÃ­nh xÃ¡c hÆ¡n.\n4. Dá»¯ Liá»‡u bá»‹ Thiáº¿u KhÃ´ng Ngáº«u NhiÃªn: Trong cÃ¡c trÆ°á»ng há»£p dá»¯ liá»‡u thiáº¿u khÃ´ng ngáº«u nhiÃªn (MNAR), cÃ¡c phÆ°Æ¡ng phÃ¡p tÃ¡i táº¡o dá»¯ liá»‡u truyá»n thá»‘ng, vá»‘n giáº£ Ä‘á»‹nh ráº±ng dá»¯ liá»‡u thiáº¿u lÃ  ngáº«u nhiÃªn, cÃ³ thá»ƒ dáº«n Ä‘áº¿n káº¿t quáº£ sai lá»‡ch. CÃ¡c phÆ°Æ¡ng phÃ¡p há»c mÃ¡y cÃ³ thá»ƒ há»c cÃ¡ch xá»­ lÃ½ nhá»¯ng sai lá»‡ch nÃ y báº±ng cÃ¡ch hiá»ƒu cÃ¡c má»‘i quan há»‡ tiá»m áº©n trong dá»¯ liá»‡u, lÃ m cho chÃºng trá»Ÿ nÃªn máº¡nh máº½ vÃ  chÃ­nh xÃ¡c hÆ¡n.\n5. TÃ­nh Cháº¯c Cháº¯n: CÃ¡c phÆ°Æ¡ng phÃ¡p há»c mÃ¡y thÆ°á»ng máº¡nh máº½ hÆ¡n, Ä‘áº·c biá»‡t khi dá»¯ liá»‡u cÃ³ cÃ¡c máº«u phá»©c táº¡p hoáº·c dá»¯ liá»‡u thiáº¿u tuÃ¢n theo cÃ¡c cÆ¡ cháº¿ khÃ´ng xÃ¡c Ä‘á»‹nh. ChÃºng cÃ³ thá»ƒ thÃ­ch nghi vá»›i cÃ¡c loáº¡i dá»¯ liá»‡u thiáº¿u khÃ¡c nhau, giÃºp xá»­ lÃ½ cÃ¡c nhiá»‡m vá»¥ tÃ¡i táº¡o dá»¯ liá»‡u thiáº¿u trong chuá»—i thá»i gian Ä‘áº§y thá»­ thÃ¡ch. Nhá»¯ng ÄÃ¡nh Äá»•i khi sá»­ dá»¥ng há»c mÃ¡y thay cho cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng: Máº·c dÃ¹ cÃ¡c phÆ°Æ¡ng phÃ¡p há»c mÃ¡y thÆ°á»ng mang láº¡i káº¿t quáº£ chÃ­nh xÃ¡c hÆ¡n, nhÆ°ng chÃºng yÃªu cáº§u nhiá»u tÃ i nguyÃªn tÃ­nh toÃ¡n hÆ¡n so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng. Tuy nhiÃªn, tÃ­nh linh hoáº¡t vÃ  sá»©c máº¡nh cá»§a chÃºng khiáº¿n chÃºng trá»Ÿ thÃ nh lá»±a chá»n lÃ½ tÆ°á»Ÿng Ä‘á»ƒ xá»­ lÃ½ cÃ¡c nhiá»‡m vá»¥ tÃ¡i táº¡o dá»¯ liá»‡u thiáº¿u trong chuá»—i thá»i gian, nÆ¡i Ä‘á»™ chÃ­nh xÃ¡c lÃ  yáº¿u tá»‘ quan trá»ng.\nNgá»¯ cáº£nh, cháº©n bá»‹ dá»¯ liá»‡u giáº£ láº­p MÃ´ táº£ dá»¯ liá»‡u: Má»™t chuá»—i thá»i gian tá»« ngÃ y 1 thÃ¡ng 1 nÄƒm 2025 Ä‘áº¿n ngÃ y 30 thÃ¡ng 4 nÄƒm 2025 Ä‘Æ°á»£c táº¡o ra vá»›i cÃ¡c khoáº£ng thá»i gian 10 phÃºt. chuá»—i thá»i gian cÃ³ chu ká»³ ngÃ y-Ä‘Ãªm: cao vÃ o ban ngÃ y (tá»« 6 AM Ä‘áº¿n 6 PM) vÃ  tháº¥p vÃ o ban Ä‘Ãªm. MÃ´ táº£ Dá»¯ Liá»‡u Thiáº¿u: 10% giÃ¡ trá»‹ nÄƒng lÆ°á»£ng Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn vÃ  thay tháº¿ báº±ng NaN Ä‘á»ƒ mÃ´ phá»ng dá»¯ liá»‡u bá»‹ thiáº¿u. Code máº«u báº±ng python 1import pandas as pd 2import numpy as np 3from datetime import datetime 4import matplotlib.pyplot as plt 5 6# Simulate mock energy production dataset 7def simulate_energy_data(start_date, end_date, freq=\u0026#39;10min\u0026#39;): 8 # Create a datetime index with 10-minute intervals 9 datetime_index = pd.date_range(start=start_date, end=end_date, freq=freq) 10 11 # Simulate energy production with day-night cycles 12 np.random.seed(42) # For reproducibility 13 hours = datetime_index.hour 14 day_energy = np.random.normal(loc=300, scale=30, size=len(hours)) 15 night_energy = np.random.normal(loc=50, scale=15, size=len(hours)) 16 energy_values = np.where((hours \u0026gt;= 6) \u0026amp; (hours \u0026lt;= 18), day_energy, night_energy) 17 18 # Introduce missing values (10% of the dataset) 19 num_missing = int(0.1 * len(energy_values)) # 10% of data will be missing 20 missing_indices = np.random.choice(len(energy_values), num_missing, replace=False) 21 energy_values[missing_indices] = np.nan # Set randomly selected indices to NaN 22 23 # Create DataFrame with the simulated energy data 24 energy_data = pd.DataFrame({ 25 \u0026#39;Datetime\u0026#39;: datetime_index, 26 \u0026#39;Energy_Production\u0026#39;: energy_values 27 }) 28 29 return energy_data 30 31 32def plot_origin_data(energy_data_with_missing): 33 plt.figure(figsize=(24, 6)) 34 plt.plot(energy_data_with_missing[\u0026#39;Datetime\u0026#39;], energy_data_with_missing[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Energy Production\u0026#39;) 35 plt.xlabel(\u0026#39;Datetime\u0026#39;) 36 plt.ylabel(\u0026#39;Energy Production\u0026#39;) 37 plt.title(\u0026#39;Simulated Energy Production Over Time\u0026#39;) 38 plt.legend() 39 40 plt.grid(True) 41 plt.show() 42# Main script 43if __name__ == \u0026#34;__main__\u0026#34;: 44 start_date = datetime(2025, 1, 1) 45 end_date = datetime(2025, 4, 40) 46 47 # Generate the simulated dataset 48 energy_data_with_missing = simulate_energy_data(start_date, end_date) 49 50 # Display the first few rows of the dataset 51 print(energy_data_with_missing.head()) 52 53 54 plot_origin_data(energy_data_with_missing) PhÆ°Æ¡ng PhÃ¡p tÃ¡i táº¡o Dá»¯ Liá»‡u Dá»±a TrÃªn Há»“i Quy PhÆ°Æ¡ng phÃ¡p tÃ¡i táº¡o dá»¯ liá»‡u dá»±a trÃªn há»“i quy sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n â€” má»™t lá»›p thuáº­t toÃ¡n há»c mÃ¡y, cháº³ng háº¡n nhÆ° há»“i quy tuyáº¿n tÃ­nh hoáº·c cÃ¡c bá»™ há»“i quy cÃ¢y quyáº¿t Ä‘á»‹nh â€” Ä‘á»ƒ Æ°á»›c tÃ­nh giÃ¡ trá»‹ tá»« cÃ¡c má»‘i quan há»‡ Ä‘Ã£ biáº¿t giá»¯a cÃ¡c Ä‘áº·c trÆ°ng khÃ¡c hoáº·c cÃ¡c máº«u thá»i gian, nhÆ° giÃ¡ trá»‹ trá»… trong chuá»—i thá»i gian.\nMÃ´ hÃ¬nh tÃ¡i táº¡o vÃ o cÃ¡c khoáº£ng trá»‘ng báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c xu hÆ°á»›ng vÃ  má»‘i quan há»‡ tiá»m áº©n Ä‘Ã£ há»c tá»« dá»¯ liá»‡u.\ná» bÃ i viáº¿t nÃ y, chÃºng ta sáº½ tÃ¬m hiá»ƒu cÃ¡ch tÃ¡i táº¡o dá»¯ liá»‡u bá»‹ thiáº¿u sá»­ dá»¥ng mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh vá»›i thÆ° viá»‡n LinearRegression cá»§a sklearn\n1 2from sklearn.linear_model import LinearRegression 3 4# Impute missing values using linear regression 5def impute_missing_values(data): 6 # Extract the non-missing data 7 non_missing_data = data.dropna() 8 9 # Prepare the features (X) and target (y) 10 X = non_missing_data.index.values.reshape(-1, 1) 11 y = non_missing_data[\u0026#39;Energy_Production\u0026#39;].values 12 13 # Fit the linear regression model 14 model = LinearRegression() 15 model.fit(X, y) 16 17 # Predict the missing values 18 missing_data = data[data[\u0026#39;Energy_Production\u0026#39;].isna()] 19 X_missing = missing_data.index.values.reshape(-1, 1) 20 predicted_values = model.predict(X_missing) 21 22 # Create a DataFrame for the imputed data 23 imputed_data = data.copy() 24 imputed_data.loc[data[\u0026#39;Energy_Production\u0026#39;].isna(), \u0026#39;Energy_Production\u0026#39;] = predicted_values 25 26 return imputed_data 27 28 29def plot_full_data(energy_data_imputed,energy_data_with_missing): 30 plt.figure(figsize=(24, 6)) 31 32 plt.plot(energy_data_imputed[\u0026#39;Datetime\u0026#39;], energy_data_imputed[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Imputed Data\u0026#39;, color=\u0026#39;blue\u0026#39; ) 33 plt.plot(energy_data_with_missing[\u0026#39;Datetime\u0026#39;], energy_data_with_missing[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 34 plt.xlabel(\u0026#39;Datetime\u0026#39;) 35 plt.ylabel(\u0026#39;Energy Production\u0026#39;) 36 plt.title(\u0026#39;Simulated Energy Production Over Time (Original vs Imputed)\u0026#39;) 37 plt.legend() 38 plt.grid(True) 39 plt.show() 40 41# Main script 42if __name__ == \u0026#34;__main__\u0026#34;: 43 44 start_date = datetime(2024, 1, 1) 45 end_date = datetime(2024, 4, 30) 46 47 # Generate the simulated dataset 48 energy_data_with_missing = simulate_energy_data(start_date, end_date) 49 50 51 plot_origin_data(energy_data_with_missing) 52 53 54 # Impute the missing values 55 energy_data_imputed = impute_missing_values(energy_data_with_missing.copy()) 56 57 # Display the first few rows of the dataset 58 print(energy_data_imputed.head()) 59 60 plot_full_data(energy_data_imputed,energy_data_with_missing) Code Ä‘Æ¡n giáº£n pháº£i khÃ´ng cÃ¡c báº¡n, nhÃ¬n vÃ o Ä‘á»“ thá»‹ thÃ¬ chÃºng ta thÃ¡y ráº±ng xu hÆ°á»›ng cá»§a missing data Ä‘Ã£ giá»‘ng gáº§n nhÆ° i sÃ¬ vá»›i xu hÆ°á»›ng cá»§a dá»¯ liá»‡u gá»‘c rá»“i Ä‘Ã³.\nMáº·c dÃ¹ chÃºng ta cÃ³ thá»ƒ quan sÃ¡t ráº±ng cÃ¡c giÃ¡ trá»‹ tÃ¡i táº¡o theo xu hÆ°á»›ng chung cá»§a dá»¯ liá»‡u gá»‘c, nhÆ°ng Ä‘iá»u nÃ y khÃ´ng Ä‘á»§ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ hiá»‡u quáº£ cá»§a phÆ°Æ¡ng phÃ¡p tÃ¡i táº¡o dá»¯ liá»‡u. ChÃºng ta cáº§n Ä‘Æ°a ra cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘á»‹nh lÆ°á»£ng Ä‘á»ƒ chá»©ng minh mÃ´ hÃ¬nh nÃ y á»•n, á»Ÿ má»©c cháº¥p nháº­n Ä‘Æ°á»£c\nÄÃ¡nh giÃ¡ hiá»‡u quáº£ cá»§a viá»‡c tÃ¡i táº¡o dá»¯ liá»‡u 1.Statistical Comparison - So sÃ¡nh thá»‘ng kÃª So sÃ¡nh cÃ¡c chá»‰ sá»‘ thá»‘ng kÃª (trung bÃ¬nh, Ä‘á»™ lá»‡ch chuáº©n, giÃ¡ trá»‹ nhá» nháº¥t, giÃ¡ trá»‹ lá»›n nháº¥t) Ä‘á»ƒ Ä‘áº£m báº£o dá»¯ liá»‡u tÃ¡i táº¡o phÃ¹ há»£p vá»›i phÃ¢n phá»‘i dá»¯ liá»‡u gá»‘c.\n1 2# Statistical comparison function using describe 3def statistical_comparison(original_data, imputed_data): 4 original_stats = original_data[\u0026#39;Energy_Production\u0026#39;].describe() 5 imputed_stats = imputed_data[\u0026#39;Energy_Production\u0026#39;].describe() 6 comparison = pd.DataFrame({ 7 \u0026#39;Metric\u0026#39;: original_stats.index, 8 \u0026#39;Original Data\u0026#39;: original_stats.values, 9 \u0026#39;Imputed Data\u0026#39;: imputed_stats.values 10 }) 11 return comparison 12 13comparison = statistical_comparison(energy_data_with_missing.dropna(), energy_data_imputed) 14print(comparison) Káº¿t quáº£\n1 Metric Original Data Imputed Data 20 count 15553.000000 17281.000000 31 mean 185.155737 185.155865 42 std 127.062030 120.541640 53 min -16.984058 -16.984058 64 25% 51.260972 53.436820 75 50% 257.313693 185.404682 86 75% 302.393653 298.653209 97 max 415.581945 415.581945 Tá»« báº£ng so sÃ¡nh thá»‘ng kÃª á»Ÿ trÃªn , chÃºng ta cÃ³ thá»ƒ rÃºt ra nhá»¯ng káº¿t luáº­n sau:\nSá»‘ LÆ°á»£ng (Count): Bá»™ dá»¯ liá»‡u tÃ¡i táº¡o chá»©a nhiá»u Ä‘iá»ƒm dá»¯ liá»‡u hÆ¡n, 17281, so vá»›i bá»™ dá»¯ liá»‡u gá»‘c, 15553, do viá»‡c tÃ¡i táº¡o cÃ¡c giÃ¡ trá»‹ thiáº¿u Ä‘á»ƒ Ä‘áº£m báº£o dá»¯ liá»‡u Ä‘áº§y Ä‘á»§.\nTrung BÃ¬nh (Mean): Trung bÃ¬nh cá»§a dá»¯ liá»‡u tÃ¡i táº¡o lÃ  185.1558, gáº§n giá»‘ng vá»›i giÃ¡ trá»‹ trung bÃ¬nh cá»§a dá»¯ liá»‡u gá»‘c 185.1557, Ä‘iá»u nÃ y cÃ³ nghÄ©a lÃ  xu hÆ°á»›ng trung tÃ¢m cá»§a dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c duy trÃ¬ trong quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u.\nÄá»™ Lá»‡ch Chuáº©n (Standard Deviation): Dá»¯ liá»‡u tÃ¡i táº¡o cÃ³ sá»± phÃ¢n tÃ¡n tháº¥p hÆ¡n (Ä‘á»™ lá»‡ch chuáº©n = 120.54 so vá»›i 127.06 cá»§a dá»¯ liá»‡u gá»‘c). Äiá»u nÃ y cÃ³ thá»ƒ cho tháº¥y ráº±ng trong quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u, cÃ¡c giÃ¡ trá»‹ Ä‘Ã£ trá»Ÿ nÃªn mÆ°á»£t mÃ  hÆ¡n, giáº£m bá»›t sá»± phÃ¢n tÃ¡n. Há»“i quy tuyáº¿n tÃ­nh Ä‘Ã£ lÃ m \u0026ldquo;phÃ©p mÃ u dá»± Ä‘oÃ¡n\u0026rdquo; cá»§a mÃ¬nh báº±ng cÃ¡ch luÃ´n tráº£ vá» cÃ¡c giÃ¡ trá»‹ gáº§n vá»›i trung bÃ¬nh.\nGiÃ¡ Trá»‹ Tá»‘i Thiá»ƒu vÃ  Tá»‘i Äa: GiÃ¡ trá»‹ tá»‘i thiá»ƒu (-16.984058) vÃ  tá»‘i Ä‘a (415.581945) lÃ  giá»‘ng nhau, Ä‘iá»u nÃ y gá»£i Ã½ ráº±ng quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u khÃ´ng táº¡o ra cÃ¡c giÃ¡ trá»‹ ngoáº¡i lai cá»±c Ä‘oan hoáº·c khÃ´ng Ä‘i ra ngoÃ i pháº¡m vi cá»§a dá»¯ liá»‡u gá»‘c.\nCÃ¡c PhÃ¢n Vá»‹ (Quartiles 25%, 50%, 75%):\nPhÃ¢n vá»‹ thá»© 25 (quartile tháº¥p) cao hÆ¡n má»™t chÃºt trong dá»¯ liá»‡u tÃ¡i táº¡o , 53.43 so vá»›i 51.26 cá»§a dá»¯ liá»‡u gá»‘c, cho tháº¥y cÃ¡c giÃ¡ trá»‹ tÃ¡i táº¡o Ä‘Ã£ láº¥p Ä‘áº§y nhiá»u khoáº£ng trá»‘ng á»Ÿ pháº¡m vi tháº¥p. Trung vá»‹ (50%) Ä‘Ã£ thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ tá»« 257.31 trong dá»¯ liá»‡u gá»‘c thÃ nh 185.40 trong dá»¯ liá»‡u tÃ¡i táº¡o , cho tháº¥y cÃ¡c giÃ¡ trá»‹ tÃ¡i táº¡o Ä‘Ã£ giáº£m Ä‘á»™ lá»‡ch dá»¯ liá»‡u cá»§a cÃ¡c pháº§n tá»­ dá»¯ liá»‡u cao. PhÃ¢n vá»‹ thá»© 75 (quartile cao) 302.39 vÃ  298.65 , gáº§n nhÆ° tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhau, pháº£n Ã¡nh ráº±ng cÃ¡c giÃ¡ trá»‹ cao Ä‘Ã£ Ä‘Æ°á»£c báº£o tá»“n tá»‘t. Káº¿t luáº­n: PhÆ°Æ¡ng phÃ¡p há»“i quy tuyáº¿n tÃ­nh Ä‘Ã£ báº£o tá»“n phÃ¢n phá»‘i tá»•ng thá»ƒ vÃ  pháº¡m vi cá»§a dá»¯ liá»‡u, trong khi lÃ m giáº£m sá»± biáº¿n thiÃªn vÃ  lÃ m mÆ°á»£t dá»¯ liá»‡u má»™t chÃºt.\n2.Autocorrelation Kiá»ƒm tra xem tá»± tÆ°Æ¡ng quan cá»§a chuá»—i cÃ³ Ä‘Æ°á»£c duy trÃ¬ sau khi tÃ¡i táº¡o dá»¯ liá»‡u hay khÃ´ng.\n1 2 3# Autocorrelation analysis function 4def autocorrelation_analysis(original_data, imputed_data): 5 fig, axes = plt.subplots(1, 2, figsize=(15, 6)) 6 plot_acf(original_data[\u0026#39;Energy_Production\u0026#39;].dropna(), ax=axes[0], title=\u0026#39;ACF of Original Data\u0026#39;) 7 plot_acf(imputed_data[\u0026#39;Energy_Production\u0026#39;], ax=axes[1], title=\u0026#39;ACF of Imputed Data\u0026#39;) 8 plt.tight_layout() 9 plt.show() Quan sÃ¡t Ä‘á»“ thá»‹ ACF trÃªn, chÃºng ta cÃ³ thá»ƒ rÃºt ra cÃ¡c Ã½ chÃ­nh sau\nBáº£o Tá»“n CÃ¡c Phá»¥ Thuá»™c - Preservation of Temporal Dependencies:\nHÃ¬nh dáº¡ng vÃ  sá»± suy giáº£m cá»§a ACF trong dá»¯ liá»‡u tÃ¡i táº¡o cÃ³ sá»± tÆ°Æ¡ng Ä‘á»“ng Ä‘Ã¡ng ká»ƒ vá»›i dá»¯ liá»‡u gá»‘c. Äiá»u nÃ y cho tháº¥y ráº±ng cÃ¡c phá»¥ thuá»™c thá»i gian Ä‘Ã£ Ä‘Æ°á»£c báº£o tá»“n khÃ¡ tá»‘t sau quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u.\nHiá»‡u á»¨ng LÃ m Má»‹n - Slight Smoothing Effect:\nACF trÃªn dá»¯ liá»‡u tÃ¡i táº¡o cho tháº¥y giÃ¡ trá»‹ á»Ÿ má»™t sá»‘ Ä‘á»™ trá»… (lags) tháº¥p hÆ¡n so vá»›i dá»¯ liá»‡u gá»‘c. Äiá»u nÃ y cÃ³ thá»ƒ lÃ  do mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh lÃ m má»‹n cÃ¡c cá»±c trá»‹, dáº«n Ä‘áº¿n giáº£m nháº¹ má»©c Ä‘á»™ biáº¿n Ä‘á»™ng.\nCÃ¡c Máº«u Chu Ká»³ Trong ACF - Cyclic Patterns:\nCÃ¡c Ä‘á»‰nh chu ká»³ trong ACF, cháº³ng háº¡n nhÆ° tÃ­nh mÃ¹a vá»¥ hÃ ng ngÃ y, dÆ°á»ng nhÆ° Ä‘Æ°á»£c duy trÃ¬ giá»¯a dá»¯ liá»‡u gá»‘c vÃ  dá»¯ liá»‡u tÃ¡i táº¡o . Äiá»u nÃ y cho tháº¥y ráº±ng quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u Ä‘Ã£ báº£o tá»“n cÃ¡c hÃ nh vi tuáº§n hoÃ n trong táº­p dá»¯ liá»‡u.\nTÃ­nh á»”n Äá»‹nh Chung:\nSá»± tÆ°Æ¡ng Ä‘á»“ng giá»¯a hai biá»ƒu Ä‘á»“ ACF lÃ  má»™t dáº¥u hiá»‡u tÃ­ch cá»±c, cho tháº¥y phÆ°Æ¡ng phÃ¡p tÃ¡i táº¡o dá»¯ liá»‡u báº±ng há»“i quy tuyáº¿n tÃ­nh Ä‘Ã£ giá»¯ láº¡i tá»‘t cáº¥u trÃºc cá»‘t lÃµi trong dá»¯ liá»‡u.\nKáº¿t Luáº­n:\nPhÆ°Æ¡ng phÃ¡p há»“i quy tuyáº¿n tÃ­nh khÃ´ng chá»‰ báº£o tá»“n má»‘i liÃªn há»‡ thá»i gian trong dá»¯ liá»‡u mÃ  cÃ²n duy trÃ¬ cÃ¡c máº«u chu ká»³, máº·c dÃ¹ cÃ³ má»™t chÃºt hiá»‡u á»©ng lÃ m má»‹n.\n3. PhÃ¢n tÃ­ch xu hÆ°á»›ng vÃ  mÃ¹a vá»¥ - STL Decomposition (Trend and Seasonality) So SÃ¡nh Xu HÆ°á»›ng (Trend Comparison) 1 2# STL decomposition function to extract and plot trend component 3def stl_decomposition_trend(original_data, imputed_data, period): 4 stl_original = STL(original_data[\u0026#39;Energy_Production\u0026#39;] , period=period) 5 result_original = stl_original.fit() 6 trend_original = result_original.trend 7 8 stl_imputed = STL(imputed_data[\u0026#39;Energy_Production\u0026#39;], period=period) 9 result_imputed = stl_imputed.fit() 10 trend_imputed = result_imputed.trend 11 12 plt.figure(figsize=(24, 6)) 13 plt.plot(original_data[\u0026#39;Datetime\u0026#39;], trend_original, label=\u0026#39;Trend of Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 14 plt.plot(imputed_data[\u0026#39;Datetime\u0026#39;], trend_imputed, label=\u0026#39;Trend of Imputed Data\u0026#39;, color=\u0026#39;blue\u0026#39;) 15 plt.xlabel(\u0026#39;Datetime\u0026#39;) 16 plt.ylabel(\u0026#39;Trend\u0026#39;) 17 plt.title(\u0026#39;STL Decomposition Trend of Original and Imputed Data\u0026#39;) 18 plt.legend() 19 plt.grid(True) 20 plt.show() 21 22stl_decomposition_trend(energy_data_with_missing.dropna(), energy_data_imputed, period=144) # Daily seasonality (144 10-min intervals in a day) Báº£o Tá»“n Xu HÆ°á»›ng DÃ i Háº¡n:\nÄÆ°á»ng Xu hÆ°á»›ng tÃ¡i táº¡o (mÃ u xanh dÆ°Æ¡ng) nhÃ¬n chung phÃ¹ há»£p vá»›i xu hÆ°á»›ng gá»‘c (mÃ u Ä‘á»), cho tháº¥y phÆ°Æ¡ng phÃ¡p tÃ¡i táº¡o há»“i quy tuyáº¿n tÃ­nh Ä‘Ã£ báº£o tá»“n Ä‘Æ°á»£c chuyá»ƒn Ä‘á»™ng dÃ i háº¡n trong dá»¯ liá»‡u.\nHiá»‡u á»¨ng LÃ m Má»‹n:\nÄÆ°á»ng Xu hÆ°á»›ng tÃ¡i táº¡o mÆ°á»£t mÃ  hÆ¡n so vá»›i xu hÆ°á»›ng gá»‘c, Ä‘áº·c biá»‡t á»Ÿ nhá»¯ng nÆ¡i xu hÆ°á»›ng gá»‘c cÃ³ nhiá»u biáº¿n Ä‘á»™ng. Äiá»u nÃ y lÃ  Ä‘áº·c Ä‘iá»ƒm cá»§a há»“i quy tuyáº¿n tÃ­nh, vá»‘n cÃ³ xu hÆ°á»›ng khÃ´ng pháº£n Ã¡nh tá»‘t cÃ¡c biáº¿n Ä‘á»™ng máº¡nh vÃ  lÃ m má»‹n cÃ¡c cá»±c trá»‹.\nSo SÃ¡nh TÃ­nh MÃ¹a Vá»¥ (Seasonality Comparison) 1 2 3def stl_decomposition_seasonality(original_data, imputed_data, period): 4 stl_original = STL(original_data[\u0026#39;Energy_Production\u0026#39;], period=period) 5 result_original = stl_original.fit() 6 seasonality_original = result_original.seasonal 7 8 stl_imputed = STL(imputed_data[\u0026#39;Energy_Production\u0026#39;], period=period) 9 result_imputed = stl_imputed.fit() 10 seasonality_imputed = result_imputed.seasonal 11 12 plt.figure(figsize=(24, 6)) 13 plt.plot(original_data[\u0026#39;Datetime\u0026#39;], seasonality_original, label=\u0026#39;Seasonality of Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 14 plt.plot(imputed_data[\u0026#39;Datetime\u0026#39;], seasonality_imputed, label=\u0026#39;Seasonality of Imputed Data\u0026#39;, color=\u0026#39;blue\u0026#39;) 15 plt.xlabel(\u0026#39;Datetime\u0026#39;) 16 plt.ylabel(\u0026#39;Seasonality\u0026#39;) 17 plt.title(\u0026#39;STL Decomposition Seasonality of Original and Imputed Data\u0026#39;) 18 plt.legend() 19 plt.grid(True) 20 plt.show() 21stl_decomposition_seasonality(energy_data_with_missing.dropna(), energy_data_imputed, period=144) # Daily seasonality (144 10-min intervals in a day) Báº£o Tá»“n tÃ­nh Chu Ká»³:\nÄÆ°á»ng mÃ¹a vá»¥ tÃ¡i táº¡o thá»ƒ hiá»‡n ra cÃ¡c máº«u chu ká»³ tÆ°Æ¡ng Ä‘á»‘i gáº§n giá»‘ng vá»›i chu ká»³ cá»§a Ä‘Æ°á»ng mÃ¹a vá»¥ gá»‘c, pháº£n Ã¡nh ráº±ng dá»¯ liá»‡u cÃ¡c chu ká»³ sáº£n xuáº¥t ngÃ y-Ä‘Ãªm Ä‘Ã£ Ä‘Æ°á»£c duy trÃ¬ khÃ¡ tá»‘t.\nGiáº£m BiÃªn Äá»™ Chu Ká»³:\nBiÃªn Ä‘á»™ cá»§a Ä‘Æ°á»ng mÃ¹a vá»¥ tÃ¡i táº¡o bá»‹ giáº£m nháº¹ so vá»›i gá»‘c, Ä‘áº·c biá»‡t táº¡i cÃ¡c Ä‘á»‰nh vÃ  Ä‘Ã¡y. Äiá»u nÃ y cho tháº¥y quÃ¡ trÃ¬nh tÃ¡i táº¡o dá»¯ liá»‡u Ä‘Ã£ lÃ m cho cÃ¡c biáº¿n Ä‘á»™ng chu ká»³ á»Ÿ cá»±c trá»‹ trá»Ÿ nÃªn Ã­t máº¡nh máº½ hÆ¡n.\nHáº¡n Cháº¿ Cá»§a tÃ¡i táº¡o Dá»¯ Liá»‡u Báº±ng linear regression LÃ m Má»‹n CÃ¡c cá»±c trá»‹:\nTá»« so sÃ¡nh thá»‘ng kÃª, Ä‘á»™ lá»‡ch chuáº©n tháº¥p hÆ¡n á»Ÿ dá»¯ liá»‡u tÃ¡i táº¡o cho tháº¥y tÃ­nh biáº¿n Ä‘á»™ng Ä‘Ã£ bá»‹ giáº£m.\nTá»« so sÃ¡nh xu hÆ°á»›ng, xu hÆ°á»›ng tÃ¡i táº¡o mÆ°á»£t hÆ¡n vÃ  thiáº¿u má»™t sá»‘ biáº¿n Ä‘á»™ng gá»‘c trong cÃ¡c máº«u dÃ i háº¡n.\nGiáº£ Äá»‹nh Tuyáº¿n TÃ­nh:\nHiá»‡u á»©ng lÃ m má»‹n trong so sÃ¡nh xu hÆ°á»›ng cho tháº¥y phÆ°Æ¡ng phÃ¡p nÃ y khÃ³ báº¯t ká»‹p cÃ¡c thay Ä‘á»•i phi tuyáº¿n tÃ­nh trong dá»¯ liá»‡u, Ä‘áº·c biá»‡t táº¡i cÃ¡c giai Ä‘oáº¡n cÃ³ sá»± thay Ä‘á»•i Ä‘á»™t ngá»™t. Giáº£m BiÃªn Äá»™ MÃ¹a Vá»¥:\nSo sÃ¡nh tÃ­nh mÃ¹a vá»¥ cho tháº¥y biÃªn Ä‘á»™ chu ká»³ tÃ¡i táº¡o tháº¥p hÆ¡n so vá»›i gá»‘c, vá»›i cÃ¡c Ä‘á»‰nh vÃ  Ä‘Ã¡y bá»‹ lÃ m má»‹n. Äiá»u nÃ y phÃ¹ há»£p vá»›i xu hÆ°á»›ng cá»§a há»“i quy trong viá»‡c kÃ©o cÃ¡c giÃ¡ trá»‹ cá»±c Ä‘oan vá» trung bÃ¬nh. Káº¿t luáº­n PhÆ°Æ¡ng phÃ¡p tÃ¡i táº¡o há»“i quy tuyáº¿n tÃ­nh báº£o tá»“n Ä‘Æ°á»£c cÃ¡c xu hÆ°á»›ng tá»•ng thá»ƒ vÃ  cÃ¡c máº«u chu ká»³, nhÆ°ng lÃ m giáº£m tÃ­nh biáº¿n Ä‘á»™ng vÃ  lÃ m má»‹n cÃ¡c giÃ¡ trá»‹ cá»±c Ä‘oan. NgoÃ i ra, nÃ³ thá»ƒ hiá»‡n sá»± giáº£m nháº¹ cÆ°á»ng Ä‘á»™ cá»§a cÃ¡c chu ká»³ mÃ¹a vá»¥, Ä‘iá»u nÃ y Ä‘Æ°á»£c pháº£n Ã¡nh trong cáº£ phÃ¢n tÃ­ch thá»‘ng kÃª vÃ  phÃ¢n rÃ£ dá»¯ liá»‡u.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t. Xin cáº£m Æ¡n vÃ  háº¹n gáº·p láº¡i.\nTÃ i liá»‡u tham kháº£o https://www.geeksforgeeks.org/managing-missing-data-in-linear-regression/\nhttps://towardsdatascience.com/missing-data-in-time-series-machine-learning-techniques-6b2273ff8b45\nhttps://www.geeksforgeeks.org/dataset-for-linear-regression/\nhttps://www.geeksforgeeks.org/ml-handling-missing-values/\nhttps://codezup.com/mastering-linear-regression-time-series-forecasting/\n","date":"Jan 10, 2025","img":"https://unsplash.it/1920/1080?image=203","permalink":"/blog/2025-01-10-data-missing-time-serial-linear-regression/","series":null,"tags":["Missing data","time-serials"],"title":"Xá»­ LÃ½ Dá»¯ Liá»‡u Khiáº¿m Khuyáº¿t Trong Dá»¯ Liá»‡u Chuá»—i Thá»i Gian Sá»­ Dá»¥ng PhÆ°Æ¡ng PhÃ¡p Linear Regression - Machine Learning Techniques for Mising Data in Time-Serials Using Liner Regression"},{"categories":null,"content":" I. Bloom Filters lÃ  gÃ¬? II. NguyÃªn lÃ½ Bloom Filters hoáº¡t Ä‘á»™ng Cáº¥u trÃºc dá»¯ liá»‡u XÃ¡c suáº¥t dÆ°Æ¡ng tÃ­nh sai CÃ´ng thá»©c Æ°á»›c lÆ°á»£ng sá»‘ pháº§n tá»­ vÃ  sá»‘ hÃ m hash III. Æ¯u Ä‘iá»ƒm cá»§a bá»™ lá»c Bloom 1. Tiáº¿t kiá»‡m bá»™ nhá»› 2. Kiá»ƒm tra thÃ nh viÃªn nhanh chÃ³ng 3. KhÃ´ng cÃ³ false negative 4. Dá»… dÃ ng má»Ÿ rá»™ng 5. Thiáº¿t káº¿ Ä‘Æ¡n giáº£n 6. ThÃ¢n thiá»‡n vá»›i há»‡ thá»‘ng phÃ¢n tÃ¡n 7. á»¨ng dá»¥ng rá»™ng rÃ£i 8. Há»— trá»£ tÃ­nh toÃ¡n song song 9. á»¨ng dá»¥ng trong báº£o máº­t vÃ  quyá»n riÃªng tÆ° 10. Dá»… báº£o trÃ¬ Khi nÃ o nÃªn sá»­ dá»¥ng Bloom Filter? Háº¡n cháº¿ cá»§a bá»™ lá»c Bloom Filter 1. False Positive (Káº¿t quáº£ dÆ°Æ¡ng tÃ­nh giáº£) 2. KhÃ´ng há»— trá»£ xÃ³a pháº§n tá»­ 3. KhÃ´ng lÆ°u trá»¯ dá»¯ liá»‡u gá»‘c 4. KhÃ³ Ä‘iá»u chá»‰nh tá»· lá»‡ false positive 5. YÃªu cáº§u chá»n hÃ m bÄƒm phÃ¹ há»£p 6. KhÃ´ng hiá»‡u quáº£ vá»›i táº­p dá»¯ liá»‡u nhá» 7. KhÃ´ng thá»ƒ má»Ÿ rá»™ng má»™t cÃ¡ch Ä‘Æ¡n giáº£n 8. KhÃ´ng há»— trá»£ kiá»ƒm tra phá»§ Ä‘á»‹nh (No False Negatives) 9. KhÃ³ triá»ƒn khai vÃ  báº£o trÃ¬ trong há»‡ thá»‘ng lá»›n 10. KhÃ´ng phÃ¹ há»£p vá»›i dá»¯ liá»‡u Ä‘á»™ng Khi nÃ o khÃ´ng nÃªn sá»­ dá»¥ng Bloom Filter? Má»™t sá»‘ biáº¿n thá»ƒ cá»§a Bloom Filter Double Hashing Bloom Filter: CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Double Hashing Bloom Filter Æ¯u Ä‘iá»ƒm cá»§a Double Hashing Bloom Filter Háº¡n cháº¿ cá»§a Double Hashing Bloom Filter á»¨ng dá»¥ng cá»§a Double Hashing Bloom Filter Triá»ƒn khai Double Hashing Bloom Filter báº±ng Python TÃ³m táº¯t Partitioning Bloom Filter: CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Partitioning Bloom Filter Æ¯u Ä‘iá»ƒm cá»§a Partitioning Bloom Filter Háº¡n cháº¿ cá»§a Partitioning Bloom Filter á»¨ng dá»¥ng cá»§a Partitioning Bloom Filter Triá»ƒn khai Partitioning Bloom Filter báº±ng Python TÃ³m táº¯t Counting Bloom Filter: CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Counting Bloom Filter Æ¯u Ä‘iá»ƒm cá»§a Counting Bloom Filter Háº¡n cháº¿ cá»§a Counting Bloom Filter á»¨ng dá»¥ng cá»§a Counting Bloom Filter Triá»ƒn khai báº±ng Python TÃ³m táº¯t Scalable Bloom Filter Váº¥n Ä‘á» vá»›i Bloom Filter truyá»n thá»‘ng Scalable Bloom Filter giáº£i quyáº¿t váº¥n Ä‘á» nhÆ° tháº¿ nÃ o? Cáº¥u trÃºc vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Scalable Bloom Filter Æ¯u Ä‘iá»ƒm cá»§a Scalable Bloom Filter Háº¡n cháº¿ cá»§a Scalable Bloom Filter á»¨ng dá»¥ng cá»§a Scalable Bloom Filter Triá»ƒn khai Scalable Bloom Filter MÃ£ giáº£ Scalable Bloom Filter Striped Bloom Filter Äáº·c Ä‘iá»ƒm cá»§a Striped Bloom Filter CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Striped Bloom Filter Æ¯u Ä‘iá»ƒm cá»§a Striped Bloom Filter Háº¡n cháº¿ cá»§a Striped Bloom Filter Triá»ƒn khai báº±ng Python Quotient Filter (Bá»™ lá»c thÆ°Æ¡ng sá»‘) NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng Æ¯u Ä‘iá»ƒm cá»§a Quotient Filter Háº¡n cháº¿ cá»§a Quotient Filter á»¨ng dá»¥ng cá»§a Quotient Filter So sÃ¡nh vá»›i Bloom Filter VÃ­ dá»¥ mÃ£ giáº£ báº±ng Python Káº¿t luáº­n Cuckoo Filter NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng Thao tÃ¡c chÃ­nh trong Cuckoo Filter Æ¯u Ä‘iá»ƒm cá»§a Cuckoo Filter Háº¡n cháº¿ cá»§a Cuckoo Filter á»¨ng dá»¥ng cá»§a Cuckoo Filter So sÃ¡nh vá»›i Bloom Filter VÃ­ dá»¥ mÃ£ giáº£ Cuckoo Filter báº±ng Python Káº¿t luáº­n á»¨ng Dá»¥ng cá»§a Bloom Filter trong CÃ¡c LÄ©nh Vá»±c 1. PhÃ¡t Hiá»‡n Gian Láº­n TÃ i ChÃ­nh (Financial Fraud Detection) 2. Äáº·t Quáº£ng CÃ¡o (Ad Placement - Retail, Advertising) 3. Kiá»ƒm Tra TÃªn NgÆ°á»i DÃ¹ng (SaaS, Content Publishing Platforms) 4. CÃ¡c á»¨ng Dá»¥ng KhÃ¡c Cá»§a Bloom Filter BÃ i táº­p Financial Fraud Detection Spell Checker Recommendation Systems Bloom Filters Giáº£ sá»­ báº¡n muá»‘n láº­p má»™t tÃ i khoáº£ng phá»Ÿ bÃ², username lÃ  phamduytung, báº¡n hÄƒng hÃ¡i hÄƒm há»Ÿ gÃµ vÃ o cÃ¡i tÃªn Ä‘Ã³ trong Ã´ username vÃ  .. bÃ¹m, phá»Ÿ bÃ² bÃ¡o láº¡i cho báº¡n ráº±ng username Ä‘Ã³ Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng, báº¡n cá»‘ gáº¯ng thá»­ vá»›i vÃ i trÆ°á»ng há»£p nhÆ° nhÃ©t nÄƒm sinh cá»§a báº¡n vÃ o, nhÃ©t thÃªm chá»¯ viáº¿t táº¯t cá»§a trÆ°á»ng Ä‘áº¡i há»c vÃ o, nhÆ°ng phá»Ÿ bÃ² váº«n tráº£ lá»i láº¡i lÃ  tÃªn username Ä‘Ã³ Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng, tháº­t lÃ  bá»±c bá»™i pháº£i khÃ´ng?\nKhoan khoan trÃºt ná»—i bá»±c bá»™i hoáº·c tÃ¬m cÃ¡ch Ä‘áº·t tÃªn á»Ÿ Ä‘Ã¢y, chÃºng ta trá»Ÿ láº¡i báº£n cháº¥t cá»§a váº¥n Ä‘á» lÃ  há»‡ thá»‘ng search username hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?\nPhÆ°Æ¡ng Ã¡n a: tÃ¬m kiáº¿m tuyáº¿n tÃ­nh, duyá»‡t táº¥t cáº£ cÃ¡c username, náº¿u gáº·p 1 username trÃ¹ng vá»›i username mÃ¬nh nháº­p vÃ o -\u0026gt; bÃ¡o username Ä‘Ã³ Ä‘Ã£ tá»“n táº¡i\nPhÆ°Æ¡ng Ã¡n b: tÃ¬m kiáº¿m nhá»‹ phÃ¢n binary search, so sÃ¡nh tÃªn ngÆ°á»i dÃ¹ng vá»›i tÃªn á»Ÿ giá»¯a danh sÃ¡ch, náº¿u khá»›p thÃ¬ tráº£ ra Ä‘Ã£ cÃ³ , náº¿u khÃ´ng khá»›p thÃ¬ xem tÃªn ngÆ°á»i dÃ¹ng lá»›n hÆ¡n hay nhá» hÆ¡n tÃªn á»Ÿ giá»¯a, náº¿u lá»›n hÆ¡n thÃ¬ chÃºng ta sáº½ chá»‰ láº·p láº¡i viá»‡c tÃ¬m kiáº¿m nhÆ° trÃªn nhÆ°ng á»Ÿ pháº¡m vi cÃ²n 1 pháº§n 2 tá»« tÃªn á»Ÿ giá»¯a Ä‘áº¿n háº¿t. Náº¿u nhá» hÆ¡n thÃ¬ pháº¡m vi tÃ¬m kiáº¿m cÅ©ng cÃ²n lÃ  1 pháº§n 2 tá»« Ä‘áº§u Ä‘áº¿n tÃªn á»Ÿ giá»¯a, láº·p Ä‘i láº·p láº¡i viá»‡c nÃ y Ä‘áº¿n khi tÃ¬m tháº¥y ( tráº£ ra tÃªn Ä‘Ã£ sá»­ dá»¥ng) hoáº·c háº¿t pháº¡m vi tÃ¬m kiáº¿m (tráº£ ra tÃªn kháº£ dá»¥ng). CÃ¡ch nÃ y á»•n nhÆ°ng viá»‡c tÃ¬m kiáº¿m cÅ©ng tráº£i qua khÃ¡ nhiá»u bÆ°á»›c.\nPhÆ°Æ¡ng Ã¡n c: lÆ°u toÃ n bá»™ user dÆ°á»›i dáº¡ng 1 cÃ¡i cÃ¢y rá»“i duyá»‡t node. CÃ¡ch nÃ y á»•n, nhÆ°ng khÃ¡ tá»‘n bá»™ nhá»› khi tÃªn username dÃ i\nCÃ²n phÆ°Æ¡ng Ã¡n nÃ o khÃ¡c khÃ´ng?\nCÃ³, táº¥t nhiÃªn lÃ  cÃ³ rá»“i, Ä‘Ã³ chÃ­nh lÃ  Bloom Filters\nI. Bloom Filters lÃ  gÃ¬? Bloom filter, Ä‘Æ°á»£c phÃ¡t minh bá»Ÿi Burton Howard Bloom nÄƒm 1970, lÃ  má»™t cáº¥u trÃºc dá»¯ liá»‡u xÃ¡c suáº¥t dá»±a trÃªn thuáº­t toÃ¡n hasing. NÃ³ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ kiá»ƒm tra xem má»™t pháº§n tá»­ cÃ³ pháº£i thuá»™c vá» má»™t táº­p há»£p hay khÃ´ng. Táº¥t nhiÃªn, ngÆ°á»i ta cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c cáº¥u trÃºc dá»¯ liá»‡u khÃ¡c Ä‘á»ƒ thá»±c hiá»‡n viá»‡c nÃ y, nhÆ°ng Bloom filter cÃ³ Æ°u Ä‘iá»ƒm vá» hiá»‡u quáº£ vá» khÃ´ng gian vÃ  thá»i gian.\nII. NguyÃªn lÃ½ Bloom Filters hoáº¡t Ä‘á»™ng Cáº¥u trÃºc dá»¯ liá»‡u Bloom Filters Ä‘Æ°á»£c cáº¥u thÃ nh tá»« 2 thÃ nh pháº§n, thá»© nháº¥t lÃ  má»™t máº£ng N bit , má»—i pháº§n tá»­ trong máº£ng mang giÃ¡ trá»‹ 0 hoáº·c 1, giÃ¡ trá»‹ khá»Ÿi táº¡o ban Ä‘áº§u lÃ  0. ThÃ nh pháº§n thá»© 2 lÃ  k thuáº­t toÃ¡n hash khÃ¡c nhau, má»—i hÃ m hash sáº½ Ä‘Æ°á»£c chia láº¥y dÆ° cho N, vÃ  kÃ­ch hoáº¡t Ã´ nhá»› tÆ°Æ¡ng á»©ng vá»›i giÃ¡ trá»‹ sau chia dÆ° cá»§a hash.\nGiáº£ sá»­\nchÃºng ta cÃ³ N = 5, k =3 nghÄ©a lÃ  cÃ³ 3 hÃ m hash , Ä‘áº·t tÃªn lÃ  hash1, hash2, hash 3, tá»« khoÃ¡ cáº§n check vÃ  náº¿u khÃ´ng cÃ³ thÃ¬ thÃªm vÃ o lÃ  chá»¯ \u0026ldquo;duy\u0026rdquo; vÃ  chá»¯ \u0026ldquo;tung\u0026rdquo;\ná» thá»i Ä‘iá»ƒm báº¯t Ä‘áº§u , chÃºng ta cÃ³ 1 máº£ng 5 pháº§n tá»­ Ä‘á»u mang giÃ¡ trá»‹ 0\n[0,0,0,0,0]\nkiá»ƒm tra chá»¯ \u0026ldquo;duy\u0026rdquo;\nhash1(\u0026ldquo;duy\u0026rdquo;) %5 = 1 hash2(\u0026ldquo;duy\u0026rdquo;) %5 = 2 hash3(\u0026ldquo;duy\u0026rdquo;) %5 = 4\ncheck cÃ¡c giÃ¡ trá»‹ á»Ÿ vá»‹ trÃ­ 1,2,4, chÃºng ta cÃ³ toÃ n sá»‘ 0, do dÃ³ tá»« khoÃ¡ chÆ°a cÃ³ trong máº£ng, thÃªm vÃ o máº£ng.\nváº­y máº£ng chÃºng ta thu Ä‘Æ°á»£c sau khi thÃªm chá»¯ \u0026ldquo;duy\u0026rdquo; sáº½ lÃ  [0,1,1,0,1]\nkiá»ƒm tra chá»¯ \u0026ldquo;tung\u0026rdquo;\nhash1(\u0026ldquo;tung\u0026rdquo;) %5 = 1 hash2(\u0026ldquo;tung\u0026rdquo;) %5 = 3 hash3(\u0026ldquo;tung\u0026rdquo;) %5 = 4\ncheck cÃ¡c giÃ¡ trá»‹ á»Ÿ bá»‹ trÃ­ 1,3,4, chÃºng ta tháº¥y á»Ÿ 1 vÃ  4 Ä‘Ã£ lÃ  1, nhÆ°ng á»Ÿ 3 lÃ  0, váº­y lÃ  chá»¯ \u0026ldquo;tung\u0026rdquo; chÆ°a cÃ³, thÃªm vÃ o máº£ng\nváº­y máº£ng chÃºng ta cÃ³ sau khi thÃªm chá»¯ \u0026ldquo;tung\u0026rdquo; sáº½ lÃ  [0,1,1,1,1]\ngiá» giáº£ sá»­ thÃªm chá»¯ \u0026ldquo;pham\u0026rdquo; nha\nkiá»ƒm tra chá»¯ \u0026ldquo;pham\u0026rdquo;\nhash1(\u0026ldquo;tung\u0026rdquo;) %5 = 2 hash2(\u0026ldquo;tung\u0026rdquo;) %5 = 3 hash3(\u0026ldquo;tung\u0026rdquo;) %5 = 4\ncheck cÃ¡c giÃ¡ trá»‹ á»Ÿ bá»‹ trÃ­ 2,3,4, chÃºng ta tháº¥y cáº£ 3 vá»‹ trÃ­ 2 , 3, 4 Ä‘á»u lÃ  1 -\u0026gt; chá»¯ \u0026ldquo;pham\u0026rdquo; Ä‘Ã£ cÃ³, thÃ´ng bÃ¡o vá»›i ngÆ°á»i dÃ¹ng lÃ  Ä‘Ã£ cÃ³ , khÃ´ng thÃªm vÃ o\nKhoan khoan, á»§a gÃ¬ ká»³ váº­y, rÃµ rÃ ng chá»¯ \u0026ldquo;pham\u0026rdquo; chÆ°a cÃ³ mÃ \nXÃ¡c suáº¥t dÆ°Æ¡ng tÃ­nh sai ÄÃ¢y, lÃ  váº¥n Ä‘á», cáº¥u trÃºc nÃ y tá»“n táº¡i má»™t cÃ¡i gá»i lÃ  XÃ¡c suáº¥t dÆ°Æ¡ng tÃ­nh sai, nghÄ©a lÃ  pháº§n tá»­ chÆ°a cÃ³ nhÆ°ng bÃ¡o cÃ³.\nÄá»ƒ háº¡n cháº¿ cÃ¡i nÃ y, chÃºng ta cÃ³ cÃ´ng thá»©c tÃ­nh, pháº§n chá»©ng minh xÃ¡c xuáº¥t Ä‘á»¥ng Ä‘á»™ thÃ¬ cháº¯c cÃ¡c báº¡n Ä‘á»c wiki Ä‘á»ƒ hiá»ƒu thÃªm, do nÃ³ khÃ¡ rÃµ rÃ ng vÃ  dá»… hiá»ƒu Ä‘á»‘i vá»›i cÃ¡c báº¡n Ä‘Ã£ há»c toÃ¡n cÆ¡ báº£n rá»“i, cÃ²n báº¡n nÃ o chÆ°a há»c thÃ¬ bá» qua nÃ³ Ä‘i, chá»© mÃ¬nh Ä‘em gÃµ láº¡i máº¥y cÃ´ng thá»©c nÃ y thÃ¬ cÃ¡c báº¡n chÆ°a há»c cÅ©ng chÆ°a cháº¯c sáº½ hiá»ƒu\nhttps://en.wikipedia.org/wiki/Bloom_filter\nCÃ´ng thá»©c Æ°á»›c tÃ­nh sá»‘ lÆ°á»£ng pháº§n tá»­ cÃ²n láº¡i cÃ³ thá»ƒ Ä‘Æ°á»£c lÆ°u trá»¯\n$$ [ n* =- \\frac{m}{k}ln\\left[ 1-\\frac{X}{n} \\right] ] $$\nTrong Ä‘Ã³:\nn* lÃ  sá»‘ lÆ°á»£ng pháº§n tá»­ Æ°á»›c tÃ­nh cÃ²n láº¡i cÃ³ thá»ƒ Ä‘Æ°á»£c lÆ°u trá»¯\nk lÃ  sá»‘ lÆ°á»£ng hÃ m hash\nm lÃ  chiá»u dÃ i cá»§a máº£ng\nX lÃ  sá»‘ lÆ°á»£ng pháº§n tá»­ Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n 1\nCÃ´ng thá»©c Æ°á»›c lÆ°á»£ng sá»‘ pháº§n tá»­ vÃ  sá»‘ hÃ m hash CÃ³ nhiá»u cÃ¡ch thá»©c, nhÆ°ng theo wiki, pháº§n Probability of false positives thÃ¬ chÃºng ta sáº½ cÃ³, cÃ¡c báº¡n nÃªn Ä‘á»c ká»¹\n$$ [ m =-n * ln(p)/ln(2)^2 ] $$\n$$ [ k =- \\frac{m}{n}ln2 ] $$\nTrong Ä‘Ã³:\nk lÃ  sá»‘ hÃ m hash\nm lÃ  chiá»u dÃ i máº£ng\nn lÃ  sá»‘ lÆ°á»£ng cáº§n lÆ°u trá»¯, vÃ­ dá»¥ facebook mÃ¬nh thiáº¿t káº¿ cho 20 tá»· username, thÃ¬ set n = 20 tá»·\np lÃ  XÃ¡c suáº¥t dÆ°Æ¡ng tÃ­nh sai, vÃ­ dá»¥ lÃ  0.1% thÃ¬ p= 0.001\nChÃºng ta tÃ­nh Ä‘Æ°á»£c m = 383,402,335 vÃ  k = 14\nIII. Æ¯u Ä‘iá»ƒm cá»§a bá»™ lá»c Bloom Bloom Filter lÃ  má»™t cáº¥u trÃºc dá»¯ liá»‡u nhá» gá»n vÃ  hiá»‡u quáº£, thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ kiá»ƒm tra thÃ nh viÃªn (membership) trong táº­p há»£p. DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c Æ°u Ä‘iá»ƒm ná»•i báº­t cá»§a Bloom Filter:\n1. Tiáº¿t kiá»‡m bá»™ nhá»› KÃ­ch thÆ°á»›c nhá» gá»n: Bloom Filter sá»­ dá»¥ng Ã­t bá»™ nhá»› hÆ¡n nhiá»u so vá»›i cÃ¡c cáº¥u trÃºc dá»¯ liá»‡u khÃ¡c nhÆ° báº£ng bÄƒm (hash table) hoáº·c danh sÃ¡ch. ThÃ­ch há»£p cho dá»¯ liá»‡u lá»›n: Äáº·c biá»‡t há»¯u Ã­ch khi lÃ m viá»‡c vá»›i táº­p dá»¯ liá»‡u khá»•ng lá»“, nÆ¡i mÃ  viá»‡c lÆ°u trá»¯ Ä‘áº§y Ä‘á»§ cÃ¡c pháº§n tá»­ khÃ´ng kháº£ thi. 2. Kiá»ƒm tra thÃ nh viÃªn nhanh chÃ³ng Äá»™ phá»©c táº¡p O(1): Bloom Filter cÃ³ thá»ƒ kiá»ƒm tra má»™t pháº§n tá»­ cÃ³ kháº£ nÄƒng náº±m trong táº­p há»£p hay khÃ´ng trong thá»i gian háº±ng sá»‘. KhÃ´ng lÆ°u trá»¯ pháº§n tá»­: Äiá»u nÃ y giÃºp Bloom Filter hoáº¡t Ä‘á»™ng nhanh hÆ¡n vÃ  giáº£m chi phÃ­ lÆ°u trá»¯. 3. KhÃ´ng cÃ³ false negative Äáº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c khi kiá»ƒm tra sá»± tá»“n táº¡i: Náº¿u Bloom Filter xÃ¡c nháº­n ráº±ng má»™t pháº§n tá»­ náº±m trong táº­p há»£p, Ä‘iá»u Ä‘Ã³ luÃ´n Ä‘Ãºng (khÃ´ng cÃ³ false negative). Kiá»ƒm soÃ¡t false positive: False positive (khi pháº§n tá»­ khÃ´ng thuá»™c táº­p nhÆ°ng láº¡i Ä‘Æ°á»£c bÃ¡o lÃ  thuá»™c) cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£m báº±ng cÃ¡ch Ä‘iá»u chá»‰nh kÃ­ch thÆ°á»›c máº£ng bit vÃ  sá»‘ lÆ°á»£ng hÃ m bÄƒm. 4. Dá»… dÃ ng má»Ÿ rá»™ng Äiá»u chá»‰nh linh hoáº¡t: CÃ³ thá»ƒ thay Ä‘á»•i kÃ­ch thÆ°á»›c máº£ng bit hoáº·c sá»‘ hÃ m bÄƒm Ä‘á»ƒ tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t hoáº·c giáº£m tá»· lá»‡ false positive. CÃ¡c biáº¿n thá»ƒ máº¡nh máº½: Scalable Bloom Filter vÃ  Counting Bloom Filter cho phÃ©p Bloom Filter má»Ÿ rá»™ng hoáº·c há»— trá»£ cáº­p nháº­t dá»¯ liá»‡u dá»… dÃ ng. 5. Thiáº¿t káº¿ Ä‘Æ¡n giáº£n KhÃ´ng cáº§n xá»­ lÃ½ xung Ä‘á»™t: KhÃ´ng nhÆ° báº£ng bÄƒm, Bloom Filter khÃ´ng cáº§n cÃ¡c cÆ¡ cháº¿ xá»­ lÃ½ xung Ä‘á»™t phá»©c táº¡p. KhÃ´ng cáº§n thay Ä‘á»•i kÃ­ch thÆ°á»›c: Bloom Filter khÃ´ng yÃªu cáº§u \u0026ldquo;resize\u0026rdquo; nhÆ° cÃ¡c cáº¥u trÃºc dá»¯ liá»‡u khÃ¡c khi dá»¯ liá»‡u tÄƒng lÃªn. 6. ThÃ¢n thiá»‡n vá»›i há»‡ thá»‘ng phÃ¢n tÃ¡n Hiá»‡u quáº£ trÃªn máº¡ng: Bloom Filter cÃ³ thá»ƒ Ä‘Æ°á»£c truyá»n qua máº¡ng vá»›i dung lÆ°á»£ng nhá», giÃºp Ä‘á»“ng bá»™ dá»¯ liá»‡u giá»¯a cÃ¡c há»‡ thá»‘ng phÃ¢n tÃ¡n hiá»‡u quáº£. á»¨ng dá»¥ng trong há»‡ thá»‘ng lÆ°u trá»¯: Giáº£m sá»‘ láº§n truy cáº­p khÃ´ng cáº§n thiáº¿t vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¢n tÃ¡n. 7. á»¨ng dá»¥ng rá»™ng rÃ£i Äa dáº¡ng á»©ng dá»¥ng: ÄÆ°á»£c sá»­ dá»¥ng trong cÃ¡c há»‡ thá»‘ng cÆ¡ sá»Ÿ dá»¯ liá»‡u, máº¡ng, cÃ´ng cá»¥ tÃ¬m kiáº¿m, báº£o máº­t, vÃ  nhiá»u lÄ©nh vá»±c khÃ¡c. VÃ­ dá»¥ sá»­ dá»¥ng: CÆ¡ sá»Ÿ dá»¯ liá»‡u: Kiá»ƒm tra nhanh sá»± tá»“n táº¡i cá»§a khÃ³a Ä‘á»ƒ giáº£m chi phÃ­ truy cáº­p á»• Ä‘Ä©a. Bá»™ lá»c web: Loáº¡i bá» nhanh cÃ¡c URL trÃ¹ng láº·p hoáº·c khÃ´ng há»£p lá»‡. PhÃ¡t hiá»‡n thÆ° rÃ¡c: XÃ¡c Ä‘á»‹nh Ä‘á»‹a chá»‰ email hoáº·c domain trong danh sÃ¡ch Ä‘en. 8. Há»— trá»£ tÃ­nh toÃ¡n song song TÃ­nh toÃ¡n hÃ m bÄƒm Ä‘á»™c láº­p: CÃ¡c hÃ m bÄƒm cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­nh toÃ¡n song song, giÃºp Bloom Filter táº­n dá»¥ng Ä‘Æ°á»£c há»‡ thá»‘ng Ä‘a lÃµi hoáº·c phÃ¢n tÃ¡n. TÄƒng tá»‘c báº±ng pháº§n cá»©ng: CÃ³ thá»ƒ triá»ƒn khai trÃªn pháº§n cá»©ng (nhÆ° FPGA, GPU) Ä‘á»ƒ Ä‘áº¡t hiá»‡u nÄƒng cao. 9. á»¨ng dá»¥ng trong báº£o máº­t vÃ  quyá»n riÃªng tÆ° Truy váº¥n áº©n danh: Há»— trá»£ cÃ¡c giao thá»©c truy váº¥n thÃ´ng tin riÃªng tÆ° mÃ  khÃ´ng lÃ m lá»™ dá»¯ liá»‡u. PhÃ¡t hiá»‡n nhanh chÃ³ng: XÃ¡c Ä‘á»‹nh IP hoáº·c hÃ nh vi Ä‘Ã¡ng ngá» mÃ  khÃ´ng cáº§n lÆ°u trá»¯ toÃ n bá»™ dá»¯ liá»‡u nháº¡y cáº£m. 10. Dá»… báº£o trÃ¬ KhÃ´ng lÆ°u dá»¯ liá»‡u thÃ´: VÃ¬ Bloom Filter khÃ´ng lÆ°u trá»¯ chÃ­nh xÃ¡c dá»¯ liá»‡u thÃ´, chi phÃ­ quáº£n lÃ½ vÃ  báº£o trÃ¬ tháº¥p hÆ¡n. Hoáº¡t Ä‘á»™ng tÄ©nh: Má»™t Bloom Filter Ä‘Æ°á»£c táº¡o trÆ°á»›c cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng láº·p láº¡i mÃ  khÃ´ng cáº§n cáº­p nháº­t. Khi nÃ o nÃªn sá»­ dá»¥ng Bloom Filter? Bá»™ nhá»› háº¡n cháº¿: Khi khÃ´ng gian lÆ°u trá»¯ lÃ  váº¥n Ä‘á» quan trá»ng, cháº³ng háº¡n trong cÃ¡c há»‡ thá»‘ng nhÃºng hoáº·c thiáº¿t bá»‹ IoT. Cáº§n kiá»ƒm tra nhanh: Khi tá»‘c Ä‘á»™ kiá»ƒm tra thÃ nh viÃªn quan trá»ng hÆ¡n Ä‘á»™ chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i. Cháº¥p nháº­n false positive: CÃ¡c á»©ng dá»¥ng cÃ³ thá»ƒ chá»‹u Ä‘Æ°á»£c má»™t sá»‘ trÆ°á»ng há»£p false positive, vÃ­ dá»¥ nhÆ° bá»™ lá»c spam. Háº¡n cháº¿ cá»§a bá»™ lá»c Bloom Filter Máº·c dÃ¹ Bloom Filter cÃ³ nhiá»u Æ°u Ä‘iá»ƒm vÆ°á»£t trá»™i, nhÆ°ng cÅ©ng tá»“n táº¡i má»™t sá»‘ háº¡n cháº¿ cáº§n xem xÃ©t trÆ°á»›c khi sá»­ dá»¥ng. DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c nhÆ°á»£c Ä‘iá»ƒm chÃ­nh:\n1. False Positive (Káº¿t quáº£ dÆ°Æ¡ng tÃ­nh giáº£) KhÃ´ng chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i: Bloom Filter cÃ³ thá»ƒ bÃ¡o ráº±ng má»™t pháº§n tá»­ náº±m trong táº­p há»£p máº·c dÃ¹ thá»±c táº¿ khÃ´ng pháº£i váº­y. Äiá»u nÃ y xáº£y ra do báº£n cháº¥t xÃ¡c suáº¥t cá»§a cáº¥u trÃºc dá»¯ liá»‡u. KhÃ´ng phÃ¹ há»£p cho cÃ¡c á»©ng dá»¥ng yÃªu cáº§u chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i: VÃ­ dá»¥, khÃ´ng thá»ƒ sá»­ dá»¥ng Bloom Filter Ä‘á»ƒ lÆ°u trá»¯ dá»¯ liá»‡u nháº¡y cáº£m hoáº·c khi cáº§n Ä‘áº£m báº£o 100% Ä‘á»™ tin cáº­y. 2. KhÃ´ng há»— trá»£ xÃ³a pháº§n tá»­ KhÃ´ng thá»ƒ xÃ³a trong phiÃªn báº£n cÆ¡ báº£n: Má»™t pháº§n tá»­ Ä‘Ã£ Ä‘Æ°á»£c thÃªm vÃ o Bloom Filter khÃ´ng thá»ƒ bá»‹ xÃ³a, vÃ¬ viá»‡c thay Ä‘á»•i báº¥t ká»³ bit nÃ o cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡c pháº§n tá»­ khÃ¡c Ä‘Ã£ Ä‘Æ°á»£c bÄƒm vÃ o cÃ¹ng bit. Giáº£i phÃ¡p: Sá»­ dá»¥ng Counting Bloom Filter, nhÆ°ng Ä‘iá»u nÃ y Ä‘Ã²i há»i nhiá»u bá»™ nhá»› hÆ¡n. 3. KhÃ´ng lÆ°u trá»¯ dá»¯ liá»‡u gá»‘c KhÃ´ng thá»ƒ trÃ­ch xuáº¥t láº¡i dá»¯ liá»‡u: Bloom Filter chá»‰ lÆ°u dáº¥u váº¿t cá»§a pháº§n tá»­ thÃ´ng qua máº£ng bit, vÃ¬ váº­y khÃ´ng thá»ƒ truy xuáº¥t láº¡i cÃ¡c pháº§n tá»­ thá»±c táº¿ tá»« Bloom Filter. á»¨ng dá»¥ng háº¡n cháº¿: KhÃ´ng thá»ƒ sá»­ dá»¥ng Bloom Filter trong cÃ¡c há»‡ thá»‘ng cáº§n lÆ°u trá»¯ hoáº·c quáº£n lÃ½ dá»¯ liá»‡u thá»±c táº¿. 4. KhÃ³ Ä‘iá»u chá»‰nh tá»· lá»‡ false positive Cáº§n thiáº¿t káº¿ trÆ°á»›c: Tá»· lá»‡ false positive phá»¥ thuá»™c vÃ o kÃ­ch thÆ°á»›c máº£ng bit, sá»‘ lÆ°á»£ng hÃ m bÄƒm, vÃ  sá»‘ lÆ°á»£ng pháº§n tá»­. Náº¿u cÃ¡c tham sá»‘ nÃ y khÃ´ng Ä‘Æ°á»£c thiáº¿t káº¿ cáº©n tháº­n tá»« Ä‘áº§u, Bloom Filter cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng khÃ´ng hiá»‡u quáº£. KhÃ´ng linh hoáº¡t: Viá»‡c thay Ä‘á»•i cÃ¡c tham sá»‘ (nhÆ° kÃ­ch thÆ°á»›c hoáº·c sá»‘ hÃ m bÄƒm) thÆ°á»ng Ä‘Ã²i há»i pháº£i táº¡o láº¡i toÃ n bá»™ Bloom Filter. 5. YÃªu cáº§u chá»n hÃ m bÄƒm phÃ¹ há»£p Hiá»‡u suáº¥t phá»¥ thuá»™c vÃ o hÃ m bÄƒm: Náº¿u cÃ¡c hÃ m bÄƒm khÃ´ng Ä‘Æ°á»£c chá»n tá»‘t, chÃºng cÃ³ thá»ƒ táº¡o ra cÃ¡c xung Ä‘á»™t lá»›n, dáº«n Ä‘áº¿n tá»· lá»‡ false positive cao. Hao tá»•n tÃ i nguyÃªn: TÃ­nh toÃ¡n cÃ¡c hÃ m bÄƒm phá»©c táº¡p cÃ³ thá»ƒ tiÃªu tá»‘n tÃ i nguyÃªn CPU, Ä‘áº·c biá»‡t khi sá»­ dá»¥ng nhiá»u hÃ m bÄƒm. 6. KhÃ´ng hiá»‡u quáº£ vá»›i táº­p dá»¯ liá»‡u nhá» QuÃ¡ phá»©c táº¡p so vá»›i bÃ i toÃ¡n nhá»: Khi táº­p dá»¯ liá»‡u nhá», viá»‡c sá»­ dá»¥ng Bloom Filter cÃ³ thá»ƒ phá»©c táº¡p vÃ  tá»‘n tÃ i nguyÃªn hÆ¡n so vá»›i cÃ¡c giáº£i phÃ¡p khÃ¡c nhÆ° danh sÃ¡ch liÃªn káº¿t hoáº·c báº£ng bÄƒm. 7. KhÃ´ng thá»ƒ má»Ÿ rá»™ng má»™t cÃ¡ch Ä‘Æ¡n giáº£n KhÃ³ thÃªm pháº§n tá»­ má»›i: Khi táº­p dá»¯ liá»‡u lá»›n hÆ¡n dá»± kiáº¿n, Bloom Filter ban Ä‘áº§u cÃ³ thá»ƒ khÃ´ng Ä‘á»§ Ä‘á»ƒ lÆ°u trá»¯ thÃªm pháº§n tá»­ mÃ  khÃ´ng tÄƒng tá»· lá»‡ false positive. Giáº£i phÃ¡p: Sá»­ dá»¥ng Scalable Bloom Filter, nhÆ°ng Ä‘iá»u nÃ y lÃ m tÄƒng Ä‘á»™ phá»©c táº¡p vÃ  chi phÃ­. 8. KhÃ´ng há»— trá»£ kiá»ƒm tra phá»§ Ä‘á»‹nh (No False Negatives) Chá»‰ kiá»ƒm tra thÃ nh viÃªn: Bloom Filter chá»‰ xÃ¡c nháº­n ráº±ng pháº§n tá»­ \u0026ldquo;cÃ³ thá»ƒ cÃ³\u0026rdquo; hoáº·c \u0026ldquo;cháº¯c cháº¯n khÃ´ng cÃ³\u0026rdquo; trong táº­p há»£p, vÃ  khÃ´ng thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ so sÃ¡nh hoáº·c tÃ¬m kiáº¿m dá»¯ liá»‡u thá»±c táº¿. á»¨ng dá»¥ng giá»›i háº¡n: KhÃ´ng phÃ¹ há»£p cho cÃ¡c bÃ i toÃ¡n yÃªu cáº§u thÃ´ng tin chÃ­nh xÃ¡c vá» pháº§n tá»­ (nhÆ° vá»‹ trÃ­, giÃ¡ trá»‹ cá»¥ thá»ƒ). 9. KhÃ³ triá»ƒn khai vÃ  báº£o trÃ¬ trong há»‡ thá»‘ng lá»›n Cáº§n Ä‘á»“ng bá»™ hÃ³a: Trong há»‡ thá»‘ng phÃ¢n tÃ¡n, Bloom Filter cáº§n Ä‘Æ°á»£c cáº­p nháº­t hoáº·c Ä‘á»“ng bá»™ liÃªn tá»¥c, Ä‘iá»u nÃ y cÃ³ thá»ƒ gÃ¢y phá»©c táº¡p khi dá»¯ liá»‡u thay Ä‘á»•i nhanh. Chi phÃ­ bá»™ nhá»›: Máº·c dÃ¹ Bloom Filter tiáº¿t kiá»‡m bá»™ nhá»›, nhÆ°ng khi yÃªu cáº§u tá»· lá»‡ false positive tháº¥p, kÃ­ch thÆ°á»›c máº£ng bit cÃ³ thá»ƒ trá»Ÿ nÃªn lá»›n, lÃ m giáº£m lá»£i Ã­ch cá»§a nÃ³. 10. KhÃ´ng phÃ¹ há»£p vá»›i dá»¯ liá»‡u Ä‘á»™ng KhÃ´ng tá»‘i Æ°u cho dá»¯ liá»‡u thay Ä‘á»•i thÆ°á»ng xuyÃªn: Khi táº­p dá»¯ liá»‡u thay Ä‘á»•i liÃªn tá»¥c (thÃªm hoáº·c xÃ³a pháº§n tá»­), Bloom Filter cÆ¡ báº£n khÃ´ng phÃ¹ há»£p vÃ¬ khÃ´ng há»— trá»£ xÃ³a vÃ  tÃ¡i sá»­ dá»¥ng khÃ´ng gian. Khi nÃ o khÃ´ng nÃªn sá»­ dá»¥ng Bloom Filter? Khi yÃªu cáº§u káº¿t quáº£ chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i (khÃ´ng cháº¥p nháº­n false positive). Khi dá»¯ liá»‡u thay Ä‘á»•i liÃªn tá»¥c vÃ  cáº§n cáº­p nháº­t (thÃªm hoáº·c xÃ³a pháº§n tá»­). Khi táº­p dá»¯ liá»‡u nhá», Bloom Filter cÃ³ thá»ƒ phá»©c táº¡p vÃ  tá»‘n tÃ i nguyÃªn hÆ¡n cÃ¡c giáº£i phÃ¡p Ä‘Æ¡n giáº£n khÃ¡c. Má»™t sá»‘ biáº¿n thá»ƒ cá»§a Bloom Filter Double Hashing Bloom Filter: Double Hashing Bloom Filter lÃ  má»™t biáº¿n thá»ƒ cá»§a Bloom Filter truyá»n thá»‘ng sá»­ dá»¥ng double hashing Ä‘á»ƒ tÃ­nh toÃ¡n nhiá»u giÃ¡ trá»‹ bÄƒm tá»« má»™t cáº·p hÃ m bÄƒm cÆ¡ sá»Ÿ thay vÃ¬ sá»­ dá»¥ng má»™t táº­p há»£p cÃ¡c hÃ m bÄƒm Ä‘á»™c láº­p. Äiá»u nÃ y giÃºp giáº£m Ä‘á»™ phá»©c táº¡p vÃ  tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t khi triá»ƒn khai.\nCÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Double Hashing Bloom Filter Ã tÆ°á»Ÿng chÃ­nh cá»§a Double Hashing:\nSá»­ dá»¥ng hai hÃ m bÄƒm cÆ¡ báº£n, ( h_1(x) ) vÃ  ( h_2(x) ), Ä‘á»ƒ táº¡o ra ( k ) hÃ m bÄƒm cho Bloom Filter. CÃ¡c giÃ¡ trá»‹ bÄƒm Ä‘Æ°á»£c tÃ­nh theo cÃ´ng thá»©c: [ g_i(x) = (h_1(x) + i \\cdot h_2(x)) \\mod m ] ( g_i(x) ) lÃ  giÃ¡ trá»‹ bÄƒm thá»© ( i ) cho pháº§n tá»­ ( x ). ( m ) lÃ  kÃ­ch thÆ°á»›c cá»§a máº£ng bit. ( i ) lÃ  chá»‰ sá»‘ (0 Ä‘áº¿n ( k-1 )). ThÃªm pháº§n tá»­ (Insert):\nTÃ­nh ( k ) giÃ¡ trá»‹ bÄƒm tá»« hai hÃ m bÄƒm ( h_1(x) ) vÃ  ( h_2(x) ). Äáº·t cÃ¡c bit táº¡i cÃ¡c vá»‹ trÃ­ tÆ°Æ¡ng á»©ng trong máº£ng thÃ nh 1. Kiá»ƒm tra pháº§n tá»­ (Check):\nTÃ­nh ( k ) giÃ¡ trá»‹ bÄƒm tÆ°Æ¡ng tá»±. Kiá»ƒm tra xem táº¥t cáº£ cÃ¡c bit tÆ°Æ¡ng á»©ng Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº·t thÃ nh 1 chÆ°a. Æ¯u Ä‘iá»ƒm cá»§a Double Hashing Bloom Filter Giáº£m sá»‘ hÃ m bÄƒm cáº§n thiáº¿t:\nChá»‰ cáº§n hai hÃ m bÄƒm thay vÃ¬ ( k ), giÃºp Ä‘Æ¡n giáº£n hÃ³a triá»ƒn khai. TÄƒng hiá»‡u quáº£ tÃ­nh toÃ¡n:\nViá»‡c tÃ­nh toÃ¡n cÃ¡c giÃ¡ trá»‹ bÄƒm sá»­ dá»¥ng ( h_1(x) ) vÃ  ( h_2(x) ) lÃ  nhanh chÃ³ng vÃ  dá»… dÃ ng. Tá»‘i Æ°u hÃ³a bá»™ nhá»›:\nKhÃ´ng cáº§n lÆ°u trá»¯ hoáº·c triá»ƒn khai nhiá»u hÃ m bÄƒm riÃªng láº». Háº¡n cháº¿ cá»§a Double Hashing Bloom Filter Äá»™ chÃ­nh xÃ¡c phá»¥ thuá»™c vÃ o hÃ m bÄƒm cÆ¡ sá»Ÿ:\nNáº¿u ( h_1(x) ) vÃ  ( h_2(x) ) khÃ´ng tá»‘t, phÃ¢n phá»‘i giÃ¡ trá»‹ bÄƒm cÃ³ thá»ƒ khÃ´ng Ä‘á»u. False positive váº«n tá»“n táº¡i:\nGiá»‘ng Bloom Filter truyá»n thá»‘ng, nÃ³ khÃ´ng thá»ƒ trÃ¡nh hoÃ n toÃ n false positive. á»¨ng dá»¥ng cá»§a Double Hashing Bloom Filter CÆ¡ sá»Ÿ dá»¯ liá»‡u:\nGiáº£m chi phÃ­ kiá»ƒm tra sá»± tá»“n táº¡i cá»§a cÃ¡c khÃ³a trong há»‡ thá»‘ng lÆ°u trá»¯. Cache vÃ  bá»™ lá»c web:\nXÃ¡c Ä‘á»‹nh nhanh chÃ³ng xem má»™t URL cÃ³ náº±m trong danh sÃ¡ch cháº·n hay khÃ´ng. Há»‡ thá»‘ng máº¡ng:\nTheo dÃµi vÃ  lá»c gÃ³i tin hoáº·c Ä‘á»‹a chá»‰ IP. Triá»ƒn khai Double Hashing Bloom Filter báº±ng Python 1import hashlib 2 3class DoubleHashingBloomFilter: 4 def __init__(self, size, num_hashes): 5 self.size = size 6 self.num_hashes = num_hashes 7 self.bit_array = [0] * size 8 9 def _hashes(self, item): 10 h1 = int(hashlib.md5(item.encode()).hexdigest(), 16) % self.size 11 h2 = int(hashlib.sha256(item.encode()).hexdigest(), 16) % self.size 12 hashes = [(h1 + i * h2) % self.size for i in range(self.num_hashes)] 13 return hashes 14 15 def add(self, item): 16 indices = self._hashes(item) 17 for idx in indices: 18 self.bit_array[idx] = 1 19 20 def contains(self, item): 21 indices = self._hashes(item) 22 return all(self.bit_array[idx] for idx in indices) 23 24 25# Example Usage 26dbf = DoubleHashingBloomFilter(size=100, num_hashes=5) 27 28# Add elements 29dbf.add(\u0026#34;hello\u0026#34;) 30dbf.add(\u0026#34;world\u0026#34;) 31 32# Check elements 33print(dbf.contains(\u0026#34;hello\u0026#34;)) # True 34print(dbf.contains(\u0026#34;world\u0026#34;)) # True 35print(dbf.contains(\u0026#34;python\u0026#34;)) # False TÃ³m táº¯t Double Hashing Bloom Filter giáº£m sá»‘ lÆ°á»£ng hÃ m bÄƒm cáº§n thiáº¿t báº±ng cÃ¡ch sá»­ dá»¥ng hai hÃ m bÄƒm cÆ¡ sá»Ÿ Ä‘á»ƒ táº¡o ( k ) giÃ¡ trá»‹ bÄƒm. PhÃ¹ há»£p vá»›i cÃ¡c á»©ng dá»¥ng yÃªu cáº§u hiá»‡u suáº¥t cao, dá»… triá»ƒn khai vÃ  báº£o toÃ n tÃ­nh chÃ­nh xÃ¡c cá»§a Bloom Filter. MÃ£ giáº£ á»Ÿ trÃªn minh há»a cÃ¡ch triá»ƒn khai báº±ng cáº£ Python vÃ  Golang. Náº¿u cáº§n giáº£i thÃ­ch thÃªm hoáº·c cÃ³ yÃªu cáº§u cá»¥ thá»ƒ, hÃ£y cho mÃ¬nh biáº¿t nhÃ©! ğŸ˜Š\nPartitioning Bloom Filter: Partitioning Bloom Filter (PBF) lÃ  má»™t biáº¿n thá»ƒ cá»§a Bloom Filter, trong Ä‘Ã³ máº£ng bit Ä‘Æ°á»£c chia thÃ nh cÃ¡c phÃ¢n Ä‘oáº¡n riÃªng biá»‡t (partitions). Má»—i hÃ m bÄƒm chá»‰ áº£nh hÆ°á»Ÿng Ä‘áº¿n má»™t phÃ¢n Ä‘oáº¡n cá»¥ thá»ƒ thay vÃ¬ toÃ n bá»™ máº£ng. PhÆ°Æ¡ng phÃ¡p nÃ y cáº£i thiá»‡n kháº£ nÄƒng phÃ¢n tÃ¡n vÃ  giáº£m kháº£ nÄƒng cÃ¡c hÃ m bÄƒm khÃ¡c nhau ghi Ä‘Ã¨ láº«n nhau (collision) trong máº£ng bit.\nCÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Partitioning Bloom Filter Chia máº£ng bit thÃ nh nhiá»u phÃ¢n Ä‘oáº¡n (partitions):\nMáº£ng bit tá»•ng thá»ƒ Ä‘Æ°á»£c chia thÃ nh ( k ) phÃ¢n Ä‘oáº¡n, trong Ä‘Ã³ ( k ) lÃ  sá»‘ hÃ m bÄƒm. Má»—i hÃ m bÄƒm chá»‰ hoáº¡t Ä‘á»™ng trÃªn má»™t phÃ¢n Ä‘oáº¡n riÃªng biá»‡t. ThÃªm pháº§n tá»­ (Insert):\nKhi má»™t pháº§n tá»­ Ä‘Æ°á»£c thÃªm vÃ o, cÃ¡c hÃ m bÄƒm Ã¡nh xáº¡ nÃ³ Ä‘áº¿n cÃ¡c vá»‹ trÃ­ trong tá»«ng phÃ¢n Ä‘oáº¡n. Chá»‰ cÃ¡c bit trong phÃ¢n Ä‘oáº¡n tÆ°Æ¡ng á»©ng Ä‘Æ°á»£c thiáº¿t láº­p. Kiá»ƒm tra pháº§n tá»­ (Check):\nÄá»ƒ kiá»ƒm tra sá»± tá»“n táº¡i, Ã¡p dá»¥ng cÃ¡c hÃ m bÄƒm Ä‘á»ƒ kiá»ƒm tra cÃ¡c vá»‹ trÃ­ trong cÃ¡c phÃ¢n Ä‘oáº¡n tÆ°Æ¡ng á»©ng. Giáº£m xung Ä‘á»™t giá»¯a cÃ¡c hÃ m bÄƒm:\nVÃ¬ má»—i hÃ m bÄƒm chá»‰ lÃ m viá»‡c trong má»™t phÃ¢n Ä‘oáº¡n, kháº£ nÄƒng ghi Ä‘Ã¨ bit cá»§a nhau (collision) giáº£m Ä‘Ã¡ng ká»ƒ so vá»›i Bloom Filter thÃ´ng thÆ°á»ng. Æ¯u Ä‘iá»ƒm cá»§a Partitioning Bloom Filter PhÃ¢n phá»‘i Ä‘á»“ng Ä‘á»u hÆ¡n:\nViá»‡c phÃ¢n chia máº£ng giÃºp giáº£m xung Ä‘á»™t giá»¯a cÃ¡c hÃ m bÄƒm vÃ  cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c. Kiá»ƒm soÃ¡t false positive:\nXÃ¡c suáº¥t false positive cÃ³ thá»ƒ giáº£m so vá»›i Bloom Filter thÃ´ng thÆ°á»ng náº¿u cÃ¡c phÃ¢n Ä‘oáº¡n Ä‘Æ°á»£c thiáº¿t káº¿ tá»‘i Æ°u. Dá»… dÃ ng má»Ÿ rá»™ng:\nCÃ³ thá»ƒ tÄƒng sá»‘ phÃ¢n Ä‘oáº¡n hoáº·c kÃ­ch thÆ°á»›c tá»«ng phÃ¢n Ä‘oáº¡n Ä‘á»ƒ phÃ¹ há»£p vá»›i yÃªu cáº§u cá»¥ thá»ƒ. Háº¡n cháº¿ cá»§a Partitioning Bloom Filter TÄƒng phá»©c táº¡p quáº£n lÃ½:\nCáº§n Ä‘áº£m báº£o ráº±ng má»—i hÃ m bÄƒm chá»‰ hoáº¡t Ä‘á»™ng trong phÃ¢n Ä‘oáº¡n tÆ°Æ¡ng á»©ng, tÄƒng Ä‘á»™ phá»©c táº¡p khi triá»ƒn khai. Bá»™ nhá»› khÃ´ng linh hoáº¡t:\nMá»—i phÃ¢n Ä‘oáº¡n pháº£i cÃ³ kÃ­ch thÆ°á»›c giá»‘ng nhau, dáº«n Ä‘áº¿n viá»‡c sá»­ dá»¥ng bá»™ nhá»› khÃ´ng linh hoáº¡t náº¿u dá»¯ liá»‡u khÃ´ng Ä‘á»“ng Ä‘á»u. á»¨ng dá»¥ng cá»§a Partitioning Bloom Filter Há»‡ thá»‘ng lÆ°u trá»¯ vÃ  cache:\nTheo dÃµi sá»± tá»“n táº¡i cá»§a cÃ¡c pháº§n tá»­ trong cÃ¡c vÃ¹ng dá»¯ liá»‡u riÃªng biá»‡t. Quáº£n lÃ½ táº£i trong máº¡ng:\nChia nhá» dá»¯ liá»‡u theo cÃ¡c nhÃ³m (partitions) Ä‘á»ƒ giáº£m xung Ä‘á»™t khi lÆ°u trá»¯. PhÃ¢n vÃ¹ng cÆ¡ sá»Ÿ dá»¯ liá»‡u:\nGiÃºp phÃ¢n tÃ¡n truy váº¥n vÃ  dá»¯ liá»‡u trong cÃ¡c cá»¥m (cluster) cÆ¡ sá»Ÿ dá»¯ liá»‡u. Triá»ƒn khai Partitioning Bloom Filter báº±ng Python 1import hashlib 2 3class PartitioningBloomFilter: 4 def __init__(self, total_size, num_hashes): 5 self.num_hashes = num_hashes 6 self.partition_size = total_size // num_hashes 7 self.bit_array = [0] * total_size 8 9 def _hashes(self, item): 10 hashes = [] 11 for i in range(self.num_hashes): 12 hash_value = int(hashlib.md5((str(item) + str(i)).encode()).hexdigest(), 16) 13 # Map hash to the partition 14 partition_start = i * self.partition_size 15 index = partition_start + (hash_value % self.partition_size) 16 hashes.append(index) 17 return hashes 18 19 def add(self, item): 20 indices = self._hashes(item) 21 for idx in indices: 22 self.bit_array[idx] = 1 23 24 def contains(self, item): 25 indices = self._hashes(item) 26 return all(self.bit_array[idx] for idx in indices) 27 28 29# Example Usage 30pbf = PartitioningBloomFilter(total_size=100, num_hashes=5) 31 32# Add elements 33pbf.add(\u0026#34;hello\u0026#34;) 34pbf.add(\u0026#34;world\u0026#34;) 35 36# Check elements 37print(pbf.contains(\u0026#34;hello\u0026#34;)) # True 38print(pbf.contains(\u0026#34;world\u0026#34;)) # True 39print(pbf.contains(\u0026#34;python\u0026#34;)) # False TÃ³m táº¯t Partitioning Bloom Filter cáº£i thiá»‡n Bloom Filter báº±ng cÃ¡ch chia máº£ng bit thÃ nh cÃ¡c phÃ¢n Ä‘oáº¡n Ä‘á»™c láº­p. NÃ³ giáº£m xung Ä‘á»™t giá»¯a cÃ¡c hÃ m bÄƒm vÃ  cÃ³ thá»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c. ThÃ­ch há»£p cho cÃ¡c á»©ng dá»¥ng yÃªu cáº§u truy váº¥n nhanh vÃ  Ä‘á»“ng thá»i trong cÃ¡c vÃ¹ng dá»¯ liá»‡u riÃªng biá»‡t. Counting Bloom Filter: Counting Bloom Filter (CBF) lÃ  má»™t biáº¿n thá»ƒ cá»§a Bloom Filter há»— trá»£ thÃªm kháº£ nÄƒng xÃ³a (delete) pháº§n tá»­ khá»i cáº¥u trÃºc dá»¯ liá»‡u. Trong khi Bloom Filter truyá»n thá»‘ng chá»‰ cÃ³ thá»ƒ thÃªm vÃ  kiá»ƒm tra sá»± tá»“n táº¡i cá»§a pháº§n tá»­, Counting Bloom Filter cho phÃ©p cáº£ thÃªm, xÃ³a, vÃ  kiá»ƒm tra vá»›i Ä‘á»™ chÃ­nh xÃ¡c tÆ°Æ¡ng Ä‘á»‘i.\nCÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Counting Bloom Filter Thay vÃ¬ máº£ng bit, sá»­ dá»¥ng máº£ng Ä‘áº¿m (counting array):\nMá»—i vá»‹ trÃ­ trong máº£ng khÃ´ng cÃ²n lÃ  má»™t bit (0 hoáº·c 1) mÃ  lÃ  má»™t sá»‘ nguyÃªn (counter). Bá»™ Ä‘áº¿m á»Ÿ má»—i vá»‹ trÃ­ cho biáº¿t sá»‘ láº§n má»™t pháº§n tá»­ hoáº·c nhiá»u pháº§n tá»­ khÃ¡c nhau Ã¡nh xáº¡ Ä‘áº¿n vá»‹ trÃ­ Ä‘Ã³. ThÃªm pháº§n tá»­ (Insert):\nKhi thÃªm má»™t pháº§n tá»­, tÄƒng giÃ¡ trá»‹ cá»§a cÃ¡c bá»™ Ä‘áº¿m táº¡i cÃ¡c chá»‰ má»¥c Ä‘Æ°á»£c tÃ­nh bá»Ÿi cÃ¡c hÃ m bÄƒm. XÃ³a pháº§n tá»­ (Delete):\nKhi xÃ³a má»™t pháº§n tá»­, giáº£m giÃ¡ trá»‹ cá»§a cÃ¡c bá»™ Ä‘áº¿m táº¡i cÃ¡c chá»‰ má»¥c Ä‘Æ°á»£c tÃ­nh bá»Ÿi cÃ¡c hÃ m bÄƒm. Náº¿u báº¥t ká»³ bá»™ Ä‘áº¿m nÃ o giáº£m vá» 0, vá»‹ trÃ­ Ä‘Ã³ Ä‘Æ°á»£c coi lÃ  trá»‘ng. Kiá»ƒm tra pháº§n tá»­ (Check):\nPháº§n tá»­ Ä‘Æ°á»£c coi lÃ  cÃ³ thá»ƒ tá»“n táº¡i náº¿u táº¥t cáº£ cÃ¡c chá»‰ má»¥c bÄƒm tÆ°Æ¡ng á»©ng cÃ³ giÃ¡ trá»‹ lá»›n hÆ¡n 0. Æ¯u Ä‘iá»ƒm cá»§a Counting Bloom Filter Há»— trá»£ xÃ³a pháº§n tá»­:\nKháº¯c phá»¥c háº¡n cháº¿ lá»›n cá»§a Bloom Filter truyá»n thá»‘ng lÃ  khÃ´ng há»— trá»£ xÃ³a. Giá»¯ Ä‘Æ°á»£c tÃ­nh gá»n nháº¹:\nChá»‰ cáº§n má»™t lÆ°á»£ng nhá» bá»™ nhá»› bá»• sung (cÃ¡c bá»™ Ä‘áº¿m thay vÃ¬ bit). Hiá»‡u quáº£ vá»›i cÃ¡c táº­p dá»¯ liá»‡u Ä‘á»™ng:\nRáº¥t phÃ¹ há»£p trong cÃ¡c á»©ng dá»¥ng mÃ  cÃ¡c pháº§n tá»­ thÆ°á»ng xuyÃªn Ä‘Æ°á»£c thÃªm vÃ  xÃ³a. Háº¡n cháº¿ cá»§a Counting Bloom Filter False positive:\nGiá»‘ng nhÆ° Bloom Filter, CBF váº«n cÃ³ nguy cÆ¡ false positive (tráº£ vá» \u0026ldquo;cÃ³ thá»ƒ tá»“n táº¡i\u0026rdquo; cho pháº§n tá»­ khÃ´ng tá»“n táº¡i). KhÃ´ng há»— trá»£ kiá»ƒm tra \u0026ldquo;cháº¯c cháº¯n xÃ³a\u0026rdquo;:\nKhi má»™t pháº§n tá»­ bá»‹ xÃ³a, cÃ¡c pháº§n tá»­ khÃ¡c cÃ³ thá»ƒ Ã¡nh xáº¡ Ä‘áº¿n cÃ¹ng chá»‰ má»¥c váº«n giá»¯ cÃ¡c bá»™ Ä‘áº¿m. TÄƒng yÃªu cáº§u bá»™ nhá»›:\nMá»—i vá»‹ trÃ­ trong máº£ng cáº§n lÆ°u trá»¯ má»™t sá»‘ nguyÃªn thay vÃ¬ má»™t bit, dáº«n Ä‘áº¿n tÄƒng Ä‘Ã¡ng ká»ƒ dung lÆ°á»£ng bá»™ nhá»›. á»¨ng dá»¥ng cá»§a Counting Bloom Filter Quáº£n lÃ½ cache:\nTheo dÃµi cÃ¡c pháº§n tá»­ trong cache, cho phÃ©p xÃ³a khi háº¿t háº¡n hoáº·c khi khÃ´ng cÃ²n cáº§n thiáº¿t. Há»‡ thá»‘ng máº¡ng:\nTheo dÃµi cÃ¡c gÃ³i tin hoáº·c lÆ°u lÆ°á»£ng máº¡ng trong khoáº£ng thá»i gian nháº¥t Ä‘á»‹nh. CÆ¡ sá»Ÿ dá»¯ liá»‡u:\nHá»— trá»£ trong cÃ¡c há»‡ thá»‘ng lÆ°u trá»¯, nÆ¡i cÃ¡c pháº§n tá»­ cáº§n Ä‘Æ°á»£c thÃªm vÃ  xÃ³a thÆ°á»ng xuyÃªn. Triá»ƒn khai báº±ng Python 1import hashlib 2 3class CountingBloomFilter: 4 def __init__(self, size, num_hashes): 5 self.size = size 6 self.num_hashes = num_hashes 7 self.count_array = [0] * size 8 9 def _hashes(self, item): 10 hashes = [] 11 for i in range(self.num_hashes): 12 hash_value = int(hashlib.md5((str(item) + str(i)).encode()).hexdigest(), 16) 13 hashes.append(hash_value % self.size) 14 return hashes 15 16 def add(self, item): 17 indices = self._hashes(item) 18 for idx in indices: 19 self.count_array[idx] += 1 20 21 def delete(self, item): 22 indices = self._hashes(item) 23 for idx in indices: 24 if self.count_array[idx] \u0026gt; 0: 25 self.count_array[idx] -= 1 26 27 def contains(self, item): 28 indices = self._hashes(item) 29 return all(self.count_array[idx] \u0026gt; 0 for idx in indices) 30 31 32# Example Usage 33cbf = CountingBloomFilter(size=100, num_hashes=3) 34 35# Add elements 36cbf.add(\u0026#34;hello\u0026#34;) 37cbf.add(\u0026#34;world\u0026#34;) 38 39# Check elements 40print(cbf.contains(\u0026#34;hello\u0026#34;)) # True 41print(cbf.contains(\u0026#34;world\u0026#34;)) # True 42print(cbf.contains(\u0026#34;python\u0026#34;)) # False 43 44# Delete an element 45cbf.delete(\u0026#34;hello\u0026#34;) 46print(cbf.contains(\u0026#34;hello\u0026#34;)) # False TÃ³m táº¯t Counting Bloom Filter cho phÃ©p thÃªm, xÃ³a vÃ  kiá»ƒm tra pháº§n tá»­, má»Ÿ rá»™ng tÃ­nh nÄƒng cá»§a Bloom Filter truyá»n thá»‘ng. NÃ³ phÃ¹ há»£p vá»›i cÃ¡c á»©ng dá»¥ng yÃªu cáº§u thao tÃ¡c Ä‘á»™ng vá»›i táº­p dá»¯ liá»‡u, nhÆ°ng váº«n giá»¯ cÃ¡c Æ°u Ä‘iá»ƒm vá» hiá»‡u suáº¥t vÃ  bá»™ nhá»› cá»§a Bloom Filter. Náº¿u cáº§n há»— trá»£ thÃªm, hÃ£y cho mÃ¬nh biáº¿t nhÃ©! ğŸ˜Š\nScalable Bloom Filter Scalable Bloom Filter (SBF) lÃ  má»™t biáº¿n thá»ƒ cá»§a Bloom Filter Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ kháº¯c phá»¥c háº¡n cháº¿ cá»‘ há»¯u cá»§a Bloom Filter truyá»n thá»‘ng: kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh. SBF cÃ³ thá»ƒ má»Ÿ rá»™ng Ä‘á»™ng khi sá»‘ lÆ°á»£ng pháº§n tá»­ tÄƒng mÃ  khÃ´ng lÃ m máº¥t tÃ­nh hiá»‡u quáº£ hoáº·c chÃ­nh xÃ¡c cá»§a Bloom Filter.\nVáº¥n Ä‘á» vá»›i Bloom Filter truyá»n thá»‘ng Giá»›i háº¡n kÃ­ch thÆ°á»›c: Bloom Filter truyá»n thá»‘ng yÃªu cáº§u kÃ­ch thÆ°á»›c máº£ng bit cá»‘ Ä‘á»‹nh khi khá»Ÿi táº¡o, dá»±a trÃªn sá»‘ pháº§n tá»­ Æ°á»›c tÃ­nh vÃ  tá»· lá»‡ false positive mong muá»‘n. Náº¿u sá»‘ pháº§n tá»­ vÆ°á»£t quÃ¡ dá»± Ä‘oÃ¡n ban Ä‘áº§u, tá»· lá»‡ false positive tÄƒng Ä‘Ã¡ng ká»ƒ. KhÃ´ng thá»ƒ thay Ä‘á»•i kÃ­ch thÆ°á»›c mÃ  váº«n giá»¯ nguyÃªn cÃ¡c pháº§n tá»­ Ä‘Ã£ Ä‘Æ°á»£c thÃªm. Scalable Bloom Filter giáº£i quyáº¿t váº¥n Ä‘á» nhÆ° tháº¿ nÃ o? SBF kháº¯c phá»¥c váº¥n Ä‘á» nÃ y báº±ng cÃ¡ch:\nTÄƒng kÃ­ch thÆ°á»›c Ä‘á»™ng: Khi sá»‘ pháº§n tá»­ vÆ°á»£t quÃ¡ má»™t ngÆ°á»¡ng (threshold), SBF thÃªm má»™t Bloom Filter má»›i vá»›i kÃ­ch thÆ°á»›c lá»›n hÆ¡n. Giáº£m false positive: Má»—i Bloom Filter má»›i Ä‘Æ°á»£c táº¡o ra sá»­ dá»¥ng má»™t tá»· lá»‡ false positive tháº¥p hÆ¡n so vá»›i cÃ¡c Bloom Filter trÆ°á»›c Ä‘Ã³. Äiá»u nÃ y giÃºp giáº£m nguy cÆ¡ tá»•ng thá»ƒ cá»§a false positive. Cáº¥u trÃºc vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Scalable Bloom Filter Cáº¥u trÃºc:\nSBF bao gá»“m má»™t chuá»—i cÃ¡c Bloom Filter Ä‘Æ°á»£c táº¡o ra khi cáº§n má»Ÿ rá»™ng. Má»—i Bloom Filter cÃ³ kÃ­ch thÆ°á»›c vÃ  tá»· lá»‡ false positive khÃ¡c nhau, tÄƒng dáº§n theo thá»i gian. ChÃ¨n pháº§n tá»­ (Insert):\nPháº§n tá»­ má»›i Ä‘Æ°á»£c thÃªm vÃ o Bloom Filter hiá»‡n táº¡i (bloom filter cuá»‘i cÃ¹ng trong chuá»—i). Náº¿u Bloom Filter hiá»‡n táº¡i Ä‘áº¡t ngÆ°á»¡ng tá»‘i Ä‘a, má»™t Bloom Filter má»›i Ä‘Æ°á»£c táº¡o. Kiá»ƒm tra pháº§n tá»­ (Check):\nLáº§n lÆ°á»£t kiá»ƒm tra pháº§n tá»­ trong tá»«ng Bloom Filter, tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i chuá»—i. Náº¿u pháº§n tá»­ Ä‘Æ°á»£c tÃ¬m tháº¥y trong báº¥t ká»³ Bloom Filter nÃ o, káº¿t quáº£ tráº£ vá» lÃ  \u0026ldquo;cÃ³ thá»ƒ tá»“n táº¡i\u0026rdquo;. NgÆ°á»¡ng má»Ÿ rá»™ng (Threshold):\nSBF sá»­ dá»¥ng má»™t ngÆ°á»¡ng kiá»ƒm soÃ¡t (thÆ°á»ng dá»±a trÃªn táº£i trá»ng, nhÆ° sá»‘ lÆ°á»£ng pháº§n tá»­ Ä‘Ã£ thÃªm) Ä‘á»ƒ quyáº¿t Ä‘á»‹nh khi nÃ o cáº§n táº¡o má»™t Bloom Filter má»›i. Æ¯u Ä‘iá»ƒm cá»§a Scalable Bloom Filter Kháº£ nÄƒng má»Ÿ rá»™ng (Scalability):\nSBF khÃ´ng giá»›i háº¡n sá»‘ lÆ°á»£ng pháº§n tá»­ cÃ³ thá»ƒ thÃªm vÃ o. TÄƒng kÃ­ch thÆ°á»›c Ä‘á»™ng mÃ  khÃ´ng cáº§n Ä‘á»‹nh cáº¥u hÃ¬nh trÆ°á»›c. Giáº£m false positive hiá»‡u quáº£:\nMá»—i Bloom Filter má»›i cÃ³ tá»· lá»‡ false positive tháº¥p hÆ¡n, lÃ m giáº£m tá»· lá»‡ tá»•ng thá»ƒ. Tiáº¿t kiá»‡m bá»™ nhá»›:\nSBF sá»­ dá»¥ng kÃ­ch thÆ°á»›c bá»™ nhá»› nhá» hÆ¡n so vá»›i viá»‡c táº¡o má»™t Bloom Filter ráº¥t lá»›n ngay tá»« Ä‘áº§u. PhÃ¹ há»£p vá»›i dá»¯ liá»‡u thay Ä‘á»•i:\nSBF ráº¥t há»¯u Ã­ch trong cÃ¡c á»©ng dá»¥ng nÆ¡i sá»‘ lÆ°á»£ng pháº§n tá»­ khÃ³ dá»± Ä‘oÃ¡n. Háº¡n cháº¿ cá»§a Scalable Bloom Filter TÄƒng Ä‘á»™ phá»©c táº¡p:\nViá»‡c duy trÃ¬ nhiá»u Bloom Filter khiáº¿n kiá»ƒm tra pháº§n tá»­ tá»‘n thá»i gian hÆ¡n, Ä‘áº·c biá»‡t khi chuá»—i Bloom Filter dÃ i. Overhead bá»™ nhá»›:\nDÃ¹ SBF tiáº¿t kiá»‡m bá»™ nhá»› hÆ¡n khi so sÃ¡nh vá»›i Bloom Filter truyá»n thá»‘ng khÃ´ng Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a, nÃ³ váº«n cÃ³ overhead vÃ¬ pháº£i quáº£n lÃ½ nhiá»u Bloom Filter. KhÃ´ng há»— trá»£ xÃ³a:\nNhÆ° Bloom Filter truyá»n thá»‘ng, SBF khÃ´ng há»— trá»£ xÃ³a pháº§n tá»­. á»¨ng dá»¥ng cá»§a Scalable Bloom Filter Quáº£n lÃ½ cache:\nDÃ¹ng Ä‘á»ƒ theo dÃµi cÃ¡c pháº§n tá»­ trong cache vá»›i sá»‘ lÆ°á»£ng pháº§n tá»­ thay Ä‘á»•i Ä‘á»™ng. Há»‡ thá»‘ng lÆ°u trá»¯ vÃ  cÆ¡ sá»Ÿ dá»¯ liá»‡u:\nÄÆ°á»£c sá»­ dá»¥ng trong cÃ¡c há»‡ thá»‘ng lÆ°u trá»¯ phÃ¢n tÃ¡n nhÆ° Bigtable, HBase, hoáº·c Cassandra. Há»‡ thá»‘ng phÃ¢n tÃ¡n:\nSBF giÃºp theo dÃµi tráº¡ng thÃ¡i cá»§a cÃ¡c pháº§n tá»­ (nhÆ° dá»¯ liá»‡u, gÃ³i tin) trong há»‡ thá»‘ng mÃ  kÃ­ch thÆ°á»›c táº­p há»£p thay Ä‘á»•i liÃªn tá»¥c. Dá»¯ liá»‡u lá»›n (Big Data):\nSBF phÃ¹ há»£p vá»›i cÃ¡c á»©ng dá»¥ng xá»­ lÃ½ dá»¯ liá»‡u lá»›n, nÆ¡i sá»‘ lÆ°á»£ng pháº§n tá»­ khÃ´ng thá»ƒ dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c. Triá»ƒn khai Scalable Bloom Filter Má»™t cÃ¡ch phá»• biáº¿n Ä‘á»ƒ triá»ƒn khai SBF:\nBáº¯t Ä‘áº§u vá»›i má»™t Bloom Filter ban Ä‘áº§u cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh. Äáº·t ngÆ°á»¡ng táº£i trá»ng (load factor), vÃ­ dá»¥: khi sá»‘ pháº§n tá»­ Ä‘áº¡t 80% dung lÆ°á»£ng tá»‘i Ä‘a. Má»—i khi thÃªm má»™t Bloom Filter má»›i, tÄƒng kÃ­ch thÆ°á»›c máº£ng bit vÃ  giáº£m tá»· lá»‡ false positive báº±ng cÃ¡ch thay Ä‘á»•i sá»‘ lÆ°á»£ng hÃ m bÄƒm. MÃ£ giáº£ Scalable Bloom Filter 1 2import math 3import hashlib 4 5class BloomFilter: 6 def __init__(self, size, num_hashes): 7 self.size = size 8 self.num_hashes = num_hashes 9 self.bit_array = [0] * size 10 self.count = 0 11 12 def _hash(self, item, seed): 13 hash_value = int(hashlib.md5((str(item) + str(seed)).encode()).hexdigest(), 16) 14 return hash_value % self.size 15 16 def add(self, item): 17 for i in range(self.num_hashes): 18 index = self._hash(item, i) 19 self.bit_array[index] = 1 20 self.count += 1 21 22 def contains(self, item): 23 for i in range(self.num_hashes): 24 index = self._hash(item, i) 25 if self.bit_array[index] == 0: 26 return False 27 return True 28 29 30class ScalableBloomFilter: 31 def __init__(self, initial_size=100, fp_rate=0.05, growth_factor=2): 32 self.filters = [] 33 self.fp_rate = fp_rate 34 self.growth_factor = growth_factor 35 self.current_size = initial_size 36 self._add_new_filter() 37 38 def _optimal_num_hashes(self, size, items): 39 return max(1, math.ceil((size / items) * math.log(2))) 40 41 def _add_new_filter(self): 42 num_hashes = self._optimal_num_hashes(self.current_size, -math.log(self.fp_rate)) 43 self.filters.append(BloomFilter(self.current_size, num_hashes)) 44 self.current_size *= self.growth_factor 45 46 def add(self, item): 47 if self.filters[-1].count \u0026gt;= self.filters[-1].size: 48 self._add_new_filter() 49 self.filters[-1].add(item) 50 51 def contains(self, item): 52 return any(filter.contains(item) for filter in self.filters) 53 54 55# Example Usage: 56sbf = ScalableBloomFilter(initial_size=10, fp_rate=0.1) 57sbf.add(\u0026#34;hello\u0026#34;) 58print(sbf.contains(\u0026#34;hello\u0026#34;)) # True 59print(sbf.contains(\u0026#34;world\u0026#34;)) # False Striped Bloom Filter Striped Bloom Filter lÃ  má»™t biáº¿n thá»ƒ cá»§a Bloom Filter Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ há»— trá»£ truy cáº­p Ä‘á»“ng thá»i (concurrent access) hiá»‡u quáº£ trong mÃ´i trÆ°á»ng Ä‘a luá»“ng (multi-threaded). Má»¥c tiÃªu chÃ­nh cá»§a Striped Bloom Filter lÃ  giáº£m thiá»ƒu viá»‡c khÃ³a toÃ n bá»™ cáº¥u trÃºc dá»¯ liá»‡u khi cÃ¡c luá»“ng thá»±c hiá»‡n thÃªm hoáº·c kiá»ƒm tra pháº§n tá»­, qua Ä‘Ã³ cáº£i thiá»‡n hiá»‡u nÄƒng.\nÄáº·c Ä‘iá»ƒm cá»§a Striped Bloom Filter PhÃ¢n chia thÃ nh cÃ¡c phÃ¢n Ä‘oáº¡n Ä‘á»™c láº­p (Stripes):\nMáº£ng bit cá»§a Bloom Filter Ä‘Æ°á»£c chia thÃ nh nhiá»u phÃ¢n Ä‘oáº¡n (segments) Ä‘á»™c láº­p. Má»—i phÃ¢n Ä‘oáº¡n Ä‘Æ°á»£c báº£o vá»‡ bá»Ÿi má»™t khÃ³a riÃªng biá»‡t (lock). CÃ¡c thao tÃ¡c trÃªn tá»«ng phÃ¢n Ä‘oáº¡n cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘á»“ng thá»i mÃ  khÃ´ng áº£nh hÆ°á»Ÿng láº«n nhau. TÄƒng hiá»‡u suáº¥t truy cáº­p Ä‘á»“ng thá»i:\nBáº±ng cÃ¡ch phÃ¢n chia máº£ng vÃ  sá»­ dá»¥ng nhiá»u khÃ³a, cÃ¡c luá»“ng chá»‰ cáº§n khÃ³a má»™t phÃ¢n Ä‘oáº¡n thay vÃ¬ toÃ n bá»™ máº£ng. Äiá»u nÃ y giáº£m thiá»ƒu Ä‘á»™ trá»… trong cÃ¡c há»‡ thá»‘ng Ä‘a luá»“ng. Hoáº¡t Ä‘á»™ng giá»‘ng Bloom Filter truyá»n thá»‘ng:\nStriped Bloom Filter váº«n Ä‘áº£m báº£o cÃ¡c thuá»™c tÃ­nh cÆ¡ báº£n cá»§a Bloom Filter nhÆ° tá»· lá»‡ false positive vÃ  sá»­ dá»¥ng cÃ¡c hÃ m bÄƒm Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c chá»‰ má»¥c. CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Striped Bloom Filter 1. ChÃ¨n pháº§n tá»­ ( TÃ­nh cÃ¡c chá»‰ má»¥c bÄƒm (hash indices) cá»§a pháº§n tá»­. XÃ¡c Ä‘á»‹nh cÃ¡c phÃ¢n Ä‘oáº¡n tÆ°Æ¡ng á»©ng dá»±a trÃªn chá»‰ má»¥c. KhÃ³a cÃ¡c phÃ¢n Ä‘oáº¡n liÃªn quan Ä‘á»ƒ thÃªm bit. 2. Kiá»ƒm tra pháº§n tá»­ ( TÃ­nh cÃ¡c chá»‰ má»¥c bÄƒm cá»§a pháº§n tá»­. Truy cáº­p cÃ¡c phÃ¢n Ä‘oáº¡n tÆ°Æ¡ng á»©ng mÃ  khÃ´ng cáº§n khÃ³a (náº¿u chá»‰ kiá»ƒm tra). Náº¿u táº¥t cáº£ cÃ¡c bit táº¡i cÃ¡c chá»‰ má»¥c Ä‘Æ°á»£c Ä‘áº·t lÃ  1, pháº§n tá»­ cÃ³ thá»ƒ tá»“n táº¡i. 3. PhÃ¢n Ä‘oáº¡n (Segment): Máº£ng bit Ä‘Æ°á»£c chia thÃ nh ( S ) phÃ¢n Ä‘oáº¡n. Má»™t hÃ m bÄƒm bá»• sung Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ã¡nh xáº¡ má»™t pháº§n tá»­ Ä‘áº¿n má»™t hoáº·c nhiá»u phÃ¢n Ä‘oáº¡n cá»¥ thá»ƒ. 4. TÄƒng hiá»‡u suáº¥t Ä‘á»“ng thá»i: CÃ¡c luá»“ng chá»‰ cáº§n khÃ³a phÃ¢n Ä‘oáº¡n cáº§n thao tÃ¡c, thay vÃ¬ toÃ n bá»™ cáº¥u trÃºc dá»¯ liá»‡u. Æ¯u Ä‘iá»ƒm cá»§a Striped Bloom Filter Há»— trá»£ Ä‘á»“ng thá»i: Nhiá»u luá»“ng cÃ³ thá»ƒ thÃªm hoáº·c kiá»ƒm tra pháº§n tá»­ Ä‘á»“ng thá»i mÃ  khÃ´ng gÃ¢y xung Ä‘á»™t. Giáº£m Ä‘á»™ trá»…: PhÃ¢n Ä‘oáº¡n Ä‘á»™c láº­p giÃºp giáº£m thá»i gian chá» cá»§a cÃ¡c luá»“ng khi khÃ³a. Hiá»‡u quáº£ bá»™ nhá»›: DÃ¹ chia thÃ nh nhiá»u phÃ¢n Ä‘oáº¡n, tá»•ng bá»™ nhá»› sá»­ dá»¥ng váº«n tÆ°Æ¡ng tá»± Bloom Filter truyá»n thá»‘ng. Háº¡n cháº¿ cá»§a Striped Bloom Filter Äá»™ phá»©c táº¡p quáº£n lÃ½ khÃ³a: Cáº§n quáº£n lÃ½ nhiá»u khÃ³a hÆ¡n, lÃ m tÄƒng Ä‘á»™ phá»©c táº¡p trong triá»ƒn khai. False positive váº«n tá»“n táº¡i: NhÆ° Bloom Filter truyá»n thá»‘ng, Striped Bloom Filter váº«n khÃ´ng loáº¡i bá» Ä‘Æ°á»£c false positive. KhÃ´ng phÃ¹ há»£p vá»›i á»©ng dá»¥ng Ä‘Æ¡n luá»“ng: Trong mÃ´i trÆ°á»ng Ä‘Æ¡n luá»“ng, cÆ¡ cháº¿ phÃ¢n Ä‘oáº¡n vÃ  khÃ³a trá»Ÿ nÃªn dÆ° thá»«a. Triá»ƒn khai báº±ng Python 1import threading 2import hashlib 3 4class StripedBloomFilter: 5 def __init__(self, num_bits, num_hashes, num_stripes): 6 self.num_bits = num_bits 7 self.num_hashes = num_hashes 8 self.num_stripes = num_stripes 9 self.segment_size = num_bits // num_stripes 10 self.bit_array = [0] * num_bits 11 self.locks = [threading.Lock() for _ in range(num_stripes)] 12 13 def _hashes(self, item): 14 hashes = [] 15 for i in range(self.num_hashes): 16 hash_value = int(hashlib.md5((str(item) + str(i)).encode()).hexdigest(), 16) 17 hashes.append(hash_value % self.num_bits) 18 return hashes 19 20 def add(self, item): 21 indices = self._hashes(item) 22 locked_segments = set() 23 24 # Lock relevant segments 25 for idx in indices: 26 segment = idx // self.segment_size 27 if segment not in locked_segments: 28 self.locks[segment].acquire() 29 locked_segments.add(segment) 30 31 try: 32 for idx in indices: 33 self.bit_array[idx] = 1 34 finally: 35 # Unlock segments 36 for segment in locked_segments: 37 self.locks[segment].release() 38 39 def contains(self, item): 40 indices = self._hashes(item) 41 for idx in indices: 42 if self.bit_array[idx] == 0: 43 return False 44 return True 45 46 47# Example Usage 48sbf = StripedBloomFilter(num_bits=1024, num_hashes=3, num_stripes=4) 49 50# Adding elements 51sbf.add(\u0026#34;hello\u0026#34;) 52sbf.add(\u0026#34;world\u0026#34;) 53 54# Checking elements 55print(sbf.contains(\u0026#34;hello\u0026#34;)) # True 56print(sbf.contains(\u0026#34;world\u0026#34;)) # True 57print(sbf.contains(\u0026#34;python\u0026#34;)) # False Quotient Filter (Bá»™ lá»c thÆ°Æ¡ng sá»‘) Quotient Filter (QF) lÃ  má»™t cáº¥u trÃºc dá»¯ liá»‡u xÃ¡c suáº¥t tÆ°Æ¡ng tá»± Bloom Filter, Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ kiá»ƒm tra thÃ nh viÃªn (membership) trong táº­p há»£p vá»›i hiá»‡u quáº£ vá» máº·t bá»™ nhá»›. QF hoáº¡t Ä‘á»™ng dá»±a trÃªn ká»¹ thuáº­t bÄƒm (hashing) vÃ  chia thÆ°Æ¡ng sá»‘, cung cáº¥p má»™t giáº£i phÃ¡p nhá» gá»n cho cÃ¡c bÃ i toÃ¡n kiá»ƒm tra thÃ nh viÃªn.\nNguyÃªn lÃ½ hoáº¡t Ä‘á»™ng BÄƒm vÃ  chia thÆ°Æ¡ng sá»‘:\nTÆ°Æ¡ng tá»± Bloom Filter, QF sá»­ dá»¥ng hÃ m bÄƒm Ä‘á»ƒ táº¡o ra má»™t giÃ¡ trá»‹ bÄƒm cho pháº§n tá»­. GiÃ¡ trá»‹ bÄƒm Ä‘Æ°á»£c chia thÃ nh hai pháº§n: ThÆ°Æ¡ng sá»‘ (Quotient): XÃ¡c Ä‘á»‹nh chá»‰ sá»‘ cá»§a bucket (Ã´ nhá»›) trong má»™t máº£ng cá»‘ Ä‘á»‹nh. Pháº§n dÆ° (Remainder): LÆ°u láº¡i nhÆ° má»™t chá»¯ kÃ½ duy nháº¥t trong máº£ng Ä‘á»ƒ kiá»ƒm tra. Buckets vÃ  máº£ng:\nThÆ°Æ¡ng sá»‘ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vá»‹ trÃ­ lÆ°u pháº§n dÆ° trong máº£ng. TrÆ°á»ng há»£p xung Ä‘á»™t (collisions) Ä‘Æ°á»£c xá»­ lÃ½ báº±ng cÃ¡ch kiá»ƒm tra tuáº§n tá»± cÃ¡c Ã´ liá»n ká» (linear probing). LÆ°u trá»¯ nhá» gá»n:\nChá»‰ pháº§n dÆ° Ä‘Æ°á»£c lÆ°u trong máº£ng, giÃºp tiáº¿t kiá»‡m bá»™ nhá»› Ä‘Ã¡ng ká»ƒ so vá»›i báº£ng bÄƒm (hash table) truyá»n thá»‘ng. Metadata (dá»¯ liá»‡u phá»¥) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ theo dÃµi tráº¡ng thÃ¡i cá»§a cÃ¡c bucket (Ä‘áº§y hay rá»—ng, pháº§n tá»­ bá»‹ dá»i chá»—). Há»— trá»£ thÃªm/xÃ³a/kiá»ƒm tra:\nQF há»— trá»£ ba thao tÃ¡c cÆ¡ báº£n: thÃªm pháº§n tá»­, xÃ³a pháº§n tá»­, vÃ  kiá»ƒm tra thÃ nh viÃªn, vá»›i hiá»‡u suáº¥t cao vÃ  tiÃªu tá»‘n Ã­t bá»™ nhá»›. Æ¯u Ä‘iá»ƒm cá»§a Quotient Filter Tiáº¿t kiá»‡m bá»™ nhá»›:\nQF nhá» gá»n hÆ¡n báº£ng bÄƒm vÃ  tÆ°Æ¡ng Ä‘Æ°Æ¡ng Bloom Filter vá» má»©c Ä‘á»™ sá»­ dá»¥ng bá»™ nhá»›. Há»— trá»£ xÃ³a pháº§n tá»­:\nKhÃ´ng nhÆ° Bloom Filter cÆ¡ báº£n, QF há»— trá»£ viá»‡c xÃ³a pháº§n tá»­ mÃ  khÃ´ng cáº§n biáº¿n thá»ƒ bá»• sung nhÆ° Counting Bloom Filter. Chá»‰ cáº§n má»™t hÃ m bÄƒm:\nQF chá»‰ cáº§n má»™t hÃ m bÄƒm duy nháº¥t, giÃºp giáº£m chi phÃ­ tÃ­nh toÃ¡n so vá»›i Bloom Filter (yÃªu cáº§u nhiá»u hÃ m bÄƒm). Hiá»‡u suáº¥t cao:\nThao tÃ¡c thÃªm, xÃ³a vÃ  kiá»ƒm tra nhanh chÃ³ng vá»›i Ä‘á»™ phá»©c táº¡p tháº¥p. Kháº£ nÄƒng má»Ÿ rá»™ng Ä‘á»™ng:\nQF cÃ³ thá»ƒ má»Ÿ rá»™ng dung lÆ°á»£ng hoáº·c tÃ¡i cáº¥u trÃºc máº£ng khi cáº§n thiáº¿t mÃ  khÃ´ng áº£nh hÆ°á»Ÿng lá»›n Ä‘áº¿n hiá»‡u suáº¥t. Háº¡n cháº¿ cá»§a Quotient Filter False Positive (Káº¿t quáº£ dÆ°Æ¡ng tÃ­nh giáº£):\nTÆ°Æ¡ng tá»± Bloom Filter, QF cÃ³ thá»ƒ bÃ¡o ráº±ng má»™t pháº§n tá»­ thuá»™c táº­p há»£p dÃ¹ thá»±c táº¿ khÃ´ng pháº£i váº­y. Tuy nhiÃªn, khÃ´ng cÃ³ false negative (káº¿t quáº£ Ã¢m tÃ­nh giáº£). Phá»©c táº¡p hÆ¡n Bloom Filter:\nViá»‡c quáº£n lÃ½ metadata (tráº¡ng thÃ¡i bucket, pháº§n tá»­ bá»‹ dá»i) khiáº¿n QF phá»©c táº¡p hÆ¡n trong triá»ƒn khai. Cá»‘ Ä‘á»‹nh dung lÆ°á»£ng:\nDung lÆ°á»£ng cá»§a QF cáº§n Ä‘Æ°á»£c thiáº¿t káº¿ trÆ°á»›c. Khi vÆ°á»£t quÃ¡ giá»›i háº¡n, viá»‡c má»Ÿ rá»™ng dung lÆ°á»£ng sáº½ yÃªu cáº§u tÃ¡i cáº¥u trÃºc máº£ng, gÃ¢y tá»‘n kÃ©m tÃ i nguyÃªn. Hiá»‡u suáº¥t giáº£m vá»›i cÃ¡c táº­p dá»¯ liá»‡u phÃ¢n tÃ¡n:\nQF khÃ´ng phÃ¹ há»£p vá»›i cÃ¡c á»©ng dá»¥ng yÃªu cáº§u truy cáº­p ngáº«u nhiÃªn, do cáº§n kiá»ƒm tra tuáº§n tá»± trong trÆ°á»ng há»£p xung Ä‘á»™t. á»¨ng dá»¥ng cá»§a Quotient Filter CÆ¡ sá»Ÿ dá»¯ liá»‡u: Lá»c dá»¯ liá»‡u, kiá»ƒm tra thÃ nh viÃªn trong chá»‰ má»¥c hoáº·c giáº£m truy cáº­p Ä‘Ä©a khÃ´ng cáº§n thiáº¿t. Há»‡ thá»‘ng máº¡ng: Lá»c gÃ³i tin hoáº·c kiá»ƒm tra thÃ nh viÃªn cá»§a Ä‘á»‹a chá»‰ IP trong báº£ng Ä‘á»‹nh tuyáº¿n. Há»‡ thá»‘ng phÃ¢n tÃ¡n: Äá»“ng bá»™ dá»¯ liá»‡u giá»¯a cÃ¡c nÃºt hoáº·c kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n. LÆ°u trá»¯: Loáº¡i bá» trÃ¹ng láº·p dá»¯ liá»‡u (deduplication) trong cÃ¡c há»‡ thá»‘ng lÆ°u trá»¯. So sÃ¡nh vá»›i Bloom Filter TÃ­nh nÄƒng Bloom Filter Quotient Filter False Positive CÃ³ thá»ƒ xáº£y ra CÃ³ thá»ƒ xáº£y ra False Negative KhÃ´ng KhÃ´ng Há»— trá»£ xÃ³a KhÃ´ng (cáº§n Counting BF) CÃ³ Bá»™ nhá»› Hiá»‡u quáº£ cao Hiá»‡u quáº£ (kÃ¨m metadata) HÃ m bÄƒm Nhiá»u Má»™t Má»Ÿ rá»™ng Ä‘á»™ng Cáº§n Scalable Bloom Filter Há»— trá»£ giá»›i háº¡n VÃ­ dá»¥ mÃ£ giáº£ báº±ng Python 1class QuotientFilter: 2 def __init__(self, size): 3 self.size = size 4 self.table = [None] * size 5 self.metadata = [False] * size # Tráº¡ng thÃ¡i bucket 6 7 def _hash(self, value): 8 h = hash(value) 9 quotient = h // self.size 10 remainder = h % self.size 11 return quotient, remainder 12 13 def insert(self, value): 14 quotient, remainder = self._hash(value) 15 while self.metadata[quotient]: # Xá»­ lÃ½ xung Ä‘á»™t 16 quotient = (quotient + 1) % self.size 17 self.table[quotient] = remainder 18 self.metadata[quotient] = True 19 20 def query(self, value): 21 quotient, remainder = self._hash(value) 22 while self.metadata[quotient]: 23 if self.table[quotient] == remainder: 24 return True 25 quotient = (quotient + 1) % self.size 26 return False 27 28 def delete(self, value): 29 quotient, remainder = self._hash(value) 30 while self.metadata[quotient]: 31 if self.table[quotient] == remainder: 32 self.table[quotient] = None 33 self.metadata[quotient] = False 34 return True 35 quotient = (quotient + 1) % self.size 36 return False Káº¿t luáº­n Quotient Filter lÃ  má»™t giáº£i phÃ¡p máº¡nh máº½, káº¿t há»£p hiá»‡u quáº£ cá»§a Bloom Filter vÃ  báº£ng bÄƒm, phÃ¹ há»£p cho cÃ¡c á»©ng dá»¥ng cáº§n kiá»ƒm tra thÃ nh viÃªn, há»— trá»£ xÃ³a, vÃ  tiáº¿t kiá»‡m bá»™ nhá»›. Tuy nhiÃªn, cáº§n xem xÃ©t cÃ¡c háº¡n cháº¿ vá» thiáº¿t káº¿ vÃ  á»©ng dá»¥ng Ä‘á»ƒ sá»­ dá»¥ng tá»‘i Æ°u trong cÃ¡c bÃ i toÃ¡n cá»¥ thá»ƒ.\nCuckoo Filter Cuckoo Filter lÃ  má»™t cáº¥u trÃºc dá»¯ liá»‡u xÃ¡c suáº¥t Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ kiá»ƒm tra thÃ nh viÃªn trong táº­p há»£p (membership test) giá»‘ng nhÆ° Bloom Filter, nhÆ°ng vá»›i nhiá»u cáº£i tiáº¿n. NÃ³ sá»­ dá»¥ng Ã½ tÆ°á»Ÿng tá»« Cuckoo Hashing vÃ  cung cáº¥p má»™t sá»‘ tÃ­nh nÄƒng ná»•i báº­t nhÆ° há»— trá»£ xÃ³a pháº§n tá»­ vÃ  hiá»‡u quáº£ vá» bá»™ nhá»›.\nNguyÃªn lÃ½ hoáº¡t Ä‘á»™ng Cuckoo Filter hoáº¡t Ä‘á»™ng dá»±a trÃªn hai khÃ¡i niá»‡m chÃ­nh:\nFingerprinting (Chá»¯ kÃ½):\nMá»—i pháº§n tá»­ Ä‘Æ°á»£c bÄƒm Ä‘á»ƒ táº¡o ra má»™t giÃ¡ trá»‹ fingerprint ngáº¯n, Ä‘áº¡i diá»‡n cho pháº§n tá»­ Ä‘Ã³. Chá»‰ lÆ°u trá»¯ giÃ¡ trá»‹ fingerprint trong máº£ng, giÃºp tiáº¿t kiá»‡m bá»™ nhá»›. Cuckoo Hashing:\nMá»—i pháº§n tá»­ cÃ³ thá»ƒ Ä‘Æ°á»£c lÆ°u á»Ÿ má»™t trong hai vá»‹ trÃ­ tiá»m nÄƒng trong máº£ng (table). Khi thÃªm pháº§n tá»­ má»›i mÃ  vá»‹ trÃ­ Ä‘Ã£ bá»‹ chiáº¿m, má»™t pháº§n tá»­ khÃ¡c cÃ³ thá»ƒ bá»‹ \u0026ldquo;Ä‘áº©y\u0026rdquo; Ä‘áº¿n vá»‹ trÃ­ thá»© hai cá»§a nÃ³, theo cÃ¡ch tÆ°Æ¡ng tá»± thuáº­t toÃ¡n Cuckoo Hashing. Thao tÃ¡c chÃ­nh trong Cuckoo Filter ThÃªm pháº§n tá»­ (Insert):\nTÃ­nh hai vá»‹ trÃ­ bÄƒm (bucket) cho pháº§n tá»­ dá»±a trÃªn giÃ¡ trá»‹ fingerprint. Náº¿u má»™t trong hai vá»‹ trÃ­ cÃ²n trá»‘ng, lÆ°u fingerprint táº¡i Ä‘Ã³. Náº¿u cáº£ hai vá»‹ trÃ­ Ä‘á»u Ä‘áº§y, chá»n ngáº«u nhiÃªn má»™t fingerprint trong bucket vÃ  \u0026ldquo;Ä‘áº©y\u0026rdquo; nÃ³ Ä‘áº¿n vá»‹ trÃ­ thá»© hai cá»§a nÃ³. Tiáº¿p tá»¥c láº·p láº¡i cho Ä‘áº¿n khi chÃ¨n thÃ nh cÃ´ng hoáº·c vÆ°á»£t quÃ¡ sá»‘ láº§n thá»­ (rehash náº¿u cáº§n). Kiá»ƒm tra pháº§n tá»­ (Query):\nTÃ­nh hai vá»‹ trÃ­ bÄƒm dá»±a trÃªn giÃ¡ trá»‹ fingerprint. Kiá»ƒm tra xem giÃ¡ trá»‹ fingerprint cÃ³ tá»“n táº¡i táº¡i má»™t trong hai bucket khÃ´ng. XÃ³a pháº§n tá»­ (Delete):\nTÃ­nh hai vá»‹ trÃ­ bÄƒm dá»±a trÃªn giÃ¡ trá»‹ fingerprint. Náº¿u giÃ¡ trá»‹ fingerprint tá»“n táº¡i táº¡i má»™t trong hai vá»‹ trÃ­, xÃ³a nÃ³. Æ¯u Ä‘iá»ƒm cá»§a Cuckoo Filter Há»— trá»£ xÃ³a pháº§n tá»­:\nKhÃ´ng giá»‘ng Bloom Filter cÆ¡ báº£n, Cuckoo Filter há»— trá»£ xÃ³a pháº§n tá»­ dá»… dÃ ng mÃ  khÃ´ng cáº§n cÃ¡c biáº¿n thá»ƒ phá»©c táº¡p. Tá»· lá»‡ false positive tháº¥p:\nCuckoo Filter cung cáº¥p tá»· lá»‡ dÆ°Æ¡ng tÃ­nh giáº£ (false positive) tháº¥p, Ä‘áº·c biá»‡t khi tá»‘i Æ°u kÃ­ch thÆ°á»›c bucket vÃ  fingerprint. Tiáº¿t kiá»‡m bá»™ nhá»›:\nNhá» chá»‰ lÆ°u trá»¯ giÃ¡ trá»‹ fingerprint ngáº¯n, Cuckoo Filter thÆ°á»ng tiáº¿t kiá»‡m bá»™ nhá»› hÆ¡n Bloom Filter trong nhiá»u trÆ°á»ng há»£p. Hiá»‡u suáº¥t cao:\nThao tÃ¡c thÃªm, xÃ³a vÃ  kiá»ƒm tra nhanh chÃ³ng, thÆ°á»ng cÃ³ Ä‘á»™ phá»©c táº¡p ( O(1) ) trung bÃ¬nh. Há»— trá»£ kiá»ƒm tra Ã¢m tÃ­nh chÃ­nh xÃ¡c:\nKhÃ´ng bao giá» xáº£y ra false negative (káº¿t quáº£ Ã¢m tÃ­nh sai). Kháº£ nÄƒng má»Ÿ rá»™ng:\nCuckoo Filter cÃ³ thá»ƒ má»Ÿ rá»™ng thÃ´ng qua cÆ¡ cháº¿ rehash hoáº·c tÄƒng kÃ­ch thÆ°á»›c máº£ng khi cáº§n thiáº¿t. Háº¡n cháº¿ cá»§a Cuckoo Filter KhÃ³ khÄƒn vá»›i chÃ¨n pháº§n tá»­ dÃ y Ä‘áº·c:\nKhi máº£ng quÃ¡ Ä‘áº§y, viá»‡c thÃªm pháº§n tá»­ má»›i cÃ³ thá»ƒ dáº«n Ä‘áº¿n hiá»‡n tÆ°á»£ng \u0026ldquo;cuckoo evictions\u0026rdquo; (Ä‘áº©y vÃ²ng láº·p khÃ´ng thÃ nh cÃ´ng), buá»™c pháº£i tÃ¡i cáº¥u trÃºc (rehash) toÃ n bá»™ máº£ng. Cáº¥u trÃºc phá»©c táº¡p hÆ¡n Bloom Filter:\nSo vá»›i Bloom Filter, Cuckoo Filter yÃªu cáº§u quáº£n lÃ½ nhiá»u bucket, cÆ¡ cháº¿ Ä‘áº©y pháº§n tá»­, vÃ  xá»­ lÃ½ xung Ä‘á»™t phá»©c táº¡p hÆ¡n. KhÃ´ng tá»‘i Æ°u vá»›i sá»‘ lÆ°á»£ng pháº§n tá»­ lá»›n:\nVá»›i táº­p dá»¯ liá»‡u quÃ¡ lá»›n, Bloom Filter cÃ³ thá»ƒ hiá»‡u quáº£ hÆ¡n vá» máº·t bá»™ nhá»› so vá»›i Cuckoo Filter. á»¨ng dá»¥ng cá»§a Cuckoo Filter Há»‡ thá»‘ng cÆ¡ sá»Ÿ dá»¯ liá»‡u: Kiá»ƒm tra dá»¯ liá»‡u tá»“n táº¡i trong cÃ¡c chá»‰ má»¥c hoáº·c giáº£m truy cáº­p Ä‘Ä©a. Há»‡ thá»‘ng máº¡ng: Lá»c gÃ³i tin hoáº·c kiá»ƒm tra Ä‘á»‹a chá»‰ IP trong báº£ng Ä‘á»‹nh tuyáº¿n. Há»‡ thá»‘ng phÃ¢n tÃ¡n: Äá»“ng bá»™ dá»¯ liá»‡u, kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n. Bá»™ nhá»› Ä‘á»‡m (Cache): Lá»c nhanh cÃ¡c truy váº¥n trong bá»™ nhá»› Ä‘á»‡m. So sÃ¡nh vá»›i Bloom Filter TÃ­nh nÄƒng Bloom Filter Cuckoo Filter False Positive CÃ³ thá»ƒ xáº£y ra CÃ³ thá»ƒ xáº£y ra False Negative KhÃ´ng KhÃ´ng Há»— trá»£ xÃ³a KhÃ´ng (cáº§n Counting BF) CÃ³ Bá»™ nhá»› Tiáº¿t kiá»‡m cao Tiáº¿t kiá»‡m tá»‘t (nhÆ°ng phá»©c táº¡p hÆ¡n) Thao tÃ¡c thÃªm ÄÆ¡n giáº£n, khÃ´ng Ä‘áº©y pháº§n tá»­ Phá»©c táº¡p hÆ¡n do Ä‘áº©y pháº§n tá»­ Kháº£ nÄƒng má»Ÿ rá»™ng Cáº§n Scalable Bloom Filter CÃ³ há»— trá»£ má»Ÿ rá»™ng trá»±c tiáº¿p VÃ­ dá»¥ mÃ£ giáº£ Cuckoo Filter báº±ng Python 1import random 2 3class CuckooFilter: 4 def __init__(self, size, bucket_size=2, fingerprint_size=4): 5 self.size = size 6 self.bucket_size = bucket_size 7 self.fingerprint_size = fingerprint_size 8 self.buckets = [[] for _ in range(size)] 9 10 def _hash(self, value): 11 return hash(value) % self.size 12 13 def _fingerprint(self, value): 14 return hash(value) % (2 ** self.fingerprint_size) 15 16 def insert(self, value): 17 fingerprint = self._fingerprint(value) 18 i1 = self._hash(value) 19 i2 = (i1 ^ hash(fingerprint)) % self.size 20 21 if len(self.buckets[i1]) \u0026lt; self.bucket_size: 22 self.buckets[i1].append(fingerprint) 23 return True 24 elif len(self.buckets[i2]) \u0026lt; self.bucket_size: 25 self.buckets[i2].append(fingerprint) 26 return True 27 28 # Eviction 29 i = random.choice([i1, i2]) 30 for _ in range(self.size): 31 evicted_fingerprint = self.buckets[i].pop(0) 32 self.buckets[i].append(fingerprint) 33 fingerprint = evicted_fingerprint 34 i = (i ^ hash(fingerprint)) % self.size 35 if len(self.buckets[i]) \u0026lt; self.bucket_size: 36 self.buckets[i].append(fingerprint) 37 return True 38 39 return False # Failed to insert after many attempts 40 41 def query(self, value): 42 fingerprint = self._fingerprint(value) 43 i1 = self._hash(value) 44 i2 = (i1 ^ hash(fingerprint)) % self.size 45 46 return fingerprint in self.buckets[i1] or fingerprint in self.buckets[i2] 47 48 def delete(self, value): 49 fingerprint = self._fingerprint(value) 50 i1 = self._hash(value) 51 i2 = (i1 ^ hash(fingerprint)) % self.size 52 53 if fingerprint in self.buckets[i1]: 54 self.buckets[i1].remove(fingerprint) 55 return True 56 elif fingerprint in self.buckets[i2]: 57 self.buckets[i2].remove(fingerprint) 58 return True 59 return False Káº¿t luáº­n Cuckoo Filter lÃ  má»™t cáº¥u trÃºc dá»¯ liá»‡u máº¡nh máº½, hiá»‡u quáº£ vÃ  phÃ¹ há»£p cho cÃ¡c á»©ng dá»¥ng cáº§n thÃªm, xÃ³a, vÃ  kiá»ƒm tra thÃ nh viÃªn nhanh chÃ³ng. Máº·c dÃ¹ phá»©c táº¡p hÆ¡n Bloom Filter, nÃ³ mang láº¡i nhiá»u tÃ­nh nÄƒng há»¯u Ã­ch nhÆ° há»— trá»£ xÃ³a vÃ  hiá»‡u quáº£ bá»™ nhá»› cao hÆ¡n trong má»™t sá»‘ trÆ°á»ng há»£p.\ná»¨ng Dá»¥ng cá»§a Bloom Filter trong CÃ¡c LÄ©nh Vá»±c 1. PhÃ¡t Hiá»‡n Gian Láº­n TÃ i ChÃ­nh (Financial Fraud Detection) Má»¥c Ä‘Ã­ch: XÃ¡c Ä‘á»‹nh hÃ nh vi Ä‘Ã¡ng ngá» trong thÃ³i quen mua sáº¯m cá»§a ngÆ°á»i dÃ¹ng.\nCÃ¡ch sá»­ dá»¥ng:\nSá»­ dá»¥ng má»™t Bloom Filter riÃªng cho má»—i ngÆ°á»i dÃ¹ng. Kiá»ƒm tra má»i giao dá»‹ch Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i: NgÆ°á»i dÃ¹ng nÃ y Ä‘Ã£ thanh toÃ¡n tá»« Ä‘á»‹a Ä‘iá»ƒm nÃ y trÆ°á»›c Ä‘Ã¢y chÆ°a? Bloom Filter cung cáº¥p pháº£n há»“i cá»±c ká»³ nhanh (Ä‘á»™ trá»… tháº¥p). NhÃ¢n báº£n dá»¯ liá»‡u qua cÃ¡c khu vá»±c Ä‘á»ƒ xá»­ lÃ½ khi ngÆ°á»i dÃ¹ng di chuyá»ƒn. Lá»£i Ã­ch khi sá»­ dá»¥ng Bloom Filter:\nGiao dá»‹ch hoÃ n táº¥t nhanh chÃ³ng. Giáº£m nguy cÆ¡ giao dá»‹ch bá»‹ giÃ¡n Ä‘oáº¡n trong trÆ°á»ng há»£p máº¡ng bá»‹ phÃ¢n vÃ¹ng (káº¿t ná»‘i Ä‘Æ°á»£c giá»¯ trong thá»i gian ngáº¯n hÆ¡n). TÄƒng cÆ°á»ng lá»›p báº£o máº­t cho cáº£ chá»§ tháº» tÃ­n dá»¥ng vÃ  nhÃ  bÃ¡n láº». CÃ¡c cÃ¢u há»i khÃ¡c mÃ  Bloom Filter cÃ³ thá»ƒ há»— trá»£ trong ngÃ nh tÃ i chÃ­nh:\nNgÆ°á»i dÃ¹ng Ä‘Ã£ tá»«ng mua sáº£n pháº©m/dá»‹ch vá»¥ trong danh má»¥c nÃ y chÆ°a? CÃ³ cáº§n bá» qua má»™t sá»‘ bÆ°á»›c báº£o máº­t khi mua sáº¯m vá»›i cÃ¡c cá»­a hÃ ng trá»±c tuyáº¿n Ä‘Ã¡ng tin cáº­y (nhÆ° Amazon, Apple App Store)? Tháº» tÃ­n dá»¥ng nÃ y cÃ³ bá»‹ bÃ¡o máº¥t hoáº·c Ä‘Ã¡nh cáº¯p khÃ´ng? Lá»£i Ã­ch bá»• sung: CÃ¡c tá»• chá»©c tÃ i chÃ­nh cÃ³ thá»ƒ trao Ä‘á»•i danh sÃ¡ch sá»‘ tháº» bá»‹ máº¥t/máº¥t cáº¯p mÃ  khÃ´ng tiáº¿t lá»™ sá»‘ thá»±c. 2. Äáº·t Quáº£ng CÃ¡o (Ad Placement - Retail, Advertising) Má»¥c Ä‘Ã­ch: Hiá»ƒn thá»‹ quáº£ng cÃ¡o hoáº·c Ä‘á» xuáº¥t sáº£n pháº©m má»™t cÃ¡ch cÃ¡ nhÃ¢n hÃ³a.\nCÃ¡ch sá»­ dá»¥ng:\nSá»­ dá»¥ng má»™t Bloom Filter cho má»—i ngÆ°á»i dÃ¹ng, lÆ°u trá»¯ danh sÃ¡ch sáº£n pháº©m Ä‘Ã£ mua. Khi há»‡ thá»‘ng Ä‘á» xuáº¥t sáº£n pháº©m má»›i: Náº¿u sáº£n pháº©m chÆ°a cÃ³ trong Bloom Filter, quáº£ng cÃ¡o Ä‘Æ°á»£c hiá»ƒn thá»‹ vÃ  sáº£n pháº©m Ä‘Æ°á»£c thÃªm vÃ o Bloom Filter. Náº¿u sáº£n pháº©m Ä‘Ã£ cÃ³ trong Bloom Filter, há»‡ thá»‘ng tiáº¿p tá»¥c kiá»ƒm tra sáº£n pháº©m khÃ¡c cho Ä‘áº¿n khi tÃ¬m Ä‘Æ°á»£c sáº£n pháº©m chÆ°a cÃ³. Lá»£i Ã­ch khi sá»­ dá»¥ng Bloom Filter:\nGiáº£i phÃ¡p chi phÃ­ tháº¥p Ä‘á»ƒ táº¡o tráº£i nghiá»‡m cÃ¡ nhÃ¢n hÃ³a gáº§n nhÆ° theo thá»i gian thá»±c. KhÃ´ng cáº§n Ä‘áº§u tÆ° vÃ o cÆ¡ sá»Ÿ háº¡ táº§ng Ä‘áº¯t Ä‘á». 3. Kiá»ƒm Tra TÃªn NgÆ°á»i DÃ¹ng (SaaS, Content Publishing Platforms) Má»¥c Ä‘Ã­ch: XÃ¡c Ä‘á»‹nh tÃªn ngÆ°á»i dÃ¹ng/email/domain name/slug Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng chÆ°a.\nCÃ¡ch sá»­ dá»¥ng:\nSá»­ dá»¥ng má»™t Bloom Filter lÆ°u táº¥t cáº£ cÃ¡c tÃªn ngÆ°á»i dÃ¹ng Ä‘Ã£ Ä‘Äƒng kÃ½. Khi ngÆ°á»i dÃ¹ng nháº­p tÃªn mong muá»‘n: Náº¿u khÃ´ng cÃ³ trong Bloom Filter, tÃ i khoáº£n Ä‘Æ°á»£c táº¡o vÃ  tÃªn Ä‘Æ°á»£c thÃªm vÃ o Bloom Filter. Náº¿u cÃ³, á»©ng dá»¥ng quyáº¿t Ä‘á»‹nh kiá»ƒm tra cÆ¡ sá»Ÿ dá»¯ liá»‡u chÃ­nh hoáº·c tá»« chá»‘i tÃªn Ä‘Ã³. Lá»£i Ã­ch khi sá»­ dá»¥ng Bloom Filter:\nPhÆ°Æ¡ng phÃ¡p ráº¥t nhanh vÃ  hiá»‡u quáº£ Ä‘á»ƒ thá»±c hiá»‡n thao tÃ¡c phá»• biáº¿n. KhÃ´ng cáº§n Ä‘áº§u tÆ° vÃ o cÆ¡ sá»Ÿ háº¡ táº§ng phá»©c táº¡p. 4. CÃ¡c á»¨ng Dá»¥ng KhÃ¡c Cá»§a Bloom Filter Kiá»ƒm Tra ChÃ­nh Táº£ (Spell Checker):\nTrong thá»i ká»³ Ä‘áº§u, bá»™ kiá»ƒm tra chÃ­nh táº£ Ä‘Æ°á»£c triá»ƒn khai báº±ng Bloom Filter. CÆ¡ Sá»Ÿ Dá»¯ Liá»‡u (Databases):\nNhiá»u cÆ¡ sá»Ÿ dá»¯ liá»‡u phá»• biáº¿n sá»­ dá»¥ng Bloom Filter Ä‘á»ƒ giáº£m sá»‘ láº§n truy cáº­p Ä‘Ä©a tá»‘n kÃ©m cho cÃ¡c hÃ ng/cá»™t khÃ´ng tá»“n táº¡i. CÃ¡c há»‡ thá»‘ng nhÆ° PostgreSQL, Apache Cassandra, Cloud Bigtable sá»­ dá»¥ng ká»¹ thuáº­t nÃ y. CÃ´ng Cá»¥ TÃ¬m Kiáº¿m (Search Engines):\nBitFunnel, má»™t thuáº­t toÃ¡n láº­p chá»‰ má»¥c cho cÃ´ng cá»¥ tÃ¬m kiáº¿m, sá»­ dá»¥ng Bloom Filter Ä‘á»ƒ lÆ°u trá»¯ chá»‰ má»¥c tÃ¬m kiáº¿m. An Ninh (Security):\nDÃ¹ng Bloom Filter Ä‘á»ƒ phÃ¡t hiá»‡n máº­t kháº©u yáº¿u, URL Ä‘á»™c háº¡i, vÃ  cÃ¡c nguy cÆ¡ an ninh khÃ¡c. BÃ i táº­p Financial Fraud Detection xÃ¢y dá»±ng á»©ng dá»¥ng Financial Fraud Detection sá»­ dá»¥ng Bloom Filter. Má»¥c tiÃªu lÃ  kiá»ƒm tra xem ngÆ°á»i dÃ¹ng Ä‘Ã£ thá»±c hiá»‡n giao dá»‹ch tá»« má»™t Ä‘á»‹a Ä‘iá»ƒm cá»¥ thá»ƒ hay chÆ°a Ä‘á»ƒ phÃ¡t hiá»‡n hÃ nh vi gian láº­n. Náº¿u ngÆ°á»i dÃ¹ng chÆ°a thá»±c hiá»‡n giao dá»‹ch á»Ÿ 1 ban nÃ o Ä‘Ã³ trong lá»‹ch sá»­ thÃ¬ cáº£nh bÃ¡o lÃªn\n1 2import hashlib 3 4class BloomFilter: 5 def __init__(self, size, num_hash_functions): 6 # KÃ­ch thÆ°á»›c Bloom filter (sá»‘ lÆ°á»£ng bit) 7 self.size = size 8 # Sá»‘ hÃ m bÄƒm 9 self.num_hash_functions = num_hash_functions 10 # Máº£ng bit Ä‘á»ƒ lÆ°u trá»¯ (khá»Ÿi táº¡o vá»›i cÃ¡c bit = 0) 11 self.bit_array = [0] * size 12 13 def _hash(self, item, i): 14 \u0026#34;\u0026#34;\u0026#34;HÃ m bÄƒm Ä‘á»ƒ táº¡o chá»‰ sá»‘ tá»« item, vá»›i i lÃ  chá»‰ sá»‘ cá»§a hÃ m bÄƒm.\u0026#34;\u0026#34;\u0026#34; 15 return int(hashlib.sha256(f\u0026#34;{item}{i}\u0026#34;.encode(\u0026#39;utf-8\u0026#39;)).hexdigest(), 16) % self.size 16 17 def add(self, item): 18 \u0026#34;\u0026#34;\u0026#34;ThÃªm má»™t item vÃ o Bloom filter.\u0026#34;\u0026#34;\u0026#34; 19 for i in range(self.num_hash_functions): 20 index = self._hash(item, i) 21 self.bit_array[index] = 1 22 23 def check(self, item): 24 \u0026#34;\u0026#34;\u0026#34;Kiá»ƒm tra má»™t item cÃ³ trong Bloom filter khÃ´ng.\u0026#34;\u0026#34;\u0026#34; 25 for i in range(self.num_hash_functions): 26 index = self._hash(item, i) 27 if self.bit_array[index] == 0: 28 return False # Náº¿u báº¥t ká»³ bit nÃ o lÃ  0, pháº§n tá»­ cháº¯c cháº¯n khÃ´ng cÃ³ trong bá»™ lá»c 29 return True # Náº¿u táº¥t cáº£ cÃ¡c bit Ä‘á»u lÃ  1, cÃ³ kháº£ nÄƒng pháº§n tá»­ cÃ³ trong bá»™ lá»c 30 31# Khá»Ÿi táº¡o Bloom filter vá»›i kÃ­ch thÆ°á»›c 1000 bit vÃ  3 hÃ m bÄƒm 32bloom_filter = BloomFilter(size=1000, num_hash_functions=3) 33 34# MÃ´ phá»ng thÃ´ng tin giao dá»‹ch cá»§a ngÆ°á»i dÃ¹ng 35users_transactions = { 36 \u0026#34;tung\u0026#34;: [\u0026#34;New York\u0026#34;, \u0026#34;Los Angeles\u0026#34;, \u0026#34;Miami\u0026#34;], 37 \u0026#34;kim\u0026#34;: [\u0026#34;London\u0026#34;, \u0026#34;Paris\u0026#34;, \u0026#34;Berlin\u0026#34;], 38 \u0026#34;tuan\u0026#34;: [\u0026#34;Tokyo\u0026#34;, \u0026#34;Osaka\u0026#34;, \u0026#34;Kyoto\u0026#34;] 39} 40 41# ThÃªm táº¥t cáº£ cÃ¡c giao dá»‹ch vÃ o Bloom filter 42for user, locations in users_transactions.items(): 43 for location in locations: 44 bloom_filter.add(f\u0026#34;{user}-{location}\u0026#34;) # Káº¿t há»£p tÃªn ngÆ°á»i dÃ¹ng vÃ  Ä‘á»‹a Ä‘iá»ƒm giao dá»‹ch 45 46# Kiá»ƒm tra má»™t giao dá»‹ch má»›i tá»« ngÆ°á»i dÃ¹ng 47def check_fraud(user, location): 48 if not bloom_filter.check(f\u0026#34;{user}-{location}\u0026#34;): 49 return f\u0026#34;Warning: Transaction from {location} by {user} might be suspicious!\u0026#34; 50 else: 51 return f\u0026#34;Transaction from {location} by {user} is normal.\u0026#34; 52 53# Kiá»ƒm tra má»™t sá»‘ giao dá»‹ch 54test_transactions = [ 55 (\u0026#34;tung\u0026#34;, \u0026#34;Miami\u0026#34;), # Giao dá»‹ch há»£p lá»‡ 56 (\u0026#34;tung\u0026#34;, \u0026#34;Chicago\u0026#34;), # Giao dá»‹ch má»›i (khÃ´ng cÃ³ trong Bloom filter) 57 (\u0026#34;kim\u0026#34;, \u0026#34;Paris\u0026#34;), # Giao dá»‹ch há»£p lá»‡ 58 (\u0026#34;tuan\u0026#34;, \u0026#34;Kyoto\u0026#34;) # Giao dá»‹ch há»£p lá»‡ 59] 60 61# Kiá»ƒm tra cÃ¡c giao dá»‹ch 62for user, location in test_transactions: 63 result = check_fraud(user, location) 64 print(result) Káº¿t quáº£:\n1Transaction from Miami by tung is normal. 2Warning: Transaction from Chicago by tung might be suspicious! 3Transaction from Paris by kim is normal. 4Transaction from Kyoto by tuan is normal. Spell Checker xÃ¢y dá»±ng má»™t Spell Checker sá»­ dá»¥ng Bloom Filter. MÃ£ nÃ y sáº½ kiá»ƒm tra xem má»™t tá»« cÃ³ trong tá»« Ä‘iá»ƒn (dictionary) hay khÃ´ng vÃ  Ä‘Æ°a ra káº¿t quáº£.\n1 2import hashlib 3 4class BloomFilter: 5 def __init__(self, size, num_hash_functions): 6 # KÃ­ch thÆ°á»›c cá»§a Bloom filter (sá»‘ lÆ°á»£ng bit) 7 self.size = size 8 # Sá»‘ hÃ m bÄƒm 9 self.num_hash_functions = num_hash_functions 10 # Máº£ng bit Ä‘á»ƒ lÆ°u trá»¯ (Ä‘Æ°á»£c khá»Ÿi táº¡o vá»›i táº¥t cáº£ cÃ¡c bit lÃ  0) 11 self.bit_array = [0] * size 12 13 def _hash(self, item, i): 14 \u0026#34;\u0026#34;\u0026#34;HÃ m bÄƒm Ä‘á»ƒ táº¡o chá»‰ sá»‘ tá»« item, vá»›i i lÃ  chá»‰ sá»‘ cá»§a hÃ m bÄƒm.\u0026#34;\u0026#34;\u0026#34; 15 # DÃ¹ng hÃ m bÄƒm SHA-256 vÃ  Ä‘iá»u chá»‰nh vá»›i chá»‰ sá»‘ i Ä‘á»ƒ táº¡o ra cÃ¡c chá»‰ sá»‘ khÃ¡c nhau 16 return int(hashlib.sha256(f\u0026#34;{item}{i}\u0026#34;.encode(\u0026#39;utf-8\u0026#39;)).hexdigest(), 16) % self.size 17 18 def add(self, item): 19 \u0026#34;\u0026#34;\u0026#34;ThÃªm má»™t item vÃ o Bloom filter.\u0026#34;\u0026#34;\u0026#34; 20 for i in range(self.num_hash_functions): 21 index = self._hash(item, i) 22 self.bit_array[index] = 1 23 24 def check(self, item): 25 \u0026#34;\u0026#34;\u0026#34;Kiá»ƒm tra má»™t item cÃ³ trong Bloom filter khÃ´ng.\u0026#34;\u0026#34;\u0026#34; 26 for i in range(self.num_hash_functions): 27 index = self._hash(item, i) 28 if self.bit_array[index] == 0: 29 return False # Náº¿u báº¥t ká»³ bit nÃ o lÃ  0, pháº§n tá»­ cháº¯c cháº¯n khÃ´ng cÃ³ trong bá»™ lá»c 30 return True # Náº¿u táº¥t cáº£ cÃ¡c bit Ä‘á»u lÃ  1, cÃ³ kháº£ nÄƒng pháº§n tá»­ cÃ³ trong bá»™ lá»c 31 32# Táº¡o má»™t Bloom filter vá»›i kÃ­ch thÆ°á»›c 1000 bit vÃ  3 hÃ m bÄƒm 33bloom_filter = BloomFilter(size=1000, num_hash_functions=3) 34 35# Tá»« Ä‘iá»ƒn máº«u 36dictionary = [\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;spell\u0026#34;, \u0026#34;check\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;bloom\u0026#34;, \u0026#34;filter\u0026#34;] 37 38# ThÃªm táº¥t cáº£ cÃ¡c tá»« vÃ o Bloom filter 39for word in dictionary: 40 bloom_filter.add(word) 41 42# Kiá»ƒm tra chÃ­nh táº£ cá»§a má»™t sá»‘ tá»« 43test_words = [\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;java\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;flutter\u0026#34;] 44 45for word in test_words: 46 if bloom_filter.check(word): 47 print(f\u0026#34;\u0026#39;{word}\u0026#39; cÃ³ thá»ƒ lÃ  má»™t tá»« Ä‘Ãºng.\u0026#34;) 48 else: 49 print(f\u0026#34;\u0026#39;{word}\u0026#39; cháº¯c cháº¯n lÃ  má»™t tá»« sai.\u0026#34;) Káº¿t quáº£:\n1 2\u0026#39;hello\u0026#39; cÃ³ thá»ƒ lÃ  má»™t tá»« Ä‘Ãºng. 3\u0026#39;world\u0026#39; cÃ³ thá»ƒ lÃ  má»™t tá»« Ä‘Ãºng. 4\u0026#39;java\u0026#39; cháº¯c cháº¯n lÃ  má»™t tá»« sai. 5\u0026#39;python\u0026#39; cÃ³ thá»ƒ lÃ  má»™t tá»« Ä‘Ãºng. Recommendation Systems Bloom Filters triá»ƒn khai viá»‡c trÃ¡nh gá»£i Ã½ cÃ¡c sáº£n pháº©m mÃ  ngÆ°á»i dÃ¹ng Ä‘Ã£ tÆ°Æ¡ng tÃ¡c trÆ°á»›c Ä‘Ã³ báº±ng cÃ¡ch sá»­ dá»¥ng Bloom Filters.\n1 2 3import hashlib 4 5class BloomFilter: 6 def __init__(self, size, num_hash_functions): 7 # KÃ­ch thÆ°á»›c Bloom filter (sá»‘ lÆ°á»£ng bit) 8 self.size = size 9 # Sá»‘ hÃ m bÄƒm 10 self.num_hash_functions = num_hash_functions 11 # Máº£ng bit Ä‘á»ƒ lÆ°u trá»¯ (khá»Ÿi táº¡o táº¥t cáº£ cÃ¡c bit lÃ  0) 12 self.bit_array = [0] * size 13 14 def _hash(self, item, i): 15 \u0026#34;\u0026#34;\u0026#34;HÃ m bÄƒm Ä‘á»ƒ táº¡o chá»‰ sá»‘ tá»« item, vá»›i i lÃ  chá»‰ sá»‘ cá»§a hÃ m bÄƒm.\u0026#34;\u0026#34;\u0026#34; 16 return int(hashlib.sha256(f\u0026#34;{item}{i}\u0026#34;.encode(\u0026#39;utf-8\u0026#39;)).hexdigest(), 16) % self.size 17 18 def add(self, item): 19 \u0026#34;\u0026#34;\u0026#34;ThÃªm má»™t item vÃ o Bloom filter.\u0026#34;\u0026#34;\u0026#34; 20 for i in range(self.num_hash_functions): 21 index = self._hash(item, i) 22 self.bit_array[index] = 1 23 24 def check(self, item): 25 \u0026#34;\u0026#34;\u0026#34;Kiá»ƒm tra má»™t item cÃ³ trong Bloom filter khÃ´ng.\u0026#34;\u0026#34;\u0026#34; 26 for i in range(self.num_hash_functions): 27 index = self._hash(item, i) 28 if self.bit_array[index] == 0: 29 return False # Náº¿u báº¥t ká»³ bit nÃ o lÃ  0, pháº§n tá»­ cháº¯c cháº¯n khÃ´ng cÃ³ trong bá»™ lá»c 30 return True # Náº¿u táº¥t cáº£ cÃ¡c bit Ä‘á»u lÃ  1, cÃ³ kháº£ nÄƒng pháº§n tá»­ cÃ³ trong bá»™ lá»c 31 32# Khá»Ÿi táº¡o Bloom filter 33bloom_filter = BloomFilter(size=1000, num_hash_functions=3) 34 35# MÃ´ phá»ng danh sÃ¡ch sáº£n pháº©m ngÆ°á»i dÃ¹ng Ä‘Ã£ tÆ°Æ¡ng tÃ¡c 36user_interactions = { 37 \u0026#34;tung\u0026#34;: [\u0026#34;thá»‹t bÃ²\u0026#34;, \u0026#34;hÃ nh tÃ¢y\u0026#34;, \u0026#34;khoai tÃ¢y\u0026#34;], 38 \u0026#34;tuan\u0026#34;: [\u0026#34;thit heo\u0026#34;, \u0026#34;trá»©ng\u0026#34;], 39 \u0026#34;canh\u0026#34;: [\u0026#34;thá»‹t bÃ²\u0026#34;, \u0026#34;trá»©ng\u0026#34;, \u0026#34;sá»¯a TH\u0026#34;, \u0026#34;kem\u0026#34;] 40} 41 42# ThÃªm cÃ¡c sáº£n pháº©m Ä‘Ã£ tÆ°Æ¡ng tÃ¡c vÃ o Bloom filter 43for user, items in user_interactions.items(): 44 for item in items: 45 bloom_filter.add(f\u0026#34;{user}-{item}\u0026#34;) # Káº¿t há»£p user vÃ  item Ä‘á»ƒ lÆ°u trá»¯ duy nháº¥t 46 47# HÃ m gá»£i Ã½ sáº£n pháº©m 48def recommend_items(user, candidate_items): 49 \u0026#34;\u0026#34;\u0026#34;ÄÆ°a ra gá»£i Ã½ cÃ¡c sáº£n pháº©m chÆ°a tÆ°Æ¡ng tÃ¡c.\u0026#34;\u0026#34;\u0026#34; 50 recommendations = [] 51 for item in candidate_items: 52 if not bloom_filter.check(f\u0026#34;{user}-{item}\u0026#34;): 53 recommendations.append(item) # Chá»‰ thÃªm sáº£n pháº©m náº¿u chÆ°a tÆ°Æ¡ng tÃ¡c 54 return recommendations 55 56# Danh sÃ¡ch cÃ¡c sáº£n pháº©m cÃ³ thá»ƒ gá»£i Ã½ 57candidate_items = [\u0026#34;thá»‹t bÃ²\u0026#34;, \u0026#34;hÃ nh tÃ¢y\u0026#34;, \u0026#34;khoai tÃ¢y\u0026#34;,\u0026#34;trá»©ng\u0026#34;, \u0026#34;sá»¯a TH\u0026#34;, \u0026#34;kem\u0026#34;,\u0026#34;thit heo\u0026#34;] 58 59# Gá»£i Ã½ sáº£n pháº©m cho tung 60user = \u0026#34;tung\u0026#34; 61recommendations = recommend_items(user, candidate_items) 62 63print(f\u0026#34;Recommendations for {user}: {recommendations}\u0026#34;) Káº¿t quáº£:\n1Recommendations for tung: [\u0026#39;trá»©ng\u0026#39;, \u0026#39;sá»¯a TH\u0026#39;, \u0026#39;kem\u0026#39;, \u0026#39;thit heo\u0026#39;] https://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html\nhttps://en.wikipedia.org/wiki/Bloom_filter\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t. Xin cáº£m Æ¡n vÃ  háº¹n gáº·p láº¡i.\n","date":"Nov 24, 2024","img":"https://unsplash.it/1920/1080?image=202","permalink":"/blog/2024-11-24-system-design-top-10-interview-bloom-filters/","series":null,"tags":["System Design"],"title":"Top 10 Thuáº­t ToÃ¡n System Design CÃ¡c Báº¡n NÃªn Biáº¿t VÃ  ThÆ°á»ng ÄÆ°á»£c Há»i Trong Phá»ng Váº¥n - Top 3 Bloom Filters"},{"categories":null,"content":" I. KhÃ¡i niá»‡m II. Distributed Hash Table Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ Ä‘Ã¢u 1. Peer-to-peer (P2P) networks 2. Distributed databases 3. Content delivery networks 4. Event Notification 5. Distributed File Systems III. CÃ¡c yÃªu cáº§u cá»§a má»™t lookup algorithm tá»‘t Autonomy vÃ  decentralization Fault tolerance Scalability Load balance Low maintenance overhead IV. Äiá»ƒm máº¡nh cá»§a Distributed Hash Table Scalability Efficiency Fault tolerance Decentralization Security V. Äiá»ƒm khÃ´ng máº¡nh cá»§a Distributed Hash Table Complexity Performance Security Compatibility Limited functionality VI. Tham kháº£o Äáº¿n thá»i Ä‘iá»ƒm hiá»‡n táº¡i, cuá»‘i nÄƒm 2024, tá»« khoÃ¡ Decentralization váº«n Ä‘ang lÃ  má»™t tá»« khoÃ¡ hot, quang trá»ng. Tá»« viá»‡c bÃ¹ng ná»• , ná»Ÿ rá»™ cá»§a block chain, Ä‘áº¿n viá»‡c cÃ¡c data center cá»§a cÃ¡c táº­p Ä‘oÃ n lá»›n nÆ°á»›c ngoÃ i Ä‘Æ°á»£c Ä‘áº·t á»Ÿ nhiá»u nÆ¡i, trong nÆ°á»›c thÃ¬ viá»‡c sá»‘ hoÃ¡ dá»¯ liá»‡u phÃ¡t triá»ƒn máº¡nh máº½.\nTrong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ cÃ¹ng nhau hiá»ƒu khÃ¡i niá»‡m cÆ¡ báº£n cá»§a Distributed Hash Tables, Æ°u Ä‘iá»ƒm vÃ  nhÆ°á»£c Ä‘iá»ƒm cá»§a nÃ³\nI. KhÃ¡i niá»‡m Distributed Hash Tables - DHT lÃ  má»™t há»‡ thá»‘ng phÃ¢n tÃ¡n phi táº­p trung cung cáº¥p dá»‹ch vá»¥ tra cá»©u, tá»±a tá»±a nhÆ° hash table.\nHash table: lÃ  má»™t báº£ng dá»¯ liá»‡u key - value. Value Ä‘Æ°á»£c lÆ°u trá»¯ vÃ  truy váº¥n thÃ´ng qua key. Key Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nÆ¡i lÆ°u trá»¯ value.\nVÃ­ dá»¥\nkey :a, value:/data/2024/02/01/12/01/01/a.txt key :b, value:/data/2024/02/01/12/01/01/b.txt\nDistributed Hash Tables: dá»¯ liá»‡u cÅ©ng dáº¡ng key - value, nhÆ°ng dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u trá»¯ phÃ¢n tÃ¡n trÃªn nhiá»u node trong má»™t network, khÃ¡c vá»›i Hash table lÃ  chá»‰ lÆ°u trá»¯ trong 1 node.\ntrong Distributed Hash Tables, má»—i node chá»‹u trÃ¡ch nhiá»‡m lÆ°u trá»¯ má»™t pháº§n dá»¯ liá»‡u. Khi ngÆ°á»i dÃ¹ng truy váº¥n hoáº·c lÆ°u dá»¯ liá»‡u lÃªn Distributed Hash Tables, ngÆ°á»i dÃ¹ng sáº½ Ä‘áº©y dá»¯ liá»‡u lÃªn network. YÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng sáº½ Ä‘Æ°á»£c dáº©y lÃªn node tÆ°Æ¡ng á»©ng vá»›i khoÃ¡ cá»§a dá»¯ liá»‡u. Node Ä‘Ã³ sáº½ chá»‹u trÃ¡ch nhiá»‡m lÆ°u trá»¯ vÃ  truy váº¥n dá»¯ liá»‡u cá»§a ngÆ°á»i dÃ¹ng.\nVáº­y nÃªn, má»™t Distributed Hash Tables cáº§n cÃ³ Ã­t nháº¥t 3 thÃ nh pháº§n chÃ­nh\nDistributed application: Chá»‹u trÃ¡ch nhiá»‡m giao tiáº¿p vá»›i ngÆ°á»i dÃ¹ng qua 2 phÆ°Æ¡ng thá»©c lÃ  push ( key, value) Ä‘á»ƒ ngÆ°á»i dÃ¹ng Ä‘áº©y dá»¯ liá»‡u lÃªn network vÃ  get(key) Ä‘á»ƒ ngÆ°á»i dÃ¹ng láº¥y dá»¯ liá»‡u thÃ´ng qua key. App cÃ³ thá»ƒ Ä‘Æ°á»£c lÆ°u trá»¯ phÃ¢n tÃ¡n á»Ÿ trÃªn nhiá»u node.\nDistributed hash table: hay cÃ²n gá»i lÃ  DHash, chá»‹u trÃ¡ch nhiá»‡m láº¥y ra node Ä‘ang lÆ°u dá»¯ liá»‡u cá»§a key. Data cÃ³ thá»ƒ Ä‘Æ°á»£c lÆ°u trá»¯ trÃªn nhiá»u node.\nLookup service: thÃ nh pháº§n nÃ y á» trÃªn node, tráº£ dá»¯ liá»‡u cá»§a key.\nII. Distributed Hash Table Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ Ä‘Ã¢u lÃ  má»™t há»‡ thá»‘ng phÃ¢n tÃ¡n phi táº­p trung, Distributed Hash Table Ä‘Æ°á»£c sá»­ dá»¥ng dÆ°á»›i nhiá»u má»¥c Ä‘Ã­ch khÃ¡c nhau, gom nhÃ³m láº¡i thÃ¬ Ä‘áº¿n thá»i Ä‘iá»ƒm hiá»‡n táº¡i, chÃºng ta cÃ³ 4 nhÃ³m chÃ­nh\n1. Peer-to-peer (P2P) networks á» Ä‘Ã¢y, mÃ¬nh Ä‘á» cáº­p tá»›i BitTorrent cho Ä‘Æ¡n giáº£n hen\nVÃ­ dá»¥ , mÃ¬nh muá»‘n download file tÃªn lÃ  abc.txt\nchÃºng ta sáº½ dÃ¹ng Distributed application nhÆ° BitTorrent\nDistributed hash table:\nkey sáº½ lÃ  hash (\u0026lsquo;abc.txt\u0026rsquo;)\nvalue lÃ  ip mÃ¡y cÃ³ chá»©a file \u0026lsquo;abc.txt\u0026rsquo;\nLookup service:\ngá»i Ä‘áº¿n mÃ¡y cÃ³ ip do Distributed hash table tráº£ vá» vÃ  kÃ¨m theo má»™t sá»‘ lá»‡nh xÃ¡c thá»±c Ä‘á»ƒ láº¥y file abc.txt\n2. Distributed databases NgÃ y nay, vá»›i dá»± phÃ¡t triá»ƒn máº¡nh máº½ cá»§a big data, iot, má»™t mÃ¡y khá»§ng long cÅ©ng cÃ³ thá»ƒ chÆ°a Ä‘á»§ Ä‘Ã¡p á»©ng táº£i vÃ  tÃ i nguyÃªn Ä‘á»ƒ lÆ°u trá»¯ dá»¯ liá»‡u.\n3. Content delivery networks ChÃºng ta tÆ°á»Ÿng tÆ°á»£ng há»‡ s3 cá»§a amazone Ã¡, cháº¯c cháº¯n nÃ³ pháº£i Ä‘Æ°á»£c lÆ°u trÃªn nhiá»u node rá»“i.\n4. Event Notification Giá»‘ng firebase.\n5. Distributed File Systems Quáº£n lÃ½ file trong há»‡ thá»‘ng lÆ°u trá»¯ dá»¯ liá»‡u phÃ¢n tÃ¡n\nIII. CÃ¡c yÃªu cáº§u cá»§a má»™t lookup algorithm tá»‘t Autonomy vÃ  decentralization CÃ¡c node tá»± Ä‘á»™ng phá»‘i há»£p vá»›i nhau táº¡o lÃªn há»‡ thá»‘ng, khÃ´ng cáº§n node trung tÃ¢m\nFault tolerance Há»‡ thá»‘ng Ä‘Ã¡ng tin cáº­y, khi cÃ³ má»™t node trong há»‡ thá»‘ng bá»‹ lá»—i, thÃ¬ há»‡ thá»‘ng váº«n hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng\nScalability Há»‡ thá»‘ng pháº£i hoáº¡t Ä‘á»™ng hiá»‡u quáº£ ngay cáº£ khi cÃ³ hÃ ng ngÃ n, hÃ ng triá»‡u node.\nLoad balance CÃ¡c key cáº§n pháº£i phÃ¢n bá»‘ Ä‘á»u giá»¯a cÃ¡c node, trÃ¡nh cho quÃ¡ táº£i 1 node nÃ o Ä‘Ã³\nLow maintenance overhead Khi cÃ³ 1 node má»›i tham gia vÃ o há»‡ thá»‘ng hoáº·c má»™t node rá»i khá»i há»‡ thá»‘ng, má»™t váº¥n Ä‘á» gáº·p pháº£i lÃ  chÃºng ta sáº½ tá»‘n kha khÃ¡ bandwidth Ä‘á»ƒ gá»­i thÃ´ng bÃ¡o tá»›i cÃ¡c node cÃ²n láº¡i ráº±ng cÃ³ node má»›i hoáº·c cÃ³ node rá»i khá»i há»‡ thá»‘ng. NÃªn, thay vÃ¬ gá»­i thÃ´ng bÃ¡o tá»›i toÃ¡n bá»™ node trong network, chÃºng ta cÃ³ thá»ƒ chá»‰ gá»­i thÃ´ng bÃ¡o tá»›i cÃ¡c neighbors thÃ´i.\nIV. Äiá»ƒm máº¡nh cá»§a Distributed Hash Table Scalability Distributed Hash Table cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng cao vÃ¬ chÃºng cÃ³ thá»ƒ lÆ°u trá»¯ vÃ  truy xuáº¥t lÆ°á»£ng lá»›n dá»¯ liá»‡u mÃ  khÃ´ng cáº§n Ä‘iá»u phá»‘i táº­p trung hoáº·c mÃ¡y chá»§ Ä‘á»ƒ quáº£n lÃ½ há»‡ thá»‘ng. Distributed Hash Table phÃ¹ há»£p vá»›i cÃ¡c há»‡ thá»‘ng phÃ¢n tÃ¡n quy mÃ´ lá»›n.\nEfficiency Distributed Hash Table cung cáº¥p cÃ¡ch thá»©c lÆ°u trá»¯ vÃ  truy váº¥n dá»¯ liá»‡u má»™t cÃ¡ch hiá»‡u quáº£, sá»­ dá»¥ng khoÃ¡ dá»¯ liá»‡u Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vÃ­ trá»‹ cá»§a dá»¯ liá»‡u trong há»‡ thá»‘ng. ChÃ­nh Ä‘iá»u Ä‘Ã³ giÃºp cho Distributed Hash Table cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh vÃ  truy váº¥n dá»¯ liá»‡u nhanh chÃ³ng mÃ  khÃ´ng cáº§n pháº£i tÃ¬m kiáº¿m trÃªn toÃ n bá»™ node cá»§a há»‡ thá»‘ng.\nFault tolerance Distributed Hash Table Ä‘áº£m báº£o toÃ n váº¹n dá»¯ liá»‡u, cÃ³ thá»ƒ quáº£n lÃ½ vÃ  cÃ´ láº­p node lá»—i mÃ  khÃ´ng cáº§n server trung tÃ¢m quáº£n lÃ½. Dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u trá»¯ phÃ¢n tÃ¡n trÃªn cÃ¡c node nÃªn khi cÃ³ node bá»‹ lá»—i, node sáº½ bá»‹ cÃ´ láº­p vÃ  dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c tráº£ vá» cho ngÆ°á»i dÃ¹ng tá»« cÃ¡c node cÃ²n láº¡i trong há»‡ thá»‘ng\nDecentralization Distributed Hash Table lÃ  há»‡ quáº£n lÃ½ phi táº­p trung, khÃ´ng cáº§n central authority (CA) hoáº·c server quáº£n lÃ½ trung tÃ¢m, do Ä‘Ã³ há»‡ thá»‘ng Ã­t bá»‹ khai thÃ¡c lá»— há»•ng báº£o máº­t hÆ¡n khi bá»‹ táº¥n cÃ´ng. Ãt chá»© khÃ´ng pháº£i lÃ  khÃ´ng cÃ³\nSecurity Distributed Hash Table cung cáº¥p cÃ¡c cÆ¡ cháº¿ báº£o máº­t Ä‘á»ƒ lÆ°u trá»¯ vÃ  truy váº¥n dá»¯ liá»‡u, khi dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u phÃ¢n tÃ¡n trÃªn nhiá»u node cá»§a há»‡ thá»‘ng thay vÃ¬ chá»‰ lÆ°u trÃªn má»™t node, Ä‘iá»u nÃ y giÃºp giáº£m thiá»ƒu rá»§i ro khi káº» gian muá»‘n thay Ä‘á»•i dá»¯ liá»‡u vÃ¬ má»¥c Ä‘Ã­ch khÃ´ng tá»‘t.\nV. Äiá»ƒm khÃ´ng máº¡nh cá»§a Distributed Hash Table Complexity Distributed Hash Table khÃ¡ khoai khi triá»ƒn khai vÃ  báº£o trÃ¬, há»‡ thá»‘ng cáº§n má»™t lÆ°á»£ng lá»›n nodes Ä‘á»ƒ cÃ¡c chá»©c nÄƒng hoáº¡t Ä‘á»™ng má»™t cÃ¡ch trÆ¡n tru, hiá»‡u quáº£. Do pháº£i quáº£n lÃ½ quÃ¡ nhiá»u node, ngÆ°á»i quáº£n lÃ½ sáº½ gáº·p thÃ¡ch thá»©c khi cÃ³ sá»± cá»‘ xui xáº»o xáº£y ra, ngoÃ i ra ngÆ°á»i quáº£n lÃ½ cÃ²n pháº£i hiá»ƒu ká»¹ há»‡ thá»‘ng cá»§a mÃ¬nh\nPerformance Trong má»™t sá»‘ trÆ°á»ng há»£p xáº¥u, Distributed Hash Table cÃ³ hiá»‡u nÄƒng lá»Ÿm hÆ¡n so vá»›i cÃ¡c há»‡ distributed systems khÃ¡c, Ä‘áº·c biá»‡t lá»Ÿm khi há»‡ thá»‘ng Ä‘ang gáº§n quÃ¡ táº£i (heavy load) hoáº·c khi há»‡ thá»‘ng quÃ¡ lá»›n, ngÆ°á»i quáº£n trá»‹ config sá»‘ lÆ°á»£ng neighbors hoáº·c sá»‘ hop nhiá»u.\nSecurity Báº£n thÃ¢n Distributed Hash Table cÃ³ trang bá»‹ má»™t vÃ i cÃ¡ch thá»©c báº£o máº­t dá»¯ liá»‡u Ä‘á»ƒ Ä‘áº£m báº£o toÃ n váº¹n dá»¯ liá»‡u cá»§a ngÆ°á»i dÃ¹ng khi lÆ°u trá»¯ vÃ  truy váº¥n dá»¯ liá»‡u, nhÆ°ng vá» máº·t thiáº¿t káº¿ thÃ¬ há»‡ thá»‘ng cÃ³ thá»ƒ tá»“n táº¡i cÃ¡c lá»—i há»•ng vá» báº£o máº­t hoáº·c bá»‹ táº¥n cÃ´ng kiáº¿n trÃºc há»‡ thá»‘ng, vÃ­ dá»¥ nhÆ° táº¥n cÃ´ng tá»« chá»‘i dá»‹ch vá»¥ (DDoS) hoáº·c táº¥n cÃ´ng máº¡o nháº­n - Sybil attack, lÃ  hÃ¬nh thá»©c táº¥n cÃ´ng vÃ o cÃ¡c máº¡ng lÆ°á»›i ngang hÃ ng Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng cÃ¡ch táº¡o nhiá»u thá»±c thá»ƒ áº£o (tÃ i khoáº£n, node hoáº·c mÃ¡y tÃ­nh) Ä‘á»ƒ chiáº¿m quyá»n kiá»ƒm soÃ¡t máº¡ng lÆ°á»›i.\nCompatibility Distributed Hash Table cÃ³ thá»ƒ khÃ´ng tÆ°Æ¡ng thÃ­ch vá»›i toÃ n bá»™ kiá»ƒu dá»¯ liá»‡u cá»§a ngá»«oi dÃ¹ng. Má»™t sá»‘ kiáº¿n trÃºc yÃªu cáº§u má»™t cáº¥u trÃºc hoáº·c Ä‘á»‹nh dáº¡ng Ä‘áº·c biá»‡t Ä‘á»ƒ hoáº¡t Ä‘á»™ng\nLimited functionality Distributed Hash Table Ä‘Æ°á»£c thiáº¿t Ä‘á»ƒ Ä‘á»ƒ lÆ°u trá»¯ vÃ  láº¥y dá»¯ liá»‡u, vÃ  khÃ´ng há»— trá»£ cÃ¡c hÃ m bá»• trá»£\nVI. Tham kháº£o https://www.cs.princeton.edu/courses/archive/fall18/cos418/docs/L6-dhts.pdf\nhttps://www.cs.cmu.edu/%7Edga/15-744/S07/lectures/16-dht.pdf\nhttps://web.mit.edu/6.829/www/currentsemester/materials/chord.pdf\nhttps://www.tutorialspoint.com/distributed-hash-tables-dhts\nhttps://www.geeksforgeeks.org/distributed-hash-tables-with-kademlia/\nhttps://medium.com/the-code-vault/data-structures-distributed-hash-table-febfd01fc0af\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t. Xin cáº£m Æ¡n vÃ  háº¹n gáº·p láº¡i.\n","date":"Nov 23, 2024","img":"https://unsplash.it/1920/1080?image=200","permalink":"/blog/2024-11-23-system-design-top-10-interview-distributed-hash-table/","series":null,"tags":["System Design"],"title":"Top 10 Thuáº­t ToÃ¡n System Design CÃ¡c Báº¡n NÃªn Biáº¿t VÃ  ThÆ°á»ng ÄÆ°á»£c Há»i Trong Phá»ng Váº¥n - Top 2 Distributed Hash Tables"},{"categories":null,"content":" I. LÃ½ thuyáº¿t cÄƒn báº£n Reinforcement Learning CÃ¡c thÃ nh pháº§n cÆ¡ báº£n cá»§a Reinforcement Learning LÃ½ thuyáº¿t toÃ¡n há»c Q-Learning CÃ¡c khÃ¡i niá»‡m trong Q-learning CÃ¡ch Q-learning hoáº¡t Ä‘á»™ng Double Deep Q-Network 1. Váº¥n Ä‘á» cá»§a Q-learning (Overestimation Bias): 2. Cáº£i tiáº¿n cá»§a Double Deep Q-Network (DDQN): 3. Lá»£i Ã­ch cá»§a DDQN so vá»›i DQN/Q-learning: 4. VÃ­ dá»¥ trá»±c quan vá» sá»± khÃ¡c biá»‡t: 5. TÃ³m táº¯t: II. Thá»±c hÃ nh vá»›i chÆ°Æ¡ng trÃ¬nh mario Environment Khá»Ÿi táº¡o mÃ´i trÆ°á»ng Xá»­ lÃ½ dá»¯ liá»‡u Agent Act Remember Learn Play Replay Káº¿t quáº£ III. Tham kháº£o ChÃ o cÃ¡c báº¡n, sau má»™t thá»i gian á»Ÿ áº©n, chÃºng ta láº¡i tiáº¿p tá»¥c vá»›i viá»‡c thá»±c chiáº¿n AI, á»Ÿ bÃ i viáº¿t nÃ y, chÃºng ta sáº½ train mÃ´ hÃ¬nh AI Reinforcement Learning vá»›i tá»±a game Ä‘Ã£ Ä‘i vÃ o bao nhiÃªu tháº¿ há»‡ tráº» thÆ¡, Mario, tuy nhiÃªn, Ä‘á»ƒ báº¯t Ä‘áº§u bÃ i viáº¿t, mÃ¬nh sáº½ note láº¡i má»™t vÃ i Ã½ vá» Reinforcement Learning, Q learning, vÃ  cáº£i tiáº¿n cá»§a Deep Q-Network lÃ  Double Deep Q-Network , trong pháº§n code mÃ¬nh sáº½ sá»­ dá»¥ng Double Deep Q-Network\nI. LÃ½ thuyáº¿t cÄƒn báº£n Reinforcement Learning CÃ¡c thÃ nh pháº§n cÆ¡ báº£n cá»§a Reinforcement Learning Theo lÃ½ thuyáº¿t Reinforcement Learning, chÃºng ta cáº§n cÃ¡c thÃ nh pháº§n sau:\nAgent: lÃ  Ä‘á»‘i tÆ°á»£ng giá»¯ cÃ¡c hÃ nh Ä‘á»™ng (Action), thá»±c hiá»‡n cÃ¡c hÃ nh Ä‘á»™ng\nEnvironment : MÃ´i trÆ°á»ng xung quanh nÆ¡i agent tÆ°Æ¡ng tÃ¡c\nAction : Danh sÃ¡ch cÃ¡c hÃ nh Ä‘á»™ng mÃ  Agent thá»±c hiá»‡n, vÃ­ dá»¥ nháº£y, cháº¡y, Ä‘i lÃªn trÆ°á»›c 1 bÆ°á»›c, Ä‘i lÃ¹i 1 bÆ°á»›c, báº¯n Ä‘áº¡n \u0026hellip; Khi Agent thá»±c hiá»‡n cÃ¡c action, thÃ¬ environment thay Ä‘á»•i\nState : Danh sÃ¡ch cÃ¡c tráº¡ng thÃ¡i cá»§a environment khi cÃ³ action tá»« agent\nOptimal Action-Value function : HÃ m Q*(s,a), chá»¯ Q cÃ³ thá»ƒ hiá»ƒu lÃ  viáº¿t táº¯t cá»§a tá»« quality\nReward : Agent nháº­n reward tá»« Environment khi cÃ³ action\nVÃ­ dá»¥, Agent lÃ  con robot, Ation lÃ  [dáº­m chÃ¢n, vá»— tay ], khi con robot dáº­m chÃ¢n, mÃ´i trÆ°á»ng thay Ä‘á»•i, Ä‘áº¥t lÃºn hÆ¡n má»™t chÃºt, lÃºc nÃ y State lÃ  1 bá»©c tranh cÃ³ 1 con rÃ´ bá»‘t vá»›i chÃ¢n con rÃ´ bá»‘t hÆ¡i hÆ¡i lÃºn má»™t chÃºt xuá»‘ng Ä‘áº¥t, vÃ  environment sáº½ tráº£ vá» 1 giÃ¡ trá»‹ Reward nÃ o Ä‘Ã³ cho Agent sau hÃ nh Ä‘á»™ng dáº­m chÃ¢n cá»§a Agent, dá»… hiá»ƒu pháº£i khÃ´ng cÃ¡c báº¡n.\nReward cá»§a hÃ nh Ä‘á»™ng dáº­m chÃ¢n cÃ³ thá»ƒ sáº½ cÃ³ giÃ¡ trá»‹ khÃ¡c so vá»›i reward cá»§a hÃ nh Ä‘á»™ng vá»— tay.\nVÃ¬ chÃºng ta khÃ´ng biáº¿t khi nÃ o hÃ nh Ä‘á»™ng káº¿t thÃºc, nÃªn rewards sáº½ lÃ  má»™t chuá»—i vÃ´ háº¡n cÃ¡c reward sau thá»i Ä‘iá»ƒm action xáº£y ra, tÃ­nh tá»« thá»i Ä‘iá»ƒm t_0 ban Ä‘áº§u.\nChuá»—i vÃ´ háº¡n khÃ´ng cÃ³ há»™i tá»¥, nÃªn ngÆ°á»i ta cháº¿ (trick) sáº½ thÃªm 1 tham sá»‘ lÃ  discount factor hay discount rate, Ä‘á»ƒ chuá»—i nÃ y há»™i tá»¥.\nLÃ½ thuyáº¿t toÃ¡n há»c Ä‘á»©ng Ä‘áº±ng sau lÃ  Markov decision process vÃ  sá»­ dá»¥ng ná»n táº£n lÃ  phÆ°Æ¡ng trÃ¬nh Bellman, Markov decision process Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t tá»« nÄƒm 1950s, báº¡n cÃ³ thá»ƒ tra google Ä‘á»ƒ tÃ¬m hiá»ƒu thÃªm. Giá» mÃ¬nh hiá»ƒu lÃ  cÃ³ lÃ½ thuyáº¿t toÃ¡n há»c Ä‘áº£m báº£o chuá»—i nÃ y há»™i tá»¥ rá»“i, triá»ƒn thÃ´i.\nLÃ½ thuyáº¿t toÃ¡n há»c á» má»¥c nÃ y mÃ¬nh Ä‘á» cáº­p má»™t chÃºt vá» Markov decision process vÃ  phÆ°Æ¡ng trÃ¬nh Bellman, cÃ¡c báº¡n cÃ³ thá»ƒ bá» qua náº¿u tháº¥y ngÃ¡n, mÃ¬nh note láº¡i Ä‘á»ƒ sau nÃ y khá»i máº¥t cÃ´ng tÃ¬m\nPhÆ°Æ¡ng trÃ¬nh cá»§a Markov Decision Process (MDP) chÃ­nh lÃ  biá»ƒu thá»©c mÃ´ táº£ cÃ¡ch giÃ¡ trá»‹ cá»§a cÃ¡c tráº¡ng thÃ¡i hoáº·c hÃ nh Ä‘á»™ng Ä‘Æ°á»£c cáº­p nháº­t thÃ´ng qua quÃ¡ trÃ¬nh ra quyáº¿t Ä‘á»‹nh. Tuy nhiÃªn, báº£n thÃ¢n MDP khÃ´ng cÃ³ má»™t phÆ°Æ¡ng trÃ¬nh duy nháº¥t cá»¥ thá»ƒ, mÃ  thÆ°á»ng Ä‘Æ°á»£c mÃ´ táº£ qua cÃ¡c thÃ nh pháº§n cÆ¡ báº£n nhÆ° táº­p tráº¡ng thÃ¡i, hÃ nh Ä‘á»™ng, xÃ¡c suáº¥t chuyá»ƒn tráº¡ng thÃ¡i, pháº§n thÆ°á»Ÿng, vÃ  há»‡ sá»‘ chiáº¿t kháº¥u.\nPhÆ°Æ¡ng trÃ¬nh chÃ­nh xÃ¡c nháº¥t liÃªn quan Ä‘áº¿n MDP lÃ  phÆ°Æ¡ng trÃ¬nh Bellman, mÃ  chÃºng ta cÃ³ thá»ƒ viáº¿t theo hai dáº¡ng: dáº¡ng hÃ m giÃ¡ trá»‹ tráº¡ng thÃ¡i vÃ  dáº¡ng hÃ m giÃ¡ trá»‹ hÃ nh Ä‘á»™ng. Hai phÆ°Æ¡ng trÃ¬nh nÃ y thá»ƒ hiá»‡n rÃµ cÃ¡ch tÃ­nh toÃ¡n tá»•ng pháº§n thÆ°á»Ÿng ká»³ vá»ng.\nMarkov Decision Process (MDP) MDP lÃ  má»™t khung toÃ¡n há»c dÃ¹ng Ä‘á»ƒ mÃ´ táº£ cÃ¡c bÃ i toÃ¡n ra quyáº¿t Ä‘á»‹nh trong mÃ´i trÆ°á»ng khÃ´ng cháº¯c cháº¯n. Má»™t MDP bao gá»“m cÃ¡c thÃ nh pháº§n sau:\nS (State space): Táº­p há»£p cÃ¡c tráº¡ng thÃ¡i cÃ³ thá»ƒ xáº£y ra trong mÃ´i trÆ°á»ng. A (Action space): Táº­p há»£p cÃ¡c hÃ nh Ä‘á»™ng mÃ  ngÆ°á»i ra quyáº¿t Ä‘á»‹nh (agent) cÃ³ thá»ƒ thá»±c hiá»‡n á»Ÿ má»—i tráº¡ng thÃ¡i. P (Transition probability): XÃ¡c suáº¥t chuyá»ƒn tráº¡ng thÃ¡i ( P(s\u0026rsquo;|s, a) ), biá»ƒu thá»‹ xÃ¡c suáº¥t tráº¡ng thÃ¡i káº¿ tiáº¿p ( s\u0026rsquo; ) xáº£y ra khi thá»±c hiá»‡n hÃ nh Ä‘á»™ng ( a ) táº¡i tráº¡ng thÃ¡i ( s ). R (Reward function): HÃ m thÆ°á»Ÿng ( R(s, a) ), lÃ  pháº§n thÆ°á»Ÿng tá»©c thÃ¬ nháº­n Ä‘Æ°á»£c khi thá»±c hiá»‡n hÃ nh Ä‘á»™ng ( a ) táº¡i tráº¡ng thÃ¡i ( s ). $(\\gamma) (Discount factor)$: Há»‡ sá»‘ chiáº¿t kháº¥u $( \\gamma \\in [0, 1] )$, xÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ Æ°u tiÃªn cho pháº§n thÆ°á»Ÿng tá»©c thÃ¬ so vá»›i pháº§n thÆ°á»Ÿng trong tÆ°Æ¡ng lai. Khi $( \\gamma )$ gáº§n báº±ng 1, giÃ¡ trá»‹ cÃ¡c pháº§n thÆ°á»Ÿng trong tÆ°Æ¡ng lai cÃ ng Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ cao. Má»¥c tiÃªu cá»§a MDP lÃ  tÃ¬m ra chÃ­nh sÃ¡ch tá»‘i Æ°u - optimal policy $( \\pi^* )$, tá»©c lÃ  má»™t chuá»—i cÃ¡c hÃ nh Ä‘á»™ng giÃºp tá»‘i Ä‘a hÃ³a tá»•ng pháº§n thÆ°á»Ÿng ká»³ vá»ng trong dÃ i háº¡n.\nPhÆ°Æ¡ng trÃ¬nh Bellman PhÆ°Æ¡ng trÃ¬nh Bellman mÃ´ táº£ má»‘i quan há»‡ Ä‘á»‡ quy giá»¯a giÃ¡ trá»‹ cá»§a má»™t tráº¡ng thÃ¡i hoáº·c má»™t hÃ nh Ä‘á»™ng vá»›i cÃ¡c tráº¡ng thÃ¡i káº¿ tiáº¿p hoáº·c hÃ nh Ä‘á»™ng tiáº¿p theo. NÃ³ thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tÃ­nh toÃ¡n giÃ¡ trá»‹ ká»³ vá»ng cá»§a cÃ¡c tráº¡ng thÃ¡i hoáº·c hÃ nh Ä‘á»™ng, giÃºp Ä‘Ã¡nh giÃ¡ vÃ  tÃ¬m ra chÃ­nh sÃ¡ch tá»‘i Æ°u.\na. PhÆ°Æ¡ng trÃ¬nh Bellman cho hÃ m giÃ¡ trá»‹ tráº¡ng thÃ¡i ( V(s) )\nHÃ m giÃ¡ trá»‹ tráº¡ng thÃ¡i ( V(s) ) cho biáº¿t tá»•ng pháº§n thÆ°á»Ÿng ká»³ vá»ng khi báº¯t Ä‘áº§u tá»« tráº¡ng thÃ¡i ( s ) vÃ  theo chÃ­nh sÃ¡ch tá»‘i Æ°u. PhÆ°Æ¡ng trÃ¬nh Bellman cho hÃ m giÃ¡ trá»‹ tráº¡ng thÃ¡i lÃ :\n$$ [ V(s) = \\max_{a} \\left[ R(s, a) + \\gamma \\sum_{s\u0026rsquo;} P(s\u0026rsquo;|s, a)V(s\u0026rsquo;) \\right] ] $$\ná» Ä‘Ã¢y:\n( V(s) ) lÃ  giÃ¡ trá»‹ cá»§a tráº¡ng thÃ¡i ( s ). ( R(s, a) ) lÃ  pháº§n thÆ°á»Ÿng nháº­n Ä‘Æ°á»£c khi thá»±c hiá»‡n hÃ nh Ä‘á»™ng ( a ) táº¡i tráº¡ng thÃ¡i ( s ). ( P(s\u0026rsquo;|s, a) ) lÃ  xÃ¡c suáº¥t chuyá»ƒn tá»« tráº¡ng thÃ¡i ( s ) sang tráº¡ng thÃ¡i ( s\u0026rsquo; ) khi thá»±c hiá»‡n hÃ nh Ä‘á»™ng ( a ). $( \\gamma )$ lÃ  há»‡ sá»‘ chiáº¿t kháº¥u, vÃ  $( \\sum_{s\u0026rsquo;} P(s\u0026rsquo;|s, a)V(s\u0026rsquo;) )$ lÃ  giÃ¡ trá»‹ ká»³ vá»ng cá»§a cÃ¡c tráº¡ng thÃ¡i tiáº¿p theo. b. PhÆ°Æ¡ng trÃ¬nh Bellman cho hÃ m giÃ¡ trá»‹ hÃ nh Ä‘á»™ng ( Q(s, a) )\nHÃ m giÃ¡ trá»‹ hÃ nh Ä‘á»™ng ( Q(s, a) ) biá»ƒu diá»…n tá»•ng pháº§n thÆ°á»Ÿng ká»³ vá»ng khi báº¯t Ä‘áº§u tá»« tráº¡ng thÃ¡i ( s ), thá»±c hiá»‡n hÃ nh Ä‘á»™ng ( a ), vÃ  sau Ä‘Ã³ tiáº¿p tá»¥c theo chÃ­nh sÃ¡ch tá»‘i Æ°u. PhÆ°Æ¡ng trÃ¬nh Bellman cho hÃ m giÃ¡ trá»‹ hÃ nh Ä‘á»™ng lÃ :\n$$ [ Q(s, a) = R(s, a) + \\gamma \\sum_{s\u0026rsquo;} P(s\u0026rsquo;|s, a) \\max_{a\u0026rsquo;} Q(s\u0026rsquo;, a\u0026rsquo;) ] $$\ná» Ä‘Ã¢y:\n( Q(s, a) ) lÃ  giÃ¡ trá»‹ cá»§a hÃ nh Ä‘á»™ng ( a ) á»Ÿ tráº¡ng thÃ¡i ( s ). ( \\max_{a\u0026rsquo;} Q(s\u0026rsquo;, a\u0026rsquo;) ) lÃ  giÃ¡ trá»‹ tá»‘i Æ°u cá»§a hÃ nh Ä‘á»™ng tiáº¿p theo á»Ÿ tráº¡ng thÃ¡i káº¿ tiáº¿p ( s\u0026rsquo; ). Q-Learning Q-learning lÃ  má»™t thuáº­t toÃ¡n trong nhÃ³m há»c tÄƒng cÆ°á»ng (reinforcement learning) , thuá»™c nhÃ³m model-free, value-based, off-policy. Thuáº­t toÃ¡n sáº½ tÃ¬m ra chuá»—i hÃ nh Ä‘á»™ng tá»‘t nháº¥t dá»±a trÃªn tráº¡ng thÃ¡i hiá»‡n táº¡i cá»§a agent. â€œQâ€ Ä‘áº¡i diá»‡n cho cháº¥t lÆ°á»£ng. Cháº¥t lÆ°á»£ng biá»ƒu thá»‹ giÃ¡ trá»‹ cá»§a hÃ nh Ä‘á»™ng trong viá»‡c tá»‘i Ä‘a hÃ³a (cá»±c Ä‘áº¡i hÃ³a) pháº§n thÆ°á»Ÿng á»Ÿ tÆ°Æ¡ng lai.\nCÃ³ má»™t sá»‘ key word cáº§n lÃ m rÃµ má»™t chÃºt.\nChÃºng ta cÃ³ hai nhÃ³m thuáº­t toÃ¡n lÃ  model-base vÃ  model-free\nmodel-base dÃ¹ng 2 hÃ m lÃ  transition vÃ  reward Ä‘á»ƒ Æ°á»›c tÃ­nh Ä‘Æ°á»ng Ä‘i tá»‘i Æ°u, chÃºng ta pháº£i váº¯t Ã³c suy nghÄ© 2 hÃ m nÃ y, tÆ°á»Ÿng tÆ°á»£ng báº¡n chÆ¡i cá» vÃ  dá»± Ä‘oÃ¡n trÆ°á»›c cÃ¡c nÆ°á»›c Ä‘i cá»§a Ä‘á»‘i thá»§, biáº¿t Ä‘Æ°á»£c Ä‘á»‘i thá»§ sáº½ Ä‘i nhÆ° tháº¿ nÃ o, nÃªn ta cÃ³ thá»ƒ chá»n nhá»¯ng nÆ°á»›c Ä‘i sao cho káº¿t quáº£ cuá»‘i cÃ¹ng ta sáº½ tháº¯ng.\nmodel-free há»c tá»« chuá»—i hÃ nh Ä‘á»™ng, rÃºt ra kinh nghiá»‡m, vÃ  váº¥p ngÃ£ Ä‘Ã¢u , Ä‘á»©ng dáº­y á»Ÿ Ä‘Ã³, khÃ´ng cáº§n Ä‘á»‹nh nghÄ©a transition function vÃ  reward function. TÆ°á»Ÿng tÆ°á»£ng báº¡n tá»± mÃ¬nh há»c cÃ¡ch Ä‘i xe Ä‘áº¡p, báº¡n ngÃ£, rÃºt kinh nghiá»‡m tá»« lá»—i láº§m vÃ  dáº§n dáº§n Ä‘i Ä‘Æ°á»£c mÃ  khÃ´ng cáº§n báº£n hÆ°á»›ng dáº«n chi tiáº¿t nÃ o, cá»© Ã´m xe Ä‘áº¡p mÃ  táº­p dáº§n.\nTiáº¿p tá»›i, chÃºng ta cÃ³ 2 loáº¡i phÆ°Æ¡ng thá»©c lÃ  value-based vÃ  policy-based\nPhÆ°Æ¡ng phÃ¡p value-based , huáº¥n luyá»‡n hÃ m giÃ¡ trá»‹, huáº¥n luyá»‡n lÃ m sao Ä‘á»ƒ hÃ m giÃ¡ trá»‹ cÃ³ thá»ƒ tÃ¬m ra tráº¡ng thÃ¡i mÃ  tráº¡ng thÃ¡i Ä‘Ã³ lÃ m cho hÃ m giÃ¡ trá»‹ Ä‘áº¡t giÃ¡ trá»‹ lá»›n nháº¥t, Ä‘áº¡t giÃ¡ trá»‹ cá»±c Ä‘áº¡i, tá»« Ä‘Ã³ quyáº¿t Ä‘á»‹nh sá»­ dá»¥ng hÃ nh Ä‘á»™ng Ä‘Ã³. NÃ³i cÃ¡ch khÃ¡c, nÃ³ giÃºp agent hiá»ƒu xem á»Ÿ tráº¡ng thÃ¡i nÃ o thÃ¬ hÃ nh Ä‘á»™ng nÃ o sáº½ mang láº¡i pháº§n thÆ°á»Ÿng cao nháº¥t. VÃ­ dá»¥, báº¡n chá»n mÃ´n há»c cÃ³ giÃ¡ trá»‹ nháº¥t Ä‘á»ƒ há»c trÆ°á»›c nháº±m Ä‘áº¡t Ä‘iá»ƒm sá»‘ cao nháº¥t.\nPhÆ°Æ¡ng phÃ¡p policy-based Ä‘Æ°a ra cÃ¡c policy quy Ä‘á»‹nh á»©ng vá»›i tá»«ng state, ta sáº½ Ä‘Æ°a ra cÃ¡c action gÃ¬, nÃ³ há»c cÃ¡ch Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh tá»‘t nháº¥t trong tá»«ng tráº¡ng thÃ¡i. Giá»‘ng nhÆ° khi báº¡n khÃ´ng chá»‰ há»c lÃ½ thuyáº¿t mÃ  thá»±c sá»± thá»±c hÃ nh Ä‘á»ƒ biáº¿t cÃ¡ch hÃ nh Ä‘á»™ng tá»‘t nháº¥t trong tá»«ng tÃ¬nh huá»‘ng cá»¥ thá»ƒ.\nCuá»‘i cÃ¹ng, cÃ³ 2 cÃ¡i chÃ­nh sÃ¡ch Ä‘á»‘i láº­p lÃ  off-policy vÃ  on-policy\noff-policy thuáº­t toÃ¡n Ä‘Ã¡nh giÃ¡ vÃ  cáº­p nháº­t láº¡i policy má»›i, policy má»›i khÃ¡c vá»›i policy Ä‘ang thá»±c hiá»‡n action. NghÄ©a lÃ  nÃ³ khÃ´ng cáº§n theo Ä‘Ãºng chÃ­nh sÃ¡ch hiá»‡n hÃ nh mÃ  cÃ³ thá»ƒ há»c vÃ  cáº£i thiá»‡n chÃ­nh sÃ¡ch má»›i dá»±a trÃªn dá»¯ liá»‡u vÃ  kinh nghiá»‡m thu tháº­p Ä‘Æ°á»£c, kiá»ƒu nhÆ° lÃ  vá»«a chÆ¡i game vá»«a nghÄ© ra chiáº¿n lÆ°á»£c má»›i thay vÃ¬ bÃ¡m sÃ¡t chiáº¿n lÆ°á»£c cÅ©.\non-policy nÃ³ khÃ´ng chá»‰ dÃ¹ng chÃ­nh sÃ¡ch hiá»‡n táº¡i mÃ  cÃ²n Ä‘iá»u chá»‰nh vÃ  cáº£i thiá»‡n chÃ­nh sÃ¡ch Ä‘Ã³ liÃªn tá»¥c dá»±a trÃªn nhá»¯ng gÃ¬ Ä‘Ã£ há»c Ä‘Æ°á»£c tá»« má»—i hÃ nh Ä‘á»™ng. NhÆ° cÃ¡ch báº¡n tiáº¿p tá»¥c hoÃ n thiá»‡n chiáº¿n lÆ°á»£c chÆ¡i game cá»§a mÃ¬nh má»—i láº§n chÆ¡i dá»±a trÃªn nhá»¯ng gÃ¬ Ä‘Ã£ tráº£i qua.\nCÃ¡c khÃ¡i niá»‡m trong Q-learning Káº¿ thá»«a cÃ¡c key trong Reinforcement Learning, chÃºng ta cÃ³\nStates(s) : vá»‹ trÃ­ hiá»‡n táº¡i cá»§a agent trong environment\nAction(a) : HÃ nh Ä‘á»™ng cá»§a agent trong má»™t state cá»¥ thá»ƒ\nRewards : GiÃ¡ trá»‹ pháº§n thÆ°á»Ÿng hoáº·c giÃ¡ trá»‹ pháº¡t khi má»™t Action xáº£y ra\nEpisodes: Káº¿t thÃºc state, khi Agent khÃ´ng thá»ƒ thá»±c hiá»‡n má»™t action má»›i. Episodes xáº£y ra khi agent phÃ¡ Ä‘áº£o hoáº·c agent bá»‹ die\n$Q(S_t+1, a)$ : GiÃ¡ trá»‹ ká»³ vá»ng Ä‘áº¡t Ä‘Æ°á»£c Q value á»Ÿ state t+1 vÃ  hÃ nh Ä‘á»™ng a\nCÃ¡ch Q-learning hoáº¡t Ä‘á»™ng Q-Table Q-Table vá» cÆ¡ báº£n lÃ  má»™t báº£ng tra cá»©u, trong Ä‘Ã³ má»—i hÃ ng Ä‘áº¡i diá»‡n cho má»™t tráº¡ng thÃ¡i cÃ³ thá»ƒ cÃ³, vÃ  má»—i cá»™t Ä‘áº¡i diá»‡n cho má»™t hÃ nh Ä‘á»™ng cÃ³ thá»ƒ thá»±c hiá»‡n. Báº£ng nÃ y lÆ°u trá»¯ cÃ¡c giÃ¡ trá»‹ Q-values (pháº§n thÆ°á»Ÿng ká»³ vá»ng) cho má»—i cáº·p tráº¡ng thÃ¡i-hÃ nh Ä‘á»™ng. Theo thá»i gian, Agent sáº½ cáº­p nháº­t báº£ng nÃ y Ä‘á»ƒ há»c cÃ¡ch lá»±a chá»n hÃ nh Ä‘á»™ng tá»‘t nháº¥t trong má»—i tráº¡ng thÃ¡i.\nQ-value Q-value Ä‘áº¡i diá»‡n cho pháº§n thÆ°á»Ÿng tÆ°Æ¡ng lai, ká»³ vá»ng mÃ  Agent sáº½ nháº­n Ä‘Æ°á»£c khi thá»±c hiá»‡n má»™t hÃ nh Ä‘á»™ng nháº¥t Ä‘á»‹nh tá»« tráº¡ng thÃ¡i hiá»‡n táº¡i, vÃ  sau Ä‘Ã³ thá»±c hiá»‡n theo policy tá»‘t nháº¥t (tá»‘i Ä‘a hÃ³a pháº§n thÆ°á»Ÿng).\nQ-learning Function LÃ  má»™t model-free reinforcement learning, sá»­ dá»¥ng phÆ°Æ¡ng trÃ¬nh Bellman, cáº­p nháº­t báº£ng Q thÃ´ng qua viá»‡c há»c tá»« sá»± tÆ°Æ¡ng tÃ¡c vá»›i mÃ´i trÆ°á»ng. Khi Agent thá»±c hiá»‡n má»™t hÃ nh Ä‘á»™ng, nÃ³ sáº½ quan sÃ¡t pháº§n thÆ°á»Ÿng vÃ  tráº¡ng thÃ¡i má»›i mÃ  nÃ³ chuyá»ƒn Ä‘áº¿n. Thuáº­t toÃ¡n sau Ä‘Ã³ sáº½ cáº­p nháº­t giÃ¡ trá»‹ Q cho cáº·p tráº¡ng thÃ¡i-hÃ nh Ä‘á»™ng Ä‘Ã³ theo quy táº¯c cáº­p nháº­t sau:\n$$ [ Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left( r + \\gamma \\max_a\u0026rsquo; Q(s\u0026rsquo;, a\u0026rsquo;) - Q(s, a) \\right) ] $$\nTrong Ä‘Ã³:\n$( Q(s, a) )$ lÃ  giÃ¡ trá»‹ Q cho tráº¡ng thÃ¡i ( s ) vÃ  hÃ nh Ä‘á»™ng ( a ) $( \\alpha )$ lÃ  tá»‘c Ä‘á»™ há»c (quyáº¿t Ä‘á»‹nh má»©c Ä‘á»™ mÃ  thÃ´ng tin má»›i ghi Ä‘Ã¨ thÃ´ng tin cÅ©) $( r )$ lÃ  pháº§n thÆ°á»Ÿng nháº­n Ä‘Æ°á»£c sau khi thá»±c hiá»‡n hÃ nh Ä‘á»™ng ( a ) á»Ÿ tráº¡ng thÃ¡i ( s ) $( \\gamma )$ lÃ  há»‡ sá»‘ chiáº¿t kháº¥u (xÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ pháº§n thÆ°á»Ÿng tÆ°Æ¡ng lai Ä‘Æ°á»£c tÃ­nh Ä‘áº¿n) $( \\max_a\u0026rsquo; Q(s\u0026rsquo;, a\u0026rsquo;) )$ lÃ  pháº§n thÆ°á»Ÿng ká»³ vá»ng lá»›n nháº¥t cho tráº¡ng thÃ¡i tiáº¿p theo ( s\u0026rsquo; ) sau hÃ nh Ä‘á»™ng ( a\u0026rsquo; ) Theo thá»i gian, Agent sá»­ dá»¥ng Q-learning sáº½ dáº§n dáº§n hoÃ n thiá»‡n báº£ng Q cá»§a mÃ¬nh vÃ  há»c Ä‘Æ°á»£c cÃ¡ch thá»±c hiá»‡n cÃ¡c hÃ nh Ä‘á»™ng tá»‘i Æ°u cho má»—i tráº¡ng thÃ¡i Ä‘á»ƒ tá»‘i Ä‘a hÃ³a pháº§n thÆ°á»Ÿng ká»³ vá»ng.\nQ-learning algorithm Init Q_table -\u0026gt; Choose action -\u0026gt; Do action -\u0026gt; Mesure reward -\u0026gt; Update Q Table -\u0026gt; Choose action \u0026hellip;\nInit Q_table XÃ¢y dá»±ng báº£ng bao gá»“m hÃ ng lÃ  cÃ¡c state, cá»™t lÃ  cÃ¡c action , Ä‘áº§u tiÃªn cÃ³ thá»ƒ khá»Ÿi táº¡o giÃ¡ trá»‹ cá»§a báº£ng nÃ y lÃ  0.\nChoose action á» láº§n cháº¡y Ä‘áº§u tiÃªn, chÃºng ta cÃ³ thá»ƒ random action, á»Ÿ láº§n cháº¡y sau, chÃºng ta láº¥y action á»Ÿ báº£ng Q Table á»Ÿ trÃªn\nDo action Thá»±c hiá»‡n chá»n hÃ nh Ä‘á»™ng vÃ  thá»±c hiá»‡n hÃ nh Ä‘á»™ng Ä‘áº¿n khi quÃ¡ trÃ¬nh train dá»«ng láº¡i.\nVá»›i má»—i láº§n Choose action vÃ  Do action, chÃºng ta sáº½:\ná» láº§n cháº¡y Ä‘áº§u tiÃªn, chÃºng ta láº¥y ngáº«u nhiÃªn 1 hÃ nh Ä‘á»™ng, sau Ä‘Ã³ Agent sáº½ thá»±c hiá»‡n hÃ nh Ä‘á»™ng vÃ  nháº­n reward, update Q Table sá»­ dá»¥ng Q-learning Function Ä‘Ã£ nÃªu phÃ­a trÃªn. á» cÃ¡c láº§n cháº¡y sau, chÃºng ta láº¥y ra hÃ nh Ä‘á»™ng tá»‘t nháº¥t Ä‘á»ƒ Agent thá»±c hiá»‡n hÃ nh Ä‘á»™ng vÃ  chÃºng ta láº¡i update Q Table tiáº¿p.\nVÃ¬ lÃ½ do lÃ  Agent cáº§n tá»‘i Ä‘a hÃ³a pháº§n thÆ°á»Ÿng Ä‘áº¡t Ä‘Æ°á»£c, nÃªn á»Ÿ Ä‘Ã¢y xuáº¥t hiá»‡n 2 khÃ¡i niá»‡m lÃ  exploration (khÃ¡m phÃ¡) vÃ  exploitation (khai thÃ¡c), vÃ  cáº§n cÃ¢n báº±ng cáº£ 2\nExploration (KhÃ¡m phÃ¡):\nKhÃ¡m phÃ¡ lÃ  khi Agent thá»­ nhá»¯ng hÃ nh Ä‘á»™ng má»›i hoáº·c chÆ°a tá»«ng thá»­ trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ tÃ¬m hiá»ƒu thÃªm vá» mÃ´i trÆ°á»ng. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  Agent cÃ³ thá»ƒ sáº½ khÃ´ng chá»n hÃ nh Ä‘á»™ng cÃ³ pháº§n thÆ°á»Ÿng cao nháº¥t dá»±a trÃªn thÃ´ng tin hiá»‡n táº¡i mÃ  thay vÃ o Ä‘Ã³ thá»­ cÃ¡c hÃ nh Ä‘á»™ng chÆ°a rÃµ káº¿t quáº£. LÃ½ do: Náº¿u Agent chá»‰ khai thÃ¡c cÃ¡c hÃ nh Ä‘á»™ng cÃ³ pháº§n thÆ°á»Ÿng cao hiá»‡n táº¡i mÃ  khÃ´ng khÃ¡m phÃ¡ cÃ¡c hÃ nh Ä‘á»™ng khÃ¡c, nÃ³ cÃ³ thá»ƒ bá» lá»¡ nhá»¯ng hÃ nh Ä‘á»™ng tá»‘t hÆ¡n á»Ÿ tÆ°Æ¡ng lai. MÃ´i trÆ°á»ng cÃ³ thá»ƒ phá»©c táº¡p vÃ  thay Ä‘á»•i, nÃªn Agent cáº§n tiáº¿p tá»¥c tÃ¬m hiá»ƒu Ä‘á»ƒ cÃ³ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§. Exploitation (Khai thÃ¡c):\nKhai thÃ¡c lÃ  khi Agent chá»n hÃ nh Ä‘á»™ng dá»±a trÃªn thÃ´ng tin mÃ  nÃ³ Ä‘Ã£ há»c Ä‘Æ°á»£c Ä‘á»ƒ tá»‘i Æ°u hÃ³a pháº§n thÆ°á»Ÿng. Trong trÆ°á»ng há»£p nÃ y, Agent chá»n hÃ nh Ä‘á»™ng mÃ  nÃ³ tin lÃ  cÃ³ pháº§n thÆ°á»Ÿng cao nháº¥t dá»±a trÃªn nhá»¯ng gÃ¬ nÃ³ Ä‘Ã£ tráº£i nghiá»‡m. LÃ½ do: Sau khi Ä‘Ã£ tÃ­ch lÅ©y Ä‘á»§ thÃ´ng tin vá» mÃ´i trÆ°á»ng, Agent cáº§n táº­p trung khai thÃ¡c cÃ¡c hÃ nh Ä‘á»™ng Ä‘Ã£ Ä‘Æ°á»£c biáº¿t lÃ  cÃ³ lá»£i Ä‘á»ƒ tá»‘i Ä‘a hÃ³a pháº§n thÆ°á»Ÿng trong dÃ i háº¡n. Táº¡i sao cáº§n cÃ³ cáº£ hai?\nCÃ¢n báº±ng: Náº¿u chá»‰ khai thÃ¡c mÃ  khÃ´ng khÃ¡m phÃ¡, Agent cÃ³ thá»ƒ rÆ¡i vÃ o cÃ¡i gá»i lÃ  local optimum (cá»±c Ä‘áº¡i cá»¥c bá»™) mÃ  bá» lá»¡ cÆ¡ há»™i Ä‘áº¡t Ä‘Æ°á»£c global optimum (cá»±c Ä‘áº¡i toÃ n cá»¥c), tá»©c lÃ  giáº£i phÃ¡p tá»‘t nháº¥t. Máº·t khÃ¡c, náº¿u chá»‰ khÃ¡m phÃ¡ mÃ  khÃ´ng khai thÃ¡c, Agent sáº½ khÃ´ng thá»ƒ táº­n dá»¥ng nhá»¯ng gÃ¬ nÃ³ Ä‘Ã£ há»c Ä‘Æ°á»£c, dáº«n Ä‘áº¿n khÃ´ng tá»‘i Æ°u hÃ³a pháº§n thÆ°á»Ÿng. VÃ­ dá»¥:\nExploration: Báº¡n Ä‘i Äƒn á»Ÿ má»™t nhÃ  hÃ ng má»›i mÃ  báº¡n chÆ°a bao giá» thá»­, hy vá»ng tÃ¬m Ä‘Æ°á»£c mÃ³n Äƒn ngon hÆ¡n. Exploitation: Báº¡n quay láº¡i má»™t nhÃ  hÃ ng quen thuá»™c mÃ  báº¡n biáº¿t cháº¯c mÃ³n Äƒn á»Ÿ Ä‘Ã³ ráº¥t ngon. Trong thá»±c táº¿, cÃ¡c thuáº­t toÃ¡n nhÆ° epsilon-greedy sá»­ dá»¥ng má»™t chiáº¿n lÆ°á»£c káº¿t há»£p cáº£ khÃ¡m phÃ¡ vÃ  khai thÃ¡c, cho phÃ©p Agent thá»±c hiá»‡n pháº§n lá»›n cÃ¡c hÃ nh Ä‘á»™ng khai thÃ¡c nhÆ°ng Ä‘Ã´i khi váº«n khÃ¡m phÃ¡ nhá»¯ng hÃ nh Ä‘á»™ng má»›i vá»›i má»™t xÃ¡c suáº¥t nhá» (epsilon).\nTrong Q-learning, á»Ÿ giai Ä‘oáº¡n Ä‘áº§u, giÃ¡ trá»‹ epsilon thÆ°á»ng lá»›n Ä‘á»ƒ xÃ¡c xuáº¥t Exploration xuáº¥t hiá»‡n nhiá»u, qua má»—i láº§n láº·p, Agent cÃ ng ngÃ y cÃ ng tá»± tin vá»›i cÃ¡c giÃ¡ trá»‹ há»c Ä‘Æ°á»£c Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t á»Ÿ Q table, nÃªn giÃ¡ trá»‹ Exploration á»Ÿ cÃ¡c láº§n láº·p sau sáº½ giáº£m bá»›t, nhá» Ä‘áº§n, tá»« Ä‘Ã³ xÃ¡c xuáº¥t chá»n action tá»« Q table sáº½ lá»›n hÆ¡n.\nMeasuring the Rewards Sau khi thá»±c hiá»‡n hÃ nh Ä‘á»™ng, chÃºng ta sáº½ thu Ä‘Æ°á»£c káº¿t quáº£ vÃ  pháº§n thÆ°á»Ÿng\nCÃ³ nhiá»u cÃ¡ch cho thÆ°á»Ÿng, tÃ¹y , má»™t dáº¡ng Ä‘Æ¡n giáº£n nháº¥t Ä‘Ã³ lÃ \nNáº¿u vá» Ä‘Ã­ch , +1 Ä‘iá»ƒm thÆ°á»Ÿng\nNáº¿u tháº¥t báº¡i, chÆ°a vá» Ä‘Ã­ch , 0 Ä‘iá»ƒm\nUpdate Q Table Trong Q-learning, khi má»™t Agent cáº­p nháº­t giÃ¡ trá»‹ Q cho má»™t cáº·p tráº¡ng thÃ¡i-hÃ nh Ä‘á»™ng, quÃ¡ trÃ¬nh nÃ y dá»±a trÃªn sá»± káº¿t há»£p giá»¯a giÃ¡ trá»‹ Q cÅ© (former Q-value) vÃ  giÃ¡ trá»‹ Q má»›i Æ°á»›c tÃ­nh (new Q-value estimation). ÄÃ¢y lÃ  hai khÃ­a cáº¡nh quan trá»ng cá»§a cÃ´ng thá»©c cáº­p nháº­t Q-value trong Q-learning:\nFormer Q-value (GiÃ¡ trá»‹ Q cÅ©):\nÄÃ¢y lÃ  giÃ¡ trá»‹ Q hiá»‡n táº¡i cho má»™t cáº·p tráº¡ng thÃ¡i-hÃ nh Ä‘á»™ng cá»¥ thá»ƒ mÃ  Agent Ä‘Ã£ ghi nháº­n trÆ°á»›c Ä‘Ã³. NÃ³ thá»ƒ hiá»‡n pháº§n thÆ°á»Ÿng ká»³ vá»ng mÃ  Agent Ä‘Ã£ tÃ­nh toÃ¡n tá»« cÃ¡c láº§n tÆ°Æ¡ng tÃ¡c trÆ°á»›c Ä‘Ã³ vá»›i mÃ´i trÆ°á»ng.\nTrong cÃ´ng thá»©c cáº­p nháº­t Q-learning:\n$$ [ Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left( r + \\gamma \\max_a\u0026rsquo; Q(s\u0026rsquo;, a\u0026rsquo;) - Q(s, a) \\right) ] $$\nPháº§n $( Q(s, a) )$ bÃªn pháº£i cá»§a dáº¥u mÅ©i tÃªn lÃ  giÃ¡ trá»‹ Q cÅ©.\nNew Q-value estimation (GiÃ¡ trá»‹ Q má»›i Æ°á»›c tÃ­nh): ÄÃ¢y lÃ  giÃ¡ trá»‹ Q Ä‘Æ°á»£c cáº­p nháº­t dá»±a trÃªn pháº§n thÆ°á»Ÿng vá»«a nháº­n Ä‘Æ°á»£c vÃ  dá»± Ä‘oÃ¡n pháº§n thÆ°á»Ÿng trong tÆ°Æ¡ng lai (dá»±a trÃªn tráº¡ng thÃ¡i tiáº¿p theo vÃ  hÃ nh Ä‘á»™ng tá»‘t nháº¥t cÃ³ thá»ƒ thá»±c hiá»‡n).\nPháº§n ( r + \\gamma \\max_a\u0026rsquo; Q(s\u0026rsquo;, a\u0026rsquo;) ) trong cÃ´ng thá»©c lÃ  pháº§n thÆ°á»Ÿng má»›i vÃ  giÃ¡ trá»‹ ká»³ vá»ng cá»§a tráº¡ng thÃ¡i tiáº¿p theo. Äiá»u nÃ y Ä‘áº¡i diá»‡n cho sá»± Æ°á»›c tÃ­nh má»›i vá» pháº§n thÆ°á»Ÿng náº¿u Agent tiáº¿p tá»¥c thá»±c hiá»‡n chÃ­nh sÃ¡ch tá»‘i Æ°u tá»« tráº¡ng thÃ¡i tiáº¿p theo.\nAlpha (Î±) - Há»‡ sá»‘ há»c (Learning Rate):\n-Ã nghÄ©a: Alpha kiá»ƒm soÃ¡t má»©c Ä‘á»™ mÃ  cÃ¡c giÃ¡ trá»‹ Q hiá»‡n táº¡i Ä‘Æ°á»£c cáº­p nháº­t báº±ng thÃ´ng tin má»›i. NÃ³ quyáº¿t Ä‘á»‹nh xem tÃ¡c nhÃ¢n sáº½ há»c nhanh chÃ³ng tá»« cÃ¡c tráº£i nghiá»‡m má»›i hay há»c dáº§n dáº§n.\nPháº¡m vi: $( 0 \\leq \\alpha \\leq 1 )$\nGiáº£i thÃ­ch:\nÎ± = 1: TÃ¡c nhÃ¢n hoÃ n toÃ n bá» qua thÃ´ng tin cÅ© vÃ  chá»‰ dÃ¹ng giÃ¡ trá»‹ má»›i Æ°á»›c tÃ­nh. NghÄ©a lÃ  má»—i khi cÃ³ má»™t tráº£i nghiá»‡m má»›i, giÃ¡ trá»‹ Q cÅ© sáº½ Ä‘Æ°á»£c thay tháº¿ hoÃ n toÃ n.\nÎ± = 0: TÃ¡c nhÃ¢n hoÃ n toÃ n khÃ´ng cáº­p nháº­t giÃ¡ trá»‹ Q cÅ©, cÃ³ nghÄ©a lÃ  tÃ¡c nhÃ¢n sáº½ khÃ´ng há»c gÃ¬ tá»« tráº£i nghiá»‡m má»›i.\nGiÃ¡ trá»‹ trung gian (0 \u0026lt; Î± \u0026lt; 1): Káº¿t há»£p giá»¯a giÃ¡ trá»‹ Q cÅ© vÃ  giÃ¡ trá»‹ má»›i, tá»©c lÃ  há»c táº­p tá»« cáº£ kinh nghiá»‡m cÅ© vÃ  má»›i má»™t cÃ¡ch tá»« tá»«. Trong thá»±c táº¿, alpha thÆ°á»ng Ä‘Æ°á»£c chá»n lÃ  má»™t giÃ¡ trá»‹ nhá» (vÃ­ dá»¥: 0.1 hoáº·c 0.01) Ä‘á»ƒ tÃ¡c nhÃ¢n cÃ³ thá»ƒ há»c á»•n Ä‘á»‹nh vÃ  khÃ´ng thay Ä‘á»•i quÃ¡ Ä‘á»™t ngá»™t.\nGamma (Î³) - Há»‡ sá»‘ chiáº¿t kháº¥u (Discount Factor):\nÃ nghÄ©a: Gamma xÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ mÃ  tÃ¡c nhÃ¢n coi trá»ng cÃ¡c pháº§n thÆ°á»Ÿng trong tÆ°Æ¡ng lai. NÃ³ cho phÃ©p tÃ¡c nhÃ¢n cÃ¢n nháº¯c giá»¯a viá»‡c nháº­n pháº§n thÆ°á»Ÿng ngay láº­p tá»©c vÃ  pháº§n thÆ°á»Ÿng tiá»m nÄƒng trong tÆ°Æ¡ng lai. Pháº¡m vi: $( 0 \\leq \\gamma \\leq 1 )$ Giáº£i thÃ­ch: Î³ = 0: TÃ¡c nhÃ¢n chá»‰ quan tÃ¢m Ä‘áº¿n pháº§n thÆ°á»Ÿng tá»©c thÃ¬ mÃ  khÃ´ng Ä‘á»ƒ Ã½ Ä‘áº¿n pháº§n thÆ°á»Ÿng tÆ°Æ¡ng lai. Äiá»u nÃ y khiáº¿n tÃ¡c nhÃ¢n chá»‰ tá»‘i Æ°u hÃ³a cho lá»£i Ã­ch ngáº¯n háº¡n. Î³ = 1: TÃ¡c nhÃ¢n Ä‘Ã¡nh giÃ¡ pháº§n thÆ°á»Ÿng hiá»‡n táº¡i vÃ  tÆ°Æ¡ng lai má»™t cÃ¡ch cÃ¢n báº±ng, tá»©c lÃ  pháº§n thÆ°á»Ÿng trong tÆ°Æ¡ng lai xa cÃ³ cÃ¹ng trá»ng sá»‘ vá»›i pháº§n thÆ°á»Ÿng ngay láº­p tá»©c. GiÃ¡ trá»‹ trung gian (0 \u0026lt; Î³ \u0026lt; 1): ÄÃ¢y lÃ  lá»±a chá»n phá»• biáº¿n trong cÃ¡c bÃ i toÃ¡n thá»±c táº¿. Gamma sáº½ giáº£m dáº§n giÃ¡ trá»‹ cá»§a cÃ¡c pháº§n thÆ°á»Ÿng cÃ ng xa trong tÆ°Æ¡ng lai, nhÆ°ng váº«n Ä‘áº£m báº£o ráº±ng tÃ¡c nhÃ¢n quan tÃ¢m Ä‘áº¿n viá»‡c tá»‘i Ä‘a hÃ³a pháº§n thÆ°á»Ÿng dÃ i háº¡n. TÃ³m láº¡i, vai trÃ² cá»§a Î± vÃ  Î³:\nAlpha (Î±): Äiá»u chá»‰nh tá»‘c Ä‘á»™ há»c, tá»©c lÃ  má»©c Ä‘á»™ cáº­p nháº­t giÃ¡ trá»‹ Q dá»±a trÃªn thÃ´ng tin má»›i. Gamma (Î³): Äiá»u chá»‰nh sá»± Æ°u tiÃªn giá»¯a pháº§n thÆ°á»Ÿng hiá»‡n táº¡i vÃ  pháº§n thÆ°á»Ÿng trong tÆ°Æ¡ng lai. Cáº£ hai tham sá»‘ nÃ y áº£nh hÆ°á»Ÿng trá»±c tiáº¿p Ä‘áº¿n hiá»‡u quáº£ há»c táº­p cá»§a tÃ¡c nhÃ¢n trong mÃ´i trÆ°á»ng vÃ  cáº§n Ä‘Æ°á»£c tinh chá»‰nh phÃ¹ há»£p cho tá»«ng bÃ i toÃ¡n cá»¥ thá»ƒ.\nDouble Deep Q-Network Sau khi tÃ¬m hiá»ƒu Q learning, chÃºng ta sáº½ tÃ¬m hiá»ƒu 1 cáº£i tiáº¿n cá»§a nÃ³ lÃ  Double Deep Q-Network\nDouble Deep Q-Network (DDQN) lÃ  má»™t cáº£i tiáº¿n cá»§a Q-learning (cá»¥ thá»ƒ lÃ  DQN - Deep Q-Network) nháº±m giáº£i quyáº¿t má»™t sá»‘ váº¥n Ä‘á» quan trá»ng trong quÃ¡ trÃ¬nh há»c táº­p. So vá»›i Q-learning, DDQN giÃºp giáº£m sá»± thiÃªn lá»‡ch Æ°á»›c lÆ°á»£ng (overestimation bias) vÃ  cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c trong viá»‡c chá»n hÃ nh Ä‘á»™ng. DÆ°á»›i Ä‘Ã¢y lÃ  chi tiáº¿t vá» cÃ¡c cáº£i tiáº¿n cá»§a DDQN so vá»›i Q-learning:\n1. Váº¥n Ä‘á» cá»§a Q-learning (Overestimation Bias): Q-learning tiÃªu chuáº©n (bao gá»“m cáº£ DQN, phiÃªn báº£n má»Ÿ rá»™ng vá»›i máº¡ng nÆ¡-ron) cÃ³ xu hÆ°á»›ng gáº·p pháº£i váº¥n Ä‘á» gá»i lÃ  thiÃªn lá»‡ch Æ°á»›c lÆ°á»£ng quÃ¡ má»©c (overestimation bias). Khi tÃ­nh toÃ¡n giÃ¡ trá»‹ Q, Q-learning chá»n hÃ nh Ä‘á»™ng dá»±a trÃªn giÃ¡ trá»‹ Q lá»›n nháº¥t trong Q-table (hoáº·c máº¡ng Q trong DQN). Tuy nhiÃªn, do sá»± ngáº«u nhiÃªn trong mÃ´i trÆ°á»ng vÃ  cÃ¡c lá»—i nhá» khi Æ°á»›c tÃ­nh, tÃ¡c nhÃ¢n cÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ quÃ¡ cao giÃ¡ trá»‹ Q cá»§a má»™t sá»‘ hÃ nh Ä‘á»™ng.\nCÃ´ng thá»©c cáº­p nháº­t Q-learning:\n$$ [ Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left( r + \\gamma \\max_a Q(s\u0026rsquo;, a\u0026rsquo;) - Q(s, a) \\right) ] $$\nTrong Ä‘Ã³, ( \\max_a Q(s\u0026rsquo;, a\u0026rsquo;) ) chá»n hÃ nh Ä‘á»™ng cÃ³ giÃ¡ trá»‹ Q cao nháº¥t cho tráº¡ng thÃ¡i tiáº¿p theo ( s\u0026rsquo; ). Viá»‡c sá»­ dá»¥ng cÃ¹ng má»™t máº¡ng Ä‘á»ƒ chá»n vÃ  Ä‘Ã¡nh giÃ¡ hÃ nh Ä‘á»™ng nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n thiÃªn lá»‡ch khi cÃ¡c giÃ¡ trá»‹ Q bá»‹ phÃ³ng Ä‘áº¡i má»™t cÃ¡ch khÃ´ng chÃ­nh xÃ¡c.\n2. Cáº£i tiáº¿n cá»§a Double Deep Q-Network (DDQN): DDQN Ä‘Æ°á»£c phÃ¡t triá»ƒn Ä‘á»ƒ kháº¯c phá»¥c váº¥n Ä‘á» thiÃªn lá»‡ch Æ°á»›c lÆ°á»£ng quÃ¡ má»©c trong Q-learning/DQN báº±ng cÃ¡ch tÃ¡ch biá»‡t viá»‡c chá»n hÃ nh Ä‘á»™ng vÃ  Ä‘Ã¡nh giÃ¡ giÃ¡ trá»‹ cá»§a hÃ nh Ä‘á»™ng. Trong DDQN, hai máº¡ng nÆ¡-ron khÃ¡c nhau Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ thá»±c hiá»‡n hai nhiá»‡m vá»¥ nÃ y:\nMáº¡ng chÃ­nh (main network): ÄÆ°á»£c sá»­ dá»¥ng Ä‘á»ƒ chá»n hÃ nh Ä‘á»™ng tá»‘t nháº¥t cho tráº¡ng thÃ¡i tiáº¿p theo. Máº¡ng má»¥c tiÃªu (target network): ÄÆ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Æ°á»›c tÃ­nh giÃ¡ trá»‹ cá»§a hÃ nh Ä‘á»™ng Ä‘Ã³. CÃ´ng thá»©c cáº­p nháº­t DDQN:\n$$ [ Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left( r + \\gamma Q_{\\text{target}}(s\u0026rsquo;, \\arg\\max_a Q_{\\text{main}}(s\u0026rsquo;, a\u0026rsquo;)) - Q(s, a) \\right) ] $$\nTrong Ä‘Ã³:\n( Q_{\\text{main}}(s\u0026rsquo;, a\u0026rsquo;) ): Máº¡ng chÃ­nh Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ chá»n hÃ nh Ä‘á»™ng tá»‘t nháº¥t táº¡i tráº¡ng thÃ¡i ( s\u0026rsquo; ) (tá»©c lÃ  hÃ nh Ä‘á»™ng cÃ³ giÃ¡ trá»‹ Q cao nháº¥t).\n( Q_{\\text{target}}(s\u0026rsquo;, a\u0026rsquo;) ): Máº¡ng má»¥c tiÃªu Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ giÃ¡ trá»‹ Q cá»§a hÃ nh Ä‘á»™ng Ä‘Ã³.\nÃ tÆ°á»Ÿng chÃ­nh: Báº±ng cÃ¡ch sá»­ dá»¥ng hai máº¡ng riÃªng biá»‡t (má»™t Ä‘á»ƒ chá»n hÃ nh Ä‘á»™ng, má»™t Ä‘á»ƒ Ä‘Ã¡nh giÃ¡), DDQN trÃ¡nh Ä‘Æ°á»£c viá»‡c phÃ³ng Ä‘áº¡i giÃ¡ trá»‹ Q do cÃ¹ng má»™t máº¡ng chá»n vÃ  Ä‘Ã¡nh giÃ¡ hÃ nh Ä‘á»™ng trong Q-learning/DQN tiÃªu chuáº©n. Äiá»u nÃ y giÃºp giáº£m thiÃªn lá»‡ch vÃ  cáº£i thiá»‡n hiá»‡u quáº£ há»c táº­p.\n3. Lá»£i Ã­ch cá»§a DDQN so vá»›i DQN/Q-learning: Giáº£m thiÃªn lá»‡ch Æ°á»›c lÆ°á»£ng (Overestimation Bias): DDQN cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a Æ°á»›c tÃ­nh giÃ¡ trá»‹ Q báº±ng cÃ¡ch tÃ¡ch rá»i nhiá»‡m vá»¥ chá»n vÃ  Ä‘Ã¡nh giÃ¡ hÃ nh Ä‘á»™ng. Há»c táº­p á»•n Ä‘á»‹nh hÆ¡n: Viá»‡c giáº£m thiÃªn lá»‡ch giÃºp DDQN á»•n Ä‘á»‹nh hÆ¡n trong quÃ¡ trÃ¬nh há»c táº­p, Ä‘áº·c biá»‡t khi cÃ¡c tÃ¡c nhÃ¢n tÆ°Æ¡ng tÃ¡c vá»›i nhá»¯ng mÃ´i trÆ°á»ng phá»©c táº¡p vÃ  ngáº«u nhiÃªn. Cáº£i thiá»‡n Ä‘á»™ há»™i tá»¥ (Convergence): Do cÃ¡c giÃ¡ trá»‹ Q khÃ´ng bá»‹ phÃ³ng Ä‘áº¡i má»™t cÃ¡ch sai láº§m, quÃ¡ trÃ¬nh há»c táº­p cá»§a tÃ¡c nhÃ¢n trá»Ÿ nÃªn hiá»‡u quáº£ vÃ  nhanh hÆ¡n, giÃºp há»‡ thá»‘ng há»™i tá»¥ vá» giáº£i phÃ¡p tá»‘t hÆ¡n. 4. VÃ­ dá»¥ trá»±c quan vá» sá»± khÃ¡c biá»‡t: DQN: Náº¿u cÃ³ hai hÃ nh Ä‘á»™ng A vÃ  B, vÃ  DQN Ä‘Ã¡nh giÃ¡ hÃ nh Ä‘á»™ng A cÃ³ giÃ¡ trá»‹ Q lÃ  10 (thá»±c táº¿ lÃ  8) vÃ  B lÃ  9 (thá»±c táº¿ lÃ  7), DQN sáº½ chá»n A vÃ¬ $( \\max(10, 9) = 10 )$. Tuy nhiÃªn, giÃ¡ trá»‹ thá»±c cá»§a A chá»‰ lÃ  8, dáº«n Ä‘áº¿n Ä‘Ã¡nh giÃ¡ sai. DDQN: Trong DDQN, máº¡ng chÃ­nh sáº½ chá»n A, nhÆ°ng máº¡ng má»¥c tiÃªu sáº½ Ä‘Ã¡nh giÃ¡ A dá»±a trÃªn giÃ¡ trá»‹ thá»±c táº¿ cá»§a nÃ³, lÃ m giáº£m kháº£ nÄƒng phÃ³ng Ä‘áº¡i giÃ¡ trá»‹ vÃ  giÃºp lá»±a chá»n chÃ­nh xÃ¡c hÆ¡n. 5. TÃ³m táº¯t: Q-learning/DQN: Chá»‰ dÃ¹ng má»™t máº¡ng Ä‘á»ƒ chá»n vÃ  Ä‘Ã¡nh giÃ¡, dá»… gáº·p tÃ¬nh tráº¡ng Æ°á»›c lÆ°á»£ng quÃ¡ cao (overestimation). DDQN: TÃ¡ch biá»‡t viá»‡c chá»n vÃ  Ä‘Ã¡nh giÃ¡ hÃ nh Ä‘á»™ng, giÃºp giáº£m thiÃªn lá»‡ch vÃ  cáº£i thiá»‡n quÃ¡ trÃ¬nh há»c táº­p. II. Thá»±c hÃ nh vá»›i chÆ°Æ¡ng trÃ¬nh mario á» bÃ i thá»±c hÃ nh nÃ y, mÃ¬nh káº¿ thá»«a code tá»« blog chÃ­nh chá»§ cá»§a pytorch\nTrain trÃ² chÆ¡i mario sá»­ dá»¥ng Reinforcement Learning\ncÃ¡c nguyÃªn liá»‡u cáº§n thiáº¿t\n1pip install gym==0.22.0 --update 2pip install gym-super-mario-bros==7.4.0 3pip install tensordict==0.3.0 4pip install torchrl==0.3.0 CÃ¡c báº¡n lÆ°u Ã½ sá»­ dá»¥ng Ä‘Ãºng phiÃªn báº£n Ä‘á»ƒ khá»i bá»‹ lá»—i\nEnvironment Khá»Ÿi táº¡o mÃ´i trÆ°á»ng Trong trÃ² chÆ¡i mario, chÃºng ta cÃ³ nhiá»u Ä‘á»‘i tÆ°á»£ng khi chÆ¡i, lÃ  cÃ¢y náº¥m , cÃ¡c á»‘ng trá»¥ mÃ u xanh, cÃ¡c viÃªn gáº¡ch \u0026hellip;\nKhi chÃºng ta thá»±c hiá»‡n má»™t hÃ nh Ä‘á»™ng ( áº¥n nÃºt trÃªn Joypad ), trÃ² chÆ¡i sáº½ pháº£n há»“i láº¡i next_state lÃ  hÃ¬nh áº£nh cá»§a khung hÃ¬nh sau khi ta nháº¥n nÃºt, reward, done, info\n1 2env = gym_super_mario_bros.make(\u0026#34;SuperMarioBros-1-1-v0\u0026#34;) 3 4# Limit the action-space to 5# 0. walk right 6# 1. jump right 7env = JoypadSpace(env, [[\u0026#34;right\u0026#34;], [\u0026#34;right\u0026#34;, \u0026#34;A\u0026#34;]]) 8 9env.reset() 10next_state, reward, done, info = env.step(action=0) 11print(f\u0026#34;{next_state.shape},\\n {reward},\\n {done},\\n {info}\u0026#34;) 12 13 14(240, 256, 3), 15 0.0, 16 False, 17 {\u0026#39;coins\u0026#39;: 0, \u0026#39;flag_get\u0026#39;: False, \u0026#39;life\u0026#39;: 2, \u0026#39;score\u0026#39;: 0, \u0026#39;stage\u0026#39;: 1, \u0026#39;status\u0026#39;: \u0026#39;small\u0026#39;, \u0026#39;time\u0026#39;: 400, \u0026#39;world\u0026#39;: 1, \u0026#39;x_pos\u0026#39;: 40, \u0026#39;y_pos\u0026#39;: 79} Xá»­ lÃ½ dá»¯ liá»‡u Dá»¯ liá»‡u cá»§a state lÃ  má»™t hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c (240, 256, 3) , há»‡ bgr, chÃºng ta sáº½ convert vá» GrayScale (1 ,240, 256) vÃ  resize vá» hÃ¬nh vuÃ´ng cÃ³ kÃ­ch thÆ°á»›c 84x84 Ä‘á»ƒ tÄƒng thá»i gian xá»­ lÃ½ . CÃ¡c báº¡n cÃ³ thá»ƒ thay Ä‘á»•i thÃ nh 112x112 hoáº·c 96x96 tÃ¹y thÃ­ch.\nNgoÃ i ra, do hÃ¬nh trÆ°á»›c khi áº¥n vÃ  hÃ¬nh sau khi áº¥n nÃºt thÆ°á»ng sáº½ gáº§n gáº§n giá»‘ng nhau, nÃªn chÃºng ta sáº½ thÃªm má»™t lá»›p SkipFrame, hiá»ƒu Ä‘Ãºng nhÆ° tÃªn, chÃºng ta sáº½ cá»™ng dá»“n giÃ¡ trá»‹ reward Ä‘á»ƒ tráº£ ra cho mÃ´ hÃ¬nh thá»±c hiá»‡n cáº­p nháº­t trá»ng sá»‘. VÃ­ dá»¥ SkipFrame(4), nghÄ©a lÃ  ta sáº½ cá»™ng dá»“n giÃ¡ trá»‹ reward cá»§a 4 hÃ¬nh liÃªn tiáº¿p thÃ nh tá»•ng reward vÃ  cáº­p nháº­t trá»ng sá»‘, cÃ¡i nÃ y giÃºp cho mÃ´ hÃ¬nh cháº¡y nhanh hÆ¡n xÃ­u mÃ  váº«n Ä‘áº£m báº£o thÃ´ng tin, táº¥t nhiÃªn sá»‘ lÆ°á»£ng frame bá»‹ skip cáº§n be bÃ© thÃ´i\nChÃºng ta sáº½ táº¡o cÃ¡c lá»›p , implement tá»« gym.Wrapper\n1 2class SkipFrame(gym.Wrapper): 3 def __init__(self, env, skip): 4 \u0026#34;\u0026#34;\u0026#34;Return only every `skip`-th frame\u0026#34;\u0026#34;\u0026#34; 5 super().__init__(env) 6 self._skip = skip 7 8 def step(self, action): 9 \u0026#34;\u0026#34;\u0026#34;Repeat action, and sum reward\u0026#34;\u0026#34;\u0026#34; 10 total_reward = 0.0 11 for i in range(self._skip): 12 # Accumulate reward and repeat the same action 13 obs, reward, done, trunk, info = self.env.step(action) 14 total_reward += reward 15 if done: 16 break 17 return obs, total_reward, done, trunk, info 18 19 20class GrayScaleObservation(gym.ObservationWrapper): 21 def __init__(self, env): 22 super().__init__(env) 23 obs_shape = self.observation_space.shape[:2] 24 self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8) 25 26 def permute_orientation(self, observation): 27 # permute [H, W, C] array to [C, H, W] tensor 28 observation = np.transpose(observation, (2, 0, 1)) 29 observation = torch.tensor(observation.copy(), dtype=torch.float) 30 return observation 31 32 def observation(self, observation): 33 observation = self.permute_orientation(observation) 34 transform = T.Grayscale() 35 observation = transform(observation) 36 return observation 37 38 39class ResizeObservation(gym.ObservationWrapper): 40 def __init__(self, env, shape): 41 super().__init__(env) 42 if isinstance(shape, int): 43 self.shape = (shape, shape) 44 else: 45 self.shape = tuple(shape) 46 47 obs_shape = self.shape + self.observation_space.shape[2:] 48 self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8) 49 50 def observation(self, observation): 51 transforms = T.Compose( 52 [T.Resize(self.shape, antialias=True), T.Normalize(0, 255)] 53 ) 54 observation = transforms(observation).squeeze(0) 55 return observation 56 57 58# Apply Wrappers to environment 59env = SkipFrame(env, skip=4) 60env = GrayScaleObservation(env) 61env = ResizeObservation(env, shape=84) 62 63env = FrameStack(env, num_stack=4) Cuá»‘i cÃ¹ng, chÃºng ta sáº½ Ä‘Ã³ng cÃ¡c khai bÃ¡o trÃªn vÃ o má»™t FrameStack vá»›i sá»‘ lÆ°á»£ng lá»›p lÃ  4, nghÄ©a lÃ  chÃºng ta sáº½ Ä‘Æ°a vÃ o 4 hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c (240, 256, 3), káº¿t quáº£ lÃ  hÃ¬nh cÃ³ kÃ­ch thÆ°Æ¡c (4, 84, 84)\nAgent ChÃºng ta chÆ¡i mario, nÃªn táº¡o 1 Agent tÃªn lÃ  mario , theo lÃ½ thuyáº¿t, chÃºng ta sáº½ cÃ³ cÃ¡c hÃ nh Ä‘á»™ng cho agent\nAct : Tráº£ vá» 1 hÃ nh Ä‘á»™ng tá»‘i Æ°u , trong danh sÃ¡ch cÃ¡c hÃ nh Ä‘á»™ng dá»±a trÃªn hÃ¬nh áº£nh hiá»‡nt táº¡i\nRemember experiences. Experience = (current state, current action, reward, next state). Mario sáº½ lÆ°u láº¡i cÃ¡c hÃ nh Ä‘á»™ng (cache) vÃ  nhá»› láº¡i cÃ¡c hÃ nh Ä‘á»™ng cá»§a mÃ¬nh Ä‘á»ƒ rÃºt ra bÃ i há»c\nLearn: Cáº­p nháº­t trá»ng sá»‘\n1 2class Mario: 3 def __init__(): 4 pass 5 6 def act(self, state): 7 \u0026#34;\u0026#34;\u0026#34;Given a state, choose an epsilon-greedy action\u0026#34;\u0026#34;\u0026#34; 8 pass 9 10 def cache(self, experience): 11 \u0026#34;\u0026#34;\u0026#34;Add the experience to memory\u0026#34;\u0026#34;\u0026#34; 12 pass 13 14 def recall(self): 15 \u0026#34;\u0026#34;\u0026#34;Sample experiences from memory\u0026#34;\u0026#34;\u0026#34; 16 pass 17 18 def learn(self): 19 \u0026#34;\u0026#34;\u0026#34;Update online action value (Q) function with a batch of experiences\u0026#34;\u0026#34;\u0026#34; 20 pass Act Khi chÆ¡i mario, hÃ nh Ä‘á»™ng chÃºng ta sáº½ thá»±c hiá»‡n sáº½ lÃ  láº¥y ngáº«u nhiÃªn 1 hÃ nh Ä‘á»™ng trong táº­p lá»‡nh (explore), hoáº·c lÃ  thá»±c hiá»‡n lá»‡nh tá»‘i Æ°u do mÃ´ hÃ¬nh gá»£i Ã½ (exploit). Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c tÃ­nh nÄƒng nÃ y, chÃºng ta sáº½ sá»­ dá»¥ng exploration_rate Ä‘á»ƒ Ä‘iá»u khiá»ƒn xÃ¡c xuáº¥t chá»n explore hay exploit.\nNgoÃ i ra, do lÃ  mÃ´ hÃ¬nh AI, nÃªn chÃºng ta cáº§n xÃ¢y dá»±ng má»™t lá»›p CNN tÃªn lÃ  MarioNet Ä‘á»ƒ hÃ m learn cáº­p nháº­t trá»ng sá»‘\n1 2class Mario: 3 def __init__(self, state_dim, action_dim, save_dir): 4 self.state_dim = state_dim 5 self.action_dim = action_dim 6 self.save_dir = save_dir 7 8 self.device = \u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34; 9 10 # Mario\u0026#39;s DNN to predict the most optimal action - we implement this in the Learn section 11 self.net = MarioNet(self.state_dim, self.action_dim).float() 12 self.net = self.net.to(device=self.device) 13 14 self.exploration_rate = 1 15 self.exploration_rate_decay = 0.99999975 16 self.exploration_rate_min = 0.1 17 self.curr_step = 0 18 19 self.save_every = 5e5 # no. of experiences between saving Mario Net 20 21 def act(self, state): 22 \u0026#34;\u0026#34;\u0026#34; 23 Given a state, choose an epsilon-greedy action and update value of step. 24 25 Inputs: 26 state(``LazyFrame``): A single observation of the current state, dimension is (state_dim) 27 Outputs: 28 ``action_idx`` (``int``): An integer representing which action Mario will perform 29 \u0026#34;\u0026#34;\u0026#34; 30 # EXPLORE 31 if np.random.rand() \u0026lt; self.exploration_rate: 32 action_idx = np.random.randint(self.action_dim) 33 34 # EXPLOIT 35 else: 36 state = state[0].__array__() if isinstance(state, tuple) else state.__array__() 37 state = torch.tensor(state, device=self.device).unsqueeze(0) 38 action_values = self.net(state, model=\u0026#34;online\u0026#34;) 39 action_idx = torch.argmax(action_values, axis=1).item() 40 41 # decrease exploration_rate 42 self.exploration_rate *= self.exploration_rate_decay 43 self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate) 44 45 # increment step 46 self.curr_step += 1 47 return action_idx Remember Pháº§n nÃ y gá»“m 2 hÃ m lÃ  cache vÃ  recall. cache, hiá»ƒu Ä‘Ãºng nhÆ° tÃªn, lÃ  lÆ°u láº¡i cÃ¡c giÃ¡ trá»‹ state, next_state, action, reward, done. recall lÃ  láº¥y cÃ¡c giÃ¡ trá»‹ Ä‘Ã£ Ä‘Æ°á»£c nhá»› ra\n1 2class Mario(Mario): # subclassing for continuity 3 def __init__(self, state_dim, action_dim, save_dir): 4 super().__init__(state_dim, action_dim, save_dir) 5 self.memory = TensorDictReplayBuffer(storage=LazyMemmapStorage(100000, device=torch.device(\u0026#34;cpu\u0026#34;))) 6 self.batch_size = 32 7 8 def cache(self, state, next_state, action, reward, done): 9 \u0026#34;\u0026#34;\u0026#34; 10 Store the experience to self.memory (replay buffer) 11 12 Inputs: 13 state (``LazyFrame``), 14 next_state (``LazyFrame``), 15 action (``int``), 16 reward (``float``), 17 done(``bool``)) 18 \u0026#34;\u0026#34;\u0026#34; 19 def first_if_tuple(x): 20 return x[0] if isinstance(x, tuple) else x 21 state = first_if_tuple(state).__array__() 22 next_state = first_if_tuple(next_state).__array__() 23 24 state = torch.tensor(state) 25 next_state = torch.tensor(next_state) 26 action = torch.tensor([action]) 27 reward = torch.tensor([reward]) 28 done = torch.tensor([done]) 29 30 # self.memory.append((state, next_state, action, reward, done,)) 31 self.memory.add(TensorDict({\u0026#34;state\u0026#34;: state, \u0026#34;next_state\u0026#34;: next_state, \u0026#34;action\u0026#34;: action, \u0026#34;reward\u0026#34;: reward, \u0026#34;done\u0026#34;: done}, batch_size=[])) 32 33 def recall(self): 34 \u0026#34;\u0026#34;\u0026#34; 35 Retrieve a batch of experiences from memory 36 \u0026#34;\u0026#34;\u0026#34; 37 batch = self.memory.sample(self.batch_size).to(self.device) 38 state, next_state, action, reward, done = (batch.get(key) for key in (\u0026#34;state\u0026#34;, \u0026#34;next_state\u0026#34;, \u0026#34;action\u0026#34;, \u0026#34;reward\u0026#34;, \u0026#34;done\u0026#34;)) 39 return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze() Learn á» pháº§n init trÃªn, chÃºng ta cÃ³ cÃ¡i khai bÃ¡o MarioNet, á»Ÿ Ä‘Ã¢y, chÃºng ta sá»­ dá»¥ng mÃ´ hÃ¬nh DDQN - Double Q-learning https://arxiv.org/pdf/1509.06461\nDDQN sá»­ dá»¥ng hai CNN Ä‘áº·t tÃªn lÃ  Q_online vÃ  Q_target. Hai mÃ´ hÃ¬nh cnn nÃ y Ä‘á»™c láº­p vá»›i nhau\nChÃºng ta sáº½ chia sáº½ chung features cá»§a Q_online vÃ  Q_target, nhÆ°ng FC classifiers sáº½ Ä‘á»™c láº­p nhau, cÃ¡c giÃ¡ trá»‹ trá»ng sá»‘ cá»§a Q_target sáº½ bá»‹ frozen Ä‘á»ƒ ngÄƒng cáº­p nháº­t trá»ng sá»‘ tá»« backprop\n1 2class MarioNet(nn.Module): 3 \u0026#34;\u0026#34;\u0026#34;mini CNN structure 4 input -\u0026gt; (conv2d + relu) x 3 -\u0026gt; flatten -\u0026gt; (dense + relu) x 2 -\u0026gt; output 5 \u0026#34;\u0026#34;\u0026#34; 6 7 def __init__(self, input_dim, output_dim): 8 super().__init__() 9 c, h, w = input_dim 10 11 if h != 84: 12 raise ValueError(f\u0026#34;Expecting input height: 84, got: {h}\u0026#34;) 13 if w != 84: 14 raise ValueError(f\u0026#34;Expecting input width: 84, got: {w}\u0026#34;) 15 16 self.online = self.__build_cnn(c, output_dim) 17 18 self.target = self.__build_cnn(c, output_dim) 19 self.target.load_state_dict(self.online.state_dict()) 20 21 # Q_target parameters are frozen. 22 for p in self.target.parameters(): 23 p.requires_grad = False 24 25 def forward(self, input, model): 26 if model == \u0026#34;online\u0026#34;: 27 return self.online(input) 28 elif model == \u0026#34;target\u0026#34;: 29 return self.target(input) 30 31 def __build_cnn(self, c, output_dim): 32 return nn.Sequential( 33 nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4), 34 nn.ReLU(), 35 nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2), 36 nn.ReLU(), 37 nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1), 38 nn.ReLU(), 39 nn.Flatten(), 40 nn.Linear(3136, 512), 41 nn.ReLU(), 42 nn.Linear(512, output_dim), 43 ) Estimate Do chÃºng ta cÃ³ 2 lá»›p cnn, nÃªn chÃºng ta cáº§n xÃ¢y 2 hÃ m Estimate\nVá»›i Q_online, chÃºng ta thá»±c hiá»‡n infer, xong.\nVá»›i Q_target, giÃ¡ trá»‹ reward hÆ¡i phá»©c táº¡p má»™t chÃºt, phÃ¢n tÃ­ch chÃºng\nchÃºng ta cÃ³ giÃ¡ trá»‹ reward hiá»‡n táº¡i\nChÃºng ta cáº§n káº¿t há»£p vá»›i reward cá»§a Q_target, nhÆ°ng action thÃ¬ khÃ´ng biáº¿t, váº­y nÃªn chÃºng ta sáº½ láº¥y action tá»‘i Æ°u tá»« Q_online vá»›i state hiá»‡n táº¡i\n1 2class Mario(Mario): 3 def __init__(self, state_dim, action_dim, save_dir): 4 super().__init__(state_dim, action_dim, save_dir) 5 self.gamma = 0.9 6 7 def td_estimate(self, state, action): 8 current_Q = self.net(state, model=\u0026#34;online\u0026#34;)[ 9 np.arange(0, self.batch_size), action 10 ] # Q_online(s,a) 11 return current_Q 12 13 @torch.no_grad() 14 def td_target(self, reward, next_state, done): 15 next_state_Q = self.net(next_state, model=\u0026#34;online\u0026#34;) 16 best_action = torch.argmax(next_state_Q, axis=1) 17 next_Q = self.net(next_state, model=\u0026#34;target\u0026#34;)[ 18 np.arange(0, self.batch_size), best_action 19 ] 20 return (reward + (1 - done.float()) * self.gamma * next_Q).float() Cáº­p nháº­t model Sá»­ dá»¥ng cnn, nÃªn chÃºng ta cáº§n Ä‘á»‹nh nghÄ©a lÃ  loss vÃ  hÃ m optimizer, sau khi update trá»ng sá»‘ cá»§a Q_online, chÃºng ta sáº½ cáº­p nháº­t trá»ng sá»‘ Ä‘Ã³ cho Q_target\n1 2class Mario(Mario): 3 def __init__(self, state_dim, action_dim, save_dir): 4 super().__init__(state_dim, action_dim, save_dir) 5 self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025) 6 self.loss_fn = torch.nn.SmoothL1Loss() 7 8 def update_Q_online(self, td_estimate, td_target): 9 loss = self.loss_fn(td_estimate, td_target) 10 self.optimizer.zero_grad() 11 loss.backward() 12 self.optimizer.step() 13 return loss.item() 14 15 def sync_Q_target(self): 16 self.net.target.load_state_dict(self.net.online.state_dict()) Save checkpoint 1class Mario(Mario): 2 def save(self): 3 save_path = ( 4 self.save_dir / f\u0026#34;mario_net_{int(self.curr_step // self.save_every)}.chkpt\u0026#34; 5 ) 6 torch.save( 7 dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate), 8 save_path, 9 ) 10 print(f\u0026#34;MarioNet saved to {save_path} at step {self.curr_step}\u0026#34;) Gom vÃ o hÃ m learn 1 2class Mario(Mario): 3 def __init__(self, state_dim, action_dim, save_dir): 4 super().__init__(state_dim, action_dim, save_dir) 5 self.burnin = 1e4 # min. experiences before training 6 self.learn_every = 3 # no. of experiences between updates to Q_online 7 self.sync_every = 1e4 # no. of experiences between Q_target \u0026amp; Q_online sync 8 9 def learn(self): 10 if self.curr_step % self.sync_every == 0: 11 self.sync_Q_target() 12 13 if self.curr_step % self.save_every == 0: 14 self.save() 15 16 if self.curr_step \u0026lt; self.burnin: 17 return None, None 18 19 if self.curr_step % self.learn_every != 0: 20 return None, None 21 22 # Sample from memory 23 state, next_state, action, reward, done = self.recall() 24 25 # Get TD Estimate 26 td_est = self.td_estimate(state, action) 27 28 # Get TD Target 29 td_tgt = self.td_target(reward, next_state, done) 30 31 # Backpropagate loss through Q_online 32 loss = self.update_Q_online(td_est, td_tgt) 33 34 return (td_est.mean().item(), loss) Play ChÃºng ta thá»±c hiá»‡n learn 40000 láº§n\n1 2use_cuda = torch.cuda.is_available() 3print(f\u0026#34;Using CUDA: {use_cuda}\u0026#34;) 4print() 5 6save_dir = Path(\u0026#34;checkpoints\u0026#34;) / datetime.datetime.now().strftime(\u0026#34;%Y-%m-%dT%H-%M-%S\u0026#34;) 7save_dir.mkdir(parents=True) 8 9mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir) 10 11logger = MetricLogger(save_dir) 12 13episodes = 40000 14for e in range(episodes): 15 16 state = env.reset() 17 18 # Play the game! 19 while True: 20 21 # Run agent on the state 22 action = mario.act(state) 23 24 # Agent performs action 25 next_state, reward, done, trunc, info = env.step(action) 26 27 # Remember 28 mario.cache(state, next_state, action, reward, done) 29 30 # Learn 31 q, loss = mario.learn() 32 33 # Logging 34 logger.log_step(reward, loss, q) 35 36 # Update state 37 state = next_state 38 39 # Check if end of game 40 if done or info[\u0026#34;flag_get\u0026#34;]: 41 break 42 43 logger.log_episode() 44 45 if (e % 20 == 0) or (e == episodes - 1): 46 logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step) Replay á» hÃ m nÃ y, mÃ¬nh load model lÃªn vÃ  cho auto chÆ¡i, sau vÃ i vÃ²ng láº·p cÅ©ng sáº½ vá» Ä‘Ã­ch Ä‘Æ°á»£c :)\ná» Ä‘Ã¢y, cÃ¡c báº¡n chÃº Ã½ phiÃªn báº£n gym 0.22.0, á»Ÿ bÃ i viáº¿t gá»‘c há» xÃ i gym 0.17.x nÃªn khÃ´ng cÃ³ hÃ m save video, pháº£i tá»± viáº¿t láº¡i, cÃ²n cÃ¡c báº£n cao hÆ¡n thÃ¬ há» tÃ¡ch rÃµ biáº¿n done cá»§a env.step thÃ nh 2 biáº¿n nÃªn náº¿u báº¡n nÃ o xÃ i code thÃ¬ sáº½ bá»‹ lá»—i.\n1 2import random, datetime 3from pathlib import Path 4 5import gym 6import gym_super_mario_bros 7from gym.wrappers import FrameStack, GrayScaleObservation, TransformObservation 8from nes_py.wrappers import JoypadSpace 9 10from metrics import MetricLogger 11from agent import Mario 12from wrappers import ResizeObservation, SkipFrame 13 14 15word = 1 16state = 1 17env = gym_super_mario_bros.make(f\u0026#39;SuperMarioBros-{word}-{state}-v0\u0026#39;) 18 19 20 21env = JoypadSpace( 22 env, 23 [[\u0026#39;right\u0026#39;], 24 [\u0026#39;right\u0026#39;, \u0026#39;A\u0026#39;]] 25) 26 27env = SkipFrame(env, skip=4) 28env = GrayScaleObservation(env, keep_dim=False) 29env = ResizeObservation(env, shape=84) 30env = TransformObservation(env, f=lambda x: x / 255.) 31env = FrameStack(env, num_stack=4) 32env = gym.wrappers.RecordVideo(env=env, video_folder=\u0026#34;video\u0026#34;, name_prefix=f\u0026#34;mario_-{word}-{state}\u0026#34;) 33 34env.reset() 35 36 37 38# Start the recorder 39env.start_video_recorder() 40 41save_dir = Path(\u0026#39;checkpoints\u0026#39;) / \u0026#34;test\u0026#34; 42save_dir.mkdir(parents=True,exist_ok=True) 43 44checkpoint = Path(\u0026#39;checkpoints/2024-10-12T14-02-01/mario_net_15.chkpt\u0026#39;) 45mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir, checkpoint=checkpoint) 46mario.exploration_rate = mario.exploration_rate_min 47 48logger = MetricLogger(save_dir) 49 50episodes = 50 51 52for e in range(episodes): 53 54 state = env.reset() 55 56 while True: 57 58 env.render() 59 60 action = mario.act(state) 61 62 next_state, reward, done, info = env.step(action) 63 64 mario.cache(state, next_state, action, reward, done) 65 # print(next_state, reward, done, info) 66 67 logger.log_step(reward, None, None) 68 69 state = next_state 70 71 if done or info[\u0026#39;flag_get\u0026#39;]: 72 break 73 74 logger.log_episode() 75 76 if e % 20 == 0: 77 logger.record( 78 episode=e, 79 epsilon=mario.exploration_rate, 80 step=mario.curr_step 81 ) 82 83env.close_video_recorder() 84 85# Close the environment 86env.close() code chÃ­nh chá»§ https://pytorch.org/tutorials/intermediate/mario_rl_tutorial.html\nKáº¿t quáº£ Äá»£i táº§m 48h khi cháº¡y báº±ng GPU, mÃ¬nh train báº±ng RTX 4060 TI 16G, khÃ¡ lÃ¢u\nNáº¿u train vá»›i pháº§n cá»©ng máº¡nh hÆ¡n, nhÆ° RTX 4090, hoáº·c A100, hoáº·c Ä‘á»•i má»™t model máº¡nh hÆ¡n nhÆ° Proximal Policy Optimizatio, sáº½ nhanh hÆ¡n\nModel trÃªn mÃ¬nh train vá»›i level 1, Ä‘á»ƒ cháº¡y auto cho level 2,3\u0026hellip; 32, mÃ¬nh pháº£i cháº¡y 32 láº§n train tÆ°Æ¡ng á»©ng cho má»—i level.\nMÃ¬nh thá»­ Ä‘á»ƒ model cháº¡y thá»­ cho level 2,3 nhÆ°ng khÃ´ng vá» Ä‘Ã­ch Ä‘Æ°á»£c, pháº£i train láº¡i\nYour browser does not support the video tag. Pháº§n tiáº¿p theo, mÃ¬nh sáº½ train thá»­ model PPO thay DDQN\nIII. Tham kháº£o https://arxiv.org/pdf/1509.06461\nhttps://www.geeksforgeeks.org/what-is-reinforcement-learning/\nhttps://pytorch.org/tutorials/intermediate/mario_rl_tutorial.html\nhttps://github.com/yfeng997/MadMario\nhttps://towardsdatascience.com/reinforcement-learning-101-e24b50e1d292\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t. Xin cáº£m Æ¡n vÃ  háº¹n gáº·p láº¡i.\n","date":"Oct 27, 2024","img":"https://unsplash.it/1920/1080?image=1","permalink":"/blog/2024-10-27-mario-reinfomation-learning-double-dqn/","series":null,"tags":["Reinformation Learning","DeepLearning"],"title":"Sá»­ Dá»¥ng MÃ´ HÃ¬nh Double DQN  Huáº¥n Luyá»‡n MÃ´ HÃ¬nh Reinforcement Learning Vá»›i Game Mario"},{"categories":null,"content":" Hashing lÃ  gÃ¬? Consistent Hashing lÃ  gÃ¬? á»¨ng dá»¥ng cá»§a Consistent Hashing Implement Consistent Hashing Æ¯u vÃ  nhÆ°á»£c Ä‘iá»ƒm cá»§a Consistent Hashing Hashing lÃ  gÃ¬? Hasing, tiáº¿ng viá»‡t cÃ³ thá»ƒ dá»‹ch lÃ  \u0026ldquo;bÄƒm\u0026rdquo; lÃ  quÃ¡ trÃ¬nh chÃºng ta Ä‘Æ°a má»™t chuá»—i vÃ o má»™t hÃ m bÄƒm vÃ  bÄƒm nÃ³ ra, rá»“i nÃ©n nÃ³ láº¡i trong má»™t vÃ¹ng khÃ´ng gian, thu Ä‘Æ°á»£c vá»‹ trÃ­ cá»§a chuá»—i Ä‘áº§u vÃ o trong vÃ¹ng khÃ´ng gian nÃ©n Ä‘Ã³.\nCÃ´ng thá»©c biá»ƒu diá»…n\n1 2vi_tri = ham_bam(dau_vao)%kich_thuoc_khong_gian VÃ­ dá»¥:\n1 2Giáº£ sá»­ chÃºng ta cÃ³ kÃ­ch thÆ°á»›c khÃ´ng gian kich_thuoc_khong_gian = 10 3 4ChÃºng ta muá»‘n lÆ°u trá»¯ chuá»—i Ä‘áº§u vÃ o lÃ  dau_vao = \u0026#34;Hello\u0026#34; 5 6Sá»­ dá»¥ng hÃ m bÄƒm ham_bam(\u0026#34;Hello\u0026#34;) ra káº¿t quáº£ lÃ  16 7 8ta cÃ³ vi_tri = ham_bam(\u0026#34;Hello\u0026#34;) % 10 = 16 % 10 = 6 9 10Váº­y chuá»—i dá»¯ liá»‡u \u0026#34;Hello\u0026#34; sáº½ Ä‘Æ°á»£c lÆ°u trá»¯ táº¡i vá»‹ trÃ­ 6 trong khÃ´ng gian nhá»› size 10. QuÃ¡ trÃ¬nh nÃ y cho phÃ©p chÃºng ta biáº¿n má»™t chuá»—i dá»¯ liá»‡u thÃ nh má»™t vá»‹ trÃ­ trong khÃ´ng gian nhá»›, giÃºp cho viá»‡c lÆ°u trá»¯ vÃ  truy xuáº¥t dá»¯ liá»‡u trá»Ÿ nÃªn hiá»‡u quáº£ hÆ¡n.\nConsistent Hashing lÃ  gÃ¬? Consistent Hashing (bÄƒm nháº¥t quÃ¡n) lÃ  ká»¹ thuáº­t Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n phá»‘i cÃ¡c khoÃ¡ (key) Ä‘á»u trÃªn cÃ¡c cá»¥m mÃ¡y tÃ­nh (clusters), má»¥c tiÃªu lÃ  giáº£m thiá»ƒu sá»‘ lÆ°á»£ng cÃ¡c khoÃ¡ cáº§n di chuyá»ƒn khi thÃªm nodes hoáº·c xoÃ¡ nodes ( xoÃ¡ trong trÆ°á»ng há»£p lá»—i , thÃªm trong trÆ°á»ng há»£p muá»‘n scale há»‡ thá»‘ng), giáº£m sá»‘ lÆ°á»£ng cÃ¡c khoÃ¡ cáº§n di chuyá»ƒn gÃ³p pháº§n lÃ m á»•n Ä‘á»‹nh há»‡ thá»‘ng, vÃ  giáº£m tÃ¡c Ä‘á»™ng tiÃªu cá»±c cá»§a sá»± thay Ä‘á»•i nÃ y lÃªn há»‡ thá»‘ng\nMá»¥c tiÃªu:\nPhÃ¢n phá»‘i cÃ¡c khÃ³a (keys) Ä‘á»u trÃªn má»™t cá»¥m cÃ¡c nÃºt (nodes) trong há»‡ thá»‘ng.\nGiáº£m thiá»ƒu sá»‘ lÆ°á»£ng khÃ³a cáº§n di chuyá»ƒn khi thÃªm hoáº·c xÃ³a nÃºt khá»i cá»¥m.\nCáº¥u trÃºc:\nSá»­ dá»¥ng má»™t vÃ²ng áº£o (hashring) Ä‘á»ƒ biá»ƒu diá»…n cÃ¡c yÃªu cáº§u cá»§a server/clients vÃ  cÃ¡c server nodes.\nSá»‘ lÆ°á»£ng vá»‹ trÃ­ trÃªn vÃ²ng khÃ´ng cá»‘ Ä‘á»‹nh, nhÆ°ng Ä‘Æ°á»£c coi lÃ  cÃ³ vÃ´ sá»‘ Ä‘iá»ƒm.\nCÃ¡c nÃºt mÃ¡y chá»§ cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘áº·t táº¡i cÃ¡c vá»‹ trÃ­ ngáº«u nhiÃªn trÃªn vÃ²ng báº±ng cÃ¡ch sá»­ dá»¥ng hÃ m bÄƒm (hashing).\nCÃ¡c yÃªu cáº§u (requests) tá»« ngÆ°á»i dÃ¹ng, mÃ¡y tÃ­nh hoáº·c chÆ°Æ¡ng trÃ¬nh khÃ´ng cÃ³ mÃ¡y chá»§ cÅ©ng Ä‘Æ°á»£c Ä‘áº·t trÃªn cÃ¹ng má»™t vÃ²ng báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¹ng má»™t hÃ m bÄƒm.\nLá»£i Ã­ch:\nKhi thÃªm hoáº·c xÃ³a nÃºt khá»i cá»¥m, chá»‰ cáº§n di chuyá»ƒn má»™t sá»‘ nhá» khÃ³a Ä‘áº¿n cÃ¡c nÃºt khÃ¡c.\nGiáº£m thiá»ƒu tÃ¡c Ä‘á»™ng cá»§a viá»‡c thÃªm hoáº·c xÃ³a nÃºt Ä‘áº¿n toÃ n bá»™ há»‡ thá»‘ng.\nCáº£i thiá»‡n hiá»‡u suáº¥t vÃ  Ä‘á»™ tin cáº­y cá»§a há»‡ thá»‘ng.\nCÃ¡ch thá»©c hoáº¡t Ä‘á»™ng:\nKhi má»™t yÃªu cáº§u Ä‘Æ°á»£c gá»­i Ä‘áº¿n há»‡ thá»‘ng, nÃ³ sáº½ Ä‘Æ°á»£c bÄƒm (hash) Ä‘á»ƒ táº¡o ra má»™t giÃ¡ trá»‹ bÄƒm.\nGiÃ¡ trá»‹ bÄƒm nÃ y sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vá»‹ trÃ­ cá»§a yÃªu cáº§u trÃªn vÃ²ng áº£o.\nHá»‡ thá»‘ng sáº½ tÃ¬m nÃºt mÃ¡y chá»§ gáº§n nháº¥t vá»›i vá»‹ trÃ­ cá»§a yÃªu cáº§u trÃªn vÃ²ng vÃ  gá»­i yÃªu cáº§u Ä‘áº¿n nÃºt Ä‘Ã³.\nNáº¿u nÃºt mÃ¡y chá»§ Ä‘Ã³ khÃ´ng kháº£ dá»¥ng, há»‡ thá»‘ng sáº½ tÃ¬m nÃºt mÃ¡y chá»§ tiáº¿p theo trÃªn vÃ²ng vÃ  gá»­i yÃªu cáº§u Ä‘áº¿n nÃºt Ä‘Ã³.\nKá»¹ thuáº­t Consistent Hashing giÃºp phÃ¢n phá»‘i táº£i trá»ng Ä‘á»u trÃªn cÃ¡c nÃºt mÃ¡y chá»§ vÃ  giáº£m thiá»ƒu tÃ¡c Ä‘á»™ng cá»§a viá»‡c thÃªm hoáº·c xÃ³a nÃºt Ä‘áº¿n toÃ n bá»™ há»‡ thá»‘ng.\ná»¨ng dá»¥ng cá»§a Consistent Hashing NgÃ y nay Consistent Hashing lÃ  má»™t ká»¹ thuáº­t phá»• biáº¿n Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c há»‡ thá»‘ng phÃ¢n tÃ¡n Ä‘á»ƒ giáº£i quyáº¿t thÃ¡ch thá»©c phÃ¢n phá»‘i hiá»‡u quáº£ cÃ¡c khÃ³a hoáº·c pháº§n tá»­ dá»¯ liá»‡u trÃªn nhiá»u nÃºt/mÃ¡y chá»§ trong má»™t máº¡ng lÆ°á»›i.\nBáº±ng cÃ¡ch sá»­ dá»¥ng Consistent Hashing, cÃ¡c há»‡ thá»‘ng phÃ¢n tÃ¡n cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c nhiá»u lá»£i Ã­ch, bao gá»“m:\nCáº£i thiá»‡n kháº£ nÄƒng má»Ÿ rá»™ng: Consistent Hashing cho phÃ©p cÃ¡c há»‡ thá»‘ng phÃ¢n tÃ¡n má»Ÿ rá»™ng dá»… dÃ ng hÆ¡n, vÃ¬ cÃ¡c nÃºt má»›i cÃ³ thá»ƒ Ä‘Æ°á»£c thÃªm hoáº·c xÃ³a mÃ  khÃ´ng lÃ m giÃ¡n Ä‘oáº¡n toÃ n bá»™ há»‡ thá»‘ng.\nGiáº£m thiá»ƒu chi phÃ­ Ã¡nh xáº¡ láº¡i: Báº±ng cÃ¡ch giáº£m thiá»ƒu sá»‘ lÆ°á»£ng cÃ¡c phÃ©p Ã¡nh xáº¡ láº¡i cáº§n thiáº¿t, Consistent Hashing giÃºp giáº£m thiá»ƒu chi phÃ­ liÃªn quan Ä‘áº¿n viá»‡c thÃªm hoáº·c xÃ³a nÃºt, giÃºp duy trÃ¬ hiá»‡u suáº¥t cá»§a há»‡ thá»‘ng.\nTÄƒng cÆ°á»ng kháº£ nÄƒng chá»‹u lá»—i: Consistent Hashing giÃºp phÃ¢n phá»‘i cÃ¡c pháº§n tá»­ dá»¯ liá»‡u trÃªn nhiá»u nÃºt, giÃºp tÄƒng cÆ°á»ng kháº£ nÄƒng chá»‹u lá»—i cá»§a há»‡ thá»‘ng vÃ  giáº£m thiá»ƒu rá»§i ro máº¥t dá»¯ liá»‡u trong trÆ°á»ng há»£p nÃºt bá»‹ lá»—i.\nCÃ¢n báº±ng táº£i tá»‘t hÆ¡n: Consistent Hashing cÃ³ thá»ƒ giÃºp phÃ¢n phá»‘i táº£i trÃªn cÃ¡c nÃºt má»™t cÃ¡ch Ä‘á»“ng Ä‘á»u hÆ¡n, giÃºp cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a há»‡ thá»‘ng vÃ  giáº£m thiá»ƒu rá»§i ro cÃ¡c Ä‘iá»ƒm nÃ³ng.\nConsistent Hashing Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong cÃ¡c há»‡ thá»‘ng phÃ¢n tÃ¡n khÃ¡c nhau, bao gá»“m:\nCÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¢n tÃ¡n: Consistent Hashing Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c cÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¢n tÃ¡n Ä‘á»ƒ phÃ¢n phá»‘i cÃ¡c pháº§n tá»­ dá»¯ liá»‡u trÃªn nhiá»u nÃºt vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a há»‡ thá»‘ng.\nHá»‡ thá»‘ng lÆ°u trá»¯ Ä‘á»‡m: Consistent Hashing Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c há»‡ thá»‘ng lÆ°u trá»¯ Ä‘á»‡m Ä‘á»ƒ phÃ¢n phá»‘i cÃ¡c pháº§n tá»­ Ä‘á»‡m trÃªn nhiá»u nÃºt vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a há»‡ thá»‘ng.\nMáº¡ng lÆ°á»›i phÃ¢n phá»‘i ná»™i dung (CDN): Consistent Hashing Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c máº¡ng lÆ°á»›i phÃ¢n phá»‘i ná»™i dung Ä‘á»ƒ phÃ¢n phá»‘i ná»™i dung trÃªn nhiá»u nÃºt vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a há»‡ thá»‘ng.\nHá»‡ thá»‘ng lÆ°u trá»¯ Ä‘Ã¡m mÃ¢y: Consistent Hashing Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c há»‡ thá»‘ng lÆ°u trá»¯ Ä‘Ã¡m mÃ¢y Ä‘á»ƒ phÃ¢n phá»‘i cÃ¡c pháº§n tá»­ dá»¯ liá»‡u trÃªn nhiá»u nÃºt vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a há»‡ thá»‘ng.\nTÃ³m láº¡i, Consistent Hashing lÃ  má»™t ká»¹ thuáº­t máº¡nh máº½ giÃºp cÃ¡c há»‡ thá»‘ng phÃ¢n tÃ¡n phÃ¢n phá»‘i cÃ¡c khÃ³a hoáº·c pháº§n tá»­ dá»¯ liá»‡u trÃªn nhiá»u nÃºt má»™t cÃ¡ch hiá»‡u quáº£, giáº£m thiá»ƒu sá»‘ lÆ°á»£ng cÃ¡c phÃ©p Ã¡nh xáº¡ láº¡i cáº§n thiáº¿t khi thÃªm hoáº·c xÃ³a nÃºt, vÃ  cáº£i thiá»‡n kháº£ nÄƒng má»Ÿ rá»™ng, kháº£ nÄƒng chá»‹u lá»—i vÃ  cÃ¢n báº±ng táº£i cá»§a há»‡ thá»‘ng.\nImplement Consistent Hashing Äá»ƒ triá»ƒn khai má»™t há»‡ thá»‘ng sá»­ dá»¥ng consistent hasing, chÃºng ta cáº§n xÃ¡c Ä‘á»‹nh 7 bÆ°á»›c sau\nBÆ°á»›c 1: Chá»n hÃ m bÄƒm\nChá»n má»™t hÃ m bÄƒm táº¡o ra má»™t dáº£i giÃ¡ trá»‹ bÄƒm phÃ¢n bá»‘ Ä‘á»u. CÃ¡c lá»±a chá»n phá»• biáº¿n bao gá»“m MD5, SHA-1 hoáº·c SHA-256. BÆ°á»›c 2: Äá»‹nh nghÄ©a vÃ²ng bÄƒm\nBiá»ƒu diá»…n dáº£i giÃ¡ trá»‹ bÄƒm nhÆ° má»™t vÃ²ng.\nVÃ²ng nÃ y nÃªn bao phá»§ toÃ n bá»™ dáº£i giÃ¡ trá»‹ bÄƒm cÃ³ thá»ƒ vÃ  Ä‘Æ°á»£c phÃ¢n bá»‘ Ä‘á»u.\nBÆ°á»›c 3: GÃ¡n nÃºt vÃ o vÃ²ng\nGÃ¡n má»—i nÃºt trong há»‡ thá»‘ng má»™t vá»‹ trÃ­ trÃªn vÃ²ng bÄƒm.\nÄiá»u nÃ y thÆ°á»ng Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng cÃ¡ch bÄƒm Ä‘á»‹nh danh cá»§a nÃºt báº±ng hÃ m bÄƒm Ä‘Ã£ chá»n.\nBÆ°á»›c 4: Ãnh xáº¡ khÃ³a\nKhi cáº§n lÆ°u trá»¯ hoáº·c truy xuáº¥t má»™t khÃ³a, bÄƒm khÃ³a báº±ng hÃ m bÄƒm Ä‘Ã£ chá»n Ä‘á»ƒ thu Ä‘Æ°á»£c giÃ¡ trá»‹ bÄƒm.\nTÃ¬m vá»‹ trÃ­ trÃªn vÃ²ng bÄƒm nÆ¡i giÃ¡ trá»‹ bÄƒm rÆ¡i vÃ o.\nÄi theo chiá»u kim Ä‘á»“ng há»“ trÃªn vÃ²ng Ä‘á»ƒ tÃ¬m nÃºt Ä‘áº§u tiÃªn gáº·p pháº£i. NÃºt nÃ y trá»Ÿ thÃ nh nÃºt sá»Ÿ há»¯u khÃ³a.\nBÆ°á»›c 5: ThÃªm nÃºt\nKhi má»™t nÃºt má»›i Ä‘Æ°á»£c thÃªm vÃ o, tÃ­nh toÃ¡n vá»‹ trÃ­ cá»§a nÃ³ trÃªn vÃ²ng bÄƒm báº±ng hÃ m bÄƒm.\nXÃ¡c Ä‘á»‹nh dáº£i khÃ³a sáº½ Ä‘Æ°á»£c sá»Ÿ há»¯u bá»Ÿi nÃºt má»›i. Äiá»u nÃ y thÆ°á»ng liÃªn quan Ä‘áº¿n viá»‡c tÃ¬m nÃºt tiá»n nhiá»‡m trÃªn vÃ²ng.\nCáº­p nháº­t vÃ²ng Ä‘á»ƒ bao gá»“m nÃºt má»›i vÃ  Ã¡nh xáº¡ láº¡i cÃ¡c khÃ³a bá»‹ áº£nh hÆ°á»Ÿng Ä‘áº¿n nÃºt má»›i.\nBÆ°á»›c 6: XÃ³a nÃºt\nKhi má»™t nÃºt bá»‹ xÃ³a, xÃ¡c Ä‘á»‹nh vá»‹ trÃ­ cá»§a nÃ³ trÃªn vÃ²ng bÄƒm.\nXÃ¡c Ä‘á»‹nh dáº£i khÃ³a sáº½ bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi viá»‡c xÃ³a nÃºt. Äiá»u nÃ y thÆ°á»ng liÃªn quan Ä‘áº¿n viá»‡c tÃ¬m nÃºt káº¿ tiáº¿p trÃªn vÃ²ng.\nCáº­p nháº­t vÃ²ng Ä‘á»ƒ loáº¡i trá»« nÃºt Ä‘Ã£ xÃ³a vÃ  Ã¡nh xáº¡ láº¡i cÃ¡c khÃ³a bá»‹ áº£nh hÆ°á»Ÿng Ä‘áº¿n nÃºt káº¿ tiáº¿p.\nBÆ°á»›c 7: CÃ¢n báº±ng táº£i\nÄá»‹nh ká»³ kiá»ƒm tra táº£i trÃªn má»—i nÃºt báº±ng cÃ¡ch theo dÃµi sá»‘ lÆ°á»£ng khÃ³a nÃ³ sá»Ÿ há»¯u.\nNáº¿u cÃ³ sá»± máº¥t cÃ¢n báº±ng, hÃ£y xem xÃ©t viá»‡c phÃ¢n phá»‘i láº¡i má»™t sá»‘ khÃ³a Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± phÃ¢n bá»‘ Ä‘á»u hÆ¡n.\nDÆ°á»›i dÃ¢y lÃ  code golang , coi nhÆ° lÃ  demo example 7 bÆ°á»›c trÃªn\n1 2package main 3 4import ( 5\t\u0026#34;crypto/md5\u0026#34; 6\t\u0026#34;fmt\u0026#34; 7\t\u0026#34;sort\u0026#34; 8\t\u0026#34;strconv\u0026#34; 9\t\u0026#34;sync\u0026#34; 10) 11 12type ConsistentHashRing struct { 13\tring map[uint64]string 14\tsortedKeys []uint64 15\treplicas int 16\tmu sync.RWMutex 17} 18 19func NewConsistentHashRing(replicas int) *ConsistentHashRing { 20\treturn \u0026amp;ConsistentHashRing{ 21\tring: make(map[uint64]string), 22\tsortedKeys: make([]uint64, 0), 23\treplicas: replicas, 24\t} 25} 26 27// BÆ°á»›c 1: Chá»n hÃ m bÄƒm, á»Ÿ Ä‘Ã¢y dÃ¹ng md5. 28 29func (chr *ConsistentHashRing) getHash(value string) uint64 { 30\thash := md5.Sum([]byte(value)) 31\tvar hashValue uint64 32\tfor i := 0; i \u0026lt; 8; i++ { 33\thashValue = (hashValue \u0026lt;\u0026lt; 8) | uint64(hash[i]) 34\t} 35\treturn hashValue 36} 37 38// BÆ°á»›c 3: GÃ¡n nÃºt vÃ o vÃ²ng. 39func (chr *ConsistentHashRing) assignNodesToRing() { 40\tsort.Slice(chr.sortedKeys, func(i, j int) bool { 41\treturn chr.sortedKeys[i] \u0026lt; chr.sortedKeys[j] 42\t}) 43} 44 45// BÆ°á»›c 5: ThÃªm nÃºt 46func (chr *ConsistentHashRing) AddNode(node string) { 47\tfor i := 0; i \u0026lt; chr.replicas; i++ { 48\treplicaKey := chr.getHash(node + \u0026#34;_\u0026#34; + strconv.Itoa(i)) 49\tchr.ring[replicaKey] = node 50\tchr.sortedKeys = append(chr.sortedKeys, replicaKey) 51 52\tfmt.Printf(\u0026#34;Added node: %s with hash: %d on replica %d\\n\u0026#34;, node, replicaKey, i) 53\t} 54\tchr.assignNodesToRing() 55} 56 57// BÆ°á»›c 6: XÃ³a nÃºt 58func (chr *ConsistentHashRing) RemoveNode(node string) { 59\tfor i := 0; i \u0026lt; chr.replicas; i++ { 60\treplicaKey := chr.getHash(node + \u0026#34;_\u0026#34; + strconv.Itoa(i)) 61\tdelete(chr.ring, replicaKey) 62\tchr.sortedKeys = removeUint64Slice(chr.sortedKeys, replicaKey) 63\t} 64} 65 66// BÆ°á»›c 4: Ãnh xáº¡ khÃ³a 67func (chr *ConsistentHashRing) KeyMap(key string) string { 68\tchr.mu.RLock() 69\tdefer chr.mu.RUnlock() 70 71\thashValue := chr.getHash(key) 72\tindex := sort.Search(len(chr.sortedKeys), func(i int) bool { 73\treturn chr.sortedKeys[i] \u0026gt;= hashValue 74\t}) 75 76\tif index == len(chr.sortedKeys) { 77\t// Wrap around to the beginning of the ring 78\treturn chr.ring[chr.sortedKeys[0]] 79\t} 80 81\treturn chr.ring[chr.sortedKeys[index]] 82} 83 84func removeUint64Slice(s []uint64, e uint64) []uint64 { 85\tfor i, a := range s { 86\tif a == e { 87\treturn append(s[:i], s[i+1:]...) 88\t} 89\t} 90\treturn s 91} 92 93// BÆ°á»›c 7: CÃ¢n báº±ng táº£i 94// LoadBalancing kiá»ƒm tra táº£i trÃªn má»—i nÃºt vÃ  phÃ¢n phá»‘i láº¡i khÃ³a náº¿u cáº§n 95func (chr *ConsistentHashRing) LoadBalancing() { 96\tchr.mu.Lock() 97\tdefer chr.mu.Unlock() 98 99\tnodeCount := make(map[string]int) 100\tfor _, node := range chr.ring { 101\tnodeCount[node]++ 102\t} 103 104\tavgCount := len(chr.ring) / len(nodeCount) 105\tfor node, count := range nodeCount { 106\tif count \u0026gt; avgCount { 107\t// Node nÃ y cÃ³ táº£i quÃ¡ cao, phÃ¢n phá»‘i láº¡i khÃ³a 108\tfmt.Printf(\u0026#34;Node %s cÃ³ táº£i quÃ¡ cao, phÃ¢n phá»‘i láº¡i khÃ³a\\n\u0026#34;, node) 109\t// ... 110\t} 111\t} 112} 113 114func (chr *ConsistentHashRing) PrintMap(key string) { 115\tnode := chr.KeyMap(key) 116 117\tfmt.Printf(\u0026#34;The key \u0026#39;%s\u0026#39; is mapped to node: %s\\n\u0026#34;, key, node) 118} 119func main() { 120\thashRing := NewConsistentHashRing(3) 121 122\t// Add nodes to the ring 123\thashRing.AddNode(\u0026#34;sw_hn\u0026#34;) 124\thashRing.AddNode(\u0026#34;sw_dn\u0026#34;) 125\thashRing.AddNode(\u0026#34;sw_hcm\u0026#34;) 126 127\t// // Get the node for a key 128\t// key := \u0026#34;TÃ¡c giáº£ Pháº¡m Duy TÃ¹ng\u0026#34; 129\thashRing.PrintMap(\u0026#34;TÃ¡c giáº£ Pháº¡m Duy TÃ¹ng\u0026#34;) 130\thashRing.PrintMap(\u0026#34;NgÃ y cáº­p nháº­t 08/09/2024\u0026#34;) 131\thashRing.PrintMap(\u0026#34;NgÃ y mÆ°a bÃ£o\u0026#34;) 132\thashRing.PrintMap(\u0026#34;Viáº¿t vÃ o ngÃ y bÃ£o, TÃªn cÆ¡n bÃ£o lÃ  Yagi\u0026#34;) 133\thashRing.PrintMap(\u0026#34;TÃ¡c giáº£ Pháº¡m Duy TÃ¹ng, Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t\u0026#34;) 134\thashRing.LoadBalancing() 135 136} LÆ°u Ã½: code demo thÃ´i, xÃ i hÃ m hash Ä‘Æ¡n giáº£n, vÃ  sá»­ dá»¥ng tÃ¬m kiáº¿m nhá»‹ phÃ¢n Ä‘á»ƒ tÃ¬m vá»‹ trÃ­ cá»§a pháº§n tá»­ trong vÃ²ng. Thá»±c táº¿ thÃ¬ cháº¯c khÃ´ng ai chÆ¡i máº¥y hÃ m nÃ y :)\nKáº¿t quáº£:\n1\u0026gt;\u0026gt;\u0026gt;\u0026gt; go run consistent_hashing.go 2 3Added node: sw_hn with hash: 17429720091564777933 on replica 0 4Added node: sw_hn with hash: 6206559145603051050 on replica 1 5Added node: sw_hn with hash: 501148381563080863 on replica 2 6Added node: sw_dn with hash: 10372921504992544131 on replica 0 7Added node: sw_dn with hash: 10352104123016491672 on replica 1 8Added node: sw_dn with hash: 4947674849506040391 on replica 2 9Added node: sw_hcm with hash: 13712729030455601798 on replica 0 10Added node: sw_hcm with hash: 13299855957139837304 on replica 1 11Added node: sw_hcm with hash: 15146544336749671394 on replica 2 12The key \u0026#39;TÃ¡c giáº£ Pháº¡m Duy TÃ¹ng\u0026#39; is mapped to node: sw_dn 13The key \u0026#39;NgÃ y cáº­p nháº­t 08/09/2024\u0026#39; is mapped to node: sw_dn 14The key \u0026#39;NgÃ y mÆ°a bÃ£o\u0026#39; is mapped to node: sw_dn 15The key \u0026#39;Viáº¿t vÃ o ngÃ y bÃ£o, TÃªn cÆ¡n bÃ£o lÃ  Yagi\u0026#39; is mapped to node: sw_hn 16The key \u0026#39;TÃ¡c giáº£ Pháº¡m Duy TÃ¹ng, Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t\u0026#39; is mapped to node: sw_dn Æ¯u vÃ  nhÆ°á»£c Ä‘iá»ƒm cá»§a Consistent Hashing Æ¯u Ä‘iá»ƒm cá»§a viá»‡c sá»­ dá»¥ng Consistent Hashing\nCÃ¢n báº±ng táº£i: Consistent Hashing giÃºp phÃ¢n phá»‘i táº£i trá»ng cá»§a máº¡ng Ä‘á»u giá»¯a cÃ¡c nÃºt, báº£o vá»‡ hiá»‡u suáº¥t vÃ  kháº£ nÄƒng Ä‘Ã¡p á»©ng cá»§a há»‡ thá»‘ng ngay cáº£ khi lÆ°á»£ng dá»¯ liá»‡u tÄƒng lÃªn vÃ  thay Ä‘á»•i theo thá»i gian.\nKháº£ nÄƒng má»Ÿ rá»™ng: Consistent Hashing ráº¥t linh hoáº¡t vÃ  cÃ³ thá»ƒ thÃ­ch nghi vá»›i sá»± thay Ä‘á»•i cá»§a sá»‘ lÆ°á»£ng nÃºt hoáº·c lÆ°á»£ng dá»¯ liá»‡u Ä‘Æ°á»£c xá»­ lÃ½ mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t cá»§a toÃ n bá»™ há»‡ thá»‘ng.\nTá»‘i thiá»ƒu hoÃ¡ sá»‘ lÆ°á»£ng Ã¡nh xáº¡ láº¡i: Consistent Hashing giáº£m thiá»ƒu sá»‘ lÆ°á»£ng khÃ³a cáº§n Ã¡nh xáº¡ láº¡i khi thÃªm hoáº·c xÃ³a nÃºt, Ä‘áº£m báº£o ráº±ng há»‡ thá»‘ng luÃ´n á»•n Ä‘á»‹nh vÃ  nháº¥t quÃ¡n ngay cáº£ khi máº¡ng thay Ä‘á»•i theo thá»i gian.\nTÄƒng kháº£ nÄƒng chá»‹u lá»—i: Consistent Hashing giÃºp dá»¯ liá»‡u luÃ´n kháº£ dá»¥ng vÃ  cáº­p nháº­t, ngay cáº£ trong trÆ°á»ng há»£p nÃºt bá»‹ lá»—i. Kháº£ nÄƒng sao chÃ©p khÃ³a trÃªn nhiá»u nÃºt vÃ  Ã¡nh xáº¡ láº¡i khÃ³a Ä‘áº¿n nÃºt khÃ¡c trong trÆ°á»ng há»£p lá»—i giÃºp tÄƒng cÆ°á»ng Ä‘á»™ á»•n Ä‘á»‹nh vÃ  tin cáº­y cá»§a toÃ n bá»™ há»‡ thá»‘ng.\nÄÆ¡n giáº£n hÃ³a hoáº¡t Ä‘á»™ng: Consistent Hashing giÃºp Ä‘Æ¡n giáº£n hÃ³a quÃ¡ trÃ¬nh thÃªm hoáº·c xÃ³a nÃºt khá»i máº¡ng, giÃºp dá»… dÃ ng quáº£n lÃ½ vÃ  duy trÃ¬ há»‡ thá»‘ng phÃ¢n tÃ¡n lá»›n.\nNhÆ°á»£c Ä‘iá»ƒm cá»§a viá»‡c sá»­ dá»¥ng Consistent Hashing\nHÃ m bÄƒm: Hiá»‡u suáº¥t cá»§a Consistent Hashing phá»¥ thuá»™c vÃ o viá»‡c sá»­ dá»¥ng hÃ m bÄƒm phÃ¹ há»£p. HÃ m bÄƒm pháº£i táº¡o ra giÃ¡ trá»‹ duy nháº¥t cho má»—i khÃ³a vÃ  pháº£i lÃ  xÃ¡c Ä‘á»‹nh Ä‘á»ƒ cÃ³ hiá»‡u quáº£. Sá»± phá»©c táº¡p cá»§a hÃ m bÄƒm cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t vÃ  hiá»‡u quáº£ cá»§a toÃ n bá»™ há»‡ thá»‘ng.\nTá»‘n kÃ©m hiá»‡u suáº¥t: Viá»‡c sá»­ dá»¥ng Consistent Hashing cÃ³ thá»ƒ dáº«n Ä‘áº¿n má»™t sá»‘ tá»‘n kÃ©m hiá»‡u suáº¥t do cáº§n pháº£i sá»­ dá»¥ng tÃ i nguyÃªn tÃ­nh toÃ¡n Ä‘á»ƒ Ã¡nh xáº¡ khÃ³a Ä‘áº¿n nÃºt, sao chÃ©p khÃ³a vÃ  Ã¡nh xáº¡ láº¡i khÃ³a trong trÆ°á»ng há»£p thÃªm hoáº·c xÃ³a nÃºt.\nThiáº¿u linh hoáº¡t: Trong má»™t sá»‘ trÆ°á»ng há»£p, giá»›i háº¡n cá»‘ Ä‘á»‹nh cá»§a Consistent Hashing cÃ³ thá»ƒ háº¡n cháº¿ kháº£ nÄƒng cá»§a há»‡ thá»‘ng Ä‘á»ƒ thÃ­ch nghi vá»›i sá»± thay Ä‘á»•i cá»§a nhu cáº§u hoáº·c Ä‘iá»u kiá»‡n máº¡ng.\nSá»­ dá»¥ng tÃ i nguyÃªn cao: Trong má»™t sá»‘ trÆ°á»ng há»£p, viá»‡c sá»­ dá»¥ng Consistent Hashing cÃ³ thá»ƒ dáº«n Ä‘áº¿n sá»­ dá»¥ng tÃ i nguyÃªn cao khi thÃªm hoáº·c xÃ³a nÃºt khá»i máº¡ng, Ä‘iá»u nÃ y cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t vÃ  hiá»‡u quáº£ cá»§a toÃ n bá»™ há»‡ thá»‘ng.\nPhá»©c táº¡p cá»§a quáº£n lÃ½: Viá»‡c quáº£n lÃ½ vÃ  duy trÃ¬ há»‡ thá»‘ng sá»­ dá»¥ng Consistent Hashing cÃ³ thá»ƒ phá»©c táº¡p vÃ  Ä‘Ã²i há»i chuyÃªn mÃ´n vÃ  ká»¹ nÄƒng Ä‘áº·c biá»‡t.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t. Xin cáº£m Æ¡n vÃ  háº¹n gáº·p láº¡i. BÃ i sau sáº½ nÃ³i vá» Distributed Hash Tables\n","date":"Sep 8, 2024","img":"https://unsplash.it/1920/1080?image=2","permalink":"/blog/2024-09-05-system-design-top-10-interview-consistent-hashing/","series":null,"tags":["System Design"],"title":"Top 10 Thuáº­t ToÃ¡n System Design CÃ¡c Báº¡n NÃªn Biáº¿t VÃ  ThÆ°á»ng ÄÆ°á»£c Há»i Trong Phá»ng Váº¥n - Top 1 Consistent Hashing"},{"categories":null,"content":" Netflix: PhÃ¡t Triá»ƒn Kháº¯c Phá»¥c Sá»± Cá»‘ Big Data Picnic: Cáº£i Thiá»‡n Truy Xuáº¥t TÃ¬m Kiáº¿m Uber: CÃ¡ NhÃ¢n HÃ³a ThÃ´ng Tin NgoÃ i á»¨ng Dá»¥ng GitLab: XÃ¡c Thá»±c vÃ  Kiá»ƒm Tra MÃ´ HÃ¬nh AI LinkedIn: Káº¿t Ná»‘i ThÃ nh ViÃªn vá»›i Sáº£n Pháº©m Cao Cáº¥p Swiggy: Äá» Xuáº¥t Sáº£n Pháº©m Cho NgÆ°á»i DÃ¹ng Má»›i Careem: Giáº£m Gian Láº­n Báº±ng Tiá»n Táº¡m á»¨ng Slack: AI Cho Tin Nháº¯n Báº£o Máº­t Trong Doanh Nghiá»‡p Picnic: Há»— Trá»£ YÃªu Cáº§u KhÃ¡ch HÃ ng Foodpanda: Tá»‘i Æ¯u HÃ³a Cung vÃ  Cáº§u Etsy: TÃ¬m Kiáº¿m vÃ  Äá» Xuáº¥t Báº±ng HÃ¬nh áº¢nh LinkedIn: PhÃ¡t Hiá»‡n HÃ¬nh áº¢nh Do AI Táº¡o Ra Discord: CÃ¡c TrÆ°á»ng Há»£p Sá»­ Dá»¥ng AI Táº¡o Sinh Pinterest: Cáº£i Thiá»‡n Hiá»‡u Suáº¥t Quáº£ng CÃ¡o Expedia: TÃ¬m Kiáº¿m Ngá»¯ NghÄ©a Cho Du Lá»‹ch 15 VÃ­ dá»¥ Thá»±c Táº¿ vá» á»¨ng Dá»¥ng cá»§a LLM Trong CÃ¡c NgÃ nh CÃ´ng Nghiá»‡p KhÃ¡c Nhau\nBá»Ÿi Sana Hassan - 3 ThÃ¡ng 7, 2024\nTrong tháº¿ giá»›i cÃ´ng nghá»‡ Ä‘áº§y biáº¿n Ä‘á»™ng, cÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n (LLM) Ä‘Ã£ trá»Ÿ nÃªn quan trá»ng trong nhiá»u ngÃ nh cÃ´ng nghiá»‡p khÃ¡c nhau. Kháº£ nÄƒng xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, táº¡o ná»™i dung vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u cá»§a chÃºng Ä‘Ã£ má»Ÿ Ä‘Æ°á»ng cho nhiá»u á»©ng dá»¥ng. HÃ£y cÃ¹ng khÃ¡m phÃ¡ 15 vÃ­ dá»¥ chi tiáº¿t vá» cÃ¡ch cÃ¡c cÃ´ng ty táº­n dá»¥ng LLM trong cÃ¡c tÃ¬nh huá»‘ng thá»±c táº¿.\nNetflix: PhÃ¡t Triá»ƒn Kháº¯c Phá»¥c Sá»± Cá»‘ Big Data Netflix Ä‘Ã£ chuyá»ƒn tá»« cÃ¡c bá»™ phÃ¢n loáº¡i dá»±a trÃªn quy táº¯c truyá»n thá»‘ng sang cÃ¡c há»‡ thá»‘ng kháº¯c phá»¥c tá»± Ä‘á»™ng dá»±a trÃªn há»c mÃ¡y Ä‘á»ƒ xá»­ lÃ½ cÃ¡c cÃ´ng viá»‡c big data bá»‹ lá»—i. Sá»± chuyá»ƒn Ä‘á»•i nÃ y Ä‘Ã£ cho phÃ©p Netflix tá»± Ä‘á»™ng phÃ¡t hiá»‡n, cháº©n Ä‘oÃ¡n vÃ  sá»­a cÃ¡c váº¥n Ä‘á» trong cÃ¡c quy trÃ¬nh dá»¯ liá»‡u cá»§a mÃ¬nh, giáº£m Ä‘Ã¡ng ká»ƒ thá»i gian ngá»«ng hoáº¡t Ä‘á»™ng vÃ  Ä‘áº£m báº£o dá»‹ch vá»¥ phÃ¡t trá»±c tuyáº¿n liá»n máº¡ch. LLM giÃºp hiá»ƒu dá»¯ liá»‡u log, xÃ¡c Ä‘á»‹nh cÃ¡c máº«u lá»—i vÃ  Ä‘á» xuáº¥t hoáº·c thá»±c hiá»‡n cÃ¡c biá»‡n phÃ¡p sá»­a chá»¯a, nÃ¢ng cao hiá»‡u quáº£ vÃ  Ä‘á»™ tin cáº­y cá»§a hoáº¡t Ä‘á»™ng.\nPicnic: Cáº£i Thiá»‡n Truy Xuáº¥t TÃ¬m Kiáº¿m Picnic, má»™t dá»‹ch vá»¥ giao hÃ ng táº¡p hÃ³a trá»±c tuyáº¿n, Ä‘Ã£ tÃ­ch há»£p LLM Ä‘á»ƒ cáº£i thiá»‡n sá»± liÃªn quan cá»§a káº¿t quáº£ tÃ¬m kiáº¿m cho cÃ¡c danh sÃ¡ch sáº£n pháº©m. Viá»‡c sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n cho phÃ©p Picnic hiá»ƒu rÃµ hÆ¡n cÃ¡c truy váº¥n cá»§a ngÆ°á»i dÃ¹ng vÃ  ngá»¯ cáº£nh, mang láº¡i káº¿t quáº£ tÃ¬m kiáº¿m chÃ­nh xÃ¡c vÃ  cÃ¡ nhÃ¢n hÃ³a hÆ¡n. Sá»± cáº£i thiá»‡n nÃ y nÃ¢ng cao tráº£i nghiá»‡m khÃ¡ch hÃ ng vÃ  tÄƒng tá»· lá»‡ chuyá»ƒn Ä‘á»•i báº±ng cÃ¡ch giÃºp khÃ¡ch hÃ ng dá»… dÃ ng tÃ¬m tháº¥y sáº£n pháº©m há» cáº§n.\nUber: CÃ¡ NhÃ¢n HÃ³a ThÃ´ng Tin NgoÃ i á»¨ng Dá»¥ng Há»‡ thá»‘ng Ä‘á» xuáº¥t tiÃªn tiáº¿n cá»§a Uber cÃ¡ nhÃ¢n hÃ³a thÃ´ng tin ngoÃ i á»©ng dá»¥ng Ä‘á»ƒ tÄƒng cÆ°á»ng sá»± tÆ°Æ¡ng tÃ¡c cá»§a ngÆ°á»i dÃ¹ng. Báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n Ä‘á» xuáº¥t dá»±a trÃªn LLM tinh vi, Uber cÃ³ thá»ƒ Ä‘iá»u chá»‰nh thÃ´ng bÃ¡o vÃ  gá»£i Ã½ theo sá»Ÿ thÃ­ch vÃ  hÃ nh vi cá»§a tá»«ng ngÆ°á»i dÃ¹ng. Sá»± cÃ¡ nhÃ¢n hÃ³a nÃ y má»Ÿ rá»™ng ra ngoÃ i á»©ng dá»¥ng, Ä‘áº£m báº£o ngÆ°á»i dÃ¹ng nháº­n Ä‘Æ°á»£c cÃ¡c cáº­p nháº­t vÃ  Æ°u Ä‘Ã£i liÃªn quan qua email, SMS vÃ  cÃ¡c kÃªnh khÃ¡c, tá»« Ä‘Ã³ cáº£i thiá»‡n sá»± duy trÃ¬ vÃ  sá»± hÃ i lÃ²ng cá»§a ngÆ°á»i dÃ¹ng.\nGitLab: XÃ¡c Thá»±c vÃ  Kiá»ƒm Tra MÃ´ HÃ¬nh AI GitLab Ä‘Ã£ phÃ¡t triá»ƒn GitLab Duo, má»™t ná»n táº£ng xÃ¡c thá»±c vÃ  kiá»ƒm tra cÃ¡c káº¿t quáº£ do AI táº¡o ra. SÃ¡ng kiáº¿n nÃ y sá»­ dá»¥ng LLM Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng, Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ä‘á»™ tin cáº­y cá»§a cÃ¡c mÃ´ hÃ¬nh AI á»Ÿ quy mÃ´ lá»›n. GitLab Duo giÃºp xÃ¡c Ä‘á»‹nh cÃ¡c thiÃªn vá»‹ tiá»m áº©n, lá»—i vÃ  cÃ¡c khu vá»±c cáº§n cáº£i thiá»‡n trong cÃ¡c mÃ´ hÃ¬nh AI, Ä‘áº£m báº£o ráº±ng cÃ¡c mÃ´ hÃ¬nh triá»ƒn khai Ä‘áº¡t tiÃªu chuáº©n hiá»‡u suáº¥t vÃ  Ä‘á»™ tin cáº­y cao. Quy trÃ¬nh kiá»ƒm tra nghiÃªm ngáº·t nÃ y ráº¥t quan trá»ng Ä‘á»ƒ duy trÃ¬ niá»m tin vÃ o cÃ¡c tÃ­nh nÄƒng do AI Ä‘iá»u khiá»ƒn.\nLinkedIn: Káº¿t Ná»‘i ThÃ nh ViÃªn vá»›i Sáº£n Pháº©m Cao Cáº¥p LinkedIn sá»­ dá»¥ng LLM Ä‘á»ƒ Ä‘á» xuáº¥t cÃ¡c sáº£n pháº©m cao cáº¥p phÃ¹ há»£p cho ngÆ°á»i dÃ¹ng. Báº±ng cÃ¡ch phÃ¢n tÃ­ch dá»¯ liá»‡u ngÆ°á»i dÃ¹ng, bao gá»“m lá»‹ch sá»­ cÃ´ng viá»‡c, sá»Ÿ thÃ­ch vÃ  mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng, há»‡ thá»‘ng Ä‘á» xuáº¥t cá»§a LinkedIn cÃ³ thá»ƒ káº¿t ná»‘i thÃ nh viÃªn vá»›i cÃ¡c dá»‹ch vá»¥ vÃ  sáº£n pháº©m cao cáº¥p phÃ¹ há»£p nháº¥t vá»›i nhu cáº§u cá»§a há». CÃ¡ch tiáº¿p cáº­n cÃ³ má»¥c tiÃªu nÃ y giÃºp LinkedIn nÃ¢ng cao sá»± hÃ i lÃ²ng cá»§a ngÆ°á»i dÃ¹ng vÃ  thÃºc Ä‘áº©y Ä‘Äƒng kÃ½ vÃ o cÃ¡c dá»‹ch vá»¥ cao cáº¥p cá»§a mÃ¬nh.\nSwiggy: Äá» Xuáº¥t Sáº£n Pháº©m Cho NgÆ°á»i DÃ¹ng Má»›i Swiggy, má»™t ná»n táº£ng giao Ä‘á»“ Äƒn hÃ ng Ä‘áº§u, sá»­ dá»¥ng há»c táº­p liÃªn miá»n phÃ¢n cáº¥p Ä‘á»ƒ cung cáº¥p cÃ¡c Ä‘á» xuáº¥t sáº£n pháº©m cho ngÆ°á»i dÃ¹ng má»›i. Báº±ng cÃ¡ch phÃ¢n tÃ­ch dá»¯ liá»‡u tá»« cÃ¡c miá»n khÃ¡c nhau vÃ  há»c há»i tá»« cÃ¡c tÆ°Æ¡ng tÃ¡c cá»§a ngÆ°á»i dÃ¹ng, há»‡ thá»‘ng Ä‘á» xuáº¥t cá»§a Swiggy cÃ³ thá»ƒ Ä‘Æ°a ra cÃ¡c gá»£i Ã½ cÃ¡ nhÃ¢n hÃ³a phÃ¹ há»£p vá»›i sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng má»›i. CÃ¡ch tiáº¿p cáº­n nÃ y hiá»‡u quáº£ trong viá»‡c tiáº¿p cáº­n vÃ  giá»¯ chÃ¢n khÃ¡ch hÃ ng má»›i.\nCareem: Giáº£m Gian Láº­n Báº±ng Tiá»n Táº¡m á»¨ng Careem, má»™t dá»‹ch vá»¥ gá»i xe, sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y Ä‘á»ƒ giáº£m rá»§i ro gian láº­n thÃ´ng qua cÃ¡c ká»¹ thuáº­t tiá»n táº¡m á»©ng. Báº±ng cÃ¡ch Ã¡p dá»¥ng cÃ¡c khoáº£n giá»¯ táº¡m thá»i trÃªn cÃ¡c giao dá»‹ch, Careem cÃ³ thá»ƒ phÃ¢n tÃ­ch cÃ¡c máº«u giao dá»‹ch vÃ  Ä‘Ã¡nh dáº¥u cÃ¡c hoáº¡t Ä‘á»™ng Ä‘Ã¡ng ngá» theo thá»i gian thá»±c. CÆ¡ cháº¿ phÃ¡t hiá»‡n gian láº­n chá»§ Ä‘á»™ng nÃ y, Ä‘Æ°á»£c há»— trá»£ bá»Ÿi LLM, giÃºp giáº£m cÃ¡c vá»¥ gian láº­n, báº£o vá»‡ cÃ´ng ty vÃ  ngÆ°á»i dÃ¹ng khá»i cÃ¡c tá»•n tháº¥t tiá»m áº©n.\nSlack: AI Cho Tin Nháº¯n Báº£o Máº­t Trong Doanh Nghiá»‡p Slack Ä‘Ã£ phÃ¡t triá»ƒn cÃ¡c kháº£ nÄƒng AI Ä‘á»ƒ nÃ¢ng cao báº£o máº­t vÃ  riÃªng tÆ° cho tin nháº¯n trong doanh nghiá»‡p. Sá»­ dá»¥ng LLM, cÃ¡c tÃ­nh nÄƒng AI cá»§a Slack cÃ³ thá»ƒ xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch tin nháº¯n trong khi Ä‘áº£m báº£o tiÃªu chuáº©n cao vá» báº£o máº­t vÃ  quyá»n riÃªng tÆ°. CÃ¡c tÃ­nh nÄƒng nÃ y bao gá»“m tÃ³m táº¯t tin nháº¯n tá»± Ä‘á»™ng, tráº£ lá»i thÃ´ng minh vÃ  Ä‘á» xuáº¥t theo ngá»¯ cáº£nh Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u quáº£ giao tiáº¿p mÃ  khÃ´ng lÃ m giáº£m báº£o vá»‡ dá»¯ liá»‡u.\nPicnic: Há»— Trá»£ YÃªu Cáº§u KhÃ¡ch HÃ ng Picnic Ä‘Ã£ vÆ°á»£t qua rÃ o cáº£n ngÃ´n ngá»¯ trong há»— trá»£ khÃ¡ch hÃ ng báº±ng cÃ¡ch sá»­ dá»¥ng xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP). Báº±ng cÃ¡ch chuyá»ƒn hÆ°á»›ng yÃªu cáº§u há»— trá»£ Ä‘áº¿n cÃ¡c nhÃ¢n viÃªn phÃ¹ há»£p nháº¥t vÃ  cung cáº¥p dá»‹ch thuáº­t theo thá»i gian thá»±c, Picnic Ä‘áº£m báº£o ráº±ng khÃ¡ch hÃ ng nháº­n Ä‘Æ°á»£c sá»± há»— trá»£ ká»‹p thá»i vÃ  chÃ­nh xÃ¡c báº¥t ká»ƒ ngÃ´n ngá»¯. Há»‡ thá»‘ng há»— trá»£ dá»±a trÃªn NLP nÃ y nÃ¢ng cao cháº¥t lÆ°á»£ng dá»‹ch vá»¥ khÃ¡ch hÃ ng vÃ  giÃºp Picnic phá»¥c vá»¥ má»™t cÆ¡ sá»Ÿ khÃ¡ch hÃ ng Ä‘a dáº¡ng.\nFoodpanda: Tá»‘i Æ¯u HÃ³a Cung vÃ  Cáº§u Foodpanda sá»­ dá»¥ng há»c mÃ¡y Ä‘á»ƒ cÃ¢n báº±ng cung vÃ  cáº§u cho cÃ¡c dá»‹ch vá»¥ giao Ä‘á»“ Äƒn. Báº±ng cÃ¡ch sá»­ dá»¥ng phÃ¢n tÃ­ch dá»± Ä‘oÃ¡n vÃ  cÃ¡c thuáº­t toÃ¡n tiÃªn tiáº¿n, Foodpanda cÃ³ thá»ƒ dá»± bÃ¡o cÃ¡c máº«u nhu cáº§u vÃ  phÃ¢n bá»• tÃ i nguyÃªn. Viá»‡c tá»‘i Æ°u hÃ³a nÃ y giÃºp quáº£n lÃ½ thá»i gian giao hÃ ng, giáº£m chi phÃ­ váº­n hÃ nh vÃ  Ä‘áº£m báº£o tráº£i nghiá»‡m tá»‘t hÆ¡n cho khÃ¡ch hÃ ng vÃ  Ä‘á»‘i tÃ¡c giao hÃ ng.\nEtsy: TÃ¬m Kiáº¿m vÃ  Äá» Xuáº¥t Báº±ng HÃ¬nh áº¢nh Etsy Ä‘Ã£ triá»ƒn khai ká»¹ thuáº­t há»c biá»ƒu diá»…n vÃ  Ä‘Ã¡nh giÃ¡ báº±ng hÃ¬nh áº£nh cho tÃ¬m kiáº¿m vÃ  Ä‘á» xuáº¥t tÆ°Æ¡ng tá»±. Báº±ng cÃ¡ch táº­n dá»¥ng thá»‹ giÃ¡c mÃ¡y tÃ­nh vÃ  LLM, há»‡ thá»‘ng cá»§a Etsy cÃ³ thá»ƒ phÃ¢n tÃ­ch hÃ¬nh áº£nh sáº£n pháº©m vÃ  cung cáº¥p cho ngÆ°á»i dÃ¹ng cÃ¡c máº·t hÃ ng tÆ°Æ¡ng tá»± vá» máº·t hÃ¬nh áº£nh. TÃ­nh nÄƒng nÃ y nÃ¢ng cao tráº£i nghiá»‡m mua sáº¯m báº±ng cÃ¡ch giÃºp ngÆ°á»i dÃ¹ng dá»… dÃ ng tÃ¬m tháº¥y cÃ¡c sáº£n pháº©m phÃ¹ há»£p vá»›i sá»Ÿ thÃ­ch cá»§a há» dá»±a trÃªn cÃ¡c thuá»™c tÃ­nh hÃ¬nh áº£nh.\nLinkedIn: PhÃ¡t Hiá»‡n HÃ¬nh áº¢nh Do AI Táº¡o Ra LinkedIn Ä‘Ã£ phÃ¡t triá»ƒn cÃ¡c há»‡ thá»‘ng Ä‘á»ƒ phÃ¡t hiá»‡n hÃ¬nh áº£nh do AI táº¡o ra (deepfake). Sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n nháº­n diá»‡n hÃ¬nh áº£nh tiÃªn tiáº¿n vÃ  LLM, LinkedIn cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh vÃ  Ä‘Ã¡nh dáº¥u ná»™i dung deepfake, Ä‘áº£m báº£o tÃ­nh toÃ n váº¹n vÃ  Ä‘Ã¡ng tin cáº­y cá»§a há»“ sÆ¡ ngÆ°á»i dÃ¹ng vÃ  ná»™i dung trÃªn ná»n táº£ng. Kháº£ nÄƒng nÃ y ráº¥t quan trá»ng trong viá»‡c duy trÃ¬ má»™t mÃ´i trÆ°á»ng ngÆ°á»i dÃ¹ng an toÃ n vÃ  xÃ¡c thá»±c.\nDiscord: CÃ¡c TrÆ°á»ng Há»£p Sá»­ Dá»¥ng AI Táº¡o Sinh Discord, má»™t ná»n táº£ng giao tiáº¿p phá»• biáº¿n, Ä‘Ã£ khÃ¡m phÃ¡ nhiá»u trÆ°á»ng há»£p sá»­ dá»¥ng AI táº¡o sinh Ä‘á»ƒ tÄƒng cÆ°á»ng sá»± tÆ°Æ¡ng tÃ¡c cá»§a ngÆ°á»i dÃ¹ng. Báº±ng cÃ¡ch phÃ¡t triá»ƒn vÃ  tÃ­ch há»£p nhanh chÃ³ng cÃ¡c tÃ­nh nÄƒng AI táº¡o sinh, Discord cÃ³ thá»ƒ cung cáº¥p cho ngÆ°á»i dÃ¹ng cÃ¡c cÃ´ng cá»¥ sÃ¡ng táº¡o nhÆ° avatar do AI táº¡o ra, kiá»ƒm duyá»‡t ná»™i dung vÃ  pháº£n há»“i tá»± Ä‘á»™ng. CÃ¡c tÃ­nh nÄƒng nÃ y táº­n dá»¥ng LLM Ä‘á»ƒ cáº£i thiá»‡n tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng vÃ  thÃºc Ä‘áº©y cá»™ng Ä‘á»“ng tÆ°Æ¡ng tÃ¡c hÆ¡n.\nPinterest: Cáº£i Thiá»‡n Hiá»‡u Suáº¥t Quáº£ng CÃ¡o Pinterest Ä‘Ã£ phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh tá»‘i Æ°u hÃ³a chuyá»ƒn Ä‘á»•i quáº£ng cÃ¡o Ä‘á»ƒ nÃ¢ng cao hiá»‡u suáº¥t quáº£ng cÃ¡o. Báº±ng cÃ¡ch táº­n dá»¥ng LLM, Pinterest cÃ³ thá»ƒ phÃ¢n tÃ­ch hÃ nh vi vÃ  sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ cung cáº¥p cÃ¡c quáº£ng cÃ¡o má»¥c tiÃªu vÃ  liÃªn quan. Viá»‡c tá»‘i Æ°u hÃ³a nÃ y dáº«n Ä‘áº¿n tá»· lá»‡ chuyá»ƒn Ä‘á»•i cao hÆ¡n, tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng tá»‘t hÆ¡n vÃ  tÄƒng doanh thu cho cÃ¡c nhÃ  quáº£ng cÃ¡o trÃªn ná»n táº£ng.\nExpedia: TÃ¬m Kiáº¿m Ngá»¯ NghÄ©a Cho Du Lá»‹ch Expedia sá»­ dá»¥ng cÃ¡c biá»ƒu diá»…n cho cÃ¡c khÃ¡i niá»‡m du lá»‹ch lÆ°u trÃº Ä‘á»ƒ nÃ¢ng cao kháº£ nÄƒng tÃ¬m kiáº¿m ngá»¯ nghÄ©a. Báº±ng cÃ¡ch hiá»ƒu nghÄ©a ngá»¯ cáº£nh cá»§a cÃ¡c truy váº¥n cá»§a ngÆ°á»i dÃ¹ng, há»‡ thá»‘ng tÃ¬m kiáº¿m cá»§a Expedia cÃ³ thá»ƒ cung cáº¥p cÃ¡c káº¿t quáº£ chÃ­nh xÃ¡c vÃ  liÃªn quan hÆ¡n cho cÃ¡c khÃ¡ch sáº¡n vÃ  chá»— á»Ÿ du lá»‹ch. Chá»©c\nnÄƒng tÃ¬m kiáº¿m ngá»¯ nghÄ©a nÃ y, Ä‘Æ°á»£c há»— trá»£ bá»Ÿi LLM, cáº£i thiá»‡n tráº£i nghiá»‡m Ä‘áº·t chá»— báº±ng cÃ¡ch giÃºp ngÆ°á»i dÃ¹ng tÃ¬m tháº¥y cÃ¡c tÃ¹y chá»n tá»‘t nháº¥t dá»±a trÃªn nhu cáº§u vÃ  sá»Ÿ thÃ­ch cá»§a há».\nTÃ³m láº¡i, cÃ¡c vÃ­ dá»¥ nÃ y minh há»a tÃ¡c Ä‘á»™ng chuyá»ƒn Ä‘á»•i cá»§a LLM trÃªn nhiá»u lÄ©nh vá»±c, thÃºc Ä‘áº©y Ä‘á»•i má»›i vÃ  hiá»‡u quáº£. Khi cÃ´ng nghá»‡ LLM tiáº¿n bá»™, cÃ¡c á»©ng dá»¥ng cá»§a nÃ³ Ä‘Æ°á»£c dá»± Ä‘oÃ¡n sáº½ má»Ÿ rá»™ng, cung cáº¥p cÃ¡c giáº£i phÃ¡p phá»©c táº¡p hÆ¡n cho cÃ¡c thÃ¡ch thá»©c trong ngÃ nh. CÃ¡c cÃ´ng ty nÃªn cÃ¢n nháº¯c táº­n dá»¥ng cÃ¡c ná»n táº£ng chuyÃªn dá»¥ng nhÆ° AI Drive Pro Ä‘á»ƒ quáº£n lÃ½ vÃ  tá»‘i Æ°u hÃ³a viá»‡c triá»ƒn khai LLM cá»§a há» Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tá»‘i Æ°u.\nTham kháº£o\nhttps://www.evidentlyai.com/ml-system-design\n","date":"Jul 6, 2024","img":"https://unsplash.it/1920/1080?image=3","permalink":"/blog/2024-07-06-llm-applications-in-real/","series":null,"tags":["bigdata"],"title":"CÃ¡c á»¨ng Dá»¥ng Cá»§a LLM Trong Thá»±c Táº¿"},{"categories":null,"content":"Giá»›i thiá»‡u Hiá»‡n nay, NVIDA Ä‘ang lÃ  nhÃ  sáº£n xuáº¥t GPU hÃ ng Ä‘áº§u tháº¿ giá»›i, vÃ  cÃ¹ng vá»›i sá»± phÃ¡t triá»ƒn cá»§a cá»§a mÃ´ hÃ¬nh AI, chip NVIDIA Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng ráº£i vÃ¬ cÃ¡c tÃ­nh nÄƒng sau\n1. Hiá»‡u Suáº¥t Cao Táº­n Dá»¥ng GPU\nCUDA Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘á»ƒ táº­n dá»¥ng sá»©c máº¡nh xá»­ lÃ½ song song cá»§a GPU, cho phÃ©p thá»±c hiá»‡n hÃ ng ngÃ n tÃ¡c vá»¥ tÃ­nh toÃ¡n Ä‘á»“ng thá»i. GPU cÃ³ nhiá»u lÃµi hÆ¡n so vá»›i CPU, giÃºp tÄƒng tá»‘c Ä‘á»™ tÃ­nh toÃ¡n Ä‘Ã¡ng ká»ƒ khi xá»­ lÃ½ cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n AI vÃ  há»c sÃ¢u. Tá»‘i Æ¯u HÃ³a ToÃ¡n Há»c\nCUDA cung cáº¥p cÃ¡c thÆ° viá»‡n toÃ¡n há»c hiá»‡u suáº¥t cao nhÆ° cuBLAS, cuDNN, vÃ  cuFFT, giÃºp tá»‘i Æ°u hÃ³a cÃ¡c phÃ©p toÃ¡n ma tráº­n vÃ  phÃ©p biáº¿n Ä‘á»•i Fourier, cÃ¡c phÃ©p toÃ¡n phá»• biáº¿n trong cÃ¡c mÃ´ hÃ¬nh AI. 2. ThÆ° Viá»‡n vÃ  Há»‡ Sinh ThÃ¡i Phong PhÃº ThÆ° Viá»‡n AI\nCÃ¡c thÆ° viá»‡n há»c sÃ¢u phá»• biáº¿n nhÆ° TensorFlow, PyTorch, vÃ  MXNet Ä‘á»u cÃ³ há»— trá»£ CUDA, giÃºp dá»… dÃ ng triá»ƒn khai vÃ  tá»‘i Æ°u hÃ³a cÃ¡c mÃ´ hÃ¬nh AI trÃªn GPU. CÃ¡c thÆ° viá»‡n nÃ y tÃ­ch há»£p cháº·t cháº½ vá»›i CUDA, cung cáº¥p cÃ¡c cÃ´ng cá»¥ vÃ  API máº¡nh máº½ Ä‘á»ƒ xÃ¢y dá»±ng, huáº¥n luyá»‡n, vÃ  triá»ƒn khai cÃ¡c mÃ´ hÃ¬nh AI. Cá»™ng Äá»“ng vÃ  Há»— Trá»£\nNVIDIA cÃ³ má»™t cá»™ng Ä‘á»“ng lá»›n cÃ¡c nhÃ  phÃ¡t triá»ƒn vÃ  nhÃ  nghiÃªn cá»©u, cung cáº¥p há»— trá»£ qua cÃ¡c diá»…n Ä‘Ã n, tÃ i liá»‡u, vÃ  khÃ³a há»c trá»±c tuyáº¿n. CÃ¡c cÃ´ng cá»¥ phÃ¡t triá»ƒn nhÆ° NVIDIA CUDA Toolkit, NVIDIA Nsight, vÃ  cuDNN Debugger giÃºp dá»… dÃ ng phÃ¡t triá»ƒn vÃ  gá»¡ lá»—i á»©ng dá»¥ng AI. 3. TÃ­nh TÆ°Æ¡ng ThÃ­ch vÃ  Di Äá»™ng Pháº§n Cá»©ng TÆ°Æ¡ng ThÃ­ch\nCUDA tÆ°Æ¡ng thÃ­ch vá»›i háº§u háº¿t cÃ¡c GPU cá»§a NVIDIA, tá»« cÃ¡c dÃ²ng sáº£n pháº©m tiÃªu dÃ¹ng Ä‘áº¿n cÃ¡c dÃ²ng sáº£n pháº©m chuyÃªn dá»¥ng cho trung tÃ¢m dá»¯ liá»‡u. Äiá»u nÃ y cho phÃ©p sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh AI trÃªn nhiá»u loáº¡i pháº§n cá»©ng, tá»« mÃ¡y tÃ­nh cÃ¡ nhÃ¢n Ä‘áº¿n cÃ¡c há»‡ thá»‘ng mÃ¡y chá»§ lá»›n. TÆ°Æ¡ng ThÃ­ch Pháº§n Má»m\nCUDA há»— trá»£ nhiá»u ngÃ´n ngá»¯ láº­p trÃ¬nh vÃ  framework, giÃºp dá»… dÃ ng tÃ­ch há»£p vÃ o cÃ¡c dá»± Ã¡n hiá»‡n cÃ³ mÃ  khÃ´ng cáº§n thay Ä‘á»•i nhiá»u vá» mÃ£ nguá»“n. 4. Kháº£ NÄƒng Má»Ÿ Rá»™ng vÃ  TÃ­nh Linh Hoáº¡t Huáº¥n Luyá»‡n PhÃ¢n TÃ¡n\nCUDA há»— trá»£ cÃ¡c ká»¹ thuáº­t huáº¥n luyá»‡n phÃ¢n tÃ¡n, cho phÃ©p huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh lá»›n trÃªn nhiá»u GPU hoáº·c tháº­m chÃ­ nhiá»u mÃ¡y tÃ­nh. CÃ¡c framework nhÆ° Horovod (do Uber phÃ¡t triá»ƒn) sá»­ dá»¥ng CUDA Ä‘á»ƒ thá»±c hiá»‡n huáº¥n luyá»‡n phÃ¢n tÃ¡n hiá»‡u quáº£. Kháº£ NÄƒng TÃ¹y Chá»‰nh\nCUDA cung cáº¥p kháº£ nÄƒng tÃ¹y chá»‰nh cao, cho phÃ©p cÃ¡c nhÃ  phÃ¡t triá»ƒn tá»‘i Æ°u hÃ³a cÃ¡c thuáº­t toÃ¡n cá»¥ thá»ƒ cho á»©ng dá»¥ng cá»§a há». CUDA cung cáº¥p quyá»n truy cáº­p trá»±c tiáº¿p vÃ o pháº§n cá»©ng GPU, giÃºp tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t theo yÃªu cáº§u cá»¥ thá»ƒ. 5. Hiá»‡u Quáº£ Kinh Táº¿ Tá»‘i Æ¯u Chi PhÃ­:\nSá»­ dá»¥ng GPU vÃ  CUDA Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh AI cÃ³ thá»ƒ giÃºp tiáº¿t kiá»‡m chi phÃ­ báº±ng cÃ¡ch giáº£m thá»i gian huáº¥n luyá»‡n so vá»›i viá»‡c sá»­ dá»¥ng CPU. TÃ­nh hiá»‡u quáº£ cao cá»§a GPU giÃºp giáº£m tá»•ng chi phÃ­ cho pháº§n cá»©ng vÃ  nÄƒng lÆ°á»£ng. CÃ¡c thÆ° viá»‡n láº­p trÃ¬nh song song khÃ¡c ngoÃ i CUDA 1. OpenCL (Open Computing Language) Tá»•ng quan:\nOpenCL lÃ  má»™t tiÃªu chuáº©n má»Ÿ cho láº­p trÃ¬nh song song trÃªn cÃ¡c ná»n táº£ng dá»‹ thá»ƒ, bao gá»“m CPU, GPU, DSP vÃ  FPGA. NÃ³ Ä‘Æ°á»£c quáº£n lÃ½ bá»Ÿi Khronos Group. Äáº·c Ä‘iá»ƒm chÃ­nh:\nÄá»™c láº­p vá»›i ná»n táº£ng: Hoáº¡t Ä‘á»™ng trÃªn cÃ¡c pháº§n cá»©ng tá»« nhiá»u nhÃ  cung cáº¥p khÃ¡c nhau, bao gá»“m AMD, Intel vÃ  NVIDIA. TÃ­nh toÃ¡n song song: Há»— trá»£ tÃ­nh toÃ¡n dá»±a trÃªn tÃ¡c vá»¥ vÃ  dá»¯ liá»‡u. Hiá»‡u suáº¥t: ThÆ°á»ng cÃ³ má»™t chÃºt chi phÃ­ hiá»‡u suáº¥t so vá»›i CUDA do tÃ­nh cháº¥t tá»•ng quÃ¡t cá»§a nÃ³. TrÆ°á»ng há»£p sá»­ dá»¥ng:\nTÃ­nh toÃ¡n khoa há»c Xá»­ lÃ½ hÃ¬nh áº£nh vÃ  video thá»i gian thá»±c MÃ´ hÃ¬nh tÃ i chÃ­nh Æ¯u Ä‘iá»ƒm:\nTÃ­nh di Ä‘á»™ng: Viáº¿t má»™t láº§n, cháº¡y má»i nÆ¡i. Há»— trá»£ pháº§n cá»©ng rá»™ng rÃ£i: CÃ³ thá»ƒ cháº¡y trÃªn CPU, GPU vÃ  cÃ¡c bá»™ tÄƒng tá»‘c khÃ¡c tá»« nhiá»u nhÃ  cung cáº¥p. NhÆ°á»£c Ä‘iá»ƒm:\nHiá»‡u suáº¥t: CÃ³ thá»ƒ khÃ´ng tá»‘i Æ°u nhÆ° CUDA trÃªn GPU cá»§a NVIDIA. Phá»©c táº¡p: API má»©c tháº¥p cÃ³ thá»ƒ khÃ³ láº­p trÃ¬nh hÆ¡n CUDA. 2. AMD ROCm (Radeon Open Compute) Tá»•ng quan:\nAMD ROCm lÃ  má»™t ná»n táº£ng mÃ£ nguá»“n má»Ÿ cho tÃ­nh toÃ¡n GPU. NÃ³ cung cáº¥p cÃ¡c cÃ´ng cá»¥ Ä‘á»ƒ chuyá»ƒn Ä‘á»•i cÃ¡c á»©ng dá»¥ng CUDA sang cháº¡y trÃªn GPU cá»§a AMD. Äáº·c Ä‘iá»ƒm chÃ­nh:\nHIP (Heterogeneous-Compute Interface for Portability): Má»™t runtime vÃ  API cho phÃ©p mÃ£ CUDA Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i Ä‘á»ƒ cháº¡y trÃªn pháº§n cá»©ng AMD. Há»— trá»£ TensorFlow vÃ  PyTorch: TÃ­ch há»£p cho cÃ¡c khung mÃ¡y há»c phá»• biáº¿n. TrÆ°á»ng há»£p sá»­ dá»¥ng:\nHá»c mÃ¡y vÃ  AI TÃ­nh toÃ¡n hiá»‡u nÄƒng cao Trung tÃ¢m dá»¯ liá»‡u vÃ  Ä‘iá»‡n toÃ¡n Ä‘Ã¡m mÃ¢y Æ¯u Ä‘iá»ƒm:\nMÃ£ nguá»“n má»Ÿ: ÄÆ°á»£c cá»™ng Ä‘á»“ng Ä‘Ã³ng gÃ³p vá»›i sá»± tham gia cá»§a nhiá»u tá»• chá»©c. TÆ°Æ¡ng thÃ­ch CUDA: Dá»… dÃ ng chuyá»ƒn mÃ£ CUDA thÃ´ng qua HIP. NhÆ°á»£c Ä‘iá»ƒm:\nHáº¡n cháº¿ pháº§n cá»©ng: Chá»§ yáº¿u há»— trá»£ GPU cá»§a AMD. Äá»™ trÆ°á»Ÿng thÃ nh: Ãt trÆ°á»Ÿng thÃ nh hÆ¡n so vá»›i CUDA, Ã­t tÃ i nguyÃªn vÃ  cÃ´ng cá»¥ hÆ¡n. 3. SYCL (C++ for Heterogeneous Computing) Tá»•ng quan:\nSYCL lÃ  má»™t mÃ´ hÃ¬nh láº­p trÃ¬nh má»©c cao dá»±a trÃªn C++ cho tÃ­nh toÃ¡n dá»‹ thá»ƒ, cho phÃ©p mÃ£ di Ä‘á»™ng trÃªn cÃ¡c pháº§n cá»©ng khÃ¡c nhau bao gá»“m CPU, GPU vÃ  FPGA. Äáº·c Ä‘iá»ƒm chÃ­nh:\nLáº­p trÃ¬nh nguá»“n Ä‘Æ¡n: Cho phÃ©p mÃ£ cho mÃ¡y chá»§ vÃ  thiáº¿t bá»‹ Ä‘Æ°á»£c viáº¿t trong má»™t tá»‡p nguá»“n duy nháº¥t. TÃ­ch há»£p C++: Sá»­ dá»¥ng cÃ¡c tÃ­nh nÄƒng C++ hiá»‡n Ä‘áº¡i cho mÃ£ an toÃ n vÃ  biá»ƒu cáº£m hÆ¡n. Backend: CÃ³ thá»ƒ biÃªn dá»‹ch sang OpenCL, CUDA (thÃ´ng qua hipSYCL), vÃ  nhiá»u hÆ¡n ná»¯a. TrÆ°á»ng há»£p sá»­ dá»¥ng:\ná»¨ng dá»¥ng Ä‘a ná»n táº£ng Há»‡ thá»‘ng thá»i gian thá»±c NghiÃªn cá»©u khoa há»c Æ¯u Ä‘iá»ƒm:\nTÃ­nh di Ä‘á»™ng: TÃ­nh di Ä‘á»™ng cao trÃªn cÃ¡c ná»n táº£ng pháº§n cá»©ng khÃ¡c nhau. C++ hiá»‡n Ä‘áº¡i: Lá»£i Ã­ch tá»« sá»± an toÃ n vÃ  tÃ­nh máº¡nh máº½ cá»§a C++. NhÆ°á»£c Ä‘iá»ƒm:\nÄÆ°á»ng cong há»c táº­p: YÃªu cáº§u quen thuá»™c vá»›i cáº£ C++ hiá»‡n Ä‘áº¡i vÃ  cÃ¡c khÃ¡i niá»‡m láº­p trÃ¬nh song song. Phá»¥ thuá»™c vÃ o cÃ´ng cá»¥: Hiá»‡u suáº¥t vÃ  tÃ­nh nÄƒng cÃ³ thá»ƒ phá»¥ thuá»™c nhiá»u vÃ o viá»‡c triá»ƒn khai SYCL (vÃ­ dá»¥: DPC++, hipSYCL). 4. Vulkan Compute Tá»•ng quan:\nVulkan Compute lÃ  má»™t pháº§n cá»§a API Ä‘á»“ há»a Vulkan há»— trá»£ cÃ¡c shader tÃ­nh toÃ¡n cho tÃ­nh toÃ¡n tá»•ng quÃ¡t trÃªn GPU. Äáº·c Ä‘iá»ƒm chÃ­nh:\nKiá»ƒm soÃ¡t má»©c tháº¥p: Cung cáº¥p kiá»ƒm soÃ¡t chi tiáº¿t vá» cÃ¡c hoáº¡t Ä‘á»™ng cá»§a GPU. Äa ná»n táº£ng: Hoáº¡t Ä‘á»™ng trÃªn nhiá»u há»‡ Ä‘iá»u hÃ nh vÃ  nhÃ  cung cáº¥p pháº§n cá»©ng khÃ¡c nhau. TrÆ°á»ng há»£p sá»­ dá»¥ng:\ná»¨ng dá»¥ng Ä‘á»“ há»a vÃ  tÃ­nh toÃ¡n thá»i gian thá»±c PhÃ¡t triá»ƒn trÃ² chÆ¡i MÃ´ phá»ng vÃ  hÃ¬nh áº£nh hÃ³a Æ¯u Ä‘iá»ƒm:\nHiá»‡u suáº¥t: Hiá»‡u quáº£ cao nhá» truy cáº­p má»©c tháº¥p vÃ o pháº§n cá»©ng GPU. Há»— trá»£ Ä‘a nhÃ  cung cáº¥p: TÆ°Æ¡ng thÃ­ch vá»›i nhiá»u loáº¡i GPU. NhÆ°á»£c Ä‘iá»ƒm:\nPhá»©c táº¡p: API má»©c tháº¥p yÃªu cáº§u hiá»ƒu biáº¿t chi tiáº¿t vá» kiáº¿n trÃºc GPU. CÃ´ng sá»©c phÃ¡t triá»ƒn: ÄÃ²i há»i nhiá»u cÃ´ng sá»©c Ä‘á»ƒ thiáº¿t láº­p vÃ  báº£o trÃ¬ so vá»›i cÃ¡c API má»©c cao hÆ¡n. 5. Intel oneAPI Tá»•ng quan:\nIntel oneAPI lÃ  má»™t mÃ´ hÃ¬nh láº­p trÃ¬nh há»£p nháº¥t thiáº¿t káº¿ Ä‘á»ƒ Ä‘Æ¡n giáº£n hÃ³a viá»‡c phÃ¡t triá»ƒn trÃªn cÃ¡c kiáº¿n trÃºc Ä‘a dáº¡ng nhÆ° CPU, GPU, FPGA vÃ  bá»™ tÄƒng tá»‘c AI. Äáº·c Ä‘iá»ƒm chÃ­nh:\nDPC++ (Data Parallel C++): Má»™t pháº§n má»Ÿ rá»™ng cá»§a SYCL cho oneAPI, há»— trá»£ mÃ£ cháº¡y trÃªn cÃ¡c pháº§n cá»©ng khÃ¡c nhau. ThÆ° viá»‡n tá»‘i Æ°u hÃ³a: Cung cáº¥p cÃ¡c thÆ° viá»‡n hiá»‡u nÄƒng cho toÃ¡n há»c, phÃ¢n tÃ­ch dá»¯ liá»‡u, há»c sÃ¢u, v.v. TrÆ°á»ng há»£p sá»­ dá»¥ng:\nTÃ­nh toÃ¡n hiá»‡u nÄƒng cao AI vÃ  há»c mÃ¡y PhÃ¢n tÃ­ch dá»¯ liá»‡u Æ¯u Ä‘iá»ƒm:\nKiáº¿n trÃºc chÃ©o: Cho phÃ©p má»™t mÃ£ nguá»“n duy nháº¥t cháº¡y trÃªn nhiá»u pháº§n cá»©ng Intel vÃ  khÃ´ng pháº£i Intel. Há»‡ sinh thÃ¡i: Há»‡ sinh thÃ¡i máº¡nh vá»›i nhiá»u cÃ´ng cá»¥ vÃ  thÆ° viá»‡n. NhÆ°á»£c Ä‘iá»ƒm:\nTáº­p trung vÃ o Intel: Chá»§ yáº¿u tá»‘i Æ°u hÃ³a cho pháº§n cá»©ng Intel, cÃ³ thá»ƒ khÃ´ng hiá»‡u quáº£ trÃªn cÃ¡c thiáº¿t bá»‹ khÃ´ng pháº£i cá»§a Intel. Má»›i: Váº«n Ä‘ang phÃ¡t triá»ƒn, cÃ³ thá»ƒ Ã­t tÃ i nguyÃªn so vá»›i CUDA. 6. OpenMP (Open Multi-Processing) Tá»•ng quan:\nOpenMP lÃ  má»™t API há»— trá»£ láº­p trÃ¬nh Ä‘a ná»n táº£ng bá»™ nhá»› chia sáº» Ä‘a xá»­ lÃ½ trong C, C++ vÃ  Fortran. CÃ¡c phiÃªn báº£n gáº§n Ä‘Ã¢y bao gá»“m cÃ¡c chá»‰ thá»‹ Ä‘á»ƒ tÃ­nh toÃ¡n trÃªn GPU. Äáº·c Ä‘iá»ƒm chÃ­nh:\nChá»‰ thá»‹ trÃ¬nh biÃªn dá»‹ch: ÄÆ¡n giáº£n hÃ³a láº­p trÃ¬nh song song vá»›i cÃ¡c chá»‰ thá»‹ trÃ¬nh biÃªn dá»‹ch. Há»— trá»£ CPU vÃ  GPU: CÃ¡c phiÃªn báº£n gáº§n Ä‘Ã¢y há»— trá»£ tÃ­nh toÃ¡n trÃªn GPU. Song song hÃ³a dáº§n dáº§n: Cho phÃ©p song song hÃ³a dáº§n dáº§n cÃ¡c mÃ£ nguá»“n hiá»‡n cÃ³. TrÆ°á»ng há»£p sá»­ dá»¥ng:\nBá»™ nhá»› chia sáº» Ä‘a xá»­ lÃ½ Song song hÃ³a mÃ£ CPU hiá»‡n cÃ³ TÃ­nh toÃ¡n khoa há»c hiá»‡u nÄƒng cao Æ¯u Ä‘iá»ƒm:\nDá»… sá»­ dá»¥ng: MÃ´ hÃ¬nh song song Ä‘Æ¡n giáº£n hÆ¡n so vá»›i láº­p trÃ¬nh Ä‘a luá»“ng rÃµ rÃ ng. MÃ£ nguá»“n káº¿ thá»«a: Tá»‘t cho viá»‡c song song hÃ³a cÃ¡c mÃ£ nguá»“n CPU hiá»‡n cÃ³. NhÆ°á»£c Ä‘iá»ƒm:\nKháº£ nÄƒng má»Ÿ rá»™ng: PhÃ¹ há»£p nháº¥t cho cÃ¡c há»‡ thá»‘ng bá»™ nhá»› chia sáº», cÃ³ thá»ƒ khÃ´ng má»Ÿ rá»™ng tá»‘t cho cÃ¡c há»‡ thá»‘ng phÃ¢n tÃ¡n lá»›n. Hiá»‡u suáº¥t: TÃ­nh toÃ¡n trÃªn GPU cÃ³ thá»ƒ kÃ©m hiá»‡u quáº£ hÆ¡n so vá»›i CUDA. Lá»i káº¿t CÃ¡c lá»±a chá»n thay tháº¿ nÃ y Ä‘á»u cÃ³ nhá»¯ng Ä‘iá»ƒm máº¡nh vÃ  yáº¿u riÃªng, vÃ  lá»±a chá»n tá»‘t nháº¥t thÆ°á»ng phá»¥ thuá»™c vÃ o cÃ¡c yÃªu cáº§u cá»¥ thá»ƒ cá»§a á»©ng dá»¥ng vÃ  cÆ¡ sá»Ÿ háº¡ táº§ng hiá»‡n cÃ³ cá»§a chÃ­nh báº¡n. Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t. Háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Jun 12, 2024","img":"https://unsplash.it/1920/1080?image=15","permalink":"/blog/2024-06-12-cuda-alternate/","series":null,"tags":["Machine Learning","Parallel Computing","Cuda"],"title":"Má»™t Sá»‘ ThÆ° Viá»‡n TÃ­nh ToÃ¡n Song Song Thay Tháº¿ Cho Cuda"},{"categories":null,"content":" 1. PhÃ¢n tÃ­ch há»“i quy (regression analysis) 1.1. Linear Regression: 1.2. Simple Linear Regression: 1.3. Multiple Linear Regression: 2. PhÃ¢n tÃ­ch nhÃ¢n tá»‘ (Factor analysis) 3. Neural network 4. PhÃ¢n tÃ­ch cá»¥m (Cluster analysis) 5. PhÃ¢n tÃ­ch tá»• há»£p - PhÃ¢n tÃ­ch theo nhÃ³m (Cohort analysis) Cohort Dá»±a trÃªn Thá»i gian Cohort Dá»±a trÃªn lá»£i Ã­ch 6. PhÃ¢n tÃ­ch thuá»™c tÃ­nh - PhÃ¢n tÃ­ch káº¿t há»£p (conjoint analysis) 7. PhÃ¢n tÃ­ch vÄƒn báº£n (Text analysis) 8. PhÃ¢n tÃ­ch chuá»—i thá»i gian (time series analysis) 9. Khai thÃ¡c dá»¯ liá»‡u (Data mining) 10. CÃ¢y quyáº¿t Ä‘á»‹nh (decision tree) Nguá»“n: NhÃ¢n dá»‹p táº¿t, ráº£nh rá»—i cháº¡y kpi viáº¿t bÃ i Ä‘á»ƒ Ä‘áº£m báº£o sá»‘ lÆ°á»£ng bÃ i viáº¿t, chá»© Ä‘á»ƒ cÃ¡i website nÃ³ muá»‘n má»‘c meo háº¿t cáº£ rá»“i. CÆ¡ mÃ  viáº¿t cÃ ng nhiá»u thÃ¬ cÃ ng khÃ´ng Ä‘á»§, cÃ¡i gÃ¬ cÅ©ng muá»‘n viáº¿t, thÃ nh ra nÃ³ dÃ i dÃ²ng, lÃª thÃª, ngá»“i Ä‘á»c láº¡i tháº¥y chÃ¡n ngÃ¡n, nÃªn pháº£i ngá»“i tÃ©m tÃ©m ná»™i dung láº¡i. BÃ  con Ä‘á»c tháº¥y chá»— nÃ o cÃ²n dÃ i , cáº§n tÃ³m, tÃ©m, gá»t thÃ¬ vui lÃ²ng tháº£y cÃ¡i commend hen.\n1. PhÃ¢n tÃ­ch há»“i quy (regression analysis) Regression analysis lÃ  má»™t phÆ°Æ¡ng phÃ¡p thá»‘ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Æ°á»›c lÆ°á»£ng má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n phá»¥ thuá»™c (hay cÃ²n Ä‘Æ°á»£c gá»i lÃ  biáº¿n \u0026lsquo;outcome\u0026rsquo; hoáº·c biáº¿n \u0026lsquo;response\u0026rsquo; ) vÃ  má»™t hoáº·c nhiá»u biáº¿n Ä‘á»™c láº­p ( cÅ©ng Ä‘Æ°á»£c gá»i vá»›i tÃªn lÃ  \u0026lsquo;predictors\u0026rsquo;, \u0026lsquo;covariates\u0026rsquo;, \u0026rsquo;explanatory variables\u0026rsquo;, \u0026lsquo;features\u0026rsquo;). Chi tiáº¿t:\n1.1. Linear Regression: Há»“i quy tuyáº¿n tÃ­nh lÃ  hÃ¬nh thá»©c phÃ¢n tÃ­ch há»“i quy phá»• biáº¿n nháº¥t. NÃ³ nháº±m má»¥c Ä‘Ã­ch tÃ¬m ra Ä‘Æ°á»ng tháº³ng khá»›p vá»›i dá»¯ liá»‡u nháº¥t ( fitted line) theo má»™t sá»‘ tiÃªu chÃ­ toÃ¡n há»c cá»¥ thá»ƒ nÃ o Ä‘Ã³.\nHá»“i quy tuyáº¿n tÃ­nh giáº£ Ä‘á»‹nh ráº±ng cÃ¡c má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n lÃ  tuyáº¿n tÃ­nh vÃ  thoáº£ cÃ¡c giáº£ Ä‘á»‹nh lÃ  normality of residuals vÃ  independence of errors. 1.2. Simple Linear Regression: Trong há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n, chÃºng ta Ä‘Ã¡nh giÃ¡ má»‘i quan há»‡ giá»¯a má»™t biáº¿n phá»¥ thuá»™c duy nháº¥t (Y) vÃ  má»™t biáº¿n Ä‘á»™c láº­p (X). PhÆ°Æ¡ng trÃ¬nh: Y = x +bX + epsilon\n1.3. Multiple Linear Regression: LÃ  biáº¿n thá»ƒ má»Ÿ rá»™ng cá»§a há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n, vá»›i nhiá»u biáº¿n Ä‘á»™c láº­p X PhÆ°Æ¡ng trÃ¬nh: Y = x + bX1 + cX2 + dX3 ... + epsilon 2. PhÃ¢n tÃ­ch nhÃ¢n tá»‘ (Factor analysis) Factor analysis lÃ  má»™t ká»¹ thuáº­t thá»‘ng kÃª, phÃ¢n tÃ­ch yáº¿u tá»‘ nháº­n diá»‡n cáº¥u trÃºc cÆ¡ báº£n cá»§a má»™t táº­p há»£p cÃ¡c biáº¿n vÃ  giáº£i thÃ­ch chÃºng dÆ°á»›i dáº¡ng má»™t sá»‘ lÆ°á»£ng nhá» hÆ¡n cÃ¡c yáº¿u tá»‘ chung. PhÃ¢n tÃ­ch yáº¿u tá»‘ giÃºp giáº£m chiá»u dá»¯ liá»‡u vÃ  sá»± phá»©c táº¡p cá»§a nÃ³, cÅ©ng nhÆ° khÃ¡m phÃ¡ nhá»¯ng yáº¿u tá»‘ tiá»m áº©n gÃ¢y ra sá»± biáº¿n Ä‘á»™ng chung cá»§a cÃ¡c biáº¿n quan sÃ¡t.\nPhÃ¢n loáº¡i:\nExploratory factor analysis (EFA): Loáº¡i phÃ¢n tÃ­ch nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng khi ngÆ°á»i phÃ¢n tÃ­ch khÃ´ng cÃ³ hiá»ƒu biáº¿t gÃ¬ vá» dá»¯ liá»‡u. Má»¥c tiÃªu cá»§a phÃ¢n tÃ­ch nÃ y lÃ  tÃ¬m sá»‘ factor tá»‘i Æ°u vá»›i Ä‘iá»u kiá»‡n cá»±c Ä‘áº¡i hoÃ¡ cÃ¡c biáº¿n trong dá»¯ liá»‡u.\nConfirmatory factor analysis (CFA): Loáº¡i phÃ¢n tÃ­ch nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng khi ngÆ°á»i phÃ¢n tÃ­ch cÃ³ mÃ´ hÃ¬nh lÃ½ thuÃªts hoáº·c giáº£ thueyets vá» cÃ¡c factor vÃ  má»‘i quan há»‡ giá»¯a chÃºng.\nPrincipal component analysis (PCA): Dáº¡ng phÃ¢n tÃ­ch nÃ y thÆ°á»ng nháº§m láº«n vá»›i EFA, nhÆ°ng chÃºng khÃ¡c má»¥c tiÃªu vÃ  khÃ¡c giáº£ Ä‘á»‹nh. Má»¥c tiÃªu cá»§a PCA lÃ  tÃ¬m ra sá»± káº¿t há»£p tuyáº¿n tÃ­nh cá»§a cÃ¡c biáº¿n quan sÃ¡t Ä‘á»ƒ thu Ä‘Æ°á»£c phÆ°Æ¡ng sai lá»›n nháº¥t trong dá»¯ liá»‡u, mÃ  khÃ´ng giáº£ Ä‘á»‹nh vá» báº¥t ká»³ yáº¿u tá»‘ tiá»m áº©n nÃ o. PCA thÃ­ch há»£p hÆ¡n cho viá»‡c giáº£m kÃ­ch thÆ°á»›c dá»¯ liá»‡u vÃ  tÃ³m táº¯t, trong khi PhÃ¢n tÃ­ch Yáº¿u tá»‘ KhÃ¡m phÃ¡ (EFA) thÃ­ch há»£p hÆ¡n cho viá»‡c tÃ¬m ra cÃ¡c khÃ¡i niá»‡m tiá»m áº©n vÃ  má»‘i quan há»‡ nguyÃªn nhÃ¢n.\nFactor analysis tráº£i qua cÃ¡c nhiá»u bÆ°á»›c sau:\nData preparation:Xem sá»‘ dÃ²ng, sá»‘ cá»™t, phÃ¢n phá»‘i cá»§a cÃ¡c biáº¿n, má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n.\nFactor extraction: XÃ¡c Ä‘á»‹nh sá»‘ lÆ°á»£ng cÃ¡c factor cáº§n rÃºt trÃ­ch. Sá»­ dá»¥ng principal component analysis, maximum likelihood, principal axis factoring, 3 cháº¥m \u0026hellip;\nFactor rotation: BÆ°á»›c nÃ y dÃ¹ng Ä‘á»ƒ cáº£i thiá»‡n kháº£ nÄƒng diá»…n giáº£i vÃ  tÄƒng tÃ­nh rÃµ rÃ ng cá»§a cÃ¡c yáº¿u tá»‘ báº±ng cÃ¡ch thay Ä‘á»•i hÆ°á»›ng vÃ  vá»‹ trÃ­ cá»§a chÃºng. CÃ³ hai loáº¡i chÃ­nh : xoay gÃ³c vÃ  xoay chÃ©o. Xoay gÃ³c giáº£ Ä‘á»‹nh ráº±ng cÃ¡c yáº¿u tá»‘ khÃ´ng tÆ°Æ¡ng quan, trong khi xoay chÃ©o cho phÃ©p má»™t sá»‘ tÆ°Æ¡ng quan giá»¯a cÃ¡c yáº¿u tá»‘ .\nFactor interpretation: Ä‘áº·t tÃªn cho cÃ¡c factor ( bÆ°á»›c nÃ y khÃ¡ khÃ³, do tÃªn pháº£i cover Ä‘Æ°á»£c dá»¯ liá»‡u mÃ  nÃ³ Ä‘ang handle).\nPhÃ¢n tÃ­ch yáº¿u tá»‘ lÃ  má»™t cÃ´ng cá»¥ há»¯u Ã­ch vÃ  máº¡nh máº½ Ä‘á»ƒ khÃ¡m phÃ¡ vÃ  xÃ¡c nháº­n cáº¥u trÃºc cá»§a dá»¯ liá»‡u, nhÆ°ng nÃ³ cÅ©ng mang Ä‘áº¿n má»™t sá»‘ háº¡n cháº¿ vÃ  thÃ¡ch thá»©c\nSubjectivity: Má»—i nhÃ  phÃ¢n tÃ­ch cÃ³ má»™t chiáº¿n lÆ°á»£c phÃ¢n tÃ­ch khÃ¡c nhau, nÃªn cÃ³ thá»ƒ sáº½ cÃ³ cÃ¡c bÃ¡o cÃ¡o khÃ¡c nhau, trÃªn cÃ¹ng má»™t dá»¯ liá»‡u.\nComplexity: PhÆ°Æ¡ng phÃ¡p Factor analysis khÃ¡ khÃ³ tiáº¿p cáº­n, Ä‘Ã²i há»i ngÆ°á»i phÃ¢n tÃ­ch cÃ³ kiáº¿n thá»©c chuyÃªn sÃ¢u vá» dá»¯ liá»‡u há» Ä‘ang cÃ³, vÃ  cÃ³ kiáº¿n thá»©c vá»¯ng cháº¯c vá» thá»‘ng kÃª, giáº£i Ä‘á»‹nh, cÃ³ kháº£ nÄƒng sá»­ dá»¥ng cÃ¡c tool phÃ¢n tÃ­ch dá»¯ liá»‡u lá»›n.\nValidity: PhÆ°Æ¡ng phÃ¡p nÃ y khÃ´ng thá»ƒ dá»©ng minh má»‘i quan há»‡ nhÃ¢n quáº£ , tÃ­nh há»£p lá»‡ cá»§a cÃ¡c yáº¿u tá»‘. Má»i thÃ´ng tin Ä‘Æ°á»£c rÃºt ra tá»« trong dá»¯ liá»‡u dá»±a trÃªn cÃ¡c tiÃªu chÃ­ thá»‘ng kÃª vÃ  cÃ¡c giáº£ Ä‘inh.\n3. Neural network Má»™t máº¡ng neural lÃ  má»™t loáº¡i trÃ­ tuá»‡ nhÃ¢n táº¡o cá»‘ gáº¯ng mÃ´ phá»ng cÃ¡ch nÃ£o ngÆ°á»i hoáº¡t Ä‘á»™ng. NÃ³ bao gá»“m nhiá»u Ä‘Æ¡n vá»‹ Ä‘Æ°á»£c káº¿t ná»‘i gá»i lÃ  neuron, chÃºng xá»­ lÃ½ thÃ´ng tin vÃ  há»c tá»« dá»¯ liá»‡u. Máº¡ng neural cÃ³ thá»ƒ thá»±c hiá»‡n nhiá»u nhiá»‡m vá»¥ khÃ¡c nhau, nhÆ° nháº­n dáº¡ng giá»ng nÃ³i, phÃ¢n tÃ­ch hÃ¬nh áº£nh vÃ  xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ khÃ¡i niá»‡m chÃ­nh cá»§a máº¡ng neural:\nMá»™t máº¡ng neural cÃ³ nhiá»u lá»›p cá»§a cÃ¡c neuron, nhÆ° lÃ  má»™t lá»›p Ä‘áº§u vÃ o, má»™t hoáº·c nhiá»u lá»›p áº©n, vÃ  má»™t lá»›p Ä‘áº§u ra. Má»—i lá»›p nháº­n Ä‘áº§u vÃ o tá»« lá»›p trÆ°á»›c Ä‘Ã³ vÃ  chuyá»ƒn Ä‘áº§u ra cho lá»›p káº¿ tiáº¿p.\nMá»—i neuron cÃ³ má»™t trá»ng sá»‘ vÃ  má»™t Ä‘á»™ lá»‡ch, quyáº¿t Ä‘á»‹nh má»©c Ä‘á»™ áº£nh hÆ°á»Ÿng cá»§a nÃ³ Ä‘á»‘i vá»›i Ä‘áº§u ra. Trá»ng sá»‘ vÃ  Ä‘á»™ lá»‡ch Ä‘Æ°á»£c Ä‘iá»u chá»‰nh trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, nÆ¡i máº¡ng há»c tá»« dá»¯ liá»‡u vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t.\nMá»—i neuron cÅ©ng cÃ³ má»™t hÃ m kÃ­ch hoáº¡t, quyáº¿t Ä‘á»‹nh liá»‡u neuron cÃ³ Ä‘Æ°á»£c kÃ­ch hoáº¡t hay khÃ´ng dá»±a trÃªn Ä‘áº§u vÃ o. Má»™t sá»‘ hÃ m kÃ­ch hoáº¡t phá»• biáº¿n bao gá»“m sigmoid, tanh, vÃ  ReLU.\nCÃ³ nhiá»u loáº¡i máº¡ng neural khÃ¡c nhau, nhÆ° máº¡ng neural feedforward, máº¡ng neural há»“i quy, máº¡ng neural tÃ­ch cháº­p, vÃ  máº¡ng neural sÃ¢u. Má»—i loáº¡i cÃ³ kiáº¿n trÃºc, Æ°u Ä‘iá»ƒm vÃ  á»©ng dá»¥ng riÃªng.\n4. PhÃ¢n tÃ­ch cá»¥m (Cluster analysis) PhÃ¢n tÃ­ch cá»¥m lÃ  má»™t phÆ°Æ¡ng phÃ¡p phÃ¢n tÃ­ch dá»¯ liá»‡u nhÃ³m cÃ¡c Ä‘á»‘i tÆ°á»£ng dá»±a trÃªn cÃ¡c thuá»™c tÃ­nh chung cá»§a chÃºng. NÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng trong há»c mÃ¡y, phÃ¢n tÃ­ch hÃ¬nh áº£nh, khai thÃ¡c dá»¯ liá»‡u vÃ  nháº­n dáº¡ng máº«u.\nTÃ¬m ra cáº¥u trÃºc vÃ  sá»‘ lÆ°á»£ng cá»¥ng tá»‘i Æ°u phÃ¹ há»£p vá»›i dá»¯ liá»‡u. CÃ³ nhiá»u loáº¡i cá»¥m nhÆ° cá»¥m cáº§u, cá»¥m phÃ¢n cáº¥p, cá»¥m dá»±a trÃªn máº­t Ä‘á»™, cá»¥m khÃ´ng gian con, vÃ  cá»¥m dá»±a trÃªn mÃ´ hÃ¬nh.\nPhÃ¢n tÃ­ch cá»¥m Ä‘Ã²i há»i viá»‡c lá»±a chá»n má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m phÃ¹ há»£p vÃ  cÃ i Ä‘áº·t cÃ¡c tham sá»‘ cá»§a nÃ³. Má»™t sá»‘ thuáº­t toÃ¡n phÃ¢n cá»¥m phá»• biáº¿n bao gá»“m K-means, phÃ¢n cá»¥m phÃ¢n cáº¥p, DBSCAN, phÃ¢n cá»¥m phá»•, vÃ  mÃ´ hÃ¬nh há»—n há»£p Gaussian.\nPhÃ¢n tÃ­ch cá»¥m cÅ©ng yÃªu cáº§u kiá»ƒm Ä‘á»‹nh vÃ  diá»…n giáº£i káº¿t quáº£ phÃ¢n cá»¥m. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau nhÆ° kiá»ƒm Ä‘á»‹nh thá»‘ng kÃª, so sÃ¡nh vá»›i cÃ¡c lá»›p Ä‘Ã£ biáº¿t, hoáº·c cÃ¡c tiÃªu chÃ­ cá»¥ thá»ƒ cho tá»«ng lÄ©nh vá»±c.\nPhÃ¢n tÃ­ch cá»¥m lÃ  má»™t cÃ´ng cá»¥ há»¯u Ã­ch vÃ  máº¡nh máº½ Ä‘á»ƒ khÃ¡m phÃ¡ vÃ  xÃ¡c nháº­n cáº¥u trÃºc cá»§a dá»¯ liá»‡u, nhÆ°ng nÃ³ cÅ©ng cÃ³ má»™t sá»‘ háº¡n cháº¿ vÃ  thÃ¡ch thá»©c:\nTÃ­nh chá»§ quan: PhÃ¢n tÃ­ch cá»¥m liÃªn quan Ä‘áº¿n nhiá»u quyáº¿t Ä‘á»‹nh vÃ  Ä‘Ã¡nh giÃ¡ tá»« phÃ­a nghiÃªn cá»©u, nhÆ° loáº¡i phÃ¢n tÃ­ch cá»¥m, phÆ°Æ¡ng phÃ¡p phÃ¢n cá»¥m, sá»‘ lÆ°á»£ng cá»¥m, vÃ  cÃ¡ch diá»…n giáº£i cá»¥m. Nhá»¯ng lá»±a chá»n nÃ y cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ vÃ  káº¿t luáº­n cá»§a phÃ¢n tÃ­ch, vÃ  cÃ¡c nhÃ  nghiÃªn cá»©u khÃ¡c nhau cÃ³ thá»ƒ thu Ä‘Æ°á»£c káº¿t quáº£ khÃ¡c nhau tá»« cÃ¹ng má»™t dá»¯ liá»‡u.\nÄá»™ phá»©c táº¡p: PhÃ¢n tÃ­ch cá»¥m cÃ³ thá»ƒ khÃ³ hiá»ƒu vÃ  Ã¡p dá»¥ng Ä‘Ãºng, Ä‘áº·c biá»‡t lÃ  Ä‘á»‘i vá»›i ngÆ°á»i má»›i há»c vÃ  ngÆ°á»i khÃ´ng chuyÃªn vá» thá»‘ng kÃª. NÃ³ Ä‘Ã²i há»i sá»± hiá»ƒu biáº¿t tá»‘t vá» lÃ½ thuyáº¿t cÆ¡ báº£n, giáº£ Ä‘á»‹nh, phÆ°Æ¡ng phÃ¡p vÃ  cÃ´ng thá»©c cÆ¡ báº£n, cÅ©ng nhÆ° kháº£ nÄƒng sá»­ dá»¥ng pháº§n má»m vÃ  cÃ´ng cá»¥ phÃ¹ há»£p.\nTÃ­nh há»£p lá»‡: PhÃ¢n tÃ­ch cá»¥m khÃ´ng chá»©ng minh sá»± nhÃ¢n quáº£ hoáº·c tÃ­nh há»£p lá»‡ cá»§a cÃ¡c cá»¥m. NÃ³ chá»‰ cung cáº¥p má»™t giáº£i thÃ­ch cÃ³ thá»ƒ vá» dá»¯ liá»‡u dá»±a trÃªn tiÃªu chÃ­ thá»‘ng kÃª vÃ  giáº£ Ä‘á»‹nh. NgÆ°á»i nghiÃªn cá»©u luÃ´n nÃªn kiá»ƒm tra tÃ­nh há»£p lá»‡ vÃ  Ä‘á»™ tin cáº­y cá»§a cÃ¡c cá»¥m báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhÆ° chá»‰ sá»‘ alpha cá»§a Cronbach, tÃ­nh há»£p lá»‡ xÃ¢y dá»±ng, tÃ­nh há»£p lá»‡ há»™i tá»¥, tÃ­nh há»£p lá»‡ phÃ¢n loáº¡i.\n5. PhÃ¢n tÃ­ch tá»• há»£p - PhÃ¢n tÃ­ch theo nhÃ³m (Cohort analysis) PhÃ¢n tÃ­ch nhÃ³m lÃ  má»™t ká»¹ thuáº­t quan trá»ng trong lÄ©nh vá»±c phÃ¢n tÃ­ch hÃ nh vi.\nPhÃ¢n tÃ­ch nhÃ³m liÃªn quan Ä‘áº¿n viá»‡c chia dá»¯ liá»‡u tá»« má»™t bá»™ dá»¯ liá»‡u thÃ nh cÃ¡c nhÃ³m liÃªn quan, Ä‘Æ°á»£c gá»i lÃ  cohort, thay vÃ¬ xem xÃ©t dá»¯ liá»‡u nhÆ° má»™t Ä‘Æ¡n vá»‹ duy nháº¥t.\nCÃ¡c nhÃ³m nÃ y cÃ³ cÃ¡c Ä‘áº·c Ä‘iá»ƒm tÆ°Æ¡ng tá»±, cháº³ng háº¡n nhÆ° thá»i gian tham gia hoáº·c kÃ­ch thÆ°á»›c.\nCohort analysis thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u lÄ©nh vá»±c, vÃ­ nhÆ° doanh nghiá»‡p cung cáº¥p dá»‹ch vá»¥ Ä‘Ã¡m mÃ¢y, doanh nghiá»‡p kinh doanh trÃ² chÆ¡i , cÃ¡c ná»n táº£ng thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­, cÃ¡c doanh nghiá»‡p bÃ¡n láº», báº¥t Ä‘á»™ng sáº£n, ngÃ¢n hÃ ng \u0026hellip;.\nMá»¥c tiÃªu chÃ­nh cá»§a phÃ¢n tÃ­ch nhÃ³m lÃ  hiá»ƒu hÃ nh vi cá»§a khÃ¡ch hÃ ng qua toÃ n bá»™ vÃ²ng Ä‘á»i cá»§a má»—i khÃ¡ch hÃ ng.\nBáº±ng cÃ¡ch nhÃ³m khÃ¡ch hÃ ng thÃ nh cÃ¡c nhÃ³m quáº£n lÃ½ Ä‘Æ°á»£c, doanh nghiá»‡p cÃ³ cÃ¡i nhÃ¬n sÃ¢u sáº¯c vá» xu hÆ°á»›ng vÃ  mÃ´ hÃ¬nh theo thá»i gian.\nNÃ³ giÃºp Ä‘iá»u chá»‰nh cÃ¡c Æ°u Ä‘Ã£i sáº£n pháº©m vÃ  chiáº¿n lÆ°á»£c tiáº¿p thá»‹ cho cÃ¡c phÃ¢n khÃºc khÃ¡ch hÃ ng cá»¥ thá»ƒ.\nCohort Dá»±a trÃªn Thá»i gian CÃ¡c nhÃ³m nÃ y bao gá»“m khÃ¡ch hÃ ng Ä‘Äƒng kÃ½ sá»­ dá»¥ng sáº£n pháº©m hoáº·c dá»‹ch vá»¥ trong má»™t khoáº£ng thá»i gian cá»¥ thá»ƒ (vÃ­ dá»¥, hÃ ng thÃ¡ng hoáº·c hÃ ng quÃ½).\nPhÃ¢n tÃ­ch nhÃ³m dá»±a trÃªn thá»i gian cho tháº¥y cÃ¡ch hÃ nh vi cá»§a khÃ¡ch hÃ ng thay Ä‘á»•i dá»±a trÃªn thá»i Ä‘iá»ƒm há» báº¯t Ä‘áº§u sá»­ dá»¥ng sáº£n pháº©m cá»§a cÃ´ng ty.\nVÃ­ dá»¥, so sÃ¡nh tá»· lá»‡ giá»¯ láº¡i giá»¯a Ä‘Äƒng kÃ½ Q1 vÃ  Q2 cÃ³ thá»ƒ lÃ m ná»•i báº­t cÃ¡c váº¥n Ä‘á» tiá»m áº©n hoáº·c thÃ¡ch thá»©c tá»« Ä‘á»‘i thá»§.\nNÃ³ cÅ©ng giÃºp Ä‘Ã¡nh giÃ¡ tá»· lá»‡ chuyá»ƒn Ä‘á»•i vÃ  xÃ¡c Ä‘á»‹nh nguyÃªn nhÃ¢n Ä‘áº±ng sau viá»‡c máº¥t khÃ¡ch hÃ ng.\nCohort Dá»±a trÃªn lá»£i Ã­ch Hiá»ƒu RÃµ HÃ nh Vi KhÃ¡ch HÃ ng: PhÃ¢n tÃ­ch nhÃ³m mang láº¡i cÃ¡i nhÃ¬n tá»· má»‹ vá» cÃ¡ch cÃ¡c nhÃ³m khÃ¡ch hÃ ng khÃ¡c nhau thá»ƒ hiá»‡n hÃ nh vi qua thá»i gian.\nTá»‘i Æ¯u HÃ³a Tiáº¿p Thá»‹: Báº±ng cÃ¡ch hiá»ƒu hÃ nh vi nhÃ³m, doanh nghiá»‡p cÃ³ thá»ƒ Ä‘iá»u chá»‰nh ná»— lá»±c tiáº¿p thá»‹ vÃ  chiáº¿n lÆ°á»£c giao tiáº¿p.\nCáº£i Tiáº¿n Sáº£n Pháº©m: CÃ¡c thÃ´ng tin tá»« phÃ¢n tÃ­ch nhÃ³m hÆ°á»›ng dáº«n cho sá»± cáº£i tiáº¿n sáº£n pháº©m vÃ  phÃ¡t triá»ƒn tÃ­nh nÄƒng.\nCÃ¢u nÃ³i Äƒn tiá»n: phÃ¢n tÃ­ch khÃ´ng chá»‰ Ä‘Æ¡n thuáº§n lÃ  vá» nhá»¯ng con sá»‘; nÃ³ lÃ  vá» viá»‡c hiá»ƒu nhá»¯ng cÃ¢u chuyá»‡n Ä‘áº±ng sau nhá»¯ng con sá»‘ Ä‘Ã³ vÃ  ra quyáº¿t Ä‘á»‹nh thÃ´ng tin dá»±a trÃªn hÃ nh vi cá»§a khÃ¡ch hÃ ng.\n6. PhÃ¢n tÃ­ch thuá»™c tÃ­nh - PhÃ¢n tÃ­ch káº¿t há»£p (conjoint analysis) PhÃ¢n tÃ­ch káº¿t há»£p lÃ  má»™t ká»¹ thuáº­t thá»‘ng kÃª Ä‘Æ°á»£c sá»­ dá»¥ng trong nghiÃªn cá»©u thá»‹ trÆ°á»ng Ä‘á»ƒ hiá»ƒu cÃ¡ch khÃ¡ch hÃ ng Ä‘Ã¡nh giÃ¡ cÃ¡c thuá»™c tÃ­nh khÃ¡c nhau cá»§a má»™t sáº£n pháº©m hoáº·c dá»‹ch vá»¥.\nNÃ³ dá»±a trÃªn nguyÃªn táº¯c ráº±ng báº¥t ká»³ sáº£n pháº©m nÃ o cÅ©ng cÃ³ thá»ƒ phÃ¢n rÃ£ thÃ nh má»™t táº­p há»£p cÃ¡c thuá»™c tÃ­nh áº£nh hÆ°á»Ÿng Ä‘áº¿n giÃ¡ trá»‹ Ä‘Æ°á»£c ngÆ°á»i dÃ¹ng cáº£m nháº­n Ä‘á»‘i vá»›i má»™t má»¥c hoáº·c dá»‹ch vá»¥.\nPhÃ¢n tÃ­ch káº¿t há»£p thÆ°á»ng Ä‘Æ°á»£c thá»±c hiá»‡n thÃ´ng qua má»™t cuá»™c kháº£o sÃ¡t chuyÃªn biá»‡t yÃªu cáº§u ngÆ°á»i tiÃªu dÃ¹ng xáº¿p háº¡ng sá»± quan trá»ng cá»§a cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»¥ thá»ƒ. PhÃ¢n tÃ­ch káº¿t quáº£ cho phÃ©p cÃ´ng ty gÃ¡n giÃ¡ trá»‹ cho má»—i Ä‘áº·c Ä‘iá»ƒm.\nCÃ³ nhiá»u loáº¡i phÃ¢n tÃ­ch káº¿t há»£p, bao gá»“m\nPhÃ¢n tÃ­ch Há»™i tá»¥ Dá»±a trÃªn Sá»± Lá»±a Chá»n (CBC)\nPhÃ¢n tÃ­ch Há»™i tá»¥ ThÃ­ch á»©ng (ACA)\nPhÃ¢n tÃ­ch Há»™i tá»¥ ToÃ n bá»™\nPhÃ¢n tÃ­ch Há»™i tá»¥ MaxDiff\nViá»‡c cÃ¡c cÃ´ng ty sá»­ dá»¥ng loáº¡i phÃ¢n tÃ­ch há»™i tá»¥ nÃ o, phá»¥ thuá»™c vÃ o má»¥c tiÃªu Ä‘á»‹nh hÃ¬nh phÃ¢n tÃ­ch vÃ  loáº¡i sáº£n pháº©m hoáº·c dá»‹ch vá»¥ Ä‘ang Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡.\nPhÃ¢n tÃ­ch há»™i tá»¥ cÃ³ thá»ƒ giÃºp doanh nghiá»‡p hiá»ƒu Ä‘Æ°á»£c nhá»¯ng Ä‘áº·c tÃ­nh nÃ o cá»§a sáº£n pháº©m hoáº·c dá»‹ch vá»¥ cá»§a há» Ä‘Æ°á»£c khÃ¡ch hÃ ng Ä‘Ã¡nh giÃ¡ cao nháº¥t, vÃ  gÃ¡n má»™t giÃ¡ trá»‹ cá»¥ thá»ƒ cho má»—i Ä‘áº·c tÃ­nh. Hiá»ƒu biáº¿t nÃ y cho phÃ©p xÃ¢y dá»±ng chiáº¿n lÆ°á»£c cÃ³ thÃ´ng tin hÆ¡n tá»« lÃ¢u dÃ i Ä‘áº¿n giÃ¡ cáº£ vÃ  bÃ¡n hÃ ng.\n7. PhÃ¢n tÃ­ch vÄƒn báº£n (Text analysis) PhÃ¢n tÃ­ch vÄƒn báº£n lÃ  quÃ¡ trÃ¬nh trÃ­ch xuáº¥t thÃ´ng tin giÃ¡ trá»‹ tá»« dá»¯ liá»‡u vÄƒn báº£n khÃ´ng cÃ³ cáº¥u trÃºc. NÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho nhiá»u má»¥c Ä‘Ã­ch khÃ¡c nhau nhÆ° hiá»ƒu pháº£n há»“i cá»§a khÃ¡ch hÃ ng, tÃ³m táº¯t tÃ i liá»‡u, xÃ¡c Ä‘á»‹nh chá»§ Ä‘á» vÃ  phÃ¢n loáº¡i cáº£m xÃºc. PhÃ¢n tÃ­ch vÄƒn báº£n cÃ³ thá»ƒ thá»±c hiá»‡n báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p vÃ  ká»¹ thuáº­t khÃ¡c nhau, phá»¥ thuá»™c vÃ o loáº¡i vÄƒn báº£n vÃ  má»¥c tiÃªu nghiÃªn cá»©u. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ phÆ°Æ¡ng phÃ¡p phá»• biáº¿n:\nSentiment analysis: PhÆ°Æ¡ng phÃ¡p nÃ y xÃ¡c Ä‘á»‹nh cáº£m xÃºc cá»§a vÄƒn báº£n, nhÆ° tÃ­ch cá»±c, tiÃªu cá»±c hoáº·c trung tÃ­nh. NÃ³ cÃ³ thá»ƒ giÃºp doanh nghiá»‡p Ä‘o lÆ°á»ng sá»± hÃ i lÃ²ng cá»§a khÃ¡ch hÃ ng, danh tiáº¿ng thÆ°Æ¡ng hiá»‡u vÃ  Ä‘Ã¡nh giÃ¡ sáº£n pháº©m.\nPhÃ¢n tÃ­ch chá»§ Ä‘á»: PhÆ°Æ¡ng phÃ¡p nÃ y xÃ¡c Ä‘á»‹nh cÃ¡c chá»§ Ä‘á» chÃ­nh cá»§a vÄƒn báº£n, nhÆ° thá»ƒ thao, chÃ­nh trá»‹, hoáº·c giáº£i trÃ­. NÃ³ cÃ³ thá»ƒ giÃºp doanh nghiá»‡p tá»• chá»©c vÃ  phÃ¢n loáº¡i lÆ°á»£ng lá»›n dá»¯ liá»‡u vÄƒn báº£n nhÆ° email, bÃ i viáº¿t trÃªn máº¡ng xÃ£ há»™i vÃ  yÃªu cáº§u há»— trá»£.\nTrÃ­ch xuáº¥t tá»« khÃ³a: PhÆ°Æ¡ng phÃ¡p nÃ y trÃ­ch xuáº¥t cÃ¡c tá»« hoáº·c cá»¥m tá»« quan trá»ng nháº¥t tá»« vÄƒn báº£n, nhÆ° tÃªn, Ä‘á»‹a Ä‘iá»ƒm hoáº·c khÃ¡i niá»‡m. NÃ³ cÃ³ thá»ƒ giÃºp doanh nghiá»‡p tÃ¬m kiáº¿m thÃ´ng tin quan trá»ng nhÆ° váº¥n Ä‘á» cá»§a khÃ¡ch hÃ ng, Ä‘áº·c Ä‘iá»ƒm sáº£n pháº©m hoáº·c xu hÆ°á»›ng thá»‹ trÆ°á»ng.\nPhÃ¢n tÃ­ch vÄƒn báº£n cÃ³ thá»ƒ thá»±c hiá»‡n thá»§ cÃ´ng hoáº·c tá»± Ä‘á»™ng. PhÃ¢n tÃ­ch vÄƒn báº£n thá»§ cÃ´ng tá»‘n thá»i gian, dá»… chÃ¡n vÃ  dá»… gáº·p lá»—i. PhÃ¢n tÃ­ch vÄƒn báº£n tá»± Ä‘á»™ng sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t há»c mÃ¡y Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u vÄƒn báº£n má»™t cÃ¡ch nhanh chÃ³ng, chÃ­nh xÃ¡c vÃ  cÃ³ thá»ƒ má»Ÿ rá»™ng. Hiá»‡n nay, CÃ³ nhiá»u cÃ´ng cá»¥ trá»±c tuyáº¿n giÃºp thá»±c hiá»‡n phÃ¢n tÃ­ch vÄƒn báº£n má»™t cÃ¡ch tá»± Ä‘á»™ng. Vá» tiáº¿ng viá»‡t thÃ¬ chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng thÆ° viá»‡n under the sea, hoáº·c náº¿u cÃ¡c báº¡n cÃ³ dá»¯ liá»‡u lá»›n thÃ¬ cÃ³ thá»ƒ implement láº¡i cÃ¡c thuáº­t toÃ¡n Ä‘Ã£ public vÃ  train láº¡i mÃ´ hÃ¬nh\n8. PhÃ¢n tÃ­ch chuá»—i thá»i gian (time series analysis) PhÃ¢n tÃ­ch chuá»—i thá»i gian lÃ  má»™t cÃ¡ch cá»¥ thá»ƒ Ä‘á»ƒ phÃ¢n tÃ­ch má»™t chuá»—i Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Æ°á»£c thu tháº­p trong má»™t khoáº£ng thá»i gian. KhÃ¡c vá»›i viá»‡c thu tháº­p dá»¯ liá»‡u ngáº«u nhiÃªn hoáº·c ráº£i rÃ¡c, phÃ¢n tÃ­ch chuá»—i thá»i gian liÃªn quan Ä‘áº¿n viá»‡c ghi láº¡i cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u á»Ÿ cÃ¡c khoáº£ng thá»i gian Ä‘á»u Ä‘áº·n trong má»™t khoáº£ng thá»i gian cá»‘ Ä‘á»‹nh. Sá»± khÃ¡c biá»‡t chÃ­nh náº±m á»Ÿ cÃ¡ch cÃ¡c biáº¿n thay Ä‘á»•i theo thá»i gian. Dá»¯ liá»‡u chuá»—i thá»i gian cung cáº¥p thÃ´ng tin quÃ½ giÃ¡ vá» xu hÆ°á»›ng, dá»± Ä‘oÃ¡n.\nPhÃ¢n tÃ­ch chuá»—i thá»i gian xá»­ lÃ½ cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Æ°á»£c sáº¯p xáº¿p theo thá»i gian. VÃ­ dá»¥ bao gá»“m chiá»u cao cá»§a Ä‘á»£t thá»§y triá»u, tá»‘c Ä‘á»™ giÃ³ trÃªn biá»ƒn, Ä‘á»™ dÃ y cá»§a sÆ°Æ¡ng mÃ¹, giÃ¡ Ä‘Ã³ng cá»­a hÃ ng ngÃ y trÃªn thá»‹ trÆ°á»ng chá»©ng khoÃ¡n, Ä‘á»ƒ:\nHiá»ƒu rÃµ Xu hÆ°á»›ng: CÃ¡c tá»• chá»©c sá»­ dá»¥ng phÃ¢n tÃ­ch chuá»—i thá»i gian Ä‘á»ƒ hiá»ƒu nguyÃªn nhÃ¢n cÆ¡ báº£n cá»§a cÃ¡c xu hÆ°á»›ng hoáº·c mÃ´ hÃ¬nh há»‡ thá»‘ng theo thá»i gian. CÃ¡c biá»ƒu Ä‘á»“ minh há»a xu hÆ°á»›ng theo mÃ¹a vá»¥, vÃ  cÃ¡c ná»n táº£ng phÃ¢n tÃ­ch hiá»‡n Ä‘áº¡i vÆ°á»£t xa cÃ¡c biá»ƒu Ä‘á»“ Ä‘Æ°á»ng Ä‘Æ¡n giáº£n.\nDá»± Ä‘oÃ¡n: Dá»± bÃ¡o chuá»—i thá»i gian dá»± Ä‘oÃ¡n giÃ¡ trá»‹ tÆ°Æ¡ng lai dá»±a trÃªn dá»¯ liá»‡u lá»‹ch sá»­. NÃ³ giÃºp dá»± Ä‘oÃ¡n cÃ¡c biáº¿n Ä‘á»•i, nhÆ° mÃ¹a vá»¥ hoáº·c hÃ nh vi chu ká»³.\nTÃ i chÃ­nh: PhÃ¢n tÃ­ch biáº¿n Ä‘á»™ng tiá»n tá»‡, giÃ¡ cá»• phiáº¿u vÃ  cÃ¡c chá»‰ sá»‘ kinh táº¿.\nBÃ¡n láº»: NghiÃªn cá»©u dá»¯ liá»‡u bÃ¡n hÃ ng vÃ  mÃ´ hÃ¬nh yÃªu cáº§u.\nDá»± bÃ¡o thá»i tiáº¿t: Dá»± Ä‘oÃ¡n Ä‘iá»u kiá»‡n thá»i tiáº¿t dá»±a trÃªn dá»¯ liá»‡u lá»‹ch sá»­.\nChÄƒm sÃ³c sá»©c khá»e: GiÃ¡m sÃ¡t cÃ¡c chá»‰ sá»‘ quan trá»ng cá»§a bá»‡nh nhÃ¢n theo thá»i gian.\nKinh táº¿ há»c: Theo dÃµi cÃ¡c chá»‰ sá»‘ kinh táº¿ nhÆ° tÄƒng trÆ°á»Ÿng GDP.\n9. Khai thÃ¡c dá»¯ liá»‡u (Data mining) Khai thÃ¡c dá»¯ liá»‡u lÃ  quÃ¡ trÃ¬nh trÃ­ch xuáº¥t vÃ  khÃ¡m phÃ¡ cÃ¡c mÃ´ hÃ¬nh trong cÃ¡c táº­p dá»¯ liá»‡u lá»›n liÃªn quan Ä‘áº¿n cÃ¡c phÆ°Æ¡ng phÃ¡p á»Ÿ sá»± giao lá»™ giá»¯a há»c mÃ¡y, thá»‘ng kÃª vÃ  há»‡ thá»‘ng cÆ¡ sá»Ÿ dá»¯ liá»‡u. Khai thÃ¡c dá»¯ liá»‡u cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho nhiá»u má»¥c Ä‘Ã­ch, nhÆ° hiá»ƒu cáº¥u trÃºc vÃ  mÃ´ hÃ¬nh cÆ¡ báº£n cá»§a dá»¯ liá»‡u, phÃ¢n tÃ­ch hiá»‡u suáº¥t cá»§a má»™t cÃ´ng ty, hoáº·c dá»± Ä‘oÃ¡n doanh thu vÃ  áº£nh hÆ°á»Ÿng cá»§a quyáº¿t Ä‘á»‹nh kinh doanh. Khai thÃ¡c dá»¯ liá»‡u phá»¥ thuá»™c vÃ o viá»‡c thu tháº­p dá»¯ liá»‡u hiá»‡u quáº£, lÆ°u trá»¯ vÃ  xá»­ lÃ½ mÃ¡y tÃ­nh.\nCÃ¡c bÃ i toÃ¡n trong data mining bao gá»“m: Classification, Clustering, Association rule mining, Sequential pattern mining, Anomaly detection\nKhai thÃ¡c dá»¯ liá»‡u cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng trong nhiá»u lÄ©nh vá»±c nhÆ° tÃ i chÃ­nh, bÃ¡n láº», dá»± bÃ¡o thá»i tiáº¿t, chÄƒm sÃ³c sá»©c khá»e vÃ  kinh táº¿. Khai thÃ¡c dá»¯ liá»‡u cÃ³ thá»ƒ giÃºp tá»• chá»©c Ä‘áº¡t Ä‘Æ°á»£c thÃ´ng tin, Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh tá»‘t hÆ¡n vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a há». Tuy nhiÃªn, khai thÃ¡c dá»¯ liá»‡u cÅ©ng Ä‘áº·t ra má»™t sá»‘ thÃ¡ch thá»©c vÃ  rá»§i ro, nhÆ° cháº¥t lÆ°á»£ng dá»¯ liá»‡u, quyá»n riÃªng tÆ°, an ninh vÃ  Ä‘áº¡o Ä‘á»©c. Do Ä‘Ã³, khai thÃ¡c dá»¯ liá»‡u nÃªn Ä‘Æ°á»£c thá»±c hiá»‡n cáº©n tháº­n vÃ  tÃ´n trá»ng Ä‘á»‘i vá»›i dá»¯ liá»‡u vÃ  nhá»¯ng ngÆ°á»i liÃªn quan.\n10. CÃ¢y quyáº¿t Ä‘á»‹nh (decision tree) Má»™t cÃ¢y quyáº¿t Ä‘á»‹nh lÃ  má»™t biá»ƒu diá»…n cá»§a cÃ¡c duyá»‡t Ä‘á»‹nh dá»©oi dáº¡ng cÃ¢y. NÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho cáº£ cÃ¡c nhiá»‡m vá»¥ phÃ¢n loáº¡i vÃ  há»“i quy trong há»c mÃ¡y giÃ¡m sÃ¡t. Má»™t cÃ¢y quyáº¿t Ä‘á»‹nh bao gá»“m cÃ¡c nÃºt, nhÃ¡nh vÃ  lÃ¡ tÆ°Æ¡ng á»©ng vá»›i cÃ¡c Ä‘áº·c trÆ°ng, quy táº¯c vÃ  dá»± Ä‘oÃ¡n cá»§a dá»¯ liá»‡u. Má»™t cÃ¢y quyáº¿t Ä‘á»‹nh Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch chia dá»¯ liá»‡u thÃ nh cÃ¡c táº­p con dá»±a trÃªn giÃ¡ trá»‹ cá»§a cÃ¡c Ä‘áº·c trÆ°ng cho Ä‘áº¿n khi Ä‘áº¡t Ä‘áº¿n má»™t tiÃªu chÃ­ dá»«ng. TiÃªu chÃ­ chia thÆ°á»ng dá»±a trÃªn má»™t Ä‘á»™ Ä‘á»“ng nháº¥t hoáº·c phÆ°Æ¡ng sai, cháº³ng háº¡n nhÆ° entropy hoáº·c chá»‰ sá»‘ Gini\nMá»™t sá»‘ Æ°u Ä‘iá»ƒm cá»§a cÃ¢y quyáº¿t Ä‘á»‹nh bao gá»“m:\nDá»… hiá»ƒu vÃ  giáº£i thÃ­ch, vÃ¬ chÃºng giá»‘ng nhÆ° quÃ¡ trÃ¬nh suy luáº­n cá»§a con ngÆ°á»i.\nCÃ³ thá»ƒ xá»­ lÃ½ cáº£ dá»¯ liá»‡u sá»‘ vÃ  dá»¯ liá»‡u phÃ¢n loáº¡i, cÅ©ng nhÆ° cÃ³ thá»ƒ xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u.\nChá»‹u Ä‘Æ°á»£c áº£nh hÆ°á»Ÿng tá»« nhiá»…u vÃ  giá»¯ nguyÃªn tÃ­nh cháº¥t khi dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng.\nMá»™t sá»‘ nhÆ°á»£c Ä‘iá»ƒm cá»§a cÃ¢y quyáº¿t Ä‘á»‹nh lÃ :\nDá»… bá»‹ overfitting, cÃ¢y cÃ ng sÃ¢u, cÃ ng phá»©c táº¡p thÃ¬ cÃ ng dá»… bá»‹ overfitting.\nCÃ³ thá»ƒ khÃ´ng á»•n Ä‘á»‹nh, vÃ¬ nhá»¯ng thay Ä‘á»•i nhá» trong dá»¯ liá»‡u cÃ³ thá»ƒ dáº«n Ä‘áº¿n nhá»¯ng thay Ä‘á»•i lá»›n trong cáº¥u trÃºc cÃ¢y.\nCÃ³ thá»ƒ bá»‹ thiÃªn vá»‹, vÃ¬ chÃºng cÃ³ xu hÆ°á»›ng Æ°a thÃ­ch Ä‘áº·c trÆ°ng cÃ³ nhiá»u cáº¥p Ä‘á»™ hoáº·c loáº¡i.\nNguá»“n: Regression analysis - Wikipedia. https://en.wikipedia.org/wiki/Regression_analysis.\nRegression Analysis - Formulas, Explanation, Examples and Definitions. https://corporatefinanceinstitute.com/resources/data-science/regression-analysis/.\nSimple Linear Regression | An Easy Introduction \u0026amp; Examples - Scribbr. https://www.scribbr.com/statistics/simple-linear-regression/.\nFactor analysis - Wikipedia. https://en.wikipedia.org/wiki/Factor_analysis.\nFactor Analysis Guide with an Example - Statistics By Jim. https://statisticsbyjim.com/basics/factor-analysis/.\nFactor Analysis - Steps, Methods and Examples - Research Method. https://researchmethod.net/factor-analysis/.\nFactor analysis - Wikipedia. https://en.wikipedia.org/wiki/Factor_analysis.\nFactor Analysis Guide with an Example - Statistics By Jim. https://statisticsbyjim.com/basics/factor-analysis/.\nFactor Analysis - Steps, Methods and Examples - Research Method. https://researchmethod.net/factor-analysis/.\nWhat are Neural Networks? | IBM. https://www.ibm.com/topics/neural-networks.\nNeural network - Wikipedia. https://en.wikipedia.org/wiki/Neural_network.\nWhat are Neural Networks? | IBM. https://www.ibm.com/topics/neural-networks.\nNeural network - Wikipedia. https://en.wikipedia.org/wiki/Neural_network.\nWhat Is a Neural Network? - Investopedia. https://www.investopedia.com/terms/n/neuralnetwork.asp.\nWhat is a neural network? A computer scientist explains - The Conversation. https://theconversation.com/what-is-a-neural-network-a-computer-scientist-explains-151897.\nCluster analysis - Wikipedia. https://en.wikipedia.org/wiki/Cluster_analysis.\nCluster Analysis - Types, Methods and Examples - Research Method. https://researchmethod.net/cluster-analysis/.\nWhat Is Cluster Analysis? (Examples + Applications) | Built In. https://builtin.com/data-science/cluster-analysis.\nCluster analysis - Wikipedia. https://en.wikipedia.org/wiki/Cluster_analysis.\nCluster Analysis - Types, Methods and Examples - Research Method. https://researchmethod.net/cluster-analysis/.\nWhat Is Cluster Analysis? (Examples + Applications) | Built In. https://builtin.com/data-science/cluster-analysis.\nGetty Images. https://www.gettyimages.com/detail/illustration/big-data-illustration-with-structuring-map-royalty-free-illustration/1139303464.\nhttps://online.hbs.edu/blog/post/what-is-conjoint-analysis\nWhat Is Conjoint Analysis \u0026amp; How Can You Use It? | HBS Online. https://online.hbs.edu/blog/post/what-is-conjoint-analysis.\nConjoint analysis - Wikipedia. https://en.wikipedia.org/wiki/Conjoint_analysis.\nWhat is a Conjoint Analysis? Types \u0026amp; Use Cases - Qualtrics. https://www.qualtrics.com/experience-management/research/types-of-conjoint/.\nen.wikipedia.org. https://en.wikipedia.org/wiki/Conjoint_analysis.\nText Analysis: Definition, Benefits \u0026amp; Examples - Qualtrics XM. https://www.qualtrics.com/experience-management/research/text-analysis/.\nTextual Analysis | Guide, 3 Approaches \u0026amp; Examples - Scribbr. https://www.scribbr.com/methodology/textual-analysis/.\nTime Series Analysis: Definition, Types \u0026amp; Techniques | Tableau. https://www.tableau.com/learn/articles/time-series-analysis.\nTime series - Wikipedia. https://en.wikipedia.org/wiki/Time_series.\nTime Series Analysis and Forecasting | Data-Driven Insights. https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-to-time-series-analysis/.\nData mining - Wikipedia. https://en.wikipedia.org/wiki/Data_mining.\nWhat Is Data Mining? How It Works, Benefits, Techniques, and Examples. https://www.investopedia.com/terms/d/datamining.asp.\nWhat is Data Mining? | IBM. https://www.ibm.com/topics/data-mining.\nDecision tree - Wikipedia. https://en.wikipedia.org/wiki/Decision_tree.\nDecision Tree - GeeksforGeeks. https://www.geeksforgeeks.org/decision-tree/.\nWhat is a Decision Tree | IBM. https://www.ibm.com/topics/decision-trees.\nen.wikipedia.org. https://en.wikipedia.org/wiki/Decision_tree.\n","date":"Feb 16, 2024","img":"https://unsplash.it/1920/1080?image=4","permalink":"/blog/2024-02-16-cac-phuong-phap-phan-tich-du-lieu-lon/","series":null,"tags":["bigdata"],"title":"CÃ¡c PhÆ°Æ¡ng PhÃ¡p PhÃ¢n TÃ­ch Dá»¯ Liá»‡u Lá»›n"},{"categories":null,"content":" 1. MÃ´ hÃ¬nh thÃ¡c nÆ°á»›c (waterfall model) 2. MÃ´ hÃ¬nh chá»¯ V (V model) 3. MÃ´ hÃ¬nh tiáº¿p cáº­n láº·p (Interactive Model) 4. MÃ´ hÃ¬nh xoáº¯n á»‘c (Spiral model) 6. NhÃ³m mÃ´ hÃ¬nh Agile 6.1 MÃ´ hÃ¬nh SCRUM 6.2 MÃ´ hÃ¬nh KANBAN 6.3 MÃ´ hÃ¬nh EXTREME PROGRAMMING - láº­p trÃ¬nh cá»±c háº¡n - XP ChÃ o táº¥t cáº£ cÃ¡c báº¡n, chÃºc cÃ¡c báº¡n nÄƒm má»›i an lÃ nh vÃ  háº¡nh phÃºc.\nHÃ´m nay, mÃ¹ng 4 táº¿t, mÃ¬nh ráº£nh rá»—i xÃ­u nÃªn chia sáº½ vá»›i má»i ngÆ°á»i bÃ i viáº¿t má»›i, tá»•ng há»£p nhá» vá» cÃ¡c mÃ´ hÃ¬nh phÃ¡t triá»ƒn pháº§n má»m\n1. MÃ´ hÃ¬nh thÃ¡c nÆ°á»›c (waterfall model) MÃ´ hÃ¬nh thÃ¡c nÆ°á»›c lÃ  má»™t mÃ´ hÃ¬nh tuyáº¿n tÃ­nh, trong Ä‘Ã³ cÃ¡c giai Ä‘oáº¡n phÃ¡t triá»ƒn diá»…n ra theo má»™t trÃ¬nh tá»± tuyáº¿n tÃ­nh. Má»—i giai Ä‘oáº¡n chá»‰ Ä‘Æ°á»£c thá»±c hiá»‡n tiáº¿p khi giai Ä‘oáº¡n trÆ°á»›c Ä‘Ã£ káº¿t thÃºc. MÃ´ hÃ¬nh nÃ y dá»… sá»­ dá»¥ng, dá»… tiáº¿p cáº­n, nhÆ°ng ráº¥t khÃ³ Ä‘á»ƒ quay láº¡i giai Ä‘oáº¡n nÃ o khi nÃ³ Ä‘Ã£ káº¿t thÃºc vÃ  Ã­t tÃ­nh linh hoáº¡t.\nCÃ¡c giai Ä‘oáº¡n Ä‘i theo tá»«ng bÆ°á»›c:\nRequirements Gathering and Analysis \u0026raquo; System Design \u0026raquo; Implementation \u0026raquo; Testing Deployment \u0026raquo; Maintenance\n2. MÃ´ hÃ¬nh chá»¯ V (V model) lÃ  mÃ´ hÃ¬nh thÃ¡c nÆ°á»›c má»Ÿ rá»™ng, phÃ¡t triá»ƒn cÃ¡c bÃ i kiá»ƒm tra vÃ  kiá»ƒm thá»­ song song vá»›i tá»«ng giai Ä‘oáº¡n phÃ¡t triá»ƒn, nháº±m háº¡n cháº¿ nhá»¯ng khuyáº¿t Ä‘iá»ƒm cá»§a mÃ´ hÃ¬nh waterfall. PhÃ¹ há»£p vá»›i dá»± Ã¡n vá»«a vÃ  nhá».\nVáº½ hÆ¡i xáº¥u\nRequirements Gathering and Analysis \u003c\u003c acceptance test design \u003e\u003e acceptance testing â†“ â†‘ System Design \u003c\u003c system test design \u003e\u003eSystem testing â†“ â†‘ Architecture Design \u003c\u003c integration test design \u003e\u003e integration testing â†“ â†‘ Module design \u003c\u003c Unit test design \u003e\u003e Unit test â†“ â†‘ Implementation Äá»‘i vá»›i dá»± Ã¡n lá»›n, thÃ¬ khÃ´ng nÃªn Ã¡p dá»¥ng mÃ´ hÃ¬nh nÃ y.\n3. MÃ´ hÃ¬nh tiáº¿p cáº­n láº·p (Interactive Model) má»—i quy trÃ¬nh phÃ¡t triá»ƒn lÃ  má»™t vÃ²ng láº·p\nRequirement ==\u0026gt; Analytic and design â†‘ â†“ init ==\u0026gt; plaining implement =\u0026gt; deploy â†‘ â†“ evaluation \u0026lt;== testing\n4. MÃ´ hÃ¬nh xoáº¯n á»‘c (Spiral model) MÃ´ hÃ¬nh linh hoáº¡t káº¿t há»£p cÃ¡c khÃ­a cáº¡nh cá»§a mÃ´ hÃ¬nh thÃ¡c nÆ°á»›c vÃ  phÆ°Æ¡ng phÃ¡p Agile. MÃ´ hÃ¬nh nÃ y chÃº trá»ng vÃ o phÃ¢n tÃ­ch rá»§i ro dá»± Ã¡n, báº¯t Ä‘áº§u vá»›i yÃªu cáº§u/má»¥c tiÃªu thiáº¿t káº¿ vÃ  káº¿t thÃºc vá»›i viá»‡c khÃ¡ch hÃ ng kiá»ƒm tra tiáº¿n Ä‘á»™ cá»§a tá»«ng giai Ä‘oáº¡n. MÃ´ hÃ¬nh nÃ y cÃ³ tÃ­nh linh hoáº¡t cao, nhÆ°ng cÅ©ng tá»‘n nhiá»u thá»i gian vÃ  tÃ i nguyÃªn\nÆ¯u: Ä‘áº·t trá»ng tÃ¢m vÃ o quáº£n lÃ½ vÃ  giáº£m thiá»ƒu rá»§i ro\nNhÆ°á»£c: chi phÃ­ cao\nthÃ­ch há»£p cho cÃ¡c dá»± Ã¡n lá»›n, dá»± Ã¡n phá»©c táº¡p, dá»± Ã¡n cÃ³ nguy cÆ¡ thay Ä‘á»•i cao, dá»± Ã¡n láº§n Ä‘Æ°á»ng dÃ² bÆ°á»›c.\nMÃ´ hÃ¬nh tÄƒng trÆ°á»Ÿng (Incremental model): MÃ´ hÃ¬nh phÃ¡t triá»ƒn tá»«ng bÆ°á»›c má»™t, bá»• sung cÃ¡c tÃ­nh nÄƒng má»›i vÃ o phiÃªn báº£n cÅ© cho Ä‘áº¿n khi Ä‘áº¡t Ä‘Æ°á»£c phiÃªn báº£n hoÃ n chá»‰nh.\nMÃ´ hÃ¬nh nÃ y giÃºp sáº£n xuáº¥t pháº§n má»m lÃ m viá»‡c á»Ÿ giai Ä‘oáº¡n trung gian, nhÆ°ng cÅ©ng cÃ³ thá»ƒ gÃ¢y khÃ³ khÄƒn trong viá»‡c tÃ­ch há»£p cÃ¡c phiÃªn báº£n khÃ¡c nhau.\n6. NhÃ³m mÃ´ hÃ¬nh Agile 6.1 MÃ´ hÃ¬nh SCRUM MÃ´ hÃ¬nh nÃ y hiá»‡n Ä‘ang Ä‘Æ°á»£c ráº¥t nhiá»u cÃ´ng ty product vÃ  outsource sá»­ dá»¥ng, gá»“m cÃ³ cÃ¡c thÃ nh pháº§n cÆ¡ báº£n sau\nTá»• chá»©c Organization : Product Owner, ScrumMaster, Development Team\nTÃ i liá»‡u (Atifacts): Product Backlog, Sprint Backlog, Estimation\nQui trÃ¬nh(Process): Sprint Planning meeting, Review, Daily Scrum Meeting\nÆ¯u Ä‘iá»ƒm cá»§a mÃ´ hÃ¬nh:\nMá»™t ngÆ°á»i cÃ³ thá»ƒ thá»±c hiá»‡n nhiá»u viá»‡c vÃ­ dá»¥ nhÆ° dev cÃ³ thá»ƒ test.\nPhÃ¡t hiá»‡n lá»—i sá»›m.\nCÃ³ kháº£ nÄƒng Ã¡p dá»¥ng Ä‘Æ°á»£c cho nhá»¯ng dá»± Ã¡n mÃ  yÃªu cáº§u khÃ¡ch hÃ ng khÃ´ng rÃµ rÃ ng ngay tá»« Ä‘áº§u.\nNhÆ°á»£c Ä‘iá»ƒm cá»§a mÃ´ hÃ¬nh:\nTrÃ¬nh Ä‘á»™ cá»§a nhÃ³m cáº§n cÃ³ má»™t ká»¹ nÄƒng nháº¥t Ä‘á»‹nh.\nPháº£i cÃ³ sá»± hiá»ƒu biáº¿t vá» mÃ´ hÃ¬nh aglie.\nKhÃ³ khÄƒn trong viá»‡c xÃ¡c Ä‘á»‹nh ngÃ¢n sÃ¡ch vÃ  thá»i gian.\nLuÃ´n nghe Ã½ kiáº¿n pháº£n há»“i tá»« khÃ¡ch hÃ ng vÃ  thay Ä‘á»•i theo nÃªn thá»i gian sáº½ kÃ©o dÃ i.\n6.2 MÃ´ hÃ¬nh KANBAN MÃ´ hÃ¬nh nÃ y xÃ¢y dá»±ng 1 báº£ng tÃªn lÃ  KANBAN Ä‘á»ƒ quáº£n lÃ½ cÃ´ng viá»‡c, cÃ¡i nÃ y khÃ¡ Ä‘Æ¡n giáº£n nhÆ°ng cá»±c ká»³ hiá»‡u quáº£, chÃºng ta cÃ³ thá»ƒ xÃ¢y dá»±ng team KANBAN vÃ  member KANBAN (má»—i member tá»± xÃ¢y dá»±ng)\n6.3 MÃ´ hÃ¬nh EXTREME PROGRAMMING - láº­p trÃ¬nh cá»±c háº¡n - XP KhÃ¡c vá»›i mÃ´ hÃ¬nh Scrum táº­p trung vÃ o cáº¥p Ä‘á»™ quáº£n lÃ½ dá»± Ã¡n trá»ng tÃ¢m lÃ  Æ°u tiÃªn cÃ´ng viá»‡c vÃ  láº¥y pháº£n há»“i, XP láº¡i táº­p trung vÃ o phÃ¡t triá»ƒn pháº§n má»m cháº¥t lÆ°á»£ng cao song song vá»›i cháº¥t lÆ°á»£ng cuá»™c sá»‘ng cá»§a nhÃ³m phÃ¡t triá»ƒn\nCÃ¡c vai trÃ² trong CP: Huáº¥n luyá»‡n viÃªn(Coach), KhÃ¡ch hÃ ng (Customer), Láº­p trÃ¬nh viÃªn (Programmer), vÃ  Kiá»ƒm Ä‘á»‹nh viÃªn (Tester).\nCÃ¡c yáº¿u tá»‘ cá»‘t lÃµi cá»§a XP:\nGiÃ¡ trá»‹:\nGiao tiáº¿p: XP nháº¥n máº¡nh cÃ¡c cuá»™c tháº£o luáº­n trá»±c tiáº¿p kÃ¨n theo báº£ng vÃ  bÃºt, nÃ³i chung lÃ  tháº£o luáº­n face-to-face, khÃ´ng screen.\nÄÆ¡n giáº£n: Táº­p trung vÃ o giáº£i phÃ¡p Ä‘Æ¡n giáº£n nháº¥t mÃ  váº«n Ä‘Ã¡p á»©ng nhu cáº§u hoáº¡t Ä‘á»™ng. TrÃ¡nh sá»± phá»©c táº¡p khÃ´ng cáº§n thiáº¿t, trÃ¡nh sá»± dá»± Ä‘oÃ¡n.\nPháº£n há»“i: LiÃªn tá»¥c thu tháº­p pháº£n há»“i Ä‘á»ƒ cáº£i thiá»‡n.\nDÅ©ng cáº£m: HÃ nh Ä‘á»™ng máº¡nh máº½ trÆ°á»›c sá»± sá»£ hÃ£i. Sáºµn lÃ²ng nÃªu lÃªn váº¥n Ä‘á» tá»• chá»©c, dá»«ng cÃ¡c thá»±c hÃ nh khÃ´ng hiá»‡u quáº£ vÃ  cháº¥p nháº­n pháº£n há»“i.\nTÃ´n trá»ng: CÃ¡c thÃ nh viÃªn trong nhÃ³m pháº£i tÃ´n trá»ng láº«n nhau Ä‘á»ƒ giao tiáº¿p hiá»‡u quáº£ vÃ  cá»™ng tÃ¡c, tÆ°Æ¡ng tÃ¡c tá»‘t vá»›i nhau (hÆ¡i khÃ³).\nCÃ¡ch thá»©c thá»±c hiá»‡n:\nPhÃ¡t hÃ nh ThÆ°á»ng xuyÃªn: Chu ká»³ phÃ¡t triá»ƒn ngáº¯n, cáº­p nháº­t thÆ°á»ng xuyÃªn.\nLáº­p TrÃ¬nh ÄÃ´i: NhÃ  phÃ¡t triá»ƒn lÃ m viá»‡c theo cáº·p, liÃªn tá»¥c xem xÃ©t vÃ  cáº£i thiá»‡n mÃ£ nguá»“n.\nKiá»ƒm thá»­ ÄÆ¡n vá»‹: Kiá»ƒm thá»­ táº¥t cáº£ mÃ£ nguá»“n Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c.\nThiáº¿t káº¿ ÄÆ¡n giáº£n: Giá»¯ cho thiáº¿t káº¿ há»‡ thá»‘ng cÃ ng Ä‘Æ¡n giáº£n cÃ ng tá»‘t.\nTÆ°Æ¡ng TÃ¡c vá»›i KhÃ¡ch hÃ ng: Giao tiáº¿p thÆ°á»ng xuyÃªn vá»›i khÃ¡ch hÃ ng Ä‘á»ƒ hiá»ƒu rÃµ yÃªu cáº§u Ä‘ang thay Ä‘á»•i.\nXP phÃ¹ há»£p cho:\nYÃªu cáº§u pháº§n má»m thay Ä‘á»•i Ä‘á»™ng.\nRá»§i ro trong cÃ¡c dá»± Ã¡n cÃ³ thá»i gian cá»‘ Ä‘á»‹nh sá»­ dá»¥ng cÃ´ng nghá»‡ má»›i.\nNhÃ³m phÃ¡t triá»ƒn nhá», Ä‘áº·t táº¡i cÃ¹ng má»™t Ä‘á»‹a Ä‘iá»ƒm.\nCÃ´ng nghá»‡ cho phÃ©p kiá»ƒm thá»­ tá»± Ä‘á»™ng Ä‘Æ¡n vá»‹ vÃ  chá»©c nÄƒng.\nNguá»“n:\nhttps://en.wikipedia.org/wiki/Extreme_programming\n","date":"Feb 13, 2024","img":"https://unsplash.it/1920/1080?image=5","permalink":"/blog/2024-02-13-mo-hinh-phat-trien-phan-mem/","series":null,"tags":["software"],"title":"MÃ´ HÃ¬nh PhÃ¡t Triá»ƒn Pháº§n Má»m"},{"categories":null,"content":" I. PhÃ¢n loáº¡i cÃ¡c loáº¡i data analytics 1. No analytics: 2. Descriptive analytics - PhÃ¢n tÃ­ch mÃ´ táº£ Má»™t sá»‘ vÃ­ dá»¥ sá»­ dá»¥ng Descriptive analytics 3 Diagnostic analytics - PhÃ¢n tÃ­ch cháº©n Ä‘oÃ¡n TÃ¬m hiá»ƒu má»™t sá»‘ khÃ¡i niá»‡m cÆ¡ báº£n cá»§a Diagnostic analytics Má»™t sá»‘ vÃ­ dá»¥ sá»­ dá»¥ng diagnostic analytics 4 Predictive analytics: 5 VÃ­ dá»¥ cá»§a PREDICTIVE ANALYTICS trong thá»±c táº¿ 5 Prescriptive analytics: II. SÃ¡u bÆ°á»›c cÆ¡ báº£n báº¯t Ä‘áº§u má»™t dá»± Ã¡n Data Analytics BÆ°á»›c 0 : Prepair - Chuáº©n bá»‹ BÆ°á»›c 1: Define analytics requirement - TÃ¬m ra cÃ¡c cÃ¢u há»i cáº§n tráº£ lá»i BÆ°á»›c 2: Collecting data BÆ°á»›c 3: Clearning data BÆ°á»›c 4: Analyzing data BÆ°á»›c 5: Presenting Report III. CÃ¡c bÃ i toÃ¡n thÃ´ng dá»¥ng nháº¥t cá»§a DA Äo lÆ°á»ng tÃ¡c Ä‘á»™ng cá»§a thay Ä‘á»•i so vá»›i hiá»‡n táº¡i ( Quan trá»ng nháº¥t) Dá»± bÃ¡o ( Quan trá»ng) PhÃ¢n tÃ­ch khÃ¡ch hÃ ng Nháº­n dáº¡ng khÃ¡ch hÃ ng ( Quan trá»ng nháº¥t) Cross selling Customer journey Basket analytics Äo lÆ°á»ng thá»i háº¡n tÃ¡c Ä‘á»™ng cá»§a má»™t cáº£i tiáº¿n / sale Thá»© tá»± quan tÃ¢m cá»§a cÃ¡c cÃ´ng ty Sale -\u0026gt; marketing -\u0026gt; product -\u0026gt; hÆ°á»›ng phÃ¡t triá»ƒn.\nHiá»‡n nay, cÃ¡c cÃ´ng ty thÃ´ng thÆ°á»ng sáº½ tuyá»ƒn cÃ¡c báº¡n Data Analytics lÃ  nhá»¯ng báº¡n cÃ³ \u0026ldquo;kiáº¿n thá»©c ngÃ nh cá»©ng\u0026rdquo; cá»™ng vá»›i ká»¹ nÄƒng vá» data. Bá»Ÿi váº­y, nghá» nÃ y cÃ³ má»©c Ä‘á»™ cáº¡nh tranh khÃ¡ khá»‘c liá»‡t. Má»™t sá»‘ ngÃ nh cá»©ng hiá»‡n giá» mÃ¬nh cÃ³ thá»ƒ ká»ƒ tÃªn lÃ  marketting, quáº£n lÃ½ chuá»—i cung á»©ng, váº­n hÃ nh, kho bÃ£i, tÃ i chÃ­nh, v.v\nI. PhÃ¢n loáº¡i cÃ¡c loáº¡i data analytics TÃ³m táº¯t ngáº¯n gá»n, cho nhá»¯ng ai lÆ°á»i Ä‘á»c:\nNáº¿u tá»• chá»©c cá»§a báº¡n chÆ°a bao giá» phÃ¢n tÃ­ch dá»¯ liá»‡u, hÃ£y báº¯t Ä‘áº§u táº­p lÃ m quen vá»›i viá»‡c phÃ¢n tÃ­ch, báº±ng cÃ¡ch Ä‘Æ°a ra nhá»¯ng cÃ¢u há»i cáº§n sá»± tráº£ lá»i, Ä‘Æ°a ra cÃ¡c quy trÃ¬nh cáº§n sá»± tá»‘i Æ°u, thu tháº­p dá»¯ liá»‡u xung quanh cÃ¡c cÃ¢u há»i, cÃ¡c quy trÃ¬nh vÃ  sá»­ dá»¥ng má»™t trong cÃ¡c kiá»ƒu phÃ¢n tÃ­ch bÃªn dÆ°á»›i Ä‘á»ƒ váº½ láº¡i bá»©c tranh Ä‘áº§y Ä‘á»§.\nDescriptive: Trend cá»§a data chá»‰ ra cÃ¡i gÃ¬?\nDiagnostic: Yáº¿u tá»‘ nÃ o Ä‘Ã³ng gÃ³p vÃ o cÃ¡c trend trÃªn, táº¡i sao trend láº¡i xáº£y ra?\nPredictive: Náº¿u cÃ³ thá»ƒ, xÃ¡c Ä‘á»‹nh khi nÃ o trend lÃ  má»™t yáº¿u tá»‘ mÃ  nÃ³ váº«n cÃ²n tiáº¿p tá»¥c ( cÃ²n trend á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i) hoáº·c trend sáº½ láº·p láº¡i (chu ká»³)\nPrescriptive: ÄÃ o sÃ¢u vÃ o phÃ¢n tÃ­ch.\nNáº¿u chÃºng ta cÃ³ cÃ¡c thuáº­t toÃ¡n Ä‘á»™c quyá»n hoáº·c cÃ³ cÃ¡c cÃ´ng cá»¥ phÃ¢n tÃ­ch cá»§a bÃªn thá»© ba, cháº¡y thuáº­t toÃ¡n Ä‘Ã³ trÃªn dá»¯ liá»‡u cá»§a mÃ¬nh.\nNáº¿u khÃ´ng cÃ³, hÃ£y xÃ¢y dá»±ng manual analysis cÃ¡c \u0026ldquo;nÆ°á»›c\u0026rdquo; phÃ¢n tÃ­ch dá»±a trÃªn nhá»¯ng khÃ¡m phÃ¡ cá»§a báº¡n vá» quy trÃ¬nh cáº§n tá»‘i Æ°u hoáº·c vá» cÃ¢u há»i cáº§n sá»± tráº£ lá»i. iáº¿n hÃ nh phÃ¢n tÃ­ch thá»§ cÃ´ng cÃ¡c bÆ°á»›c tiáº¿p theo cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘Æ°á»£c dá»±a trÃªn nhá»¯ng gÃ¬ báº¡n Ä‘Ã£ khÃ¡m phÃ¡ Ä‘Æ°á»£c vá» cÃ¢u há»i hoáº·c quy trÃ¬nh cá»§a mÃ¬nh. Má»—i lá»±a chá»n \u0026ldquo;nÆ°á»›c\u0026rdquo; Ä‘i Ä‘Ã³ sáº½ tÃ¡c Ä‘á»™ng nhÆ° tháº¿ nÃ o Ä‘áº¿n káº¿t quáº£ cá»§a cÃ¡c tÃ¬nh huá»‘ng vÃ  tá»« Ä‘Ã³ nÃ³ sáº½ tÃ¡c Ä‘á»™ng nhÆ° tháº¿ nÃ o Ä‘áº¿n má»¥c tiÃªu cá»§a báº¡n?\n1. No analytics: KhÃ´ng cÃ³ phÃ¢n tÃ­ch, cháº¡y theo cáº£m há»©ng vÃ  kinh nghiá»‡m cá»§a má»™t sá»‘ ngÆ°á»i.\n2. Descriptive analytics - PhÃ¢n tÃ­ch mÃ´ táº£ Descriptive analytics lÃ  má»™t pháº§n trong lÄ©nh vá»±c phÃ¢n tÃ­ch dá»¯ liá»‡u (data analytics) vÃ  nÃ³ táº­p trung vÃ o viá»‡c tÃ³m táº¯t, mÃ´ táº£ vÃ  hiá»ƒu sá»± thá»±c táº¡i cá»§a dá»¯ liá»‡u. Má»¥c tiÃªu chÃ­nh cá»§a descriptive analytics lÃ  cung cáº¥p thÃ´ng tin dá»±a trÃªn dá»¯ liá»‡u lá»‹ch sá»­ Ä‘á»ƒ giÃºp tá»• chá»©c hoáº·c ngÆ°á»i quáº£n lÃ½ hiá»ƒu rÃµ tÃ¬nh hÃ¬nh hiá»‡n táº¡i, khÃ¡m phÃ¡ mÃ´ hÃ¬nh hoáº·c xu hÆ°á»›ng trong dá»¯ liá»‡u, vÃ  Ä‘Æ°a ra cÃ¡c quyáº¿t Ä‘á»‹nh tÆ°Æ¡ng lai dá»±a trÃªn kiáº¿n thá»©c nÃ y.\nCÃ¡c phÆ°Æ¡ng phÃ¡p vÃ  cÃ´ng cá»¥ phá»• biáº¿n trong descriptive analytics bao gá»“m:\nBÃ¡o cÃ¡o vÃ  Biá»ƒu Ä‘á»“: Sá»­ dá»¥ng biá»ƒu Ä‘á»“, biá»ƒu Ä‘á»“, vÃ  bÃ¡o cÃ¡o Ä‘á»ƒ biá»ƒu thá»‹ dá»¯ liá»‡u vÃ  thá»ƒ hiá»‡n má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n sá»‘. CÃ¡c biá»ƒu Ä‘á»“ vÃ  bÃ¡o cÃ¡o nÃ y giÃºp táº¡o ra cÃ¡i nhÃ¬n tá»•ng quan vá» dá»¯ liá»‡u.\nTÃ³m táº¯t Thá»‘ng kÃª: TÃ­nh toÃ¡n cÃ¡c thá»‘ng kÃª mÃ´ táº£ nhÆ° trung bÃ¬nh, phÆ°Æ¡ng sai, tá»· lá»‡, vÃ  phÃ¢n phá»‘i dá»¯ liá»‡u. Äiá»u nÃ y giÃºp trong viá»‡c mÃ´ táº£ cÃ¡c tÃ­nh cháº¥t quan trá»ng cá»§a dá»¯ liá»‡u.\nPhÃ¢n tÃ­ch dá»¯ liá»‡u lá»‹ch sá»­: Xem xÃ©t dá»¯ liá»‡u lá»‹ch sá»­ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xu hÆ°á»›ng, biáº¿n Ä‘á»™ng, vÃ  cÃ¡c sá»± kiá»‡n quan trá»ng trong quÃ¡ khá»©. Äiá»u nÃ y cÃ³ thá»ƒ giÃºp dá»± Ä‘oÃ¡n sá»± kiá»‡n tÆ°Æ¡ng lai dá»±a trÃªn dá»¯ liá»‡u lá»‹ch sá»­.\nPhÃ¢n loáº¡i vÃ  nhÃ³m dá»¯ liá»‡u: NhÃ³m dá»¯ liá»‡u vÃ o cÃ¡c phÃ¢n loáº¡i Ä‘á»ƒ hiá»ƒu rÃµ cÃ¡c nhÃ³m vÃ  sá»± tÆ°Æ¡ng quan giá»¯a chÃºng.\nKhÃ¡m phÃ¡ dá»¯ liá»‡u (Data Exploration): Sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t khÃ¡m phÃ¡ dá»¯ liá»‡u Ä‘á»ƒ phÃ¡t hiá»‡n thÃ´ng tin má»›i vÃ  báº¥t thÆ°á»ng trong dá»¯ liá»‡u, cháº³ng háº¡n nhÆ° viá»‡c sá»­ dá»¥ng mÃ´ hÃ¬nh phÃ¢n cá»¥m.\nLá»c vÃ  tÃ¬m kiáº¿m dá»¯ liá»‡u: TÃ¬m kiáº¿m dá»¯ liá»‡u cá»¥ thá»ƒ hoáº·c lá»c dá»¯ liá»‡u Ä‘á»ƒ táº­p trung vÃ o cÃ¡c yáº¿u tá»‘ quan trá»ng.\nDescriptive analytics thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ mÃ´ táº£ hiá»‡n tÆ°á»£ng, hiá»ƒu rÃµ tÃ¬nh hÃ¬nh hiá»‡n táº¡i, vÃ  xÃ¡c Ä‘á»‹nh cÃ¡c váº¥n Ä‘á» hoáº·c cÆ¡ há»™i cÆ¡ báº£n. NÃ³ cung cáº¥p ná»n táº£ng cho cÃ¡c giai Ä‘oáº¡n phÃ¢n tÃ­ch tiáº¿p theo nhÆ° predictive analytics (dá»± Ä‘oÃ¡n tÆ°Æ¡ng lai) vÃ  prescriptive analytics (Ä‘Æ°a ra hÆ°á»›ng dáº«n vÃ  Ä‘á» xuáº¥t hÃ nh Ä‘á»™ng).\nMá»™t sá»‘ vÃ­ dá»¥ sá»­ dá»¥ng Descriptive analytics Traffic and Engagement Reports Ngá»¯ cáº£nh lÃ  báº¡n Ä‘ang cÃ³ má»™t website bÃ¡n hÃ ng, cÃ³ lÆ°u láº¡i hÃ nh vi tÆ°Æ¡ng tÃ¡c cá»§a khÃ¡ch hÃ ng lÃªn trÃªn website sá»­ dá»¥ng GA. Má»™t sá»‘ bÃ¡o cÃ¡o báº¡n cÃ³ thá»ƒ xÃ¢y dá»±ng.\nBÃ¡o cÃ¡o kÃªnh truyá»n thÃ´ng nÃ o Ä‘ang thu hÃºt nhiá»u lÆ°u lÆ°á»£ng truy cáº­p trÃªn trang web cá»§a báº¡n nháº¥t.\nXÃ¡c Ä‘á»‹nh sá»‘ lÆ°á»£ng ngÆ°á»i dÃ¹ng tá»« má»—i nguá»“n\nSo sÃ¡nh sá»‘ ngÆ°á»i dÃ¹ng á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i vá»›i quÃ¡ khá»© tá»« cÃ¹ng má»™t nguá»“n.\nXem sá»‘ lÆ°á»£ng truy cáº­p tá»« quáº£ng cÃ¡o tráº£ phÃ­ Ä‘ang tÄƒng lÃªn bao nhiÃªu pháº§n trÄƒm\nCÃ¡c yáº¿u tá»‘ mÃ¬nh liá»‡t kÃª á»Ÿ trÃªn lÃ  má»™t trong cÃ¡c thÃ´ng tin quan trá»ng Ä‘á»ƒ cÃ¡c loáº¡i phÃ¢n tÃ­ch khÃ¡c bÃªn dÆ°á»›i Ä‘Ã o sÃ¢u hÆ¡n lÃ½ do.\nVÃ¬ sao nguá»“n truy cáº­p tá»« facebook láº¡i tÄƒng theo thá»i gian\nXu hÆ°á»›ng tÄƒng nÃ y cÃ³ cÃ²n tiáº¿p tá»¥c á»Ÿ tÆ°Æ¡ng lai\nHÃ nh Ä‘á»™ng tiáº¿p theo cá»§a chÃºng ta lÃ  gÃ¬\nFinancial Statement Analysis BÃ¡o cÃ¡o tÃ i chÃ­nh lÃ  bÃ¡o cÃ¡o Ä‘á»‹nh ká»³ nÃªu chi tiáº¿t thÃ´ng tin tÃ i chÃ­nh vá» má»™t doanh nghiá»‡p vÃ  cÃ¹ng nhau Ä‘Æ°a ra cÃ¡i nhÃ¬n toÃ n diá»‡n vá» tÃ¬nh hÃ¬nh tÃ i chÃ­nh cá»§a cÃ´ng ty.\nCÃ³ má»™t sá»‘ loáº¡i bÃ¡o cÃ¡o tÃ i chÃ­nh, bao gá»“m báº£ng cÃ¢n Ä‘á»‘i káº¿ toÃ¡n, bÃ¡o cÃ¡o káº¿t quáº£ hoáº¡t Ä‘á»™ng kinh doanh, bÃ¡o cÃ¡o lÆ°u chuyá»ƒn tiá»n tá»‡ vÃ  bÃ¡o cÃ¡o vá»‘n chá»§ sá»Ÿ há»¯u cá»§a cá»• Ä‘Ã´ng. Má»—i kÃªnh phá»¥c vá»¥ má»™t Ä‘á»‘i tÆ°á»£ng cá»¥ thá»ƒ vÃ  truyá»n táº£i nhá»¯ng thÃ´ng tin khÃ¡c nhau vá» tÃ i chÃ­nh cá»§a cÃ´ng ty.\nPhÃ¢n tÃ­ch bÃ¡o cÃ¡o tÃ i chÃ­nh cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n theo ba cÃ¡ch chÃ­nh: dá»c, ngang vÃ  tá»· lá»‡.\nPhÃ¢n tÃ­ch theo chiá»u dá»c lÃ  viá»‡c Ä‘á»c cÃ¡c dÃ²ng dá»¯ liá»‡u theo thá»© tá»± tá»« trÃªn xuá»‘ng dÆ°á»›i vÃ  so sÃ¡nh tá»«ng má»¥c vá»›i cÃ¡c má»¥c á»Ÿ trÃªn vÃ  dÆ°á»›i nÃ³. Äiá»u nÃ y giÃºp xÃ¡c Ä‘á»‹nh má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n. VÃ­ dá»¥: náº¿u má»—i chi tiáº¿t Ä‘Æ¡n hÃ ng lÃ  má»™t tá»· lá»‡ pháº§n trÄƒm cá»§a tá»•ng sá»‘ thÃ¬ viá»‡c so sÃ¡nh chÃºng cÃ³ thá»ƒ cung cáº¥p thÃ´ng tin chi tiáº¿t vá» chi tiáº¿t Ä‘Æ¡n hÃ ng nÃ o chiáº¿m tá»· lá»‡ pháº§n trÄƒm lá»›n hÆ¡n vÃ  nhá» hÆ¡n trong tá»•ng sá»‘.\nPhÃ¢n tÃ­ch theo chiá»u ngang lÃ  viá»‡c Ä‘á»c má»™t bÃ¡o cÃ¡o tá»« trÃ¡i sang pháº£i vÃ  so sÃ¡nh tá»«ng má»¥c vá»›i chÃ­nh nÃ³ á»Ÿ ká»³ trÆ°á»›c. Loáº¡i phÃ¢n tÃ­ch nÃ y xÃ¡c Ä‘á»‹nh sá»± thay Ä‘á»•i theo thá»i gian.\nCuá»‘i cÃ¹ng, phÃ¢n tÃ­ch tá»· lá»‡ lÃ  viá»‡c viá»‡c so sÃ¡nh má»™t pháº§n cá»§a bÃ¡o cÃ¡o vá»›i pháº§n khÃ¡c dá»±a trÃªn má»‘i quan há»‡ cá»§a chÃºng vá»›i tá»•ng thá»ƒ. Äiá»u nÃ y so sÃ¡nh trá»±c tiáº¿p cÃ¡c máº·t hÃ ng qua cÃ¡c thá»i ká»³, cÅ©ng nhÆ° tá»· lá»‡ cá»§a cÃ´ng ty báº¡n vá»›i ngÃ nh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ xem cÃ´ng ty cá»§a báº¡n hoáº¡t Ä‘á»™ng hiá»‡u quáº£ hÆ¡n hay kÃ©m hÆ¡n.\nMá»—i phÆ°Æ¡ng phÃ¡p phÃ¢n tÃ­ch bÃ¡o cÃ¡o tÃ i chÃ­nh nÃ y lÃ  vÃ­ dá»¥ vá» descriptive analytics vÃ¬ chÃºng cung cáº¥p thÃ´ng tin vá» xu hÆ°á»›ng vÃ  má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n dá»±a trÃªn dá»¯ liá»‡u hiá»‡n táº¡i vÃ  lá»‹ch sá»­.\nDemand Trends Descriptive analytics cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xu hÆ°á»›ng trong sá»Ÿ thÃ­ch vÃ  hÃ nh vi cá»§a khÃ¡ch hÃ ng, Ä‘á»“ng thá»i Ä‘Æ°a ra cÃ¡c giáº£ Ä‘á»‹nh vá» nhu cáº§u Ä‘á»‘i vá»›i cÃ¡c sáº£n pháº©m hoáº·c dá»‹ch vá»¥ cá»¥ thá»ƒ.\nMá»™t usecase thÆ°á»ng Ä‘Æ°á»£c nháº¯c tá»›i lÃ  Netflixâ€™s. Team cá»§a há» Ä‘Ã£ thu tháº­p má»™t lÆ°á»£ng lá»›n hÃ nh vi cá»§a ngÆ°á»i dÃ¹ng trÃªn ná»n táº£ng cá»§a há». Há» phÃ¢n tÃ­ch dá»¯ liá»‡u nÃ y Ä‘á»ƒ xÃ¡c Ä‘á»‹nh ra cÃ¡c chÆ°Æ¡ng trÃ¬nh TV vÃ  cÃ¡c bá»™ phim Ä‘ang lÃ  trending á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i vÃ  Ä‘Æ°a ra cÃ¡c gá»£i Ã½ phim trending á»Ÿ trang chá»§.\nKhÃ´ng dá»«ng láº¡i á»Ÿ Ä‘Ã³, cÃ¡c dá»¯ liá»‡u nÃ y cÃ²n giÃºp Netflix biáº¿t Ä‘Æ°á»£c ráº±ng loáº¡i phim nÃ o, diá»…n viÃªn nÃ o, Ä‘áº¡o diá»…n nÃ o hiá»‡n táº¡i Ä‘ang Ä‘Æ°á»£c yÃªu thÃ­ch. VÃ  nÃ³ giÃºp Ä‘Æ°a quyáº¿t Ä‘á»‹nh vá» ná»™i dung cÃ¡c phim sáº¯p tá»›i sáº½ Ä‘Æ°á»£c báº¥m mÃ¡y, há»£p Ä‘á»“ng vá»›i nhÃ  sáº£n xuáº¥t phim, Ä‘Æ°a ra cÃ¡c chiáº¿n dá»‹ch quáº£n cÃ¡o, retargeting quáº£n cÃ¡o.\nAggregated Survey Results Descriptive analytics cÅ©ng há»¯u Ã­ch trong nghiÃªn cá»©u thá»‹ trÆ°á»ng.\nVÃ­ dá»¥: báº¡n cÃ³ thá»ƒ tiáº¿n hÃ nh má»™t cuá»™c kháº£o sÃ¡t vÃ  xÃ¡c Ä‘á»‹nh ráº±ng khi Ä‘á»™ tuá»•i cá»§a ngÆ°á»i tráº£ lá»i tÄƒng lÃªn thÃ¬ kháº£ nÄƒng há» mua sáº£n pháº©m cá»§a báº¡n cÅ©ng tÄƒng theo. Náº¿u báº¡n Ä‘Ã£ thá»±c hiá»‡n kháº£o sÃ¡t nÃ y nhiá»u láº§n trong nhiá»u nÄƒm, thÃ¬ phÃ¢n tÃ­ch mÃ´ táº£ cÃ³ thá»ƒ cho báº¡n biáº¿t liá»‡u má»‘i tÆ°Æ¡ng quan giá»¯a Ä‘á»™ tuá»•i mua hÃ ng nÃ y luÃ´n tá»“n táº¡i hay nÃ³ chá»‰ xáº£y ra trong nÄƒm nay.\nNhá»¯ng hiá»ƒu biáº¿t sÃ¢u sáº¯c nhÆ° tháº¿ nÃ y cÃ³ thá»ƒ má»Ÿ Ä‘Æ°á»ng cho cÃ¡c phÃ¢n tÃ­ch cháº©n Ä‘oÃ¡n giáº£i thÃ­ch lÃ½ do táº¡i sao má»™t sá»‘ yáº¿u tá»‘ nháº¥t Ä‘á»‹nh láº¡i cÃ³ má»‘i tÆ°Æ¡ng quan vá»›i nhau. Sau Ä‘Ã³, báº¡n cÃ³ thá»ƒ táº­n dá»¥ng cÃ¡c phÃ¢n tÃ­ch dá»± Ä‘oÃ¡n vÃ  phÃ¢n tÃ­ch theo quy Ä‘á»‹nh Ä‘á»ƒ láº­p káº¿ hoáº¡ch cáº£i tiáº¿n sáº£n pháº©m hoáº·c chiáº¿n dá»‹ch tiáº¿p thá»‹ trong tÆ°Æ¡ng lai dá»±a trÃªn nhá»¯ng xu hÆ°á»›ng Ä‘Ã³.\nProgress to Goals descriptive analytics cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»ƒ theo dÃµi tiáº¿n trÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu (Progress to Goals). CÃ¡c bÃ¡o cÃ¡o vá» tiáº¿n Ä‘á»™ cá»§a KPIs cÃ³ thá»ƒ giÃºp team cá»§a báº¡n hiá»ƒu Ä‘Æ°á»£c ráº±ng cÃ´ng viá»‡c mÃ¬nh lÃ m cÃ³ Ä‘ang Ä‘i Ä‘Ãºng hÆ°á»›ng, hay nÃ³ Ä‘ang Ä‘i sai hÆ°á»›ng vÃ  chÃºng ta cáº§n Ä‘iá»u chá»‰nh láº¡i Ä‘á»ƒ Ä‘i Ä‘Ãºng hÆ°á»›ng.\nVÃ­ dá»¥: náº¿u tá»• chá»©c cá»§a báº¡n Ä‘áº·t má»¥c tiÃªu Ä‘áº¡t Ä‘Æ°á»£c 500.000 unique page views / month, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng dá»¯ liá»‡u lÆ°u lÆ°á»£ng truy cáº­p Ä‘á»ƒ theo dÃµi. Giáº£ sá»­, trong ná»­a thÃ¡ng, báº¡n Ä‘áº¡t Ä‘Æ°á»£c 200.000 lÆ°á»£t xem, váº­y lÃ  Ä‘i ná»¯a cháº·n Ä‘Æ°á»ng rá»“i nhÆ°ng chÃºng ta chÆ°a Ä‘áº¡t Ä‘Æ°á»£c 1 ná»¯a má»¥c tiÃªu. PhÃ¢n tÃ­ch dáº¡ng nÃ y chá»‰ cho chÃºng ta Ä‘iá»u Ä‘Ã³ vÃ  chÃºng ta cáº§n sá»­ dá»¥ng nhá»¯ng phÃ¢n tÃ­ch chuyÃªn sÃ¢u hÆ¡n bÃªn dÆ°á»›i Ä‘á»ƒ cáº£i thiá»‡n lÆ°u lÆ°á»£ng truy cáº­p Ä‘á»ƒ quay láº¡i hÆ°á»›ng Ä‘Ãºng KPI cá»§a báº¡n.\n3 Diagnostic analytics - PhÃ¢n tÃ­ch cháº©n Ä‘oÃ¡n Diagnostic analytics (phÃ¢n tÃ­ch cháº©n Ä‘oÃ¡n) lÃ  má»™t loáº¡i phÃ¢n tÃ­ch dá»¯ liá»‡u trong lÄ©nh vá»±c quáº£n lÃ½ dá»±a trÃªn dá»¯ liá»‡u (data analytics), nÆ¡i má»¥c tiÃªu chÃ­nh lÃ  tÃ¬m hiá»ƒu vÃ  hiá»ƒu rÃµ nguyÃªn nhÃ¢n hoáº·c lÃ½ do xáº£y ra cá»§a má»™t sá»± kiá»‡n hoáº·c tÃ¬nh huá»‘ng cá»¥ thá»ƒ. Má»¥c Ä‘Ã­ch chÃ­nh cá»§a diagnostic analytics lÃ  giÃºp tá»• chá»©c hoáº·c ngÆ°á»i quáº£n lÃ½ Ä‘á»‘i máº·t vá»›i cÃ¡c váº¥n Ä‘á» hoáº·c sá»± cá»‘, cung cáº¥p thÃ´ng tin Ä‘á»ƒ lÃ m rÃµ táº¡i sao chÃºng xáº£y ra vÃ  giÃºp Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh hoáº·c biá»‡n phÃ¡p sá»­a chá»¯a.\nCÃ¡c Ä‘iá»ƒm chÃ­nh cá»§a diagnostic analytics bao gá»“m:\nTÃ¬m hiá»ƒu nguyÃªn nhÃ¢n: Loáº¡i phÃ¢n tÃ­ch nÃ y táº­p trung vÃ o viá»‡c phÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘á»ƒ tÃ¬m ra nguyÃªn nhÃ¢n gá»‘c rá»… cá»§a má»™t sá»± kiá»‡n hoáº·c tÃ¬nh huá»‘ng cá»¥ thá»ƒ. Äiá»u nÃ y giÃºp hiá»ƒu rÃµ táº¡i sao Ä‘iá»u Ä‘Ã³ xáº£y ra vÃ  táº¡o cÆ¡ há»™i Ä‘á»ƒ ngÄƒn cháº·n sá»± kiá»‡n tÆ°Æ¡ng tá»± trong tÆ°Æ¡ng lai.\nSá»­ dá»¥ng dá»¯ liá»‡u lá»‹ch sá»­: Diagnostic analytics sá»­ dá»¥ng dá»¯ liá»‡u lá»‹ch sá»­ vÃ  thÃ´ng tin vá» sá»± kiá»‡n cá»¥ thá»ƒ Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  phÃ¡t hiá»‡n cÃ¡c mÃ´ hÃ¬nh hoáº·c má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n.\nHá»— trá»£ quyáº¿t Ä‘á»‹nh: Káº¿t quáº£ cá»§a diagnostic analytics cÃ³ thá»ƒ há»— trá»£ quyáº¿t Ä‘á»‹nh vá» viá»‡c xá»­ lÃ½ cÃ¡c váº¥n Ä‘á» hoáº·c sá»± cá»‘. Dá»±a vÃ o thÃ´ng tin nÃ y, ngÆ°á»i quáº£n lÃ½ cÃ³ thá»ƒ Ä‘Æ°a ra cÃ¡c biá»‡n phÃ¡p cáº£i thiá»‡n hoáº·c Ä‘iá»u chá»‰nh quy trÃ¬nh lÃ m viá»‡c Ä‘á»ƒ ngÄƒn cháº·n cÃ¡c váº¥n Ä‘á» tÆ°Æ¡ng tá»±.\nVÃ­ dá»¥ vá» á»©ng dá»¥ng cá»§a diagnostic analytics bao gá»“m viá»‡c phÃ¢n tÃ­ch táº¡i sao sáº£n pháº©m cÃ³ tá»· lá»‡ tráº£ hÃ ng cao, lÃ m rÃµ táº¡i sao má»™t dá»± Ã¡n Ä‘Ã£ trá»… háº¡n, hoáº·c tÃ¬m hiá»ƒu lÃ½ do táº¡i sao doanh sá»‘ bÃ¡n hÃ ng cá»§a má»™t sáº£n pháº©m cá»¥ thá»ƒ Ä‘Ã£ giáº£m sÃºt. Khi hiá»ƒu Ä‘Æ°á»£c nguyÃªn nhÃ¢n, tá»• chá»©c cÃ³ thá»ƒ Ä‘Æ°a ra cÃ¡c biá»‡n phÃ¡p sá»­a chá»¯a hoáº·c cáº£i thiá»‡n quÃ¡ trÃ¬nh lÃ m viá»‡c Ä‘á»ƒ giáº£m thiá»ƒu cÃ¡c váº¥n Ä‘á» nÃ y trong tÆ°Æ¡ng lai.\nCÃ³ má»™t sá»‘ khÃ¡i niá»‡m cáº§n hiá»ƒu trÆ°á»›c khi Ä‘i sÃ¢u vÃ o phÃ¢n tÃ­ch cháº©n Ä‘oÃ¡n: kiá»ƒm tra giáº£ thuyáº¿t (hypothesis testing), sá»± khÃ¡c nhau giá»¯a má»‘i tÆ°Æ¡ng quan vÃ  quan há»‡ nhÃ¢n quáº£, phÃ¢n tÃ­ch há»“i quy cháº©n Ä‘oÃ¡n (diagnostic regression analysis).\nTÃ¬m hiá»ƒu má»™t sá»‘ khÃ¡i niá»‡m cÆ¡ báº£n cá»§a Diagnostic analytics Hypothesis Testing Kiá»ƒm Ä‘á»‹nh giáº£ thuyáº¿t (Hypothesis Testing) lÃ  má»™t phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª cÆ¡ báº£n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh vá» cÃ¡c tham sá»‘ cá»§a quáº§n thá»ƒ dá»±a trÃªn dá»¯ liá»‡u máº«u. ÄÃ¢y lÃ  má»™t quy trÃ¬nh há»‡ thá»‘ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ xem cÃ³ Ä‘á»§ báº±ng chá»©ng Ä‘á»ƒ há»— trá»£ hoáº·c phá»§ Ä‘á»‹nh má»™t giáº£ thuyáº¿t cá»¥ thá»ƒ vá» quáº§n thá»ƒ hay khÃ´ng. DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c bÆ°á»›c vÃ  khÃ¡i niá»‡m chÃ­nh liÃªn quan Ä‘áº¿n kiá»ƒm Ä‘á»‹nh giáº£ thuyáº¿t\nXÃ¢y dá»±ng Giáº£ Thuyáº¿t: Giáº£ thuyáº¿t khÃ´ng (H0): ÄÃ¢y lÃ  giáº£ thuyáº¿t máº·c Ä‘á»‹nh hoáº·c tráº¡ng thÃ¡i hiá»‡n hÃ nh. NÃ³ cho ráº±ng khÃ´ng cÃ³ hiá»‡u á»©ng, khÃ´ng cÃ³ sá»± khÃ¡c biá»‡t hoáº·c khÃ´ng cÃ³ má»‘i quan há»‡ nÃ o trong quáº§n thá»ƒ. ThÆ°á»ng Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  H0.\nGiáº£ thuyáº¿t thay tháº¿ (Ha hoáº·c H1): ÄÃ¢y lÃ  giáº£ thuyáº¿t mÃ  báº¡n muá»‘n kiá»ƒm tra. NÃ³ Ä‘áº¡i diá»‡n cho má»™t kháº³ng Ä‘á»‹nh cá»¥ thá»ƒ hoáº·c hiá»‡u á»©ng mÃ  báº¡n muá»‘n chá»©ng minh. ThÆ°á»ng Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  Ha hoáº·c H1.\nChá»n Má»©c Ã NghÄ©a (Î±): Má»©c Ã½ nghÄ©a, kÃ½ hiá»‡u lÃ  Î± (alpha), Ä‘áº¡i diá»‡n cho xÃ¡c suáº¥t cá»§a lá»—i loáº¡i I, tá»©c lÃ  lá»—i sai khi tá»« chá»‘i má»™t giáº£ thuyáº¿t khÃ´ng Ä‘Ãºng. Má»©c Ã½ nghÄ©a thÆ°á»ng bao gá»“m 0,05 (5%) vÃ  0,01 (1%), nhÆ°ng sá»± lá»±a chá»n phá»¥ thuá»™c vÃ o ngá»¯ cáº£nh vÃ  má»©c Ä‘á»™ tin cáº­y yÃªu cáº§u.\nThu tháº­p vÃ  PhÃ¢n TÃ­ch Dá»¯ Liá»‡u: Thu tháº­p má»™t máº«u tá»« quáº§n thá»ƒ quan tÃ¢m vÃ  thá»±c hiá»‡n phÃ¢n tÃ­ch thá»‘ng kÃª cáº§n thiáº¿t Ä‘á»ƒ tÃ­nh toÃ¡n thá»‘ng kÃª kiá»ƒm Ä‘á»‹nh, Ä‘o lÆ°á»ng má»‘i quan há»‡ hoáº·c hiá»‡u á»©ng Ä‘ang Ä‘Æ°á»£c nghiÃªn cá»©u.\nTÃ­nh ToÃ¡n Thá»‘ng KÃª Kiá»ƒm Äá»‹nh: Thá»‘ng kÃª kiá»ƒm Ä‘á»‹nh phá»¥ thuá»™c vÃ o loáº¡i kiá»ƒm Ä‘á»‹nh Ä‘ang thá»±c hiá»‡n (vÃ­ dá»¥: kiá»ƒm Ä‘á»‹nh t-student, kiá»ƒm Ä‘á»‹nh chi bÃ¬nh phÆ°Æ¡ng, kiá»ƒm Ä‘á»‹nh z). NÃ³ Ä‘o lÆ°á»ng má»©c Ä‘á»™ mÃ  thá»‘ng kÃª máº«u khÃ¡c biá»‡t so vá»›i giÃ¡ trá»‹ ká»³ vá»ng dÆ°á»›i giáº£ thuyáº¿t khÃ´ng.\nXÃ¡c Ä‘á»‹nh VÃ¹ng Quan Trá»ng hoáº·c GiÃ¡ trá»‹ p (P-Value): VÃ¹ng Quan Trá»ng: Trong kiá»ƒm Ä‘á»‹nh giáº£ thuyáº¿t, vÃ¹ng quan trá»ng Ä‘áº¡i diá»‡n cho táº­p há»£p cÃ¡c giÃ¡ trá»‹ cá»§a thá»‘ng kÃª kiá»ƒm Ä‘á»‹nh mÃ  báº¡n sáº½ tá»« chá»‘i giáº£ thuyáº¿t khÃ´ng. CÃ¡c giÃ¡ trá»‹ nÃ y Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh dá»±a trÃªn má»©c Ã½ nghÄ©a Ä‘Ã£ chá»n vÃ  phÃ¢n phá»‘i cá»§a thá»‘ng kÃª kiá»ƒm Ä‘á»‹nh.\nGiÃ¡ trá»‹ p (P-Value): GiÃ¡ trá»‹ p lÃ  xÃ¡c suáº¥t cá»§a viá»‡c thu Ä‘Æ°á»£c thá»‘ng kÃª kiá»ƒm Ä‘á»‹nh cÃ ng \u0026ldquo;tÆ°Æ¡ng Ä‘á»‘i\u0026rdquo; hoáº·c \u0026ldquo;tÆ°Æ¡ng Ä‘á»‘i hÆ¡n\u0026rdquo; so vá»›i thá»‘ng kÃª kiá»ƒm Ä‘á»‹nh quan sÃ¡t trong máº«u dá»¯ liá»‡u, giáº£ sá»­ ráº±ng giáº£ thuyáº¿t khÃ´ng Ä‘Ãºng. GiÃ¡ trá»‹ p nhá» (thÆ°á»ng nhá» hÆ¡n Î±) cho tháº¥y cÃ³ Ä‘á»§ báº±ng chá»©ng Ä‘á»ƒ phá»§ Ä‘á»‹nh giáº£ thuyáº¿t khÃ´ng.\nÄÆ°a Ra Quyáº¿t Äá»‹nh: Náº¿u thá»‘ng kÃª kiá»ƒm Ä‘á»‹nh náº±m trong vÃ¹ng quan trá»ng (tá»©c lÃ  xÃ¡c suáº¥t xáº£y ra do sá»± tÃ¬nh cá» tháº¥p), báº¡n tá»« chá»‘i giáº£ thuyáº¿t khÃ´ng Ä‘á»ƒ á»§ng há»™ giáº£ thuyáº¿t thay tháº¿.\nNáº¿u thá»‘ng kÃª kiá»ƒm Ä‘á»‹nh khÃ´ng náº±m trong vÃ¹ng quan trá»ng, báº¡n khÃ´ng tá»« chá»‘i giáº£ thuyáº¿t khÃ´ng, tá»©c lÃ  khÃ´ng cÃ³ Ä‘á»§ báº±ng chá»©ng Ä‘á»ƒ á»§ng há»™ giáº£ thuyáº¿t thay tháº¿.\nÄÆ°a Ra Káº¿t Luáº­n: Dá»±a trÃªn quyáº¿t Ä‘á»‹nh á»Ÿ bÆ°á»›c 6, báº¡n Ä‘Æ°a ra káº¿t luáº­n vá» tham sá»‘ cá»§a quáº§n thá»ƒ báº¡n Ä‘ang kiá»ƒm tra. Báº¡n cÃ³ thá»ƒ káº¿t luáº­n ráº±ng cÃ³ Ä‘á»§ báº±ng chá»©ng cho má»™t hiá»‡u á»©ng, má»™t sá»± khÃ¡c biá»‡t, hoáº·c má»™t má»‘i quan há»‡ (tá»« chá»‘i giáº£ thuyáº¿t khÃ´ng) hoáº·c ráº±ng khÃ´ng cÃ³ Ä‘á»§ báº±ng chá»©ng Ä‘á»ƒ lÃ m Ä‘iá»u Ä‘Ã³ (khÃ´ng tá»« chá»‘i giáº£ thuyáº¿t khÃ´ng).\nHypothesis testing lÃ  quy trÃ¬nh thá»‘ng kÃª (the statistical process) Ä‘á»ƒ chá»©ng minh hoáº·c bÃ¡c bá» má»™t giáº£ Ä‘á»‹nh.\nHypotheses cÃ³ thá»ƒ lÃ  future-oriented (vÃ­ dá»¥, Náº¿u chÃºng ta Ä‘á»•i logo cá»§a cÃ´ng ty chÃºng ta, nhiá»u ngá»«i á»Ÿ Báº¯c Má»¹ sáº½ mua sáº£n pháº©m cá»§a chÃºng ta), trong predictive analytics hoáº·c prescriptive analytics.\nTrong diagnostic analytics, hypotheses lÃ  historically-oriented (vÃ­ dá»¥, TÃ´i dá»± Ä‘oÃ¡n doanh sá»‘ bÃ¡n hÃ ng thÃ¡ng nÃ y sá»¥t giáº£m lÃ  do sáº£n pháº©m cá»§a chÃºng tÃ´i tÄƒng giÃ¡ gáº§n Ä‘Ã¢y.). CÃ¡c giáº£ Ä‘á»‹nh Ä‘á»‹nh hÆ°á»›ng viá»‡c phÃ¢n tÃ­ch cá»§a báº¡n vÃ  Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° má»™t lá»i nháº¯c nhá»Ÿ vá» Ä‘iá»u báº¡n Ä‘ang muá»‘n chá»©ng minh hoáº·c bÃ¡c bá».\nCorrelation vs. Causation TÆ°Æ¡ng quan vÃ  nhÃ¢n quáº£ (Correlation and Causation) lÃ  hai khÃ¡i niá»‡m quan trá»ng trong thá»‘ng kÃª vÃ  khoa há»c dá»¯ liá»‡u. Tuy cÃ¹ng liÃªn quan Ä‘áº¿n sá»± liÃªn káº¿t giá»¯a hai biáº¿n, nhÆ°ng chÃºng cÃ³ Ã½ nghÄ©a khÃ¡c nhau:\nTÆ°Æ¡ng Quan (Correlation): TÆ°Æ¡ng quan chá»‰ Ä‘Æ¡n giáº£n lÃ  mÃ´ táº£ má»‘i quan há»‡ tÆ°Æ¡ng Ä‘á»‘i giá»¯a hai biáº¿n. NÃ³ chá»‰ cho ta biáº¿t náº¿u cÃ³ sá»± thay Ä‘á»•i theo cÃ¹ng hÆ°á»›ng hoáº·c ngÆ°á»£c hÆ°á»›ng giá»¯a cÃ¡c biáº¿n. Khi hai biáº¿n tÆ°Æ¡ng quan, cÃ³ thá»ƒ cÃ³ sá»± thay Ä‘á»•i chung nhÆ°ng khÃ´ng cÃ³ liÃªn quan nhÃ¢n quáº£. Äiá»u nÃ y cÃ³ thá»ƒ lÃ  do tÃ¬nh cá» hoáº·c cÃ³ biáº¿n khÃ¡c áº©n sau má»‘i quan há»‡ tÆ°Æ¡ng quan. VÃ­ dá»¥: CÃ³ má»™t tÆ°Æ¡ng quan máº¡nh giá»¯a viá»‡c sá»­ dá»¥ng Ã´ tÃ´ vÃ  lÆ°á»£ng dáº§u tiÃªu thá»¥ hÃ ng nÄƒm. Tuy nhiÃªn, Ä‘iá»u nÃ y khÃ´ng cÃ³ nghÄ©a ráº±ng viá»‡c sá»­ dá»¥ng Ã´ tÃ´ gÃ¢y ra sá»± tÄƒng tiÃªu thá»¥ dáº§u.\nNhÃ¢n Quáº£ (Causation): NhÃ¢n quáº£ Ä‘á» cáº­p Ä‘áº¿n má»‘i quan há»‡ nguyÃªn nhÃ¢n vÃ  káº¿t quáº£ giá»¯a hai biáº¿n, trong Ä‘Ã³ má»™t biáº¿n (biáº¿n nguyÃªn nhÃ¢n) gÃ¢y ra sá»± thay Ä‘á»•i trong biáº¿n káº¿t quáº£.\nÄá»ƒ káº¿t luáº­n vá» má»‘i quan há»‡ nhÃ¢n quáº£, cáº§n cÃ³ nhiá»u báº±ng chá»©ng hÆ¡n so vá»›i chá»‰ tÆ°Æ¡ng quan. ThÃ´ng thÆ°á»ng, cáº§n tiáº¿n hÃ nh thá»­ nghiá»‡m kiá»ƒm tra nhÃ¢n quáº£ hoáº·c sá»­ dá»¥ng thiáº¿t káº¿ nghiÃªn cá»©u Ä‘á»ƒ loáº¡i trá»« cÃ¡c yáº¿u tá»‘ khÃ¡c.\nVÃ­ dá»¥: Náº¿u báº¡n thá»±c hiá»‡n má»™t thá»­ nghiá»‡m ngáº«u nhiÃªn Ä‘á»ƒ Ä‘o lÆ°á»£ng vitamin C Ä‘Æ°á»£c cung cáº¥p cho má»™t nhÃ³m ngÆ°á»i vÃ  xem xÃ©t tÃ¡c Ä‘á»™ng cá»§a nÃ³ Ä‘á»‘i vá»›i sá»©c khá»e, báº¡n cÃ³ thá»ƒ Ä‘Æ°a ra káº¿t luáº­n vá» má»‘i quan há»‡ nhÃ¢n quáº£ giá»¯a vitamin C vÃ  sá»©c khá»e.\nTÃ³m láº¡i, tÆ°Æ¡ng quan chá»‰ mÃ´ táº£ má»‘i quan há»‡ giá»¯a hai biáº¿n, trong khi nhÃ¢n quáº£ Ä‘á» cáº­p Ä‘áº¿n má»‘i quan há»‡ nguyÃªn nhÃ¢n vÃ  káº¿t quáº£. Viá»‡c xÃ¡c Ä‘á»‹nh má»‘i quan há»‡ nhÃ¢n quáº£ thÆ°á»ng phá»©c táº¡p hÆ¡n vÃ  Ä‘Ã²i há»i nhiá»u nghiÃªn cá»©u vÃ  báº±ng chá»©ng Ä‘á»ƒ cÃ³ thá»ƒ cháº¯c cháº¯n ráº±ng má»™t biáº¿n gÃ¢y ra sá»± thay Ä‘á»•i trong biáº¿n khÃ¡c.\nNáº¿u tá»• chá»©c cá»§a báº¡n cÃ³ Ä‘á»§ tÃ i nguyÃªn, báº¡n cÃ³ thá»ƒ cháº¡y thá»±c nghiá»‡m Ä‘á»ƒ tÃ¬m ra má»‘i quan há»‡ nhÃ¢n quáº£. Náº¿u xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c má»‘i quan há»‡ nhÃ¢n quáº£ cá»§a 2 biáº¿n, má»‘i tÆ°Æ¡ng quan váº«n cÃ³ thá»ƒ mang láº¡i cÃ¡i nhÃ¬n sÃ¢u sáº¯c cáº§n thiáº¿t Ä‘á»ƒ hiá»ƒu dá»¯ liá»‡u cá»§a báº¡n vÃ  sá»­ dá»¥ng dá»¯ liá»‡u Ä‘Ã³ Ä‘á»ƒ Ä‘Æ°a ra cÃ¡c quyáº¿t Ä‘á»‹nh chÃ­nh xÃ¡c hÆ¡n.\nDiagnostic Regression Analysis Má»™t sá»‘ má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n cÃ³ thá»ƒ dá»… dÃ ng nháº­n ra, nhÆ°ng má»™t sá»‘ khÃ¡c yÃªu cáº§u phÃ¢n tÃ­ch sÃ¢u hÆ¡n. PhÃ¢n tÃ­ch há»“i quy Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh má»‘i quan há»‡ giá»¯a hai biáº¿n (single linear regression) hoáº·c ba biáº¿n trá»Ÿ lÃªn (multiple regression). Má»‘i quan há»‡ Ä‘Æ°á»£c thá»ƒ hiá»‡n báº±ng má»™t phÆ°Æ¡ng trÃ¬nh toÃ¡n há»c chuyá»ƒn thÃ nh Ä‘á»™ dá»‘c cá»§a Ä‘Æ°á»ng phÃ¹ há»£p nháº¥t vá»›i má»‘i quan há»‡ cá»§a cÃ¡c biáº¿n.\nRegression giÃºp chÃºng ta xÃ¡c Ä‘á»‹nh insight vá» cáº¥u trÃºc cá»§a má»‘i quan há»‡ trong 2 hay nhiá»u biáº¿n vÃ  cung cáº¥p thÆ°á»›c Ä‘o má»©c Ä‘á»™ phÃ¹ há»£p cá»§a dá»¯ liá»‡u vá»›i má»‘i quan há»‡( cá»§a 2 hay nhiá»u biáº¿n) Ä‘Ã³\nnostic analytics lÃ  viá»‡c chÃºng ta sá»­ dá»¥ng phÃ¢n tÃ­ch há»“i quy Ä‘á»ƒ giáº£i thÃ­ch má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n trong dá»¯ liá»‡u lá»‹ch sá»­. Sau Ä‘Ã³, Ä‘Æ°á»ng há»“i quy cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ dá»± Ä‘oÃ¡n cho tÆ°Æ¡ng lai ( lÃ  vÃ­ dá»¥ cá»§a nhÃ³m predictive analytics).\nMá»™t sá»‘ vÃ­ dá»¥ sá»­ dá»¥ng diagnostic analytics Examining Market Demand Má»™t usecase cá»§a diagnostic analytics lÃ  xÃ¡c Ä‘á»‹nh lÃ½ do Ä‘áº±ng sau nhu cáº§u sáº£n pháº©m.\nVÃ­ dá»¥: CÃ´ng ty HelloFresh - cÃ´ng ty Ä‘áº¡i chÃºng quá»‘c táº¿ cung cáº¥p Ä‘á»“ Äƒn sÆ¡ cháº¿ sáºµn cÃ³ trá»¥ sá»Ÿ táº¡i Berlin, Äá»©c. ÄÃ¢y lÃ  nhÃ  cung cáº¥p Ä‘á»“ Äƒn sÆ¡ cháº¿ sáºµn lá»›n nháº¥t á»Ÿ Hoa Ká»³, vÃ  cÅ©ng cÃ³ hoáº¡t Ä‘á»™ng á»Ÿ Canada, TÃ¢y Ã‚u. CÃ´ng ty thu tháº­p hÃ ng triá»‡u Ä‘iá»ƒm dá»¯ liá»‡u tá»« ngÆ°á»i dÃ¹ng toÃ n cáº§u, bao gá»“m thÃ´ng tin vá» vá»‹ trÃ­ Ä‘á»‹a lÃ½, dá»¯ liá»‡u nhÃ¢n kháº©u há»c Ä‘Æ°á»£c tiáº¿t lá»™, loáº¡i bá»¯a Äƒn, sá»Ÿ thÃ­ch vá» hÆ°Æ¡ng vá»‹ cÅ©ng nhÆ° nhá»‹p vÃ  thá»i gian Ä‘áº·t hÃ ng thÃ´ng thÆ°á»ng.\nNhÃ³m cá»§a HelloFresh sá»­ dá»¥ng dá»¯ liá»‡u nÃ y Ä‘á»ƒ xÃ¡c Ä‘á»‹nh má»‘i quan há»‡ giá»¯a cÃ¡c xu hÆ°á»›ng vá» thuá»™c tÃ­nh vÃ  hÃ nh vi cá»§a khÃ¡ch hÃ ng. NhÆ° má»™t vÃ­ dá»¥ giáº£ Ä‘á»‹nh, hÃ£y tÆ°á»Ÿng tÆ°á»£ng nhÃ³m HelloFresh xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c sá»± gia tÄƒng Ä‘á»™t biáº¿n vá» Ä‘Æ¡n Ä‘áº·t hÃ ng cÃ´ng thá»©c cháº¿ biáº¿n tá»« cÃ¡. Sau khi tiáº¿n hÃ nh phÃ¢n tÃ­ch cháº©n Ä‘oÃ¡n, há» phÃ¡t hiá»‡n ra ráº±ng cÃ¡c thuá»™c tÃ­nh cÃ³ má»‘i tÆ°Æ¡ng quan cao nháº¥t vá»›i viá»‡c Ä‘áº·t hÃ ng cÃ¡c cÃ´ng thá»©c náº¥u cÃ¡ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh lÃ  ná»¯ vÃ  sá»‘ng á»Ÿ vÃ¹ng Ä‘Ã´ng báº¯c Hoa Ká»³.\nTá»« Ä‘Ã³, nhÃ³m cÃ³ thá»ƒ tiáº¿n hÃ nh nghiÃªn cá»©u thá»‹ trÆ°á»ng vá»›i nhÃ³m nhÃ¢n kháº©u há»c cá»¥ thá»ƒ Ä‘Ã³ Ä‘á»ƒ tÃ¬m hiá»ƒu thÃªm vá» nhu cáº§u vá» cÃ´ng thá»©c náº¥u cÃ¡. CÃ³ pháº£i nguyÃªn nhÃ¢n lÃ  do má»™t nghiÃªn cá»©u khoa há»c gáº§n Ä‘Ã¢y ca ngá»£i lá»£i Ã­ch sá»©c khá»e cá»§a cÃ¡ Ä‘á»‘i vá»›i phá»¥ ná»¯? CÃ³ láº½ nhá»¯ng ngÆ°á»i sá»‘ng á»Ÿ vÃ¹ng Ä‘Ã´ng báº¯c Hoa Ká»³ cÃ³ kháº©u vá»‹ háº£i sáº£n tinh táº¿ vÃ¬ há» sá»‘ng tÆ°Æ¡ng Ä‘á»‘i gáº§n Äáº¡i TÃ¢y DÆ°Æ¡ng. LÃ½ luáº­n cá»§a há» cÃ³ thá»ƒ cung cáº¥p nhá»¯ng hiá»ƒu biáº¿t sÃ¢u sáº¯c cÃ³ tÃ¡c Ä‘á»™ng cho HelloFresh.\nKhi nghiÃªn cá»©u cÃ¡c loáº¡i phÃ¢n tÃ­ch khÃ¡c, nhÃ³m cÅ©ng cÃ³ thá»ƒ xem xÃ©t liá»‡u xu hÆ°á»›ng nÃ y cÃ³ tiáº¿p tá»¥c hay khÃ´ng (phÃ¢n tÃ­ch dá»± Ä‘oÃ¡n) vÃ  liá»‡u viá»‡c táº¡o ra nhiá»u cÃ´ng thá»©c náº¥u Äƒn tá»« cÃ¡ hÆ¡n cÃ³ xá»©ng Ä‘Ã¡ng vá»›i cÃ´ng sá»©c vÃ  tiá»n báº¡c Ä‘á»ƒ Ä‘Ã¡p á»©ng sá»Ÿ thÃ­ch cá»§a Ä‘á»‘i tÆ°á»£ng nÃ y hay khÃ´ng (phÃ¢n tÃ­ch theo quy Ä‘á»‹nh).\nExplaining Customer Behavior Äá»‘i vá»›i cÃ¡c cÃ´ng ty, viá»‡c thu tháº­p dá»¯ liá»‡u khÃ¡ch hÃ ng, phÃ¢n tÃ­ch, cháº©n Ä‘oÃ¡n lÃ  chÃ¬a khÃ³a Ä‘á»ƒ hiá»ƒu lÃ½ do táº¡i sao khÃ¡ch hÃ ng lÃ m nhÆ° váº­y. Nhá»¯ng thÃ´ng tin chi tiáº¿t nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ cáº£i thiá»‡n sáº£n pháº©m vÃ  tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng (UX), Ä‘á»‹nh vá»‹ láº¡i thÃ´ng Ä‘iá»‡p thÆ°Æ¡ng hiá»‡u vÃ  Ä‘áº£m báº£o sáº£n pháº©m phÃ¹ há»£p vá»›i Ä‘á»‘i tÆ°á»£ng.\nTiáº¿p tá»¥c vá»›i vÃ­ dá»¥ HelloFresh, hÃ£y xem xÃ©t giÃ¡ trá»‹ cá»§a viá»‡c giá»¯ chÃ¢n khÃ¡ch hÃ ng Ä‘á»‘i vá»›i cÃ´ng ty hoáº¡t Ä‘á»™ng theo mÃ´ hÃ¬nh Ä‘Äƒng kÃ½. Giá»¯ chÃ¢n khÃ¡ch hÃ ng sáº½ tiáº¿t kiá»‡m chi phÃ­ hÆ¡n so vá»›i viá»‡c cÃ³ Ä‘Æ°á»£c khÃ¡ch hÃ ng má»›i, vÃ¬ váº­y HelloFresh sá»­ dá»¥ng phÃ¢n tÃ­ch cháº©n Ä‘oÃ¡n Ä‘á»ƒ xÃ¡c Ä‘á»‹nh lÃ½ do khiáº¿n khÃ¡ch hÃ ng rá»i Ä‘i chá»n há»§y Ä‘Äƒng kÃ½.\nTrong quÃ¡ trÃ¬nh há»§y, khÃ¡ch hÃ ng rá»i Ä‘i pháº£i cung cáº¥p lÃ½ do há»§y. CÃ¡c tÃ¹y chá»n bao gá»“m tá»« â€œkhÃ´ng phÃ¹ há»£p vá»›i tÃºi tiá»n cá»§a tÃ´iâ€ Ä‘áº¿n â€œkhÃ´ng phÃ¹ há»£p vá»›i lá»‹ch trÃ¬nh hoáº·c nhu cáº§u Äƒn kiÃªng cá»§a tÃ´iâ€ vÃ  cÅ©ng cÃ³ tÃ¹y chá»n Ä‘á»ƒ viáº¿t cÃ¢u tráº£ lá»i. Báº±ng cÃ¡ch thu tháº­p dá»¯ liá»‡u nÃ y, HelloFresh cÃ³ thá»ƒ phÃ¢n tÃ­ch cÃ¡c lÃ½ do máº¥t khÃ¡ch hÃ ng Ä‘Æ°á»£c nÃªu nhiá»u nháº¥t á»Ÿ cÃ¡c khu vá»±c vÃ  nhÃ¢n kháº©u há»c cá»¥ thá»ƒ, Ä‘á»“ng thá»i sá»­ dá»¥ng phÃ¢n tÃ­ch cháº©n Ä‘oÃ¡n Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i â€œTáº¡i sao má»i ngÆ°á»i há»§y Ä‘Äƒng kÃ½?â€\nNhá»¯ng hiá»ƒu biáº¿t sÃ¢u sáº¯c nÃ y cÃ³ thá»ƒ giÃºp cáº£i thiá»‡n tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng vÃ  sáº£n pháº©m cá»§a HelloFresh Ä‘á»ƒ trÃ¡nh máº¥t thÃªm khÃ¡ch hÃ ng vÃ¬ nhá»¯ng lÃ½ do Ä‘Ã³.\nIdentifying Technology Issues Má»™t vÃ­ dá»¥ vá» diagnostic analytics trong bÃ i toÃ¡n nÃ y lÃ  cÃ¡c tester bá»‹ yÃªu cáº§u sá»­ dá»¥ng chÆ°Æ¡ng trÃ¬nh pháº§n má»m vÃ  cháº¡y thá»­ nghiá»‡m (test) Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nguyÃªn nhÃ¢n cá»§a sá»± cá»‘, cÃ¡c lá»—i. Äiá»u nÃ y thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  \u0026ldquo;cháº¡y cháº©n Ä‘oÃ¡n\u0026rdquo; vÃ  cÃ³ thá»ƒ lÃ  Ä‘iá»u báº¡n Ä‘Ã£ lÃ m trÆ°á»›c Ä‘Ã¢y khi gáº·p sá»± cá»‘ mÃ¡y tÃ­nh.\nMá»™t sá»‘ thuáº­t toÃ¡n cháº¡y liÃªn tá»¥c vÃ  hoáº¡t Ä‘á»™ng á»Ÿ cháº¿ Ä‘á»™ ná»n cá»§a mÃ¡y, trong khi nhá»¯ng thuáº­t toÃ¡n khÃ¡c cáº§n do con ngÆ°á»i thá»±c hiá»‡n. Má»™t loáº¡i kiá»ƒm tra cháº©n Ä‘oÃ¡n mÃ  báº¡n cÃ³ thá»ƒ quen thuá»™c lÃ  cháº©n Ä‘oÃ¡n dá»±a trÃªn giáº£i phÃ¡p, phÃ¡t hiá»‡n vÃ  gáº¯n cá» cÃ¡c triá»‡u chá»©ng cá»§a cÃ¡c váº¥n Ä‘á» Ä‘Ã£ biáº¿t vÃ  tiáº¿n hÃ nh quÃ©t Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nguyÃªn nhÃ¢n gá»‘c rá»…. Äiá»u nÃ y cÃ³ thá»ƒ cho phÃ©p báº¡n giáº£i quyáº¿t váº¥n Ä‘á» vÃ  bÃ¡o cÃ¡o váº¥n Ä‘á» náº¿u nguyÃªn nhÃ¢n nghiÃªm trá»ng.\nImproving Company Culture Diagnostic analytics cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c táº­n dá»¥ng Ä‘á»ƒ cáº£i thiá»‡n vÄƒn hÃ³a ná»™i bá»™ cÃ´ng ty. Bá»™ pháº­n nhÃ¢n sá»± cÃ³ thá»ƒ thu tháº­p thÃ´ng tin vá» cáº£m giÃ¡c an toÃ n vá» thá»ƒ cháº¥t vÃ  tÃ¢m lÃ½ cá»§a nhÃ¢n viÃªn, nhá»¯ng váº¥n Ä‘á» há» quan tÃ¢m cÅ©ng nhÆ° nhá»¯ng pháº©m cháº¥t vÃ  ká»¹ nÄƒng giÃºp ai Ä‘Ã³ thÃ nh cÃ´ng vÃ  háº¡nh phÃºc. Nhiá»u thÃ´ng tin chi tiáº¿t trong sá»‘ nÃ y Ä‘áº¿n tá»« viá»‡c thá»±c hiá»‡n cÃ¡c cuá»™c kháº£o sÃ¡t ná»™i bá»™, áº©n danh vÃ  thá»±c hiá»‡n cÃ¡c cuá»™c phá»ng váº¥n thÃ´i viá»‡c Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c yáº¿u tá»‘ gÃ³p pháº§n khiáº¿n nhÃ¢n viÃªn muá»‘n á»Ÿ láº¡i hoáº·c rá»i Ä‘i.\nThu tháº­p thÃ´ng tin vá» suy nghÄ© vÃ  cáº£m xÃºc cá»§a nhÃ¢n viÃªn cho phÃ©p báº¡n phÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  xÃ¡c Ä‘á»‹nh cÃ¡ch cáº£i thiá»‡n cÃ¡c lÄ©nh vá»±c nhÆ° vÄƒn hÃ³a vÃ  lá»£i Ã­ch cÃ´ng ty. Äiá»u nÃ y cÃ³ thá»ƒ bao gá»“m báº¥t cá»© Ä‘iá»u gÃ¬ tá»« mong muá»‘n cÃ´ng ty Ä‘Ã³ng gÃ³p nhiá»u hÆ¡n cho trÃ¡ch nhiá»‡m xÃ£ há»™i cá»§a doanh nghiá»‡p (CSR) cho Ä‘áº¿n cáº£m giÃ¡c bá»‹ phÃ¢n biá»‡t Ä‘á»‘i xá»­ táº¡i nÆ¡i lÃ m viá»‡c. Trong nhá»¯ng trÆ°á»ng há»£p nÃ y, dá»¯ liá»‡u trÃ¬nh bÃ y má»™t trÆ°á»ng há»£p phÃ¢n bá»• nhiá»u nguá»“n lá»±c hÆ¡n cho CSR vÃ  cÃ¡c ná»— lá»±c Ä‘a dáº¡ng, cÃ´ng báº±ng, hÃ²a nháº­p vÃ  thuá»™c vá».\nNhá»¯ng hiá»ƒu biáº¿t sÃ¢u sáº¯c tá»« cÃ¡c cuá»™c kháº£o sÃ¡t vÃ  phá»ng váº¥n cÅ©ng cÃ³ thá»ƒ cho phÃ©p ngÆ°á»i quáº£n lÃ½ tuyá»ƒn dá»¥ng xÃ¡c Ä‘á»‹nh nhá»¯ng pháº©m cháº¥t vÃ  ká»¹ nÄƒng nÃ o giÃºp ai Ä‘Ã³ thÃ nh cÃ´ng táº¡i cÃ´ng ty hoáº·c trong nhÃ³m cá»¥ thá»ƒ cá»§a báº¡n, tá»« Ä‘Ã³ giÃºp thu hÃºt vÃ  tuyá»ƒn dá»¥ng nhá»¯ng á»©ng viÃªn tá»‘t hÆ¡n cho cÃ¡c vai trÃ² cÃ²n trá»‘ng.\nPhÃ¢n tÃ­ch cháº©n Ä‘oÃ¡n cÃ³ thá»ƒ giÃºp nÃ¢ng cao má»©c Ä‘á»™ hÃ i lÃ²ng, an toÃ n vÃ  giá»¯ chÃ¢n nhÃ¢n viÃªn, cÅ©ng nhÆ° giÃºp quy trÃ¬nh tuyá»ƒn dá»¥ng hiá»‡u quáº£ hÆ¡n.\n4 Predictive analytics: Predictive analytics lÃ  má»™t phÆ°Æ¡ng phÃ¡p trong lÄ©nh vá»±c phÃ¢n tÃ­ch dá»¯ liá»‡u (data analytics) sá»­ dá»¥ng Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¡c sá»± kiá»‡n tÆ°Æ¡ng lai hoáº·c káº¿t quáº£ dá»±a trÃªn dá»¯ liá»‡u lá»‹ch sá»­ vÃ  mÃ´ hÃ¬nh hÃ³a thá»‘ng kÃª. ÄÃ¢y lÃ  má»™t cÃ´ng cá»¥ máº¡nh máº½ trong nhiá»u lÄ©nh vá»±c vÃ  ngÃ nh cÃ´ng nghiá»‡p, nhÆ° tiáº¿p thá»‹, tÃ i chÃ­nh, y táº¿, sáº£n xuáº¥t, vÃ  nhiá»u lÄ©nh vá»±c khÃ¡c.\nCÃ¡c bÆ°á»›c chÃ­nh trong quÃ¡ trÃ¬nh predictive analytics bao gá»“m:\nThu tháº­p dá»¯ liá»‡u: BÆ°á»›c Ä‘áº§u tiÃªn lÃ  thu tháº­p vÃ  tá»•ng há»£p dá»¯ liá»‡u liÃªn quan Ä‘áº¿n váº¥n Ä‘á» cáº§n dá»± Ä‘oÃ¡n. Dá»¯ liá»‡u nÃ y cÃ³ thá»ƒ lÃ  dá»¯ liá»‡u lá»‹ch sá»­ hoáº·c dá»¯ liá»‡u thá»i gian thá»±c.\nTiá»n xá»­ lÃ½ dá»¯ liá»‡u: Dá»¯ liá»‡u thÆ°á»ng cáº§n pháº£i Ä‘Æ°á»£c lÃ m sáº¡ch vÃ  tiá»n xá»­ lÃ½ trÆ°á»›c khi sá»­ dá»¥ng. Äiá»u nÃ y bao gá»“m viá»‡c loáº¡i bá» dá»¯ liá»‡u khÃ´ng há»£p lá»‡ hoáº·c thiáº¿u sÃ³t, xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u, vÃ  biáº¿n Ä‘á»•i dá»¯ liá»‡u náº¿u cáº§n.\nXÃ¢y dá»±ng mÃ´ hÃ¬nh: Trong bÆ°á»›c nÃ y, cÃ¡c mÃ´ hÃ¬nh thá»‘ng kÃª hoáº·c machine learning Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  dá»± Ä‘oÃ¡n cÃ¡c sá»± kiá»‡n tÆ°Æ¡ng lai. CÃ¡c mÃ´ hÃ¬nh phá»• biáº¿n bao gá»“m há»“i quy tuyáº¿n tÃ­nh, cÃ¢y quyáº¿t Ä‘á»‹nh, máº¡ng nÆ¡-ron, vÃ  nhiá»u mÃ´ hÃ¬nh khÃ¡c.\nÄÃ¡nh giÃ¡ vÃ  tinh chá»‰nh mÃ´ hÃ¬nh: MÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p kiá»ƒm tra vÃ  Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng dá»± Ä‘oÃ¡n. Náº¿u cáº§n, mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t.\nTriá»ƒn khai mÃ´ hÃ¬nh: Sau khi mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ vÃ  cháº¥p nháº­n, nÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c triá»ƒn khai Ä‘á»ƒ sá»­ dá»¥ng trong thá»±c táº¿. CÃ¡c dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­ch há»£p vÃ o quy trÃ¬nh kinh doanh hoáº·c há»‡ thá»‘ng thÃ´ng tin.\nPredictive analytics cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u má»¥c Ä‘Ã­ch, cháº³ng háº¡n nhÆ° dá»± Ä‘oÃ¡n doanh sá»‘ bÃ¡n hÃ ng, phÃ¢n tÃ­ch rá»§i ro tÃ­n dá»¥ng, dá»± Ä‘oÃ¡n biáº¿n Ä‘á»™ng thá»‹ trÆ°á»ng, quáº£n lÃ½ tá»“n kho, dá»± Ä‘oÃ¡n thá»i tiáº¿t, vÃ  nhiá»u á»©ng dá»¥ng khÃ¡c. ÄÃ¢y lÃ  cÃ´ng cá»¥ quan trá»ng giÃºp doanh nghiá»‡p vÃ  tá»• chá»©c lÃ m quyáº¿t Ä‘á»‹nh dá»±a trÃªn dá»¯ liá»‡u vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t kinh doanh.\n5 VÃ­ dá»¥ cá»§a PREDICTIVE ANALYTICS trong thá»±c táº¿ Finance: Forecasting Future Cash Flow GiÃ¡o sÆ° V.G. Narayanan cá»§a HBS nÃ³i: â€œCÃ¡c nhÃ  quáº£n lÃ½ cáº§n pháº£i nhÃ¬n vá» phÃ­a trÆ°á»›c Ä‘á»ƒ láº­p káº¿ hoáº¡ch cho tÃ¬nh hÃ¬nh hoáº¡t Ä‘á»™ng kinh doanh trong tÆ°Æ¡ng lai cá»§a há»â€. â€œBáº¥t ká»ƒ báº¡n lÃ m viá»‡c trong lÄ©nh vá»±c nÃ o, luÃ´n cÃ³ ráº¥t nhiá»u Ä‘iá»u khÃ´ng cháº¯c cháº¯n liÃªn quan Ä‘áº¿n quÃ¡ trÃ¬nh nÃ y.â€\nMá»i doanh nghiá»‡p Ä‘á»u cáº§n lÆ°u giá»¯ há»“ sÆ¡ tÃ i chÃ­nh Ä‘á»‹nh ká»³ vÃ  phÃ¢n tÃ­ch dá»± Ä‘oÃ¡n cÃ³ thá»ƒ Ä‘Ã³ng má»™t vai trÃ² lá»›n trong viá»‡c dá»± bÃ¡o tÃ¬nh tráº¡ng tÆ°Æ¡ng lai cá»§a cÃ´ng ty. Sá»­ dá»¥ng dá»¯ liá»‡u lá»‹ch sá»­ tá»« cÃ¡c bÃ¡o cÃ¡o tÃ i chÃ­nh trÆ°á»›c Ä‘Ã³ cÅ©ng nhÆ° dá»¯ liá»‡u tá»« ngÃ nh rá»™ng hÆ¡n, báº¡n cÃ³ thá»ƒ dá»± Ä‘oÃ¡n sá»‘ bÃ¡n, doanh thu vÃ  chi phÃ­ Ä‘á»ƒ táº¡o ra bá»©c tranh vá» tÆ°Æ¡ng lai vÃ  Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh.\nDá»± bÃ¡o dÃ²ng tiá»n trong tÆ°Æ¡ng lai lÃ  má»™t quy trÃ¬nh phÃ¢n tÃ­ch tÃ i chÃ­nh quan trá»ng, bao gá»“m viá»‡c Æ°á»›c tÃ­nh dÃ²ng tiá»n vÃ o vÃ  ra mÃ  má»™t doanh nghiá»‡p dá»± kiáº¿n â€‹â€‹sáº½ táº¡o ra trong má»™t khoáº£ng thá»i gian cá»¥ thá»ƒ trong tÆ°Æ¡ng lai. Dá»± bÃ¡o dÃ²ng tiá»n chÃ­nh xÃ¡c lÃ  ráº¥t quan trá»ng Ä‘á»ƒ láº­p káº¿ hoáº¡ch tÃ i chÃ­nh hiá»‡u quáº£, ngÃ¢n sÃ¡ch vÃ  quyáº¿t Ä‘á»‹nh trong má»™t cÃ´ng ty. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t cÃ¡i nhÃ¬n tá»•ng quan vá» cÃ¡c bÆ°á»›c vÃ  yáº¿u tá»‘ cáº§n xem xÃ©t khi dá»± bÃ¡o dÃ²ng tiá»n trong tÆ°Æ¡ng lai:\nThu tháº­p Dá»¯ liá»‡u Lá»‹ch sá»­: Báº¯t Ä‘áº§u báº±ng viá»‡c thu tháº­p vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u tÃ i chÃ­nh lá»‹ch sá»­, bao gá»“m bÃ¡o cÃ¡o dÃ²ng tiá»n, bÃ¡o cÃ¡o lá»£i nhuáº­n vÃ  báº£ng cÃ¢n Ä‘á»‘i káº¿ toÃ¡n. Dá»¯ liá»‡u lá»‹ch sá»­ cung cáº¥p thÃ´ng tin quÃ½ bÃ¡u vá» cÃ¡c mÃ´ hÃ¬nh vÃ  xu hÆ°á»›ng dÃ²ng tiá»n trong quÃ¡ khá»©.\nXÃ¡c Ä‘á»‹nh CÃ¡c ThÃ nh Pháº§n DÃ²ng Tiá»n: PhÃ¢n chia dÃ²ng tiá»n thÃ nh cÃ¡c thÃ nh pháº§n khÃ¡c nhau, bao gá»“m dÃ²ng tiá»n tá»« hoáº¡t Ä‘á»™ng kinh doanh, dÃ²ng tiá»n tá»« hoáº¡t Ä‘á»™ng Ä‘áº§u tÆ° vÃ  dÃ²ng tiá»n tá»« hoáº¡t Ä‘á»™ng tÃ i chÃ­nh. Äiá»u nÃ y giÃºp hiá»ƒu rÃµ dÃ²ng tiá»n Ä‘áº¿n tá»« Ä‘Ã¢u vÃ  Ä‘iá»u gÃ¬ lÃ m tiÃªu hao dÃ²ng tiá»n.\nÆ¯á»›c TÃ­nh Doanh Sá»‘ vÃ  Doanh Thu: Æ¯á»›c tÃ­nh doanh sá»‘ bÃ¡n hÃ ng vÃ  doanh thu tÆ°Æ¡ng lai dá»±a trÃªn nghiÃªn cá»©u thá»‹ trÆ°á»ng, dá»¯ liá»‡u doanh sá»‘ bÃ¡n hÃ ng lá»‹ch sá»­ vÃ  xu hÆ°á»›ng trong ngÃ nh. Xem xÃ©t cÃ¡c yáº¿u tá»‘ nhÆ° mÃ¹a vá»¥, sá»± phÃ¡t triá»ƒn cá»§a thá»‹ trÆ°á»ng vÃ  Ä‘á»™ng thÃ¡i cáº¡nh tranh.\nÆ¯á»›c TÃ­nh Chi PhÃ­ vÃ  PhÃ­: Dá»± Ä‘oÃ¡n cÃ¡c chi phÃ­ hoáº¡t Ä‘á»™ng, bao gá»“m chi phÃ­ vá»‘n hÃ ng bÃ¡n, chi phÃ­ hoáº¡t Ä‘á»™ng cá»‘ Ä‘á»‹nh vÃ  chi phÃ­ biáº¿n Ä‘á»•i. Xem xÃ©t láº¡m phÃ¡t, xu hÆ°á»›ng chi phÃ­ vÃ  cÃ¡c biá»‡n phÃ¡p tiáº¿t kiá»‡m chi phÃ­ cÃ³ thá»ƒ thá»±c hiá»‡n.\nThay Äá»•i Vá»‘n LÃ m Viá»‡c: PhÃ¢n tÃ­ch thay Ä‘á»•i trong vá»‘n lÃ m viá»‡c, bao gá»“m cÃ¡c tÃ i khoáº£n pháº£i thu, tÃ i khoáº£n pháº£i tráº£ vÃ  vÃ²ng quay tá»“n kho. Thay Ä‘á»•i trong vá»‘n lÃ m viá»‡c cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘Ã¡ng ká»ƒ Ä‘áº¿n dÃ²ng tiá»n.\nLáº­p Káº¿ Hoáº¡ch Äáº§u TÆ° Cá»‘ Äá»‹nh (CapEx): Dá»± Ä‘oÃ¡n cÃ¡c khoáº£n Ä‘áº§u tÆ° cá»‘ Ä‘á»‹nh cho viá»‡c mua sáº¯m tÃ i sáº£n, thiáº¿t bá»‹ vÃ  cÆ¡ sá»Ÿ háº¡ táº§ng. CapEx cÃ³ thá»ƒ cÃ³ áº£nh hÆ°á»Ÿng lá»›n Ä‘áº¿n dÃ²ng tiá»n, vÃ¬ váº­y cáº§n láº­p káº¿ hoáº¡ch cho nhá»¯ng khoáº£n chi nÃ y.\nQuáº£n LÃ½ Ná»£ vÃ  Vá»‘n Chá»§ Sá»Ÿ Há»¯u: Xem xÃ©t báº¥t ká»³ khoáº£n tráº£ ná»£, vay má»›i hoáº·c cáº¥p vá»‘n chá»§ sá»Ÿ há»¯u. Dá»‹ch vá»¥ ná»£, lÃ£i suáº¥t vÃ  vá»‘n cá»• pháº§n áº£nh hÆ°á»Ÿng Ä‘áº¿n dÃ²ng tiá»n.\nPhÃ¢n TÃ­ch Ká»‹ch Báº£n: Tiáº¿n hÃ nh phÃ¢n tÃ­ch nháº¡y cáº£m vÃ  láº­p káº¿ hoáº¡ch cho cÃ¡c ká»‹ch báº£n khÃ¡c nhau Ä‘á»ƒ tÃ­nh Ä‘áº¿n cÃ¡c káº¿t quáº£ kháº£ dÄ© khÃ¡c nhau. Äiá»u nÃ y giÃºp Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a cÃ¡c ká»‹ch báº£n khÃ¡c nhau lÃªn dÃ²ng tiá»n.\nTáº¡o BÃ¡o CÃ¡o DÃ²ng Tiá»n: PhÃ¡t triá»ƒn bÃ¡o cÃ¡o dá»± bÃ¡o dÃ²ng tiá»n bao gá»“m dÃ²ng tiá»n vÃ o vÃ  ra trong khoáº£ng thá»i gian dá»± bÃ¡o. BÃ¡o cÃ¡o nÃ y nÃªn cung cáº¥p cÃ¡i nhÃ¬n rÃµ rÃ ng vá» dÃ²ng tiá»n theo tá»«ng thÃ¡ng hoáº·c quÃ½.\nTheo DÃµi vÃ  ÄÃ¡nh GiÃ¡: LiÃªn tá»¥c theo dÃµi vÃ  Ä‘Ã¡nh giÃ¡ dÃ²ng tiá»n thá»±c táº¿ so vá»›i sá»‘ liá»‡u dá»± bÃ¡o. Äiá»u chá»‰nh dá»± bÃ¡o khi cáº§n dá»±a trÃªn hiá»‡u suáº¥t thá»±c táº¿ vÃ  thay Ä‘á»•i trong Ä‘iá»u kiá»‡n thá»‹ trÆ°á»ng.\nCÃ´ng Cá»¥ Dá»± BÃ¡o DÃ²ng Tiá»n: Xem xÃ©t viá»‡c sá»­ dá»¥ng pháº§n má»m mÃ´ hÃ¬nh tÃ i chÃ­nh hoáº·c cÃ´ng cá»¥ báº£ng tÃ­nh Ä‘á»ƒ tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh dá»± bÃ¡o vÃ  thá»±c hiá»‡n phÃ¢n tÃ­ch nháº¡y cáº£m.\nÄÃ¡nh GiÃ¡ Rá»§i Ro: XÃ¡c Ä‘á»‹nh vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c rá»§i ro cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n dÃ²ng tiá»n, cháº³ng háº¡n nhÆ° suy thoÃ¡i kinh táº¿, thay Ä‘á»•i trong hÃ nh vi cá»§a khÃ¡ch hÃ ng hoáº·c sá»± cá»‘ trong chuá»—i cung á»©ng.\nDá»± bÃ¡o dÃ²ng tiá»n hiá»‡u quáº£ lÃ  quan trá»ng Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng má»™t cÃ´ng ty cÃ³ thá»ƒ Ä‘Ã¡p á»©ng cÃ¡c nghÄ©a vá»¥ tÃ i chÃ­nh cá»§a mÃ¬nh, táº­n dá»¥ng cÆ¡ há»™i tÄƒng trÆ°á»Ÿng vÃ  Ä‘á»‘i máº·t vá»›i nhá»¯ng thÃ¡ch thá»©c tÃ i chÃ­nh. NÃ³ cÅ©ng giÃºp tá»‘i Æ°u hÃ³a chiáº¿n lÆ°á»£c quáº£n lÃ½ tiá»n máº·t vÃ  Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh Ä‘áº§u tÆ° dá»±a trÃªn thÃ´ng tin. NgoÃ i ra, cÃ¡c dá»± bÃ¡o dÃ²ng tiá»n chÃ­nh xÃ¡c thÆ°á»ng Ä‘Æ°á»£c yÃªu cáº§u bá»Ÿi cÃ¡c nhÃ  cho vay vÃ  nhÃ  Ä‘áº§u tÆ° nhÆ° má»™t pháº§n cá»§a quÃ¡ trÃ¬nh kiá»ƒm tra tÃ i chÃ­nh.\nEntertainment \u0026amp; Hospitality: Determining Staffing Needs Má»™t vÃ­ dá»¥ lÃ  viá»‡c sÃ²ng báº¡c vÃ  khÃ¡ch sáº¡n Caesars Entertainment sá»­ dá»¥ng phÃ¢n tÃ­ch dá»± Ä‘oÃ¡n Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nhu cáº§u nhÃ¢n sá»± cá»§a cÃ¡c Ä‘á»‹a Ä‘iá»ƒm kinh doanh cá»§a mÃ¬nh vÃ o nhá»¯ng thá»i Ä‘iá»ƒm cá»¥ thá»ƒ.\nTrong ngÃ nh giáº£i trÃ­ vÃ  khÃ¡ch sáº¡n, lÆ°á»£ng khÃ¡ch hÃ ng Ä‘áº¿n vÃ  Ä‘i phá»¥ thuá»™c vÃ o nhiá»u yáº¿u tá»‘ khÃ¡c nhau, táº¥t cáº£ Ä‘á»u áº£nh hÆ°á»Ÿng Ä‘áº¿n sá»‘ lÆ°á»£ng nhÃ¢n viÃªn mÃ  má»™t Ä‘á»‹a Ä‘iá»ƒm hoáº·c khÃ¡ch sáº¡n cáº§n táº¡i má»™t thá»i Ä‘iá»ƒm nháº¥t Ä‘á»‹nh. Viá»‡c sá»­ dá»¥ng quÃ¡ nhiá»u nhÃ¢n lá»±c sáº½ tá»‘n tiá»n vÃ  viá»‡c thiáº¿u nhÃ¢n lá»±c cÃ³ thá»ƒ dáº«n Ä‘áº¿n tráº£i nghiá»‡m khÃ¡ch hÃ ng tá»“i tá»‡, nhÃ¢n viÃªn lÃ m viá»‡c quÃ¡ sá»©c vÃ  nhá»¯ng sai láº§m tá»‘n kÃ©m.\nÄá»ƒ dá»± Ä‘oÃ¡n sá»‘ lÆ°á»£t nháº­n phÃ²ng khÃ¡ch sáº¡n vÃ o má»™t ngÃ y nháº¥t Ä‘á»‹nh, má»™t nhÃ³m Ä‘Ã£ phÃ¡t triá»ƒn mÃ´ hÃ¬nh há»“i quy bá»™i xem xÃ©t má»™t sá»‘ yáº¿u tá»‘. MÃ´ hÃ¬nh nÃ y cho phÃ©p Caesars bá»‘ trÃ­ nhÃ¢n sá»± cho cÃ¡c khÃ¡ch sáº¡n vÃ  sÃ²ng báº¡c cá»§a mÃ¬nh vÃ  trÃ¡nh sá»­ dá»¥ng quÃ¡ nhiá»u nhÃ¢n lá»±c á»Ÿ má»©c tá»‘t nháº¥t cÃ³ thá»ƒ.\nMarketing: Behavioral Targeting Trong tiáº¿p thá»‹, dá»¯ liá»‡u ngÆ°á»i tiÃªu dÃ¹ng ráº¥t phong phÃº vÃ  Ä‘Æ°á»£c táº­n dá»¥ng Ä‘á»ƒ táº¡o ná»™i dung, táº¡o quáº£ng cÃ¡o vÃ  táº¡o cÃ¡c chiáº¿n lÆ°á»£c nháº±m tiáº¿p cáº­n khÃ¡ch hÃ ng tiá»m nÄƒng tá»‘t hÆ¡n. Báº±ng cÃ¡ch kiá»ƒm tra dá»¯ liá»‡u hÃ nh vi lá»‹ch sá»­ vÃ  sá»­ dá»¥ng dá»¯ liá»‡u Ä‘Ã³ Ä‘á»ƒ dá»± Ä‘oÃ¡n Ä‘iá»u gÃ¬ sáº½ xáº£y ra trong tÆ°Æ¡ng lai, báº¡n Ä‘Ã£ sá»­ dá»¥ng phÃ¢n tÃ­ch dá»± Ä‘oÃ¡n.\nPhÃ¢n tÃ­ch dá»± Ä‘oÃ¡n cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng trong tiáº¿p thá»‹ Ä‘á»ƒ dá»± bÃ¡o xu hÆ°á»›ng bÃ¡n hÃ ng vÃ o cÃ¡c thá»i Ä‘iá»ƒm khÃ¡c nhau trong nÄƒm vÃ  lÃªn káº¿ hoáº¡ch cho cÃ¡c chiáº¿n dá»‹ch phÃ¹ há»£p.\nManufacturing: Preventing Malfunction CÃ¡c vÃ­ dá»¥ trÃªn sá»­ dá»¥ng phÃ¢n tÃ­ch dá»± Ä‘oÃ¡n Ä‘á»ƒ thá»±c hiá»‡n hÃ nh Ä‘á»™ng dá»±a trÃªn cÃ¡c tÃ¬nh huá»‘ng cÃ³ thá»ƒ xáº£y ra, nhÆ°ng báº¡n cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng phÃ¢n tÃ­ch dá»± Ä‘oÃ¡n Ä‘á»ƒ ngÄƒn xáº£y ra cÃ¡c tÃ¬nh huá»‘ng khÃ´ng mong muá»‘n hoáº·c cÃ³ háº¡i. VÃ­ dá»¥, trong lÄ©nh vá»±c sáº£n xuáº¥t, cÃ¡c thuáº­t toÃ¡n cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘Ã o táº¡o báº±ng cÃ¡ch sá»­ dá»¥ng dá»¯ liá»‡u lá»‹ch sá»­ Ä‘á»ƒ dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c khi nÃ o má»™t bá»™ pháº­n mÃ¡y mÃ³c cÃ³ thá»ƒ gáº·p trá»¥c tráº·c.\nKhi Ä‘Ã¡p á»©ng cÃ¡c tiÃªu chÃ­ cho sá»± cá»‘ sáº¯p xáº£y ra, thuáº­t toÃ¡n sáº½ Ä‘Æ°á»£c kÃ­ch hoáº¡t Ä‘á»ƒ cáº£nh bÃ¡o nhÃ¢n viÃªn cÃ³ thá»ƒ dá»«ng mÃ¡y vÃ  cÃ³ kháº£ nÄƒng tiáº¿t kiá»‡m cho cÃ´ng ty hÃ ng nghÃ¬n, náº¿u khÃ´ng muá»‘n nÃ³i lÃ  hÃ ng triá»‡u Ä‘Ã´ la chi phÃ­ sáº£n pháº©m bá»‹ hÆ° há»ng vÃ  sá»­a chá»¯a. PhÃ¢n tÃ­ch nÃ y dá»± Ä‘oÃ¡n cÃ¡c tÃ¬nh huá»‘ng trá»¥c tráº·c táº¡i thá»i Ä‘iá»ƒm nÃ y thay vÃ¬ trÆ°á»›c nhiá»u thÃ¡ng hoáº·c nhiá»u nÄƒm.\nMá»™t sá»‘ thuáº­t toÃ¡n tháº­m chÃ­ cÃ²n Ä‘á» xuáº¥t cÃ¡c báº£n sá»­a lá»—i vÃ  tá»‘i Æ°u hÃ³a Ä‘á»ƒ trÃ¡nh cÃ¡c trá»¥c tráº·c trong tÆ°Æ¡ng lai vÃ  nÃ¢ng cao hiá»‡u quáº£, tiáº¿t kiá»‡m thá»i gian, tiá»n báº¡c vÃ  cÃ´ng sá»©c. ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ vá» phÃ¢n tÃ­ch theo quy Ä‘á»‹nh; thÆ°á»ng xuyÃªn hÆ¡n khÃ´ng, má»™t hoáº·c nhiá»u loáº¡i phÃ¢n tÃ­ch Ä‘Æ°á»£c sá»­ dá»¥ng song song Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á».\nHealth Care: Early Detection of Allergic Reactions Má»™t vÃ­ dá»¥ khÃ¡c vá» viá»‡c sá»­ dá»¥ng thuáº­t toÃ¡n Ä‘á»ƒ phÃ¢n tÃ­ch dá»± Ä‘oÃ¡n nhanh chÃ³ng nháº±m phÃ²ng ngá»«a Ä‘áº¿n tá»« ngÃ nh chÄƒm sÃ³c sá»©c khá»e. Viá»‡n Wyss táº¡i Äáº¡i há»c Harvard há»£p tÃ¡c vá»›i Quá»¹ KeepSmilin4Abbie Ä‘á»ƒ phÃ¡t triá»ƒn má»™t thiáº¿t bá»‹ cÃ´ng nghá»‡ cÃ³ thá»ƒ Ä‘eo Ä‘Æ°á»£c nháº±m dá»± Ä‘oÃ¡n pháº£n á»©ng dá»‹ á»©ng pháº£n vá»‡ vÃ  tá»± Ä‘á»™ng truyá»n epinephrine cá»©u sá»‘ng.\nCáº£m biáº¿n, Ä‘Æ°á»£c gá»i lÃ  AbbieSense, phÃ¡t hiá»‡n cÃ¡c dáº¥u hiá»‡u sinh lÃ½ sá»›m cá»§a sá»‘c pháº£n vá»‡ nhÆ° nhá»¯ng yáº¿u tá»‘ dá»± bÃ¡o pháº£n á»©ng tiáº¿p theo â€” vÃ  nÃ³ thá»±c hiá»‡n nhanh hÆ¡n nhiá»u so vá»›i kháº£ nÄƒng cá»§a con ngÆ°á»i. Khi má»™t pháº£n á»©ng Ä‘Æ°á»£c dá»± Ä‘oÃ¡n sáº½ xáº£y ra, má»™t pháº£n á»©ng thuáº­t toÃ¡n sáº½ Ä‘Æ°á»£c kÃ­ch hoáº¡t. Thuáº­t toÃ¡n cÃ³ thá»ƒ dá»± Ä‘oÃ¡n má»©c Ä‘á»™ nghiÃªm trá»ng cá»§a pháº£n á»©ng, cáº£nh bÃ¡o cho cÃ¡ nhÃ¢n vÃ  ngÆ°á»i chÄƒm sÃ³c, Ä‘á»“ng thá»i tá»± Ä‘á»™ng tiÃªm epinephrine khi cáº§n thiáº¿t. Kháº£ nÄƒng dá»± Ä‘oÃ¡n pháº£n á»©ng cá»§a cÃ´ng nghá»‡ nÃ y vá»›i tá»‘c Ä‘á»™ nhanh hÆ¡n tá»‘c Ä‘á»™ phÃ¡t hiá»‡n thá»§ cÃ´ng cÃ³ thá»ƒ cá»©u Ä‘Æ°á»£c máº¡ng sá»‘ng.\n5 Prescriptive analytics: ÄÆ°a ra, gá»£i Ã½ business modelling má»›i, Data Ä‘Æ°a ra lá»i khuyÃªn Ä‘á»ƒ thay Ä‘á»•i mÃ´ hÃ¬nh kinh doanh.\nPrescriptive analytics lÃ  má»™t loáº¡i phÃ¢n tÃ­ch dá»¯ liá»‡u trong lÄ©nh vá»±c quáº£n lÃ½ dá»±a trÃªn dá»¯ liá»‡u (data analytics), nÆ¡i má»¥c tiÃªu chÃ­nh lÃ  cung cáº¥p cÃ¡c hÆ°á»›ng dáº«n vÃ  Ä‘á» xuáº¥t vá» cÃ¡ch thá»±c hiá»‡n má»™t hÃ nh Ä‘á»™ng cá»¥ thá»ƒ Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tá»‘i Æ°u dá»±a trÃªn má»™t loáº¡t cÃ¡c biáº¿n sá»‘ vÃ  háº¡n cháº¿. KhÃ¡i niá»‡m nÃ y Ä‘áº·t ra cÃ¢u há»i \u0026ldquo;NÃªn lÃ m gÃ¬?\u0026rdquo; vÃ  Ä‘Æ°a ra cÃ¡c giáº£i phÃ¡p hoáº·c hÆ°á»›ng dáº«n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu mong muá»‘n.\nPrescriptive analytics thÆ°á»ng bao gá»“m cÃ¡c bÆ°á»›c sau:\nThu tháº­p dá»¯ liá»‡u: Báº¯t Ä‘áº§u báº±ng viá»‡c thu tháº­p vÃ  tá»•ng há»£p dá»¯ liá»‡u liÃªn quan Ä‘áº¿n váº¥n Ä‘á» hoáº·c quÃ¡ trÃ¬nh cáº§n Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a. Äiá»u nÃ y cÃ³ thá»ƒ bao gá»“m dá»¯ liá»‡u lá»‹ch sá»­, dá»¯ liá»‡u hiá»‡n táº¡i vÃ  cÃ¡c thÃ´ng tin khÃ¡c liÃªn quan.\nTiá»n xá»­ lÃ½ dá»¯ liá»‡u: Dá»¯ liá»‡u thÆ°á»ng cáº§n Ä‘Æ°á»£c lÃ m sáº¡ch, biáº¿n Ä‘á»•i vÃ  chuáº©n hÃ³a trÆ°á»›c khi sá»­ dá»¥ng cho phÃ¢n tÃ­ch. Äiá»u nÃ y bao gá»“m viá»‡c loáº¡i bá» dá»¯ liá»‡u khÃ´ng há»£p lá»‡, xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u vÃ  chuáº©n hÃ³a Ä‘á»‹nh dáº¡ng.\nXÃ¢y dá»±ng mÃ´ hÃ¬nh: Sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p phÃ¢n tÃ­ch dá»¯ liá»‡u phá»©c táº¡p nhÆ° tá»‘i Æ°u hÃ³a, mÃ´ hÃ¬nh hÃ³a toÃ¡n há»c, mÃ´ hÃ¬nh há»c mÃ¡y vÃ  mÃ´ hÃ¬nh láº­p káº¿ hoáº¡ch Ä‘á»ƒ táº¡o ra cÃ¡c ká»‹ch báº£n vÃ  giáº£i phÃ¡p tá»‘i Æ°u dá»±a trÃªn dá»¯ liá»‡u vÃ  cÃ¡c yáº¿u tá»‘ háº¡n cháº¿.\nÄÆ°a ra giáº£i phÃ¡p vÃ  quyáº¿t Ä‘á»‹nh: Dá»±a trÃªn káº¿t quáº£ cá»§a mÃ´ hÃ¬nh phÃ¢n tÃ­ch, prescriptive analytics Ä‘Æ°a ra cÃ¡c giáº£i phÃ¡p hoáº·c quyáº¿t Ä‘á»‹nh cá»¥ thá»ƒ Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu tá»‘i Æ°u. Äiá»u nÃ y cÃ³ thá»ƒ bao gá»“m viá»‡c Ä‘á» xuáº¥t káº¿ hoáº¡ch sáº£n xuáº¥t, quáº£n lÃ½ tá»“n kho, láº­p lá»‹ch giao hÃ ng, hoáº·c cÃ¡c hÃ nh Ä‘á»™ng kinh doanh khÃ¡c.\nTriá»ƒn khai vÃ  theo dÃµi: CÃ¡c giáº£i phÃ¡p vÃ  quyáº¿t Ä‘á»‹nh Ä‘Æ°á»£c triá»ƒn khai trong thá»±c táº¿ vÃ  theo dÃµi Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh hiá»‡u quáº£ vÃ  Ä‘á» xuáº¥t Ä‘iá»u chá»‰nh náº¿u cáº§n.\nPrescriptive analytics thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u lÄ©nh vá»±c, nhÆ° tÃ i chÃ­nh, sáº£n xuáº¥t, dá»± Ã¡n, y táº¿ vÃ  quáº£n lÃ½ chuá»—i cung á»©ng Ä‘á»ƒ giÃºp tá»• chá»©c ra quyáº¿t Ä‘á»‹nh chiáº¿n lÆ°á»£c, tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh kinh doanh vÃ  táº¡o ra giÃ¡ trá»‹ tá»‘i Æ°u.\n6 VÃ­ dá»¥ PRESCRIPTIVE ANALYTICS trong thá»±c táº¿\nVenture Capital: Investment Decisions CÃ¡c quyáº¿t Ä‘á»‹nh Ä‘áº§u tÆ°, máº·c dÃ¹ thÆ°á»ng dá»±a trÃªn trá»±c giÃ¡c, nhÆ°ng cÃ³ thá»ƒ Ä‘Æ°á»£c cá»§ng cá»‘ báº±ng cÃ¡c thuáº­t toÃ¡n cÃ¢n nháº¯c rá»§i ro vÃ  Ä‘Æ°a ra khuyáº¿n nghá»‹ cÃ³ nÃªn Ä‘áº§u tÆ° hay khÃ´ng.\nMá»™t vÃ­ dá»¥ trong lÄ©nh vá»±c Ä‘áº§u tÆ° máº¡o hiá»ƒm lÃ  má»™t thá»­ nghiá»‡m kiá»ƒm tra tÃ­nh hiá»‡u quáº£ cá»§a cÃ¡c quyáº¿t Ä‘á»‹nh cá»§a thuáº­t toÃ¡n vá» viá»‡c nÃªn Ä‘áº§u tÆ° vÃ o cÃ´ng ty khá»Ÿi nghiá»‡p nÃ o so vá»›i quyáº¿t Ä‘á»‹nh cá»§a cÃ¡c nhÃ  Ä‘áº§u tÆ° thiÃªn tháº§n.\nNhá»¯ng phÃ¡t hiá»‡n nÃ y cÃ³ nhiá»u sáº¯c thÃ¡i. Thuáº­t toÃ¡n hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n cÃ¡c nhÃ  Ä‘áº§u tÆ° thiÃªn tháº§n, nhá»¯ng ngÆ°á»i Ã­t kinh nghiá»‡m Ä‘áº§u tÆ° hÆ¡n vÃ  kÃ©m ká»¹ nÄƒng hÆ¡n trong viá»‡c kiá»ƒm soÃ¡t thÃ nh kiáº¿n nháº­n thá»©c cá»§a há»; tuy nhiÃªn, cÃ¡c nhÃ  Ä‘áº§u tÆ° thiÃªn tháº§n Ä‘Ã£ vÆ°á»£t trá»™i hÆ¡n thuáº­t toÃ¡n khi há» cÃ³ kinh nghiá»‡m Ä‘áº§u tÆ° vÃ  cÃ³ thá»ƒ kiá»ƒm soÃ¡t nhá»¯ng thÃ nh kiáº¿n â€‹â€‹nháº­n thá»©c cá»§a mÃ¬nh.\nThá»­ nghiá»‡m nÃ y lÃ m sÃ¡ng tá» vai trÃ² bá»• sung mÃ  phÃ¢n tÃ­ch theo quy Ä‘á»‹nh pháº£i Ä‘Ã³ng trong viá»‡c Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh vÃ  tiá»m nÄƒng cá»§a nÃ³ trong viá»‡c há»— trá»£ viá»‡c ra quyáº¿t Ä‘á»‹nh khi khÃ´ng cÃ³ kinh nghiá»‡m vÃ  cáº§n gáº¯n cá» nhá»¯ng thÃ nh kiáº¿n vá» nháº­n thá»©c. Má»™t thuáº­t toÃ¡n chá»‰ khÃ´ng thiÃªn vá»‹ khi dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘Ã o táº¡o cÃ¹ng vá»›i nÃ³, do Ä‘Ã³ cáº§n cÃ³ sá»± Ä‘Ã¡nh giÃ¡ cá»§a con ngÆ°á»i cho dÃ¹ cÃ³ sá»­ dá»¥ng thuáº­t toÃ¡n hay khÃ´ng.\nSales: Lead Scoring Prescriptive analytics Ä‘Ã³ng má»™t vai trÃ² ná»•i báº­t trong viá»‡c bÃ¡n hÃ ng thÃ´ng qua viá»‡c cháº¥m Ä‘iá»ƒm khÃ¡ch hÃ ng tiá»m nÄƒng, cÃ²n Ä‘Æ°á»£c gá»i lÃ  xáº¿p háº¡ng khÃ¡ch hÃ ng tiá»m nÄƒng. Ghi Ä‘iá»ƒm khÃ¡ch hÃ ng tiá»m nÄƒng lÃ  quÃ¡ trÃ¬nh chá»‰ Ä‘á»‹nh giÃ¡ trá»‹ Ä‘iá»ƒm cho cÃ¡c hÃ nh Ä‘á»™ng khÃ¡c nhau dá»c theo kÃªnh bÃ¡n hÃ ng, cho phÃ©p báº¡n hoáº·c thuáº­t toÃ¡n xáº¿p háº¡ng khÃ¡ch hÃ ng tiá»m nÄƒng dá»±a trÃªn kháº£ nÄƒng há» chuyá»ƒn Ä‘á»•i thÃ nh khÃ¡ch hÃ ng.\nCÃ¡c hÃ nh Ä‘á»™ng báº¡n cÃ³ thá»ƒ gÃ¡n giÃ¡ trá»‹ bao gá»“m:\nLÆ°á»£t xem trang\nTÆ°Æ¡ng tÃ¡c qua email\nTÃ¬m kiáº¿m trang web\nTÆ°Æ¡ng tÃ¡c ná»™i dung, cháº³ng háº¡n nhÆ° tham dá»± há»™i tháº£o trÃªn web, táº£i xuá»‘ng sÃ¡ch Ä‘iá»‡n tá»­ hoáº·c xem video\nKhi gÃ¡n cho má»—i hÃ nh Ä‘á»™ng má»™t giÃ¡ trá»‹ Ä‘iá»ƒm, hÃ£y chá»‰ Ä‘á»‹nh sá»‘ Ä‘iá»ƒm cao nháº¥t cho nhá»¯ng hÃ nh Ä‘á»™ng ngá»¥ Ã½ Ã½ Ä‘á»‹nh mua hÃ ng (vÃ­ dá»¥: truy cáº­p trang sáº£n pháº©m) vÃ  Ä‘iá»ƒm tiÃªu cá»±c cho nhá»¯ng hÃ nh Ä‘á»™ng tiáº¿t lá»™ Ã½ Ä‘á»‹nh khÃ´ng mua hÃ ng (vÃ­ dá»¥: xem tin tuyá»ƒn dá»¥ng trÃªn trang web cá»§a báº¡n ). Äiá»u nÃ y cÃ³ thá»ƒ giÃºp Æ°u tiÃªn tiáº¿p cáº­n nhá»¯ng khÃ¡ch hÃ ng tiá»m nÄƒng cÃ³ nhiá»u kháº£ nÄƒng chuyá»ƒn Ä‘á»•i thÃ nh khÃ¡ch hÃ ng nháº¥t, cÃ³ kháº£ nÄƒng tiáº¿t kiá»‡m thá»i gian vÃ  tiá»n báº¡c cho tá»• chá»©c cá»§a báº¡n.\nContent Curation: Algorithmic Recommendations Náº¿u báº¡n Ä‘Ã£ tá»«ng sá»­ dá»¥ng má»™t máº¡ng xÃ£ há»™i hoáº·c á»©ng dá»¥ng háº¹n hÃ², báº¡n cÃ³ thá»ƒ Ä‘Ã£ trá»±c tiáº¿p tráº£i nghiá»‡m cÃ¡c Prescriptive analytics thÃ´ng qua cÃ¡c Ä‘á» xuáº¥t ná»™i dung thuáº­t toÃ¡n.\nThuáº­t toÃ¡n cá»§a doanh nghiá»‡p thu tháº­p dá»¯ liá»‡u dá»±a trÃªn lá»‹ch sá»­ tÆ°Æ¡ng tÃ¡c cá»§a báº¡n trÃªn ná»n táº£ng cá»§a há» (vÃ  cÃ³ thá»ƒ cáº£ nhá»¯ng ná»n táº£ng khÃ¡c). Sá»± káº¿t há»£p cÃ¡c hÃ nh vi trÆ°á»›c Ä‘Ã¢y cá»§a báº¡n cÃ³ thá»ƒ Ä‘Ã³ng vai trÃ² lÃ  tÃ¡c nhÃ¢n kÃ­ch hoáº¡t thuáº­t toÃ¡n Ä‘Æ°a ra Ä‘á» xuáº¥t cá»¥ thá»ƒ. VÃ­ dá»¥: náº¿u báº¡n thÆ°á»ng xuyÃªn xem video Ä‘Ã¡nh giÃ¡ giÃ y trÃªn YouTube, thuáº­t toÃ¡n cá»§a ná»n táº£ng cÃ³ thá»ƒ sáº½ phÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘Ã³ vÃ  khuyÃªn báº¡n nÃªn xem nhiá»u hÆ¡n cÃ¹ng loáº¡i video hoáº·c ná»™i dung tÆ°Æ¡ng tá»± mÃ  báº¡n cÃ³ thá»ƒ tháº¥y thÃº vá»‹.\nTrÃªn máº¡ng xÃ£ há»™i, nguá»“n cáº¥p dá»¯ liá»‡u â€œDÃ nh cho báº¡nâ€ cá»§a TikTok lÃ  má»™t vÃ­ dá»¥ vá» hoáº¡t Ä‘á»™ng phÃ¢n tÃ­ch theo quy Ä‘á»‹nh. Trang web cá»§a cÃ´ng ty giáº£i thÃ­ch ráº±ng cÃ¡c tÆ°Æ¡ng tÃ¡c cá»§a ngÆ°á»i dÃ¹ng trÃªn á»©ng dá»¥ng, giá»‘ng nhÆ° viá»‡c ghi Ä‘iá»ƒm trong doanh sá»‘ bÃ¡n hÃ ng, Ä‘Æ°á»£c tÃ­nh trá»ng sá»‘ dá»±a trÃªn dáº¥u hiá»‡u quan tÃ¢m.\nâ€œVÃ­ dá»¥â€, trang web cá»§a TikTok cho biáº¿t, â€œnáº¿u báº¡n xem háº¿t má»™t video, Ä‘Ã³ lÃ  dáº¥u hiá»‡u máº¡nh máº½ cho tháº¥y báº¡n quan tÃ¢m. Sau Ä‘Ã³, cÃ¡c video Ä‘Æ°á»£c xáº¿p háº¡ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh kháº£ nÄƒng báº¡n quan tÃ¢m Ä‘áº¿n tá»«ng video vÃ  Ä‘Æ°á»£c gá»­i tá»›i tá»«ng nguá»“n cáº¥p dá»¯ liá»‡u \u0026lsquo;DÃ nh cho báº¡n\u0026rsquo; duy nháº¥t.â€\nTrÆ°á»ng há»£p sá»­ dá»¥ng phÃ¢n tÃ­ch theo quy Ä‘á»‹nh nÃ y cÃ³ thá»ƒ giÃºp tá»· lá»‡ tÆ°Æ¡ng tÃ¡c cá»§a khÃ¡ch hÃ ng cao hÆ¡n, má»©c Ä‘á»™ hÃ i lÃ²ng cá»§a khÃ¡ch hÃ ng tÄƒng lÃªn vÃ  kháº£ nÄƒng nháº¯m má»¥c tiÃªu láº¡i khÃ¡ch hÃ ng báº±ng quáº£ng cÃ¡o dá»±a trÃªn lá»‹ch sá»­ hÃ nh vi cá»§a há».\nBanking: Fraud Detection BÃ i toÃ¡n prescriptive analytics á»Ÿ Ä‘Ã¢y lÃ  phÃ¡t hiá»‡n vÃ  gáº¯ng nhÃ£n gian láº­n ngÃ¢n hÃ ng.\nVá»›i khá»‘i lÆ°á»£ng dá»¯ liá»‡u khá»•ng lá»“ Ä‘Æ°á»£c lÆ°u trá»¯ trong há»‡ thá»‘ng cá»§a ngÃ¢n hÃ ng, má»™t ngÆ°á»i gáº§n nhÆ° khÃ´ng thá»ƒ phÃ¡t hiá»‡n thá»§ cÃ´ng báº¥t ká»³ hoáº¡t Ä‘á»™ng Ä‘Ã¡ng ngá» nÃ o trong má»™t tÃ i khoáº£n. Má»™t thuáº­t toÃ¡nâ€”Ä‘Æ°á»£c Ä‘Ã o táº¡o báº±ng cÃ¡ch sá»­ dá»¥ng dá»¯ liá»‡u giao dá»‹ch lá»‹ch sá»­ cá»§a khÃ¡ch hÃ ngâ€”phÃ¢n tÃ­ch vÃ  quÃ©t dá»¯ liá»‡u giao dá»‹ch má»›i Ä‘á»ƒ tÃ¬m nhá»¯ng Ä‘iá»ƒm báº¥t thÆ°á»ng. VÃ­ dá»¥: cÃ³ láº½ báº¡n thÆ°á»ng chi 3.000 Ä‘Ã´ la má»—i thÃ¡ng, nhÆ°ng thÃ¡ng nÃ y, tháº» tÃ­n dá»¥ng cá»§a báº¡n bá»‹ tÃ­nh phÃ­ 30.000 Ä‘Ã´ la.\nThuáº­t toÃ¡n phÃ¢n tÃ­ch cÃ¡c máº«u trong dá»¯ liá»‡u giao dá»‹ch cá»§a báº¡n, cáº£nh bÃ¡o ngÃ¢n hÃ ng vÃ  Ä‘Æ°a ra hÆ°á»›ng hÃ nh Ä‘á»™ng Ä‘Æ°á»£c Ä‘á» xuáº¥t. Trong vÃ­ dá»¥ nÃ y, hÃ nh Ä‘á»™ng cÃ³ thá»ƒ lÃ  há»§y tháº» tÃ­n dá»¥ng vÃ¬ nÃ³ cÃ³ thá»ƒ Ä‘Ã£ bá»‹ Ä‘Ã¡nh cáº¯p.\nProduct Management: Development and Improvement Prescriptive analytics cÅ©ng cÃ³ thá»ƒ cung cáº¥p thÃ´ng tin cho viá»‡c phÃ¡t triá»ƒn vÃ  cáº£i tiáº¿n sáº£n pháº©m. NgÆ°á»i quáº£n lÃ½ sáº£n pháº©m cÃ³ thá»ƒ thu tháº­p dá»¯ liá»‡u ngÆ°á»i dÃ¹ng báº±ng cÃ¡ch kháº£o sÃ¡t khÃ¡ch hÃ ng, cháº¡y thá»­ nghiá»‡m phiÃªn báº£n beta cá»§a sáº£n pháº©m, tiáº¿n hÃ nh nghiÃªn cá»©u thá»‹ trÆ°á»ng vá»›i nhá»¯ng ngÆ°á»i hiá»‡n khÃ´ng pháº£i lÃ  ngÆ°á»i dÃ¹ng sáº£n pháº©m vÃ  thu tháº­p dá»¯ liá»‡u hÃ nh vi khi ngÆ°á»i dÃ¹ng hiá»‡n táº¡i tÆ°Æ¡ng tÃ¡c. Táº¥t cáº£ dá»¯ liá»‡u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n tÃ­châ€”theo cÃ¡ch thá»§ cÃ´ng hoáº·c báº±ng thuáº­t toÃ¡nâ€”Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xu hÆ°á»›ng, khÃ¡m phÃ¡ lÃ½ do cá»§a nhá»¯ng xu hÆ°á»›ng Ä‘Ã³ vÃ  dá»± Ä‘oÃ¡n liá»‡u cÃ¡c xu hÆ°á»›ng Ä‘Æ°á»£c dá»± Ä‘oÃ¡n cÃ³ tÃ¡i diá»…n hay khÃ´ng.\nPhÃ¢n tÃ­ch theo quy Ä‘á»‹nh cÃ³ thá»ƒ giÃºp xÃ¡c Ä‘á»‹nh nhá»¯ng tÃ­nh nÄƒng nÃ o nÃªn Ä‘Æ°a vÃ o hoáº·c loáº¡i bá» khá»i sáº£n pháº©m vÃ  nhá»¯ng tÃ­nh nÄƒng nÃ o cáº§n thay Ä‘á»•i Ä‘á»ƒ Ä‘áº£m báº£o tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng tá»‘i Æ°u.\nMarketing: Email Automation Tá»± Ä‘á»™ng hÃ³a email lÃ  má»™t vÃ­ dá»¥ rÃµ rÃ ng vá» phÃ¢n tÃ­ch theo quy Ä‘á»‹nh táº¡i nÆ¡i lÃ m viá»‡c. CÃ¡c nhÃ  tiáº¿p thá»‹ sá»­ dá»¥ng tÃ­nh nÄƒng tá»± Ä‘á»™ng hÃ³a email Ä‘á»ƒ sáº¯p xáº¿p khÃ¡ch hÃ ng tiá»m nÄƒng thÃ nh cÃ¡c danh má»¥c dá»±a trÃªn Ä‘á»™ng lá»±c, suy nghÄ© vÃ  Ã½ Ä‘á»‹nh cá»§a há», Ä‘á»“ng thá»i gá»­i ná»™i dung email cho há» dá»±a trÃªn cÃ¡c danh má»¥c Ä‘Ã³. Má»i tÆ°Æ¡ng tÃ¡c cá»§a khÃ¡ch hÃ ng tiá»m nÄƒng vá»›i email Ä‘á»u cÃ³ thá»ƒ xáº¿p há» vÃ o danh má»¥c khÃ¡c, dáº«n Ä‘áº¿n kÃ­ch hoáº¡t má»™t nhÃ³m thÃ´ng bÃ¡o khÃ¡c.\nMáº·c dÃ¹ Ä‘Ã¢y chá»‰ lÃ  phÃ¢n tÃ­ch quy Ä‘á»‹nh theo thuáº­t toÃ¡n thuáº§n tÃºy, nhÆ°ng má»™t ngÆ°á»i nÃªn láº­p káº¿ hoáº¡ch, táº¡o vÃ  giÃ¡m sÃ¡t cÃ¡c luá»“ng tá»± Ä‘á»™ng hÃ³a. Tá»± Ä‘á»™ng hÃ³a email cho phÃ©p cÃ¡c cÃ´ng ty cung cáº¥p tin nháº¯n Ä‘Æ°á»£c cÃ¡ nhÃ¢n hÃ³a trÃªn quy mÃ´ lá»›n vÃ  tÄƒng cÆ¡ há»™i chuyá»ƒn Ä‘á»•i khÃ¡ch hÃ ng tiá»m nÄƒng thÃ nh khÃ¡ch hÃ ng báº±ng cÃ¡ch sá»­ dá»¥ng ná»™i dung phÃ¹ há»£p vá»›i Ä‘á»™ng cÆ¡ vÃ  nhu cáº§u cá»§a há».\nII. SÃ¡u bÆ°á»›c cÆ¡ báº£n báº¯t Ä‘áº§u má»™t dá»± Ã¡n Data Analytics BÆ°á»›c 0 : Prepair - Chuáº©n bá»‹ Kiáº¿n thá»©c ngÃ nh\nSáº£n pháº©m nhÆ° tháº¿ nÃ o\nKhÃ¡ch hÃ ng lÃ  ai (who)\nKhÃ¡i niá»‡m Ä‘áº·c thÃ¹\nBÆ°á»›c 1: Define analytics requirement - TÃ¬m ra cÃ¡c cÃ¢u há»i cáº§n tráº£ lá»i CÃ¢u há»i Ä‘Æ°á»£c Ä‘Æ°a ra tá»« cÃ¡c bá»™ pháº­n trong cÃ´ng ty\nCÃ¢u há»i Ä‘Æ°á»£c Ä‘Æ°a ra tá»« chÃ­nh báº¡n trong quÃ¡ trÃ¬nh cÃ¡c báº¡n lÃ m viá»‡c trong cÃ´ng ty\nBÆ°á»›c 2: Collecting data Náº¯m rÃµ dá»¯ liá»‡u mÃ¬nh Ä‘ang cÃ³\nNáº¯m rÃµ data mÃ¬nh cÃ³ thá»ƒ láº¥y Ä‘Æ°á»£c tá»«\nData Engineer\nData analytics lead\nData sciencetist\nTá»« nhá»¯ng ngÆ°á»i cÃ³ kiáº¿n thá»©c liÃªn quan tá»›i data mÃ¬nh cáº§n thu tháº­p\nBÆ°á»›c 3: Clearning data Xá»­ lÃ½ dá»¯ liá»‡u rá»—ng\nXá»­ lÃ½ outliers\nXá»­ lÃ½ giÃ¡ trá»‹ sai lá»‡ch\nÄÆ°a cÃ¡c giÃ¡ trá»‹ sá»‘ vá» cÃ¹ng 1 range khi cÃ³ sá»± chÃªnh lá»‡ch quÃ¡ lá»›n\nBÆ°á»›c 4: Analyzing data Sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh\nSegmentation -\u0026gt; clustering\nPredict prices -\u0026gt; time series\nKhÃ¡ch hÃ ng tiá»m áº©n -\u0026gt; classification\nÄÃ¡nh giÃ¡ campain -\u0026gt; A/B testing\nBÆ°á»›c 5: Presenting Report Táº¡o cÃ¡c Reporting cho ban giÃ¡m Ä‘á»‘c vÃ  cÃ¡c Ä‘á»‘i tÆ°á»£ng liÃªn quan\nThu nháº­n cÃ¡c gÃ³p Ã½\nQuay láº¡i bÆ°á»›c 0 Ä‘á»ƒ chá»‰nh sá»­a\nIII. CÃ¡c bÃ i toÃ¡n thÃ´ng dá»¥ng nháº¥t cá»§a DA CÃ³ 3 bÃ i toÃ n thÃ´ng dá»¥ng nháº¥t, mÃ¬nh chá»‰ liá»‡t kÃª tÃ³m táº¯t, do má»—i má»¥c lÃ  má»™t chá»§ Ä‘á» siÃªu to khá»•ng lá»“ vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c tiáº¿p tá»¥c trÃ¬nh bÃ y á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\nÄo lÆ°á»ng tÃ¡c Ä‘á»™ng cá»§a thay Ä‘á»•i so vá»›i hiá»‡n táº¡i ( Quan trá»ng nháº¥t) Sá»± thay Ä‘á»•i vá» sáº£n pháº©m\nSá»± thay Ä‘á»•i vá» sÃ¡ng kiáº¿n\nSá»­ dá»¥ng A/B testing\nA láº¥y 1 táº­p nhá» Ä‘á»ƒ cáº£i tiáº¿n, gá»i lÃ  A\nB lÃ  pháº§n cÅ©, lÃºc chÆ°a thay Ä‘á»•i\nDá»± bÃ¡o ( Quan trá»ng) Sá»­ dá»¥ng trong tÃ i chÃ­nh, marketing\nDá»± bÃ¡o doanh thu cá»§a quÃ½\nDá»± bÃ¡o doanh thu cá»§a nÄƒm\nDá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u , giÃ¡ vÃ ng, sá»©c mua \u0026hellip;.\nSá»­ dá»¥ng mÃ´ hÃ¬nh time series\nPhÃ¢n tÃ­ch khÃ¡ch hÃ ng Nháº­n dáº¡ng khÃ¡ch hÃ ng ( Quan trá»ng nháº¥t) Customer segmentation\nCustomer profiling\nSá»­ dá»¥ng thuáº­t toÃ¡n clustering\nSá»­ dá»¥ng mÃ´ hÃ¬nh RFM\nCÃ¡c báº¡n cÃ³ thá»ƒ xem vÃ­ dá»¥ trong bÃ i viáº¿t nÃ y cá»§a mÃ¬nh vá» mÃ´ hÃ¬nh RFM\nhttps://www.phamduytung.com/blog/2022-12-03-marketing-with-python/\nCross selling TÃ¬m khÃ¡ch hÃ ng tiá»m nÄƒng sáº½ mua hÃ ng\nCustomer propensity model\nSá»­ dá»¥ng logistic regression\nCustomer journey PhÃ¢n tÃ­ch phá»…u khÃ¡ch hÃ ng\ntÃ¬m hiá»ƒu lá»™ trÃ¬nh cá»§a khÃ¡ch hÃ ng\nFunnel analysis\nBasket analytics PhÃ¢n tÃ­ch giá» hÃ ng\nMá»™t khÃ¡ch hÃ ng sáº½ nhiá»u kháº£ nÄƒng mua má»™t loáº¡i hÃ ng nÃ o tiáº¿p theo thÃ¬ sá»­ dá»¥ng Basket analytics\nLuáº­t káº¿t há»£p\nÄo lÆ°á»ng thá»i háº¡n tÃ¡c Ä‘á»™ng cá»§a má»™t cáº£i tiáº¿n / sale Survival analytics\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\nTÃ i liá»‡u tham kháº£o\nhttps://online.hbs.edu/blog/post/descriptive-analytics\nhttps://online.hbs.edu/blog/post/diagnostic-analytics\nKhoÃ¡ há»c nÃªn há»c\nhttps://www.coursera.org/specializations/statistical-inference-for-data-science-applications\n","date":"Jul 29, 2023","img":"https://unsplash.it/1920/1080?image=6","permalink":"/blog/2023-09-02-data-analytics-step-by-step/","series":null,"tags":["Data Analytics"],"title":"Data Analytics  - Nghá» Má»›i Thá»i ThÆ°á»£ng"},{"categories":null,"content":" I. Äáº·t váº¥n Ä‘á» II. CÃ¡ch thá»©c thá»±c hiá»‡n III. CÃ¡ch tiáº¿p cáº­n Store Capacity Clustering Store Attribute Clustering Category Sales Clustering Productivity-based Clustering Price-based Clustering Multi-dimensional clustering IV. Má»™t sá»‘ vÃ­ dá»¥ thá»±c tiá»…n Tá»± thiáº¿t láº­p phÃ¢n khÃºc giÃ¡. Láº­p káº¿ hoáº¡ch phÃ¡t tá» rÆ¡i quáº£ng cÃ¡o BÃ i toÃ¡n tÃ i xáº¿ giao hÃ ng grab BÃ i viáº¿t nÃ y lÃ  gÃ³c nhÃ¬n cá»§a má»™t Ã´ng IT Ä‘ang táº­p tÃ nh Data Driven Development, viáº¿t note láº¡i chÆ¡i chÆ¡i dá»±a vÃ o cÃ¡c tÃ i liá»‡u Ä‘á»c Ä‘Æ°á»£c vÃ o tá»« khoÃ¡ store clustering retail, viáº¿t báº­y viáº¿t báº¡, cÃ¡c báº¡n cÃ³ Ã½ tÆ°á»Ÿng hay ho cÃ³ thá»ƒ gÃ³p Ã½ giÃºp mÃ¬nh cÃ³ thÃªm nhiá»u gÃ³c nhÃ¬n hÆ¡n nha.\nI. Äáº·t váº¥n Ä‘á» Trong mÃ´ hÃ¬nh kinh doanh bÃ¡n láº», cÃ³ hai mÃ´ hÃ¬nh dáº¡ng chuá»—i cá»­a hÃ ng khÃ¡c nhau, má»—i mÃ´ hÃ¬nh Ä‘á»u cÃ³ Æ°u vÃ  nhÆ°á»£c Ä‘iá»ƒm riÃªng:\nDáº¡ng chuá»—i mÃ  táº¥t cáº£ cÃ¡c cá»­a hÃ ng giá»‘ng há»‡t nhau ( vÃ­ dá»¥ Starbucks), dáº¡ng chuá»—i nÃ y thÃ¬ viá»‡c váº­n hÃ nh Ä‘Æ¡n giáº£n, theo quy trÃ¬nh cÃ³ sáºµn, Ä‘á»“ng nháº¥t, nháº¥t quÃ¡n, mang láº¡i tráº£i nghiá»‡m xuyÃªn suá»‘t vá»›i khÃ¡ch hÃ ng. Háº§u nhÆ° lÃ  quáº£n lÃ½ khÃ¡ nhÃ n.\nDáº¡ng chuá»—i thá»© 2, cÃ¡c Quáº£n lÃ½ Ä‘Æ°á»£c xem nhÆ° lÃ  Ã´ng chá»§ nhá» cá»§a cá»­a hÃ ng, cÃ³ quyá»n tá»± quyáº¿t trong viá»‡c phÃ¢n loáº¡i, Ä‘á»‹nh giÃ¡, vÃ  khuyáº¿n mÃ£i. VÃ­ dá»¥: cÃ¡c nhÃ  bÃ¡n láº» nhÆ° Táº­p Ä‘oÃ n Aeon , ICA, Metro, hoáº·c bÃ¡ch hoÃ¡ xanh cá»§a Viá»‡t Nam trao khÃ¡ nhiá»u quyá»n kiá»ƒm soÃ¡t cho cÃ¡c quáº£n lÃ½ cá»­a hÃ ng.\nDÃ¹ mÃ´ hÃ¬nh kinh doanh lÃ  dáº¡ng 1 hay dáº¡ng 2, thÃ¬ viá»‡c nhÃ³m cÃ¡c siÃªu thá»‹ cÃ³ tÃ­nh cháº¥t tÆ°Æ¡ng Ä‘á»“ng thÃ nh cÃ¡c nhÃ³m Ä‘á»“ng nháº¥t vá»›i nhau vá» cÃ¡c khÃ­a cáº¡nh nÃ o Ä‘Ã³ ( trong machine learning gá»i lÃ  gom cá»¥m), cÅ©ng giÃºp cho ngÆ°á»i Ä‘iá»u hÃ nh cÃ³ thá»ƒ scale Ä‘Æ°á»£c cÃ¡c chiáº¿n lÆ°á»£c marketing, sá»­ dá»¥ng cÃ¡ch tiáº¿p cáº­n cookie-cutter (( tá»« khoÃ¡ cookie cutter approach in business) Ä‘áº¡i loáº¡i lÃ  náº¿u 1 mÃ´ hÃ¬nh marketing thÃ nh cÃ´ng cho cá»­a hÃ ng A, thÃ¬ cÅ©ng cÃ³ thá»ƒ scale out vÃ  thÃ nh cÃ´ng á»Ÿ cÃ¡c cá»­a hÃ ng A1.. An cÃ³ cÃ¹ng cá»¥m vá»›i cá»­a hÃ ng A.) , cÃ¡ch tiáº¿p cáº­n nÃ y cÅ©ng cÃ³ thá»ƒ Ã¡p dá»¥ng vá»›i mÃ´ hÃ¬nh kinh doanh nhÆ°á»£ng quyá»n (franchisee).\nII. CÃ¡ch thá»©c thá»±c hiá»‡n KhÃ¡i niá»‡m phÃ¢n loáº¡i cá»­a hÃ ng khÃ´ng má»›i, nhÆ°ng cÃ³ ráº¥t Ã­t nhÃ  bÃ¡n láº» á»Ÿ cÃ¡c thá»‹ trÆ°á»ng nhá» sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng thá»©c khoa há»c Ä‘á»ƒ táº¡o mÃ´ hÃ¬nh. VÃ  ráº¥t ráº¥t Ã­t nhÃ  bÃ¡n láº» há»‡ thá»‘ng hoÃ¡ quy trÃ¬nh phÃ¢n loáº¡i | gom cá»¥m, cÃ³ thá»ƒ lÃ  lÃ½ do tÃ i chÃ­nh khÃ´ng cho phÃ©p, hoáº·c viá»‡c thuÃª Ä‘Æ¡n vá»‹ tÆ° váº¥n Ä‘á»™c láº­p khÃ¡ tá»‘n kÃ©m. MÃ´ hÃ¬nh mÃ¬nh Ä‘á» cáº­p tá»›i á»Ÿ Ä‘Ã¢y lÃ : Data Science láº­p phÃ¢n tÃ­ch, Business kiá»ƒm chá»©ng, vÃ  cáº§n cÃ³ sá»± thÃ´ng suá»‘t vá» máº·t data giá»¯a Data Science vÃ  Business.\nCÃ¡c yáº¿u tá»‘ tham chiáº¿u chÃ­nh:\n% bÃ¡n hÃ ng trÃªn deal vá»›i nhÃ  cung cáº¥p\n% tá»· lá»‡ bÃ¡n hÃ ng há»—n há»£p há»£p(category mix) \u0026hellip;\nCÃ¡c yáº¿u tá»‘ tham chiáº¿u bá»• sung bÃªn cáº¡nh Ä‘Ã³:\nSá»± hiá»‡n diá»‡n cá»§a Ä‘á»‘i thá»§\nVá»‹ trÃ­ Ä‘á»‹a lÃ½\nNhÃ¢n kháº©u há»c \u0026hellip;\ná» Ä‘Ã¢y, mÃ¬nh chá»‰ liá»‡t kÃª má»™t vÃ i yáº¿u tá»‘, má»™t vÃ i yáº¿u tá»‘ chi tiáº¿t Ä‘Æ°á»£c liá»‡t kÃª á»Ÿ pháº§n tiáº¿p theo.\nCÃ¡c yáº¿u tá»‘ tham chiáº¿u bá»• sung sáº½ giÃºp chÃºng ta phÃ¢n biá»‡t cÃ¡c cá»¥m rÃµ rÃ ng hÆ¡n vÃ  nhÃ¬n tháº¥y sá»± khÃ¡c nhau giá»¯a cÃ¡c cá»¥m Ä‘Ã³.\ntheo solvoyo.com, ngÃ y nay, ngÆ°á»i ta thÆ°á»ng phÃ¢n loáº¡i theo category level thay vÃ¬ store level. Category level máº¡ng láº¡i sá»± chÃ­nh xÃ¡c cao hÆ¡n, nhÆ°ng khi thá»±c hiá»‡n láº¡i phá»©c táº¡p hÆ¡n\nSau Ä‘Ã³, chÃºng ta sáº½ xÃ¢y dá»±ng model dá»±a trÃªn cÃ¡c yáº¿u tá»‘ trÃªn, vÃ  kiá»ƒm chá»©ng model. CÃ³ má»™t vÃ i mÃ´ hÃ¬nh clustering trong machine learning cÃ¡c báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng nhÆ° KNN, SVC, DBScan, kmean \u0026hellip;\nThÃ´ng qua viá»‡c sá»­ dá»¥ng phÃ¢n cá»¥m, cÃ¡c nhÃ  bÃ¡n láº» cÃ³ thá»ƒ sá»‘ hoÃ¡ nhu cáº§u cá»§a tá»«ng khu vá»±c vÃ  Ä‘á» ra nhá»¯ng phÆ°Æ¡ng Ã¡n váº­n hÃ nh (má»›i) hiá»‡u quáº£ hÆ¡n (táº¥t nhiÃªn, Ä‘Ã¢y má»›i chá»‰ lÃ  pháº§n lÃ½ thuyáº¿t, cáº§n thá»­ nghiá»‡m Ä‘á»ƒ chá»©ng minh tÃ­nh Ä‘Ãºng Ä‘áº¯n xem ráº±ng cÃ¡c cá»¥m chÃºng ta Ä‘á» xuáº¥t cÃ³ tháº­t sá»± liÃªn quan máº¡nh vá»›i nhau hay khÃ´ng, hay cÃ²n yáº¿u tá»‘ áº©n quan trá»ng nÃ o Ä‘Ã³ mÃ  chÃºng ta Ä‘Ã£ bá» lá»¡ trong quÃ¡ trÃ¬nh thu tháº­p dá»¯ liá»‡u).\nVÃ­ dá»¥: má»™t chuá»—i cá»­a hÃ ng tiá»‡n lá»£i cÃ³ thá»ƒ Ä‘iá»u chá»‰nh cÃ¡ch tiáº¿p cáº­n khÃ¡ch hÃ ng báº±ng cÃ¡ch bÃ¡n hÃ ng theo giá» hÃ ng, chia thÃ nh gÃ³i giá» hÃ ng buá»•i sÃ¡ng, giá» hÃ ng buá»•i trÆ°a, giá» hÃ ng buá»•i tá»‘i, phÃ¹ há»£p vá»›i má»¥c tiÃªu mua sáº¯m vÃ  vá»‹ trÃ­ cá»§a khÃ¡ch hÃ ng.\nVÃ­ dá»¥ khÃ¡c: Cá»­a hÃ ng cÃ  phÃª má»›i, cá»­a hÃ ng bÃ¡nh ngá»t má»›i, cá»­a hÃ ng phá»Ÿ má»›i, á»Ÿ gáº§n vá»‹ trÃ­ Ä‘á»‹a lÃ½, kÃ­ch thÆ°á»›c gáº§n giá»‘ng nhau, nhÆ°ng triá»ƒn vá»ng phÃ¡t triá»ƒn cÃ³ thá»ƒ sáº½ khÃ¡c nhau, do triá»ƒn vá»ng phÃ¡t triá»ƒn cá»§a thá»±c pháº©m mang Ä‘i khÃ¡c hoÃ n toÃ n vá»›i thá»±c pháº©m Äƒn táº¡i chá»—.\nViá»‡c phÃ¢n cá»¥m cá»­a hÃ ng lÃ  bÆ°á»›c Ä‘áº§u giÃºp cho cÃ¡c nhÃ  quáº£n lÃ½ cÃ³ má»™t bá»©c tranh Æ°á»›m chá»«ng khi Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh, vÃ  giÃºp há» Ä‘Æ°a ra káº¿t luáº­n má»™t cÃ¡ch Ä‘á»‹nh lÆ°á»£ng hÆ¡n.\nIII. CÃ¡ch tiáº¿p cáº­n Store Capacity Clustering Net selling space ( Ä‘o lÆ°á»£ng trÃªn Ä‘Æ¡n vá»‹ mÃ©t vuÃ´ng)\nShelf capacity ( Ä‘o lÆ°á»£ng trÃªn Ä‘Æ¡n vá»‹ sá»‘ lÆ°á»£ng sáº£n pháº©m / Ä‘Æ¡n vá»‹ chuáº©n (ká»‡))\nOption capacity ( sá»‘ lÆ°á»£ng sku trÃªn má»—i cá»­a hÃ ng cÃ³ thá»ƒ Ä‘Æ°á»£c trÆ°ng bÃ y táº¡i 1 thá»i Ä‘iá»ƒm)\nUnit capacity ( Sá»‘ lÆ°á»£ng sáº£n pháº©m cÃ³ thá»ƒ trÆ°ng bÃ y táº¡i 1 thá»i Ä‘iá»ƒm)\nStore Attribute Clustering LÆ°á»£t khÃ¡ch trung bÃ¬nh cá»§a cá»­a hÃ ng\nVá»‹ trÃ­ ( Ä‘á»™ thá»‹, nÃ´ng thÃ´n, khu cÃ´ng nghiá»‡p, khu cháº¿ xuáº¥t, khu xÃ¢y dá»±ng má»›i)\nIncome profiles\nCultural profiles ( xÃ©t trÃªn khÃ¡ch hÃ ng trung thÃ nh, vÃ­ dá»¥ nhÆ° dÃ¢n tá»™c)\nMall type ( Ä‘áº¡i siÃªu thá»‹, cá»­a hÃ ng nhá»)\n\u0026hellip;\nCategory Sales Clustering Weekly unit sales\nWeekly revenue\nInventory turn (dá»±a trÃªn yáº¿u tá»‘ bao lÃ¢u hÃ ng vá» má»™t láº§n)\nProductivity-based Clustering Revenue per square meter (or sq. foot)\nGM per square meter\nUnit sales per product (option, or SKU)\nPrice-based Clustering Average unit retail\nPrice profile performance (dá»±a trÃªn sá»± Ä‘Ã³ng gÃ³p cá»§a doanh sá»‘ bÃ¡n hÃ ng tá»« cÃ¡c phÃ¢n khÃºc giÃ¡ khÃ¡c nhau nhÆ° cao, trung bÃ¬nh, tháº¥p hoáº·c dá»±a trÃªn sá»± Ä‘Ã³ng gÃ³p cá»§a doanh sá»‘ giáº£m giÃ¡ vÃ  bÃ¡n hÃ ng nguyÃªn giÃ¡)\nPrice elasticity (dá»±a trÃªn sá»± thay Ä‘á»•i vá» nhu cáº§u Ä‘á»ƒ Ä‘Ã¡p á»©ng vá»›i nhá»¯ng thay Ä‘á»•i vá» giÃ¡, thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c há»‡ thá»‘ng láº­p káº¿ hoáº¡ch khuyáº¿n mÃ£i vÃ  tá»‘i Æ°u hÃ³a giáº£m giÃ¡)\nMulti-dimensional clustering ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p nhÃ³m cÃ¡c cá»­a hÃ ng dá»±a trÃªn cÃ¡c metric vÃ  cÃ¡c attributes Ä‘Æ°á»£c Ä‘á» cáº­p á»Ÿ phÃ­a trÃªn.\nVÃ­ dá»¥, vá»›i má»—i category cá»§a cá»­a hÃ ng, cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n cá»¥m dá»±a vÃ o sale performance, capacity, price performance\nIV. Má»™t sá»‘ vÃ­ dá»¥ thá»±c tiá»…n Tá»± thiáº¿t láº­p phÃ¢n khÃºc giÃ¡. CÃ¡c nÆ¡i cÃ³ tá»· lá»‡ khÃ¡ch hÃ ng mua má»™t láº§n cao thÆ°á»ng sáº½ thiáº¿t láº­p má»™t má»©c giÃ¡ cao hÆ¡n nhá»¯ng nÆ¡i cÃ³ tá»· lá»‡ khÃ¡ch hÃ ng trung thÃ nh cao. VÃ­ dá»¥:\nCÃ¡c website hÃ£ng\nSáº£n pháº©m Ä‘Æ°á»£c bÃ¡n á»Ÿ sÃ¢n bay so vá»›i bÃ¡n á»Ÿ cÃ¡c cá»­a hÃ ng xung quanh nÆ¡i báº¡n sinh sá»‘ng.\nTáº¥t nhiÃªn, sáº½ cÃ³ nhiá»u báº¡n sáº½ cáº£i láº¡i ráº±ng giÃ¡ á»Ÿ sÃ¢n bay cao do cÃ¡c chi phÃ­ thuÃª nhÃ¢n viÃªn, chi phÃ­ máº·t báº±ng, chi phÃ­ tá»« abc Ä‘áº¿n xyz cao \u0026hellip;\nViá»‡c phÃ¢n cá»¥m, Ä‘á»‹nh danh cÃ¡c nhÃ³m cá»­a hÃ ng cÃ³ Ä‘áº·c Ä‘iá»ƒm riÃªng biá»‡t nhÆ° trÃªn, vÃ­ dá»¥ nhÆ° cá»­a hÃ ng liá»n ká» khu du lá»‹ch, sáº½ giÃºp cÃ¡c báº¡n cÃ³ gÃ³c nhÃ¬n khoa há»c hÆ¡n vÃ o quy hoáº¡ch phÃ¢n vÃ¹ng giÃ¡ hoáº·c quy trÃ¬nh bÃ¡n hÃ ng.\nLáº­p káº¿ hoáº¡ch phÃ¡t tá» rÆ¡i quáº£ng cÃ¡o Tá»‘i Æ°u hoÃ¡ chi phÃ­ in áº¥n\nÄa dáº¡ng hoÃ¡ tá» rÆ¡i\nDá»± Ä‘oÃ¡n Ä‘Æ°á»£c tá»· lá»‡ mua hÃ ng , Ä‘á» ra chiáº¿n lÆ°á»£c mua bÃ¡n há»£p lÃ½ hÆ¡n.\nBÃ i toÃ¡n tÃ i xáº¿ giao hÃ ng grab Trong báº¥t ká»³ sá»± thay Ä‘á»•i nÃ o vá» máº·t váº­n hÃ nh vÃ  quáº£n lÃ½, chÃºng ta nÃªn Ä‘o lÆ°á»ng sá»± tÄƒng trÆ°á»Ÿng vÃ  kiá»ƒm Ä‘á»‹nh láº¡i Ä‘á»ƒ chá»©ng minh giÃ¡ trá»‹ thay Ä‘á»•i lÃ  Ä‘Ãºng Ä‘áº¯n vÃ  há»— trá»£ tá»‘t cho viá»‡c triá»ƒn khai ra quy mÃ´ lá»›n.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\nTÃ i liá»‡u tham kháº£o\nhttps://analyticsindiamag.com/analytics-driven-store-clustering-sales-and-profits-retail/\nhttps://www.solvoyo.com/whitepapers/approaches-to-retail-store-clustering/\nhttps://www.davinciretail.com/resources/what-is-retail-store-clustering\nhttps://www.forbes.com/sites/forbestechcouncil/2022/04/20/clustering-the-new-world-of-retail-product-segmentation\n","date":"Jul 29, 2023","img":"https://unsplash.it/1920/1080?image=7","permalink":"/blog/2023-07-29-store-clustering/","series":null,"tags":["Retail"],"title":"PhÃ¢n Cá»¥m Cá»­a HÃ ng Äá»ƒ ÄÆ°a Ra Quyáº¿t Äá»‹nh ThÃ´ng Minh HÆ¡n - LÃ½ Thuyáº¿t"},{"categories":null,"content":" Äáº·t váº¥n Ä‘á» Má»Ÿ bÃ i Project lÃ  gÃ¬ Product lÃ  gÃ¬ 1. Má»™t sá»‘ hÆ°á»›ng dáº«n Ä‘á»ƒ chuyá»ƒn tÆ° duy tá»« project mindset sang product mindset 1.1 Táº¡o ra cÃ¡c team sáº£n pháº©m nhá» 1.2 ÄÃ³n nháº­n sá»± thay Ä‘á»•i vÃ  cháº¥p nháº­n sá»± thÃ­ch nghi 1.3 Äá»«ng dÃ­ dealine 1.4 Äá»«ng cá»‘ gáº¯ng báº¥u vÃ­u vÃ o Ã½ tÆ°á»Ÿng Ä‘áº§u tiÃªn 1.5 Cá»‘ gáº¯ng gáº¯ng káº¿t roadmap vá»›i mindset 2. Má»™t sá»‘ kinh nghiá»‡m vá» product mindset 2.1 Trao giÃ¡ trá»‹, khÃ´ng trao tÃ­nh nÄƒng 2.2 PhÃ¡t triá»ƒn sáº£n pháº©m dá»±a trÃªn dá»¯ liá»‡u (Data Driven development) 2.3 Táº­p trung vÃ o sáº£n pháº©m PhÃ¡t triá»ƒn UX 2.4 Minimum Viable Product CÃ¡c xÃ¡c Ä‘á»‹nh Minimum Viable Product VÃ­ dá»¥ cÃ¡c cÃ´ng ty khá»Ÿi nghiá»‡p vá»›i Minimum Viable Product Airbnb Foursquare TÃ i liá»‡u tham kháº£o Äáº·t váº¥n Ä‘á» CÃ³ bao giá» báº¡n gáº·p má»™t trong cÃ¡c trÆ°á»ng há»£p sau Ä‘Ã¢y:\nBáº¡n release má»™t sáº£n pháº©m ra thá»‹ trÆ°á»ng vÃ  nÃ³ Ä‘Ã£ lá»—i thá»i lÃºc báº¡n release\nBáº¡n release má»™t sáº£n pháº©m, vÃ  ngÆ°á»i dÃ¹ng khÃ´ng thÃ¨m sá»­ dá»¥ng.\nNáº¿u báº¡n gáº·p váº¥n Ä‘á» trÃªn, hÃ£y há»c bÃ i viáº¿t nÃ y, náº¿u khÃ´ng báº¡n hÃ£y Ä‘á»c cÃ¡c bÃ i viáº¿t khÃ¡c trong website cá»§a mÃ¬nh www.phamduytung.com\nLÆ°u Ã½ nhá»: ÄÃ¢y lÃ  mindset, khÃ´ng pháº£i lÃ  toolset, nÃªn chÃºng ta cáº§n thá»±c hÃ nh nÃ³, cáº§n sá»± tráº£i nghiá»‡m trong cÃ¢u \u0026ldquo;kiáº¿n thá»©c, kinh nghiá»‡m, tráº£i nghiá»‡m\u0026rdquo; thÃ¬ má»›i tháº¥m dáº§n dáº§n Ä‘Æ°á»£c. Táº¡i thá»i Ä‘iá»ƒm viáº¿t bÃ i viáº¿t nÃ y, mÃ¬nh chá»‰ cÃ³ má»™t xÃ­u xÃ­u tráº£i nghiá»‡m nhÆ° váº­y, cÃ³ thá»ƒ qua vÃ i nÄƒm ná»¯a, tráº£i nghiá»‡m cá»§a mÃ¬nh sáº½ khÃ¡c Ä‘i, vÃ  mÃ¬nh sáº½ viáº¿t bÃ i viáº¿t khÃ¡c Ä‘á»ƒ cáº­p nháº­t sá»± tráº£i nghiá»‡m cá»§a mÃ¬nh.\nMá»Ÿ bÃ i Tá»« trÆ°á»›c tá»›i nay, chÃºng ta thÆ°á»ng vÃ´ tÃ¬nh bá»‹ Ä‘Ã³ng trong cÃ¡i khung tÆ° duy project, Ä‘áº·c biá»‡t lÃ  cÃ¡c báº¡n trÆ°á»Ÿng thÃ nh tá»« freelancer. Háº§u háº¿t chÃºng ta lÃ  \u0026ldquo;lÃ­nh Ä‘Ã¡nh thuÃª\u0026rdquo;, vá»›i kiá»ƒu lÃ m dá»± Ã¡n A trong vÃ²ng 3 thÃ¡ng, xong , lá»¥m tiá»n. Nháº£y vÃ o dá»± Ã¡n B, lÃ m, lá»¥m tiá»n. \u0026hellip; cho Ä‘áº¿n khi báº¡n ra ngoÃ i khá»Ÿi nghiá»‡p vá»›i má»™t Ã½ tÆ°á»Ÿng hay ho nÃ o Ä‘Ã³, hoáº·c báº¡n vÃ o cÃ´ng ty product lÃ m chá»‰ Ä‘Ãºng 1 product.\nProject lÃ  gÃ¬ CÃ¡c dá»± Ã¡n, theo Ä‘á»‹nh nghÄ©a, lÃ  nhá»¯ng ná»— lá»±c táº¡m thá»i. Má»™t táº­p há»£p cÃ¡c cÃ¡ nhÃ¢n vÃ  tá»• chá»©c Ä‘áº£m nháº­n cÃ¡c nhiá»‡m vá»¥ cáº§n thiáº¿t Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»™t má»¥c tiÃªu cá»¥ thá»ƒ. CÃ³ má»™t lá»‹ch trÃ¬nh, ngÃ¢n sÃ¡ch, Ä‘iá»ƒm khá»Ÿi Ä‘áº§u vÃ  Ä‘iá»ƒm cuá»‘i. Tiáº¿n Ä‘á»™ cá»§a dá»± Ã¡n Ä‘Æ°á»£c Ä‘o lÆ°á»ng vÃ  káº¿t thÃºc sau khi Ä‘áº¡t Ä‘Æ°á»£c cÃ¡c má»¥c tiÃªu vÃ  cá»™t má»‘c Ä‘á»‹nh trÆ°á»›c.\nNÃ³i tÃ³m láº¡i, má»™t dá»± Ã¡n báº¯t Ä‘áº§u vá»›i má»™t káº¿t luáº­n Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh rÃµ rÃ ng vÃ  Ä‘Æ°á»£c hiá»ƒu rÃµ. Tá»« Ä‘Ã³, nhÃ³m pháº¥n Ä‘áº¥u Ä‘á»ƒ trÃ¡nh Ä‘i chá»‡ch khá»i káº¿ hoáº¡ch hoáº·c lá»‹ch trÃ¬nh. CÃ¡c bÃªn liÃªn quan biáº¿t Ä‘iá»u gÃ¬ sáº½ xáº£y ra, khi nÃ o vÃ  chi phÃ­ bao nhiÃªu.\nProduct lÃ  gÃ¬ Sáº£n pháº©m lÃ  má»‘i quan tÃ¢m liÃªn tá»¥c. Má»¥c tiÃªu cá»§a sáº£n pháº©m khÃ´ng pháº£i lÃ  khi nÃ o nÃ³ káº¿t thÃºc. CÃ¡c tá»• chá»©c sáº½ sá»­ dá»¥ng nghiá»‡p vá»± tá»‘i Æ°u hoÃ¡ cá»§a mÃ¬nh Ä‘á»ƒ cá»±c Ä‘áº¡i hoÃ¡ lá»£i nhuáº­n vÃ  cÃ¡c KPIs liÃªn quan, báº±ng cÃ¡ch phÃ¢n tÃ­ch má»©c Ä‘á»™ sá»­ dá»¥ng (usage), sá»± tÄƒng trÆ°á»Ÿng (growth), vÃ  sá»± trung thÃ nh cá»§a ngÆ°á»i dÃ¹ng (loyalty)\nMá»™t sáº£n pháº©m má»›i cÃ³ thá»ƒ lÃ  káº¿t quáº£ cá»§a má»™t dá»± Ã¡n hoáº·c nhiá»u dá»± Ã¡n, nhÆ°ng sau khi sáº£n pháº©m Ä‘Æ°á»£c giá»›i thiá»‡u, váº«n cÃ³ nhiá»u cáº£i tiáº¿n vÃ  cáº­p nháº­t láº·p Ä‘i láº·p láº¡i. CÃ´ng viá»‡c cá»§a nhÃ³m sáº£n pháº©m sáº½ khÃ´ng bao giá» káº¿t thÃºc chá»«ng nÃ o sáº£n pháº©m váº«n cÃ²n trÃªn thá»‹ trÆ°á»ng.\nTÃ³m láº¡i, cÃ¡c sáº£n pháº©m liÃªn tá»¥c phÃ¡t triá»ƒn dá»±a trÃªn cÃ¡c bÃ i há»c, pháº£n há»“i, sá»± thay Ä‘á»•i cá»§a thá»‹ trÆ°á»ng Â° vÃ  cÃ¡c nguyÃªn táº¯c cÆ¡ báº£n vá» tÃ i chÃ­nh Â°Â° (financial fundamentals). LuÃ´n cÃ³ chá»— Ä‘á»ƒ cáº£i tiáº¿n, nÃ¢ng cao vÃ  má»Ÿ rá»™ng sang cÃ¡c thá»‹ trÆ°á»ng vÃ  trÆ°á»ng há»£p sá»­ dá»¥ng má»›i.\nÂ° VÃ­ dá»¥ nhÆ° covid áº­p tá»›i, chÃºng ta pháº£i lÃ m gÃ¬\nÂ°Â° VÃ­ dá»¥ nhÆ° thuáº¿ gtgt giáº£m tá»« 10% xuá»‘ng 8%\nÄá»‘i vá»›i cÃ¡c nhÃ³m khá»Ÿi nghiá»‡p, sáº£n pháº©m hiáº¿m khi nÃ o hoÃ n thÃ nh ngay láº­p tá»©c ( trá»« má»™t sá»‘ trÆ°á»ng há»£p Ä‘áº·c biá»‡t). Háº§u háº¿t chÃºng ta thÆ°á»ng Ä‘Æ°a ra thá»‹ trÆ°á»ng má»™t báº£n thÄƒm dÃ² thá»‹ trÆ°á»ng (cÃ³ thá»ƒ cÃ³ 1 hoáº·c nhiá»u phrases, má»—i pharse sáº½ hoÃ n thiá»‡n má»™t tÃ­nh nÄƒng nÃ o Ä‘Ã³) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡.\n1. Má»™t sá»‘ hÆ°á»›ng dáº«n Ä‘á»ƒ chuyá»ƒn tÆ° duy tá»« project mindset sang product mindset 1.1 Táº¡o ra cÃ¡c team sáº£n pháº©m nhá» Náº¿u team member lÃ  coder , thua. ChÃºng ta Ä‘á»u cÃ³ chÃ­nh kiáº¿n, Ä‘á»u cÃ³ niá»m tá»± hÃ o, Ä‘á»u cÃ³ suy nghÄ© , Ä‘á»u cÃ³ Ã½ tÆ°á»Ÿng | giáº£i phÃ¡p \u0026ldquo;Ä‘iÃªn rá»“\u0026rdquo; cho má»™t váº¥n Ä‘á» nÃ o Ä‘Ã³.\nCÃ³ má»™t táº§ng nhu cáº§u trong thÃ¡p nhu cáº§u maslow gáº¯ng liá»n sÃ¢u xa vá»›i cÃ¡i nÃ y, mÃ¬nh cáº£m tháº¥y váº­y.\n1.2 ÄÃ³n nháº­n sá»± thay Ä‘á»•i vÃ  cháº¥p nháº­n sá»± thÃ­ch nghi TÆ° duy sáº£n pháº©m báº¯t nguá»“n tá»« viá»‡c táº¡o ra tráº£i nghiá»‡m Ä‘á»™c Ä‘Ã¡o cho ngÆ°á»i dÃ¹ng dá»±a trÃªn viá»‡c há»c há»i vÃ  pháº£n há»“i. Äá»ƒ thÃºc Ä‘áº©y mÃ´i trÆ°á»ng nÃ y, nhÃ³m pháº£i luÃ´n cá»Ÿi má»Ÿ Ä‘á»ƒ thÆ°á»ng xuyÃªn Ä‘iá»u chá»‰nh káº¿ hoáº¡ch\u0026hellip; vÃ  Ä‘Ã´i khi loáº¡i bá» chÃºng hoÃ n toÃ n.\n1.3 Äá»«ng dÃ­ dealine Ãp lá»±c táº¡o ra kim cÆ°Æ¡ng, táº¡o ra sá»± Ä‘á»™t phÃ¡ hay Ã¡p lá»±c táº¡o nÃªn tÃ¢m lÃ½ sá»£ hÃ£i, cuá»™c sá»‘ng báº¿ táº¯c, chÃ¡n náº£n, sá»£ ngÃ y chá»§ nháº­t, sá»£ ngÃ y X pháº£i release sáº£n pháº©m \u0026hellip;.\nTuá»³\n1.4 Äá»«ng cá»‘ gáº¯ng báº¥u vÃ­u vÃ o Ã½ tÆ°á»Ÿng Ä‘áº§u tiÃªn TÆ° duy cá»§a product lÃ  tÆ° duy má»Ÿ, Ä‘Ã³n nháº­n nhá»¯ng sá»± thay Ä‘á»•i má»™t cÃ¡ch liÃªn tá»¥c, cho nÃªn sáº£n pháº©m khi hoÃ n thÃ nh Ä‘áº¿n tay ngÆ°á»i dÃ¹ng nÃ³ cÃ³ thá»ƒ Ä‘i xa má»™t váº¡n tÃ¡m ngÃ n dáº·m so vá»›i Ã½ tÆ°á»Ÿng ban Ä‘áº§u cá»§a mÃ¬nh rá»“i.\n1.5 Cá»‘ gáº¯ng gáº¯ng káº¿t roadmap vá»›i mindset CÃ³ má»™t thá»© gá»i lÃ  Theme-Based Roadmap Ä‘Æ°á»£c sá»­ dá»¥ng trong tÆ° duy product. NÃ³ sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ thay tháº¿ cho feature roadmap\n2. Má»™t sá»‘ kinh nghiá»‡m vá» product mindset 2.1 Trao giÃ¡ trá»‹, khÃ´ng trao tÃ­nh nÄƒng Háº§u háº¿t, ngÆ°á»i dÃ¹ng khÃ´ng cáº§n tá»›i nhá»¯ng tÃ­nh nÄƒng, há» cáº§n nhá»¯ng thá»© mÃ  cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» cá»§a há». ChÃºng ta cáº§n thá»±c sá»± hiá»ƒu Ä‘Æ°á»£c giÃ¡ trá»‹ thá»±c sá»± mÃ  nhá»¯ng thá»© chÃºng ta lÃ m ra sáº½ mang láº¡i gÃ¬ cho ngÆ°á»i dÃ¹ng, lÃºc Ä‘Ã³, team sáº½ thá»±c sá»± hiá»ƒu táº¡i sao cáº§n pháº£i lÃ m nÃ³ vÃ  Ä‘Ã³ má»›i lÃ  sáº£n pháº©m cÃ³ Ã­ch.\nÄá»ƒ trao Ä‘Æ°á»£c cÃ¡c giÃ¡ trá»‹ cÃ³ Ã­ch, team member cáº§n biáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» lÃ  gÃ¬. BA hoáº·c PO hoáº·c PM pháº£i hiá»ƒu Ä‘Æ°á»£c viá»‡c cáº§n lÃ m mang láº¡i giÃ¡ trá»‹ gÃ¬. Dev cÅ©ng cáº§n hiá»ƒu \u0026ldquo;váº¥n Ä‘á» lÃ  gÃ¬\u0026rdquo; Ä‘á»ƒ Ä‘Æ°a Ä‘Æ°á»£c cÃ¡c láº­p trÃ¬nh phÃ¹ há»£p vÃ  cÃ³ thá»ƒ gÃ³p Ã½ ngÆ°á»£c láº¡i cho BA.\nNáº¿u dev chá»‰ hiá»ƒu tÃ­nh nÄƒng -\u0026gt; BA cá»±c -\u0026gt; DEV yÃªu cáº§u BA mÃ´ táº£ pháº£i tháº­t sá»± rÃµ rÃ ng. (dev lÃºc nÃ y chá»‰ lÃ  Ã´ng coder)\nNáº¿u phÆ°Æ¡ng Ã¡n cá»§a BA khÃ´ng há»£p lÃ½ -\u0026gt; váº¥n Ä‘á» chÆ°a Ä‘Æ°á»£c giáº£i quyáº¿t trá»n váº¹n.\nTam sao tháº¥t báº£n giá»¯ cÃ¡c láº§n trao Ä‘á»•i , tá»« Ä‘á»‘i tÃ¡c =\u0026gt; Sale =\u0026gt; BA =\u0026gt; Dev -\u0026gt; Dev cáº§n cÃ³ máº·t trong cÃ¡c cuá»™c tháº£o luáº­n cá»§a BA vá»›i khÃ¡ch hÃ ng, vá»›i sale (cÃ¡i nÃ y hÆ¡i khÃ³, nháº¥t lÃ  khi lÃ m dá»± Ã¡n vá»›i Ä‘á»‘i tÃ¡c Nháº­t)\nThiáº¿u Ä‘á»‹nh nghÄ©a / mÃ´ táº£ rÃµ rÃ ng vá» viá»‡c hoÃ n thÃ nh tÃ­nh nÄƒng -\u0026gt; bem nhau -\u0026gt; toang.\n2.2 PhÃ¡t triá»ƒn sáº£n pháº©m dá»±a trÃªn dá»¯ liá»‡u (Data Driven development) Data Driven lÃ  má»™t thuáº­t ngá»¯ kinh doanh Ä‘á» cáº­p Ä‘áº¿n viá»‡c sá»­ dá»¥ng dá»¯ liá»‡u Ä‘á»ƒ cung cáº¥p thÃ´ng tin giÃºp báº¡n ra quyáº¿t Ä‘á»‹nh nhanh hÆ¡n. NÃ³i cÃ¡ch khÃ¡c, quyáº¿t Ä‘á»‹nh Ä‘Æ°á»£c Ä‘Æ°a ra vá»›i báº±ng chá»©ng thá»±c nghiá»‡m thá»±c táº¿ chá»© khÃ´ng pháº£i suy Ä‘oÃ¡n hoáº·c kinh nghiá»‡m cÃ¡ nhÃ¢n.\nData driven lÃ  thá»© báº¯t buá»™c pháº£i lÃ m Ä‘á»ƒ cÃ³ thá»ƒ xÃ¢y dá»±ng sáº£n pháº©m thÃ nh cÃ´ng. Má»i thá»© cáº§n Ä‘Æ°á»£c Ä‘o Ä‘áº¡c á»Ÿ táº¥t cáº£ cÃ¡c khÃ¢u, vÃ  lÃ  ná»n táº£ng cá»§a viá»‡c ra quyáº¿t Ä‘á»‹nh.\nViá»‡c Ä‘Ã¡nh giÃ¡ má»™t tÃ­nh nÄƒng cÃ³ hoÃ n thÃ nh hay khÃ´ng cÅ©ng pháº£i dá»±a vÃ o con sá»‘, pháº£i Ä‘á»‹nh lÆ°á»£ng Ä‘Æ°á»£c, khÃ´ng thá»ƒ phan bá»«a phÃ¡n báº­y Ä‘Æ°á»£c. Náº¿u chÃºng ta khÃ´ng Ä‘á»‹nh lÆ°á»£ng Ä‘Æ°á»£c káº¿t quáº£ báº±ng má»™t con sá»‘ cá»¥ thá»ƒ thÃ¬ viá»‡c ta cÃ³ lÃ m hay khÃ´ng lÃ m sáº½ cháº³ng khÃ¡c gÃ¬ nhau cáº£.\nChÃºng ta cáº§n chá»n thang Ä‘o Ä‘á»ƒ Ä‘Ã¡nh giÃ¡, náº¿u chá»n sai thang Ä‘Ã³ thÃ¬ giÃ¡ trá»‹ cá»§a dá»¯ liá»‡u ráº¥t tháº¥p. Thang Ä‘o pháº£i Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ ráº¥t cáº§n tháº­n Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c dá»¯ liá»‡u cÃ³ giÃ¡ trá»‹. Dá»¯ liá»‡u cáº§n Ä‘Æ°á»£c Ä‘áº·t trong má»™t ngá»¯ cáº£nh cá»¥ thá»ƒ thÃ¬ má»›i phÃ¡t huy Ä‘Æ°á»£c háº¿t giÃ¡ trá»‹ cá»§a dá»¯ liá»‡u. CÃ²n náº¿u khÃ´ng cÃ³ ngá»¯ cáº£nh, thÃ¬ dá»¯ liá»‡u Ä‘Ã³ cÅ©ng chá»‰ lÃ  dá»¯ liá»‡u rÃ¡c mÃ  thÃ´i.\nThang Ä‘o nÃ y sáº½ sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ chÃºng ta Ä‘Ã£ thu tháº­p á»Ÿ trÃªn, Ä‘á»ƒ Ä‘Æ°a ra nháº­n xÃ©t.\nVÃ­ dá»¥ kinh Ä‘iá»ƒn: Khi cáº§n dev má»™t sáº£n pháº©m mobile má»›i mang láº¡i giÃ¡ trá»‹ ABCD \u0026hellip; cho khÃ¡ch hÃ ng, team dev bá»‹ vÆ°á»›ng vÃ o bÃ i toÃ¡n, chá»n react-native, hay flutter, hay kortin + swift \u0026hellip;\nÄá»ƒ Ä‘Ã¡nh giÃ¡, chÃºng ta cáº§n pháº£i xÃ¢y dá»±ng má»™t thang Ä‘o dá»±a trÃªn dá»¯ liá»‡u Ä‘á»‹nh lÆ°á»£ng. vÃ­ dá»¥ cÃ´ng nghá»‡ cÃ³ á»•n Ä‘á»‹nh? cÃ³ nhiá»u thÆ° viá»‡n há»— trá»£?, cÃ³ cá»™ng Ä‘á»“ng máº¡nh? cÃ³ group telegram lá»›n hÆ¡n 100 ngÃ n dev , cÃ³ tay to á»Ÿ sau chá»‘ng lÆ°ng, \u0026hellip;.\n2.3 Táº­p trung vÃ o sáº£n pháº©m CÃ¡i khÃ¡c hÃ ng mong muá»‘n lÃ  lÃ  sáº£n pháº©m, lÃ  giÃ¡ trá»‹, khÃ¡ch hÃ ng khÃ´ng quan tÃ¢m cÃ´ng sá»©c chÃºng ta bá» ra lÃ  bao nhiÃªu, chÃºng ta Ä‘Ã£ tá»‘i Æ°u code báº±ng giáº£i thuáº­t nÃ y giáº£i thuáº­t ná», chÃºng ta sá»­ dá»¥ng cÃ´ng nghá»‡ A, cÃ´ng nghá»‡ B,\u0026hellip; háº§m bÃ  láº±ng.\nNÃ³i má»™t cÃ¡ch hÆ¡i phÅ©, cÃ´ng nghá»‡ cÃ³ tá»‘t tá»›i má»©c nÃ o mÃ  khÃ´ng giáº£i quyáº¿t dÆ°á»£c váº¥n Ä‘á» cá»§a khÃ¡ch hÃ ng thÃ¬ nÃ³ lÃ  vÃ´ nghÄ©a. Báº£n thÃ¢n mÃ¬nh cÅ©ng hay bá»‹ chÃº tÃ¢m quÃ¡ má»©c vÃ o cÃ´ng nghá»‡, kÃ©o dá»¯ liá»‡u, kÃ©o source code vá» Ä‘á»ƒ thá»­ tÃ­nh nÄƒng nÃ y , chá»©c nÄƒng kia, bla, bla, bla, mÃ  khÃ´ng nháº­n thá»©c ráº±ng nÃ³ khÃ´ng pháº£i lÃ  má»‘i quan tÃ¢m Ä‘áº§u tiÃªn. á» Ä‘Ã¢y mÃ¬nh cáº§n má»Ÿ ngoáº·c má»™t chÃºt lÃ  náº¿u cÃ´ng nghá»‡ Ä‘Æ°a ra mÃ  táº¡o ra giÃ¡ trá»‹ lá»›n thÃ¬ lÃºc nÃ o cÅ©ng Ä‘Æ°á»£c welcome.\nPhÃ¡t triá»ƒn UX Má»™t sáº£n pháº©m tá»‘t mÃ  cÃ³ UX tá»“i thÃ¬ cÅ©ng khÃ³ cÃ³ kháº£ nÄƒng lÃ´i kÃ©o, giá»¯ chÃ¢n khÃ¡ch hÃ ng, cÃ¡i nÃ y Ä‘á»ƒ láº¡i cho cÃ¡c báº¡n tráº£i nghiá»‡m Ä‘á»ƒ má»i Ã´ng Designer vÃ o :)\n2.4 Minimum Viable Product Minimum Viable Product MVP, lÃ  má»™t sáº£n pháº©m cÃ³ Ä‘á»§ tÃ­nh nÄƒng Ä‘á»ƒ thu hÃºt khÃ¡ch hÃ ng cháº¥p nháº­n sá»›m vÃ  xÃ¡c nháº­n Ã½ tÆ°á»Ÿng sáº£n pháº©m sá»›m trong chu ká»³ phÃ¡t triá»ƒn sáº£n pháº©m. Trong cÃ¡c ngÃ nh cÃ´ng nghiá»‡p nhÆ° pháº§n má»m, MVP cÃ³ thá»ƒ giÃºp nhÃ³m sáº£n pháº©m nháº­n Ä‘Æ°á»£c pháº£n há»“i cá»§a ngÆ°á»i dÃ¹ng cÃ ng nhanh cÃ ng tá»‘t Ä‘á»ƒ láº·p láº¡i vÃ  cáº£i thiá»‡n sáº£n pháº©m.\nEric Ries, ngÆ°á»i Ä‘Ã£ giá»›i thiá»‡u khÃ¡i niá»‡m MVP nhÆ° má»™t pháº§n cá»§a phÆ°Æ¡ng phÃ¡p Lean Startup cá»§a mÃ¬nh, mÃ´ táº£ má»¥c Ä‘Ã­ch cá»§a MVP theo cÃ¡ch nÃ y: ÄÃ¢y lÃ  phiÃªn báº£n cá»§a má»™t sáº£n pháº©m má»›i cho phÃ©p má»™t nhÃ³m thu tháº­p sá»‘ lÆ°á»£ng tÃ¬m hiá»ƒu tá»‘i Ä‘a Ä‘Æ°á»£c xÃ¡c nháº­n vá» khÃ¡ch hÃ ng vá»›i Ã­t ná»— lá»±c nháº¥t.\nMá»™t cÃ´ng ty cÃ³ thá»ƒ chá»n phÃ¡t triá»ƒn vÃ  phÃ¡t hÃ nh má»™t sáº£n pháº©m kháº£ thi tá»‘i thiá»ƒu vÃ¬ nhÃ³m sáº£n pháº©m cá»§a há» muá»‘n:\nPhÃ¡t hÃ nh sáº£n pháº©m ra thá»‹ trÆ°á»ng cÃ ng nhanh cÃ ng tá»‘t\nThá»­ nghiá»‡m Ã½ tÆ°á»Ÿng vá»›i ngÆ°á»i dÃ¹ng thá»±c trÆ°á»›c khi cam káº¿t ngÃ¢n sÃ¡ch lá»›n cho sá»± phÃ¡t triá»ƒn Ä‘áº§y Ä‘á»§ cá»§a sáº£n pháº©m\nTÃ¬m hiá»ƒu nhá»¯ng gÃ¬ cá»™ng hÆ°á»Ÿng vá»›i thá»‹ trÆ°á»ng má»¥c tiÃªu cá»§a cÃ´ng ty vÃ  nhá»¯ng gÃ¬ khÃ´ng\nNgoÃ i viá»‡c cho phÃ©p cÃ´ng ty cá»§a báº¡n xÃ¡c nháº­n Ã½ tÆ°á»Ÿng cho má»™t sáº£n pháº©m mÃ  khÃ´ng cáº§n xÃ¢y dá»±ng toÃ n bá»™ sáº£n pháº©m, MVP cÅ©ng cÃ³ thá»ƒ giÃºp giáº£m thiá»ƒu thá»i gian vÃ  nguá»“n lá»±c mÃ  báº¡n cÃ³ thá»ƒ cam káº¿t\nCÃ¡c xÃ¡c Ä‘á»‹nh Minimum Viable Product LÃ m tháº¿ nÃ o Ä‘á»ƒ báº¡n phÃ¡t triá»ƒn MVP vÃ  lÃ m tháº¿ nÃ o Ä‘á»ƒ nhÃ³m cá»§a báº¡n biáº¿t khi nÃ o báº¡n cÃ³ MVP sáºµn sÃ ng ra máº¯t? DÆ°á»›i Ä‘Ã¢y lÃ  má»™t vÃ i bÆ°á»›c chiáº¿n lÆ°á»£c cáº§n thá»±c hiá»‡n.\nÄáº£m báº£o MVP theo káº¿ hoáº¡ch phÃ¹ há»£p vá»›i má»¥c tiÃªu kinh doanh TrÆ°á»›c khi cÃ¢n nháº¯c nhá»¯ng tÃ­nh nÄƒng nÃ o cáº§n xÃ¢y dá»±ng, bÆ°á»›c Ä‘áº§u tiÃªn trong viá»‡c phÃ¡t triá»ƒn MVP lÃ  Ä‘áº£m báº£o sáº£n pháº©m sáº½ phÃ¹ há»£p vá»›i má»¥c tiÃªu chiáº¿n lÆ°á»£c cá»§a nhÃ³m hoáº·c cÃ´ng ty báº¡n.\nNhá»¯ng má»¥c tiÃªu Ä‘Ã³ lÃ  gÃ¬? Báº¡n Ä‘ang lÃ m viá»‡c hÆ°á»›ng tá»›i má»™t con sá»‘ doanh thu trong sÃ¡u thÃ¡ng tá»›i? Báº¡n cÃ³ nguá»“n lá»±c háº¡n cháº¿? Nhá»¯ng cÃ¢u há»i nÃ y cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n viá»‡c liá»‡u bÃ¢y giá» cÃ³ pháº£i lÃ  lÃºc Ä‘á»ƒ báº¯t Ä‘áº§u phÃ¡t triá»ƒn MVP má»›i hay khÃ´ng.\nNgoÃ i ra, hÃ£y há»i má»¥c Ä‘Ã­ch cá»§a sáº£n pháº©m MVP nÃ y sáº½ phá»¥c vá»¥ gÃ¬? VÃ­ dá»¥: nÃ³ sáº½ thu hÃºt ngÆ°á»i dÃ¹ng má»›i trong má»™t thá»‹ trÆ°á»ng liá»n ká» vá»›i thá»‹ trÆ°á»ng cho cÃ¡c sáº£n pháº©m hiá»‡n cÃ³ cá»§a báº¡n? Náº¿u Ä‘Ã³ lÃ  má»™t trong nhá»¯ng má»¥c tiÃªu kinh doanh hiá»‡n táº¡i cá»§a báº¡n, thÃ¬ káº¿ hoáº¡ch MVP nÃ y cÃ³ thá»ƒ kháº£ thi vá» máº·t chiáº¿n lÆ°á»£c.\nNhÆ°ng náº¿u Æ°u tiÃªn hiá»‡n táº¡i cá»§a cÃ´ng ty báº¡n lÃ  tiáº¿p tá»¥c táº­p trung vÃ o cÃ¡c thá»‹ trÆ°á»ng cá»‘t lÃµi cá»§a báº¡n, báº¡n cÃ³ thá»ƒ cáº§n pháº£i gÃ¡c láº¡i Ã½ tÆ°á»Ÿng nÃ y vÃ  thay vÃ o Ä‘Ã³, táº­p trung vÃ o má»™t MVP Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cung cáº¥p chá»©c nÄƒng má»›i cho khÃ¡ch hÃ ng hiá»‡n táº¡i cá»§a báº¡n.\nBáº¯t Ä‘áº§u xÃ¡c Ä‘á»‹nh cÃ¡c váº¥n Ä‘á» cá»¥ thá»ƒ mÃ  báº¡n muá»‘n giáº£i quyáº¿t hoáº·c cÃ¡c cáº£i tiáº¿n báº¡n muá»‘n kÃ­ch hoáº¡t cho tÃ­nh cÃ¡ch ngÆ°á»i dÃ¹ng cá»§a mÃ¬nh. BÃ¢y giá» báº¡n Ä‘Ã£ xÃ¡c Ä‘á»‹nh káº¿ hoáº¡ch MVP phÃ¹ há»£p vá»›i má»¥c tiÃªu kinh doanh cá»§a mÃ¬nh, báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u suy nghÄ© thÃ´ng qua cÃ¡c giáº£i phÃ¡p cá»¥ thá»ƒ mÃ  báº¡n muá»‘n sáº£n pháº©m cá»§a mÃ¬nh cung cáº¥p cho ngÆ°á»i dÃ¹ng. Nhá»¯ng giáº£i phÃ¡p nÃ y, mÃ  báº¡n cÃ³ thá»ƒ viáº¿t trong cÃ¢u chuyá»‡n cá»§a ngÆ°á»i dÃ¹ng, khÃ´ng Ä‘áº¡i diá»‡n cho táº§m nhÃ¬n tá»•ng thá»ƒ cá»§a sáº£n pháº©m â€” chá»‰ lÃ  táº­p há»£p con cá»§a táº§m nhÃ¬n Ä‘Ã³. ChÃºng ta chá»‰ cÃ³ thá»ƒ phÃ¡t triá»ƒn má»™t lÆ°á»£ng nhá» chá»©c nÄƒng cho MVP cá»§a mÃ¬nh.\nBáº¡n sáº½ cáº§n pháº£i cÃ³ chiáº¿n lÆ°á»£c trong viá»‡c quyáº¿t Ä‘á»‹nh chá»©c nÄƒng háº¡n cháº¿ nÃ o sáº½ Ä‘Æ°a vÃ o MVP cá»§a mÃ¬nh. Báº¡n cÃ³ thá»ƒ dá»±a trÃªn cÃ¡c quyáº¿t Ä‘á»‹nh nÃ y dá»±a trÃªn má»™t sá»‘ yáº¿u tá»‘, bao gá»“m:\nNghiÃªn cá»©u ngÆ°á»i dÃ¹ng\nPhÃ¢n tÃ­ch cáº¡nh tranh\nBáº¡n sáº½ cÃ³ thá»ƒ láº·p láº¡i má»™t sá»‘ loáº¡i chá»©c nÄƒng nhanh nhÆ° tháº¿ nÃ o khi nháº­n Ä‘Æ°á»£c pháº£n há»“i cá»§a ngÆ°á»i dÃ¹ng\nChi phÃ­ tÆ°Æ¡ng Ä‘á»‘i Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c cÃ¢u chuyá»‡n ngÆ°á»i dÃ¹ng\nChuyá»ƒn chá»©c nÄƒng MVP cá»§a báº¡n thÃ nh má»™t káº¿ hoáº¡ch hÃ nh Ä‘á»™ng phÃ¡t triá»ƒn. BÃ¢y giá» báº¡n Ä‘Ã£ cÃ¢n nháº¯c cÃ¡c yáº¿u tá»‘ chiáº¿n lÆ°á»£c á»Ÿ trÃªn vÃ  giáº£i quyáº¿t chá»©c nÄƒng háº¡n cháº¿ mÃ  báº¡n muá»‘n cho MVP cá»§a mÃ¬nh, Ä‘Ã£ Ä‘áº¿n lÃºc chuyá»ƒn Ä‘iá»u nÃ y thÃ nh má»™t káº¿ hoáº¡ch hÃ nh Ä‘á»™ng Ä‘á»ƒ phÃ¡t triá»ƒn.\nLÆ°u Ã½: Äiá»u cáº§n thiáº¿t lÃ  pháº£i ghi nhá»› chá»¯ V trong MVP â€” sáº£n pháº©m pháº£i kháº£ thi. Äiá»u Ä‘Ã³ cÃ³ nghÄ©a lÃ  nÃ³ pháº£i cho phÃ©p khÃ¡ch hÃ ng cá»§a báº¡n hoÃ n thÃ nh toÃ n bá»™ nhiá»‡m vá»¥ hoáº·c dá»± Ã¡n vÃ  cung cáº¥p tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng cháº¥t lÆ°á»£ng cao. MVP khÃ´ng thá»ƒ lÃ  giao diá»‡n ngÆ°á»i dÃ¹ng vá»›i nhiá»u cÃ´ng cá»¥ vÃ  tÃ­nh nÄƒng Ä‘Æ°á»£c xÃ¢y dá»±ng dá»Ÿ dang. NÃ³ pháº£i lÃ  má»™t sáº£n pháº©m hoáº¡t Ä‘á»™ng mÃ  cÃ´ng ty cá»§a báº¡n sáº½ cÃ³ thá»ƒ bÃ¡n.\nVÃ­ dá»¥ cÃ¡c cÃ´ng ty khá»Ÿi nghiá»‡p vá»›i Minimum Viable Product CÃ³ hai vÃ­ dá»¥ kinh Ä‘iá»ƒn thÆ°á»ng Ä‘Æ°á»£c nháº¯c tá»›i, Ä‘Ã³ lÃ :\nAirbnb Khá»Ÿi Ä‘áº§u viá»‡c kinh doanh vá»›i má»™t sá»‘ vá»‘n Ã­t á»i, cÃ¡c nhÃ  sÃ¡ng láº­p Airbnb Ä‘Ã£ sá»­ dá»¥ng chÃ­nh nhá»¯ng cÄƒng há»™ cá»§a há» Ä‘á»ƒ kiá»ƒm chá»©ng Ã½ tÆ°á»Ÿng cá»§a há» Ä‘á»ƒ táº¡o ta market offering short-term, peer-to-peer rental housing online (mÃ¬nh Ä‘á»ƒ tá»« tiáº¿ng anh á»Ÿ Ä‘Ã¢y , lÃ  tá»« khoÃ¡ cho cÃ¡c báº¡n tham kháº£o). Há» táº¡o ra má»™t trang web ráº¥t tá»‘i giáº£n, quÄƒng lÃªn Ä‘Ã³ hÃ¬nh vÃ  chi tiáº¿t vá» ngÃ´i nhÃ  cá»§a há», vÃ  gáº§n nhÆ° ngay láº­p tá»©c, Ä‘Ã£ cÃ³ khÃ¡ch hÃ ng tráº£ tiá»n cho dá»‹ch vá»¥ cá»§a há».\nGiáº£ sá»­ trong trÆ°á»ng há»£p vÃ i thÃ¡ng sau khÃ´ng cÃ³ ai thuÃª nhÃ , cÃ¡c nhÃ  sÃ¡ng láº­p Airbnb sáº½ lÃ m gÃ¬ tiáº¿p theo nhá»‰? :) :)\nFoursquare Foursquare lÃ  má»™t máº¡ng xÃ£ há»™i Ä‘Æ°á»£c sÃ¡ng láº­p nÄƒm 2009, Ä‘Æ°á»£c ra Ä‘á»i vá»›i má»™t MVP duy nháº¥t: \u0026ldquo;offering only check-ins and gamification rewards\u0026rdquo; - check-in -\u0026gt; kiá»ƒm Ä‘iá»ƒm -\u0026gt; nháº­n thÆ°á»Ÿng.\nNhÃ³m phÃ¡t triá»ƒn Foursquare báº¯t Ä‘áº§u thÃªm vÃ o cÃ¡c tÃ­nh nÄƒng recommendations, city guides Ä‘áº¿n khi ná» kiá»ƒm chá»©ng dÆ°á»£c Ã½ tÆ°á»Ÿng cá»§a mÃ¬nh, thÆ°á»›c Ä‘o cá»§a kinh doanh lÃ  sá»± tÄƒng trÆ°á»Ÿng cá»§a ngÆ°á»i sá»­ dá»¥ng dá»‹ch vá»¥.\nTÃ i liá»‡u tham kháº£o https://hbr.org/2020/05/approach-your-data-with-a-product-mindset\nhttps://www.productplan.com/learn/product-mindset-vs-project-mindset/\nhttps://www.productplan.com/glossary/minimum-viable-product/\nhttps://www.productplan.com/learn/theme-based-roadmap/\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\n","date":"Jul 23, 2023","img":"https://unsplash.it/1920/1080?image=9","permalink":"/blog/2023-07-23-product-mindset/","series":null,"tags":["mindset"],"title":"TÆ° Duy LÃ m Sáº£n Pháº©m - The Product Mindset"},{"categories":null,"content":" I. Giá»›i thiá»‡u II. N-gram Tokenizer III. Sá»­ dá»¥ng N-gram trong trÆ°á»ng há»£p tÃ¬m kiáº¿m IV. CÃ¡c phÆ°Æ¡ng phÃ¡p thay tháº¿ n-gram V. Káº¿t luáº­n I. Giá»›i thiá»‡u Chi phÃ­ liÃªn quan Ä‘áº¿n n-gram tokenizer á»Ÿ ElasticSearch vÃ  opensearch thÆ°á»ng khÃ´ng Ä‘á» cáº­p chi tiáº¿t trong cÃ¡c tÃ i liá»‡u, do Ä‘Ã³, cÃ³ khi nÃ³ sáº½ gÃ¢y ra cÃ¡c háº­u quáº£ khÃ¡ nghiÃªm trá»ng vá» chi phÃ­ vÃ  hiá»‡u nÄƒng. Dáº«n Ä‘áº¿n trÆ°á»ng há»£p lÃ  chÃºng ta pháº£i \u0026ldquo;láº¥y thá»‹t Ä‘Ã¨ ngÆ°á»i\u0026rdquo; báº±ng cÃ¡ch tÄƒng chi phÃ­ pháº§n cá»©ng má»™t cÃ¡ch lÃ£ng phÃ­. Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ Ä‘á» cáº­p Ä‘áº¿n vÃ i use-case sá»­ dá»¥ng n-gram tokenizer, má»™t sá»‘ phÆ°Æ¡ng phÃ¡p cáº£i tiáº¿n, hoáº·c má»™t vÃ i phÆ°Æ¡ng phÃ¡p thay tháº¿ nÃ³ báº±ng cÃ¡ch khÃ¡ch hiá»‡u quáº£ hÆ¡n.\nNgÃ y nay, Elasticsearch vÃ  OpenSearch lÃ  hai engines Ä‘Æ°á»£c nhiá»u cÃ´ng ty sá»­ dá»¥ng Ä‘á»ƒ lÃ m tÃ¬m kiáº¿m vÄƒn báº£n ná»™i bá»™, lÃ m bá»™ mÃ¡y tÃ¬m kiáº¿m chÃ­nh Ä‘á»ƒ sá»­ dá»¥ng ná»™i bá»™ hoáº·c cung cáº¥p dá»‹ch vá»¥ cho khÃ¡ch hÃ ng bÃªn ngoÃ i.\nHáº§u háº¿t cÃ¡c láº­p trÃ¬nh viÃªn sáº½ sá»­ dá»¥ng hÃ m analyzers vÃ  tokenizers máº·c Ä‘á»‹nh do Elasticsearch vÃ  OpenSearch cung cáº¥p sáºµn, Ä‘á»ƒ chia nhá» Ä‘oáº¡n vÄƒn báº£n thÃ nh cÃ¡c token. VÃ­ dá»¥ nhÆ° cÃ¢u \u0026ldquo;ÄÃ¢y lÃ  nÄƒm ráº¥t láº¡ lÃ¹ng\u0026rdquo; khi sá»­ dá»¥ng analyzer máº·c Ä‘á»‹nh thÃ¬ sáº½ chia thÃ nh danh sÃ¡ch cÃ¡c tá»« [ ÄÃ¢y, lÃ , nÄƒm, ráº¥t, láº¡, lÃ¹ng], má»—i tá»« trong danh sÃ¡ch cÃ¡c tá»« trÃªn Ä‘á»u cÃ³ thá»ƒ dá»… dÃ ng Ä‘Æ°á»£c search. ÄÃ¢y lÃ  cÃ¡i mÃ  chÃºng ta thÆ°á»ng gá»i lÃ  \u0026ldquo;full-text-search\u0026rdquo;, lÃ  tÃ¬m kiáº¿m vÄƒn báº£n báº±ng dá»±a trÃªn má»™t hoáº·c má»™t vÃ i tá»« cÃ³ tá»“n táº¡i trong Ä‘oáº¡n vÄƒn báº£n Ä‘Ã³.\nTrong má»™t sá»‘ trÆ°á»ng há»£p há»£p, ngÆ°á»i ta sáº½ sá»­ dá»¥ng cÃ¡c analyzer Ä‘áº·c biá»‡t Ä‘á»ƒ lÃ m cÃ¡c cÃ´ng viá»‡c Ä‘áº·c biá»‡t, khÃ´ng pháº£i lÃ  full text search.\nMá»™t trong nhá»¯ng thÃ nh pháº§n Ä‘áº·c biá»‡t trong elasticsearch vÃ  open search lÃ  n-gram tokenizer. HÃ£y Ä‘iá»ƒm qua má»™t vÃ i á»©ng dá»¥ng cá»§a nÃ³ mÃ  ngÆ°á»i cáº¥u hÃ¬nh thÆ°á»ng hay sá»­ dá»¥ng sai\nII. N-gram Tokenizer N-gram Tokenizer táº¡o ra má»™t nhÃ³m cÃ¡c kÃ½ tá»±, nhá»¯ng token nÃ³ táº¡o ra khÃ´ng nháº¥t thiáº¿t lÃ  nhá»¯ng tá»« giá»‘ng nhÆ° analyzer tiÃªu chuáº©n, nÃ³ chá»©a nhá»¯ng tá»« liÃªn tiÃªn tiáº¿p nhau, chiá»u dÃ i cá»§a token phá»¥ thuá»™c vÃ o N. VÃ­ dá»¥ trong trÆ°á»ng há»£p N = 2 vÃ  tá»« cá»§a cÃºng ta lÃ  \u0026ldquo;láº¡ lÃ¹ng\u0026rdquo;, chÃºng ta cÃ³ cÃ¡c token lÃ  [l, láº¡, áº¡, \u0026ldquo;áº¡ \u0026ldquo;, \u0026quot; \u0026ldquo;, \u0026quot; l\u0026rdquo;, l, lÃ¹, Ã¹, Ã¹n, n, ng, g]\nBáº¡n cÃ³ thá»ƒ tháº¥y ráº±ng, thay vÃ¬ chá»‰ táº¡o ra hai token [láº¡, lÃ¹ng], n-gram sáº½ chia dá»¯ liá»‡u thÃ nh nhÃ³m cÃ¡c kÃ½ tá»±. Phá»¥ thuá»™c vÃ o N mÃ  ta cÃ³ sá»‘ lÆ°á»£ng token khÃ¡c nhau, Trong vÃ­ dá»¥ trÃªn, chÃºng ta cÃ³ 17 token vá»›i N = 2 , nghÄ©a lÃ  sá»‘ lÆ°á»£ng token Ä‘Ã£ tÄƒng hÆ¡n 6 láº§n. Trong trÆ°á»ng há»£p N=3, N=4, hoáº·c trong trÆ°á»ng há»£p tá»« cáº§n index dÃ i hÆ¡n, sá»‘ lÆ°á»£ng token cÃ²n bá»‹ nhÃ¢n lÃªn gáº¥p nhiá»u láº§n ná»¯a\nIII. Sá»­ dá»¥ng N-gram trong trÆ°á»ng há»£p tÃ¬m kiáº¿m CÃ³ ráº¥t nhiá»u tÆ° váº¥n trÃªn máº¡ng vá» cÃ¡ch sá»­ dá»¥ng n-gram, vÃ  cÃ¡c tÆ° váº¥n trÃªn thÆ°á»ng xoay quanh cÃ¡c chá»§ Ä‘á» sau\nPhÃ¡t hiá»‡n lá»—i chÃ­nh táº£ Viá»‡c gÃµ vÄƒn báº£n sai chÃ­nh táº£ lÃ  má»™t váº¥n Ä‘á» thÆ°á»ng gáº·p, ngay cáº£ cÃ¡c bÃ¡o chÃ­ chÃ­nh thá»‘ng cÅ©ng gáº·p trÆ°á»ng há»£p trÃªn. VÃ­ dá»¥ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ gÃµ sai tá»« \u0026ldquo;apple\u0026rdquo; thÃ nh \u0026ldquo;aple\u0026rdquo; (Ä‘iá»‡n thoáº¡i apple). Viá»‡c sá»­ dá»¥ng n-grams sáº½ giÃºp ta giáº£i phÃ¡t hiá»‡n tá»« bá»‹ gÃµ sai, trong khi Ä‘Ã³, analyzer máº·c Ä‘á»‹nh sáº½ khÃ´ng phÃ¡t hiá»‡n ra.\nTÃ¬m kiáº¿m trong lÃºc gÃµ Thá»±c hiá»‡n viá»‡c search trong lÃºc ngÆ°á»i dÃ¹ng gÃµ trÃªn thanh tÃ¬m kiáº¿m. NÃ³ sáº½ tÃ¬m kiáº¿m trÆ°á»›c cÃ¡c káº¿t quáº£ há»£p lá»‡ ngay cáº£ khi ngÆ°á»i dÃ¹ng chÆ°a hoÃ n táº¥t viá»‡c tÃ¬m kiáº¿m. VÃ­ dá»¥ gá»£i Ã½ tá»« khoÃ¡ \u0026ldquo;iphone 14 promax\u0026rdquo; khi ngÆ°á»i dÃ¹ng chá»‰ má»›i gÃµ Ä‘áº¿n tá»« \u0026ldquo;ipho\u0026rdquo;\nPrefix searches TÃ¬m kiáº¿m vÄƒn báº£n báº¯t Ä‘áº§u cá»§a tá»«, vÃ­ dá»¥ ngÆ°á»i dÃ¹ng gÃµ \u0026ldquo;ip\u0026rdquo; thÃ¬ sáº½ khá»›p vá»›i \u0026ldquo;iphone\u0026rdquo;, khi tá»« \u0026ldquo;ip\u0026rdquo; Ä‘Æ°á»£c index lÃ  token cá»§a tá»« \u0026ldquo;iphone\u0026rdquo;. Prefix search chá»‰ láº¥y index, khÃ´ng thá»±c hiá»‡n prefix query\nSuffix searches Äá»‘i láº­p vá»›i Prefix searches, Ä‘Ã´i lÃºc chÃºng ta sáº½ cáº§n tÃ¬m kiáº¿m cÃ¡c kÃ½ tá»± á»Ÿ cuá»‘i, vÃ­ dá»¥ nhÆ° biá»ƒn sá»‘ xe (thÆ°á»ng ngÆ°á»i dÃ¹ng sáº½ khÃ´ng nhá»› pháº§n kÃ½ hiá»‡u vÃ  kÃ½ sá»‘ Ä‘áº§u, vÃ­ dá»¥ 50A1), sá»‘ Ä‘iá»‡n thoáº¡i ( tÃ¬m kiáº¿m 4 kÃ½ tá»± cuá»‘i).\nInfix searches TÆ°Æ¡ng tá»± nhÆ° trÃªn, nhÆ°ng tÃ¬m á»Ÿ giá»¯a.\nTrong nhá»¯ng trÆ°á»ng há»£p trÃªn, láº­p trÃ¬nh viÃªn hay Ä‘Æ°á»£c tÆ° váº¥n lÃ  xÃ i n-gram. N-gram cÃ³ thá»ƒ giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» trÃªn, nhÆ°ng chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng nhiá»u cÃ¡c khÃ¡c hiá»‡u quáº£ hÆ¡n.\nLÃ½ do khÃ´ng nÃªn xÃ i n-gram lÃ  vÃ¬ sá»± bÃ¹ng ná»• token do chÃ­nh n-gram mang láº¡i, dáº«n Ä‘áº¿n chÃºng ta cáº§n tiÃªu tá»‘n nhiá»u tÃ i nguyÃªn nhÆ° CPU, RAM Ä‘á»ƒ xá»­ lÃ½ index, táº¡o token trong lÃºc index vÃ  search, tá»‘n nhiá»u á»• cá»©ng Ä‘á»ƒ lÆ°u trá»¯. Cuá»‘i cÃ¹ng, hiá»‡u nÄƒng truy váº¥n sáº½ giáº£m.\nIV. CÃ¡c phÆ°Æ¡ng phÃ¡p thay tháº¿ n-gram ChÃºng ta sáº½ xem xÃ©t tá»«ng trÆ°á»ng há»£p cá»¥ thá»ƒ\nGÃµ sai chÃ­nh táº£ Thay vÃ¬ sá»­ dá»¥ng n-gram, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng term suggester vÃ  phrase suggester trong elastic search, link https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters.html#phrase-suggester, https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters.html#term-suggester, Ä‘Æ¡n giáº£n.\nTÃ¬m kiáº¿m trong lÃºc gÃµ CÃ¡i nÃ y thÃ¬ chÃºng ta xÃ i n-gram cÅ©ng Ä‘Æ°á»£c, nhÆ°ng mÃ  elastic search cÃ³ há»— trá»£ cho chÃºng ta má»™t vÃ i tiá»‡n Ã­ch Ä‘Æ¡n giáº£n hÆ¡n nhiá»u, chÃºng ta khÃ´ng cáº§n pháº£i váº¯t Ã³c suy nghÄ© cáº¥u hÃ¬nh n báº±ng bao nhiÃªu. ÄÃ³ lÃ  sá»­ dá»¥ng trÆ°á»ng dá»¯ liá»‡u search-as-you-type https://www.elastic.co/guide/en/elasticsearch/reference/current/search-as-you-type.html. Hoáº·c chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng completion suggester vÃ  context suggester, link https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters.html#completion-suggester , https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters.html#context-suggester\nPrefix searches Elastic cÅ©ng há»— trá»£ sáºµn luÃ´n, Ä‘Ã³ lÃ  Prefix queryedit https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-prefix-query.html\nSuffix searches Chá»— nÃ y chÃºng ta sáº½ sá»­ dá»¥ng combo Reverse token filter vÃ  Match phrase prefix query https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-reverse-tokenfilter.html, https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase-prefix.html#query-dsl-match-query-phrase-prefix\nVÃ­ dá»¥ nhÆ° chÃºng ta cÃ³ sá»‘ Ä‘iá»‡n thoáº¡i 0902987235, chÃºng ta sáº½ Reverse token filter thÃ nh 5327892090, 4 sá»‘ cuá»‘i cáº§n tÃ¬m lÃ  7235 sáº½ bá»‹ reverser thÃ nh 5327, thá»±c hiá»‡n Match phrase prefix query 5327, chÃºng ta sáº½ tÃ¬m Ä‘Æ°á»£c 5327892090 , Reverse láº¡i ra chuá»—i sá»‘ Ä‘iá»‡n thoáº¡i cáº§n tÃ¬m.\nInfix searches ÄÃ¢y lÃ  Ã´ng tá»‘n nhiá»u chi phÃ­ nháº¥t, vá»›i sql engine, chÃºng ta xÃ i tá»« khoÃ¡ like dáº«n Ä‘áº¿n bá»‹ máº¥t index, vá»›i n-gram, chÃºng ta pháº£i index háº¿t toÃ n bá»™ token, vÃ o. Trong elastic cÃ³ há»— trá»£ chÃºng ta Word delimiter graph token filter, giáº£i quyáº¿t cÃ¡i nÃ y dá»… dÃ ng https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-word-delimiter-graph-tokenfilter.html\nV. Káº¿t luáº­n Vá»›i cÃ¡c cÃ´ng nghá»‡ trÃªn, chÃºng sáº½ giÃºp chÃºng ta nhÃ n hÆ¡n khi sá»­ dá»¥ng elastic, opensearch. CÃ¡c báº¡n náº¿u cÃ³ Ä‘ang bá»‹ nhá»¯ng vÆ°á»›ng máº¯c trÃªn, hÃ£y thá»­ cÃ¡c cÃ¡ch Ä‘Æ°á»£c Ä‘á» xuáº¥t, biáº¿t Ä‘Ã¢u báº¥t ngá» sáº½ xáº£y ra.\nNguá»“n: https://blog.bigdataboutique.com/2023/01/dont-use-n-gram-in-elasticsearch-and-opensearch-6f0b48\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\n","date":"Mar 25, 2023","img":"https://unsplash.it/1920/1080?image=10","permalink":"/blog/2023-03-25-elasticsearch-opensearch-ngram/","series":null,"tags":["RFM","Recommendation","Marketing"],"title":"N-Gram Trong Elastic Search VÃ  Opensearch - Khi NÃ o KhÃ´ng NÃªn Sá»­ Dá»¥ng"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Symbolic AI lÃ  gÃ¬ Connectionist AI lÃ  gÃ¬ ChÃºng ta nÃªn chá»n cÃ¡i nÃ o HÆ°á»›ng phÃ¡t triá»ƒn tiáº¿p theo cá»§a AI Tham kháº£o Lá»i má»Ÿ Ä‘áº§u Dáº¡o gáº§n Ä‘Ã¢y, khi cÃ¡c á»©ng dá»¥ng AI Ä‘ang hÃ´ mÆ°a gá»i giÃ³ trÃªn toÃ n cÃµi, Ä‘iá»ƒn hÃ¬nh lÃ  hot keywork chatGPT, thÃ¬ trong cá»™ng Ä‘á»“ng nghiÃªn cá»©u cÅ©ng ná»• ra cuá»™c chiáº¿n giá»¯a hai phe Symbolic AI vÃ  Connectionist AI. CÃ³ váº» nhÆ° á»Ÿ nÆ¡i nÃ o cÃ³ chia nhÃ³m, thÃ¬ sáº½ cÃ³ má»™t nhÃ³m ngÆ°á»i chá»n phe nÃ y, vÃ  má»™t nhÃ³m khÃ¡c chá»n phe cÃ²n láº¡i, má»™t nhÃ³m khÃ¡c ná»¯a Ä‘á»©ng á»Ÿ cáº£ hai, nhÃ³m khÃ¡c ná»¯a khÃ´ng chá»n nhÃ³m nÃ o cáº£. Hai nhÃ³m lÃ  nhÃ³m Ä‘á»©ng cáº£ hai vÃ  nhÃ³m khÃ´ng chá»n nhÃ³m nÃ o cáº£ thÆ°á»ng Ã­t hoáº·c khÃ´ng lÃ m gÃ¬ cáº£, cÃ²n nhÃ³m chá»n phe nÃ y vÃ  nhÃ³m chá»n phe kia sáº½ Ä‘á»‘i Ä‘áº§u nhau ráº¥t gay gáº¯t.\nDÆ°á»›i sá»± cÆ°á»ng Ä‘iá»‡u cá»§a giá»›i truyá»n thÃ´ng, cÃ¹ng vá»›i viá»‡c ná»•i nhÆ° cá»“n cá»§a nhá»¯ng á»©ng dá»¥ng Ä‘Æ°á»£c PR má»™t cÃ¡ch máº¡nh máº½, thÃ¬ nhÃ³m Connectionist AI Ä‘ang bá»‹ xem lÃ  \u0026hellip; AI.\nSá»± tháº­t lÃ  má»—i nhÃ³m thuáº­t toÃ¡n Ä‘á»u cÃ³ chá»— Ä‘á»©ng cá»§a nÃ³. KhÃ´ng cÃ³ má»™t thuáº­t toÃ¡n AI nÃ o toÃ n nÄƒng á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i, giÃºp giáº£i cÃ¡c bÃ i toÃ¡n, hay nÃ³i cÃ¡ch khÃ¡c lÃ  chÃºng ta khÃ´ng cÃ³ \u0026ldquo;viÃªn Ä‘áº¡n báº¡c\u0026rdquo; nÃ o trong AI. Má»—i cÃ´ng cá»¥ Ä‘á»u cÃ³ Ä‘iá»ƒm máº¡nh vÃ  Ä‘iá»ƒm yáº¿u riÃªng, vÃ  viá»‡c chÃºng ta sá»­ dá»¥ng Ä‘Ãºng cÃ´ng cá»¥ sáº½ lÃ  chÃ¬a khoÃ¡ cho sá»± thÃ nh cÃ´ng.\nSymbolic AI lÃ  gÃ¬ NhÃ³m thuáº­t toÃ¡n nÃ y Ä‘Ã´i khi cÃ²n Ä‘Æ°á»£c gá»i lÃ  GOFAI (Good Old Fashioned A.I.), khÃ´ng nÃªn hiá»ƒu nÃ³ theo nghÄ©a lÃ  cÃ´ng nghá»‡ cÅ© hay cÃ´ng nghá»‡ lá»—i thá»i. MÃ  nÃªn hiá»ƒu lÃ  nÃ³ lÃ  cÃ¡ch tiáº¿p cáº­n cá»• Ä‘iá»ƒn cá»§a viá»‡c biáº¿n thÃ´ng tin tri thá»©c vÃ  vÃ  cÃ¡c luáº­t cá»§a con ngÆ°á»i thÃ nh nhá»¯ng dÃ²ng code trÃªn mÃ¡y tÃ­nh.\nCon ngÆ°á»i thÆ°á»ng xuyÃªn sá»­ dá»¥ng cÃ¡c \u0026ldquo;biá»ƒu tÆ°á»£ng\u0026rdquo; Ä‘á»ƒ gÃ¡n Ã½ nghÄ©a cho cÃ¡c sá»± váº­t vÃ  sá»± kiá»‡n trong mÃ´i trÆ°á»ng cá»§a há». VÃ­ dá»¥, náº¿u ai Ä‘Ã³ nÃ³i vá»›i báº¡n cá»§a há» ráº±ng há» vá»«a mua má»™t bÃ³ hoa há»“ng, ngÆ°á»i nghe tin Ä‘Ã³ cÃ³ thá»ƒ nhanh chÃ³ng liÃªn tÆ°á»Ÿng Ä‘áº¿n hÃ¬nh áº£nh cá»§a nhá»¯ng bÃ´ng hoa. Ã tÆ°á»Ÿng cá»§a symbolic AI lÃ  nhá»¯ng \u0026ldquo;biá»ƒu tÆ°á»£ng\u0026rdquo; nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ nh khá»‘i nháº­n thá»©c.\nCÃ¡c há»‡ thá»‘ng thuá»™c loáº¡i nÃ y thÆ°á»ng liÃªn quan Ä‘áº¿n lÃ½ luáº­n suy diá»…n, suy luáº­n logic vÃ  má»™t sá»‘ thuáº­t toÃ¡n tÃ¬m kiáº¿m Ä‘á»ƒ tÃ¬m ra giáº£i phÃ¡p trong cÃ¡c rÃ ng buá»™c cá»§a mÃ´ hÃ¬nh Ä‘Ã£ chá»‰ Ä‘á»‹nh. ChÃºng bao gá»“m cÃ¡c há»‡ thá»‘ng chuyÃªn gia, sá»­ dá»¥ng cÃ¡c quy táº¯c vÃ  cÃ¢y quyáº¿t Ä‘á»‹nh Ä‘á»ƒ suy ra káº¿t luáº­n tá»« dá»¯ liá»‡u Ä‘áº§u vÃ o, bá»™ giáº£i rÃ ng buá»™c, tÃ¬m kiáº¿m giáº£i phÃ¡p trong má»™t khÃ´ng gian kháº£ nÄƒng vÃ  há»‡ thá»‘ng láº­p káº¿ hoáº¡ch, cá»‘ gáº¯ng tÃ¬m má»™t chuá»—i cÃ¡c hÃ nh Ä‘á»™ng Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»™t má»¥c tiÃªu Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh rÃµ rÃ ng tá»« má»™t sá»‘ tráº¡ng thÃ¡i ban Ä‘áº§u. ChÃºng cÅ©ng thÆ°á»ng cÃ³ cÃ¡c biáº¿n thá»ƒ cÃ³ kháº£ nÄƒng xá»­ lÃ½ sá»± khÃ´ng cháº¯c cháº¯n vÃ  rá»§i ro.\nCÃ¡c thuáº­t toÃ¡n nhÆ° váº­y thÆ°á»ng cÃ³ Ä‘á»™ phá»©c táº¡p thuáº­t toÃ¡n lÃ  NP-hard, khi giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» trong tháº¿ giá»›i thá»±c, nhÃ³m nÃ y pháº£i Ä‘á»‘i máº·t vá»›i khÃ´ng gian tÃ¬m kiáº¿m siÃªu lá»›n. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  cÃ¡c thuáº­t toÃ¡n thuyá»n thá»‘ng trang bá»‹ ká»¹ nÄƒng tÃ¬m kiáº¿m ngáº«u nhiÃªn sáº½ khÃ´ng hoáº¡t Ä‘á»™ng, ngoáº¡i trá»« cÃ¡c trÆ°á»ng há»£p ngoáº¡i lá»‡, Do kháº£ nÄƒng cao lÃ  lá»i giáº£n sáº½ vÃ©t cáº¡n khÃ´ng gian tÃ¬m kiáº¿m.\nCÃ³ ráº¥t nhiá»u nhÃ³m thuáº­t toÃ¡n trong nhÃ³m nÃ y:\nBranch and bound algorithms CÃ¡c thuáº­t toÃ¡n thuá»™c nhÃ³m Branch and bound Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c bÃ i toÃ¡n tá»‘i Æ°u hoÃ¡ hoáº·c bÃ i toÃ¡n rÃ ng buá»™c cÃ³ Ä‘iá»u kiá»‡n. Khi mÃ  chÃºng ta khÃ´ng thá»ƒ Ã¡p dá»¥ng heuristic trong cÃ¡c bÃ i toÃ¡n Ä‘Ã³. CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a cÃ¡c bÃ i toÃ¡n dáº¡ng nÃ y lÃ  phÃ¢n váº¥n Ä‘á» thÃ nh cÃ¡c vÃ¹ng nhá» sá»­ dá»¥ng upper bound vÃ  lower bound, vÃ  thá»±c hiá»‡n tÃ¬m kiáº¿m giáº£i phÃ¡p trÃªn cÃ¡c vÃ¹ng Ä‘Ã³.\nLocal search TÃ¬m kiáº¿m cá»¥c bá»™ xem xÃ©t cÃ¡c biáº¿n thá»ƒ gáº§n Ä‘Ãºng vÃ  sá»­ dá»¥ng cÃ¡c biáº¿n thá»ƒ Ä‘Ã³ Ä‘á»ƒ cá»‘ gáº¯ng cáº£i thiá»‡n nÃ³ dáº§n dáº§n. ÄÃ´i khi, thá»±c hiá»‡n cÃ¡c bÆ°á»›c nháº£y ngáº«u nhiÃªn nháº±m thoÃ¡t khá»i tá»‘i Æ°u cá»¥c bá»™.\nMeta-heuristics SiÃªu kinh nghiá»‡m sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n tiáº¿n hÃ³a, báº¯t chÆ°á»›c cÃ¡c cÆ¡ cháº¿ cá»™ng tÃ¡c hoáº·c phÃ¢n tÃ¡n Ä‘Æ°á»£c tÃ¬m tháº¥y trong tá»± nhiÃªn, cháº³ng háº¡n nhÆ° chá»n lá»c tá»± nhiÃªn hoáº·c cÃ¡c hÃ nh vi Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« báº§y Ä‘Ã n.\nHeuristic search Heuristic search sá»­ dá»¥ng hÃ m lÆ°á»£ng giÃ¡ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ liÃªn quan cá»§a Ä‘iá»ƒm dá»¯ liá»‡u vÃ  má»¥c tiÃªu.\nCÃ¡c thuáº­t toÃ¡n nÃ y thÆ°á»ng khÃ´ng phÃ¹ há»£p vá»›i dá»¯ liá»‡u Ä‘áº§u vÃ o lÃ  nhiá»…u, hoáº·c trong cÃ¡c tÃ¬nh huá»‘ng mÃ´ hÃ¬nh khÃ´ng Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a rÃµ rÃ ng. ChÃºng tá» ra hiá»‡u quáº£ trong ngá»¯ cáº£nh chÃºng ta cÃ³ cÃ¡c hÃ nh Ä‘á»™ng rÃµ rÃ ng vÃ  cá»¥ thá»ƒ, vÃ  há»‡ thá»‘ng cáº§n cung cáº¥p má»™t ká»¹ thuáº­t chuáº©n Ä‘á»ƒ triá»ƒn khai cÃ¡c hÃ nh Ä‘á»™ng trÃªn.\nConnectionist AI lÃ  gÃ¬ CÃ¡i tÃªn Ä‘Æ°á»£c láº¥y tá»« liÃªn káº¿t máº¡ng mÃ  cÃ¡c thuáº­t toÃ¡n trong nhÃ³m nÃ y sá»­ dá»¥ng. Ká»¹ thuáº­t phá»• biáº¿n trong nhÃ³m nÃ y lÃ  sá»­ dá»¥ng Artificial Neural Network (ANN). ChÃºng bao gá»“m nhiá»u lá»›p máº¡ng, má»—i lá»›p sáº½ cÃ³ nhiá»u node, chÃºng sáº½ xá»­ lÃ½ cÃ¡c tÃ­n hiá»‡u Ä‘áº§u vÃ o, káº¿t há»£p chÃºng vá»›i cÃ¡c trá»ng sá»‘, vÃ  biáº¿n Ä‘á»•i chÃºng trÆ°á»›c khi Ä‘Æ°a vÃ o lá»›p tiáº¿p theo. Support Vector Machines (SVMs) cÅ©ng thuá»™c nhÃ³m nÃ y.\nANNs cÃ³ ráº¥t nhiá»u biáº¿n thá»ƒ, vÃ­ dá»¥ Convolution Neural Networks (Ä‘Æ°á»£c sá»­ dá»¥ng chá»§ yáº¿u trong xá»­ lÃ½ áº£nh), Long Short-term Memory Networks ( thÆ°á»ng Ä‘Æ°á»£c dÃ¹ng trong bÃ i toÃ¡n phÃ¢n tÃ­ch time series hoáº·c cÃ¡c bÃ i toÃ¡n mÃ  thá»i gian lÃ  Ä‘áº·c trÆ°ng quan trá»ng, bá»‹ áº©n Ä‘i dÆ°á»›i lÄƒng kÃ­nh bÃ¬nh thÆ°á»ng (vÄƒn báº£n :) ). Deep learning vá» cÆ¡ báº£n lÃ  Ä‘á»“ng nghÄ©a vá»›i Artificial Neural Networks.\nGiÃ¡ trá»‹ cá»‘t lÃµi cá»§a loáº¡i ká»¹ thuáº­t nÃ y lÃ  ngÆ°á»i dÃ¹ng khÃ´ng cáº§n chá»‰ Ä‘á»‹nh cÃ¡c quy táº¯c cá»§a miá»n Ä‘Æ°á»£c mÃ´ hÃ¬nh hÃ³a. Máº¡ng tá»± phÃ¡t hiá»‡n ra cÃ¡c quy táº¯c tá»« training data. NgÆ°á»i dÃ¹ng cung cáº¥p dá»¯ liá»‡u Ä‘áº§u vÃ o vÃ  dá»¯ liá»‡u Ä‘áº§u ra máº«u (bá»™ dá»¯ liá»‡u cÃ ng lá»›n vÃ  Ä‘a dáº¡ng cÃ ng tá»‘t). CÃ¡c thuáº­t toÃ¡n káº¿t ná»‘i sau Ä‘Ã³ Ã¡p dá»¥ng cÃ¡c mÃ´ hÃ¬nh há»“i quy thá»‘ng kÃª Ä‘á»ƒ Ä‘iá»u chá»‰nh cÃ¡c há»‡ sá»‘ trá»ng sá»‘ cá»§a cÃ¡c biáº¿n trung gian cá»§a chÃºng, cho Ä‘áº¿n khi tÃ¬m tháº¥y mÃ´ hÃ¬nh phÃ¹ há»£p nháº¥t. CÃ¡c trá»ng sá»‘ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh theo hÆ°á»›ng giáº£m thiá»ƒu lá»—i tÃ­ch lÅ©y tá»« táº¥t cáº£ cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u huáº¥n luyá»‡n, sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° giáº£m Ä‘á»™ dá»‘c.\nVÃ¬ cÃ¡c ká»¹ thuáº­t nÃ y sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n cá»±c tiá»ƒu hoÃ¡ Ä‘á»™ lá»—i, nÃªn chÃºng vá»‘n cÃ³ kháº£ nÄƒng chá»‘ng nhiá»…u. ChÃºng sáº½ loáº¡i bá» cÃ¡c giÃ¡ trá»‹ ngoáº¡i lá»‡ vÃ  Ä‘Æ°a ra giáº£i phÃ¡p phÃ¢n loáº¡i dá»¯ liá»‡u trong pháº¡m vi sai sá»‘ nháº¥t Ä‘á»‹nh.\nCÃ¡c thuáº­t toÃ¡n nÃ y khÃ´ng cáº§n má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c cung cáº¥p trÆ°á»›c. NÃ³ chá»‰ cáº§n Ä‘á»§ dá»¯ liá»‡u máº«u vÃ  nÃ³ sáº½ tá»± suy ra mÃ´ hÃ¬nh. ÄÃ¢y lÃ  má»™t Ä‘áº·c Ä‘iá»ƒm ráº¥t máº¡nh máº½, nhÆ°ng cÅ©ng lÃ  má»™t Ä‘iá»ƒm yáº¿u. CÃ¡c tÃ­nh nÄƒng Ä‘áº§u vÃ o pháº£i Ä‘Æ°á»£c lá»±a chá»n ráº¥t cáº©n tháº­n. ChÃºng cÅ©ng pháº£i Ä‘Æ°á»£c chuáº©n hÃ³a hoáº·c chia tá»· lá»‡, Ä‘á»ƒ trÃ¡nh má»™t tÃ­nh nÄƒng Ã¡p Ä‘áº£o cÃ¡c tÃ­nh nÄƒng khÃ¡c vÃ  Ä‘Æ°á»£c xá»­ lÃ½ trÆ°á»›c Ä‘á»ƒ cÃ³ Ã½ nghÄ©a hÆ¡n Ä‘á»‘i vá»›i viá»‡c phÃ¢n loáº¡i.\nFeature engineering thÆ°á»ng cÃ³ thá»ƒ lÃ  yáº¿u tá»‘ quyáº¿t Ä‘á»‹nh thÃ nh cÃ´ng chÃ­nh cá»§a má»™t dá»± Ã¡n mÃ¡y há»c. Viá»‡c cÃ³ quÃ¡ nhiá»u Ä‘áº·c trÆ°ng hoáº·c khÃ´ng cÃ³ Ä‘á»§ dá»¯ liá»‡u máº«u Ä‘áº¡i diá»‡n cho toÃ n bá»™ váº¥n Ä‘á», cÃ³ thá»ƒ dáº«n dáº¿n overfitting hoáº·c underfitting. Ngay cáº£ vá»›i sá»± giÃºp Ä‘á»¡ cá»§a nhÃ  khoa há»c dá»¯ liá»‡u lÃ nh nghá» nháº¥t, báº¡n váº«n pháº£i chá»‹u sá»± phá»¥ thuá»™c vÃ o cháº¥t lÆ°á»£ng cá»§a dá»¯ liá»‡u mÃ  báº¡n cÃ³. CÃ¡c ká»¹ thuáº­t nÃ y cÅ©ng khÃ´ng trÃ¡nh khá»i curse of dimensionality, hoáº·c sá»‘ lÆ°á»£ng input feature tÄƒng, hoáº·c rá»§i ro cá»§a giáº£i phÃ¡p khÃ´ng há»£p lá»‡.\nCÃ¡c thuáº­t toÃ¡n máº·c nhiÃªn giáº£ Ä‘á»‹nh ráº±ng mÃ´ hÃ¬nh tháº¿ giá»›i mÃ  chÃºng Ä‘ang náº¯m báº¯t lÃ  tÆ°Æ¡ng Ä‘á»‘i á»•n Ä‘á»‹nh. Äiá»u nÃ y lÃ m cho chÃºng ráº¥t hiá»‡u quáº£ Ä‘á»‘i vá»›i cÃ¡c váº¥n Ä‘á» mÃ  luáº­t chÆ¡i khÃ´ng thay Ä‘á»•i nhiá»u hoáº·c thay Ä‘á»•i vá»›i tá»‘c Ä‘á»™ Ä‘á»§ cháº­m Ä‘á»ƒ cho phÃ©p thu tháº­p Ä‘á»§ cÃ¡c máº«u dá»¯ liá»‡u má»›i Ä‘á»ƒ Ä‘Ã o táº¡o láº¡i vÃ  thÃ­ch á»©ng vá»›i thá»±c táº¿ má»›i. Nháº­n dáº¡ng hÃ¬nh áº£nh lÃ  cÃ¢u chuyá»‡n thÃ nh cÃ´ng, bá»Ÿi vÃ¬ con chÃ³ nÄƒm nay vá»›i nÄƒm sau thÆ°á»ng khÃ´ng thay Ä‘á»•i nhiá»u.\nChÃºng ta nÃªn chá»n cÃ¡i nÃ o Viá»‡c chá»n thuáº­t toÃ¡n dá»±a vÃ o váº¥n Ä‘á» chÃºng ta cáº§n giáº£i quyáº¿t. NgÃ y nay, viá»‡c chá»n sai ká»¹ thuáº­t Ä‘ang dáº§n trá»Ÿ nÃªn phá»• biáº¿n. NguyÃªn nhÃ¢n ráº¥t nhiá»u, cÃ³ thá»ƒ lÃ  do sá»± cÆ°á»ng Ä‘iá»‡u hoÃ¡ cá»§a ká»¹ thuáº­t Ä‘Ã³, hoáº·c sá»± thiáº¿u nháº­n thá»©c vá» bá»‘i cáº£nh cá»§a thuáº­t toÃ¡n AI. Khi báº¡n cáº§m trong tay má»™t cÃ¡i bÃºa, má»™t thá»© báº¯t báº¯t Ä‘áº§u giá»‘ng má»™t cÃ¡i Ä‘inh.\nKhi AI phÃ¡t triá»ƒn máº¡nh máº½ trong má»i khÃ­a cáº¡nh cá»§a cuá»™c sá»‘ng cá»§a chÃºng ta, cÃ¡c yÃªu cáº§u cho AI cÃ ng ngÃ y cÃ ng trá»Ÿ nÃªn phá»©c táº¡p hÆ¡n, ráº¥t cÃ³ kháº£ nÄƒng á»©ng dá»¥ng cá»§a chÃºng ta sáº½ cáº§n cáº£ hai ká»¹ thuáº­t nÃ y. Dá»¯ liá»‡u tiáº¿ng á»“n Ä‘Æ°á»£c thu tháº­p thÃ´ng qua cÃ¡c cáº£m biáº¿n cÃ³ thá»ƒ Ä‘Æ°á»£c xá»­ lÃ½ thÃ´ng qua ANN Ä‘á»ƒ suy ra thÃ´ng tin rá»i ráº¡c vá» mÃ´i trÆ°á»ng, trong khi thuáº­t toÃ¡n tsymbolic sá»­ dá»¥ng thÃ´ng tin Ä‘Ã³ Ä‘á»ƒ tÃ¬m kiáº¿m khÃ´ng gian cá»§a cÃ¡c hÃ nh Ä‘á»™ng kháº£ thi cÃ³ thá»ƒ dáº«n Ä‘áº¿n má»™t sá»‘ káº¿t luáº­n rÃµ rÃ ng hÆ¡n.\nMá»™t thuáº­t toÃ¡n há»c mÃ¡y cÃ³ thá»ƒ ráº¥t hiá»‡u quáº£ trong viá»‡c suy luáº­n mÃ´i trÆ°á»ng xung quanh cá»§a má»™t phÆ°Æ¡ng tiá»‡n cÃ¡ nhÃ¢n trong má»™t má»©c xÃ¡c suáº¥t nháº¥t Ä‘á»‹nh, nhÆ°ng kháº£ nÄƒng xáº£y ra sai sÃ³t lÃ  khÃ´ng thá»ƒ cháº¥p nháº­n Ä‘Æ°á»£c náº¿u sai sÃ³t Ä‘Ã³ cÃ³ thá»ƒ khiáº¿n chiáº¿c xe lao xuá»‘ng vá»±c, nguyÃªn nhÃ¢n lÃ  sai sÃ³t Ä‘Ã³ chÆ°a cÃ³ trá»ng training data. HÆ¡n ná»¯a, viá»‡c Ä‘Æ°a cÃ´ng nghá»‡ há»c sÃ¢u vÃ o cÃ¡c á»©ng dá»¥ng quan trá»ng Ä‘ang tá» ra lÃ  má»™t thÃ¡ch thá»©c, Ä‘áº·c biá»‡t lÃ  khi má»™t chiáº¿c xe tay ga bá»‹ nháº§m láº«n vá»›i má»™t chiáº¿c dÃ¹ khi nÃ³ bá»‹ láº­t ngá»­a.\nViá»‡c káº¿t há»£p vá»›i symbolic AI Ä‘áº£m báº£o ráº±ng nhá»¯ng gÃ¬ rÃµ rÃ ng vá» máº·t logic váº«n Ä‘Æ°á»£c thá»±c thi, ngay cáº£ khi lá»›p há»c sÃ¢u bÃªn dÆ°á»›i nÃ³i khÃ¡c Ä‘i do má»™t sá»‘ sai lá»‡ch thá»‘ng kÃª hoáº·c sá»‘ Ä‘á»c cáº£m biáº¿n nhiá»…u. Äiá»u nÃ y ngÃ y cÃ ng trá»Ÿ nÃªn quan trá»ng Ä‘á»‘i vá»›i cÃ¡c á»©ng dá»¥ng cÃ³ rá»§i ro cao, nhÆ° quáº£n lÃ½ nhÃ  mÃ¡y Ä‘iá»‡n, Ä‘iá»u Ä‘á»™ng tÃ u há»a, há»‡ thá»‘ng lÃ¡i tá»± Ä‘á»™ng vÃ  á»©ng dá»¥ng khÃ´ng gian. Há»‡ lá»¥y cá»§a viá»‡c phÃ¢n loáº¡i sai trong cÃ¡c há»‡ thá»‘ng nhÆ° váº­y nghiÃªm trá»ng hÆ¡n nhiá»u so vá»›i viá»‡c giá»›i thiá»‡u sai phim.\nMá»™t há»‡ thá»‘ng káº¿t há»£p sá»­ dá»¥ng cáº£ thuáº­t toÃ¡n connectionist vÃ  symbolic sáº½ táº­n dá»¥ng Ä‘iá»ƒm máº¡nh cá»§a cáº£ hai trong khi kháº¯c phá»¥c Ä‘iá»ƒm yáº¿u cá»§a nhau. CÃ¡c giá»›i háº¡n cá»§a viá»‡c sá»­ dá»¥ng má»™t ká»¹ thuáº­t riÃªng láº» Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh vÃ  nghiÃªn cá»©u má»›i nháº¥t Ä‘Ã£ báº¯t Ä‘áº§u chá»‰ ra ráº±ng viá»‡c káº¿t há»£p cáº£ hai phÆ°Æ¡ng phÃ¡p cÃ³ thá»ƒ dáº«n Ä‘áº¿n má»™t giáº£i phÃ¡p thÃ´ng minh hÆ¡n.\nHÆ°á»›ng phÃ¡t triá»ƒn tiáº¿p theo cá»§a AI Theo quy luáº­t tá»± nhiÃªn, cÃ¡i gÃ¬ Ä‘áº¡t má»©c Ä‘á»™ cá»±c thá»‹nh thÃ¬ lÃ  thá»i Ä‘iá»ƒm báº¯t Ä‘áº§u dáº«n tá»›i cá»±c suy, AI cÅ©ng khÃ´ng ngoáº¡i lá»‡, do Ä‘Ã³, theo phá»ng Ä‘oÃ¡n, AI cÃ³ thá»ƒ tiáº¿n hoÃ¡ theo cÃ¡c chiá»u hÆ°á»›ng sau:\nTiáº¿n hoÃ¡ cá»§a Symbolic AI Symbolic AI sáº½ tiáº¿n hoÃ¡ báº±ng má»™t cÃ¡ch nÃ o Ä‘Ã³, sáº½ quay láº¡i thá»‘ng trá»‹\nKáº¿t há»£p Symbolic AI vÃ  Connectionist AI Connectionist AI vÃ  Symbolic AI báº±ng má»™t cÃ¡ch nÃ o Ä‘Ã³ sáº½ káº¿t há»£p vá»›i nhau\nMá»™t hÆ°á»›ng Ä‘i má»›i khÃ¡c Ä‘Æ°á»£c khai phÃ¡ ra, vÃ  cáº¡nh trang sÃ²ng pháº³ng vá»›i Symbolic AI láº«n Connectionist AI Äiá»u nÃ y khÃ¡ khÃ³, nhÆ°ng khÃ´ng gÃ¬ lÃ  khÃ´ng thá»ƒ.\nDÃ¹ AI cÃ³ tiáº¿n hoÃ¡ nhÆ° tháº¿ nÃ o, chung quy láº¡i thÃ¬ chÃºng Ä‘Æ°á»£c táº¡o ra Ä‘á»ƒ phá»¥c vá»¥ nhu cáº§u vÃ  má»¥c Ä‘Ã­ch cá»§a con ngÆ°á»i.\nTham kháº£o https://towardsdatascience.com/symbolic-vs-connectionist-a-i-8cf6b656927\nhttps://blog.re-work.co/the-difference-between-symbolic-ai-and-connectionist-ai/\nhttps://medium.com/synthetic-intelligence/dialectic-of-ai-connectionism-vs-symbolism-d8b9888d4268\nhttps://www.forbes.com/sites/forbestechcouncil/2020/09/01/symbolism-versus-connectionism-in-ai-is-there-a-third-way/?sh=2f3074fb7549\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo\n","date":"Feb 18, 2023","img":"https://unsplash.it/1920/1080?image=16","permalink":"/blog/2023-02-18-symbolic-vs-connectionist/","series":null,"tags":["RFM","Recommendation","Marketing"],"title":"Symbolic AI VÃ  Connectionist AI"},{"categories":null,"content":" 1. Giá»›i thiá»‡u RFM 2. Giá»›i thiá»‡u data vÃ  tÃ¬m hiá»ƒu data 2.1 Giá»›i thiá»‡u data 2.2 Thá»±c hiá»‡n má»™t sá»‘ phÃ©p thá»‘ng kÃª trÃªn dá»¯ liá»‡u 2.3 PhÃ¢n tÃ­ch dá»¯ liá»‡u 2.3.1 TÃ­nh doanh thu theo thÃ¡ng 2.3.2 Thá»‘ng kÃª tÄƒng trÆ°á»Ÿng cá»§a doanh thu 2.3.3 PhÃ¢n tÃ­ch sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng thÃ¡ng 2.3.4 Sá»‘ Ä‘Æ¡n Ä‘áº·t hÃ ng trong thÃ¡ng 2.3.5 Doanh thu trung bÃ¬nh má»—i Ä‘Æ¡n hÃ ng 2.3.6 Sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng má»›i/ cÅ© theo tá»«ng thÃ¡ng 2.3.7 Tá»· lá»‡ tÄƒng trÆ°á»Ÿng khÃ¡ch hÃ ng má»›i 2.3.8 Tá»· lá»‡ giá»¯ chÃ¢n khÃ¡ch hÃ ng cÅ© hÃ ng thÃ¡ng 3. PhÃ¢n KhÃºc KhÃ¡ch HÃ ng 3.1 Clean data 3.1 TÃ­nh Recency 3.2 TÃ­nh Frequency 3.3 TÃ­nh Monetary 3.4 Táº¡o báº£ng RFM 3.5 PhÃ¢n nhÃ³m khÃ¡ch hÃ ng sá»­ dá»¥ng RFM Tham kháº£o 1. Giá»›i thiá»‡u RFM RFM lÃ  3 kÃ½ tá»± Ä‘áº§u tiÃªn cá»§a Recency, frequency, monetary. NÃ³ lÃ  cÃ´ng cá»¥ phÃ¢n tÃ­ch Ä‘Æ°á»£c marketing sá»­ dá»¥ng Ä‘á»ƒ Ä‘á»‹nh danh khÃ¡ch hÃ ng cá»§a cÃ´ng ty dá»±a trÃªn thÃ³i quen mua sáº¯m tá»± nhiÃªn cá»§a há».\nRFM phÃ¢n tÃ­ch vÃ  Ä‘Ã¡nh giÃ¡ khÃ¡ch hÃ ng báº±ng cÃ¡ch tÃ­nh Ä‘iá»ƒm hÃ nh vi mua sáº¯m cá»§a há» dá»±a trÃªn ba tiÃªu chÃ­:\nRecency: Khoáº£ng thá»i gian mua hÃ ng gáº§n nháº¥t lÃ  bao lÃ¢u. Náº¿u há» Ä‘Ã£ mua hÃ ng gáº§n Ä‘Ã¢y, xÃ¡c suáº¥t há» sáº½ mua thÃªm má»™t láº§n ná»¯a ráº¥t cao. Tuy nhiÃªn, náº¿u khÃ¡ch hÃ ng khÃ´ng thá»±c hiá»‡n báº¥t ká»³ má»™t giao dá»‹ch nÃ o trong má»™t khoáº£ng thá»i gian dÃ i, chÃºng ta cÃ³ thá»ƒ lÃ´i kÃ©o há» báº±ng má»™t offer Ä‘áº·c biá»‡t, hoáº·c giá»›i thiá»‡u láº¡i thÆ°Æ¡ng hiá»‡u cá»§a mÃ¬nh cho há».\nFrequency: Táº§n suáº¥t mua hÃ ng cá»§a khÃ¡ch hÃ ng. Náº¿u khÃ¡ch hÃ ng cÃ³ táº§ng suáº¥t mua dÃ y Ä‘áº·c, chÃºng ta sáº½ biáº¿t thÃ³i quen vÃ  sá»Ÿ thÃ­ch cá»§a há». Náº¿u há» chá»‰ mua má»™t láº§n vÃ  chÆ°a bao giá» trá»Ÿ láº¡i, há» cÃ³ thá»ƒ lÃ  má»™t á»©ng viÃªn tá»‘t Ä‘á»ƒ thá»±c hiá»‡n bÃ i kháº£o sÃ¡t sá»± hÃ i lÃ²ng cá»§a khÃ¡ch hÃ ng.\nMonetary: Sá»‘ tiá»n trung bÃ¬nh khÃ¡ch hÃ ng sá»­ dá»¥ng trÃªn má»—i giao dá»‹ch. Tuy nhiÃªn, Ä‘á»«ng quÃ¡ chÃº trá»ng vÃ o con sá»‘ nÃ y. Táº¥t cáº£ cÃ¡c giao dá»‹ch mua hÃ ng Ä‘á»u cÃ³ giÃ¡ trá»‹. Monetary tÃ¡c Ä‘á»™ng trá»±c tiáº¿p Ä‘áº¿n doanh thu cá»§a cÃ´ng ty, tÃ¡c Ä‘á»™ng giÃ¡n tiáº¿p vá»›i 2 chá»‰ sá»‘ á»Ÿ trÃªn kia. Náº¿u chÃºng ta gáº·p má»™t khÃ¡ch hÃ ng thá»±c hiá»‡n nhiá»u láº§n mua hÃ ng gáº§n Ä‘Ã¢y vá»›i má»©c giÃ¡ cao, nhá»¯ng ngÆ°á»i Ä‘Ã³ cÃ³ thá»ƒ lÃ  khÃ¡ch hÃ ng trung thÃ nh cá»§a chÃºng ta.\nRMF cÃ³ thang Ä‘iá»ƒm tá»« 1-5 ( 1 lÃ  tá»‡, 5 lÃ  tá»‘t) cá»§a má»—i khÃ¡ch hÃ ng cho má»—i tiÃªu chÃ­.\nRFM giÃºp cÃ´ng ty cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n nhá»¯ng khÃ¡ch hÃ ng nÃ o cÃ³ kháº£ nÄƒng cao sáº½ mua láº¡i sáº£n pháº©m cá»§a há», doanh thu Ä‘áº¿n tá»« khÃ¡ch hÃ ng má»›i lÃ  bao nhiÃªu, cÃ¡ch biáº¿n cÆ¡ há»™i mua hÃ ng thÃ nh thÃ³i quen.\n2. Giá»›i thiá»‡u data vÃ  tÃ¬m hiá»ƒu data 2.1 Giá»›i thiá»‡u data Dá»¯ liá»‡u á»Ÿ bÃ i viáº¿t nÃ y, chÃºng ta sáº½ sá»­ dá»¥ng tá»« nguá»“n https://www.kaggle.com/datasets/lissetteg/ecommerce-dataset.\nCode load cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n1 2# This Python 3 environment comes with many helpful analytics libraries installed 3# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python 4# For example, here\u0026#39;s several helpful packages to load in 5 6import numpy as np # linear algebra 7import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) 8 9# Input data files are available in the \u0026#34;../input/\u0026#34; directory. 10 11import time, warnings 12import datetime as dt 13 14#visualizations 15import matplotlib.pyplot as plt 16from pandas.plotting import scatter_matrix 17%matplotlib inline 18import seaborn as sns 19 20warnings.filterwarnings(\u0026#34;ignore\u0026#34;) Code load data vÃ  in ra 20 dÃ²ng Ä‘áº§u tiÃªn\n1 2#load the dataset 3retail_df = pd.read_csv(\u0026#39;../input/data.csv\u0026#39;,encoding=\u0026#34;ISO-8859-1\u0026#34;,dtype={\u0026#39;CustomerID\u0026#39;: str,\u0026#39;InvoiceID\u0026#39;: str}) 4retail_df.head(20) HÃ¬nh 1: Tá»•ng quan vá» dá»¯ liá»‡u\n2.2 Thá»±c hiá»‡n má»™t sá»‘ phÃ©p thá»‘ng kÃª trÃªn dá»¯ liá»‡u Sau khi nháº­n dá»¯ liá»‡u, chÃºng ta cáº§n xem xÃ©t sÆ¡ lÆ°á»£c tá»•ng quan vá» dá»¯ liá»‡u báº±ng má»™t sá»‘ hÃ m thá»‘ng kÃª cÆ¡ báº£n\n1 2print(retail_df.describe()) 3print(retail_df.info()) HÃ¬nh 2: PhÃ¢n tÃ­ch xÃ¡c suáº¥t vá» dá»¯ liá»‡u\nDá»±a vÃ o káº¿t quáº£ hÃ¬nh 2, chÃºng ta tháº¥y ráº±ng data cÃ³ tá»•ng cá»™ng 541909 dÃ²ng, 8 cá»™t, trong Ä‘Ã³ cÃ³ má»™t sá»‘ chá»— cÃ³ giÃ¡ trá»‹ null. Cá»™t CustomerID cÃ³ giÃ¡ trá»‹ null nhiá»u nháº¥t.\n2.3 PhÃ¢n tÃ­ch dá»¯ liá»‡u 2.3.1 TÃ­nh doanh thu theo thÃ¡ng Doanh thu cá»§a má»™t Ä‘Æ¡n hÃ ng báº±ng sá»‘ lÆ°á»£ng nhÃ¢n Ä‘Æ¡n giÃ¡.\nCÃ´ng viá»‡c cáº§n lÃ m:\nTáº¡o má»™t key chung Ä‘áº¡i diá»‡n cho biáº¿n thÃ¡ng trong nÄƒm ( á»Ÿ Ä‘Ã¢y mÃ¬nh Ä‘áº·t tÃªn lÃ  MonthKey) TÃ­nh doanh thu Group doanh thu theo thÃ¡ng In ra mÃ n hÃ¬nh doanh thu theo thÃ¡ng Váº½ chart doanh thu theo thÃ¡ng Äoáº¡n code máº«u mÃ´ táº£ cÃ¡c bÆ°á»›c cáº§n lÃ m á»Ÿ trÃªn\n1 2#converting the type of Invoice Date Field from string to datetime. 3retail_df[\u0026#39;InvoiceDate\u0026#39;] = pd.to_datetime(retail_df[\u0026#39;InvoiceDate\u0026#39;]) 4 5#creating MonthKey field for reporting and visualization 6retail_df[\u0026#39;MonthKey\u0026#39;] = retail_df[\u0026#39;InvoiceDate\u0026#39;].map(lambda date: 100*date.year + date.month) 7 8#calculate Revenue for each row and create a new dataframe with MonthKey - Revenue columns 9retail_df[\u0026#39;Revenue\u0026#39;] = retail_df[\u0026#39;UnitPrice\u0026#39;] * retail_df[\u0026#39;Quantity\u0026#39;] 10revenue_by_month = retail_df.groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;Revenue\u0026#39;].sum().reset_index() 11print(revenue_by_month) 12 13# plot data 14revenue_by_month[\u0026#39;MonthKey\u0026#39;] = revenue_by_month[\u0026#39;MonthKey\u0026#39;].apply(str) 15%matplotlib inline 16plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 17plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;Revenue\u0026#39;, data=revenue_by_month, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 18plt.title(\u0026#34;Revenue by Month\u0026#34;) 19plt.show() Káº¿t quáº£ chÃºng mÃ¬nh nháº­n Ä‘Æ°á»£c\n1 2 3\tMonthKey\tRevenue 40\t201012\t748957.020 51\t201101\t560000.260 62\t201102\t498062.650 73\t201103\t683267.080 84\t201104\t493207.121 95\t201105\t723333.510 106\t201106\t691123.120 117\t201107\t681300.111 128\t201108\t682680.510 139\t201109\t1019687.622 1410\t201110\t1070704.670 1511\t201111\t1461756.250 1612\t201112\t433668.010 HÃ¬nh 3: Doanh thu theo thÃ¡ng\nNhÃ¬n vÃ o hÃ¬nh 3 á»Ÿ trÃªn, chÃºng ta tháº¥y ráº±ng, doanh thu báº¯t Ä‘áº§u tÄƒng tá»« thÃ¡ng 8, Ä‘áº¡t Ä‘á»‰nh Ä‘iá»ƒm á»Ÿ thÃ¡ng 11, thÃ¡ng 12 doanh thu siÃªu tháº¥p, ngÃ³ qua thÃ¡ng 12 nÄƒm ngoÃ¡i thÃ¬ doanh thu khÃ¡ á»•n, nÃªn cÃ³ thá»ƒ táº¡m káº¿t luáº­n lÃ  data thÃ¡ng 12 nÄƒm hiá»‡n táº¡i cÃ³ thá»ƒ chÆ°a Ä‘á»§ thÃ¡ng. ChÃºng ta cÃ³ thá»ƒ bá» data thÃ¡ng 12 ra khá»i dataset Ä‘á»ƒ trÃ¡nh bá»‹ nhiá»…u.\n2.3.2 Thá»‘ng kÃª tÄƒng trÆ°á»Ÿng cá»§a doanh thu Äá»ƒ tÃ­nh tÄƒng trÆ°á»Ÿng doanh thu, ta láº¥y doanh thu thÃ¡ng hiá»‡n táº¡i chia cho doanh thu thÃ¡ng trÆ°á»›c -1\nTrong pandas, chÃºng ta sá»­ dá»¥ng hÃ m pct_change\n1 2revenue_by_month[\u0026#39;MonthlyGrowth\u0026#39;] = revenue_by_month[\u0026#39;Revenue\u0026#39;].pct_change() 3 4 5# Plot data 6 7plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 8plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;MonthlyGrowth\u0026#39;, data=revenue_by_month, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 9plt.plot(range(1,len(revenue_by_month.index)+1),[0 for i in range(len(revenue_by_month.index))], color=\u0026#34;k\u0026#34;, lw=2.5) 10plt.title(\u0026#34;Monthly Revenue Growth Rate\u0026#34;) 11plt.show() HÃ¬nh 4: Biáº¿n Ä‘á»™ng doanh thu theo thÃ¡ng\nQua sÆ¡ Ä‘á»“ hÃ¬nh 4, chÃºng ta tháº¥y ráº±ng á»Ÿ thÃ¡ng 4 cÃ³ sá»± sá»¥t giáº£m máº¡nh vá» doanh thu, nhÃ³m kinh doanh cáº§n pháº£i phÃ¢n tÃ­ch ká»¹ hÆ¡n cÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n sá»± sá»¥t giáº£m nghiÃªm trá»ng vá» máº·t doanh thu trong thÃ¡ng nÃ y.\n2.3.3 PhÃ¢n tÃ­ch sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng thÃ¡ng Äá»ƒ tÃ­nh lÆ°á»£t khÃ¡ch mua hÃ ng háº±ng thÃ¡ng, chÃºng ta Ä‘áº¿m khÃ´ng trÃ¹ng mÃ£ khÃ¡ch hÃ ng trong thÃ¡ng\n1 2customer_by_month = retail_df.groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;CustomerID\u0026#39;].nunique().reset_index() 3customer_by_month 4 5 6customer_by_month[\u0026#39;MonthKey\u0026#39;] = customer_by_month[\u0026#39;MonthKey\u0026#39;].apply(str) 7%matplotlib inline 8plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 9plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;CustomerID\u0026#39;, data=customer_by_month, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 10plt.title(\u0026#34;Customer by Month\u0026#34;) 11plt.show() 1 2 3\tMonthKey\tCustomerID 40\t201012\t948 51\t201101\t783 62\t201102\t798 73\t201103\t1020 84\t201104\t899 95\t201105\t1079 106\t201106\t1051 117\t201107\t993 128\t201108\t980 139\t201109\t1302 1410\t201110\t1425 1511\t201111\t1711 1612\t201112\t686 HÃ¬nh 5: LÆ°á»£t khÃ¡ch theo thÃ¡ng\nNháº­n xÃ©t ráº±ng, lÆ°á»£t khÃ¡ch tÄƒng tá»« thÃ¡ng 8 trá»Ÿ vá» sau, tá»« thÃ¡ng 5 Ä‘áº¿n thÃ¡ng 8 thÃ¬ lÆ°á»£t khÃ¡ch giáº£m nháº¹, Ä‘á»u. ThÃ¡ng 1 vÃ  2 lÆ°á»£t khÃ¡ch ráº¥t tháº¥p.\n2.3.4 Sá»‘ Ä‘Æ¡n Ä‘áº·t hÃ ng trong thÃ¡ng CÅ©ng giá»‘ng nhÆ° lÆ°á»£t khÃ¡ch, chÃºng ta sáº½ Ä‘áº¿m sá»‘ lÆ°á»£ng InvoiceNo trong tá»«ng thÃ¡ng\n1 2order_by_month = retail_df.groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;InvoiceNo\u0026#39;].count().reset_index() 3order_by_month 4order_by_month[\u0026#39;MonthKey\u0026#39;] = order_by_month[\u0026#39;MonthKey\u0026#39;].apply(str) 5%matplotlib inline 6plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 7plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;InvoiceNo\u0026#39;, data=order_by_month, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 8plt.title(\u0026#34;Count total order in Month\u0026#34;) 9plt.show() HÃ¬nh 6: Sá»‘ lÆ°á»£ng Ä‘Æ¡n Ä‘áº·t hÃ ng trong thÃ¡ng\nTá»« thÃ¡ng 5 Ä‘áº¿n thÃ¡ng 7, sá»‘ lÆ°á»£ng Ä‘Æ¡n Ä‘áº·t hÃ ng tÄƒng nháº¹, tá»· lá»‡ nghá»‹ch vá»›i lÆ°á»£t khÃ¡ch\nTá»« thÃ¡ng 8 trá»Ÿ Ä‘i, sá»‘ Ä‘Æ¡n Ä‘áº·t hÃ ng tÄƒng cao, tá»· lá»‡ thuáº­n vá»›i lÆ°á»£t khÃ¡ch\n2.3.5 Doanh thu trung bÃ¬nh má»—i Ä‘Æ¡n hÃ ng Trong pandas, chÃºng ta chá»‰ cáº§n gá»i hÃ m mean Ä‘á»ƒ tÃ­nh trung bÃ¬nh\n1 2avg_order_revenue = retail_df.groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;Revenue\u0026#39;].mean().reset_index() 3 4avg_order_revenue[\u0026#39;MonthKey\u0026#39;] = avg_order_revenue[\u0026#39;MonthKey\u0026#39;].apply(str) 5 6# Plot regression line 7 8plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 9plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;Revenue\u0026#39;, data=avg_order_revenue, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 10plt.title(\u0026#34;Average Revenue per Order\u0026#34;) 11plt.show() HÃ¬nh 7: Doanh thu trung bÃ¬nh má»—i Ä‘Æ¡n hÃ ng\nNháº­n xÃ©t ráº±ng, thÃ¡ng 10, 11, lÆ°á»£t khÃ¡ch tÄƒng, sá»‘ lÆ°á»£ng Ä‘Æ¡n hÃ ng tÄƒng, nhÆ°ng trung bÃ¬nh má»—i Ä‘Æ¡n hÃ ng láº¡i tháº¥p.\n2.3.6 Sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng má»›i/ cÅ© theo tá»«ng thÃ¡ng KhÃ¡ch hÃ ng má»›i vÃ  khÃ¡ch hÃ ng cÅ© Ä‘á»u Ä‘Ã³ng vai trÃ² ráº¥t quan trá»ng trong chiáº¿n lÆ°á»£c marketing. Viá»‡c giá»¯ chÃ¢n khÃ¡ch hÃ ng cÅ© giÃºp chÃºng ta hiá»ƒu hÆ¡n vá» há» vÃ  phá»¥c vá»¥ há» tá»‘t hÆ¡n. Viá»‡c phÃ¡t triá»ƒn khÃ¡ch hÃ ng má»›i giÃºp chÃºng ta phÃ¡t triá»ƒn lá»›n lÃªn.\nTrong ngá»¯ cáº£nh bÃ i nÃ y, chÃºng ta sáº½ xÃ©t yáº¿u tá»‘t khÃ¡ch hÃ ng má»›i/cÅ© nhÆ° sau\nKhÃ¡ch hÃ ng má»›i lÃ  khÃ¡ch hÃ ng trÆ°á»›c Ä‘Ã³ chÆ°a tá»«ng mua hÃ ng. KhÃ´ng quan tÃ¢m thÃ¡ng hiá»‡n táº¡i khÃ¡ch Ä‘Ã£ mua bao nhiÃªu Ä‘Æ¡n.\nKhÃ¡ch hÃ ng cÅ© lÃ  khÃ¡ch hÃ ng Ä‘Ã£ mua Ã­t nháº¥t 1 Ä‘Æ¡n hÃ ng á»Ÿ thÃ¡ng trÆ°á»›c Ä‘Ã³.\nDo Ä‘Æ¡n vá»‹ chÃºng ta thá»‘ng kÃª tÃ­nh báº±ng thÃ¡ng, cho nÃªn náº¿u 1 khÃ¡ch hÃ ng cÃ³ mua 2 hoáº·c nhiá»u hÆ¡n Ä‘Æ¡n hÃ ng á»Ÿ thÃ¡ng hiá»‡n táº¡i, chÆ°a tá»«ng mua Ä‘Æ¡n hÃ ng nÃ o á»Ÿ cÃ¡c thÃ¡ng trÆ°á»›c Ä‘Ã³, khÃ¡ch hÃ ng Ä‘Ã³ Ä‘Æ°á»£c coi lÃ  khÃ¡ch hÃ ng má»›i.\nKá»¹ thuáº­t láº­p trÃ¬nh á»Ÿ Ä‘Ã¢y nhÆ° sau:\nLáº¥y ra danh sÃ¡ch khÃ¡ch hÃ ng vÃ  ngÃ y mua hÃ ng Ä‘áº§u tiÃªn cá»§a há»\nQuy Ä‘á»•i ngÃ y mua hÃ ng Ä‘áº§u tiÃªn thÃ nh thÃ¡ng mua hÃ ng Ä‘áº§u tiÃªn\nTáº¡o thÃªm cá»™t loáº¡i khÃ¡ch hÃ ng cho tá»«ng Ä‘Æ¡n hÃ ng (UserType). GÃ¡n máº·c Ä‘á»‹nh UserType = New. Náº¿u thÃ¡ng lÃªn Ä‘Æ¡n lá»›n hÆ¡n thÃ¡ng mua Ä‘áº§u tiÃªn -\u0026gt; Ä‘Æ¡n hÃ ng cá»§a khÃ¡ch cÅ© (UserType=Existing).\n1 2create a dataframe contaning CustomerID and first purchase date 3df_min_date_purchase =retail_df.groupby(\u0026#39;CustomerID\u0026#39;).InvoiceDate.min().reset_index() 4df_min_date_purchase.columns = [\u0026#39;CustomerID\u0026#39;,\u0026#39;MinPurchaseDate\u0026#39;] 5df_min_date_purchase[\u0026#39;MinMonthKey\u0026#39;] = df_min_date_purchase[\u0026#39;MinPurchaseDate\u0026#39;].map(lambda date: 100*date.year + date.month) 6 7#merge first purchase date column to our main dataframe (tx_uk) 8retail_new_df = pd.merge(retail_df, df_min_date_purchase, on=\u0026#39;CustomerID\u0026#39;) 9 10retail_new_df.head() 11 12#create a column called User Type and assign Existing 13#if User\u0026#39;s First Purchase Year Month before the selected Invoice Year Month 14retail_new_df[\u0026#39;UserType\u0026#39;] = \u0026#39;New\u0026#39; 15retail_new_df.loc[retail_new_df[\u0026#39;MonthKey\u0026#39;]\u0026gt;retail_new_df[\u0026#39;MinMonthKey\u0026#39;],\u0026#39;UserType\u0026#39;] = \u0026#39;Existing\u0026#39; 16 17#calculate the Revenue per month for each user type 18revenue_per_month = retail_new_df.groupby([\u0026#39;MonthKey\u0026#39;,\u0026#39;UserType\u0026#39;])[\u0026#39;Revenue\u0026#39;].sum().reset_index() 19 20#filtering the dates and plot the result 21revenue_per_month = revenue_per_month.query(\u0026#34;MonthKey != 201012 and MonthKey != 201112\u0026#34;) 22 23revenue_per_month[\u0026#39;MonthKey\u0026#39;] = revenue_per_month[\u0026#39;MonthKey\u0026#39;].apply(str) 24revenue_per_month.set_index(\u0026#39;MonthKey\u0026#39;,inplace=True) 25# Plot regression line 26 27plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 28fig, ax = plt.subplots() 29for label, grp in revenue_per_month.groupby(\u0026#39;UserType\u0026#39;): 30 grp.plot(x = grp.index, y = \u0026#39;Revenue\u0026#39;,ax = ax, label = label,style=\u0026#39;.-\u0026#39;) 31plt.title(\u0026#34;Old and New user\u0026#34;) 32plt.show() HÃ¬nh 8: Sá»‘ lÆ°á»£ng khÃ¡ch hÃ ng má»›i/ cÅ© theo tá»«ng thÃ¡ng\nNháº­n xÃ©t ráº±ng, doanh thu cho khÃ¡ch cÅ© tÄƒng dáº§n theo thá»i gian, cÃ²n doanh thu cho khÃ¡ch má»›i cÃ³ váº» giáº£m. Äá»ƒ cháº¯c cháº¯n, chÃºng ta thá»­ váº½ ra tá»· lá»‡ tÄƒng trÆ°á»Ÿng khÃ¡ch hÃ ng má»›i xem sao\n2.3.7 Tá»· lá»‡ tÄƒng trÆ°á»Ÿng khÃ¡ch hÃ ng má»›i Ta tÃ­nh tá»· lá»‡ khÃ¡ch hÃ ng má»›i / khÃ¡ch hÃ ng cÅ© theo tá»«ng thÃ¡ng\nTrong pandas, chÃºng ta sáº½ sá»­ dá»¥ng hÃ m crosstab\n1 2new_user_ratio = retail_new_df.query(\u0026#34;UserType == \u0026#39;New\u0026#39;\u0026#34;).groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;CustomerID\u0026#39;].nunique()/retail_new_df.query(\u0026#34;UserType == \u0026#39;Existing\u0026#39;\u0026#34;).groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;CustomerID\u0026#39;].nunique() 3new_user_ratio = new_user_ratio.reset_index() 4new_user_ratio = new_user_ratio.dropna() 5new_user_ratio.columns = [\u0026#34;MonthKey\u0026#34;,\u0026#34;NewCustomerRatio\u0026#34;] 6 7new_user_ratio = new_user_ratio.query(\u0026#34;MonthKey != 201012 and MonthKey != 201112\u0026#34;) 8new_user_ratio[\u0026#39;MonthKey\u0026#39;] = new_user_ratio[\u0026#39;MonthKey\u0026#39;].apply(str) 9 10# Plot regression line 11 12plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 13plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;NewCustomerRatio\u0026#39;, data=new_user_ratio, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 14plt.title(\u0026#34;New Customer Ratio\u0026#34;) 15plt.show() HÃ¬nh 9: Tá»· lá»‡ tÄƒng trÆ°á»Ÿng khÃ¡ch hÃ ng má»›i\nNhÆ° hÃ¬nh trÃªn, chÃºng ta tháº¥y ráº±ng tá»· lá»‡ khÃ¡ch hÃ ng má»›i / khÃ¡ch hÃ ng cÅ© giáº£m dáº§n theo thá»i gian\n2.3.8 Tá»· lá»‡ giá»¯ chÃ¢n khÃ¡ch hÃ ng cÅ© hÃ ng thÃ¡ng KhÃ¡ch hÃ ng cÅ© Ä‘Æ°á»£c hiá»ƒu theo nghÄ©a lÃ  khÃ¡ch hÃ ng thÃ¡ng trÆ°á»›c cÃ³ mua, thÃ¡ng nÃ y cÃ³ mua\nTá»· lá»‡ giá»¯ chÃ¢n khÃ¡ch hÃ ng lÃ  tá»· lá»‡ khÃ¡ch hÃ ng cÅ© mua hÃ ng / tá»•ng khÃ¡ch hÃ ng trong thÃ¡ng\nChÃºng ta sá»­ dá»¥ng hÃ m crosstab trÃªn khÃ¡ch hÃ ng vÃ  thÃ¡ng, Ä‘á»ƒ xem thá»­ thÃ¡ng Ä‘Ã³ khÃ¡ch cÃ³ mua hÃ ng hay khÃ´ng.\n1#identify which users are active by looking at their revenue per month 2df_user_purchase = retail_df.groupby([\u0026#39;CustomerID\u0026#39;,\u0026#39;MonthKey\u0026#39;])[\u0026#39;Revenue\u0026#39;].sum().reset_index() 3 4#create retention matrix with crosstab 5df_retention = pd.crosstab(df_user_purchase[\u0026#39;CustomerID\u0026#39;], df_user_purchase[\u0026#39;MonthKey\u0026#39;]).reset_index() 6 7print(df_retention.head()) 8 9#create an array of dictionary which keeps Retained \u0026amp; Total User count for each month 10months = df_retention.columns[2:] 11retention_array = [] 12for i in range(len(months)-1): 13 retention_data = {} 14 selected_month = months[i+1] 15 prev_month = months[i] 16 retention_data[\u0026#39;MonthKey\u0026#39;] = int(selected_month) 17 retention_data[\u0026#39;TotalUserCount\u0026#39;] = df_retention[selected_month].sum() 18 retention_data[\u0026#39;RetainedUserCount\u0026#39;] = df_retention[(df_retention[selected_month]\u0026gt;0) \u0026amp; (df_retention[prev_month]\u0026gt;0)][selected_month].sum() 19 retention_array.append(retention_data) 20 21#convert the array to dataframe and calculate Retention Rate 22df_retention = pd.DataFrame(retention_array) 23df_retention[\u0026#39;RetentionRate\u0026#39;] = df_retention[\u0026#39;RetainedUserCount\u0026#39;]/df_retention[\u0026#39;TotalUserCount\u0026#39;] 24 25df_retention = df_retention.query(\u0026#34;MonthKey != 201012 and MonthKey != 201112\u0026#34;) 26df_retention[\u0026#39;MonthKey\u0026#39;] = df_retention[\u0026#39;MonthKey\u0026#39;].apply(str) 27 28# Plot regression line 29 30plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 31plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;RetentionRate\u0026#39;, data=df_retention, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 32plt.title(\u0026#34;Monthly Retention Rate\u0026#34;) 33plt.show() Káº¿t quáº£\n1# hÃ m crosstab tráº£ ra ma tráº­n tÆ°Æ¡ng quan giá»¯a khÃ¡ch hÃ ng vÃ  thÃ¡ng, vÃ­ dá»¥ nhÆ° khÃ¡ch hÃ ng 12346 thÃ¡ng 201012 khÃ´ng cÃ³ mua hÃ ng, nhÆ°ng 201101 láº¡i cÃ³ 2\u0026gt;\u0026gt; print(df_retention.head()) 3MonthKey CustomerID 201012 201101 201102 201103 201104 201105 201106 \\ 40 12346 0 1 0 0 0 0 0 51 12347 1 1 0 0 1 0 1 62 12348 1 1 0 0 1 0 0 73 12349 0 0 0 0 0 0 0 84 12350 0 0 1 0 0 0 0 9 10MonthKey 201107 201108 201109 201110 201111 201112 110 0 0 0 0 0 0 121 0 1 0 1 0 1 132 0 0 1 0 0 0 143 0 0 0 0 1 0 154 0 0 0 0 0 0 HÃ¬nh 10: Tá»· lá»‡ giá»¯ chÃ¢n khÃ¡ch hÃ ng cÅ©\nNhÃ¬n hÃ¬nh, ta tháº¥y ráº±ng khÃ¡ch hÃ ng cÅ© mua láº¡i khÃ¡ nhiá»u á»Ÿ giai Ä‘oáº¡n thÃ¡ng 6 Ä‘áº¿n thÃ¡ng 8, sau Ä‘Ã³ tá»· lá»‡ láº¡i trá»Ÿ láº¡i bÃ¬nh thÆ°á»ng.\n3. PhÃ¢n KhÃºc KhÃ¡ch HÃ ng á» má»¥c trÃªn, chÃºng ta Ä‘Ã£ phÃ¢n tÃ­ch dá»¯ liá»‡u cá»§a cÃ´ng ty bÃ¡n láº» trá»±c tuyáº¿n vÃ  tÃ¬m ra yáº¿u tá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n doanh thu cá»§a cÃ´ng ty. á» má»¥c nÃ y, chÃºng ta sáº½ tiáº¿n hÃ nh phÃ¢n loáº¡i khÃ¡ch hÃ ng theo nhÃ³m, Ä‘á»ƒ phá»¥c vá»¥ cho nhu cáº§u marketing sau nÃ y.\nChÃºng ta pháº£i tiáº¿n hÃ nh phÃ¢n loáº¡i khÃ¡ch hÃ ng, bá»Ÿi vÃ¬ chÃºng ta khÃ´ng thá»ƒ Ä‘á»‘i xá»­ vá»›i táº¥t cáº£ khÃ¡ch hÃ ng giá»‘ng nhau Ä‘Æ°á»£c. VÃ­ dá»¥ lÃ  khÃ´ng thá»ƒ gá»­i chiáº¿n dá»‹ch marketing vá» thá»‹t cho ngÆ°á»i Äƒn chay. Hoáº·c bÃ¡n lÆ°á»£c cho nhÃ  sÆ° (Ä‘Ã¢y lÃ  vÃ­ dá»¥ minh hoáº¡ cá»§a mÃ¬nh nha, cÃ²n trÃªn cÃ³ vÃ i case-study vá» bÃ¡n cÃ¡c sáº£n pháº©m Ä‘Ã³ cho Ä‘á»‘i tÆ°á»£ng Ä‘Ã³, mÃ¬nh khÃ´ng nÃ³i vá» nhá»¯ng trÆ°á»ng há»£p Ä‘Ã³ nha).\ná» pháº§n nÃ y, chÃºng ta sáº½ tÃ¬m hiá»ƒu nhu cáº§u khÃ¡ch hÃ ng sá»­ dá»¥ng mÃ´ hÃ¬nh RFB.\nNhÆ° Ä‘Ã£ Ä‘á» cáº­p á»Ÿ má»¥c 1, mÃ´ hÃ¬nh RFB bao gá»“m Recency, Frequency and Monetary\n3.1 Clean data Äá»ƒ mÃ´ hÃ¬nh chÃ­nh xÃ¡c hÆ¡n, chÃºng ta sáº½ clean data, tráº£i qua cÃ¡c bÆ°á»›c sau:\nLoáº¡i ra cÃ¡c Ä‘Æ¡n hÃ ng cÃ³ Quantity \u0026lt;=0\nLoáº¡i bá» nhá»¯ng Ä‘Æ¡n hÃ ng CustomerID NA\nLoáº¡i bá» nhá»¯ng Ä‘Æ¡n hÃ ng bÃ¡n thÃ¡ng 12 nÄƒm 2010\nLoáº¡i bá» nhá»¯ng Ä‘Æ¡n hÃ ng bÃ¡n thÃ¡ng 12 nÄƒm 2011, do phÃ¢n tÃ­ch á»Ÿ trÃªn lÃ  data thÃ¡ng 12 khÃ´ng Ä‘á»§.\n1retail_rfm_df = retail_df.copy() 2#remove canceled orders 3retail_rfm_df = retail_rfm_df[retail_rfm_df[\u0026#39;Quantity\u0026#39;]\u0026gt;0] 4#remove rows where customerID are NA 5retail_rfm_df.dropna(subset=[\u0026#39;CustomerID\u0026#39;],how=\u0026#39;all\u0026#39;,inplace=True) 6retail_rfm_df = retail_rfm_df[retail_rfm_df[\u0026#39;InvoiceDate\u0026#39;]\u0026gt; \u0026#34;2010-12-31\u0026#34;] 7retail_rfm_df = retail_rfm_df[retail_rfm_df[\u0026#39;InvoiceDate\u0026#39;]\u0026lt; \u0026#34;2011-12-01\u0026#34;] 3.1 TÃ­nh Recency Äá»ƒ tÃ­nh thÃ´ng sá»‘ nÃ y, chÃºng ta cáº§n tÃ¬m ra ngÃ y mua gáº§n nháº¥t cá»§a khÃ¡ch hÃ ng, vÃ  sá»‘ ngÃ y khÃ´ng mua hÃ ng, ká»ƒ tá»« ngÃ y mua cuá»‘i Ä‘áº¿n hiá»‡n táº¡i.\nKá»¹ thuáº­t láº­p trÃ¬nh á»Ÿ Ä‘Ã¢y:\nGÃ¡n ngÃ y hiá»‡n táº¡i lÃ  ngÃ y 30 thÃ¡ng 11 nÄƒm 2011\nLáº¥y ra ngÃ y mua hÃ ng cuá»‘i cÃ¹ng cá»§a má»—i user\nTÃ­nh ra khoáº£ng thá»i gian ká»ƒ tá»« láº§n mua hÃ ng cuá»‘i cÃ¹ng Ä‘áº¿n thá»i Ä‘iá»ƒm hiá»‡n táº¡i\n1now = dt.date(2011,11,30) 2#create a new column called date which contains the date of invoice only 3retail_rfm_df[\u0026#39;date\u0026#39;] = pd.DatetimeIndex(retail_rfm_df[\u0026#39;InvoiceDate\u0026#39;]).date 4 5#group by customers and check last date of purshace 6recency_df = retail_rfm_df.groupby(by=\u0026#39;CustomerID\u0026#39;, as_index=False)[\u0026#39;date\u0026#39;].max() 7recency_df.columns = [\u0026#39;CustomerID\u0026#39;,\u0026#39;LastPurshaceDate\u0026#39;] 8 9#calculate recency 10recency_df[\u0026#39;Recency\u0026#39;] = recency_df[\u0026#39;LastPurshaceDate\u0026#39;].apply(lambda x: (now - x).days) 11recency_df.drop(\u0026#39;LastPurshaceDate\u0026#39;,axis=1,inplace=True) 12print(recency_df.head()) Káº¿t quáº£\n1\u0026gt;\u0026gt; recency_df.head() 2 CustomerID Recency 30 12346 316 41 12347 30 52 12348 66 63 12349 9 74 12350 301 8 9\u0026gt;\u0026gt; recency_df.Recency.describe() 10count 4174.000000 11mean 82.557499 12std 88.535941 13min 0.000000 1425% 15.000000 1550% 45.000000 1675% 128.000000 17max 330.000000 Chá»‰ sá»‘ thá»‘ng kÃª cho tháº¥y, giÃ¡ trá»‹ trung bÃ¬nh cá»§a Recency lÃ  82, 50% ngÆ°á»i dÃ¹ng láº·p láº¡i chu ká»³ mua hÃ ng trong vÃ²ng 45 ngÃ y\n3.2 TÃ­nh Frequency Táº§n suáº¥t giÃºp chÃºng ta biáº¿t Ä‘Æ°á»£c khÃ¡ch hÃ ng Ä‘Ã£ mua hÃ ng bao nhiÃªu láº§n\nKá»¹ thuáº­t láº­p trÃ¬nh á»Ÿ Ä‘Ã¢y khÃ¡ Ä‘Æ¡n giáº£n, gom nhÃ³m Ä‘Æ¡n hÃ ng theo user vÃ  Ä‘áº¿m\n1 2# drop duplicates 3retail_rfm_df_copy = retail_rfm_df 4retail_rfm_df_copy.drop_duplicates(subset=[\u0026#39;InvoiceNo\u0026#39;, \u0026#39;CustomerID\u0026#39;], keep=\u0026#34;first\u0026#34;, inplace=True) 5#calculate frequency of purchases 6frequency_df = retail_rfm_df_copy.groupby(by=[\u0026#39;CustomerID\u0026#39;], as_index=False)[\u0026#39;InvoiceNo\u0026#39;].count() 7frequency_df.columns = [\u0026#39;CustomerID\u0026#39;,\u0026#39;Frequency\u0026#39;] 8frequency_df.head() Káº¿t quáº£\n1\tCustomerID\tFrequency 20\t12346\t1 31\t12347\t5 42\t12348\t3 53\t12349\t1 64\t12350\t1 3.3 TÃ­nh Monetary Monetary lÃ  tá»•ng tiá»n khÃ¡ch hÃ ng Ä‘Ã£ sá»­ dá»¥ng\nDo Ä‘Ã£ tÃ­nh doanh thu tá»« trÆ°á»›c, nÃªn giá» chÃºng ta sá»­ dá»¥ng láº¡i, chá»‰ cáº§n gom nhÃ³m theo mÃ£ khÃ¡ch hÃ ng lÃ  Ä‘Æ°á»£c\n1 2monetary_df = retail_rfm_df.groupby([\u0026#39;CustomerID\u0026#39;])[\u0026#39;Revenue\u0026#39;].sum().reset_index() 3monetary_df.columns = [\u0026#39;CustomerID\u0026#39;,\u0026#39;Monetary\u0026#39;] 4monetary_df.head() Káº¿t quáº£\n1\tCustomerID\tMonetary 20\t12346\t77183.60 31\t12347\t120.56 42\t12348\t291.76 53\t12349\t15.00 64\t12350\t25.20 3.4 Táº¡o báº£ng RFM CÃ¡i nÃ y thÃ¬ siÃªu Ä‘Æ¡n giáº£n, chÃºng ta merge 3 báº£ng trÃªn láº¡i lÃ  xong\n1 2#merge recency dataframe with frequency dataframe 3temp_df = recency_df.merge(frequency_df,on=\u0026#39;CustomerID\u0026#39;) 4#merge with monetary dataframe to get a table with the 3 columns 5rfm_df = temp_df.merge(monetary_df,on=\u0026#39;CustomerID\u0026#39;) 6#use CustomerID as index 7rfm_df.set_index(\u0026#39;CustomerID\u0026#39;,inplace=True) 8#check the head 9rfm_df.head() Káº¿t quáº£\n1 2\tRecency\tFrequency\tMonetary 3CustomerID 412346\t316\t1\t77183.60 512347\t30\t5\t120.56 612348\t66\t3\t291.76 712349\t9\t1\t15.00 812350\t301\t1\t25.20 3.5 PhÃ¢n nhÃ³m khÃ¡ch hÃ ng sá»­ dá»¥ng RFM CÃ¡ch Ä‘Æ¡n giáº£n nháº¥t Ä‘á»ƒ phÃ¢n nhÃ³m khÃ¡ch hÃ ng lÃ  sá»­ dá»¥ng Quartiles. ChÃºng ta cÃ³ thá»ƒ chia táº­p khÃ¡ch hÃ ng thÃ nh 3 hoáº·c 4 hoáº·c 5 nhÃ³m gÃ¬ Ä‘Ã³, tuá»³ má»¥c Ä‘Ã­ch kinh doanh.\ná» Ä‘Ã¢y, giáº£ sá»­ mÃ¬nh chia lÃ m 4 nhÃ³m, sá»­ dÃ¹ng hÃ m quantile cá»§a pandas\nKá»¹ thuáº­t láº­p trÃ¬nh nhÆ° sau:\nChia cÃ¡c giÃ¡ trá»‹ cá»§a Recency, Frequency, Monetary thÃ nh 4 nhÃ³m, cÃ³ miá»n giÃ¡ trá»‹ tá»« 0 Ä‘áº¿n 3, Ä‘Æ°á»£c 4 cÃ¡i pháº§n tÆ° vá»‹ cho má»—i nhÃ³m\nGiÃ¡ trá»‹ Recency cÃ ng nhá» cÃ ng tá»‘t, trong khi Ä‘Ã³, giÃ¡ trá»‹ Frequency vÃ  Monetary cÃ ng lá»›n cÃ ng tá»‘t, Ä‘á»ƒ thá»‘ng nháº¥t chung, chÃºng ta sáº½ Ä‘á»•i dáº¥u cá»§a Recency, Ä‘á»ƒ cáº£ 3 cÃ¹ng thoáº£ tÃ­nh cháº¥t cÃ ng lá»›n cÃ ng tá»‘t.\n1 2#RFM Quartiles 3rfm_df[\u0026#39;Recency\u0026#39;] = -rfm_df[\u0026#39;Recency\u0026#39;] 4quantiles = rfm_df.quantile(q=[0.25,0.5,0.75]) 5print(quantiles) 6quantiles.to_dict() 7 8### Creation of RFM Segments 9 10# Arguments (x = value, p = recency, monetary_value, frequency, k = quartiles dict) 11def FMScore(x,p,d): 12 if x \u0026lt;= d[p][0.25]: 13 return 0 14 elif x \u0026lt;= d[p][0.50]: 15 return 1 16 elif x \u0026lt;= d[p][0.75]: 17 return 2 18 else: 19 return 3 20 21#create rfm segmentation table 22rfm_segmentation = rfm_df 23rfm_segmentation[\u0026#39;R_Quartile\u0026#39;] = rfm_segmentation[\u0026#39;Recency\u0026#39;].apply(FMScore, args=(\u0026#39;Recency\u0026#39;,quantiles,)) 24rfm_segmentation[\u0026#39;F_Quartile\u0026#39;] = rfm_segmentation[\u0026#39;Frequency\u0026#39;].apply(FMScore, args=(\u0026#39;Frequency\u0026#39;,quantiles,)) 25rfm_segmentation[\u0026#39;M_Quartile\u0026#39;] = rfm_segmentation[\u0026#39;Monetary\u0026#39;].apply(FMScore, args=(\u0026#39;Monetary\u0026#39;,quantiles,)) 26 27rfm_segmentation.head() 28 29 30rfm_segmentation[\u0026#39;RFMScore\u0026#39;] = rfm_segmentation.R_Quartile.map(str) \\ 31 + rfm_segmentation.F_Quartile.map(str) \\ 32 + rfm_segmentation.M_Quartile.map(str) 33rfm_segmentation.head() 34 35 36#How many customers do we have in each segment? 37 38print(\u0026#34;Best Customers: \u0026#34;,len(rfm_segmentation[rfm_segmentation[\u0026#39;RFMScore\u0026#39;]==\u0026#39;333\u0026#39;])) 39print(\u0026#39;Loyal Customers: \u0026#39;,len(rfm_segmentation[rfm_segmentation[\u0026#39;F_Quartile\u0026#39;]==3])) 40print(\u0026#34;Big Spenders: \u0026#34;,len(rfm_segmentation[rfm_segmentation[\u0026#39;M_Quartile\u0026#39;]==3])) 41print(\u0026#39;Almost Lost: \u0026#39;, len(rfm_segmentation[rfm_segmentation[\u0026#39;RFMScore\u0026#39;]==\u0026#39;133\u0026#39;])) 42print(\u0026#39;Lost Customers: \u0026#39;,len(rfm_segmentation[rfm_segmentation[\u0026#39;RFMScore\u0026#39;]==\u0026#39;033\u0026#39;])) 43print(\u0026#39;Lost Cheap Customers: \u0026#39;,len(rfm_segmentation[rfm_segmentation[\u0026#39;RFMScore\u0026#39;]==\u0026#39;000\u0026#39;])) Káº¿t quáº£\n1\u0026gt;\u0026gt; print(quantiles) 2\u0026gt;\u0026gt; quantiles.to_dict() 3 4 Recency Frequency Monetary 50.25 15.0 1.0 17.4000 60.50 45.0 2.0 43.5000 70.75 128.0 4.0 119.6625 8{\u0026#39;Frequency\u0026#39;: {0.25: 1.0, 0.5: 2.0, 0.75: 4.0}, 9 \u0026#39;Monetary\u0026#39;: {0.25: 17.399999999999999, 0.5: 43.5, 0.75: 119.66250000000001}, 10 \u0026#39;Recency\u0026#39;: {0.25: 15.0, 0.5: 45.0, 0.75: 128.0}} 11 12\u0026gt;\u0026gt;rfm_segmentation.head() 13 14\tRecency\tFrequency\tMonetary\tR_Quartile\tF_Quartile\tM_Quartile\tRFMScore 15CustomerID 1612346\t316\t1\t77183.60\t3\t0\t3\t303 1712347\t30\t5\t120.56\t1\t3\t3\t133 1812348\t66\t3\t291.76\t2\t2\t3\t223 1912349\t9\t1\t15.00\t0\t0\t0\t000 2012350\t301\t1\t25.20\t3\t0\t1\t301 21 22Best Customers: 10 23Loyal Customers: 980 24Big Spenders: 1044 25Almost Lost: 188 26Lost Customers: 374 27Lost Cheap Customers: 101 Tham kháº£o https://blog.hubspot.com/service/rfm-analysis\nhttps://www.investopedia.com/terms/r/rfm-recency-frequency-monetary-value.asp\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c bÃ i. Náº¿u cÃ³ báº¥t ká»³ váº¥n Ä‘á» gÃ¬, hÃ£y Ä‘á»ƒ láº¡i comment bÃªn dÆ°á»›i hoáº·c email cho mÃ¬nh qua Ä‘á»‹a chá»‰ alexblack2202@gmail.com. Háº¹n gáº·p láº¡i cÃ¡c báº¡n á»Ÿ bÃ i viáº¿t tiáº¿p theo.\nSource code mÃ¬nh cÃ³ Ä‘á»ƒ á»Ÿ https://www.kaggle.com/code/alexblack2202/customer-segmentation-using-rfm-analysis\n","date":"Dec 4, 2022","img":"https://unsplash.it/1920/1080?image=17","permalink":"/blog/2022-12-03-marketing-with-python/","series":null,"tags":["RFM","Recommendation","Marketing"],"title":"Marketing Thá»±c Chiáº¿n - PhÃ¢n Loáº¡i KhÃ¡ch HÃ ng Sá»­ Dá»¥ng RFM Analysis"},{"categories":null,"content":"NhÆ° cÃ¡c báº¡n Ä‘Ã£ biáº¿t, tiktok hiá»‡n nay lÃ  má»™t á»©ng dá»¥ng giáº£i trÃ­ phá»• biáº¿n vÃ  Ä‘á»©ng top 1 trong sá»‘ lÆ°á»£t táº£i xuá»‘ng tá»« CH play vÃ  AppStore. ThÃ nh cÃ´ng cá»§a tiktok lÃ  do há» Ä‘Ã£ xÃ¢y dá»±ng khÃ¡ thÃ nh cÃ´ng thuáº­t toÃ¡n gá»£i Ã½ video cho ngÆ°á»i dÃ¹ng, lÃ m cho ngÆ°á»i dÃ¹ng \u0026ldquo;cuá»‘n\u0026rdquo; vÃ o cÃ¡c video há» Ä‘á» xuáº¥t, mÃ  khÃ´ng biáº¿t chÃ¡n. NgÃ y 27/09/2022, há» Ä‘Ã£ cÃ´ng bá»‘ bÃ i bÃ¡o cÃ³ tá»± Ä‘á» Monolith: Real Time Recommendation System With Collisionless Embedding Table táº¡i Ä‘á»‹a chá»‰ https://arxiv.org/pdf/2209.07663.pdf. Chá»§ Ä‘á» nÃ y khÃ¡ náº·ng vá» kháº£ nÄƒng xÃ¢y dá»±ng há»‡ thá»‘ng Ä‘á»ƒ lÃ m sao Ä‘áº¡t Ä‘Æ°á»£c mÃ´ hÃ¬nh cháº¥t lÆ°á»£ng vá»›i thá»i gian near-realtime. Äá»ƒ cÃ³ thá»ƒ hiá»ƒu sÃ¢u bÃ i nÃ y, cÃ¡c báº¡n cÃ³ nÃªn cÃ³ kiáº¿n thá»©c vá» Recurrent Neural Networks for Recommendations.\nPháº§n dáº«n nháº­p - ChÃ o Ä‘áº§u 1. Pháº§n giá»›i thiá»‡u 1.1 Sparsity vÃ  Dynamism 1.2 Non-stationary Distribution 2. Design colisionless Hash Table vÃ  Online Training 2.1 XÃ¢y dá»±ng Hash Table 2.2 Online training 2.2.1 Streaming Engine 2.2 .2 Online Joiner 2.2.3 Parameter Synchronization 2.3 Fault Tolerance 3. ÄÃ¡nh giÃ¡ - EVALUATION 3.1 Thiáº¿t láº­p thÃ­ nghiá»‡m 3.1.1 XÃ¢y dá»±ng embedding table 3.1.2 Online training 3.2 Káº¿t quáº£ vÃ  phÃ¢n tÃ­ch 3.2.1 Hiá»‡u quáº£ cá»§a embedding collision 3.2.2 Online Training: Trading-off Reliability For Realtime. TÃ i liá»‡u tham kháº£o cá»§a paper Tham kháº£o Pháº§n dáº«n nháº­p - ChÃ o Ä‘áº§u CÃ¡c doanh nghiá»‡p cÃ³ nhu cáº§u xÃ¢y dá»±ng real-time recommendation Ä‘á»ƒ phá»¥c vá»¥ khÃ¡ch hÃ ng tá»‘t hÆ¡n.\nCÃ¡c framwork deep-learning Ä‘Æ°á»£c sá»­ dá»¥ng trong production thÆ°á»ng khÃ´ng Ä‘Ã¡p á»©ng Ä‘Æ°á»£c nhu cáº§u recommend cá»§a doanh nghiá»‡p, lÃ½ do lÃ :\nTinh chá»‰nh há»‡ thá»‘ng dá»±a trÃªn cÃ¡c tham sá»‘ tÄ©nh vÃ  thá»±c hiá»‡n nhiá»u phÃ©p tÃ­nh toÃ¡n trÃªn feature thÆ°a (sparse) vÃ  Ä‘á»™ng (dinamic) lÃ m giáº£m cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh.\nViá»‡c training vÃ  serving tÃ¡ch báº¡ch nhau, khÃ´ng cÃ³ online training (model khÃ´ng thá»ƒ retrain ngay láº­p tá»©c khi cÃ³ feedback cá»§a ngÆ°á»i dÃ¹ng)\nVÃ¬ nhá»¯ng nguyÃªn nhÃ¢n trÃªn, nhÃ³m tÃ¡c giáº£ cá»§a ByteDance Ä‘Ã£ thiáº¿t káº¿ má»™t mÃ´ hÃ¬nh online training má»›i, Ä‘áº·t tÃªn lÃ  Monolith.\nMÃ´ hÃ¬nh má»›i cÃ³ 2 thÃ nh tá»‘ má»›i:\nÄá» xuáº¥t collisionless embedding table vá»›i cÃ¡c tá»‘i Æ°u nhÆ° expirable embeddings vÃ  frequency filtering Ä‘á»ƒ giáº£m lÆ°á»£ng bá»™ nhá»› tiÃªu thá»¥.\nÄá» xuáº¥t má»™t mÃ´ hÃ¬nh kiáº¿n trÃºc production-ready online training vá»›i high fault-tolerance.\nCuá»‘i cÃ¹ng, chá»©ng minh ráº±ng Ä‘á»™ tin cáº­y cá»§a há»‡ thá»‘ng cÃ³ thá»ƒ Ä‘Ã¡nh Ä‘á»•i báº±ng viá»‡c há»c theo thá»i gian thá»±c.\n1. Pháº§n giá»›i thiá»‡u \u0026ldquo;HÃ¬nh 1: Monolith Online Training Architecture - HÃ¬nh áº£nh Ä‘Æ°á»£c cáº¯t tá»« paper\nData cá»§a recommendation khÃ¡c xa data cá»§a language modeling hoáº·c computer vision á»Ÿ 2 khÃ­a cáº¡nh:\nHáº§u háº¿t cÃ¡c Ä‘áº·c trÆ°ng ráº¥t thÆ°a, cÃ³ tÃ­nh phÃ¢n loáº¡i vÃ  thay Ä‘á»•i linh hoáº¡t.\nPhÃ¢n phá»‘i cá»§a data lÃ  khÃ´ng dá»«ng (non-stationary) , vd Concept Drift. [8]\n1.1 Sparsity vÃ  Dynamism Nháº¯c láº¡i, dá»¯ liá»‡u cho recommendation háº§u háº¿t lÃ  cÃ¡c Ä‘áº·c trÆ°ng category dáº¡ng thÆ°a, má»™t vÃ i trong sá»‘ Ä‘Ã³ cÃ³ táº§ng suáº¥t xuáº¥t hiá»‡n ráº¥t tháº¥p. Viá»‡c mapping chÃºng lÃªn khÃ´ng gian Ä‘áº·c trÆ°ng cao chiá»u hÆ¡n sáº½ gáº·p cÃ¡c váº¥n Ä‘á»:\nKhÃ´ng giá»‘ng nhÆ° cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ sá»‘ lÆ°á»£ng tá»« háº¡n cháº¿, data user ranking item thÆ°á»ng ráº¥t ráº¥t lá»›n. Kháº£ nÄƒng cao lÃ  1 mÃ¡y chá»§ siÃªu máº¡nh hiá»‡n nay cá»§a cÃ¡c doanh nghiá»‡p khÃ´ng chá»©a ná»•i Embedding table trÃªn bá»™ nhá»› chÃ­nh.\nTrÆ°á»ng há»£p tá»‡ nháº¥t,kÃ­ch thÆ°á»›c cá»§a Embedding table sáº½ tiáº¿p tá»¥c tÄƒng theo thá»i gian do ngÆ°á»i dÃ¹ng vÃ  sáº£n pháº©m má»›i liÃªn tá»¥c Ä‘Æ°á»£c thÃªm vÃ o há»‡ thá»‘ng. Trong khi Ä‘Ã³, má»™t sá»‘ frameword recommendation sá»­ dá»¥ng fixed-size dense variables Ä‘á»ƒ biá»ƒu diá»…n embedding table. VÃ­ dá»¥ framework [1,17]\nTrong thá»±c táº¿, nhiá»u thuáº­t toÃ¡n Ä‘Ã£ dÃ¹ng vÃ i \u0026ldquo;máº¹o\u0026rdquo;, nhÆ° xÃ i hashing nhÆ° bÃ i bÃ¡o [3] vÃ  bÃ i bÃ¡o [6] , Ä‘á»ƒ giáº£m lÆ°á»£ng memory tiÃªu thá»¥ vÃ  cho phÃ©p tÄƒng ID. Ã tÆ°á»Ÿng nÃ y dá»±a trÃªn giáº£ Ä‘á»‹nh lÃ  ID trong Embedding table phÃ¢n phá»‘i Ä‘á»u vÃ  viá»‡c collisions thÃ¬ vÃ´ háº¡i. Giáº£ Ä‘á»‹nh nÃ y khÃ´ng Ä‘Ãºng trong hiá»‡n thá»±c, khi mÃ  má»™t nhÃ³m nhá» user hoáº·c item cÃ³ táº§ng suáº¥t xuáº¥t hiá»‡n cao hÆ¡n. Vá»›i sá»± tÄƒng trÆ°á»Ÿng tá»± nhiÃªn cá»§a embedding table, xÃ¡c suáº¥t hash key Ä‘á»¥ng Ä‘á»™ sáº½ cÃ ng cao, dáº«n Ä‘áº¿n giáº£m cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh.\nDo Ä‘Ã³, nhu cáº§u tá»± nhiÃªn cá»§a má»™t há»‡ thá»‘ng gá»£i Ã½ lÃ  cÃ³ kháº£ nÄƒng capture cÃ ng nhiá»u Ä‘áº·c trÆ°ng trong chÃ­nh cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh, vÃ  cÃ³ kháº£ nÄƒng Ä‘iá»u chá»‰nh linh hoáº¡t sá»‘ user vÃ  sá»‘ item mÃ  nÃ³ cÃ³ kháº£ nÄƒng lÆ°u giá»¯.\n1.2 Non-stationary Distribution CÃ¡c pattern má»›i vá» hÃ¬nh áº£nh vÃ  ngÃ´n ngá»¯ trong bÃ i toÃ¡n xá»­ lÃ½ áº£nh vÃ  xá»­ lÃ½ ngÃ´n ngá»¯ thÆ°á»ng khÃ´ng thay Ä‘á»•i nhiá»u trong hÃ ng tháº¿ ká»·. Trong khi Ä‘Ã³, sá»± quan tÃ¢m cá»§a ngÆ°á»i dÃ¹ng vá» má»™t chá»§ Ä‘á» nÃ o Ä‘Ã³ cÃ³ thá»ƒ thay Ä‘á»•i tá»«ng phÃºt má»™t. Káº¿t quáº£ lÃ , phÃ¢n phá»‘i cá»§a dá»¯ liá»‡u ngÆ°á»i dÃ¹ng lÃ  khÃ´ng cá»‘ Ä‘á»‹nh, vÃ  hiá»‡n tÆ°á»£ng nÃ y thÆ°á»ng Ä‘Æ°á»£c gá»i vá»›i tÃªn lÃ  Concept Drift.\nThÃ´ng thÆ°á»ng, thÃ´ng tin lá»‹ch sá»­ gáº§n nháº¥t thÆ°á»ng cÃ³ Ä‘Ã³ng gÃ³p hiá»‡u quáº£ nháº¥t cho viá»‡c dá»± Ä‘oÃ¡n viá»‡c thay Ä‘á»•i hÃ nh vi ngÆ°á»i dÃ¹ng. Äá»ƒ giáº£m thiá»ƒu tÃ¡c Ä‘á»™ng cá»§a Concept Drift, cÃ¡c mÃ´ hÃ¬nh \u0026ldquo;serving\u0026rdquo; cáº§n pháº£i cáº­p nháº­t thÆ°á»ng xuyÃªn tá»« nhá»¯ng pháº£n há»“i cá»§a ngÆ°á»i dÃ¹ng, cÃ ng real-time cÃ ng tá»‘t, Ä‘á»ƒ pháº£n Ã¡nh tá»‘t nháº¥t xu hÆ°á»›ng quan tÃ¢m cá»§a ngÆ°á»i dÃ¹ng.\nDá»±a trÃªn cÃ¡c phÃ¢n tÃ­ch trÃªn, nhÃ³m tÃ¡c giáº£ Ä‘Ã£ xÃ¢y dá»±ng nÃªn monolith, cÃ³ kháº£ nÄƒng:\nCung cáº¥p Ä‘áº§y Ä‘á»§ nÄƒng lá»±c xá»­ lÃ½ cho cÃ¡c Ä‘áº·c trÆ°ng thÆ°a báº±ng cÃ¡ch thiáº¿t káº¿ má»™t collisionless hash table vÃ  cÆ¡ cháº¿ loáº¡i bá» cÃ¡c dynamic feature.\nÄÆ°a thÃ´ng tin feedback cá»§a ngÆ°á»i dÃ¹ng vÃ o training realtime vá»›i online training\nDá»±a vÃ o kiáº¿n trÃºc nÃ y, mÃ´ hÃ¬nh monolith vÆ°á»£t trá»™i hÆ¡n so vá»›i cÃ¡c há»‡ thá»‘ng sá»­ dá»¥ng collisions hash table vá»›i dung lÆ°á»£ng bá»™ nhá»› sá»­ dá»¥ng lÃ  tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhau\n2. Design colisionless Hash Table vÃ  Online Training HÃ¬nh 2: Worker-PS Architecture - HÃ¬nh áº£nh Ä‘Æ°á»£c cáº¯t tá»« paper\nKiáº¿n trÃºc cá»§a Monolith sá»­ dá»¥ng TensorFlowâ€™s distributed Worker-ParameterServer (Worker-PS) nhÆ° hÃ¬nh trÃªn. Trong mÃ´ hÃ¬nh, cÃ¡c mÃ¡y Ä‘Æ°á»£c phÃ¢n cÃ´ng vá»›i cÃ¡c nhiá»‡m vá»¥ khÃ¡c nhau. Worker machine chá»‹u trÃ¡ch nhiá»‡m tÃ­nh toÃ¡n theo Ä‘á»‹nh nghÄ©a trÆ°á»›c, PS machine lÆ°u trá»¯ cÃ¡c tham sá»‘ vÃ  cáº­p nháº­t káº¿t quáº£ tham sá»‘ theo workers.\nTrong mÃ´ hÃ¬nh recommendation, cÃ¡c tham sá»‘ Ä‘Æ°á»£c phÃ¢n loáº¡i lÃ m hai nhÃ³m: nhÃ³m dense vÃ  nhÃ³m sparse. CÃ¡c tham sá»‘ Dense lÃ  cÃ¡c trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh DNN, cÃ¡c tham sá»‘ sparse tham chiáº¿u tá»›i embedding table tÆ°Æ¡ng á»©ng vá»›i cÃ¡c sparse feature. Cáº£ Dense parameter vÃ  sparse parameter Ä‘á»u lÃ  cÃ¡c pháº§n cá»§a TensorFlow Graph, vÃ  Ä‘Æ°á»£c lÆ°u trá»¯ trÃªn parameters servers.\n2.1 XÃ¢y dá»±ng Hash Table HÃ¬nh 3: Cuckoo HashMap. - HÃ¬nh áº£nh Ä‘Æ°á»£c cáº¯t tá»« paper\nNguyÃªn táº¯c Ä‘áº§u tiÃªn Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c tham sá»‘ biá»ƒu diá»…n tÃ­nh thÆ°a lÃ  trÃ¡nh thu gá»n thÃ´ng tin tá»« cÃ¡c IDs khÃ¡c nhau vá» cÃ¹ng má»™t fixed-sze embedding.\nViá»‡c xÃ¢y dá»±ng má»™t embedding table sá»­ dá»¥ng TensorFlow Variable sáº½ dáº«n Ä‘áº¿n viá»‡c Ä‘á»¥ng Ä‘á»™ ID khi sá»‘ lÆ°á»£ng ID má»›i vÃ  table tÄƒng lÃªnh. Do Ä‘Ã³, thay vÃ¬ xÃ¢y embedding table dá»±a trÃªn Variable, tÃ¡c giáº£ Ä‘Ã£ phÃ¡t triá»ƒn má»™t key-value HashTable cho cÃ¡c tham sá»‘ thÆ°a.\nHashTable nÃ y sá»­ dá»¥ng Cuckoo Hashmap [16], há»— trá»£ viá»‡c thÃªm má»™t key má»›i mÃ  khÃ´ng Ä‘á»¥ng Ä‘á»™ vá»›i key cÅ©. Cuckoo Hashing trong trÆ°á»ng há»£p xáº¥u nháº¥t cÃ³ Ä‘á»™ phá»©c táº¡p O(1) trong viá»‡c tÃ¬m kiáº¿m vÃ  xoÃ¡, vÃ  O(1) cho viá»‡c thÃªm má»›i. NhÆ° trong hÃ¬nh 3, nÃ³ sá»­ dá»¥ng hai báº£ng T0 vÃ  T1 vá»›i hai hÃ m hash khÃ¡c nhau cÃ³ tÃªn lÃ  h0(x) vÃ  h1(x), vÃ  má»™t pháº§n tá»­ sáº½ Ä‘Æ°á»£c lÆ°u trá»¯ trong má»™t trong hai báº£ng trÃªn. Khi cá»‘ gÃ¡n thÃªm má»™t pháº§n tá»­ A vÃ o T0, Ä‘áº§u tiÃªn, nÃ³ cá»‘ gÃ¡n Ä‘áº·t A vÃ o h0(A). Náº¿u h0(A) Ä‘Ã£ hold 1 pháº§n tá»­ B nÃ o Ä‘Ã³, nÃ³ sáº½ xoÃ¡ B tá»« T0 vÃ  gÃ¡n B vÃ o T1 vá»›i logic tÆ°Æ¡ng tá»±. QuÃ¡ trÃ¬nh nÃ y Ä‘Æ°á»£c láº·p Ä‘i láº·p láº¡i Ä‘áº¿n khi á»•n Ä‘á»‹nh.\nViá»‡c giáº£m bá»™ nhá»› lÆ°u trá»¯ cÅ©ng lÃ  má»™t yáº¿u tá»‘ quang trá»ng trong thiáº¿t káº¿ há»‡ thá»‘ng. Má»™t cÃ¡ch tá»± nhiÃªn, viá»‡c má»—i láº§n thÃªm 1 pháº§n tá»­ má»›i vÃ o HashTable sáº½ lÃ m cho bá»™ nhá»› nhanh chÃ³ng Ä‘áº§y. CÃ³ 2 káº¿t luáº­n cÃ³ thá»ƒ Ä‘Æ°á»£c rÃºt ra:\nCÃ¡c ID xuáº¥t hiá»‡n vÃ i láº§n cÃ³ Ä‘Ã³ng gÃ³p ráº¥t háº¡n cháº¿ Ä‘á»‘i vá»›i viá»‡c cáº£i thiá»‡n cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh. CÃ¡c quan sÃ¡t quan trá»ng lÃ  cÃ¡c quan sÃ¡t mÃ  cÃ¡c IDs á»Ÿ dáº¡ng long-tail distributed, khi cÃ¡c ID phá»• biáº¿n cÃ³ sá»‘ láº§n xuáº¥t hiá»‡n hÃ ng triá»‡u láº§n, trong khi Ä‘Ã³, cÃ¡c ID khÃ´ng phá»• biáº¿n xuáº¥t hiá»‡n khÃ´ng quÃ¡ mÆ°á»i láº§n. CÃ¡c ID táº§ng suáº¥t tháº¥p lÃ m mÃ´ hÃ¬nh underfit do thiáº¿u data training vÃ  model sáº½ khÃ´ng cÃ³ kháº£ nÄƒng Ä‘Æ°a ra dá»± Ä‘oÃ¡n tá»‘t dÆ°a trÃªn nhá»¯ng thÃ´ng tin mÃ  chÃºng cung cáº¥p. HÆ¡n háº¿t, cÃ¡c thÃ´ng tin cá»§a cÃ¡c ID trÃªn thÆ°á»ng Ã­t áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ cá»§a mÃ´ hÃ¬nh, do Ä‘Ã³, viá»‡c xoÃ¡ Ä‘i cÃ¡c ID cÃ³ táº§ng suáº¥t tháº¥p khÃ´ng áº£nh hÆ°á»Ÿng nhiá»u Ä‘áº¿n cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh.\nLá»‹ch sá»­ tá»« thá»i napoleon cÃ³ Ä‘Ã³ng gÃ³p ráº¥t tháº¥p vÃ o mÃ´ hÃ¬nh hiá»‡n táº¡i. Do ngÆ°á»i dÃ¹ng ngá»«ng hoáº¡t Ä‘á»™ng, hoáº·c lÃ  video Ä‘Ã£ lá»—i thá»i. Viá»‡c lÆ°u trá»¯ embedding cho cÃ¡c ID nÃ y khÃ´ng giÃºp Ã­ch cho mÃ´ hÃ¬nh, ngÆ°á»£c láº¡i chÃºng cÃ²n gÃ³p pháº§n lÃ m tÄƒng chi phÃ­ lÆ°u trá»¯ vÃ  chi phÃ­ tÃ­nh toÃ¡n.\nDá»±a trÃªn nhá»¯ng Ä‘iá»u trÃªn, nhÃ³m ká»¹ sÆ° Ä‘á» xuáº¥t thiáº¿t káº¿ ID filtering heuristic Ä‘á»ƒ giÃºp tá»‘i Æ°u hoÃ¡ bá»™ nhá»› lÆ°u trá»¯:\nCÃ¡c ID Ä‘Æ°á»£c lá»c trÆ°á»›c khi Ä‘Æ°á»£c Ä‘Æ°a vÃ o trong há»‡ thá»‘ng embedding table. CÃ³ 2 phÆ°Æ¡ng phÃ¡p lá»c Lá»c theo táº§ng xuáº¥t xuáº¥t hiá»‡n trÆ°á»›c khi ID Ä‘Æ°á»£c thÃªm vÃ o. GiÃ¡ trá»‹ ngÆ°á»¡ng lÃ  siÃªu tham sá»‘ vÃ  Ä‘Æ°á»£c turning. Lá»c theo xÃ¡c xuáº¥t, giÃºp cho giáº£m bá»™ nhá»› tiÃªu thá»¥. ID Ä‘Æ°á»£c gÃ¡n thá»i gian vÃ  bá»‹ expire sau má»™t khoáº£ng thá»i gian inactive. HashTable Ä‘Æ°á»£c implement dÆ°á»›i dáº¡ng Tensorflow resource operation.\n2.2 Online training Viá»‡c trainnig Ä‘Æ°á»£c chia lÃ m 2 giai Ä‘oáº¡n:\nGiai Ä‘oáº¡n Batch training. Giai Ä‘oáº¡n nÃ y hoáº¡t Ä‘á»™ng nhÆ° viá»‡c training mÃ´ hÃ¬nh TF bÃ¬nh thÆ°á»ng. Trong má»—i bÆ°á»›c training, cÃ¡c worker Ä‘á»c má»™t mini-batch data training tá»« storage, láº¥y tham sá»‘ tá»« PS, tÃ­nh lan truyá»n xuÃ´i, lan truyá»n ngÆ°á»£c, vÃ  cáº­p nháº­t tham sá»‘ vÃ o PS. Dataset Ä‘Æ°á»£c train 1 láº§n duy nháº¥t.\nGiai Ä‘oáº¡n training online. Sau khi model Ä‘Æ°á»£c deploy vÃ o online serving, viá»‡c traning khÃ´ng cÃ³ dá»«ng háºµng, mÃ  chuyá»ƒn qua giai Ä‘oáº¡n online training. Thay vÃ¬ Ä‘á»c cÃ¡c mini-batch data tá»« storage, training worker sáº½ láº¥y realtime data Ä‘á»ƒ train vÃ  cáº­p nháº­t láº¡i PS. Training PS sáº½ Ä‘á»‹nh ká»³ cáº­p nháº­t cÃ¡c tham sá»‘ vÃ o serving PS.\n2.2.1 Streaming Engine HÃ¬nh 4: Streaming Engine. The information feedback loop from [User â†’ Model Server â†’ Training Worker â†’ Model Server â†’ User] would spend a long time when taking the Batch Training path, while the Online Training will close the loop more instantly - HÃ¬nh áº£nh Ä‘Æ°á»£c cáº¯t tá»« paper\nHÃ¬nh 4 phÃ­a trÃªn mÃ´ táº£ viá»‡c chuyá»ƒn Ä‘á»•i liá»n máº¡ch giá»¯a batch training vÃ  online training.\nMÃ´ hÃ¬nh sá»­ dá»¥ng Kafka Queue [13] Ä‘á»ƒ log láº¡i cÃ¡c hÃ nh Ä‘á»™ng cá»§a user ( click item, like item, tháº£ tim\u0026hellip;. ) vÃ  má»™t Kafka queue khÃ¡c lÆ°u láº¡i cÃ¡c Ä‘áº·c trÆ°ng. Core engine lÃ  Flink [4] stream job cho online feature joiner. Online joiner káº¿t há»£p cÃ¡c Ä‘áº·c trÆ°ng vá»›i nhÃ£n tá»« user action táº¡o thÃ nh training example, sau Ä‘Ã³ Ä‘áº©y vÃ o kafka queue. Queue cho training example Ä‘Æ°á»£c consumer bá»›i online training vÃ  batch training.\nVá»›i online training, training worker trá»±c tiáº¿p Ä‘á»c dá»¯ liá»‡u tá»« kafka Queue.\nVá»›i batch training, data sáº½ Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i vÃ o file HDFS (dump job handle viá»‡c nÃ y). Sau khi data trong HDFS tÃ­ch luá»¹ vá»›i sá»‘ lÆ°á»£ng Ä‘á»§ dÃ¹ng, training worker sáº½ load data tá»« HDFS vÃ  thá»±c hiá»‡n batch training.\n2.2 .2 Online Joiner HÃ¬nh 5: : Online Joiner - HÃ¬nh áº£nh Ä‘Æ°á»£c cáº¯t tá»« paper\nTrong á»©ng dá»¥ng thá»±c táº¿, hÃ nh Ä‘á»™ng cá»§a user vÃ  feature cá»§a user Ä‘Æ°á»£c stream vÃ o online joiner mÃ  khÃ´ng Ä‘áº£m báº£o thá»© tá»± vá» thá»i gian. Do Ä‘Ã³, cáº§n phÃ¡t sinh má»™t unique key cho má»—i request Ä‘á»ƒ Ä‘áº£m báº£o pair Ä‘Æ°á»£c chÃºng vá»›i nhau.\nViá»‡c user bá»‹ lag cÅ©ng lÃ  má»™t váº¥n Ä‘á» cáº§n Ä‘Æ°á»£c xem xÃ©t. VÃ­ dá»¥, má»™t user cÃ³ kháº£ nÄƒng máº¥t vÃ i ngÃ y má»›i ra quyáº¿t Ä‘á»‹nh mua má»™t sáº£n pháº©m mÃ  há» Ä‘Ã£ xem vÃ i ngÃ y trÆ°á»›c Ä‘Ã³. ÄÃ¢y lÃ  má»™t thÃ¡ch thá»©c tháº­t sá»±, bá»Ÿi vÃ¬ náº¿u toÃ n bá»™ cÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c lÆ°u trá»¯ trong bá»™ nhá»› chÃ­nh, thÃ¬ chÃºng ta sáº½ khÃ´ng Ä‘á»§ bá»™ nhá»› Ä‘á»ƒ lÆ°u trá»¯. NhÃ³m tÃ¡c giáº£ Ä‘Ã£ sá»­ dá»¥ng on-disk key-value storage Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c Ä‘áº·c trÆ°ng cá»§a ngÆ°á»i dÃ¹ng á»Ÿ quÃ¡ khá»©. Khi log cá»§a ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c Ä‘áº©y vÃ o há»‡ thá»‘ng, trÆ°á»›c háº¿t nÃ³ sáº½ Ä‘Æ°á»£c tÃ¬m kiáº¿m trong memory cache, trong trÆ°á»ng há»£p mising cache, nÃ³ sáº½ tÃ¬m trong key-value storage.\nMá»™t váº¥n Ä‘á» ná»¯a lÃ  phÃ¢n bá»‘ máº«u Ã¢m vÃ  máº«u dÆ°Æ¡ng trong data khÃ´ng Ä‘á»“ng Ä‘á»u. Trong Ä‘Ã³, lÆ°á»£ng máº«u dÆ°Æ¡ng thÆ°á»ng cao hÆ¡n ráº¥t nhiá»u so vá»›i máº«u Ã¢m. Äá»ƒ ngÄƒn cháº·ng tháº±ng máº«u dÆ°Æ¡ng thá»‘ng trá»‹, má»™t chiáº¿n lÆ°á»£c thÆ°á»ng hay Ä‘Æ°á»£c sá»­ dá»¥ng lÃ  sampling máº«u Ã¢m. Táº¥t nhiÃªn viá»‡c nÃ y sáº½ lÃ m thay Ä‘á»•i phÃ¢n bá»‘ cá»§a mÃ´ hÃ¬nh huáº¥n luyá»‡n. VÃ  sá»­ dá»¥ng log odds corection trong quÃ¡ trÃ¬nh serving [19]\n2.2.3 Parameter Synchronization Trong suá»‘t quÃ¡ trÃ¬nh training, dá»¯ liá»‡u sáº½ liÃªn tá»¥c Ä‘á»• vá» online serving module vÃ  cáº­p nháº­t tham sá»‘ trÃªn PS. Trong mÃ´i trÆ°á»ng tháº­t, sáº½ cÃ³ má»™t vÃ i thÃ¡ch thá»©c:\nModel trÃªn online serving PS báº¯t buá»™c pháº£i hoáº¡t Ä‘á»™ng khi update. KÃ­ch thÆ°á»›c model khÃ¡ lá»›n, vÃ  viá»‡c update toÃ n bá»™ tham sá»‘ sáº½ tá»‘n kha khÃ¡ thá»i gian (lÆ°u Ã½ á»Ÿ Ä‘Ã¢y lÃ  khÃ´ng thá»ƒ thá»±c hiá»‡n update tá»«ng pháº§n, mÃ  pháº£i update toÃ n bá»™ tham sá»‘). NÃªn pháº£i tÃ¬m cÃ¡ch thá»©c nÃ o Ä‘Ã³ Ä‘á»ƒ viá»‡c update khÃ´ng áº£nh hÆ°á»Ÿng tá»›i viá»‡c infer cá»§a model.\nViá»‡c tranfer model cÃ³ kÃ­ch thÆ°á»›c lá»›n tá»« training PS tá»›i online server PS sáº½ gÃ¢y Ã¡p lá»±c lá»›n Ä‘áº¿n bÄƒng thÃ´ng máº¡ng vÃ  bá»™ nhá»› trÃªn PS. Má»™t yÃªu cáº§u tá»‘i thiá»ƒu lÃ  bá»™ nhá»› pháº£i cÃ³ kÃ­ch thÆ°á»›c Ã­t nháº¥t lÃ  gáº¥p 2 láº§n kÃ­ch thÆ°á»›c cá»§a model (trÃªn RAM)\nÄá»ƒ scale up model cho phÃ¹ há»£p vá»›i nghiá»‡p vá»¥ kinh doanh, nhÃ³m tÃ¡c giáº£ Ä‘Ã£ thiáº¿t káº¿ riÃªng má»™t cÆ¡ cháº¿ Ä‘á»“ng bá»™ hoÃ¡, dá»±a trÃªn cÃ¡c quan sÃ¡t sau:\nCÃ¡c tham sá»‘ thÆ°a thÃ¬ thÆ°á»ng thá»‘ng trá»‹ kÃ­ch thÆ°á»›c cá»§a mÃ´ hÃ¬nh gá»£i Ã½.\nTrong má»™t khoáº£ng thá»i gian ngáº¯n (short range of time window), chá»‰ má»™t nhÃ³m nhá» cÃ¡c ID Ä‘Æ°á»£c training, vÃ  chá»‰ nhá»¯ng embedding cá»§a nhá»¯ng ID Ä‘Ã³ Ä‘Æ°á»£c cáº­p nháº­t.\nCÃ¡c biáº¿n Dense tranfer cháº­m hÆ¡n so vá»›i spare embeddings. Bá»Ÿi vÃ¬ size cá»§a Dense variable ráº¥t lá»›n.\nNháº­n Ä‘á»‹nh 1 vÃ  2 á»Ÿ nháº­n cho phÃ©p chÃºng ta trÃ¡nh cáº­p nháº­t sparse cá»§a toÃ n bá»™ cÃ¡c Ä‘áº·c trÆ°ng cá»§a ID. Trong mÃ´ hÃ¬nh, cÃ¡c ID chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n ká»ƒ tá»« láº§n huáº¥n luyá»‡n cuá»‘i cÃ¹ng sáº½ Ä‘Æ°á»£c Ä‘áº©y vÃ o touched key. Sau khi training xong, chÃºng ta sáº½ Ä‘áº©y cÃ¡c sparse parameter trong touched key vÃ o online serving PS vá»›i táº§n suáº¥t tÃ­nh báº±ng phÃºt. GÃ³i cáº­p nháº­t nÃ y khÃ¡ nhá» (so vá»›i toÃ n bá»™ ), nÃªn chÃºng Ã­t sáº½ sá»­ dá»¥ng bÄƒng thÃ´ng máº¡ng ráº¥t tháº¥p, vÃ  sáº½ khÃ´ng táº¡o mÃ´ hÃ¬nh rÄƒng cÆ°a cho bá»™ nhá»› RAM trong quÃ¡ trÃ¬nh Ä‘á»“ng bá»™.\nVá»›i nháº­n Ä‘á»‹nh (3), chÃºng ta sáº½ giáº£m I/O máº¡ng vÃ  bá»™ nhá»› sá»­ dá»¥ng báº±ng cÃ¡ch Ä‘áº·t lá»‹ch Ä‘á»“ng bá»™ hoÃ¡ dÃ y hÆ¡n cho cÃ¡c tham sá»‘ thÆ°a, trong khi Ä‘Ã³ sáº½ cÃ³ táº§ng xuáº¥t cáº­p nháº­t tham sá»‘ dense Ã­t hÆ¡n. Viá»‡c nÃ y cÅ©ng gÃ¢y ra tÃ¬nh huá»‘ng lÃ  cÃ¡c tham sá»‘ thÆ°a sáº½ má»›i hÆ¡n ráº¥t nhiá»u so vá»›i tham sá»‘ dense, do Ä‘Ã³ sáº½ cÃ³ máº¥t mÃ¡t xáº£y ra. Máº¥t mÃ¡t nÃ y Ä‘Æ°á»£c cháº¥p nháº­n do nÃ³ khÃ´ng quÃ¡ nghiÃªm trá»ng. Trong pháº§n cuá»‘i cÃ³ thÃ­ nghiá»‡m vá» váº¥n Ä‘á» nÃ y.\n2.3 Fault Tolerance Äá»‘i vá»›i há»‡ thá»‘ng thá»±c, kiáº¿n trÃºc cá»§a há»‡ thá»‘ng pháº£i Ä‘áº£m báº£o kháº£ nÄƒng phá»¥c há»“i trong trÆ°á»ng há»£p cÃ³ lá»—i xáº£y ra. Má»™t lá»±a chá»n phá»• biáº¿n thÆ°á»ng Ä‘Æ°á»£c hay dÃ¹ng lÃ  snapshot tráº¡ng thÃ¡i cá»§a model Ä‘á»‹nh ká»³, vÃ  phá»¥c há»“i dá»¯ liá»‡u tá»« láº§n snapshot cuá»‘i cÃ¹ng khi nháº­n tháº¥y cÃ³ lá»—i. Viá»‡c lá»±a chá»n táº§ng suáº¥t snapshot dá»±a vÃ o hai yáº¿u tá»‘ chÃ­nh:\nCháº¥t lÆ°á»£ng model. DÄ© nhiÃªn ráº±ng model snapshot á»Ÿ cÃ ng gáº§n phiÃªn báº£n cuá»‘i cÃ ng tá»‘t, do Ä‘Ã³ táº§ng suáº¥t snapshot pháº£i tÄƒng lÃªn.\nChi phÃ­ sá»­ dá»¥ng há»‡ thá»‘ng. Viá»‡c snapshot má»™t model cÃ³ kÃ­ch thÆ°á»›c lá»›n sáº½ tá»‘n kha khÃ¡ cpu vÃ  bá»™ nhá»› Ä‘á»ƒ copy data, ngoÃ i ra cÃ²ng tÄƒng disk I/O\nÄá»ƒ cÃ¢n báº±ng giá»¯a 2 cÃ¡i trÃªn, Monolith snapshot toÃ n bá»™ training PS má»—i ngÃ y. ChÃºng ta sáº½ máº¥t 1 ngÃ y update data khi lá»—i xáº£y ra. NhÆ°ng qua cÃ¡c thá»­ nghiá»‡m cá»§a nhÃ³m ká»¹ sÆ° ByteDance, thÃ¬ hiá»‡u nÄƒng suy giáº£m váº«n á»Ÿ má»©c cháº¥p nháº­n Ä‘Æ°á»£c.\n3. ÄÃ¡nh giÃ¡ - EVALUATION Äá»ƒ hiá»ƒu hÆ¡n vá» lá»£i Ã­ch vÃ  sá»± Ä‘Ã¡nh Ä‘á»•i cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘á» xuáº¥t,chÃºng ta xÃ¢y dá»±ng má»™t vÃ i thÃ­ nghiá»‡m vÃ  A/B testing trÃªn mÃ´i trÆ°á»ng thá»±c. Má»¥c tiÃªu lÃ  tráº£ lá»i cÃ¡c cÃ¢u há»i sau:\nLá»£i Ã­ch cá»§a collisionless hashtable lÃ  bao nhiÃªu?\nMá»©c Ä‘á»™ quang trá»ng cá»§a realtime training online?\nLiá»‡u ráº±ng mÃ´ hÃ¬nh thiáº¿t káº¿ cá»§a Monolith vá»›i cÃ¡c tham sá»‘ Ä‘Æ°á»£c Ä‘á»“ng bá»™ nhÆ° trÃªn Ä‘Ã£ Ä‘á»§ tá»‘t trong mÃ´i trÆ°á»ng thá»±c táº¿?\n3.1 Thiáº¿t láº­p thÃ­ nghiá»‡m 3.1.1 XÃ¢y dá»±ng embedding table NhÆ° mÃ´ táº£ á»Ÿ má»¥c 2.1, embedding table trong monolith lÃ  collisionless hashtable. Äá»ƒ chá»©ng minh sá»± cáº§n thiáº¿t cá»§a viá»‡c trÃ¡nh Ä‘á»¥ng Ä‘á»™ trong viá»‡c thiáº¿t káº¿ embedding table vÃ  lá»£i Ã­ch nháº­n Ä‘Æ°á»£c tá»« phiÃªn báº£n collisionless mÃ  mÃ´ hÃ¬nh Ä‘á» xuáº¥t, chÃºng ta thá»±c hiá»‡n hai nhÃ³m thÃ­ nghiá»‡m trÃªn táº­p Movielens vÃ  trong táº­p internal production dataset cá»§a ByteDance.\nHÃ¬nh 6: DeepFM model architecture - HÃ¬nh áº£nh Ä‘Æ°á»£c cáº¯t tá»« paper\nMovieLens. LÃ  táº­p dataset chuáº©n , má»Ÿ, bao gá»“m 25 triá»‡u Ä‘Ã¡nh giÃ¡ tá»« xáº¥p xá»‰ 162000 user vÃ  62000 bá»™ phim: Tiá»n xá»­ lÃ½ label. Label gá»‘c cá»§a táº­p cÃ³ giÃ¡ trá»‹ tá»« 0.5 Ä‘áº¿n 5, trong khi Ä‘Ã³, mÃ´ hÃ¬nh monolith nháº­n giÃ¡ trá»‹ binary tá»« user. ChÃºng ta sáº½ chuyá»ƒn giÃ¡ trá»‹ tá»« scale label sang binary label báº±ng viá»‡c Ä‘áº·t ngÆ°á»¡ng \u0026gt;=3.5 lÃ  positive sample vÃ  bÃ© hÆ¡n 3.5 lÃ  negative sample\nÄÃ¡nh giÃ¡ Model vÃ  metrics. ChÃºng ta sáº½ implement DeepFM model, má»™t kiáº¿n trÃºc model phá»• biáº¿n cho bÃ i toÃ¡n recommend. NÃ³ bao gá»“m thÃ nh pháº§n FM vÃ  thÃ nh pháº§n dense (xem ká»¹ hÃ¬nh 6).Sá»­ dá»¥ng AUC Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ giÃ¡ trá»‹ predict.\nÄÃ¡nh giÃ¡ Embedding collisions. Dataset nÃ y cÃ³ gáº§n 160k user vÃ  60k movie. Äá»ƒ so sÃ¡nh, chÃºng ta sáº½ sá»­ dá»¥ng MD5 lÃ m quÃ¢n Ä‘á» vÃ  mapping vÃ o má»™t nhÃ³m nhá» ID space, má»¥c Ä‘Ã­ch lÃ  lÃ m cho má»™t vÃ i ID sáº½ dÃ¹ng chung embedding vá»›i nhau. Báº£ng bÃªn dÆ°á»›i sáº½ hiá»ƒn thá»‹ chi tiáº¿t thá»‘ng kÃª cá»§a user vÃ  movie trÆ°á»›c vÃ  sau hash\nVPB User IDs Movie IDs # Before Hashing 162541 59047 # After Hashing 149970 57361 Collision rate 7.73% 2.86% Báº£ng 1: Thá»‘ng kÃª ID trÆ°á»›c vÃ  sau khi hash\n3.1.2 Online training Trong quÃ¡ trÃ¬nh online training, chÃºng ta sáº½ cáº­p nháº­t tham sá»‘ tá»« training PS sang online PS vá»›i táº§n suáº¥t theo phÃºt. ChÃºng ta thiáº¿t káº¿ hai nhÃ³m thÃ­ nghiá»‡m Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cá»§a mÃ´ hÃ¬nh vÃ  Ä‘á»™ táº£i cá»§a há»‡ thá»‘ng.\nUpdate frequency. Äá»ƒ Ä‘Ã¡nh giÃ¡ sá»± cáº§n thiáº¿t cá»§a viá»‡c update theo phÃºt, chÃºng ta xÃ¢y dá»±ng thÃ­ nghiá»‡m vá»›i táº§ng xuáº¥t update khÃ¡c nhau vÃ  xem sá»± hiá»‡u quáº£. ChÃºng ta sá»­ dá»¥ng Criteo Display Ads Challenge dataset (https://www.kaggle.com/competitions/criteo-display-ad-challenge/data), Ä‘Ã¢y lÃ  dataset Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ benchmarking CTR model. Data bao gá»“m 7 ngÃ y dá»¯ liá»‡u, ghi nháº­n feature vÃ  hÃ nh Ä‘á»™ng click cá»§a ngÆ°á»i dÃ¹ng. Trong thÃ­ nghiá»‡m nÃ y, chÃºng ta xÃ i mÃ´ hÃ¬nh DeepFM mÃ´ táº£ trong hÃ¬nh 6. Äá»ƒ mÃ´ phá»ng online training, chÃºng ta sáº½ chia táº­p dá»¯ liá»‡u thÃ nh 2 pháº§n. Pháº§n Ä‘áº§u tiÃªn lÃ  5 ngÃ y, dÃ¹ng Ä‘á»ƒ train, pháº§n thá»© 2 lÃ  2 ngÃ y cÃ²n láº¡i, dÃ¹ng cho online training. Trong 2 ngÃ y dá»¯ liá»‡u cá»§a pháº§n 2, chÃºng ta sáº½ chia thÃ nh N shard. ThÃ­ nghiá»‡m vá»›i N =10, 50, 100, tÆ°Æ¡ng á»©ng 5h (2 ngÃ y = 48 tiáº¿ng / 10 = 4.8 tiáº¿ng ~ 5 tiáº¿ng), 1h ( 48/50 ) vÃ  30 phÃºt cáº­p nháº­t dá»¯ liá»‡u má»™t láº§n.\nLive experiment. ThÃªm ná»¯a, chÃºng ta sáº½ thá»±c hiá»‡n thÃ­ nghiá»‡m thá»±c tháº¿ vá»›i real serving traffice Ä‘á»ƒ mÃ´ phá»ng sá»± quang trá»ng cá»§a online training trong á»©ng dá»¥ng thá»±c. ThÃ­ nghiá»‡m A/B testing nÃ y so online training (A) vs batch training (B). 3.2 Káº¿t quáº£ vÃ  phÃ¢n tÃ­ch 3.2.1 Hiá»‡u quáº£ cá»§a embedding collision HÃ¬nh 7: Effect of Embedding Collision On DeepFM, MovieLens\nCáº£ hai káº¿t quáº£ tá»« MovieLens dataset vÃ  Internal recommedation dataset Ä‘á»u chá»‰ ra ráº±ng collisions embedding gÃ¢y tá»•n háº¡i cho cháº¥t lÆ°á»£ng cá»§a mÃ´ hÃ¬nh.\nMÃ´ hÃ¬nh vá»›i collisionless HashTable cho káº¿t quáº£ tá»‘t hÆ¡n, luÃ´n cÃ³ Ä‘á»“ thá»‹ náº±m á»Ÿ ngoÃ i so vá»›i mÃ´ hÃ¬nh collision. Káº¿t luáº­n nÃ y luÃ´n luÃ´n Ä‘Ãºng, cho dÃ¹: TÄƒng sá»‘ lÆ°á»£ng training epoch. NhÆ° káº¿t quáº£ á»Ÿ hÃ¬nh 7. MÃ´ hÃ¬nh collisionless embedding table cÃ³ AUC cao hÆ¡n á»Ÿ epoch Ä‘áº§u tiÃªn, vÃ  há»™i tá»¥ vá»›i giÃ¡ trá»‹ cao hÆ¡n.\nThay Ä‘á»•i phÃ¢n phá»‘i theo thá»i gian (Concept Drift). NhÆ° hiá»ƒn thá»‹ trong hÃ¬nh 8, mÃ´ hÃ¬nh vá»›i collisionless embedding table cÅ©ng cho káº¿t quáº£ ráº¥t tá»‘t trong ngá»¯ cáº£nh user/items thay Ä‘á»•i.\nTÃ­nh thÆ°a cá»§a data Ä‘Æ°á»£c sinh ra bá»Ÿi collisionless embedding table sáº½ khÃ´ng lÃ m cho mÃ´ hÃ¬nh bá»‹ overfit. NhÆ° káº¿t quáº£ á»Ÿ hÃ¬nh 7, mÃ´ hÃ¬nh khÃ´ng bá»‹ overfit sau khi nÃ³ Ä‘Ã£ há»™i tá»¥ 3.2.2 Online Training: Trading-off Reliability For Realtime. HÃ¬nh 8: Effect of Embedding Collision On A Recommendation Model In Production.\nChÃºng ta khÃ¡m phÃ¡ ra ráº±ng viá»‡c Ä‘á»“ng bá»™ cÃ¡c tham sá»‘ vá»›i táº§ng suáº¥t cao thÃ¬ luÃ´n luÃ´n cáº£i tiáº¿n online serving AUC, vÃ  mÃ´ hÃ¬nh tá»‘t hÆ¡n so vá»›i ká»³ vá»ng.\nThe Effect of Parameter Synchronization Frequency. Trong thÃ­ nghiá»‡m vá» online stream training vá»›i Criteo Display Ads Challenge dataset, cháº¥t lÆ°á»£ng model sáº½ tá»‘t hÆ¡n náº¿u tÄƒng táº§ng suáº¥t Ä‘á»“ng bá»™ hoÃ¡ mÃ´ hÃ¬nh, chá»©ng minh báº±ng hai khÃ­a cáº¡nh sau: Model cÃ³ online training sáº½ tá»‘t hÆ¡n so vá»›i mÃ´ hÃ¬nh khÃ´ng cÃ³ online training. Xem hÃ¬nh 9\nModel cÃ³ táº§n suáº¥t cáº­p nháº­t cao sáº½ tá»‘t hÆ¡n so vá»›i mÃ´ hÃ¬nh cÃ³ tuáº§n suáº¥t cáº­p nháº­t tháº¥p. Xem hÃ¬nh 10 vÃ  báº£ng 2\nHÃ¬nh 9: : Online training v.s. Batch training on Criteo dataset. Blue lines: AUC of models with online training; Yellow lines: AUC of batch training models evaluated against streaming data.\nSync Interval Average AUC (online) Average AUC (batch) 5 hr 79.66 Â± 0.020 79.42 Â± 0.026 1 hr 79.78 Â± 0.005 79.44 Â± 0.030 30 min 79.80 Â± 0.008 79.43 Â± 0.025 Báº£ng 2: Average AUC comparison for DeepFM model on Criteo dataset\nHÃ¬nh 10: Comparison of different sync intervals for online training.\nBÃªn cáº¡nh cÃ¡c quan sÃ¡t nÃ y, chÃºng ta thá»±c hiá»‡n Ä‘á»“ng bá»™ sparse parameter vÃ o serving PS vá»›i táº§ng suáº¥t cÃ ng sá»›m cÃ ng tá»‘t (theo phÃºt) Ä‘á»ƒ má»Ÿ rá»™ng kháº£ nÄƒng tÃ­nh toÃ¡n vÃ  Ä‘á»™ tin cáº­y cá»§a há»‡ thá»‘ng.\nGiáº£ sá»­ ráº±ng cÃ¡c dense parameter yÃªu cáº§u táº§ng suáº¥t cáº­p nháº­t Ã­t hÆ¡n nhÆ° tháº£o luáº­n á»Ÿ má»¥c 2.2.3, chÃºng ta sáº½ cáº­p nháº­t chÃºng á»Ÿ má»©c ngÃ y, vÃ  xÃ¡c xuáº¥t há»‡ thá»‘ng bá»‹ quÃ¡ táº£i sáº½ ráº¥t tháº¥p. VÃ­ dá»¥ chÃºng ta cÃ³ 100k ID Ä‘Æ°á»£c cáº­p nháº­t trong 1 phÃºt, embedding cÃ³ kÃ­ch thÆ°á»›c 1024, tá»•ng kÃ­ch thÆ°á»›c cá»§a data cáº§n Ä‘á»ƒ chuyá»ƒn 4KB x 100000 = 40000 MB má»™t phÃºt. Vá»›i dense parameter, náº¿u chÃºng ta thá»±c hiá»‡n daily sync, chÃºng ta sáº½ chá»n thá»i Ä‘iá»ƒm sync mÃ  traffice lÃ  tháº¥p nháº¥t ( gáº§n sÃ¡ng cháº³ng háº¡n)\nThe effect of PS reliability Vá»›i viá»‡c Ä‘á»“ng bá»™ hoÃ¡ cÃ¡c tham sá»‘ á»Ÿ má»©c phÃºt, chÃºng ta tá»± nhiÃªn suy nghÄ© trong Ä‘áº§u ráº±ng táº§ng suáº¥t snapshot cÅ©ng nÃªn pháº£i tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhÆ° váº­y. Tuy nhiÃªn trong thá»±c táº¿, khi chÃºng ta sá»­ dá»¥ng snapshot vá»›i táº§ng suáº¥t 1 ngÃ y delay, cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh cÅ©ng khÃ´ng giáº£m quÃ¡ nhiá»u.\nViá»‡c tÃ¬m kiáº¿m Ä‘iá»ƒm cÃ¢n báº±ng giá»¯a cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh vÃ  nÄƒng lá»±c tÃ­nh toÃ¡n lÃ  ráº¥t khÃ³ trong bÃ nh toÃ¡n personalized ranking. Khi user cá»±c ká»³ nháº¡y cáº£m vá»›i cháº¥t lÆ°á»£ng recommendation. Theo truyá»n thá»‘ng, cÃ¡c há»‡ thá»‘ng lá»›n thÆ°á»ng cÃ³ xu hÆ°á»›ng Ä‘áº·t táº§ng xuáº¥t retrain theo hÆ°á»›ng hi sinh nÄƒng lá»±c tÃ­nh toÃ¡n (cháº¡y Ã¬ áº¡ch, lÃ¢u cÅ©ng Ä‘Æ°á»£c) vÃ  Ä‘Ã¡nh Ä‘á»•i bá»Ÿi cá»±c tiá»ƒu hoÃ¡ Ä‘á»™ lá»—i.\nVÃ­ dá»¥ vá»›i tá»· lá»‡ lá»—i 0.01 cá»§a PS machine / day, chÃºng ta sáº½ snapshot láº¡i tham sá»‘ cá»§a ngÃ y hÃ´m trÆ°á»›c, Giáº£ sá»­ dÃºng ta sharding parameter vÃ o 1000PS, chÃºng snapshot má»—i ngÃ y. Tá»· lá»‡ lá»—i 0.01%, má»—i má»™t mÃ¡y sáº½ bá»‹ lá»—i sau 10 ngÃ y , vÃ  chÃºng ta sáº½ máº¥t toÃ n bá»™ data cá»§a 1 ngÃ y cáº­p nháº­t. Giáº£ sá»­ DAU cá»§a 10 triá»‡u vÃ  chÃºng ta máº¥t 1 ngÃ y dá»¯ liá»‡u cá»§a 5k user má»—i 10 ngÃ y. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c cháº¥p nháº­n bá»Ÿi vÃ¬\na. Vá»›i cÃ¡c Ä‘áº·c trÆ°ng thÆ°a cá»§a user, nÃ³ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i tá»· lá»‡ máº¥t 0.01% DAU\nb. Vá»›i cÃ¡c Ä‘áº·c trÆ°ng Dense, chÃºng ta cáº­p nháº­t khÃ¡ cháº­m, nhÆ° tháº£o luáº­n á»Ÿ má»¥c 2.2.3, viá»‡c máº¥t 1 ngÃ y update cá»§a 1000 PS lÃ  khÃ´ng Ä‘Ã¡ng ká»ƒ.\nQua nhá»¯ng quan sÃ¡t vÃ  tÃ­nh toÃ¡n á»Ÿ trÃªn, chÃºng ta cÃ³ thá»ƒ káº¿t luáº­n ráº±ng táº§ng xuáº¥t snapshot tháº¥p khÃ´ng áº£nh hÆ°á»Ÿng nhiá»u Ä‘áº¿n kháº£ nÄƒng chá»‹u lá»—i, vÃ  giáº£m kháº£ nÄƒng xá»­ lÃ½ cá»§a há»‡ thá»‘ng.\nCáº£m Æ¡n nhÃ³m ká»¹ sÆ° ByteDance Ä‘Ã£ cung cáº¥p ráº¥t nhiá»u thÃ´ng tin há»¯u Ã­ch trong bÃ i viáº¿t. Hi vá»ng láº§n sau sáº½ Ä‘á»c Ä‘Æ°á»£c nhiá»u bÃ i cháº¥t lÆ°á»£ng hÆ¡n tháº¿ ná»¯a.\nTÃ i liá»‡u tham kháº£o cá»§a paper [1] \u0026ldquo;MartÃ­n Abadi, Paul Barham, Jianmin Chen, Z. Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek Gordon Murray, Benoit Steiner, Paul A. Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zhang. 2016. TensorFlow: A system for large-scale machine learning. ArXiv abs/1605.08695 (2016).\u0026rdquo;\n[2] Andrew P. Bradley. 1997. The use of the area under the ROC curve in the evaluation of machine learning algorithms. Pattern Recognit. 30 (1997), 1145â€“1159.\n[3] Thomas Bredillet. 2019. Core modeling at Instagram. https://instagram\u0002engineering.com/core-modeling-at-instagram-a51e0158aa48\n[4] Paris Carbone, Asterios Katsifodimos, Stephan Ewen, Volker Markl, Seif Haridi, and Kostas Tzoumas. 2015. Apache Flinkâ„¢: Stream and Batch Processing in a Single Engine. IEEE Data Eng. Bull. 38 (2015), 28â€“38.\n[5] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishikesh B. Aradhye, Glen Anderson, Gregory S. Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah. 2016. Wide \u0026amp; Deep Learning for Recommender Systems. Proceedings of the 1st Workshop on Deep Learning for Recommender Systems (2016).\n[6] Paul Covington, Jay K. Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. Proceedings of the 10th ACM Conference on Recommender Systems (2016).\n[7] Alexandra Egg. 2021. Online Learning for Recommendations at Grubhub. Fif\u0002teenth ACM Conference on Recommender Systems (2021).\n[8] JoÃ£o Gama, Indre Å½liobait Ë™ e, Albert Bifet, Mykola Pechenizkiy, and A. Bouchachia. 2014. A survey on concept drift adaptation. ACM Computing Surveys (CSUR) 46 (2014), 1 â€“ 37.\n[9] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. In IJCAI.\n[10] Udit Gupta, Xiaodong Wang, Maxim Naumov, Carole-Jean Wu, Brandon Reagen, David M. Brooks, Bradford Cottel, Kim M. Hazelwood, Bill Jia, Hsien-Hsin S. Lee, Andrey Malevich, Dheevatsa Mudigere, Mikhail Smelyanskiy, Liang Xiong, and Xuan Zhang. 2020. The Architectural Implications of Facebookâ€™s DNN-Based Personalized Recommendation. 2020 IEEE International Symposium on High Performance Computer Architecture (HPCA) (2020), 488â€“501.\n[11] F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Trans. Interact. Intell. Syst. 5 (2015), 19:1â€“19:19.\n[12] Biye Jiang, Chao Deng, Huimin Yi, Zelin Hu, Guorui Zhou, Yang Zheng, Sui Huang, Xinyang Guo, Dongyue Wang, Yue Song, Liqin Zhao, Zhi Wang, PengSun, Yu Zhang, Di Zhang, Jinhui Li, Jian Xu, Xiaoqiang Zhu, and Kun Gai. 2019 XDL: an industrial deep learning framework for high-dimensional sparse data. Proceedings of the 1st International Workshop on Deep Learning Practice for High\u0002Dimensional Sparse Data (2019).\n[13] Jay Kreps. 2011. Kafka : a Distributed Messaging System for Log Processing.\n[14] Xiangru Lian, Binhang Yuan, Xuefeng Zhu, Yulong Wang, Yongjun He, Honghuan Wu, Lei Sun, Haodong Lyu, Chengjun Liu, Xing Dong, Yiqiao Liao, Mingnan Luo, Congfei Zhang, Jingru Xie, Haonan Li, Lei Chen, Renjie Huang, Jianying Lin, Chengchun Shu, Xue-Bo Qiu, Zhishan Liu, Dongying Kong, Lei Yuan, Haibo Yu, Sen Yang, Ce Zhang, and Ji Liu. 2021. Persia: An Open, Hybrid System Scaling Deep Learning-based Recommenders up to 100 Trillion Parameters. ArXivabs/2111.05897 (2021).\n[15] Meituan. 2021. Distributed Training Optimization for TensorFlow in Recom\u0002mender Systems (in Chinese). https://tech.meituan.com/202112/09/meituantensorflow-in-recommender-systems.html\n[16] R. Pagh and Flemming Friche Rodler. 2001. Cuckoo Hashing. In ESA.\n[17] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas KÃ¶pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In NeurIPS.\n[18] Konstantin V. Shvachko, Hairong Kuang, Sanjay R. Radia, and Robert J. Chansler. 2010. The Hadoop Distributed File System. 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST) (2010), 1â€“10.\n[19] HaiYing Wang, Aonan Zhang, and Chong Wang. 2021. Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data. In Advances in Neural Information Processing Systems.\n[20] Minhui Xie, Kai Ren, Youyou Lu, Guangxu Yang, Qingxing Xu, Bihai Wu, Jiazhen Lin, Hongbo Ao, Wanhong Xu, and Jiwu Shu. 2020. Kraken: Memory-Efficient Continual Learning for Large-Scale Real-Time Recommendations. SC20: Inter\u0002national Conference for High Performance Computing, Networking, Storage and Analysis (2020), 1â€“17.\n[21] Weijie Zhao, Jingyuan Zhang, Deping Xie, Yulei Qian, Ronglai Jia, and Ping Li.2019. AIBox: CTR Prediction Model Training on a Single Node. Proceedings of the 28th ACM International Conference on Information and Knowledge Management (2019).\nTham kháº£o https://arxiv.org/pdf/2209.07663.pdf\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ dÃ nh thá»i gian Ä‘á»c bÃ i tÃ³m táº¯t nÃ y cá»§a mÃ¬nh. Náº¿u cÃ³ báº¥t ká»³ váº¥n Ä‘á» gÃ¬, hÃ£y Ä‘á»ƒ láº¡i comment bÃªn dÆ°á»›i hoáº·c email cho mÃ¬nh qua Ä‘á»‹a chá»‰ alexblack2202@gmail.com. Háº¹n gáº·p láº¡i cÃ¡c báº¡n á»Ÿ bÃ i viáº¿t tiáº¿p theo.\n","date":"Dec 1, 2022","img":"https://unsplash.it/1920/1080?image=18","permalink":"/blog/2022-12-01-tiktok-recommendation/","series":null,"tags":["Machine Learning","Tikok","Deep Learning","ByteDance","Recommendation"],"title":"Tiktok Real Time Recommendation"},{"categories":null,"content":"Má»¥c tiÃªu cá»§a chÃºng ta hÃ´m nay lÃ  khÃ¡m phÃ¡ táº­p dataset netflix nÃ y, Ä‘á»ƒ khÃ¡m phÃ¡ vÃ  Ä‘Ã o xá»›i nhá»¯ng thÃ´ng tin áº©n bÃªn trong, phá»¥c vá»¥ cho viá»‡c ra quyáº¿t Ä‘á»‹nh loáº¡i phim/ chÆ°Æ¡ng trÃ¬nh nÃ o nÃªn sáº£n xuáº¥t vÃ  chÃºng ta nÃªn Ä‘á» xuáº¥t loáº¡i hÃ¬nh kinh doanh nÃ o cho má»—i quá»‘c gia khÃ¡c nhau.\nTrá»±c quan hoÃ¡ dá»¯ liá»‡u - Data Visualization Trá»±c quan hoÃ¡ dá»¯ liá»‡u - Data Visualization Dataset cÃ¡c báº¡n cÃ³ thá»ƒ download á»Ÿ Ä‘Ã¢y: https://www.kaggle.com/datasets/shivamb/netflix-shows\nÄáº§u tiÃªn, chÃºng ta sáº½ import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t Ä‘á»ƒ phá»¥c vá»¥ cho viá»‡c phÃ¢n tÃ­ch. CÃ¡c nhÆ° viá»‡n khÃ´ng thá»ƒ thiáº¿u lÃ  pandas, matplotlib, seaborn, numpy.\n1 2import matplotlib.pyplot as plt 3 4import seaborn as sns 5 6import pandas as pd NgÃ³ sÆ¡ qua dataset, chÃºng ta cÃ³ cÃ¡c cá»™t nhÆ° sau:\nShow_id: mÃ£ Ä‘á»‹nh danh duy nháº¥t cho cÃ¡c show / phim\nType: Loáº¡i chÆ°Æ¡ng trÃ¬nh\nTitle: TÃªn phim / show\nDirector: TÃªn Ä‘áº¡o diá»…n\nCast: Diá»…n viÃªn chÃ­nh\nCountry: Quá»‘c gia nÆ¡i bá»™ phim Ä‘Æ°á»£c sáº£n xuáº¥t\nDate_added: NgÃ y Ä‘Æ°á»£c Ä‘Æ°a lÃªn há»‡ thá»‘ng netflix\nRelease_year: NgÃ y hoÃ n thÃ nh bá»™ phim\nRating: Äiá»ƒm yÃªu thÃ­ch cá»§a bá»™ phim\nDuration: Thá»i gian cá»§a bá»™ phim, hoáº·c sá»‘ táº­p .\nListed_in: Thá»ƒ loáº¡i phim\nDescription: MÃ´ táº£ sÆ¡ bá»™ vá» bá»™ phim\nBÃ¢y giá», chÃºng ta load dá»¯ liá»‡u báº±ng pandas vÃ  phÃ¢n tÃ­ch thá»­\n1 2data=pd.read_csv(\u0026#39;netflix.csv\u0026#39;) 3 4print(data.shape) 5 6\u0026gt;\u0026gt;\u0026gt;(8807, 12) Data cÃ³ 12 cá»™t nhÆ° Ä‘Ã£ Ä‘á» cáº­p á»Ÿ trÃªn, 8807 dÃ²ng. NgÃ³ xem phÃ¢n bá»‘ dá»¯ liá»‡u rá»—ng nhÆ° tháº¿ nÃ o\n1 2plt.figure(figsize=(8,8)) 3sns.heatmap(data.isna()) 4 5plt.show() NhÃ¬n vÃ o biá»ƒu Ä‘á»“ trÃªn, chÃºng ta tháº¥y ráº±ng cá»™t director bá»‹ lá»§ng NA nhiá»u nháº¥t, tiáº¿p Ä‘áº¿n lÃ  cá»™t cast vÃ  cá»™t country. Cá»™t Date_added vÃ  vÃ  rating lá»§ng chÃºt chÃºt, cÃ¡c cá»™t cÃ²n láº¡i khÃ¡ tá»‘t.\nDo cá»™t director bá»‹ lá»§ng nhiá»u, nÃªn chÃºng ta sáº½ bá» qua, khÃ´ng phÃ¢n tÃ­ch top 10 Ä‘áº¡o Ä‘iá»…n cÃ³ sá»‘ lÆ°á»£ng phim nhiá»u nháº¥t. TÆ°Æ¡ng tá»± nhÆ° váº­y vá»›i cá»™t diá»…n viÃªn chÃ­nh (cast), vÃ  cá»™t quá»‘c gia sáº£n xuáº¥t (country). NgÃ³ Ä‘i ngÃ³ láº¡i, chá»‰ cÃ²n cÃ³ liá»‡t kÃª top 10 thá»ƒ loáº¡i phim (Listed_in) Ä‘Æ°á»£c sáº£n xuáº¥t nhiá»u nháº¥t .\n1 2plt.figure(figsize=(16,16)) 3data[\u0026#34;listed_in\u0026#34;].value_counts()[:10].plot(kind=\u0026#34;barh\u0026#34;, color=\u0026#34;orange\u0026#34;) 4plt.title(\u0026#34;Top 10 thá»ƒ loáº¡i phim trÃªn NETFLIX\u0026#34;,size=20) 5 6plt.show() Phim truyá»n hÃ¬nh vÃ  phim tÃ i liá»‡u cÃ³ sá»‘ lÆ°á»£ng phim nhiá»u nháº¥t, tiáº¿p theo lÃ  phim hÃ i\nDo Na á»Ÿ cá»™t country khÃ¡ nhiá»u, nÃªn chÃºng ta sáº½ loáº¡i bá» háº¿t cÃ¡c dÃ²ng cÃ³ contry na Ä‘i\n1 2df = data.copy() 3df[\u0026#39;country\u0026#39;] = df[\u0026#39;country\u0026#39;].ffill(axis=0) 4df.head(10) Quan sÃ¡t dá»¯ liá»‡u cá»™t country, chÃºng ta nháº­n tháº¥y ráº±ng cÃ³ nhiá»u phim Ä‘Æ°á»£c quay á»Ÿ nhiá»u Ä‘á»‹a Ä‘iá»ƒm, nÃªn chÃºng ta ta cáº§n xá»­ lÃ½ láº¡i chá»— nÃ y má»™t chÃºt. ÄÆ¡n giáº£n lÃ  mÃ¬nh chá»‰ láº¥y quá»‘c gia Ä‘áº§u tiÃªn xuáº¥t hiá»‡n trong cá»™t country.\n1 2df[\u0026#39;trim_country\u0026#39;] = df[\u0026#39;country\u0026#39;].apply(lambda x: x.split(\u0026#39;,\u0026#39;)[0]) 3df.head(10) Thá»­ show ra biá»ƒu Ä‘á»“ rating cá»§a top 5 quá»‘c gia nhiá»u phim nháº¥t\n1 2 3countries = df[\u0026#39;trim_country\u0026#39;].unique() 4 5ratings = df[\u0026#39;rating\u0026#39;].unique() 6 7fig = plt.figure( 8 figsize=(20,30) 9 ) 10 11for i, name in enumerate(countries[:5]): 12 frame = df[df[\u0026#39;trim_country\u0026#39;] == str(name)] 13 ax = fig.add_subplot(len(countries[:5]),1,i+1) 14 topic = name 15 sns.countplot(x=\u0026#39;rating\u0026#39;, data= frame[frame[\u0026#39;rating\u0026#39;].isin(ratings)]) 16 ax.set_title(topic) 17 plt.subplots_adjust(left=0.1, 18 bottom=0.1, 19 right=0.9, 20 top=0.9, 21 wspace=0.4, 22 hspace=0.4) 23 ax.set(ylabel=\u0026#39;Content Produced\u0026#39;) Thá»­ show ra biá»ƒu Ä‘á»“ Ä‘áº¿m thá»ƒ loáº¡i phim Ä‘Æ°á»£c quay trÃªn top 5 quá»‘c gia cÃ³ nhiá»u phim nháº¥t xem nhÆ° tháº¿ nÃ o\n1 2countries = df[\u0026#39;trim_country\u0026#39;].unique() 3 4listing = df[\u0026#39;trim_listed_in\u0026#39;].unique() 5ratings = df[\u0026#39;rating\u0026#39;].unique() 6 7fig = plt.figure( 8 figsize=(40,30) 9 ) 10 11for i, name in enumerate(countries[:5]): 12 frame = df[df[\u0026#39;trim_country\u0026#39;] == str(name)] 13 ax = fig.add_subplot(len(countries[:5]),1,i+1) 14 topic = name 15 sns.countplot(x=\u0026#39;trim_listed_in\u0026#39;, data= frame[frame[\u0026#39;trim_listed_in\u0026#39;].isin(listing)]) 16 ax.set_title(topic) 17 plt.subplots_adjust(left=0.1, 18 bottom=0.1, 19 right=0.9, 20 top=0.9, 21 wspace=0.4, 22 hspace=0.4) 23 ax.set(ylabel=\u0026#39;Content Produced\u0026#39;) CÃ²n nhiá»u cÃ¡i Ä‘á»ƒ khÃ¡m phÃ¡ ná»¯a, vÃ­ dá»¥\nTop 10 diá»…n viÃªn xuáº¥t hiá»‡n nhiá»u nháº¥t trÃªn TV Shows\nTop 10 diá»…n viÃªn xuáº¥t hiá»‡n nhiá»u nháº¥t trÃªn Movies\nTV Shows nhiá»u mÃ¹a nháº¥t\nThá»i gian cÃ´ng chiáº¿u dÃ i nháº¥t\nTham kháº£o:\nhttps://www.kaggle.com/code/shivamb/netflix-shows-and-movies-exploratory-analysis/notebook\nhttps://www.analyticsvidhya.com/blog/2021/09/performing-eda-of-netflix-dataset-with-plotly/\nhttps://medium.datadriveninvestor.com/netflix-data-exploration-and-visualization-1d270234c2d4\nhttps://public.tableau.com/views/DataVizProject_16166857387730/dashboard_assignement?%3Aembed=y\u0026%3AshowVizHome=no\u0026%3Adisplay_count=y\u0026%3Adisplay_static_image=y\u0026%3AbootstrapWhenNotified=true\u0026%3Alanguage=en\u0026%3Amobile=true\u0026:embed=y\u0026:showVizHome=n\u0026:apiID=host0\nhttps://jovian.ai/shagunsharma04061998/netflix-data-analysis/v/1?utm_source=embed#C33\n","date":"Aug 2, 2022","img":"https://unsplash.it/1920/1080?image=19","permalink":"/blog/2022-08-02-data-exploration-and-data-visualization/","series":null,"tags":["Machine Learning","Normalization","Deep Learning"],"title":"Data Visualization - Pháº§n 1 - PhÃ¢n TÃ­ch Dá»¯ Liá»‡u Netflix"},{"categories":null,"content":"Photo mÃ¬nh láº¥y tá»« unsplash\nPython lÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh ná»•i tiáº¿ng vÃ¬ tÃ­nh cá»±c ká»³ linh hoáº¡t. Trong bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ liá»‡t kÃª 7 cÃ¡ch Ä‘á»ƒ Ä‘á»c ná»™i dung file sá»­ dá»¥ng ngÃ´n ngá»¯ Python.\nCÃ¡ch 1: Sá»­ dá»¥ng hÃ m open CÃ¡ch 2: má»Ÿ file sá»­ dá»¥ng context manager CÃ¡ch 3: Sá»­ dá»¥ng thÆ° viá»‡n pathlib CÃ¡ch 4: Sá»­ dá»¥ng shell CÃ¡ch 5: XÃ¢y dá»±ng má»™t thÆ° viá»‡n Ä‘á»c file báº±ng c CÃ¡ch 1: Sá»­ dá»¥ng hÃ m open CÃ¡ch Ä‘áº§u tiÃªn, cÅ©ng lÃ  cÃ¡ch vá»¡ lÃ²ng / giÃ¡o khoa/ trÆ°á»ng lá»›p, lÃ  sá»­ dá»¥ng hÃ m open, tráº£ vá» má»™t stream. Sau Ä‘Ã³, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng hÃ m read Ä‘á»ƒ láº¥y ná»™i dung tá»« stream.\nVÃ­ dá»¥, chÃºng ta sáº½ Ä‘á»c file thegioididong.txt báº±ng ngÃ´n ngá»¯ python nhÆ° sau:\n1 2tgdd = open(\u0026#39;thegioididong.txt\u0026#39;,\u0026#39;r\u0026#39;) 3 4lines = tgdd.read() 5print(lines) 6 7tgdd.close() Æ¯u Ä‘iá»ƒm:\nKhÃ´ng pháº£i include thÃªm thÆ° viá»‡n\nCode ngáº¯n gá»n\nKhuyáº¿t Ä‘iá»ƒm:\nPháº£i close file sau khi sá»­ dá»¥ng xong CÃ¡ch 2: má»Ÿ file sá»­ dá»¥ng context manager TrÃªn stackoverflow thÆ°á»ng khuyÃªn chÃºng ta sá»­ dá»¥ng cÃ¡ch nÃ y\n1 2with open(\u0026#39;thegioididong.txt\u0026#39;,\u0026#39;r\u0026#39;) as tgdd: 3 4 lines = tgdd.read() 5 print(lines) Æ¯u Ä‘iá»ƒm:\nKhÃ´ng pháº£i Ä‘Ã³ng file sau khi sá»­ dá»¥ng xong\nNgÄƒng ngá»«a memory leaks khi cÃ³ lá»—i trong quÃ¡ trÃ¬nh xá»­ lÃ½ vÃ  khÃ´ng gá»i Ä‘Ã³ng file.\nCÃ¡ch 3: Sá»­ dá»¥ng thÆ° viá»‡n pathlib CÃ¡ch dÃ¹ng cÅ©ng khÃ¡ dá»…, chá»‰ cáº§n include thÆ° viá»‡n vÃ o lÃ  xÃ i thÃ´i\n1 2import pathlib 3tgdd = pathlib.Path(\u0026#34;thegioididong.txt\u0026#34;) 4lines = tgdd.read_text() CÃ¡ch nÃ y cÅ©ng hay, khÃ´ng pháº£i Ä‘Ã³ng má»Ÿ file, chá»‰ cáº§n gá»i hÃ m Ä‘á»c lÃ  Ä‘Æ°á»£c. Code thÃ¬ ngáº¯n gá»n, láº¡i khÃ´ng pháº£i thÃ² ra thá»¥t vÃ o nhÆ° lÃ  context manager\nCÃ¡ch 4: Sá»­ dá»¥ng shell ChÃºng ta cÃ³ thá»ƒ dÃ¹ng python, gá»i shell script trong linux , vÃ  láº¥y káº¿t quáº£ tráº£ vá».\nÄá»ƒ sá»­ dá»¥ng cÃ¡ch nÃ y, chÃºng ta sá»­ dá»¥ng thÆ° viá»‡n subprocess\n1 2import subprocess 3output = subprocess.run([\u0026#34;cat\u0026#34;, \u0026#34;thegioididong.txt\u0026#34;], capture_output=True) 4lines = output.stdout.decode() NÃ y lÃ  má»™t cÃ¡ch cÃ³ thá»ƒ dÃ¹ng Ä‘Æ°á»£c, tuy nhiÃªn, má»™t sá»‘ file cÃ³ thá»ƒ bá»‹ lá»—i encode. TÃºm láº¡i lÃ  khÃ´ng nÃªn xÃ i cÃ¡i nÃ y\nCÃ¡ch 5: XÃ¢y dá»±ng má»™t thÆ° viá»‡n Ä‘á»c file báº±ng c Äá»ƒ sá»­ dá»¥ng cÃ¡ch nÃ y, cÃ¡c báº¡n cáº§n pháº£i cÃ i báº£n python3-dev vÃ o mÃ¡y trÆ°á»›c (trÃªn ubuntu).\nVÃ­ dá»¥, chÃºng ta sáº½ táº¡o má»™t file mwg_file.c nhÆ° sau\n1#define PY_SSIZE_T_CLEAN 2#include \u0026lt;Python.h\u0026gt; 3 4 5PyObject* mwgread(PyObject* self, PyObject* args) { 6 7 8 FILE * pFile; 9 size_t lSize; 10 char * buffer; 11 size_t result; 12 13 // Parse the Python object arguments into C variables 14 char* filename; 15 if (!PyArg_ParseTuple(args, \u0026#34;s\u0026#34;, \u0026amp;filename)) { 16 return NULL; 17 } 18 19 // Try to open the file 20 pFile = fopen(filename, \u0026#34;r\u0026#34;); 21 if (pFile == NULL) { 22 return NULL; 23 } 24 25 // obtain file size: 26 fseek (pFile , 0 , SEEK_END); 27 lSize = ftell (pFile); 28 rewind (pFile); 29 30 // allocate memory to contain the whole file: 31 buffer = (char*) malloc (sizeof(char)*lSize); 32 if (buffer == NULL) {fputs (\u0026#34;Memory error\u0026#34;,stderr); exit (2);} 33 34 // copy the file into the buffer: 35 result = fread (buffer,1,lSize,pFile); 36 if (result != lSize) {fputs (\u0026#34;Reading error\u0026#34;,stderr); exit (3);} 37 38 /* the whole file is now loaded in the memory buffer. */ 39 40 // terminate 41 fclose (pFile); 42 return Py_BuildValue(\u0026#34;s\u0026#34;, buffer); 43} 44 45 46PyMethodDef module_methods[] = { 47 {\u0026#34;read\u0026#34;, mwgread, METH_VARARGS, \u0026#34;Reads a file and returns its contents\u0026#34;}, 48 {NULL} 49}; 50 51struct PyModuleDef file_module = { 52 PyModuleDef_HEAD_INIT, 53 \u0026#34;MWGFile\u0026#34;, 54 NULL, 55 -1, 56 module_methods 57}; 58 59PyMODINIT_FUNC PyInit_MWGFile(void) { 60 return PyModule_Create(\u0026amp;file_module); 61} Má»™t pháº§n code c trÃªn mÃ¬nh láº¥y tá»« https://cplusplus.com/reference/cstdio/fread/\nSau Ä‘Ã³, chÃºng ta sáº½ táº¡o file setup.py, file nÃ y Ä‘á»ƒ chung thÆ° má»¥c vá»›i file .c\n1 2from distutils.core import setup, Extension 3 4setup( 5 name=\u0026#39;MWGFile\u0026#39;, 6 ext_modules=[Extension(\u0026#39;MWGFile\u0026#39;, sources=[\u0026#39;mwg_file.c\u0026#39;])] 7) Cuá»‘i cÃ¹ng, chÃºng ta gá»i hÃ m Ä‘á»ƒ biÃªn dá»‹ch file c vÃ  cÃ i vÃ o thÆ° viá»‡n há»‡ thá»‘ng\n1 2python3 setup.py build 3python3 setup.py install --user Äá»ƒ cháº¡y thÆ° viá»‡n c vá»«a má»›i biÃªn dá»‹ch, chÃºng ta sá»­ dá»¥ng lá»‡nh sau\n1 2import MWGFile 3contents = MWGFile.read_file(\u0026#34;thegioididong.txt\u0026#34;) 4print(contents) CÃ¡ch nÃ y khÃ¡ cá»±c, pháº£i reimplement láº¡i nhá»¯ng gÃ¬ cá»™ng Ä‘á»“ng Ä‘Ã£ lÃ m sáºµn, nhÆ°ng mÃ  cÅ©ng nÃªn thá»­ Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c thÆ° viá»‡n ná»™i bá»™ cá»§a riÃªng mÃ¬nh.\nTÃ i liá»‡u tham kháº£o\nhttps://www.w3schools.com/python/python_file_open.asp\nhttps://betterprogramming.pub/7-ways-of-reading-a-file-in-python-855340b002dc\n","date":"Jul 31, 2022","img":"https://unsplash.it/1920/1080?image=20","permalink":"/blog/2022-07-31-5-way-open-file/","series":null,"tags":["Machine Learning","Normalization","Deep Learning"],"title":"5 CÃ¡ch Má»Ÿ File Trong Python"},{"categories":"python","content":"Ná»™i dung bÃ i viáº¿t nÃ y sáº½ Ä‘á» cáº­p Ä‘áº¿n cÃ¡c chá»§ Ä‘á»\nHÃ m trong python Tham sá»‘ máº·c Ä‘á»‹nh Arbitrary Arguments Keyword Arguments Arbitrary Keyword Arguments HÃ m Lambda trong python HÃ m map HÃ m filter HÃ m reduce HÃ m trong python HÃ m lÃ  má»™t khá»‘i lá»‡nh, Ä‘Æ°á»£c thá»±c thi khi Ä‘Æ°á»£c gá»i.\nHÃ m Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a báº±ng tá»« khoÃ¡ def.\nHÃ m cÃ³ thá»ƒ nháº­n dá»¯ liá»‡u truyá»n vÃ o, Ä‘Æ°á»£c gá»i lÃ  tham sá»‘\nHÃ m cÃ³ thá»ƒ tráº£ vá» dá»¯ liá»‡u\nVÃ­ dá»¥\n1 2def isSoChan(x:int): # khai bÃ¡o hÃ m cÃ³ tÃªn lÃ  isSoChan, vá»›i tham sá»‘ truyá»n vÃ o kiá»ƒu int 3 if x \u0026lt;0: 4 return False 5 if x % 2 != 0: 6 return False 7 return True 8 9isSoChan(5) # gá»i thá»±c thi hÃ m isSoChan, vá»›i giÃ¡ trá»‹ cá»§a tham sá»‘ x lÃ  5 Tham sá»‘ máº·c Ä‘á»‹nh Má»™t sá»‘ hÃ m sáº½ cÃ³ tham sá»‘ máº·c Ä‘á»‹nh, sá»­ dá»¥ng khi ta bá» trá»‘ng, khÃ´ng truyá»n giÃ¡ trá»‹ cho tham sá»‘, vÃ­ dá»¥ nhÆ° lÃ  tham sá»‘ start cá»§a hÃ m range cÃ³ giÃ¡ trá»‹ máº·c Ä‘á»‹nh lÃ  0.\n1 2def printCountry(contry_name = \u0026#34;Viá»‡t Nam\u0026#34;): 3 print(contry_name) 4 5 6printCountry(\u0026#34;USA\u0026#34;) 7printCountry() 8 9#Káº¿t quáº£ 10 11\u0026gt;\u0026gt;\u0026gt; printCountry(\u0026#34;USA\u0026#34;) 12USA 13\u0026gt;\u0026gt;\u0026gt; printCountry() 14Viá»‡t Nam Arbitrary Arguments ÄÃ´i khi, chÃºng ta khÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c sá»‘ lÆ°á»£ng tham sá»‘ truyá»n vÃ o, python há»— trá»£ ta quÄƒng cÃ¡c giÃ¡ trá»‹ truyá»n dÆ° vÃ o má»™t tham sá»‘ cáº¥p 1. TÃªn viáº¿t táº¯t cá»§a dáº¡ng nÃ y lÃ  *args\nVÃ­ dá»¥\n1def info(name, *args): 2 print(f\u0026#34;input name: {name}\u0026#34;) 3 for item in args: 4 print(f\u0026#34;other info: {item}\u0026#34;) 5 6info(\u0026#34;alex\u0026#34;,\u0026#34;18\u0026#34;,\u0026#34;staff\u0026#34;,\u0026#34;samsung\u0026#34;,\u0026#34;apple\u0026#34;) 7 8#Káº¿t quáº£: 9 10input name: alex 11other info: 18 12other info: staff 13other info: samsung 14other info: apple Keyword Arguments Äá»ƒ gá»i hÃ m má»™t cÃ¡ch tÆ°á»ng minh, python cho phÃ©p truyá»n tham sá»‘ báº±ng cÃ¡ch chá»‰ rÃµ tÃªn tham sá»‘ cáº§n truyá»n dá»¯ liá»‡u\nVÃ­ dá»¥\n1def info(name, age, position): 2 print(f\u0026#34;name {name} age {age} position {position}\u0026#34;) 3 4info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 5 6 7info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 8 9# Káº¿t quáº£: 10 11\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 12name alex age 18 position staff 13\u0026gt;\u0026gt;\u0026gt; 14\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 15name bill age 18 position staff Arbitrary Keyword Arguments Trong trÆ°á»ng há»£p cÃ³ nhiá»u tham sá»‘ quÃ¡, chÃºng ta cÃ³ thá»ƒ viáº¿t tá»•ng há»£p cÃ¡c tham sá»‘ dÆ°á»›i dáº¡ng tham sá»‘ cáº¥p 2. TÃªn viáº¿t táº¯t cá»§a dáº¡ng nÃ y lÃ  **kwargs\nVÃ­ dá»¥\n1 2def info(**data): 3 print(f\u0026#34;name {data[\u0026#39;name\u0026#39;]} age {data[\u0026#39;age\u0026#39;]} position {data[\u0026#39;position\u0026#39;]}\u0026#34;) 4 5info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 6 7 8info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 9 10 11# Káº¿t quáº£ 12 13\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 14name alex age 18 position staff 15\u0026gt;\u0026gt;\u0026gt; 16\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 17name bill age 18 position staff HÃ m Lambda trong python HÃ m Lambda lÃ  hÃ m chá»‰ cÃ³ má»™t biá»ƒu thá»©c\nHÃ m Lambda cÃ³ thá»ƒ nháº­n nhiá»u tham sá»‘\nCÃº phÃ¡p\n1 2lambda arguments : expression VÃ­ dá»¥:\n1 2info = lambda name, age, position : f\u0026#34;name {name} age {age} position {position}\u0026#34; 3 4info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 5 6# Káº¿t quáº£ 7\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 8\u0026#39;name alex age 18 position staff\u0026#39; Sá»©c máº¡nh cá»§a lambda Ä‘Æ°á»£c khai thÃ¡c tá»‘i Ä‘a, khi lamda lÃ  tham sá»‘ cá»§a má»™t hÃ m khÃ¡c.\nHÃ m map CÃº phÃ¡p\n1 2map(function, iterable) Do input cá»§a map lÃ  function, nÃªn nÃ³ cÃ³ thá»ƒ lÃ  má»™t hÃ m tÆ°á»ng minh, hoáº·c lÃ  má»™t lambda function\nVÃ­ dá»¥:\nHÃ£y nhÃ¢n Ä‘Ã´i táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ trong list\n1 2aList = [1,2,3,4,5] 3 4# CÃ¡ch viáº¿t thÃ´ng thÆ°á»ng 5 6def square(x:int): 7 return x**2 8 9newList = [] 10for x in aList: 11 newList.append(square(x)) 12 13print(newList) 14 15# CÃ¡ch viáº¿t sá»­ dá»¥ng list comprehension 16 17newList = [x**2 for x in newList] 18print(newList) 19 20# CÃ¡ch viáº¿t sá»­ dá»¥ng map káº¿t há»£p lambda 21 22newList = list(map(lambda x:x**2,aList)) 23 24print(newList) 25 26\u0026gt;\u0026gt;\u0026gt; print(newList) 27[1, 4, 9, 16, 25] HÃ m filter CÃº phÃ¡p\n1 2filter(function, iterable) HÃ m nÃ y tá»±a tá»±a nhÆ° list comprehension vá»›i if contion\nVÃ­ dá»¥:\nHÃ£y lá»c ra cÃ¡c pháº§n tá»­ lÃ  sá»‘ cháºµn\n1 2aList = [1,2,3,4,5] 3 4# CÃ¡ch viáº¿t thÃ´ng thÆ°á»ng 5 6def isEven(x:int): 7 return x%2==0 8 9newList = [] 10for x in aList: 11 newList.append(isEven(x)) 12 13print(newList) 14 15# CÃ¡ch viáº¿t sá»­ dá»¥ng list comprehension 16 17newList = [x for x in newList if x %2 ==0] 18print(newList) 19 20# CÃ¡ch viáº¿t sá»­ dá»¥ng filter káº¿t há»£p lambda 21 22newList = list(filter(lambda x:x%2==0,aList)) 23 24print(newList) 25 26\u0026gt;\u0026gt;\u0026gt; print(newList) 27[2, 4] HÃ m reduce HÃ m cÃ³ nhiá»‡m vá»¥ tÃ­ch luá»¹ táº¥t cáº£ cÃ¡c pháº§n tá»­ vÃ  tráº£ vá» má»™t giÃ¡ trá»‹ duy nháº¥t\nCÃº phÃ¡p\n1 2reduce(function, iterable, [, initializer]) VÃ­ dá»¥:\nTÃ­nh tá»•ng cÃ¡c pháº§n tá»­ trong list sá»­ dá»¥ng reduce\n1 2from functools import reduce 3 4aList = [1,2,3,4,5] 5 6print(reduce(lambda x,y: x+y,aList)) 7 8Káº¿t quáº£: 9\u0026gt;\u0026gt;\u0026gt; print(reduce(lambda x,y: x+y,aList)) 1015 Äáº¿m sá»‘ láº§n xuáº¥t hiá»‡n cá»§a sá»‘ cháºµn trong list\n1 2from functools import reduce 3 4aList = [1,2,3,5,9] 5 6print(reduce(lambda acc,x: acc+1 if x%2 == 0 else acc,aList,0)) 7 8Káº¿t quáº£: 9\u0026gt;\u0026gt;\u0026gt; print(reduce(lambda x,y: x+y,aList,0)) 1015 Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t.\n","date":"Jul 16, 2022","img":"","permalink":"/courses/python/5_python_function/","series":["KhÃ³a há»c python cÄƒn báº£n"],"tags":["python"],"title":"BÃ i 4: HÃ m Trong Python"},{"categories":"python","content":"Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ Ä‘á» cáº­p tá»›i cÃ¡c cÃ¢u lá»‡nh Ä‘iá»u khiá»ƒn trong python. CÃ¡c cÃ¢u lá»‡nh Ä‘iá»u khiá»ƒn bao gá»“m if, if-else, for, while\nCÃ¢u lá»‡nh Ä‘iá»u khiá»ƒn if CÃ¢u lá»‡nh Ä‘iá»u khiá»ƒn for HÃ m range Káº¿t há»£p cÃ¢u lá»‡nh for vá»›i if tá»« khoÃ¡ break, tá»« khoÃ¡ continue, tá»« khoÃ¡ pass VÃ²ng láº·p while Ká»¹ thuáº­t duyá»‡t container trong python Duyá»‡t container sá»­ dá»¥ng hÃ m enumerate Duyá»‡t container sá»­ dá»¥ng hÃ m zip Duyá»‡t dic sá»­ dá»¥ng hÃ m items Duyá»‡t container sá»­ dá»¥ng hÃ m sorted Duyá»‡t container sá»­ dá»¥ng hÃ m reversed List Comprehension CÃ¢u lá»‡nh Ä‘iá»u khiá»ƒn if CÃ¢u lá»‡nh if lÃ  cÃ¢u lá»‡nh cÄƒn báº£n vÃ  quan trong nháº¥t. CÃ¢u lá»‡nh Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ quyáº¿t Ä‘á»‹nh xem má»™t khá»‘i lá»‡nh cÃ³ Ä‘Æ°á»£c thá»±c hiá»‡n hay khÃ´ng. Vá» cÆ¡ báº£n, chÃºng ta cÃ³ thá»ƒ phÃ¢n loáº¡i thÃ nh 3 nhÃ³m cÃ¢u lá»‡nh if nhÆ° sau.\nNhÃ³m if loáº¡i 1. CÃ¢u lá»‡nh if bÃ¬nh thÆ°á»ng\n1 2if \u0026lt;Ä‘iá»u kiá»‡n\u0026gt;: 3 # trÆ°á»ng há»£p \u0026lt;Ä‘iá»u kiá»‡n\u0026gt; lÃ  Ä‘Ãºng 4 cÃ¢u lá»‡nh 1 5 ... 6 cÃ¢u lá»‡nh n 7cÃ¢u lá»‡nh n+1 NhÃ³m if loáº¡i 2. CÃ¢u lá»‡nh if cÃ³ else\n1 2if \u0026lt;Ä‘iá»u kiá»‡n\u0026gt;: 3 # trÆ°á»ng há»£p \u0026lt;Ä‘iá»u kiá»‡n\u0026gt; lÃ  Ä‘Ãºng 4 cÃ¢u lá»‡nh 1 5 ... 6 cÃ¢u lá»‡nh n 7else: 8 # trÆ°á»ng há»£p \u0026lt;Ä‘iá»u kiá»‡n\u0026gt; lÃ  sai 9 cÃ¢u lá»‡nh 1 10 ... 11 cÃ¢u lá»‡nh n 12 13cÃ¢u lá»‡nh n+1 NhÃ³m if loáº¡i 3. CÃ¢u lá»‡nh if else lá»“ng nhau\n1 2if \u0026lt;Ä‘iá»u kiá»‡n 1\u0026gt;: 3 # trÆ°á»ng há»£p \u0026lt;Ä‘iá»u kiá»‡n\u0026gt; lÃ  Ä‘Ãºng 4 cÃ¢u lá»‡nh 1 5 ... 6 cÃ¢u lá»‡nh n 7elif \u0026lt;Ä‘iá»u kiá»‡n 2\u0026gt;: 8 # trÆ°á»ng há»£p \u0026lt;Ä‘iá»u kiá»‡n 1\u0026gt; lÃ  sai, \u0026lt;Ä‘iá»u kiá»‡n 2\u0026gt; lÃ  Ä‘Ãºng 9 cÃ¢u lá»‡nh 1 10 ... 11 cÃ¢u lá»‡nh n 12... 13elif \u0026lt;Ä‘iá»u kiá»‡n n\u0026gt;: 14 15 # trÆ°á»ng há»£p \u0026lt;Ä‘iá»u kiá»‡n 1\u0026gt; lÃ  sai, \u0026lt;Ä‘iá»u kiá»‡n 2\u0026gt; lÃ  sai, ... \u0026lt;Ä‘iá»u kiá»‡n n-1\u0026gt; lÃ  sai, \u0026lt;Ä‘iá»u kiá»‡n n\u0026gt; lÃ  Ä‘Ãºng 16 cÃ¢u lá»‡nh 1 17 ... 18 cÃ¢u lá»‡nh n 19else: 20 # trÆ°á»ng há»£p \u0026lt;Ä‘iá»u kiá»‡n 1\u0026gt; lÃ  sai, ..., \u0026lt;Ä‘iá»u kiá»‡n 2\u0026gt; lÃ  sai 21 cÃ¢u lá»‡nh 1 22 ... 23 cÃ¢u lá»‡nh n 24 25 26cÃ¢u lá»‡nh n+1 VÃ­ dá»¥:\nMáº¹ bÃ© Thu trÆ°á»›c khi Ä‘i lÃ m nÃ³i vá»›i bÃ© Thu ráº±ng: \u0026ldquo;Náº¿u trá»i sáº¯p mÆ°a, con hÃ£y rÃºt quáº§n Ã¡o á»Ÿ dÃ¢y phÆ¡i Ä‘á»“, há»‘t lÃºa cáº¥t vÃ o bá»“, báº¿ em vÃ o nhÃ , gÃ i then Ä‘Ã³ng cá»­a tháº­t cháº·t, gÃ i then Ä‘Ã³ng cá»­a tháº­t cháº·t. Con ngoan á»Ÿ nhÃ , chiá»u máº¹ vá» mua káº¹o cho con Äƒn\u0026rdquo;. ChÃºng ta sáº½ biáº¿n Ä‘á»•i lá»i cÄƒn dáº·n cá»§a máº¹ bÃ© Thu thÃ nh cÃ¢u lá»‡nh if nhÆ° sau:\n1 2thoi_tiet = \u0026#39;sap_mua\u0026#39; 3is_be_thu_ngoan = True 4if thoi_tiet == \u0026#39;sap_mua\u0026#39;: 5 print(\u0026#39;rÃºt quáº§n Ã¡o á»Ÿ dÃ¢y phÆ¡i Ä‘á»“\u0026#39;) 6 print(\u0026#39;há»‘t lÃºa cáº¥t vÃ o bá»“\u0026#39;) 7 print(\u0026#39;báº¿ em vÃ o nhÃ \u0026#39;) 8 print(\u0026#39;gÃ i then Ä‘Ã³ng cá»­a tháº­t cháº·t\u0026#39;) 9 print(\u0026#39;rÃºt quáº§n Ã¡o á»Ÿ dÃ¢y phÆ¡i Ä‘á»“\u0026#39;) 10 11if is_be_thu_ngoan: 12 print(\u0026#39;Máº¹ bÃ© Thu mua káº¹o\u0026#39;) 13 print(\u0026#39;Máº¹ bÃ© Thu cho bÃ© Thu Äƒn káº¹o\u0026#39;) 14 15Káº¿t quáº£ 16 17rÃºt quáº§n Ã¡o á»Ÿ dÃ¢y phÆ¡i Ä‘á»“ 18há»‘t lÃºa cáº¥t vÃ o bá»“ 19báº¿ em vÃ o nhÃ  20gÃ i then Ä‘Ã³ng cá»­a tháº­t cháº·t 21rÃºt quáº§n Ã¡o á»Ÿ dÃ¢y phÆ¡i Ä‘á»“ 22 23 24Máº¹ bÃ© Thu mua káº¹o 25Máº¹ bÃ© Thu cho bÃ© Thu Äƒn káº¹o ChÃºng ta cÃ³ cÃ¢u tá»¥c ngá»¯: Chuá»“n chuá»“n bay tháº¥p thÃ¬ mÆ°a, bay cao thÃ¬ náº¯ng, bay vá»«a thÃ¬ rÃ¢m.\nCÃ¢u lá»‡nh if else cá»§a cÃ¢u tá»¥c ngá»¯ trÃªn lÃ :\n1 2vi_tri_chuon_chuon = \u0026#39;bay_vua\u0026#39; 3 4if vi_tri_chuon_chuon == \u0026#39;bay_thap\u0026#39;: 5 print(\u0026#39;trá»i sáº¯p mÆ°a\u0026#39;) 6elif vi_tri_chuon_chuon == \u0026#39;bay_cao\u0026#39;: 7 print(\u0026#39;trá»i náº¯ng\u0026#39;) 8elif vi_tri_chuon_chuon == \u0026#39;bay_vua\u0026#39;: 9 print(\u0026#39;trá»i rÃ¢m\u0026#39;) 10else: 11 print(\u0026#39;khÃ´ng xÃ¡c Ä‘á»‹nh\u0026#39;) 12 13# Káº¿t quáº£ 14 15trá»i rÃ¢m CÃ¢u lá»‡nh Ä‘iá»u khiá»ƒn for CÃ¢u lá»‡nh for Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ duyá»‡t cÃ¡c pháº§n tá»­ trong cÃ¡c container nhÆ° String, Tuple, List, Set hoáº·c Dictionary, Array.\nfor trong python tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i foreach trong cÃ¡c ngÃ´n ngá»¯ thuá»™c há» c. Python khÃ´ng cÃ³ cÃ¢u lá»‡nh for giá»‘ng for trong c/c++, c#, java \u0026hellip;\nCÃº phÃ¡p cÃ¢u lá»‡nh for\n1 2for item in container: 3 #statement VÃ­ dá»¥\n1 2brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 3 4for item in brands: 5 print(item) 6 7#Káº¿t quáº£ 8 9iphone 10samsung 11xiaomi 12nokia HÃ m range cÃº phÃ¡p\n1 2range(start,stop,steep) HÃ m range Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tráº£ vá» má»™t chuá»—i cÃ¡c sá»‘ tá»« start (máº·c Ä‘á»‹nh lÃ  0) Ä‘áº¿n stop, vá»›i bÆ°á»›c nháº£y lÃ  steep (máº·c Ä‘á»‹nh lÃ  1)\nVÃ­ dá»¥:\nTáº¡o má»™t chuá»—i cÃ¡c sá»‘ tá»« 5 Ä‘áº¿n 9, in ra cÃ¡c sá»‘ trÃªn\n1 2itemRange = range(5,10) 3 4for item in itemRange: 5 print(item) 6 7# Káº¿t quáº£ 8 95 106 117 128 139 HÃ m range thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng vá»›i hÃ m len, Ä‘á»ƒ duyá»‡t index cá»§a list\n1 2brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;] 3 4for x in range(len(brands)): 5 print(f\u0026#34;element at {x} in list is {brands[x]} \u0026#34;) 6 7# Káº¿t quáº£ 8 9element at 0 in list is iphone 10element at 1 in list is samsung 11element at 2 in list is xiaomi NgoÃ i ra, cÃ²n tuá»³ vÃ o bÃ i toÃ¡n, chÃºng ta sá»­ dá»¥ng hÃ m range má»™t cÃ¡ch thÃ´ng minh Ä‘á»ƒ code Ä‘Æ°á»£c trong sÃ¡ng vÃ  sáº¡ch Ä‘áº¹p hÆ¡n.\nKáº¿t há»£p cÃ¢u lá»‡nh for vá»›i if HoÃ ng Ä‘áº¿ Julius Caesar lÃ  má»™t nhÃ  quÃ¢n sá»± tÃ i ba. Trong lÃºc Ã´ng lÃ£nh Ä‘áº¡o quÃ¢n Ä‘á»™i La MÃ£, Ä‘á»ƒ trÃ¡nh bá»‹ rÃ² rá»‰ ná»™i dung thÆ° tÃ­n khi truyá»n táº£i cho cÃ¡c tÆ°á»›ng sÄ©, Ã´ng Ä‘Ã£ thiáº¿t láº­p má»™t bá»™ máº­t mÃ£ lÃ  dá»‹ch tá»«ng chá»¯ trong thÃ´ng tin qua 3 chá»¯ cÃ¡i trong báº£ng mÃ£ ascii. NghÄ©a lÃ , thay vÃ¬ viáº¿t chá»¯ a, Ã´ng láº¡i viáº¿t thÃ nh chá»¯ d, thay vÃ¬ viáº¿t chá»¯ b, Ã´ng láº¡i viáº¿t chá»¯ e, \u0026hellip;., cho Ä‘áº¿n thay z thÃ nh c. Khi tÆ°á»›ng sÄ© cá»§a Ã´ng nháº­n Ä‘Æ°á»£c thÆ° tÃ­n, chá»‰ cáº§n dá»‹ch ngÆ°á»£c láº¡i vá»›i quy luáº­t trÃªn lÃ  cÃ³ Ä‘Æ°á»£c ná»™i dung bá»©c thÆ°.\nVÃ­ dá»¥ ná»™i dung bá»©c thÆ° Ã´ng gá»­i.\ngdqk Jdoold qjdb pxrl ed\nKhi tÆ°á»›ng sÄ© nháº­n Ä‘Æ°á»£c Ä‘oáº¡n lá»‡nh trÃªn, há» tiáº¿n hÃ nh dá»‹ch ngÆ°á»£c láº¡i. g tÆ°Æ¡ng á»©ng vá»›i chá»¯ d (d+3 =g) \u0026hellip;, vÃ  giáº£i mÃ£ bá»©c máº­t thÆ° cá»§a hoÃ ng Ä‘áº¿ gá»­i lÃ :\ndanh Gallia ngay muoi ba\nChÃºng ta viáº¿t chÆ°Æ¡ng trÃ¬nh nhá» vá»›i for vÃ  if Ä‘á»ƒ mÃ£ hoÃ¡ ná»™i dung thÃ´ng tin giÃºp Julius Caesar nhÃ©.\n1 2input = \u0026#39;danh Gallia ngay muoi ba\u0026#39; 3 4for c in input: 5 if c == \u0026#39;a\u0026#39;: 6 print(\u0026#39;d\u0026#39;,end=\u0026#39;\u0026#39;) 7 elif c == \u0026#39;b\u0026#39;: 8 print(\u0026#39;e\u0026#39;,end=\u0026#39;\u0026#39;) 9 elif c == \u0026#39;c\u0026#39;: 10 print(\u0026#39;f\u0026#39;,end=\u0026#39;\u0026#39;) 11 elif c == \u0026#39;d\u0026#39;: 12 print(\u0026#39;g\u0026#39;,end=\u0026#39;\u0026#39;) 13 elif c == \u0026#39;e\u0026#39;: 14 print(\u0026#39;h\u0026#39;,end=\u0026#39;\u0026#39;) 15 elif c == \u0026#39;f\u0026#39;: 16 print(\u0026#39;i\u0026#39;,end=\u0026#39;\u0026#39;) 17 elif c == \u0026#39;g\u0026#39;: 18 print(\u0026#39;j\u0026#39;,end=\u0026#39;\u0026#39;) 19 elif c == \u0026#39;h\u0026#39;: 20 print(\u0026#39;k\u0026#39;,end=\u0026#39;\u0026#39;) 21 elif c == \u0026#39;i\u0026#39;: 22 print(\u0026#39;l\u0026#39;,end=\u0026#39;\u0026#39;) 23 elif c == \u0026#39;j\u0026#39;: 24 print(\u0026#39;m\u0026#39;,end=\u0026#39;\u0026#39;) 25 elif c == \u0026#39;k\u0026#39;: 26 print(\u0026#39;n\u0026#39;,end=\u0026#39;\u0026#39;) 27 elif c == \u0026#39;l\u0026#39;: 28 print(\u0026#39;o\u0026#39;,end=\u0026#39;\u0026#39;) 29 elif c == \u0026#39;m\u0026#39;: 30 print(\u0026#39;p\u0026#39;,end=\u0026#39;\u0026#39;) 31 elif c == \u0026#39;n\u0026#39;: 32 print(\u0026#39;q\u0026#39;,end=\u0026#39;\u0026#39;) 33 elif c == \u0026#39;o\u0026#39;: 34 print(\u0026#39;r\u0026#39;,end=\u0026#39;\u0026#39;) 35 elif c == \u0026#39;p\u0026#39;: 36 print(\u0026#39;s\u0026#39;,end=\u0026#39;\u0026#39;) 37 elif c == \u0026#39;q\u0026#39;: 38 print(\u0026#39;t\u0026#39;,end=\u0026#39;\u0026#39;) 39 elif c == \u0026#39;r\u0026#39;: 40 print(\u0026#39;u\u0026#39;,end=\u0026#39;\u0026#39;) 41 elif c == \u0026#39;s\u0026#39;: 42 print(\u0026#39;v\u0026#39;,end=\u0026#39;\u0026#39;) 43 elif c == \u0026#39;t\u0026#39;: 44 print(\u0026#39;w\u0026#39;,end=\u0026#39;\u0026#39;) 45 elif c == \u0026#39;u\u0026#39;: 46 print(\u0026#39;x\u0026#39;,end=\u0026#39;\u0026#39;) 47 elif c == \u0026#39;v\u0026#39;: 48 print(\u0026#39;y\u0026#39;,end=\u0026#39;\u0026#39;) 49 elif c == \u0026#39;w\u0026#39;: 50 print(\u0026#39;z\u0026#39;,end=\u0026#39;\u0026#39;) 51 elif c == \u0026#39;x\u0026#39;: 52 print(\u0026#39;a\u0026#39;,end=\u0026#39;\u0026#39;) 53 elif c == \u0026#39;y\u0026#39;: 54 print(\u0026#39;b\u0026#39;,end=\u0026#39;\u0026#39;) 55 elif c == \u0026#39;z\u0026#39;: 56 print(\u0026#39;c\u0026#39;,end=\u0026#39;\u0026#39;) 57 else: 58 print(c,end=\u0026#39;\u0026#39;) 59print() 60 61# Káº¿t quáº£ 62 63gdqk Gdoold qjdb pxrl ed CÃ¡ch viáº¿t trÃªn khÃ¡ cÆ¡ báº¯p, tay to, dÃ i dÃ²ng, chÃºng ta hÃ£y viáº¿t Ä‘oáº¡n code trÃªn ngáº¯n gá»n hÆ¡n báº±ng cÃ¡ch.\nTáº¡o ra 2 chuá»—i, má»™t chuá»—i chá»©a cÃ¡c kÃ½ tá»± alphabet, má»™t chuá»—i chá»©a báº£ng mÃ£ hoÃ¡.\nTÃ¬m vá»‹ trÃ­ cá»§a tá»« cáº§n mÃ£ hoÃ¡ trong chuá»—i alphabet\nIn ra tá»« cáº§n láº¥y trong báº£ng mÃ£ hoÃ¡\n1 2input = \u0026#39;danh Gallia ngay muoi ba\u0026#39; 3 4alphabet = \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39; 5caesar_cipher = \u0026#39;defghijklmnopqrstuvwxyzabc\u0026#39; 6 7for c in input: 8 index = alphabet.find(c) 9 if index \u0026gt;-1: 10 print(caesar_cipher[index],end=\u0026#39;\u0026#39;) 11 else: 12 print(c,end=\u0026#39;\u0026#39;) 13 14print(\u0026#39;\u0026#39;) tá»« khoÃ¡ break, tá»« khoÃ¡ continue, tá»« khoÃ¡ pass Äá»ƒ thoÃ¡t khá»i vÃ²ng láº·p for, chÃºng ta sá»­ dá»¥ng tá»« khoÃ¡ break\nÄá»ƒ bá» qua khá»‘i lá»‡nh bÃªn dÆ°á»›i, tiáº¿p tá»¥c lá»‡nh for, chÃºng ta sá»­ dá»¥ng tá»« khoÃ¡ continue.\nÄá»ƒ giá»¯ chá»— cho tÃ­nh nÄƒng tÆ°Æ¡ng lai sáº½ phÃ¡t triá»ƒn, chÃºng ta sá»­ dá»¥ng tá»« khoÃ¡ pass Ä‘á»ƒ Ä‘Ã¡nh dáº¥u, vÃ  cÅ©ng Ä‘á»ƒ cho chÆ°Æ¡ng trÃ¬nh cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c.\nVÃ­ dá»¥ vá» break\nTÃ¬m lÃ  in ra 5 sá»‘ láº» nguyÃªn dÆ°Æ¡ng Ä‘áº§u tiÃªn bÃ© hÆ¡n 100\n1 2count = 0 3 4for x in range(100): 5 if x % 2 != 0: 6 print(x) 7 count = count + 1 8 if count \u0026gt;=5: 9 break 10 11# Káº¿t quáº£ 12 131 143 155 167 179 VÃ­ dá»¥ vá» continue\nIn ra cÃ¡c sá»‘ láº» bÃ© hÆ¡n 10\n1 2for x in range(10): 3 if x % 2 == 0: 4 continue 5 print(x) 6 7# Káº¿t quáº£ 8 91 103 115 127 139 VÃ­ dá»¥ vá» pass\nViáº¿t má»™t vÃ²ng láº·p for láº·p 10 láº§n, Ä‘á»ƒ giÃ nh Ä‘Ã³ mai má»‘t code tiáº¿p\n1 2for x in range(10): 3 pass 4 5# Káº¿t quáº£ VÃ²ng láº·p while Ã nghÄ©a: Trong khi Ä‘iá»u kiá»‡n cÃ²n Ä‘Ãºng, thÃ¬ thá»±c hiá»‡n cÃ¢u lá»‡nh.\nKáº¿t thÃºc vÃ²ng láº·p khi Ä‘iá»u kiá»‡n sai\nCÃº phÃ¡p\n1 2while \u0026lt;condition\u0026gt;: 3 # statement VÃ­ dá»¥:\nIn ra cÃ¡c sá»‘ nguyÃªn bÃ© hÆ¡n 10\n1 2 3i = 1 4while i \u0026lt; 10: 5 print(i) 6 i += 1 vÃ²ng láº·p while cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c tá»« khoÃ¡ pass, continue, break giá»‘ng nhÆ° for\nKá»¹ thuáº­t duyá»‡t container trong python Python há»— trá»£ nhiá»u hÃ m dá»±ng sáºµn, giÃºp chÃºng ta cÃ³ thá»ƒ duyá»‡t cÃ¡c container má»™t cÃ¡ch dá»… dÃ ng.\nViá»‡c sá»­ dá»¥ng cÃ¡c hÃ m duyá»‡t bÃªn dÆ°á»›i, giÃºp cho coder:\nSá»­ dá»¥ng nhanh chÃ³ng, giáº£m thá»i gian coding.\nTÃªn hÃ m chÃ­nh lÃ  tá»« khoÃ¡, mÃ´ táº£ chÃ­nh xÃ¡c má»¥c Ä‘Ã­ch sá»­ dá»¥ng hÃ m. GiÃºp giáº£m thá»i gian Ä‘á»c code, khi so vá»›i viá»‡c sá»­ dá»¥ng for/while.\nCode ngáº¯ng gá»n hÆ¡n, rÃµ rÃ ng hÆ¡n, so vá»›i for \u0026amp; while.\nDuyá»‡t container sá»­ dá»¥ng hÃ m enumerate HÃ m enumerate há»— trá»£ tráº£ vá» index vÃ  value cá»§a container\nVÃ­ dá»¥:\n1 2 3brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 4 5for index,item in enumerate(brands): 6 print(f\u0026#34;element at index {index} in list is {item} \u0026#34;) 7 8 9# Káº¿t quáº£ 10 11element at index 0 in list is iphone 12element at index 1 in list is samsung 13element at index 2 in list is xiaomi 14element at index 3 in list is nokia Duyá»‡t container sá»­ dá»¥ng hÃ m zip HÃ m dá»±ng sáºµn zip há»— trá»£ chÃºng ta káº¿t há»£p 2 container cÃ¹ng loáº¡i (list vá»›i list, dict vá»›i dict, string vá»›i string) vá»›i nhau\nVÃ­ dá»¥:\n1 2alphabet = \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39; 3caesar_cipher = \u0026#39;defghijklmnopqrstuvwxyzabc\u0026#39; 4 5 6for decode, encode in zip(alphabet,caesar_cipher): 7 print(f\u0026#34;Caesar send {encode}, we have {decode}\u0026#34;) 8 9# Káº¿t quáº£ 10 11Caesar send d, we have a 12Caesar send e, we have b 13Caesar send f, we have c 14Caesar send g, we have d 15Caesar send h, we have e 16Caesar send i, we have f 17Caesar send j, we have g 18Caesar send k, we have h 19Caesar send l, we have i 20Caesar send m, we have j 21Caesar send n, we have k 22Caesar send o, we have l 23Caesar send p, we have m 24Caesar send q, we have n 25Caesar send r, we have o 26Caesar send s, we have p 27Caesar send t, we have q 28Caesar send u, we have r 29Caesar send v, we have s 30Caesar send w, we have t 31Caesar send x, we have u 32Caesar send y, we have v 33Caesar send z, we have w 34Caesar send a, we have x 35Caesar send b, we have y 36Caesar send c, we have z Duyá»‡t dic sá»­ dá»¥ng hÃ m items VÃ­ dá»¥:\n1 2profile = {\u0026#39;name\u0026#39;:\u0026#39;alex\u0026#39;,\u0026#39;age\u0026#39;:18,\u0026#39;location\u0026#39;:\u0026#39;vietnam\u0026#39;} 3 4for key, value in profile.items(): 5 print(key,value) 6 7# Káº¿t quáº£ 8 9name alex 10age 18 11location vietnam Duyá»‡t container sá»­ dá»¥ng hÃ m sorted HÃ m sorted sáº½ xáº¯p xáº¿p láº¡i pháº§n tá»­ trong container theo thá»© tá»± (vá»›i sá»‘ thÃ¬ tá»« nhá» Ä‘áº¿n lá»›n, vá»›i chá»¯ thÃ¬ theo thá»© tá»± tá»« Ä‘iá»ƒn), vÃ  tráº£ vá» tá»«ng pháº§n tá»­ trong container Ä‘Ã£ Ä‘Æ°á»£c sort.\nVÃ­ dá»¥:\n1 2 3brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 4 5for item in sorted(brands): 6 print(item) 7 8# Káº¿t quáº£ 9 10iphone 11nokia 12samsung 13xiaomi Duyá»‡t container sá»­ dá»¥ng hÃ m reversed HÃ m reversed sáº½ duyá»‡t ngÆ°á»£c pháº§n tá»­ trong container. HÃ m nÃ y khÃ´ng lÃ m áº£nh hÆ°á»Ÿng thá»© tá»± cá»§a cÃ¡c pháº§n tá»­ trong container\nVÃ­ dá»¥:\n1 2 3brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 4 5for item in reversed(brands): 6 print(item) 7 8# Káº¿t quáº£ 9 10iphone 11nokia 12samsung 13xiaomi List Comprehension List comprehension cung cáº¥p cho chÃºng ta má»™t cÃº phÃ¡p ngáº¯n gá»n, sÃºc tÃ­ch, giÃºp chÃºng ta táº¡o má»™t list, lÃ  táº­p con tá»« má»™t list lá»›n.\nCÃº phÃ¡p chung cá»§a list comprehension lÃ :\n1 2newlist = [expression for item in iterable if condition == True] Vá»›i condition lÃ  Ä‘iá»u kiá»‡n lá»c Ä‘á»ƒ giáº£m sá»‘ lÆ°á»£ng pháº§n tá»­ tráº£ vá».\nexpression: cÃ³ thá»ƒ lÃ  má»™t biá»ƒu thá»©c if\nVÃ­ dá»¥:\n1 2brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 3filter_brands = [] 4 5for item in brands: 6 if \u0026#39;i\u0026#39; in item: 7 filter_brands.append(item) 8 9print(filter_brands) 10 11# Káº¿t quáº£ 12\u0026gt;\u0026gt;\u0026gt; print(filter_brands) 13[\u0026#39;iphone\u0026#39;, \u0026#39;xiaomi\u0026#39;, \u0026#39;nokia\u0026#39;] Äoáº¡n mÃ£ trÃªn thá»±c hiá»‡n viá»‡c in ra cÃ¡c hÃ£ng cÃ³ chá»©a kÃ½ tá»± i trong tÃªn. ChÃºng ta tá»‘n 3 dÃ²ng code (1 vÃ²ng for, 1 vÃ²ng if, 1 vÃ²ng append). Giá» chÃºng ta sáº½ viáº¿t láº¡i báº±ng list comprehension\n1 2 3brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 4 5filter_brands = [item for item in brands if \u0026#39;i\u0026#39; in item] 6 7print(filter_brands) 8 9#Káº¿t quáº£ 10 11\u0026gt;\u0026gt;\u0026gt; print(filter_brands) 12[\u0026#39;iphone\u0026#39;, \u0026#39;xiaomi\u0026#39;, \u0026#39;nokia\u0026#39;] VÃ­ dá»¥ 2\nViáº¿t hoa toÃ n bá»™ tÃªn hÃ£ng\n1 2# Máº«u vÃ²ng láº·p for 3 4brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 5 6old_upper_brands = [] 7for brand in brands: 8 old_upper_brands.append(brand.upper()) 9 10# Máº«u list comprehension 11 12new_upper_brands = [brand.upper() for brand in brands] VÃ­ dá»¥ 3:\nCho má»™t list cÃ³ 10 pháº§n tá»­, láº¥y ra cÃ¡c pháº§n tá»­ \u0026gt; 5, thay cÃ¡c pháº§n tá»­ lá»›n hÆ¡n 10 báº±ng 0\n1 2# Máº«u cÅ© 3items = [100,5,8,2,9,7,1,20,89,99] 4old_items = [] 5for item in items: 6 if item \u0026gt; 5: # chá»‰ xÃ©t nhá»¯ng pháº§n tá»­ \u0026gt;5 7 if item\u0026gt;10: # thay nhá»¯ng pháº§n tá»­ \u0026gt; 10 thÃ nh 0 8 old_items.append(0) 9 else: 10 old_items.append(item) 11 12print(old_items) 13 14new_items = [item if item \u0026lt;=10 else 0 for item in items if item\u0026gt;5] 15 16print(new_items) 17 18# Káº¿t quáº£ 19 20\u0026gt;\u0026gt;\u0026gt; print(old_items) 21[0, 8, 9, 7, 0, 0, 0] 22 23\u0026gt;\u0026gt;\u0026gt; print(new_items) 24[0, 8, 9, 7, 0, 0, 0] Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t.\n","date":"Jul 16, 2022","img":"","permalink":"/courses/python/4_python_conditional_loop/","series":["KhÃ³a há»c python cÄƒn báº£n"],"tags":["python"],"title":"BÃ i 3: CÃ¢u Lá»‡nh Äiá»u Khiá»ƒn Trong Python"},{"categories":"python","content":"Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ tÃ¬m hiá»ƒu cÃ¡c kiá»ƒu dá»¯ liá»‡u dáº¡ng container trong python\nKiá»ƒu dá»¯ liá»‡u string Má»™t vÃ i phÆ°Æ¡ng thá»©c cÆ¡ báº£n cá»§a string PhÆ°Æ¡ng thá»©c isdecimal, isdigit, isnumeric PhÆ°Æ¡ng thá»©c isascii, isalpha, isalnum, isspace, isupper PhÆ°Æ¡ng thá»©c lstrip, rstrip, strip PhÆ°Æ¡ng thá»©c find, index PhÆ°Æ¡ng thá»©c format f string Kiá»ƒu dá»¯ liá»‡u tuple Packing vÃ  Unpacking So sÃ¡nh cÃ¡c biáº¿n cÃ³ kiá»ƒu dá»¯ liá»‡u tuple Slicing trong Tuple CÃ¡c hÃ m dá»±ng sáºµn cá»§a Tuple Kiá»ƒu dá»¯ liá»‡u tá»« Ä‘iá»ƒn - dictionary Thuá»™c tÃ­nh cá»§a keys trong tá»« Ä‘iá»ƒn. Má»™t vÃ i phÆ°Æ¡ng thá»©c cá»§a dictionary copy update del item len Merge Tá»•ng káº¿t: Kiá»ƒu dá»¯ liá»‡u list Truy xuáº¥t dá»¯ liá»‡u trong list slicing CÃ¡c phÆ°Æ¡ng thá»©c Ä‘Æ°á»£c há»— trá»£ append pop remove reverse CÃ¡c hÃ m Ä‘Æ°á»£c há»— trá»£ len max min Kiá»ƒu dá»¯ liá»‡u set Má»™t vÃ i phÆ°Æ¡ng thá»©c cÆ¡ báº£n cá»§a Set PhÆ°Æ¡ng thá»©c Add PhÆ°Æ¡ng thá»©c Remove, Discard PhÆ°Æ¡ng thá»©c Pop PhÆ°Æ¡ng thá»©c Clear Kiá»ƒu dá»¯ liá»‡u array Má»™t vÃ i phÆ°Æ¡ng thá»©c cÆ¡ báº£n cá»§a array PhÆ°Æ¡ng thá»©c insert, phÆ°Æ¡ng thá»©c append PhÆ°Æ¡ng thá»©c truy xuáº¥t pháº§n tá»­ theo index PhÆ°Æ¡ng thá»©c remove, phÆ°Æ¡ng thá»©c pop PhÆ°Æ¡ng thá»©c index Kiá»ƒu dá»¯ liá»‡u string string lÃ  táº­p há»£p cÃ¡c bytes Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng kÃ½ tá»± unicode\nVÃ­ dá»¥\n1 2hello = \u0026#34;hi, i am alex\u0026#34; 3 4print(hello) 5 6greating = \u0026#34;i am from viá»‡t Nam\u0026#34; 7 8print(greating) 9 10 11#Káº¿t quáº£ 12 13\u0026gt;\u0026gt;\u0026gt; print(hello) 14hi, i am alex 15 16\u0026gt;\u0026gt;\u0026gt; print(greating) 17i am from viá»‡t Nam Má»™t vÃ i phÆ°Æ¡ng thá»©c cÆ¡ báº£n cá»§a string PhÆ°Æ¡ng thá»©c isdecimal, isdigit, isnumeric isdecimal: Tráº£ vá» true náº¿u toÃ n bá»™ cÃ¡c kÃ½ tá»± lÃ  decimal (0-9)\nisdigit: Tráº£ vá» true náº¿u toÃ n bá»™ kÃ½ tá»± lÃ  digit. Bao gá»“m cÃ¡c sá»‘ (0-9), sá»‘ mÅ© trÃªn (vÃ­ dá»¥: x2), sá»‘ mÅ© dÆ°á»›i (vÃ­ dá»¥: x2).\nisnumeric: Tráº£ vá» true náº¿u toÃ n bá»™ kÃ½ tá»± lÃ  numeric. Bao gá»“m cÃ¡c sá»‘ (0-9), sá»‘ mÅ© trÃªn (vÃ­ dá»¥: x2), sá»‘ mÅ© dÆ°á»›i (vÃ­ dá»¥: x2) , phÃ¢n sá»‘ ( vÃ­ dá»¥: 1â„2)\nVÃ­ dá»¥:\n1 2# sá»‘ 18 lÃ : 3print(\u0026#39;18\u0026#39;.isdecimal()) 4print(\u0026#39;18\u0026#39;.isdigit()) 5print(\u0026#39;18\u0026#39;.isnumeric()) 6 7# Káº¿t quáº£ 8 9\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;18\u0026#39;.isdecimal()) 10True 11\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;18\u0026#39;.isdigit()) 12True 13\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;18\u0026#39;.isnumeric()) 14True 1 2# sá»‘ 2 mÅ© 3 lÃ : 3print(\u0026#39;2\\u00b3\u0026#39;) 4print(\u0026#39;2\\u00b3\u0026#39;.isdecimal()) 5print(\u0026#39;2\\u00b3\u0026#39;.isdigit()) 6print(\u0026#39;2\\u00b3\u0026#39;.isnumeric()) 7 8# Káº¿t quáº£ 9 10\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;) 112Â³ 12\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;.isdecimal()) 13False 14\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;.isdigit()) 15True 16\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;.isnumeric()) 17True 1 2# sá»‘ â…“ lÃ : 3print(\u0026#39;\\u2153\u0026#39;) 4print(\u0026#39;\\u2153\u0026#39;.isdecimal()) 5print(\u0026#39;\\u2153\u0026#39;.isdigit()) 6print(\u0026#39;\\u2153\u0026#39;.isnumeric()) 7 8# Káº¿t quáº£ 9 10\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\\u2153\u0026#39;.isdecimal()) 11False 12\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\\u2153\u0026#39;.isdigit()) 13False 14\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\\u2153\u0026#39;.isnumeric()) 15True PhÆ°Æ¡ng thá»©c isascii, isalpha, isalnum, isspace, isupper isalpha: Tráº£ vá» true náº¿u toÃ n bá»™ kÃ½ tá»± trong báº£ng alphabet(a-z). KhÃ´ng chá»©a kÃ½ tá»± khoáº£ng tráº¯ng, # @ $ \u0026hellip;\nisalnum: Tráº£ vá» true náº¿u toÃ n bá»™ kÃ½ tá»± lÃ  alphanumeric (a-z,0-9)\nisascii: Tráº£ vá» true náº¿u toÃ n bá»™ lÃ  kÃ½ tá»± ascii (a-z)\nisspace: Tráº£ vá» true náº¿u toÃ n bá»™ kÃ½ tá»± lÃ  khoáº£ng tráº¯ng\nisupper: Tráº£ vá» true náº¿u toÃ n bá»™ kÃ½ tá»± Ä‘á»u in hoa.\nVÃ­ dá»¥:\n1 2\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex\u0026#34;.isalpha()) 3True 4 5\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100\u0026#34;.isalpha()) 6False 7 8\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100\u0026#34;.isalnum()) 9True 10 11\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100 $%\u0026#34;.isalnum()) 12False 13 14\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100 $%\u0026#34;.isascii()) 15True 16 17 18\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100\u0026#34;.isspace()) 19False 20\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;\u0026#34;.isspace()) 21False 22\u0026gt;\u0026gt;\u0026gt; print(\u0026#34; \u0026#34;.isspace()) 23True 24 25 26\u0026gt;\u0026gt;\u0026gt; print(\u0026#34; \u0026#34;.isupper()) 27False 28\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;abc\u0026#34;.isupper()) 29False 30\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;AA\u0026#34;.isupper()) 31True PhÆ°Æ¡ng thá»©c lstrip, rstrip, strip PhÆ°Æ¡ng thá»©c lstrip: XoÃ¡ chuá»—i dÆ° thá»«a á»Ÿ bÃªn trÃ¡i, máº·c Ä‘á»‹nh chuá»—i dÆ° thá»«a lÃ  khoáº£ng tráº¯ng PhÆ°Æ¡ng thá»©c rstrip: XoÃ¡ chuá»—i dÆ° thá»«a á»Ÿ bÃªn pháº£i, máº·c Ä‘á»‹nh chuá»—i dÆ° thá»«a lÃ  khoáº£ng tráº¯ng PhÆ°Æ¡ng thá»©c strip: XoÃ¡ chuá»—i dÆ° thá»«a á»Ÿ hai bÃªn, máº·c Ä‘á»‹nh chuá»—i dÆ° thá»«a lÃ  khoáº£ng tráº¯ng VÃ­ dá»¥\n1 2\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;.... alex black ..\u0026#34;.lstrip(\u0026#34;.\u0026#34;)) # chá»‰ xoÃ¡ . bÃªn trÃ¡i 3 alex black .. 4 5\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;.... alex black ..\u0026#34;.rstrip(\u0026#34;.\u0026#34;)) # chá»‰ xoÃ¡ . bÃªn pháº£i 6.... alex black 7 8\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;....alex black..\u0026#34;.strip(\u0026#34;.\u0026#34;)) # xoÃ¡ . á»Ÿ hai bÃªn 9alex black 10 11 12\u0026gt;\u0026gt;\u0026gt; print(\u0026#34; ....alex black..\u0026#34;.strip()) # xoÃ¡ khoáº£ng tráº¯ng á»Ÿ hai bÃªn 13....alex black.. PhÆ°Æ¡ng thá»©c find, index Cáº£ hai phÆ°Æ¡ng thá»©c find vÃ  index Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tÃ¬m vá»‹ trÃ­ Ä‘áº§u tiÃªn cá»§a pháº§n tá»­ cáº§n tÃ¬m\nPhÆ°Æ¡ng thá»©c find: Tráº£ vá» -1 náº¿u pháº§n tá»­ khÃ´ng tÃ¬m tháº¥y\nPhÆ°Æ¡ng thá»©c index: Tráº£ vá» lá»—i náº¿u pháº§n tá»­ khÃ´ng tÃ¬m tháº¥y\nVÃ­ dá»¥:\n1 2\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.find(\u0026#34;b\u0026#34;)) 35 4 5\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.index(\u0026#34;b\u0026#34;)) 65 7 8\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.find(\u0026#34;a\u0026#34;,5)) 97 10 11\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.index(\u0026#34;a\u0026#34;,5)) 127 13 14\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.find(\u0026#34;z\u0026#34;)) 15-1 16 17\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.index(\u0026#34;z\u0026#34;)) 18Traceback (most recent call last): 19 File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; 20ValueError: substring not found PhÆ°Æ¡ng thá»©c format PhÆ°Æ¡ng thá»©c format Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘á»‹nh dáº¡ng chuá»—i.\nVÃ­ dá»¥:\n1 2greetings = \u0026#34;Hello everyone, my name {name}, i am {age} year old. I come from {location}\u0026#34; 3 4name = \u0026#34;alex Black\u0026#34; 5age = 18 6location = \u0026#34;the moon\u0026#34; 7print(greetings.format(name=name, age=age, location=location)) 8 9#Káº¿t quáº£ 10 11\u0026gt;\u0026gt;\u0026gt; print(greetings.format(name=name, age=age, location=location)) 12Hello everyone, my name alex Black, i am 18 year old. I come from the moon CÃ¡ch viáº¿t nÃ y khÃ¡ dÃ i dÃ²ng lÃª thÃª, má»™t cÃ¡ch khÃ¡c lÃ  chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng f string.\nf string python 3 há»— trá»£ f string, giÃºp format chuá»—i, trÃ´ng Ä‘áº¹p hÆ¡n so vá»›i phÆ°Æ¡ng thá»©c format á»Ÿ trÃªn.\n1 2\u0026gt;\u0026gt;\u0026gt; age =18 3\u0026gt;\u0026gt;\u0026gt; name= \u0026#39;Alex Black\u0026#39; 4\u0026gt;\u0026gt;\u0026gt; location=\u0026#39;the moon\u0026#39; 5 6\u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;hello, my name {name}. I am {age} years old. I come from {location}\u0026#34;) 7hello, my name Alex Black. I am 18 years old. I come from the moon Kiá»ƒu dá»¯ liá»‡u tuple Tuple lÃ  táº­p cho phÃ©p chÃºng ta gÃ¡n nhiá»u biáº¿n vÃ o má»™t biáº¿n. VÃ­ dá»¥:\n1tupinfo = (\u0026#39;Alex\u0026#39;, \u0026#39;Black\u0026#39;,\u0026#39;1978\u0026#39;,\u0026#39;Emprise\u0026#39;, \u0026#39;Engineer\u0026#39;,\u0026#39;Ho Chi Minh\u0026#39;); 2tupinfo = (1,3,5,7,9,9); 3print(tupinfo[0]) 4print(tupinfo[1:4]) 5 6#káº¿t quáº£ 7\u0026gt;\u0026gt;\u0026gt; print(tupinfo[0]) 81 9\u0026gt;\u0026gt;\u0026gt; print(tupinfo[1:4]) 10(3, 5, 7) 11\u0026gt;\u0026gt;\u0026gt; Packing vÃ  Unpacking Thuáº­t ngá»¯ packing Ã¡m chá»‰ viá»‡c ta thÃªm giÃ¡ trá»‹ vÃ o tuple.\nThuáº­t ngá»¯ unpacking Ã¡m chá»‰ viá»‡c ta phÃ¢n giáº£i cÃ¡c giÃ¡ trá»‹ cá»§a tuple ra nhiá»u biáº¿n.\nChÃºng ta cÃ¹ng xem vÃ­ dá»¥:\n1 2a = (\u0026#34;alex\u0026#34; , 18, \u0026#34;Staff\u0026#34;) # tuple packing 3 4(name, age, position) = a # unpacking tuple 5 6print(name) 7print(age) 8print(position) 9 10# Káº¿t quáº£ 11 12\u0026gt;\u0026gt;\u0026gt; print(name) 13alex 14\u0026gt;\u0026gt;\u0026gt; print(age) 1518 16\u0026gt;\u0026gt;\u0026gt; print(position) 17Staff So sÃ¡nh cÃ¡c biáº¿n cÃ³ kiá»ƒu dá»¯ liá»‡u tuple Python cho phÃ©p so sÃ¡nh cÃ¡c biáº¿n thuá»™c kiá»ƒu dá»¯ liá»‡u tuple vá»›i nhau. ChÃºng ta cÃ³ thá»ƒ thá»±c hiá»‡n cÃ¡c phÃ©p so sÃ¡nh báº±ng, so sÃ¡nh lá»›n hÆ¡n, so sÃ¡nh bÃ© hÆ¡n. Viá»‡c so sÃ¡nh Ä‘Æ°á»£c thá»±c hiá»‡n láº§n lÆ°á»£t báº±ng cÃ¡ch so sÃ¡nh giÃ¡ trá»‹ cá»§a tá»«ng pháº§n tá»­ vá»›i nhau theo thá»© tá»±. Pháº§n tá»­ thá»© nháº¥t sáº½ so sÃ¡nh vá»›i pháº§n tá»­ thá»© nháº¥t, pháº§n tá»­ thá»© hai sáº½ so sÃ¡nh vá»›i pháº§n tá»­ thá»© hai\u0026hellip;.\nVÃ­ dá»¥:\n1 2num1 = (3,5,7) 3 4num2 = (3,6,4) 5 6print(num1\u0026gt;num2) 7print(num1==num2) 8print(num1\u0026lt;num2) 9 10Káº¿t quáº£: 11 12\u0026gt;\u0026gt;\u0026gt; print(num1\u0026gt;num2) 13False 14\u0026gt;\u0026gt;\u0026gt; print(num1==num2) 15False 16\u0026gt;\u0026gt;\u0026gt; print(num1\u0026lt;num2) # do 6 lá»›n hÆ¡n 5, nÃªn num2 lá»›n hÆ¡n num1 17True Má»™t lÆ°u Ã½ nhá» lÃ  á»Ÿ python, phÃ©p so sÃ¡nh báº±ng sáº½ lÃ  hai dáº¥u báº±ng (==), khÃ´ng pháº£i má»™t dáº¥u =. Dáº¥u = Ä‘áº¡i diá»‡n cho phÃ©p gÃ¡n giÃ¡ trá»‹ cho biáº¿n.\nSlicing trong Tuple Äá»ƒ láº¥y ra má»™t nhÃ³m cÃ¡c pháº§n tá»­ liá»n ká» nhau trong tuple, chÃºng ta sá»­ dá»¥ng má»™t hÃ m cÃ³ tÃªn lÃ  slicing. Slicing cÃ³ thá»ƒ Ã¡p dá»¥ng cho tuple, array, list.\nVÃ­ dá»¥:\n1 2ages = (18,16,15,18,15,17,19,18,17) 3print(ages[2:4]) 4\u0026gt;\u0026gt;\u0026gt; print(ages[2:4]) 5(15, 18) CÃ¡c hÃ m dá»±ng sáºµn cá»§a Tuple Äá»ƒ thá»±c hiá»‡n cÃ¡c cÃ´ng viá»‡c khÃ¡c nhau, kiá»ƒu dá»¯ liá»‡u tuple cÃ³ xÃ¢y dá»±ng má»™t sá»‘ hÃ m Ä‘á»ƒ chÃºng ta sá»­ dá»¥ng, nhÆ° lÃ  all(), any(), enumerate(), max(), min(), sorted(), len(), tuple(), etc.\nKiá»ƒu dá»¯ liá»‡u tá»« Ä‘iá»ƒn - dictionary Trong python, kiá»ƒu tá»« Ä‘iá»ƒn lÃ  táº­p há»£p cÃ¡c dá»¯ liá»‡u cÃ³ dáº¡ng key-value. Trong Ä‘Ã³, Key lÃ  duy nháº¥t trong tá»« Ä‘iá»ƒn. Value cÃ³ thá»ƒ lÃ  list, tuple, dictionary, sá»‘, chuá»—i, tÃºm láº¡i lÃ  value khÃ´ng bá»‹ giá»›i háº¡n vá» kiá»ƒu dá»¯ liá»‡u, thÃ­ch lÆ°u kiá»ƒu gÃ¬ cÅ©ng Ä‘Æ°á»£c. CÃ³ hai cÃ¡ch Ä‘á»ƒ táº¡o biáº¿n cÃ³ kiá»ƒu dá»¯ liá»‡u tá»« Ä‘iá»ƒn, má»™t lÃ  dÃ¹ng tá»« khoÃ¡ dict(), hai lÃ  dÃ¹ng dáº¥u Ä‘Ã³ng má»Ÿ ngoáº·c nhá»n {}.\nVÃ­ dá»¥\n1 2info = {\u0026#39;name\u0026#39;: \u0026#34;alex\u0026#34;, age:18, \u0026#39;position\u0026#39;: \u0026#34;Staff\u0026#34; } 3print(info) 4 5Káº¿t quáº£: 6 7\u0026gt;\u0026gt;\u0026gt; print(info) 8{\u0026#39;alex\u0026#39;: \u0026#39;alex\u0026#39;, 18: 18, \u0026#39;position\u0026#39;: \u0026#39;Staff\u0026#39;} Qua 10 triá»‡u láº§n test trÃªn con mÃ¡y apple m1 cá»§a mÃ¬nh, mÃ¬nh tháº¥y ráº±ng khai bÃ¡o biáº¿n dictionary báº±ng dáº¥u {} sáº½ cháº¡y nhanh hÆ¡n so vá»›i khai bÃ¡o sá»­ dá»¥ng dict()\nThuá»™c tÃ­nh cá»§a keys trong tá»« Ä‘iá»ƒn. CÃ³ ba Ä‘iá»ƒm quan trá»ng vá» key cá»§a dictionary chÃºng ta cáº§n pháº£i nhá»›:\nMá»™t lÃ  key khÃ´ng cho phÃ©p trÃ¹ng nhau.\nKey pháº£i lÃ  thuá»™c nhÃ³m báº¥t biáº¿n - immutable, nhÆ° number, tuple , string.\nKey cÃ³ phÃ¢n biá»‡t hoa thÆ°á»ng.\nVÃ­ dá»¥:\n1 2 3item = {\u0026#34;name\u0026#34;:\u0026#34; iPhone 13 Pro Max 512GB\u0026#34;,\u0026#34;Price\u0026#34;:\u0026#34;34.690.000\u0026#34;,\u0026#34;Brand\u0026#34;:\u0026#34;Apple\u0026#34;,\u0026#34;BRAND\u0026#34;:\u0026#34;Apple\u0026#34;} 4 5print(item[\u0026#34;Brand\u0026#34;]) 6 7\u0026gt;\u0026gt;\u0026gt; print(item[\u0026#34;Brand\u0026#34;]) 8Apple Má»™t vÃ i phÆ°Æ¡ng thá»©c cá»§a dictionary copy PhÆ°Æ¡ng thá»©c nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ copy pháº§n tá»­ cá»§a biáº¿n nÃ y sang biáº¿n khÃ¡c.\nVÃ­ dá»¥:\n1 2item = {\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.690.000\u0026#34;,\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 3 4item_new = item.copy() 5 6print(item_new) 7 8\u0026gt;\u0026gt;\u0026gt; print(item_new) 9{\u0026#39;Äiá»‡n thoáº¡i iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.690.000\u0026#39;, \u0026#39;Äiá»‡n thoáº¡i iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;} update PhÆ°Æ¡ng thá»©c update Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ cáº­p nháº­t dá»¯ liá»‡u náº¿u key Ä‘Ã£ cÃ³, náº¿u key chÆ°a cÃ³ thÃ¬ thÃªm cáº·p key-value vÃ o tá»« Ä‘iá»ƒn.\nVÃ­ dá»¥:\n1 2item = {\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 3 4item_new = item.copy() 5item_new.update({\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.690.000\u0026#34;}) # cáº­p nháº­t giÃ¡ trá»‹, vÃ¬ key Ä‘Ã£ tá»“n táº¡i 6 7item_new.update({\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 128GB\u0026#34; :\u0026#34;28.390.000\u0026#34;}) # thÃªm cáº·p key-value vÃ o biáº¿n item_new 8 9print(item) 10print(item_new) 11 12#Káº¿t quáº£ 13 14\u0026gt;\u0026gt;\u0026gt; print(item) 15{\u0026#39;Äiá»‡n thoáº¡i iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.790.000\u0026#39;, \u0026#39;Äiá»‡n thoáº¡i iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;} 16\u0026gt;\u0026gt;\u0026gt; print(item_new) 17{\u0026#39;Äiá»‡n thoáº¡i iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.690.000\u0026#39;, \u0026#39;Äiá»‡n thoáº¡i iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;, \u0026#39;Äiá»‡n thoáº¡i iPhone 13 Pro Max 128GB\u0026#39;: \u0026#39;28.390.000\u0026#39;} del Äá»ƒ xoÃ¡ má»™t key ra khá»i tá»« Ä‘iá»ƒn, chÃºng ta dÃ¹ng tá»« khoÃ¡ del\n1 2item = {\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 3 4del item[\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 512GB\u0026#34;] 5 6print(item) 7 8#Káº¿t quáº£ 9 10\u0026gt;\u0026gt;\u0026gt; print(item) 11{\u0026#39;Äiá»‡n thoáº¡i iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;} item PhÆ°Æ¡ng thá»©c items tráº£ vá» giÃ¡ trá»‹ cá»§a tá»« Ä‘iá»ƒn dÆ°á»›i dáº¡ng list tuple (key,value)\n1 2info = {\u0026#34;name\u0026#34;:\u0026#34;Alex\u0026#34;,\u0026#34;age\u0026#34;:18,\u0026#34;position\u0026#34;:\u0026#34;staff\u0026#34;} 3print(info.items()) 4 5# Káº¿t quáº£ 6 7\u0026gt;\u0026gt;\u0026gt; print(info.items()) 8dict_items([(\u0026#39;name\u0026#39;, \u0026#39;Alex\u0026#39;), (\u0026#39;age\u0026#39;, 18), (\u0026#39;position\u0026#39;, \u0026#39;staff\u0026#39;)]) len PhÆ°Æ¡ng thá»©c len tráº£ vá» sá»‘ lÆ°á»£ng pháº§n tá»­ trong tá»« Ä‘iá»ƒn\n1 2item = {\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 3 4print(len(item)) 5 6#Káº¿t quáº£ 7 8\u0026gt;\u0026gt;\u0026gt; print(len(item)) 92 Merge Äá»ƒ ná»‘i hai hay nhiá»u tá»« Ä‘iá»ƒn vÃ o lÃ m má»™t, cÃ³ má»™t sá»‘ cÃ¡ch sau:\nSá»­ dá»¥ng hÃ m update, hÃ m nÃ y Ä‘Ã£ Ä‘Æ°á»£c mÃ¬nh nÃ³i rÃµ á»Ÿ trÃªn, mÃ¬nh khÃ´ng nháº¯c láº¡i ná»¯a\nSá»­ dá»¥ng Kwargs **.\nTá»« phiÃªn báº£n 3.5 trá»Ÿ lÃªn, python há»— trá»£ \u0026ldquo;Ä‘á»‘i sá»‘ tá»« khÃ³a\u0026rdquo; - Kwargs - keyword arguments lÃ  **, vÃ  lÃºc nÃ y, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng ** á»Ÿ trÆ°á»›c tÃªn biáº¿n.\nVÃ­ dá»¥\n1 2itemApple = {\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;Äiá»‡n thoáº¡i iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 3 4 5itemSamsung = {\u0026#34;Äiá»‡n thoáº¡i Samsung Galaxy S22 Ultra 5G 128GB \u0026#34;:\u0026#34;27.990.000\u0026#34;,\u0026#34;Äiá»‡n thoáº¡i Samsung Galaxy S22 Ultra 5G 512GB\u0026#34;:\u0026#34;33.990.000\u0026#34;} 6 7itemPhone = {**itemApple,**itemSamsung} 8 9print(itemPhone) 10 11 12\u0026gt;\u0026gt;\u0026gt; print(itemPhone) 13{\u0026#39;Äiá»‡n thoáº¡i iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.790.000\u0026#39;, \u0026#39;Äiá»‡n thoáº¡i iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;, \u0026#39;Äiá»‡n thoáº¡i Samsung Galaxy S22 Ultra 5G 128GB \u0026#39;: \u0026#39;27.990.000\u0026#39;, \u0026#39;Äiá»‡n thoáº¡i Samsung Galaxy S22 Ultra 5G 512GB\u0026#39;: \u0026#39;33.990.000\u0026#39;} Tá»•ng káº¿t: Kiá»ƒu dá»¯ liá»‡u tá»« Ä‘iá»ƒn lÆ°u dá»¯ liá»‡u dÆ°á»›i dáº¡ng key-value\nKey-value Ä‘Æ°á»£c ngÄƒn cÃ¡ch vá»›i nhau bá»Ÿi dáº¥u hai cháº¥m (:)\nCáº·p key-value Ä‘Æ°á»£c ngÄƒn cÃ¡ch vá»›i cáº·p khÃ¡c bá»Ÿi dáº¥u pháº©y\nKey trong kiá»ƒu dá»¯ liá»‡u tá»« Ä‘iá»ƒn lÃ  duy nháº¥t\nKiá»ƒu tá»« Ä‘iá»ƒn khÃ´ng lÆ°u thÃ´ng tin theo má»™t thá»© tá»± cá»¥ thá»ƒ, thÃ´ng tin khi láº¥y ra cÃ³ thá»ƒ khÃ¡c thá»© tá»± vá»›i thÃ´ng tin khi nháº­p vÃ o. Tuy nhiÃªn, tá»« phiÃªn báº£n python3.7 trá»Ÿ Ä‘i, kiá»ƒu tá»« Ä‘iá»ƒn Ä‘Ã£ Ä‘Æ°á»£c sáº¯p xáº¿p theo thá»© tá»± cá»§a key\nKiá»ƒu dá»¯ liá»‡u list List lÃ  cÃ¡i thÃ¹ng chá»©a, Ä‘á»ƒ chá»©a táº­p cÃ¡c dá»¯ liá»‡u. Äá»ƒ khai bÃ¡o kiá»ƒu dá»¯ liá»‡u list, ta cÃ³ thá»ƒ dá»¥ng dáº¥u Ä‘Ã³ng má»Ÿ ngoáº·c vuÃ´ng ([]), hoáº·c dÃ¹ng tá»« khoÃ¡ list()\n1 2lsta = [1,2,3,4,5] # Ä‘Ã¢y lÃ  khai bÃ¡o list chÃ­nh thá»‘ng cá»§a python 3 4lstb = list((1,2,3,4,5)) # Ä‘Ã¢y lÃ  sá»­ dá»¥ng hÃ m Ä‘á»ƒ táº¡o list 5 6print(lsta) 7 8print(lstb) Truy xuáº¥t dá»¯ liá»‡u trong list Dá»¯ liá»‡u trong list cÃ³ thá»ƒ Ä‘Æ°á»£c truy xuáº¥t thÃ´ng qua index. Index lÃ  vá»‹ trÃ­ Ä‘á»©ng cá»§a pháº§n tá»­ trong list.\nVÃ­ dá»¥, náº¿u ta muá»‘n láº¥y ra giÃ¡ trá»‹ á»Ÿ vá»‹ trÃ­ 0 cá»§a list cÃ³ tÃªn lÃ  lsta, ta thá»±c hiá»‡n nhÆ° sau: lst[0]\n1 2lsta = [5,3,6,9] 3 4print(lsta[0]) 5print(lsta[2]) 6 7\u0026gt;\u0026gt;\u0026gt; print(lsta[0]) 85 9\u0026gt;\u0026gt;\u0026gt; print(lsta[2]) 106 slicing slicing lÃ  láº¥y má»™t nhÃ³m cÃ¡c pháº§n tá»­ trong list ra, cÃ¡ch thá»±c hiá»‡n giá»‘ng nhÆ° tuple\n1lsta = [5,3,6,9,3,5,1,2,9,6] 2 3print(lsta[1:5]) 4 5\u0026gt;\u0026gt;\u0026gt; print(lsta[1:5]) 6[3, 6, 9, 3] Tuy nhiÃªn, khÃ´ng giá»‘ng nhÆ° tuple, giÃ¡ trá»‹ cá»§a tuple khÃ´ng thá»ƒ thay Ä‘á»•i Ä‘Æ°á»£c, giÃ¡ trá»‹ cá»§a list cÃ³ thá»ƒ thay Ä‘á»•i Ä‘Æ°á»£c, nÃªn chÃºng ta cÃ³ thá»ƒ cáº­p nháº­t giÃ¡ trá»‹ cho list sá»­ dá»¥ng slicing\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4print(lsta) 5 6print(lsta[2:4]) 7 8lsta[2:4] = [8,8] 9 10print(lsta) 11 12print(lsta[2:4]) 13 14 15#Káº¿t quáº£ 16 17\u0026gt;\u0026gt;\u0026gt; print(lsta[2:4]) 18[6, 9] 19\u0026gt;\u0026gt;\u0026gt; 20\u0026gt;\u0026gt;\u0026gt; lsta[2:4] = [8,8] 21\u0026gt;\u0026gt;\u0026gt; 22\u0026gt;\u0026gt;\u0026gt; print(lsta) 23[5, 3, 8, 8, 3, 5, 1, 2, 9, 6] 24\u0026gt;\u0026gt;\u0026gt; 25\u0026gt;\u0026gt;\u0026gt; print(lsta[2:4]) 26[8, 8] Má»™t Ä‘iá»u khÃ¡ thÃº vá»‹, lÃ  list há»— trá»£ index ngÆ°á»£c, vÃ­ dá»¥, náº¿u chÃºng ta muá»‘n láº¥y pháº§n tá»­ cuá»‘i cÃ¹ng, ta cÃ³ thá»ƒ sá»­ dá»¥ng index [-1], dÃ¹ng [-2] náº¿u muá»‘n láº¥y pháº§n tá»­ káº¿ cuá»‘i .\nvÃ­ dá»¥\n1 2 3lsta = [5,3,6,9,3,5,1,2,9,6] 4 5print(lsta[-1]) 6 7print(lsta[-2]) 8 9#Káº¿t quáº£ 10 11\u0026gt;\u0026gt;\u0026gt; print(lsta[-1]) 126 13\u0026gt;\u0026gt;\u0026gt; 14\u0026gt;\u0026gt;\u0026gt; print(lsta[-2]) 159 Há»‡ quáº£ cá»§a index ngÆ°á»£c, lÃ  chÃºng ta cÃ³ slicing vá»›i sá»‘ Ã¢m\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4print(lsta[5:-1]) 5 6print(lsta[5:-2]) 7 8#Káº¿t quáº£ 9 10\u0026gt;\u0026gt;\u0026gt; print(lsta[5:-1]) 11[5, 1, 2, 9] 12\u0026gt;\u0026gt;\u0026gt; 13\u0026gt;\u0026gt;\u0026gt; print(lsta[5:-2]) 14[5, 1, 2] CÃ¡c phÆ°Æ¡ng thá»©c Ä‘Æ°á»£c há»— trá»£ append PhÆ°Æ¡ng thá»©c append dÃ¹ng Ä‘á»ƒ thÃªm pháº§n tá»­ vÃ o list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4lsta.append(1) 5 6lsta.append([11,12]) 7 8print(lsta) 9 10 11# Káº¿t quáº£ 12 13\u0026gt;\u0026gt;\u0026gt; print(lsta) 14[5, 3, 6, 9, 3, 5, 1, 2, 9, 6, 1, [11, 12]] pop PhÆ°Æ¡ng thá»©c pop dÃ¹ng Ä‘á»ƒ xoÃ¡ pháº§n tá»­ á»Ÿ vá»‹ trÃ­ index ra khá»i list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4lsta.pop(0) 5 6print(lsta) 7 8# Káº¿t quáº£ 9 10\u0026gt;\u0026gt;\u0026gt; print(lsta) 11[3, 6, 9, 3, 5, 1, 2, 9, 6] remove PhÆ°Æ¡ng thá»©c remove dÃ¹ng Ä‘á»ƒ xoÃ¡ pháº§n tá»­ ra khá»i list, náº¿u cÃ³ nhiá»u pháº§n tá»­ cÃ³ cÃ¹ng giÃ¡ trá»‹ vá»›i pháº§n tá»­ cáº§n xoÃ¡, thÃ¬ chá»‰ xoÃ¡ tháº±ng Ä‘áº§u tiÃªn\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4lsta.remove(9) 5 6print(lsta) 7 8 9# Káº¿t quáº£ 10 11\u0026gt;\u0026gt;\u0026gt; print(lsta) 12[5, 3, 6, 3, 5, 1, 2, 9, 6] reverse PhÆ°Æ¡ng thá»©c reverse Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ Ä‘áº£o ngÆ°á»£c list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4lsta.reverse() 5 6print(lsta) 7 8 9# Káº¿t quáº£ 10 11\u0026gt;\u0026gt;\u0026gt; print(lsta) 12[6, 9, 2, 1, 5, 3, 9, 6, 3, 5] CÃ¡c hÃ m Ä‘Æ°á»£c há»— trá»£ len HÃ m len tráº£ vá» sá»‘ lÆ°á»£ng pháº§n tá»­ trong list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4print(len(lsta)) 5 6 7# Káº¿t quáº£ 8 9\u0026gt;\u0026gt;\u0026gt; print(len(lsta)) 1010 max HÃ m max tráº£ vá» pháº§n tá»­ cÃ³ giÃ¡ trá»‹ lá»›n nháº¥t trong list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4print(max(lsta)) 5 6 7# Káº¿t quáº£ 8 9\u0026gt;\u0026gt;\u0026gt; print(max(lsta)) 109 min HÃ m min tráº£ vá» pháº§n tá»­ cÃ³ giÃ¡ trá»‹ nhá» nháº¥t trong list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4print(min(lsta)) 5 6 7# Káº¿t quáº£ 8 9\u0026gt;\u0026gt;\u0026gt; print(min(lsta)) 101 Kiá»ƒu dá»¯ liá»‡u set Trong python, set lÃ  táº­p há»£p khÃ´ng cÃ³ thá»© tá»± cÃ¡c dá»¯ liá»‡u. Dá»¯ liá»‡u trong set lÃ  duy nháº¥t.\nÄá»ƒ táº¡o má»™t set, chÃºng ta sá»­ dá»¥ng hÃ m set(), hoáº·c dÃ¹ng dáº¥u Ä‘Ã³ng má»Ÿ ngoáº·c nhá»n {}\nVÃ­ dá»¥:\n1 2item_samsung = set([\u0026#34;Samsung Galaxy S22 Ultra 5G\u0026#34;,\u0026#34;Samsung Galaxy A13\u0026#34;]) 3 4item_iphone = {\u0026#34;Iphone 12\u0026#34;,\u0026#34;Iphone 13\u0026#34;} 5 6print(item_samsung) 7 8print(item_iphone) 9 10#Káº¿t quáº£ 11 12\u0026gt;\u0026gt;\u0026gt; print(item_samsung) 13{\u0026#39;Samsung Galaxy S22 Ultra 5G\u0026#39;, \u0026#39;Samsung Galaxy A13\u0026#39;} 14\u0026gt;\u0026gt;\u0026gt; 15\u0026gt;\u0026gt;\u0026gt; print(item_iphone) 16{\u0026#39;Iphone 13\u0026#39;, \u0026#39;Iphone 12\u0026#39;} Má»™t vÃ i phÆ°Æ¡ng thá»©c cÆ¡ báº£n cá»§a Set PhÆ°Æ¡ng thá»©c Add PhÆ°Æ¡ng thá»©c nÃ y cÃ³ nhiá»‡m vá»¥ thÃªm pháº§n tá»­ vÃ  Set\nVÃ­ dá»¥:\n1 2item = set() 3 4item.add(\u0026#34;Iphone\u0026#34;) 5 6item.add(\u0026#34;Samsung\u0026#34;) 7 8print(item) 9 10 11# Káº¿t quáº£ 12 13\u0026gt;\u0026gt;\u0026gt; print(item) 14{\u0026#39;Samsung\u0026#39;, \u0026#39;Iphone\u0026#39;} PhÆ°Æ¡ng thá»©c Remove, Discard PhÆ°Æ¡ng thá»©c nÃ y dÃ¹ng Ä‘á»ƒ xoÃ¡ pháº§n tá»­ ra khá»i set. Äiá»ƒm khÃ¡c nhau cá»§a hai phÆ°Æ¡ng thá»©c nÃ y lÃ :\nPhÆ°Æ¡ng thá»©c remove: XoÃ¡ pháº§n tá»­ ra khá»i set, náº¿u khÃ´ng tá»“n táº¡i pháº§n tá»­ cáº§n xoÃ¡ trong set, chÆ°Æ¡ng trÃ¬nh sáº½ tráº£ vá» lá»—i KeyError\nPhÆ°Æ¡ng thá»©c discard: XoÃ¡ pháº§n tá»­ ra khá»i set, náº¿u khÃ´ng tá»“n táº¡i pháº§n tá»­ cáº§n xoÃ¡ trong set, chÆ°Æ¡ng trÃ¬nh váº«n hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng.\nVÃ­ dá»¥:\n1 2 3item = set() 4 5item.add(\u0026#34;Iphone\u0026#34;) 6 7item.add(\u0026#34;Samsung\u0026#34;) 8 9print(item) 10 11item.discard(\u0026#34;Samsung\u0026#34;) 12 13item.discard(\u0026#34;Xiaomi\u0026#34;) 14 15item.remove(\u0026#34;Oppo\u0026#34;) 16 17# Káº¿t quáº£ 18 19\u0026gt;\u0026gt;\u0026gt; print(item) 20{\u0026#39;Samsung\u0026#39;, \u0026#39;Iphone\u0026#39;} 21\u0026gt;\u0026gt;\u0026gt; 22\u0026gt;\u0026gt;\u0026gt; item.discard(\u0026#34;Samsung\u0026#34;) # xoÃ¡ bÃ¬nh thÆ°á»ng 23\u0026gt;\u0026gt;\u0026gt; 24\u0026gt;\u0026gt;\u0026gt; item.discard(\u0026#34;Xiaomi\u0026#34;) # Xiaomi khÃ´ng tá»“n táº¡i trong set item, chÆ°Æ¡ng trÃ¬nh váº«n khÃ´ng bÃºng ra lá»—i 25\u0026gt;\u0026gt;\u0026gt; 26\u0026gt;\u0026gt;\u0026gt; item.remove(\u0026#34;Oppo\u0026#34;) # Oppo khÃ´ng tá»“n táº¡i trong set item, chÆ°Æ¡ng trÃ¬nh bÃ¡o lá»—i KeyError 27Traceback (most recent call last): 28 File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; 29KeyError: \u0026#39;Oppo\u0026#39; PhÆ°Æ¡ng thá»©c Pop PhÆ°Æ¡ng thá»©c pop Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ láº¥y pháº§n tá»­ Ä‘áº§u tiÃªn cá»§a set ra, vÃ  loáº¡i pháº§n tá»­ cuá»‘i Ä‘Ã³ ra khá»i set.\nVÃ­ dá»¥:\n1 2 3item = {1,5,6,4,3,8,10} 4 5print(item) 6 7print(item.pop()) 8 9print(item) 10 11 12# Káº¿t quáº£ 13 14\u0026gt;\u0026gt;\u0026gt; item = {1,5,6,4,3,8,10} 15\u0026gt;\u0026gt;\u0026gt; 16\u0026gt;\u0026gt;\u0026gt; print(item) 17{1, 3, 4, 5, 6, 8, 10} 18\u0026gt;\u0026gt;\u0026gt; 19\u0026gt;\u0026gt;\u0026gt; print(item.pop()) 201 21\u0026gt;\u0026gt;\u0026gt; 22\u0026gt;\u0026gt;\u0026gt; print(item) 23{3, 4, 5, 6, 8, 10} PhÆ°Æ¡ng thá»©c Clear PhÆ°Æ¡ng thá»©c clear Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xoÃ¡ má»i pháº§n tá»­ trong set. Káº¿t quáº£ lÃ  chÃºng ta Ä‘Æ°á»£c má»™t set rá»—ng\n1 2 3item_iphone = {\u0026#34;Iphone 12\u0026#34;,\u0026#34;Iphone 13\u0026#34;} 4 5item_iphone.clear() 6 7print(item_iphone) 8 9 10# Káº¿t quáº£ 11 12\u0026gt;\u0026gt;\u0026gt; print(item_iphone) 13set() Kiá»ƒu dá»¯ liá»‡u array Array lÃ  táº­p cÃ¡c pháº§n tá»­ Ä‘Æ°á»£c lÆ°u trá»¯ cÃ³ thá»© tá»± trong bá»™ nhá»›. CÃ¡c pháº§n tá»­ trong array pháº£i cÃ³ cÃ¹ng kiá»ƒu dá»¯ liá»‡u. Kiá»ƒu dá»¯ liá»‡u array giá»‘ng kiá»ƒu array trong c++.\nVÃ­ dá»¥:\n1 2import array as arr 3 4item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5]) 5 6print(item_number) 7 8 9item_number_decimal = arr.array(\u0026#39;d\u0026#39;,[5.391,6.626,1.054,1.616]) 10 11 12print(item_number_decimal) 13 14 15 16#Káº¿t quáº£ 17 18\u0026gt;\u0026gt;\u0026gt; print(item_number) 19array(\u0026#39;i\u0026#39;, [1, 2, 3, 5]) 20 21\u0026gt;\u0026gt;\u0026gt; print(item_number_decimal) 22array(\u0026#39;d\u0026#39;, [5.391, 6.626, 1.054, 1.616]) Má»™t vÃ i phÆ°Æ¡ng thá»©c cÆ¡ báº£n cá»§a array PhÆ°Æ¡ng thá»©c insert, phÆ°Æ¡ng thá»©c append PhÆ°Æ¡ng thá»©c insert vÃ  append Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ thÃªm pháº§n tá»­ vÃ o array, Ä‘iá»ƒm khÃ¡c biá»‡t cá»§a hai phÆ°Æ¡ng thá»©c lÃ :\nPhÆ°Æ¡ng thá»©c insert: Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ chÃ¨n pháº§n tá»­ vÃ o vá»‹ trÃ­ tuá»³ Ã½.\nPhÆ°Æ¡ng thá»©c append: ChÃ¨n vÃ o cuá»‘i array.\nVÃ­ dá»¥:\n1 2import array as arr 3 4item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5]) 5 6item_number.insert(2,4) 7 8print(item_number) 9 10item_number.append(1) 11 12print(item_number) 13 14#Káº¿t quáº£ 15\u0026gt;\u0026gt;\u0026gt; item_number.insert(2,4) 16\u0026gt;\u0026gt;\u0026gt; print(item_number) 17array(\u0026#39;i\u0026#39;, [1, 2, 4, 3, 5]) 18 19\u0026gt;\u0026gt;\u0026gt; item_number.append(1) 20\u0026gt;\u0026gt;\u0026gt; print(item_number) 21array(\u0026#39;i\u0026#39;, [1, 2, 4, 3, 5, 1]) PhÆ°Æ¡ng thá»©c truy xuáº¥t pháº§n tá»­ theo index Äá»ƒ truy xuáº¥t pháº§n tá»­ theo index, chÃºng ta sá»­ dá»¥ng dáº¥u ngoáº·c vuÃ´ng [], kÃ¨m theo vá»‹ trÃ­ cá»§a pháº§n tá»­ cáº§n truy xuáº¥t.\n1 2 3 4import array as arr 5 6item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5]) 7 8print(item_number[2]) 9 10 11#Káº¿t quáº£ 12 13\u0026gt;\u0026gt;\u0026gt; print(item_number[2]) 143 PhÆ°Æ¡ng thá»©c remove, phÆ°Æ¡ng thá»©c pop PhÆ°Æ¡ng thá»©c remove vÃ  pop Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xoÃ¡ pháº§n tá»­ ra khá»i array.\nPhÆ°Æ¡ng thá»©c remove: XoÃ¡ pháº§n tá»­ ra khá»i máº£ng, náº¿u máº£ng cÃ³ nhiá»u pháº§n tá»­ trÃ¹ng vá»›i pháº§n tá»­ cáº§n xoÃ¡ thÃ¬ chá»‰ xoÃ¡ pháº§n tá»­ xuáº¥t hiá»‡n Ä‘áº§u tiÃªn. Náº¿u pháº§n tá»­ khÃ´ng cÃ³ trong máº£ng, chÆ°Æ¡ng trÃ¬nh sáº½ bÃºng ra lá»—i.\nPhÆ°Æ¡ng thá»©c pop: XoÃ¡ pháº§n tá»­ á»Ÿ vá»‹ trÃ­ index ra khá»i máº£ng, tráº£ vá» lÃ  giÃ¡ trá»‹ cá»§a pháº§n tá»­ bá»‹ remove. Náº¿u khÃ´ng truyá»n vÃ o vá»‹ trÃ­ cáº§n xoÃ¡, thÃ¬ sáº½ xoÃ¡ pháº§n tá»­ cuá»‘i cÃ¹ng trong máº£ng.\n1 2 3import array as arr 4 5item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5,2]) 6 7print(item_number) 8 9item_number.remove(2) 10 11print(item_number) 12 13print(item_number.pop(2)) 14 15print(item_number) 16 17 18#Káº¿t quáº£ 19 20\u0026gt;\u0026gt;\u0026gt; print(item_number) 21array(\u0026#39;i\u0026#39;, [1, 2, 3, 5, 2]) 22\u0026gt;\u0026gt;\u0026gt; item_number.remove(2) # xoÃ¡ sá»‘ 2 Ä‘i 23\u0026gt;\u0026gt;\u0026gt; 24\u0026gt;\u0026gt;\u0026gt; print(item_number) 25array(\u0026#39;i\u0026#39;, [1, 3, 5, 2]) # Chá»‰ sá»‘ 2 Ä‘áº§u tiÃªn bá»‹ xoÃ¡ 26\u0026gt;\u0026gt;\u0026gt; 27\u0026gt;\u0026gt;\u0026gt; print(item_number.pop(2)) # xoÃ¡ pháº§n tá»­ á»Ÿ vá»‹ trÃ­ sá»‘ 2 285 # Pháº§n tá»­ á»Ÿ vá»‹ trÃ­ sá»‘ 2 lÃ  5, pháº§n tá»­ 5 Ä‘Ã£ bá»‹ xoÃ¡ 29\u0026gt;\u0026gt;\u0026gt; 30\u0026gt;\u0026gt;\u0026gt; print(item_number) 31array(\u0026#39;i\u0026#39;, [1, 3, 2]) PhÆ°Æ¡ng thá»©c index PhÆ°Æ¡ng thá»©c nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tÃ¬m vá»‹ trÃ­ cá»§a pháº§n tá»­ trong array\n1 2import array as arr 3 4item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5,2]) 5 6print(item_number.index(2)) 7 8 9print(item_number.index(2,2)) 10 11 12 13#Káº¿t quáº£ 14 15\u0026gt;\u0026gt;\u0026gt; print(item_number.index(2)) #TÃ¬m vá»‹ trÃ­ cá»§a sá»‘ 2 161 17\u0026gt;\u0026gt;\u0026gt; 18\u0026gt;\u0026gt;\u0026gt; print(item_number.index(2,2))# TÃ¬m vá»‹ trÃ­ cá»§a sá»‘ 2, báº¯t Ä‘áº§u tá»« vá»‹ trÃ­ 2 194 ChÃºc cÃ¡c báº¡n há»c tháº­t tá»‘t.\n","date":"Jul 10, 2022","img":"","permalink":"/courses/python/3_python_data_struct/","series":["KhÃ³a há»c python cÄƒn báº£n"],"tags":["python"],"title":"BÃ i 2: Kiá»ƒu Dá»¯ Liá»‡u Trong Python"},{"categories":"python","content":"Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ tÃ¬m hiá»ƒu cÃ¡c má»¥c sau\nCÃ i Ä‘áº·t python CÃ i Ä‘áº·t pháº§n má»m Ä‘á»ƒ láº­p trÃ¬nh python (IDE) ChÆ°Æ¡ng trÃ¬nh python Ä‘áº§u tiÃªn - Hello word Biáº¿n trong python Kiá»ƒu dá»¯ liá»‡u Khai bÃ¡o vÃ  sá»­ dá»¥ng biáº¿n trong python Ã‰p kiá»ƒu dá»¯ liá»‡u Xem kiá»ƒu dá»¯ liá»‡u CÃ i Ä‘áº·t python Äá»ƒ cÃ i Ä‘áº·t python, cÃ¡c báº¡n truy cáº­p vÃ o Ä‘Æ°á»ng dáº«n https://www.python.org/downloads/ vÃ  download phiÃªn báº£n python má»›i nháº¥t, phÃ¹ há»£p vá»›i há»‡ Ä‘iá»u hÃ nh cá»§a báº¡n. Táº¡i thá»i Ä‘iá»ƒm mÃ¬nh viáº¿t bÃ i viáº¿t nÃ y, phiÃªn báº£n python má»›i nháº¥t lÃ  3.10.4. Náº¿u cÃ¡c báº¡n sá»­ dá»¥ng há»‡ Ä‘iá»u hÃ nh window, cÃ´ng viá»‡c sáº½ háº¿t sá»©c Ä‘Æ¡n giáº£n, cÃ¡c báº¡n chá»‰ cáº§n download file cÃ i Ä‘áº·t python vá», áº¥n next -\u0026gt; next -\u0026gt; next \u0026hellip; finish. Xong\nÄá»‘i vá»›i há»‡ Ä‘iá»u hÃ nh macos hoáº·c linux, thÃ´ng thÆ°á»ng thÃ¬ Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t sáºµn python, nÃªn cÃ¡c báº¡n cÃ³ thá»ƒ bá» qua bÆ°á»›c nÃ y.\nHÃ£y liÃªn há»‡ mÃ¬nh qua chat message náº¿u cÃ¡c báº¡n gáº·p báº¥t ká»³ khÃ³ khÄƒn hoáº·c lá»—i gÃ¬ khi cÃ i Ä‘áº·t python nhÃ©.\nCÃ i Ä‘áº·t pháº§n má»m Ä‘á»ƒ láº­p trÃ¬nh python (IDE) á» Ä‘Ã¢y, chÃºng ta sáº½ sá»­ dá»¥ng Visual studio code, má»™t IDE nháº¹ nhÃ ng, há»— trá»£ nhiá»u tÃ­nh nÄƒng, há»— trá»£ nhiá»u mÃ´i trÆ°á»ng. CÃ¡c báº¡n hÃ£y truy cáº­p vÃ o Ä‘Æ°á»ng dáº«n https://code.visualstudio.com/download vÃ  download file cÃ i Ä‘áº·t vá». Vá»›i há»‡ Ä‘iá»u hÃ nh window thÃ¬ chÃºng ta chá»‰ cáº§n next -\u0026gt; next \u0026hellip; finish.\nChÆ°Æ¡ng trÃ¬nh python Ä‘áº§u tiÃªn - Hello word ChÃºng ta hÃ£y má»Ÿ chÆ°Æ¡ng trÃ¬nh visual studio code lÃªn, chá»n File -\u0026gt; New File -\u0026gt; Ä‘áº·t tÃªn file lÃ  hello_word.py\nGÃµ vÃ o dÃ²ng lá»‡nh\n1print (\u0026#34;Hello World!\u0026#34;) Chá»n File -\u0026gt; Save hoáº·c áº¥n tá»• há»£p phÃ­m ctr + s (window - ubuntu) hoáº·c command + s (macos)\nChá»n Terminal -\u0026gt; New Terminal\nGÃµ vÃ o trong terminal dÃ²ng lá»‡nh\n1python3 hello_word.py Cá»­a sá»• terminal sáº½ hiá»‡n ra nhÆ° sau:\n1python3 hello_word.py 2\u0026gt;\u0026gt;\u0026gt;Hello World! Biáº¿n trong python Biáº¿n lÃ  nÆ¡i lÆ°u trá»¯ cÃ¡c giÃ¡ trá»‹. GiÃ¡ trá»‹ Ä‘Æ°á»£c gÃ¡n vÃ o biáº¿n thÃ´ng qua dáº¥u =\nVÃ­ dá»¥:\n1 2name = \u0026#39;alex\u0026#39; # name lÃ  tÃªn biáº¿n, giÃ¡ trá»‹ cá»§a name lÃ  alex 3 4age = 18 # age lÃ  tÃªn biáº¿n, giÃ¡ trá»‹ cá»§a age lÃ  18 Kiá»ƒu dá»¯ liá»‡u Má»—i giÃ¡ trá»‹ trong python Ä‘á»u thuá»™c má»™t kiá»ƒu dá»¯ liá»‡u nÃ o Ä‘Ã³. CÃ¡c kiá»ƒu dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a sáºµn trong python lÃ  string, number, list, dictionary, set. NgoÃ i ra, chÃºng ta cÃ³ thá»ƒ tá»± Ä‘á»‹nh nghÄ©a cÃ¡c kiá»ƒu dá»¯ liá»‡u Ä‘á»ƒ Ä‘Ã¡p á»©ng nhu cáº§u trong bÃ i toÃ¡n cá»§a mÃ¬nh. VÃ­ dá»¥ kiá»ƒu dá»¯ liá»‡u con mÃ¨o, con chÃ³, Ä‘á»™ng váº­t, cÃ¢y, xe Ä‘áº¡p, xe hÆ¡i \u0026hellip;\nKhai bÃ¡o vÃ  sá»­ dá»¥ng biáº¿n trong python Python khÃ´ng cÃ³ cÃ¢u lá»‡nh khai bÃ¡o biáº¿n. Biáº¿n Ä‘Æ°á»£c táº¡o ra táº¡i thá»i Ä‘iá»ƒm chÃºng Ä‘Æ°á»£c gÃ¡n giÃ¡ trá»‹.\nVÃ­ dá»¥:\n1x = 5 # biáº¿n x Ä‘Æ°á»£c táº¡o ra, cÃ³ giÃ¡ trá»‹ lÃ  5, kiá»ƒu dá»¯ liá»‡u lÃ  int 2 3x = \u0026#34;Alex\u0026#34; # biáº¿n x Ä‘Æ°á»£c gÃ¡n giÃ¡ trá»‹ lÃ  Alex, kiá»ƒu dá»¯ liá»‡u lÃ  string Ã‰p kiá»ƒu dá»¯ liá»‡u Ã‰p kiá»ƒu, nghÄ©a lÃ  biáº¿n Ä‘ang cÃ³ kiá»ƒu dá»¯ liá»‡u nÃ y, chÃºng ta muá»‘n biáº¿n nÃ³ thÃ nh kiá»ƒu dá»¯ liá»‡u ná». VÃ­ dá»¥, má»™t biáº¿n Ä‘ang cÃ³ kiá»ƒu dá»¯ liá»‡u lÃ  int, bÃ i toÃ¡n yÃªu cáº§u chuyá»ƒn sang kiá»ƒu dá»¯ liá»‡u float rá»“i tÃ­nh toÃ¡n\n1 2 3x = 5 # kiá»ƒu dá»¯ liá»‡u cá»§a x lÃ  int 4 5x = float(x) # kiá»ƒu dá»¯ liá»‡u cá»§a x lÃ  float 6 7x = str(x) # kiá»ƒu dá»¯ liá»‡u cá»§a x giá» lÃ  string Xem kiá»ƒu dá»¯ liá»‡u Äá»ƒ xem kiá»ƒu dá»¯ liá»‡u cá»§a má»™t biáº¿n, chÃºng ta sá»­ dá»¥ng hÃ m type\n1 2x = 9 3 4y = \u0026#39;alex\u0026#39; 5 6 7print(type(x)) 8 9\u0026gt;\u0026gt;\u0026gt; \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; 10 11print(type(y)) 12 13\u0026gt;\u0026gt;\u0026gt; \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; ","date":"Jun 5, 2022","img":"","permalink":"/courses/python/2_python_basic/","series":["KhÃ³a há»c python cÄƒn báº£n"],"tags":["python"],"title":"BÃ i 1: CÄƒn Báº£n Vá» Python"},{"categories":null,"content":" Chá»‰ sá»‘ MACD, lÃ  tÃªn gá»i táº¯t cá»§a moving average convergence/divergence, lÃ  má»™t chá»‰ sá»‘ giao dá»‹ch Ä‘Æ°á»£c sá»­ dá»¥ng trong phÃ¢n tÃ­ch ká»¹ thuáº­t trÃªn giÃ¡ cá»• phiáº¿u. Chá»‰ sá»‘ Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Gerald Appel vÃ o nhá»¯ng nÄƒm cuá»‘i tháº­p niÃªn 70 cá»§a tháº¿ ká»· 20.\nChá»‰ sá»‘ MACD giÃºp chÃºng ta xÃ¡c Ä‘á»‹nh sá»± thay Ä‘á»•i cá»§a sá»©c máº¡nh, hÆ°á»›ng, Ä‘á»™ng lÆ°á»£ng ( momentum), vÃ  khoáº£ng thá»i gian cá»§a xu hÆ°á»›ng giÃ¡ cá»• phiáº¿u. Äá»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u nÃ y, MACD sá»­ dá»¥ng 3 chuá»—i thá»i gian EMA khÃ¡c nhau, theo sÃ¡ch vá»Ÿ kinh Ä‘iá»ƒn lÃ  EMA12, EMA26 vÃ  EMA9. Chá»‰ sá»‘ MACD dÃ¹ng 3 chuá»—i EMA trÃªn, Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  MACD(12,26,9). Do chá»‰ sá»­ dá»¥ng lá»‹ch sá»­ giÃ¡ cá»§a quÃ¡ khá»©, nÃªn chá»‰ sá»‘ MACD Ä‘Æ°á»£c xáº¿p vÃ o nhÃ³m chá»‰ sá»‘ dá»± bÃ¡o muá»™n.\nMÃ´ hÃ¬nh MACD ÄÆ°á»ng MACD $$ MACD = EMA_{12} - EMA_{26} $$\nMACD Ä‘Æ°á»£c cáº¥u táº¡o báº±ng cÃ¡ch láº¥y chu ká»³ ngáº¯n háº¡n trá»« chu ká»³ dÃ i háº¡n (EMA12 - EMA26). Thá»‹ trÆ°á»ng tÄƒng giÃ¡ lÃ  táº¡i thá»i Ä‘iá»ƒm MACD chuyá»ƒn tráº¡ng thÃ¡i giÃ¡ trá»‹ tá»« Ã¢m sang dÆ°Æ¡ng. NgÆ°á»£c láº¡i, thá»‹ trÆ°á»ng giáº£m giÃ¡ lÃ  táº¡i thá»i Ä‘iá»ƒm MACD chuyá»ƒn tráº¡ng thÃ¡i tá»« dÆ°Æ¡ng sang Ã¢m\n$$ signal = EMA_9 $$\nÄÆ°á»ng tÃ­n hiá»‡u Ä‘i song song vá»›i Ä‘Æ°á»ng MACD, vÃ  xáº£y ra cÃ¡c trÆ°á»ng há»£p sau\nXu hÆ°á»›ng tÄƒng giÃ¡: ÄÆ°á»ng MACD cáº¯t Ä‘Æ°á»ng tÃ­n hiá»‡u, MACD Ä‘i tá»« dÆ°á»›i lÃªn\nXu hÆ°á»›ng giáº£m giÃ¡: ÄÆ°á»ng MACD cáº¯t Ä‘Æ°á»ng tÃ­n hiá»‡u, MADC Ä‘i tá»« trÃªn xuá»‘ng\n$$ histogram = MACD - signal $$\nÄÆ°á»ng histogram: Ä‘o khoáº£ng cÃ¡ch chÃªn lá»‡ch giá»¯a MACD vÃ  signal. NhÆ° hÃ¬nh 1 phÃ­a trÃªn, giÃ¡ trá»‹ cá»§a histotram Ä‘Æ°á»£c biá»ƒu diá»…n lÃ  cÃ¡c Ä‘Æ°á»ng trá»¥ hÃ¬nh vuÃ´ng, cÃ³ giÃ¡ trá»‹ dÃ i ngáº¯n khÃ¡c nhau. GiÃ¡ trá»‹ histogram pháº£n Ã¡nh giÃ¡ trá»‹ Ä‘á»™ng lÆ°á»£ng (momemtum) vá» giÃ¡. Náº¿u MACD lá»›n hÆ¡n Ä‘Æ°á»ng tÃ­n hiá»‡u thÃ¬ chÃºng ta sáº½ cÃ³ vÃ¹ng Ä‘á»“i dÆ°Æ¡ng.\nNáº¿u Ä‘á»ƒ Ã½ ká»¹, chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng, náº¿u lá»±c mua váº«n dÆ°Æ¡ng, Ä‘á»“i váº«n dÆ°Æ¡ng, nhÆ°ng giÃ¡ trá»‹ histogram ngáº¯n láº¡i, gáº§n 0, Ä‘Ã³ cÃ³ thá»ƒ lÃ  tÃ­n hiá»‡u cá»§a viá»‡c giÃ¡ cÃ³ thá»ƒ giáº£m.\nViáº¿t bot mua chá»©ng khoÃ¡n mÃ£ MWG, tá»± Ä‘á»™ng, dá»±a trÃªn MACD, kiá»ƒm thá»­ lá»£i nhuáº­n DÆ°á»›i tÆ° cÃ¡ch lÃ  láº­p trÃ¬nh viÃªn, mÃ¬nh sáº½ coding má»™t con bot nhá», chá»‰ sá»­ dá»¥ng MACD, vÃ  xem thá»­ lá»£i nhuáº­n nhÆ° tháº¿ nÃ o.\nBÃ i toÃ¡n giáº£ Ä‘á»‹nh:\nCho dÆ° 100 triá»‡u VND trong tay\nÄáº§u tÆ° cá»• phiáº¿u cá»§a táº­p Ä‘oÃ n tháº¿ giá»›i Di Ä‘á»™ng, mÃ£ cá»• phiáº¿u MWG\nThá»i gian: Tá»« ngÃ y 1/1/2021 Ä‘áº¿n 31/12/2021\nÄáº§u tÆ° toÃ n bá»™ trong má»™t láº§n, khÃ´ng DCA, khÃ´ng xÃ©t yáº¿u tá»‘ T+3, giÃ¡ mua vÃ  giÃ¡ chá»‘t lá»i lÃ  giÃ¡ táº¡i thá»i Ä‘iá»ƒm close.\nLáº¥y dá»¯ liá»‡u: MÃ¬nh sá»­ dá»¥ng thÆ° viá»‡n vnquant cá»§a anh Pháº¡m KhÃ¡nh ÄÃ¬nh. MÃ£ nguá»“n cá»§a thÆ° viá»‡n á»Ÿ Ä‘á»‹a chá»‰ https://github.com/phamdinhkhanh/vnquant. DataSource Ä‘Æ°á»£c dÃ¹ng lÃ  cá»§a vndirect. ThÆ° viá»‡n cá»§a anh KhÃ¡nh táº¡i thá»i Ä‘iá»ƒm mÃ¬nh sá»­ dá»¥ng bá»‹ lá»—i khi load data vndirect, mÃ¬nh cÃ³ rewrite láº¡i.\nÄá»ƒ tÃ­nh EMA, mÃ¬nh xÃ i hÃ m ewm cÃ³ sáºµn cá»§a pandas.\nKáº¿t quáº£: NhÆ° hÃ¬nh 1 mÃ¬nh Ä‘Ã£ show phÃ­a trÃªn, hi hi.\n1Profit gained from the MACD strategy by investing $100M in MWG : 15619726.64 2Profit percentage of the MACD strategy : 15% Náº¿u mÃ¬nh Ä‘áº§u tÆ° 100 triá»‡u á»Ÿ Ä‘áº§u nÄƒm 2021, sá»­ dá»¥ng MACD vá»›i cÃ¡c tham sá»‘ (12, 26, 9), Ä‘áº¿n cuá»‘i nÄƒm mÃ¬nh thu Ä‘Æ°á»£c thÃªm 15 triá»‡u 6 trÄƒm 19 ngÃ n 7 trÄƒm 26 Ä‘á»“ng. Lá»£i nháº­n hÆ¡n 15%, cao hÆ¡n tiá»n lá»i gá»­i ngÃ¢n hÃ ng.\nTham sá»‘ 12,16,9 theo sÃ¡ch vá»Ÿ, mÃ¬nh khÃ´ng Æ°ng láº¯m, tháº¿ lÃ  mÃ¬nh Ä‘Ã£ cho cháº¡y grid search tÃ¬m tham sá»‘ tá»‘t nháº¥t, káº¿t quáº£ á»Ÿ hÃ¬nh 2. Cuá»‘i cÃ¹ng mÃ¬nh Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c vÃ i tá»• há»£p nhÆ° (9,25,6) hoáº·c (10,26,5) cho ra lá»£i nhuáº­n Ä‘áº¡t 40%.\nHÃ¬nh 2: MWG grid search\nCho dÃ¹ cÃ¡c tá»• há»£p á»Ÿ trÃªn khÃ¡ cao, nhÆ°ng mÃ¬nh quyáº¿t Ä‘á»‹nh chá»n cáº·p tá»• há»£p (11,31,5) cho cÃ¡c bÃ i toÃ¡n trong tÆ°Æ¡ng lai. LÃ½ do lÃ  lá»£i nhuáº­n cá»§a táº­p tá»• há»£p cÅ©ng khÃ¡ cao, Ä‘áº¡t 39%, thá»© hai lÃ  táº­p tá»• há»£p trÃªn chá»©a toÃ n sá»‘ nguyÃªn tá»‘.\nBOT mua chá»©ng khoÃ¡n, rá»— VN30 TÆ°Æ¡ng tá»± nhÆ° mua cá»• phiáº¿u MWG. MÃ¬nh sáº½ thá»±c hiá»‡n test mua cá»• phiáº¿u trong rá»— VN30, gá»“m cÃ¡c mÃ£ cá»• phiáº¿u VPB, HPG, MBB, POW, STB, TCB, SSI, CTG, VRE, TCH, VHM, NVL, PDR, BID, FPT, HDB, TPB, SBT, MWG, VIC, BVH, VNM, PLX, MSN, PNJ, VCB, VJC, KDH, REE, GAS nhÆ° sau:\nMá»—i loáº¡i cá»• phiáº¿u Ä‘Æ°á»£c cáº¥p vá»‘n 100 triá»‡u, tá»•ng cá»™ng 30 mÃ£ cá»• phiáº¿u, cÃ³ 3 tá»·\nSá»­ dá»¥ng tá»• há»£p MACD(11,31,5)\nThá»‘ng kÃª lá»£i nhuáº­n cuá»‘i nÄƒm\nKáº¿t quáº£\nStock code Profit Profit Percent VPB 59531568.83 59 HPG 47797426.41 47 MBB 43655931.7 43 POW 11334630.9 11 STB 68945860.5 68 TCB 30909090.6 30 SSI 88181694.47 88 CTG 16023538.94 16 VRE 13112161.55 13 TCH 61063208.12 61 VHM 5633657.62 5 NVL 83612690.71 83 PDR 73030645.91 73 BID -10671169.9 -11 FPT 16548330.46 16 HDB 42686713.83 42 TPB 30960123.75 30 SBT 25536989.15 25 MWG 39039335.94 39 VIC 30392688.88 30 BVH -3770737.5 -4 VNM -13891787.01 -14 PLX 5485716.75 5 MSN 8503902.24 8 PNJ -6325266.73 -7 VCB -7289353.31 -8 VJC -2464227.2 -3 KDH 44801727.18 44 REE 26242537.2 26 GAS 41354753.12 41 CÃ³ Ã´ng lá»i, cÃ³ Ã´ng lá»—. Tá»•ng lá»i lÃ  869.972.383 triá»‡u, trÃªn tá»· lá»‡ Ä‘áº§u tÆ° lÃ  3 tá»·. Äáº¡t tá»· lá»‡ lá»£i nhuáº­n 28%.\ná» trÃªn, mÃ¬nh chá»‰ sá»­ dá»¥ng Ä‘Æ°á»ng xu hÆ°á»›ng Ä‘á»ƒ quyáº¿t Ä‘á»‹nh mua / bÃ¡n, chÆ°a há» sá»­ dá»¥ng giÃ¡ trá»‹ Ä‘á»™ng lÆ°á»£ng cá»§a histogram Ä‘á»ƒ xÃ©t viá»‡c chá»‘t lá»i hiá»‡u quáº£. NÃªn hiá»‡u quáº£ Ä‘áº§u tÆ° váº«n cÃ²n nhá».\nMÃ¬nh Ä‘iá»u chá»‰nh láº¡i má»™t chÃºt, náº¿u giÃ¡ trá»‹ histogram giáº£m bÃ© hÆ¡n 10% so vá»›i thá»i Ä‘iá»ƒm cao nháº¥t á»Ÿ thá»i Ä‘iá»ƒm Ä‘á»“i dÆ°Æ¡ng, mÃ¬nh sáº½ chá»‘t lá»i ngay. NgoÃ i ra, chÃºng ta sáº½ káº¿t há»£p vá»›i mÃ¢y Ichimoku Ä‘á»ƒ lá»c láº¡i cÃ¡c thá»i Ä‘iá»ƒm mua cho há»£p lÃ½ hÆ¡n.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, háº¹n gáº·p láº¡i á»Ÿ bÃ i tiáº¿p theo.\n","date":"Apr 11, 2022","img":"","permalink":"/courses/stocks/1_macd/","series":["Chá»©ng khoÃ¡n cÄƒn báº£n"],"tags":["stock"],"title":"Chá»‰ Sá»‘ Dá»± BÃ¡o MACD"},{"categories":null,"content":" Táº¡i sao chÃºng ta cáº§n chuáº©n hÃ³a layer Batch Normalization Batch Normalization hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o Khuyáº¿t Ä‘iá»ƒm cá»§a Batch Normalization Weight Normalization Layer Normalization Instance Normalization Group Normalization Nguá»“n tham kháº£o Táº¡i sao chÃºng ta cáº§n chuáº©n hÃ³a layer MÃ¬nh nghÄ©, cÃ¢u tráº£ lá»i thá»a Ä‘Ã¡ng nháº¥t lÃ  bá»Ÿi vÃ¬ nÃ³ lÃ m tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh. Trong quÃ¡ trÃ¬nh thá»±c nghiá»‡m, cÃ¡c nhÃ  nghiÃªn cá»©u nháº­n tháº¥y ráº±ng viá»‡c thÃªm Layer Normalization cho káº¿t quáº£ test tá»‘t hÆ¡n/ cháº¡y nhanh hÆ¡n, há»™i tá»¥ sá»›m hÆ¡n \u0026hellip; VÃ  tá»« Ä‘Ã³, cÃ¡c nhÃ  nghiÃªn cá»©u Ä‘á»• háº¿t tÃ¢m sá»©c khai phÃ¡, Ä‘Ã o bá»›i nÃ³ ra thá»­ sai , cáº£i tiáº¿n, Ä‘á» xuáº¥t cÃ¡c mÃ´ hÃ¬nh chuáº©n hÃ³a liÃªn lá»¥c, táº¡o nÃªn cÃ¡c mÃ´ hÃ¬nh mÃ  mÃ¬nh sáº½ liá»‡t kÃª á»Ÿ dÆ°á»›i.\nTháº­t ra, má»™t Ã½ tÆ°á»Ÿng nÃ o hay thÃ¬ cÅ©ng cÃ³ nhiá»u nhÃ  nghiÃªn cá»©u Ä‘á»• háº¿t tÃ¢m huyáº¿t vÃ o nghiÃªn cá»©u, Ä‘Ã o sÃ¢u táº­n cÃ¹ng nÃ³ ra, Ä‘á»ƒ cá»‘ng hiáº¿n cho nhÃ¢n loáº¡i.\nBatch Normalization ÄÃ¢y lÃ  má»™t trong cÃ¡c phÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a lÃ¢u Ä‘á»i vÃ  Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i nháº¥t. Ngay cáº£ mÃ¬nh khi test cÃ¡c data má»›i cÅ©ng xÃ i nÃ³ vÃ¬ sá»± tiá»‡n lá»£i vÃ  nhanh chÃ³ng cá»§a nÃ³. CÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m Ä‘á»c paper cÃ³ tá»±a Ä‘á» Batch normalization: Accelerating deep network training by reducing internal covariate shift. Nhá»¯ng pháº§n bÃªn dÆ°á»›i, mÃ¬nh sáº½ thay chá»¯ Batch Normalization thÃ nh BN Ä‘á»ƒ cho cÃ¢u chá»¯ Ä‘Æ°á»£c ngáº¯ng gá»n vÃ  táº­p trung vÃ o Ã½ chÃ­nh hÆ¡n.\nBatch Normalization (BN) Ä‘á» cáº­p Ä‘áº¿n viá»‡c chuáº©n hÃ³a giÃ¡ trá»‹ input cá»§a layer báº¥t ká»³. Chuáº©n hÃ³a cÃ³ nghÄ©a lÃ  Ä‘Æ°a phÃ¢n phá»‘i cá»§a layer vá» xáº¥p xá»‰ phÃ¢n phá»‘i chuáº©n vá»›i trung bÃ¬nh xáº¥p xá»‰ 0 vÃ  phÆ°Æ¡ng sai xáº¥p xá»‰ 1. Vá» máº·c toÃ¡n há»c, Batch Normalization (BN) thá»±c hiá»‡n nhÆ° sau: vá»›i má»—i layer, BN tÃ­nh giÃ¡ trá»‹ trung bÃ¬nh vÃ  phÆ°Æ¡ng sai cá»§a nÃ³. Sau Ä‘Ã³ sáº½ láº¥y giÃ¡ trá»‹ Ä‘áº·c trÆ°ng trá»« giÃ¡ trá»‹ trung bÃ¬nh , sau Ä‘Ã³ chia cho Ä‘á»™ lá»‡ch chuáº©n. Thá»±c táº¿, chÃºng ta hay chia táº­p train thÃ nh tá»«ng batch vá»›i kÃ­ch thÆ°á»›c lÃ  16,32,64 ,128 \u0026hellip; hÃ¬nh, hay cÃ²n gá»i lÃ  1 mini-batch size 16,32,64,128 \u0026hellip;. BN Ä‘Æ°á»£c tÃ­nh toÃ¡n trÃªn cÃ¡c mini-batch Ä‘Ã³.\nCÃ´ng thá»©c tÃ­nh trung bÃ¬nh cá»§a mini-batch\n$$ \\mu_B \\leftarrow \\frac{1}{m}\\sum^{m}_{i=1}x_i $$\nCÃ´ng thá»©c tÃ­nh phÆ°Æ¡ng sai cá»§a mini-batch\n$$ \\sigma^2_\\beta \\leftarrow \\frac{1}{m}\\sum^{m}_{i=1}(x_i-\\mu_B)^2 $$\nChuáº©n hÃ³a\n$$ \\hat{x}_i \\frac{x_i - \\mu_B}{\\sqrt{\\sigma^2_B + \\epsilon}} $$\nPhÃ­a trÃªn mÃ  mÃ´ táº£ toÃ¡n há»c phÃ©p biáº¿n Ä‘á»•i Batch Normalizing , sá»­ dá»¥ng cho hÃ m kÃ­ch hoáº¡t x trÃªn mini-batch.\nThá»±c táº¿, Ä‘Ã´i khi mÃ´ hÃ¬nh láº¡i hoáº¡t Ä‘á»™ng hiá»‡u quáº£ vá»›i má»™t giÃ¡ trá»‹ trung bÃ¬nh vÃ  phÆ°Æ¡ng sai khÃ¡c, nÃªn tÃ¡c giáº£ thÃªm 2 siÃªu tham sá»‘ lÃ  gamma - scale vÃ  beta - shift Ä‘á»ƒ cÃ³ tÃ­nh tá»•ng quÃ¡t.\n$$ y_i \\leftarrow \\gamma\\hat{x}_i + \\beta $$\nBatch Normalization hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o Vá» máº·c trá»±c quan, chÃºng ta biáº¿t ráº±ng, trong gradient descent, máº¡ng NN tÃ­nh giÃ¡ trá»‹ Ä‘áº¡o hÃ m vÃ  giáº£m trá»ng sá»‘ cá»§a nÃ³ dá»±a vÃ o hÆ°á»›ng Ä‘i cá»§a Ä‘áº¡o hÃ m. NhÆ°ng do cÃ¡c layer Ä‘Æ°á»£c xáº¿p chá»“ng lÃªn nhau, phÃ¢n phá»‘i cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o sáº½ bá»‹ thay Ä‘á»•i dáº§n do viá»‡c cáº­p nháº­t trá»ng sá»‘ cá»§a cÃ¡c layer trÆ°á»›c Ä‘Ã³, lÃ m cho phÃ¢n phá»‘i cá»§a Ä‘áº§u vÃ o cá»§a cÃ¡c layer phÃ­a sau sáº½ khÃ¡c xa so vá»›i phÃ¢n phá»‘i cá»§a data input. BN giÃºp cá»‘ Ä‘á»‹nh phÃ¢n phá»‘i cá»§a dá»¯ liá»‡u vá» phÃ¢n phá»‘i chuáº©n, qua táº¥t cáº£ cÃ¡c lá»›p, dáº«n tá»›i tÃ­nh cháº¥t phÃ¢n phá»‘i cá»§a dá»¯ liá»‡u khÃ´ng thay Ä‘á»•i qua cÃ¡c lá»›p.\nKhuyáº¿t Ä‘iá»ƒm cá»§a Batch Normalization BN thá»±c hiá»‡n láº¡i cÃ¡c phÃ©p tÃ­nh trÃ¬nh bÃ y phÃ­a trÃªn qua cÃ¡c láº§n láº·p, cho nÃªn, vá» lÃ½ thuyáº¿t, chÃºng ta cáº§n batch size Ä‘á»§ lá»›n Ä‘á»ƒ phÃ¢n phá»‘i cá»§a mini-batch xáº¥p xá»‰ phÃ¢n phá»‘i cá»§a dá»¯ liá»‡u. Äiá»u nÃ y gÃ¢y khÃ³ khÄƒn cho cÃ¡c mÃ´ hÃ¬nh Ä‘Ã²i há»i áº£nh Ä‘áº§u vÃ o cÃ³ cháº¥t lÆ°á»£ng cao (1920x1080) nhÆ° object detection, semantic segmentation, \u0026hellip; Viá»‡c huáº¥n luyá»‡n vá»›i batch size lá»›n lÃ m mÃ´ hÃ¬nh pháº£i tÃ­nh toÃ¡n nhiá»u vÃ  cháº­m.\nVá»›i Batch size = 1, giÃ¡ trá»‹ phÆ°Æ¡ng sai sáº½ lÃ  0. Do Ä‘Ã³ BN sáº½ khÃ´ng hoáº¡t Ä‘á»™ng hiá»‡u quáº£.\nBN khÃ´ng hoáº¡t Ä‘á»™ng tá»‘t vá»›i RNN. LÃ½ do lÃ  RNN cÃ³ cÃ¡c káº¿t ná»‘i láº·p láº¡i vá»›i cÃ¡c timestamps trÆ°á»›c Ä‘Ã³, vÃ  yÃªu cáº§u cÃ¡c giÃ¡ trá»‹ beta vÃ  gamma khÃ¡c nhau cho má»—i timestep, dáº«n Ä‘áº¿n Ä‘á»™ phá»©c táº¡p tÄƒng lÃªn gáº¥p nhiá»u láº§n, vÃ  gÃ¢y khÃ³ khÄƒn cho viá»‡c sá»­ dá»¥ng BN trong RNN.\nTrong quÃ¡ trÃ¬nh test, BN khÃ´ng tÃ­nh toÃ¡n láº¡i giÃ¡ trá»‹ trung bÃ¬nh vÃ  phÆ°Æ¡ng sai cá»§a táº­p test. MÃ  sá»­ dá»¥ng giÃ¡ trá»‹ trung bÃ¬nh vÃ  phÆ°Æ¡ng sai Ä‘Æ°á»£c tÃ­nh toÃ¡n tá»« táº­p train. Äiá»u nÃ y lÃ m cho viá»‡c tÃ­nh toÃ¡n tÄƒng thÃªm. á» pytorch, hÃ m model.eval() giÃºp chÃºng ta thiáº¿t láº­p mÃ´ hÃ¬nh á»Ÿ cháº¿ Ä‘á»™ evaluation. á» cháº¿ Ä‘á»™ nÃ y, BN layer sáº½ sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ trung bÃ¬nh vÃ  phÆ°Æ¡ng sai Ä‘Æ°á»£c tÃ­nh toÃ¡n tá»« trÆ°á»›c trong dá»¯ liá»‡u huáº¥n luyá»‡n. GiÃºp cho chÃºng ta khÃ´ng pháº£i tÃ­nh Ä‘i tÃ­nh láº¡i giÃ¡ trá»‹ nÃ y.\nWeight Normalization Tham kháº£o https://arxiv.org/pdf/1602.07868.pdf Do cÃ¡c báº¥t lá»£i cá»§a BN, T. Saliman vÃ  P. Kingma Ä‘á» xuáº¥t cÃ¡ch tÃ­nh khÃ¡c, vÃ  Ä‘áº·t tÃªn lÃ  Weight Normalization. Ã tÆ°á»Ÿng cá»§a tÃ¡c giáº£ lÃ  tÃ¡ch trá»ng sá»‘ thÃ nh 2 thÃ nh pháº§n lÃ  giÃ¡ trá»‹ cá»§a trá»ng sá»‘ vÃ  hÆ°á»›ng cá»§a trá»ng sá»‘. Nháº±m má»¥c Ä‘Ã­ch tÄƒng tá»‘c tá»‘c Ä‘á»™ train.\nTÃ¡c giáº£ Ä‘á» xuáº¥t sá»­ dá»¥ng hai giÃ¡ trá»‹ g( cho giÃ¡ trá»‹ trá»ng sá»‘ ) vÃ  v cho hÆ°á»›ng cá»§a trá»ng sá»‘ thay vÃ¬ sá»­ dá»¥ng 1 giÃ¡ trá»‹ w nguyÃªn thá»§y.\n$$ w = \\frac{g}{||v||}v $$\nVá»›i g lÃ  giÃ¡ trá»‹ scala, v lÃ  vector. CÃ´ng thá»©c nÃ y nhanh do chÃºng ta Ä‘Ã£ fixed Ä‘Æ°á»£c giÃ¡ trá»‹ chuáº©n cá»§a w. Do chuáº©n cá»§a w lÃºc nÃ y báº±ng g.\nKhÃ´ng giá»‘ng nhÆ° BN, WN hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c trong mÃ´ hÃ¬nh RNN. Tuy nhiÃªn, vá» thá»±c nghiá»‡m cho tháº¥y mÃ´ hÃ¬nh vá»›i WN thÆ°á»ng khÃ´ng á»•n Ä‘á»‹nh, nÃªn Ã­t khi Ä‘Æ°á»£c sá»­ dá»¥ng trong thá»±c táº¿\nLayer Normalization Tham kháº£o https://arxiv.org/pdf/1607.06450.pdf\nLáº¥y cáº£m há»©ng tá»« BN, Geoffrey Hinton vÃ  cÃ¡c Ä‘á»“ng sá»± Ä‘Ã£ Ä‘á» xuáº¥t Layer Normalization. PhÃ©p chuáº©n hÃ³a Ä‘Æ°á»£c sá»­ dá»¥ng trÃªn tá»«ng layer nhÆ° sau\n$$ \\mu^l =\\frac{1}{H}\\sum^{H}_{i=1}\\alpha^l_i $$\n$$ \\sigma^l = \\sqrt{\\frac{1}{H}\\sum^{H}_{i=1}(\\alpha^l_i-\\mu^l)^2} $$\nVá»›i H lÃ  sá»‘ lÆ°á»£ng pháº§n tá»­ trong má»™t hidden layer.\nCÃ¡i khÃ¡c nhau chÃ­nh giá»¯a BN vÃ  LN lÃ  LN sá»­ dá»¥ng chung má»™t giÃ¡ trá»‹ trung bÃ¬nh vÃ  phÆ°Æ¡ng sai trong 1 hidden layer. LN khÃ´ng phá»¥ thuá»™c vÃ o mini-batch, nÃªn cÃ³ thá»ƒ train Ä‘Æ°á»£c vá»›i batch-size = 1 mÃ  khÃ´ng gáº·p váº¥n Ä‘á» gÃ¬ cáº£.\nNgoÃ i ra LN cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng trong RNN mÃ  khÃ´ng gáº·p trá»Ÿ ngáº¡i nÃ o nhÆ° BN.\nInstance Normalization Instance Normalization cÃ²n cÃ³ tÃªn gá»i khÃ¡c lÃ  contrast normalization\nÃ tÆ°á»Ÿng á»Ÿ Ä‘Ã¢y lÃ  chÃºng ta sáº½ chuáº©n hoÃ¡ trÃªn tá»«ng channel cá»§a tá»«ng batch.\nGroup Normalization Tham kháº£o https://arxiv.org/pdf/1803.08494.pdf\nÄÆ°á»£c Ä‘á» xuáº¥t bá»Ÿi Kaiming He vÃ  cá»™ng sá»± , Group Normalization cÃ³ cÃ¡ch thá»©c hoáº¡t Ä‘á»™ng tÆ°Æ¡ng tá»± LN, chá»‰ má»™t khÃ¡c biá»‡t duy nháº¥t lÃ  thuáº­t toÃ¡n sáº½ chia cÃ¡c layer thÃ nh tá»«ng nhÃ³m vÃ  thá»±c hiá»‡n chuáº©n hÃ³a trÃªn cÃ¡c nhÃ³m Ä‘Ã³. ChÃºng ta pháº£i turning tham sá»‘ num_groups Ä‘á»ƒ tÃ¬m sá»‘ lÆ°á»£ng nhÃ³m cho káº¿t quáº£ tá»‘t nháº¥t.\nHai cÃ¡i chuáº©n hoÃ¡ cuá»‘i khÃ¡ Ä‘Æ¡n giáº£n, mÃ¬nh khÃ´ng Ä‘á» cáº­p chi tiáº¿t nhiá»u. Náº¿u cÃ³ báº¡n nÃ o quan tÃ¢m thÃ¬ vui lÃ²ng Ä‘á»ƒ láº¡i lá»i nháº¯n, mÃ¬nh sáº½ update thÃ´ng tin cÃ¡c báº¡n cáº§n.\nNguá»“n áº£nh : https://medium.com/syncedreview/facebook-ai-proposes-group-normalization-alternative-to-batch-normalization-fb0699bffae7\nJournalist: Tony Peng| Editor: Michael Sarazen\nNguá»“n tham kháº£o @inproceedings{ioffe2015batch, title={Batch normalization: Accelerating deep network training by reducing internal covariate shift}, author={Ioffe, Sergey and Szegedy, Christian}, booktitle={International conference on machine learning}, pages={448\u0026ndash;456}, year={2015}, organization={PMLR} }\nhttps://analyticsindiamag.com/understanding-normalization-methods-in-deep-learning/\nhttps://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8\nhttps://towardsdatascience.com/different-normalization-layers-in-deep-learning-1a7214ff71d6\nhttps://arxiv.org/pdf/1602.07868.pdf\nhttps://arxiv.org/pdf/1607.06450.pdf\nhttps://arxiv.org/pdf/1803.08494.pdf\nhttps://medium.com/syncedreview/facebook-ai-proposes-group-normalization-alternative-to-batch-normalization-fb0699bffae7\n","date":"Feb 25, 2022","img":"https://unsplash.it/1920/1080?image=30","permalink":"/blog/2022-02-25-normalization/","series":null,"tags":["Machine Learning","Normalization","Deep Learning"],"title":"CÃ¡c Ká»¹ Thuáº­t Chuáº©n HÃ³a Trong Deep Learning"},{"categories":"dataset","content":"1. CASIA-WebFace Dataset cÃ³ kÃ­ch thÆ°á»›c táº§m 4.1G, bao gá»“m 494,414 hÃ¬nh khuÃ´n máº·t cá»§a 10,575 ngÆ°á»i tháº­t Ä‘Æ°á»£c thu tháº­p trÃªn web vÃ  Ä‘Ã£ gÃ¡n nhÃ£n Ä‘áº§y Ä‘á»§. Dataset nÃ y phá»¥c vá»¥ cho bÃ i toÃ¡n face verification vÃ  face identification .\nhttps://archive.org/download/NudeNet_classifier_dataset_v1/NudeNet_Classifier_train_data_x320.zip\nÄá»‘i vá»›i cÃ¡c báº¡n muá»‘n mÃ¬ Äƒn liá»n, thÃ¬ cÃ³ thá»ƒ táº£i pretrain model NudeNet trÃªn pip vá» rá»“i thá»­.\n2. MS-Celeb-1M Táº­p dataset khuÃ´n máº·t gá»‘c Ä‘Æ°á»£c microsoft cÃ´ng bá»‘ nÄƒm 2016 phá»¥c vá»¥ cho bÃ i toÃ¡n nháº­n diá»‡n khuÃ´n máº·t. Táº­p nÃ y chá»©a táº§m 10 triá»‡u áº£nh cá»§a 100,000 cÃ¡ nhÃ¢n khÃ¡c nhau, Ä‘a sá»‘ lÃ  cÃ¡c diá»…n viÃªn Hollywood (nÃªn cÃ³ thÃªm tá»« Celeb - viáº¿t táº¯t cá»§a celebrity).\nNguá»“n microsoft.com\nHiá»‡n nay dataset nÃ y Ä‘Ã£ bá»‹ xÃ³a bá» khá»i website gá»‘c msceleb.org vÃ  dá»± Ã¡n nÃ y cá»§a microsoft Ä‘Ã£ bá»‹ káº¿t thÃºc vÃ¬ má»™t lÃ½ do nÃ o Ä‘Ã³.\nLink download: https://academictorrents.com/details/9e67eb7cc23c9417f39778a8e06cca5e26196a97\nCÃ¡c báº¡n cÃ¢n nháº¯c ká»¹ trÆ°á»›c khi download. Do khÃ´ng pháº£i lÃ  link chÃ­nh chá»§\nMÃ£ lá»‡nh convert tsv file sang hÃ¬nh áº£nh\n1import argparse 2import base64 3import csv 4import os 5# import magic # Detect image type from buffer contents (disabled, all are jpg) 6 7parser = argparse.ArgumentParser() 8parser.add_argument(\u0026#39;--croppedTSV\u0026#39;, type=str) 9parser.add_argument(\u0026#39;--outputDir\u0026#39;, type=str, default=\u0026#39;raw\u0026#39;) 10args = parser.parse_args() 11 12with open(args.croppedTSV, \u0026#39;r\u0026#39;) as tsvF: 13 reader = csv.reader(tsvF, delimiter=\u0026#39;\\t\u0026#39;) 14 i = 0 15 for row in reader: 16 MID, imgSearchRank, faceID, data = row[0], row[1], row[4], base64.b64decode(row[-1]) 17 18 saveDir = os.path.join(args.outputDir, MID) 19 savePath = os.path.join(saveDir, \u0026#34;{}-{}.jpg\u0026#34;.format(imgSearchRank, faceID)) 20 21 # assert(magic.from_buffer(data) == \u0026#39;JPEG image data, JFIF standard 1.01\u0026#39;) 22 23 os.makedirs(saveDir, exist_ok=True) 24 with open(savePath, \u0026#39;wb\u0026#39;) as f: 25 f.write(data) 26 27 i += 1 28 29 if i % 1000 == 0: 30 print(\u0026#34;Extracted {} images.\u0026#34;.format(i)) 31 32# Nguá»“n https://github.com/EB-Dodo/C-MS-Celeb/issues/1#issuecomment-844894295 Dá»¯ liá»‡u gá»‘c cá»§a MS-Celeb-1M cÃ³ nhiá»u hÃ¬nh áº£nh trÃ¹ng, gÃ¡n sai. CÃ³ nhiá»u task Ä‘Ã£ Ä‘Æ°á»£c implement Ä‘á»ƒ lÃ m sáº¡ch dataset trÃªn. Má»™t trong nhá»¯ng task mÃ¬nh tháº¥y khÃ¡ á»•n lÃ \nhttps://github.com/EB-Dodo/C-MS-Celeb\nTÃ¡c giáº£ Ä‘Ã£ xá»­ lÃ½, rÃºt trÃ­ch, giá»¯ láº¡i táº§m 6.5 triá»‡u hÃ¬nh cá»§a 94,682 ngÆ°á»i ná»•i tiáº¿ng\n3. VGG Face vÃ  VGG Face2 Dataset bao gá»“m 494,414 hÃ¬nh khuÃ´n máº·t cá»§a 10,575 ngÆ°á»i. CÃ¡c báº¡n cÃ³ thá»ƒ download táº¡i link chÃ­nh chá»§\nhttps://www.robots.ox.ac.uk/~vgg/data/vgg_face/vgg_face_dataset.tar.gz\ntáº­p VGG Face2 Ä‘Ã£ bá»‹ xÃ³a trÃªn trang chá»§ do vi pháº¡m báº£n quyá»n. NÃªn hiá»‡n thá»i khÃ´ng cÃ³ link chÃ­nh chá»§\n","date":"Feb 25, 2022","img":"","permalink":"/courses/ml_dataset/web_face/","series":["Machine learning dataset"],"tags":["dataset"],"title":"Dataset Nháº­n Dáº¡ng KhuÃ´ng Máº·t"},{"categories":"dataset","content":"CÃ³ Ä‘Ã´i khi, mÃ¬nh muá»‘n test má»™t model nÃ o Ä‘Ã³, nhÆ°ng mÃ  mÃ¬nh láº¡i tá»‘n ráº¥t nhiá»u thá»i gian Ä‘á»ƒ tÃ¬m kiáº¿m test data. VÃ¬ váº­y, mÃ¬nh táº¡o cÃ¡i tut nÃ y Ä‘á»ƒ lÆ°u láº¡i nhá»¯ng data mÃ¬nh lÆ°á»£m láº·t Ä‘Æ°á»£c, phá»¥c vá»¥ cho viá»‡c tÃ¬m kiáº¿m sau nÃ y dá»… dÃ ng hÆ¡n.\nDataset nÃ y cung cáº¥p táº§m 19G hÃ¬nh áº£nh nháº¡y cáº£m. Phá»¥c vá»¥ cho cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i, nháº­n dáº¡ng vÃ  kiá»ƒm duyá»‡t ná»™i dung hÃ¬nh áº£nh/ video.\nhttps://archive.org/download/NudeNet_classifier_dataset_v1/NudeNet_Classifier_train_data_x320.zip\nÄá»‘i vá»›i cÃ¡c báº¡n muá»‘n mÃ¬ Äƒn liá»n, thÃ¬ cÃ³ thá»ƒ táº£i pretrain model NudeNet trÃªn pip vá» rá»“i thá»­.\n","date":"Feb 25, 2022","img":"","permalink":"/courses/ml_dataset/nunet/","series":["Machine learning dataset"],"tags":["dataset"],"title":"NudeNet Dataset [Dataset Nháº¡y Cáº£m, 18+ Only]"},{"categories":"c++","content":"Lá»‹ch sá»­ hÃ¬nh thÃ nh, phÃ¡t triá»ƒn ngÃ´n ngá»¯ c++ C++ lÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh \u0026ldquo;báº­c trung\u0026rdquo; Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Bjarne Stroustrup vÃ o nÄƒm 1979 táº¡i phÃ²ng thÃ­ nghiá»‡m Bell Labs. C++ hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c trÃªn nhiá»u ná»n táº£ng khÃ¡c nhau nhÆ° Windows, Mac OS, vÃ  cÃ¡c phiÃªn báº£n cá»§a UNIX. Series bÃ i há»c nÃ y hÆ°á»›ng tá»›i má»™t khÃ³a há»c Ä‘Æ¡n giáº£n, vá»›i Ä‘áº§y Ä‘á»§ cÃ¡c kiáº¿n thá»©c ná»n táº£ng cá»§a C++ cho ngÆ°á»i báº¯t Ä‘áº§u há»c.\nLÃ½ do nÃªn há»c ngÃ´n ngá»¯ C++ C++ lÃ  má»™t trong nhá»¯ng ngÃ´n ngá»¯ láº­p trÃ¬nh phá»• biáº¿n trÃªn tháº¿ giá»›i.\nC++ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¡t triá»ƒn nhiá»u á»©ng dá»¥ng khÃ¡c nhau, vÃ­ dá»¥ nhÆ° láº­p trÃ¬nh game, láº­p trÃ¬nh há»‡ Ä‘iá»u hÃ nh, phÃ¡t triá»ƒn cÃ¡c á»©ng dá»¥ng nhÃºng, lÃ m website \u0026hellip;\nC++ phÃ¡t triá»ƒn pháº§n má»m cháº¡y trÃªn nhiá»u ná»n táº£ng.\nC++ cÃ³ cá»™ng Ä‘á»“ng developer máº¡nh máº½\nC++ cháº¡y nhanh\nHÃ ng tá»· lÃ½ do khÃ¡c ná»¯a, mÃ¬nh liá»‡t kÃª khÃ´ng ná»•i.\nC ++ lÃ  má»™t ngÃ´n ngá»¯ láº­p trÃ¬nh tuyá»‡t vá»i vÃ  nÃ³ giáº£i quyáº¿t Ä‘Æ°á»£c nhiá»u nhu cáº§u cá»¥ thá»ƒ. NgÃ´n ngá»¯ láº­p trÃ¬nh nÃ y Ä‘Ã£ tá»“n táº¡i Ä‘Æ°á»£c gáº§n 40 nÄƒm, nÃªn háº§u háº¿t cÃ¡c váº¥n Ä‘á» trong viá»‡c phÃ¡t triá»ƒn pháº§n má»m cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£i quyáº¿t báº±ng cÃ¡c thÆ° viá»‡n open-source vÃ  cÃ¡c frameworks. Hiá»‡n nay, Ä‘iá»ƒm ná»•i báº­t cá»§a C ++ lÃ  nÃ³ Ä‘Æ°á»£c táº¡o ra Ä‘á»ƒ cÃ³ tá»‘c Ä‘á»™ cá»±c nhanh, nhÆ°ng nÃ³ cÅ©ng phá»¥ thuá»™c vÃ o tá»‘c Ä‘á»™ cháº¡y cá»§a bá»™ xá»­ lÃ½. Má»™t trong nhá»¯ng Ä‘iá»ƒm ná»•i báº­t khÃ¡c lÃ  C ++ lÃ  má»™t ngÃ´n ngá»¯ biÃªn dá»‹ch, cho phÃ©p nÃ³ Ä‘Æ°á»£c thá»±c thi má»™t cÃ¡ch hiá»‡u quáº£. Äiá»u nÃ y lÃ  do ngÃ´n ngá»¯ biÃªn dá»‹ch Ä‘Æ°á»£c thá»±c thi trá»±c tiáº¿p, hoÃ n toÃ n ngÆ°á»£c láº¡i vá»›i má»™t ngÃ´n ngá»¯ thÃ´ng dá»‹ch. C ++ dá»‹ch tá»« má»™t nguá»“n sang mÃ£ mÃ¡y, trong khi má»™t ngÃ´n ngá»¯ thÃ´ng dá»‹ch nhÆ° JavaScript hoáº·c Python Ä‘Æ°á»£c dá»‹ch khi trÃ¬nh thÃ´ng dá»‹ch xá»­ lÃ½ mÃ£ nguá»“n.\nC ++ cung cáº¥p cÃ¡c cÆ¡ cháº¿ trá»«u tÆ°á»£ng, cho phÃ©p cÃ¡c thuáº­t toÃ¡n cÃ´ng nghiá»‡p phá»©c táº¡p Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i trong cÃ¡c thÆ° viá»‡n bá»• sung, tá»‘n Ã­t chi phÃ­ hÆ¡n so vá»›i viá»‡c phÃ¡t triá»ƒn tá»« Ä‘áº§u. CÃ³ hÃ ng ngÃ n thÆ° viá»‡n nhÆ° nÃ y Ä‘Ã£ Ä‘Æ°á»£c xuáº¥t báº£n trong nhiá»u nÄƒm vÃ  cÃ¡c á»©ng dá»¥ng thÆ°á»ng cÃ³ thá»ƒ nhanh chÃ³ng triá»ƒn khai cÃ¡c thuáº­t toÃ¡n Ä‘iá»u chá»‰nh nÃ y Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c cÃ¡c hiá»‡u quáº£ mong muá»‘n vá»›i hiá»‡u suáº¥t mÃ¡y gáº§n nhÆ° tá»‘i Æ°u. ÄÃ¢y lÃ  má»™t yáº¿u tá»‘ phÃ¡t huy tÃ¡c dá»¥ng lÃ m cho viá»‡c phÃ¡t triá»ƒn pháº§n má»m trÃªn C ++ trá»Ÿ nÃªn nhanh chÃ³ng.\nTá»‘c Ä‘á»™ cá»§a C ++ cÅ©ng khiáº¿n nÃ³ trá»Ÿ thÃ nh sá»± lá»±a chá»n tuyá»‡t vá»i cho cÃ¡c há»‡ thá»‘ng nhÃºng nhÆ° NASA, robot vÃ  tháº­m chÃ­ lÃ  cÃ¡c trÃ² chÆ¡i quy mÃ´ lá»›n Ä‘Æ°á»£c xáº¿p háº¡ng hÃ ng Ä‘áº§u nhÆ° báº¡n cÃ³, cháº³ng háº¡n nhÆ° Assassin\u0026rsquo;s Creed, Battlefield, Call of Duty vÃ  Doom. VÃ  náº¿u báº¡n nghÄ© vá» Ä‘iá»u Ä‘Ã³, cÃ¡c trÃ² chÆ¡i nÃ y cáº§n pháº£i váº¯t kiá»‡t tá»«ng pháº§n hiá»‡u suáº¥t vÃ  thá»±c hiá»‡n cÃ¡c phÃ©p tÃ­nh nhanh vÃ  tÃ­nh toÃ¡n láº¡i nhanh chÃ³ng, Ä‘iá»u mÃ  C ++ Ä‘Ã£ lÃ m cho Ä‘iá»u Ä‘Ã³ xáº£y ra.\nLÃ½ do khÃ´ng nÃªn há»c C++ Máº·t khÃ¡c, C ++ lÃ  má»™t ngÃ´n ngá»¯ ráº¥t nghiÃªm ngáº·t, ráº¥t máº¡nh vÃ  ráº¥t phá»©c táº¡p. VÃ  Ä‘iá»u nÃ y lÃ m cho C ++ trá»Ÿ nÃªn cá»±c ká»³ khÃ³ há»c, ngay cáº£ Ä‘á»‘i vá»›i cÃ¡c nhÃ  phÃ¡t triá»ƒn dÃ y dáº¡n kinh nghiá»‡m. Náº¿u báº¡n thá»±c hiá»‡n tÃ¬m kiáº¿m trÃªn Google cho â€œngÃ´n ngá»¯ láº­p trÃ¬nh khÃ³ nháº¥tâ€, báº¡n sáº½ nhanh chÃ³ng tháº¥y ráº±ng C ++ Ä‘Æ°á»£c liá»‡t kÃª lÃ  á»©ng cá»­ viÃªn hÃ ng Ä‘áº§u.\nTrÃªn háº¿t, C ++ khÃ´ng pháº£i lÃ  lá»±a chá»n phÃ¹ há»£p cho nhiá»u dá»± Ã¡n vÃ  á»©ng dá»¥ng. Náº¿u báº¡n Ä‘ang xem xÃ©t C ++ Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c API web, á»©ng dá»¥ng mÃ¡y tÃ­nh Ä‘á»ƒ bÃ n, á»©ng dá»¥ng iPhone, v.v., thÃ¬ C ++ khÃ´ng nÃªn lÃ  lá»±a chá»n cá»§a báº¡n trá»« khi báº¡n cÃ³ káº¿ hoáº¡ch cho cÃ¡c á»©ng dá»¥ng cá»§a mÃ¬nh nháº­n Ä‘Æ°á»£c hÃ ng trÄƒm nghÃ¬n lÆ°á»£t truy cáº­p má»—i giÃ¢y. Háº§u háº¿t cÃ¡c á»©ng dá»¥ng khÃ´ng cáº§n nhá»¯ng má»©c tÄƒng hiá»‡u suáº¥t nÃ y. Máº·c dÃ¹, trong pháº§n trÃªn, tÃ´i cÅ©ng Ä‘Ã£ nÃ³i vá» viá»‡c C ++ lÃ  má»™t lá»±a chá»n tuyá»‡t vá»i cho cÃ¡c há»‡ thá»‘ng nhÃºng, má»™t khÃ­a cáº¡nh khÃ¡c Ä‘á»ƒ phÃ¡t triá»ƒn nhÃºng lÃ  tÄƒng hiá»‡u suáº¥t bá»™ xá»­ lÃ½, dung lÆ°á»£ng bá»™ nhá»› kháº£ dá»¥ng vÃ  tiÃªu chuáº©n hÃ³a trÃªn ná»n táº£ng 32 vÃ  64-bit. VÃ  Ä‘iá»u nÃ y cho phÃ©p cÃ¡c ngÃ´n ngá»¯ nhÆ° Java, Lua vÃ  Python Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c há»‡ thá»‘ng nhÃºng sÃ¢u vÃ  Ä‘Ã¢y lÃ  nhá»¯ng ngÃ´n ngá»¯ dá»… sá»­ dá»¥ng hÆ¡n.\nNgay cáº£ cÃ¡c há»‡ thá»‘ng trÃ² chÆ¡i Ä‘iá»‡n tá»­ cÅ©ng phÃ¡t triá»ƒn nhanh Ä‘áº¿n má»©c nhá»¯ng trÃ² chÆ¡i quy mÃ´ lá»›n nÃ y hiá»‡n Ä‘ang sá»­ dá»¥ng Unity hoáº·c C #. VÃ¬ váº­y, má»i ngÆ°á»i Ä‘ang chá»n nhá»¯ng ngÃ´n ngá»¯ nÃ y vÃ¬ chÃºng cung cáº¥p kháº£ nÄƒng tÆ°Æ¡ng thÃ­ch Ä‘a ná»n táº£ng giá»‘ng nhÆ° C ++, nhÆ°ng chÃºng dá»… lÃ m viá»‡c hÆ¡n nhiá»u. Báº¡n cÃ³ thá»ƒ vÃ o cÃ¡c trang tÃ¬m viá»‡c á»Ÿ Viá»‡t Nam nhÆ° ItViec, hoáº·c cÃ¡c trang freelacer nhÆ° Upwork Ä‘á»ƒ tÃ¬m hiá»ƒu sá»‘ lÆ°á»£ng viá»‡c lÃ m C++ so vá»›i python , javascrip , C# Ä‘á»ƒ kiá»ƒm chá»©ng. Táº¡i thá»i Ä‘iá»ƒm viáº¿t bÃ i viáº¿t nÃ y, mÃ¬nh search trÃªn trang itviec vÃ  vá»›i tá»« khÃ³a .NET, mÃ¬nh tÃ¬m tháº¥y 238 jobs , c++ lÃ  78 jobs, python lÃ  264 jobs, javascrip lÃ  484 jobs. CÃ¡c báº¡n cÃ³ thá»ƒ tá»± Ä‘Æ°a ra káº¿t luáº­n cho riÃªng mÃ¬nh dá»±a vÃ o cÃ¡c con sá»‘ trÃªn.\nKáº¿t luáº­n MÃ¬nh hi vá»ng cÃ³ thá»ƒ cung cáº¥p Ä‘á»§ thÃ´ng tin Ä‘á»ƒ giÃºp báº¡n quyáº¿t Ä‘á»‹nh xem viá»‡c há»c C ++ cÃ³ xá»©ng Ä‘Ã¡ng vá»›i báº¡n hay khÃ´ng. C ++ lÃ  má»™t trong nhá»¯ng ngÃ´n ngá»¯ láº­p trÃ¬nh hÃ ng Ä‘áº§u, vÃ¬ váº­y hÃ£y yÃªn tÃ¢m ráº±ng ngÃ´n ngá»¯ láº­p trÃ¬nh nÃ y sáº½ khÃ´ng biáº¿n máº¥t khá»i ngÃ nh cÃ´ng nghá»‡. NhÆ°ng báº¡n chá»‰ nÃªn há»c C ++ náº¿u nÃ³ Ä‘Æ°á»£c yÃªu cáº§u trong vai trÃ² cÃ´ng viá»‡c cá»§a báº¡n hoáº·c trong lÄ©nh vá»±c mÃ  nÃ³ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i. NgÆ°á»£c láº¡i, báº¡n hÃ£y quay xe Ä‘Ãºng lÃºc. MÃ¬nh sáº½ biÃªn soáº¡n thÃªm nhiá»u bá»™ giÃ¡o trÃ¬nh há»c cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c ná»¯a. See Ya\n","date":"Feb 20, 2022","img":"","permalink":"/courses/cplusplus/1_introduction/","series":["KhÃ³a há»c c++ cÄƒn báº£n"],"tags":["c++"],"title":"BÃ i 1: Giá»›i Thiá»‡u Vá» C++"},{"categories":"c++","content":"Lá»i giá»›i thiá»‡u ChÃºng ta cáº§n má»™t pháº§n má»m cÃ³ cháº¥t lÆ°á»£ng tá»‘t tá»‘t má»™t chÃºt Ä‘á»ƒ há»— trá»£ coding nhanh, gá»n, láº¹. CÃ¡c báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c pháº§n má»m miá»…n phÃ­ nhÆ° Eclipse, NetBean, CodeBlock, Notepad++ \u0026hellip;.\nTrong bÃ i viáº¿t nÃ y, mÃ¬nh Ä‘á» nghá»‹ cÃ¡c báº¡n cÃ i visual studio hoáº·c visual studio code. Visual stuido lÃ  má»™t pháº§n khÃ¡ bÃ¡ Ä‘áº¡o, há»— trá»£ máº¡nh máº½, giÃºp cÃ¡c báº¡n láº­p trÃ¬nh viÃªn coding má»™t cÃ¡ch thoáº£i mÃ¡i mÃ  khÃ´ng pháº£i vÆ°á»›ng báº­n cÃ¡c váº¥n Ä‘á» cáº¥u hÃ¬nh bÃªn ngoÃ i. Náº¿u cÃ³ Ä‘iá»u kiá»‡n, cÃ¡c báº¡n nÃªn sá»­ dá»¥ng phiÃªn báº£n visual studio enterpise, Ä‘Æ°á»£c má»Ÿ khÃ³a táº¥t cáº£ cÃ¡c tÃ­nh nÄƒng giÃºp chÃºng ta chá»‰ cáº§n táº­p trung vÃ o coding.\nCÃ i Ä‘áº·t trÃªn Windows Táº¡i thá»i Ä‘iá»ƒm mÃ¬nh viáº¿t bÃ i viáº¿t nÃ y, Visual Studio 2022 lÃ  phiÃªn báº£n má»›i nháº¥t. CÃ¡c báº¡n cÃ³ thá»ƒ cÃ i phiÃªn báº£n Visual Studio 2019 váº«n Ä‘Æ°á»£c. HÃ£y download bá»™ cÃ i visual studio táº¡i link https://visualstudio.microsoft.com/downloads/ vÃ  cÃ i Ä‘áº·t bÃ¬nh thÆ°á»ng.\nTrÃªn MacOS CÃ i Visual studio code báº£n má»›i nháº¥t tá»« trang chá»§ microsoft\nCÃ i extentsion c/c++\nCÃ i Clang\nCÃ¢u lá»‡nh Ä‘á»ƒ kiá»ƒm tra clang Ä‘Ã£ Ä‘Æ°á»£c cÃ i hay chÆ°a\n1clang --version Náº¿u chÆ°a , má»Ÿ terminal lÃªn vÃ  paste Ä‘oáº¡n lá»‡nh nÃ y vÃ o Ä‘á»ƒ cÃ i\n1xcode-select --install Online Compilers Thá»­ tÆ°á»Ÿng tÆ°á»£ng báº¡n Ä‘ang ngá»“i trÃªn xe buÃ½t, trÃªn tay cÃ³ 1 chiáº¿c Ä‘iá»‡n thoáº¡i trang bá»‹ 4G Ä‘áº§y Ä‘á»§, báº¡n cÃ³ 1 Ã½ tÆ°á»Ÿng lÃ³e lÃªn vá» má»™t hÃ m nÃ o Ä‘áº¥y. Báº¡n pháº£i lÃ m sao ???\nCÃ¡c Ä‘Æ¡n giáº£n nháº¥t lÃ  truy cáº­p vÃ o má»™t website compiler c++ online, dev ngay cÃ¡i Ã½ tÆ°á»Ÿng cá»§a báº¡n vÃ  cháº¡y thá»­ xem nhÆ° tháº¿ nÃ o. Hiá»‡n nay, cÃ³ ráº¥t nhiá»u trang web há»— trá»£ chÃºng ta biÃªn dá»‹ch mÃ£ nguá»“n c++ online vÃ  xem káº¿t quáº£ tá»©c thÃ¬. Trong bÃ i viáº¿t nÃ y, mÃ¬nh giá»›i thiá»‡u cÃ¡c báº¡n trang http://cpp.sh/. LÃ½ do lÃ  trang nÃ y khÃ´ng cÃ³ chá»©a quáº£ng cÃ¡o, nhá»¯ng trang khÃ¡c Ã­t nhiá»u cÃ³ chÃ¨n quáº£ng cÃ¡o, mÃ¬nh khÃ´ng thÃ­ch.\ntrang web cpp.sh\nTrang nÃ y há»— trá»£ 3 trÃ¬nh biÃªn dá»‹ch lÃ  c++98, c++11 vÃ  c++ 14. NgoÃ i ra, trang web cÃ²n há»— trá»£ chÃºng ta sinh ra shot link Ä‘á»ƒ gá»­i mÃ£ nguá»“n Ã½ tÆ°á»Ÿng cá»§a chÃºng ta cho báº¡n bÃ¨, khÃ¡ tiá»‡n lá»£i.\n","date":"Feb 20, 2022","img":"","permalink":"/courses/cplusplus/2_ide/","series":["KhÃ³a há»c c++ cÄƒn báº£n"],"tags":["c++"],"title":"BÃ i 2: CÃ i Äáº·t CÃ´ng Cá»¥ Há»— Trá»£"},{"categories":"c++","content":"ChÆ°Æ¡ng trÃ¬nh Ä‘áº§u tiÃªn, Hello World MÃ£ nguá»“n\n1#include \u0026lt;iostream\u0026gt; 2using namespace std; 3 4// main() is where program execution begins. 5int main() { 6 cout \u0026lt;\u0026lt; \u0026#34;Hello World. My name AlexBlack.\u0026#34;; // prints Hello World. My name AlexBlack. 7 return 0; 8} CÃ¡c báº¡n hÃ£y thá»±c hiá»‡n cÃ¡c bÆ°á»›c mÃ¬nh mÃ´ táº£ ká»¹ á»Ÿ bÃªn dÆ°á»›i\nMá»Ÿ text editor báº¥t ká»³, vÃ­ dá»¥ visual studio code.\nTáº¡o 1 file text, Ä‘áº·t tÃªn lÃ  main.cpp\nCopy Ä‘oáº¡n mÃ£ lá»‡nh bÃªn dÆ°á»›i, quÄƒng vÃ o file main.cpp vá»«a táº¡o\nMá»Ÿ terminal (cmd trÃªn windown), cd vÃ o thÆ° má»¥c chÆ°a file main.cpp báº¡n vá»«a táº¡o.\nGÃµ \u0026lsquo;g++ hello.cpp\u0026rsquo; vÃ  áº¥n nÃºt enter. Náº¿u khÃ´ng cÃ³ báº¥t ká»³ lá»—i nÃ o xáº£y ra, sau khi thá»±c thi xong Ä‘oáº¡n lá»‡nh trÃªn, chÆ°Æ¡ng trÃ¬nh sáº½ sinh ra 1 file cÃ³ tÃªn lÃ  a.out\ngÃµ \u0026lsquo;a.out\u0026rsquo; Ä‘á»ƒ cháº¡y chÆ°Æ¡ng trÃ¬nh\nBáº¡n sáº½ nhÃ¬n tháº¥y dÃ²ng chá»¯ \u0026ldquo;Hello World. My name AlexBlack.\u0026rdquo; trÃªn mÃ n hÃ¬nh terminal cá»§a báº¡n\n1g++ main.cpp 2./a.out 3Hello World. My name AlexBlack. Giáº£i thÃ­ch:\nMá»™t chÆ°Æ¡ng trÃ¬nh c++ lÃ  má»™t tá»• há»£p bao gá»“m nhiá»u cÃ¢u lá»‡nh, má»—i cÃ¢u lá»‡nh cÃ³ nhiá»‡m vá»¥ vÃ  chá»©c nÄƒng khÃ¡c nhau, vá»›i Ä‘oáº¡n code helloworld phÃ­a trÃªn, chÆ°Æ¡ng trÃ¬nh cÃ³ chá»©a cÃ¡c thÃ nh pháº§n.\nDÃ²ng Ä‘áº§u tiÃªn, khai bÃ¡o header thÆ° viá»‡n mÃ  chÃºng ta sá»­ dá»¥ng. á» Ä‘Ã¢y, chÃºng ta sá»­ dá»¥ng thÆ° viá»‡n iostream. ÄÃ¢y lÃ  thÆ° viá»‡n cÆ¡ báº£n, náº±m trong bá»™ thÆ° viá»‡n chuáº©n cá»§a c++.\nDÃ²ng tiáº¿p theo using namespace std; bÃ¡o cho trÃ¬nh biÃªn dá»‹ch biáº¿t sá»­ dá»¥ng namespace std. KhÃ¡i niá»‡m namespace mÃ¬nh sáº½ Ä‘á» cáº­p á»Ÿ cÃ¡c chÆ°Æ¡ng tiáº¿p theo, Ä‘áº¿n chÆ°Æ¡ng Ä‘Ã³, cÃ¡c báº¡n sáº½ hiá»ƒu lÃ½ do dÃ¹ng nÃ³, cÃ³ nÃªn xÃ³a nÃ³ Ä‘i hay khÃ´ng. á» bÆ°á»›c cÆ¡ báº£n nÃ y, cÃ¡c báº¡n chá»‰ viá»‡c copy Ä‘oáº¡n lá»‡nh nÃ y rá»“i quÄƒng vÃ o xÃ i, Ä‘á»«ng tháº¯c máº¯c, phÃ¢n tÃ¢m.\nDÃ²ng tiáº¿p theo // main() is where program execution begins. ÄÃ¢y lÃ  Ä‘oáº¡n comment 1 dÃ²ng trong c++. TrÃ¬nh biÃªn dá»‹ch gáº·p // thÃ¬ sáº½ bá» qua, khÃ´ng biÃªn dá»‹ch ná»™i dung á»Ÿ sau Ä‘oáº¡n //. Comment 1 dÃ²ng Ä‘Æ°á»£c báº¯t Ä‘áº§u bá»Ÿi dáº¥u //, vÃ  káº¿t thÃºc bá»Ÿi kÃ½ tá»± xuá»‘ng dÃ²ng.\nDÃ²ng *int main() * lÃ  tÃªn hÃ m chÃ­nh. Báº¥t ká»³ má»™t chÆ°Æ¡ng trÃ¬nh c++ nÃ o, Ä‘á»u cÃ³ hÃ m báº¯t Ä‘áº§u lÃ  main. TrÃ¬nh biÃªn dá»‹ch sáº½ tÃ¬m hÃ m main Ä‘á»ƒ báº¯t Ä‘áº§u cháº¡y thá»±c thi.\nDÃ²ng cout \u0026laquo; \u0026ldquo;Hello World. My name AlexBlack.\u0026rdquo;; // prints Hello World. My name AlexBlack. in ra dÃ²ng chá»¯ Hello World. My name AlexBlack. lÃªn mÃ n hÃ¬nh\nDÃ²ng *return 0; * káº¿t thÃºc chÆ°Æ¡ng trÃ¬nh, tráº£ vá» giÃ¡ trá»‹ 0 cho chÆ°Æ¡ng trÃ¬nh cha gá»i chÆ°Æ¡ng trÃ¬nh cá»§a mÃ¬nh Ä‘ang viáº¿t.\ná» tiáº¿ng viá»‡t, chÃºng ta káº¿t thÃºc cÃ¢u bá»Ÿi dáº¥u \u0026lsquo;cháº¥m(.)\u0026rsquo;. NgÃ´n ngá»¯ C/C++ káº¿t thÃºc cÃ¢u bá»Ÿi dáº¥u cháº¥m pháº©y \u0026lsquo;;\u0026rsquo;. á» vÃ­ dá»¥ trÃªn, cÃ¢u \u0026lsquo;cout \u0026laquo; \u0026ldquo;Hello World. My name AlexBlack.\u0026rdquo;;\u0026rsquo; Ä‘Æ°á»£c káº¿t thÃºc bá»Ÿi dáº¥u cháº¥m pháº©y. Náº¿u thiáº¿u dáº¥u cháº¥m pháº©y, trÃ¬nh biÃªn dá»‹ch sáº½ bÃ¡o lá»—i cÃº phÃ¡p (cÃ³ Ä‘á» cáº­p á»Ÿ má»¥c lá»—i, bÃªn dÆ°á»›i)\nComment trong c++ C++ há»— trá»£ hai loáº¡i comment. Comment má»™t dÃ²ng vÃ  comment nhiá»u dÃ²ng\nComment má»™t dÃ²ng, báº¯t Ä‘áº§u báº±ng dáº¥u // káº¿t thÃºc báº±ng kÃ½ tá»± xuá»‘ng dÃ²ng. VÃ­ dá»¥ nhÆ° Ä‘oáº¡n mÃ£ lá»‡nh hello world á»Ÿ trÃªn, cÃ³ 2 cÃ¡i comment 1 dÃ²ng.\nVÃ­ dá»¥:\n1trá»i náº¯ng, Ä‘Æ°á»ng váº¯ng Comment nhiá»u dÃ²ng, báº¯t Ä‘áº§u báº±ng dáº¥u /*, káº¿t thÃºc báº±ng Ä‘áº¥u */. Khi báº¡n muá»‘n viáº¿t 1 Ä‘oáº¡n chÃº thÃ­ch dÃ i, nÃªu ná»•i báº­t váº¥n Ä‘á» Ä‘ang gáº·p pháº£i, hoáº·c cÃ¡ch xá»­ lÃ½ hay cá»§a báº¡n, hoáº·c báº¥t ká»³ váº¥n Ä‘á» gÃ¬ mÃ  báº¡n muá»‘n note láº¡i Ä‘á»ƒ sau nÃ y Ä‘á»c rÃµ hÆ¡n.\n1/* hÃ´m nay trá»i náº¯ng chang chang 2mÃ¨o con Ä‘i há»c cháº³ng mang thá»© gÃ¬ */ Má»™t cÃ¢u há»i thÆ°á»ng Ä‘Æ°á»£c Ä‘áº·t ra lÃ  cÃ³ nÃªn comment hay khÃ´ng. Theo Ã½ kiáº¿n riÃªng cá»§a mÃ¬nh lÃ  nÃªn. Comment cÃ ng nhiá»u cÃ ng tá»‘t, cÃ ng chi tiáº¿t cÃ ng tá»‘t. Táº¥t nhiÃªn lÃ  chÃºng ta pháº£i comment trá»ng tÃ¢m cá»§a váº¥n Ä‘á», trÃ¡nh comment lang mang.\nThá»­ Ä‘áº·t trÆ°á»ng há»£p, báº¡n viáº¿t 1 hÃ m tÃ¬m Ä‘iá»ƒm rÆ¡i cá»§a viÃªn bi sáº¯t cÃ³ khá»‘i lÆ°á»£ng x khi nÃ©m báº±ng tay pháº£i vá»›i gÃ³c nÃ©m y vÃ  lá»±c nÃ©m z. 1 tuáº§n sau báº¡n Ä‘á»c láº¡i Ä‘oáº¡n mÃ£ nguá»“n Ä‘Ã³, báº¡n tá»± tin ráº±ng mÃ¬nh sáº½ hiá»ƒu bao nhiÃªu pháº§n?\nErrors and Warnings Lá»—i lÃ  má»™t hoáº¡t Ä‘á»™ng báº¥t há»£p phÃ¡p Ä‘Æ°á»£c thá»±c hiá»‡n bá»Ÿi ngÆ°á»i dÃ¹ng dáº«n Ä‘áº¿n hoáº¡t Ä‘á»™ng báº¥t thÆ°á»ng cá»§a chÆ°Æ¡ng trÃ¬nh.\nCÃ¡c lá»—i láº­p trÃ¬nh thÆ°á»ng khÃ´ng bá»‹ phÃ¡t hiá»‡n cho Ä‘áº¿n khi chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c biÃªn dá»‹ch hoáº·c thá»±c thi. Má»™t sá»‘ lá»—i ngÄƒn cáº£n chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c biÃªn dá»‹ch hoáº·c thá»±c thi. VÃ¬ váº­y, cÃ¡c lá»—i cáº§n Ä‘Æ°á»£c loáº¡i bá» trÆ°á»›c khi biÃªn dá»‹ch vÃ  thá»±c thi.\nCÃ¡c lá»—i phá»• biáº¿n nháº¥t cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n loáº¡i nhÆ° sau.\nLá»—i trong C++ Syntax errors Run-time Errors Linker Errors Logical Errors 1. Syntax errors (lá»—i cÃº phÃ¡p) LÃ  lá»—i khi mÃ¬nh vi pháº¡m cÃ¡c luáº­t cá»§a viá»‡c viáº¿t code c++. CÃ¡c lá»—i dáº¡ng nÃ y thÆ°á»ng Ä‘Æ°á»£c phÃ¡t hiá»‡n bá»Ÿi trÃ¬nh biÃªn dá»‹ch, nÃªn nÃ³ cÃ²n cÃ³ tÃªn gá»i khÃ¡c lÃ  compile-time errors. Khi gáº·p lá»—i nÃ y, chÃºng ta sáº½ khÃ´ng biÃªn dá»‹ch thÃ nh cÃ´ng mÃ£ nguá»“n cá»§a chÆ°Æ¡ng trÃ¬nh.\nMá»™t sá»‘ lá»—i cÃº phÃ¡p phá»• biáº¿n:\nViáº¿t thiáº¿u dáº¥u ;\nViáº¿t thiáº¿u dáº¥u Ä‘Ã³ng ngoáº·c/má»Ÿ ngoáº·c.\nSá»­ dá»¥ng biáº¿n chÆ°a Ä‘Æ°á»£c khai bÃ¡o.\n1 // C++ program to illustrate syntax error 2 3#include \u0026lt;iostream\u0026gt; 4 5int main() 6{ 7 int x = 10; 8 int y = 15; 9 10 std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x\u0026lt;\u0026lt; z \u0026lt;\u0026lt;std::endl // semicolon missed 11 12 return 0; 13} 14 15//MÃ£ nguá»“n nÃ y Ä‘Æ°á»£c viáº¿t vÃ  chia sáº» bá»Ÿi Pháº¡m Duy TÃ¹ng. Khi cháº¡y dÃ²ng code lÃªn, ta sáº½ gáº·p thÃ´ng bÃ¡o lá»—i:\n1main.cpp:11:41: error: expected \u0026#39;;\u0026#39; after expression 2 std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x\u0026lt;\u0026lt; z \u0026lt;\u0026lt;std::endl // semicolon missed 3 ^ 4 ; 5main.cpp:11:28: error: use of undeclared identifier \u0026#39;z\u0026#39; 6 std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x\u0026lt;\u0026lt; z \u0026lt;\u0026lt;std::endl // semicolon missed 7 ^ 82 errors generated. Äoáº¡n bÃ¡o lá»—i trÃªn nháº¯c lÃ  chÃºng ta thiáº¿u Ä‘áº¥u ; sau biá»ƒu thÆ°á»›c á»Ÿ dÃ²ng 11 cá»™t 41. VÃ  sá»­ dá»¥ng biáº¿n z chÆ°a Ä‘Æ°á»£c khai bÃ¡o.\n2. Run-time Errors Lá»—i xáº£y ra trong quÃ¡ trÃ¬nh cháº¡y chÆ°Æ¡ng trÃ¬nh, khi chÆ°Æ¡ng trÃ¬nh Ä‘Ã£ build thÃ nh cÃ´ng. Má»™t lá»—i phá»• biáº¿n trong nhÃ³m lá»—i nÃ y lÃ  lá»—i chia cho 0.\n1// C++ program to illustrate Run-time error 2 3#include \u0026lt;iostream\u0026gt; 4 5int main() 6{ 7 int x = 10; 8 int x = 0; 9 std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x/ z \u0026lt;\u0026lt;std::endl; // run-time error 10 11 return 0; 12} 13 14//MÃ£ nguá»“n nÃ y Ä‘Æ°á»£c viáº¿t vÃ  chia sáº» bá»Ÿi Pháº¡m Duy TÃ¹ng. 3. Linker Errors Lá»—i nÃ y xáº£y ra khi ta viáº¿t chÆ°Æ¡ng trÃ¬nh cÃ³ sá»­ dá»¥ng thÃªm thÆ° viá»‡n ngoÃ i, hoáº·c thÆ° viá»‡n do chÃ­nh chÃºng ta viáº¿t. Trong quÃ¡ trÃ¬nh biÃªn dá»‹ch, trÃ¬nh biÃªn dá»‹ch Ä‘Ã£ biÃªn dá»‹ch thÃ nh cÃ´ng cÃ¡c file, nhÆ°ng khÃ´ng thá»ƒ liÃªn káº¿t cÃ¡c file láº¡i vá»›i nhau.\n1// C++ program to illustrate Linker error 2#include \u0026lt;iostream\u0026gt; 3int Main() 4{ 5 return 0; 6} 7 8//MÃ£ nguá»“n nÃ y Ä‘Æ°á»£c viáº¿t vÃ  chia sáº» bá»Ÿi Pháº¡m Duy TÃ¹ng. Trong C/C++ quy Ä‘á»‹nh hÃ m main pháº£i lÃ  chá»¯ main (viáº¿t thÆ°á»ng), á»Ÿ Ä‘Ã¢y chÆ°Æ¡ng trÃ¬nh khÃ´ng tÃ¬m Ä‘Æ°á»£c hÃ m main Ä‘á»ƒ báº¯t Ä‘áº§u thá»±c thi, nÃªn bÃ¡o lá»—i nhÆ° bÃªn dÆ°á»›i.\n1Undefined symbols for architecture arm64: 2 \u0026#34;_main\u0026#34;, referenced from: 3 implicit entry/start for main executable 4ld: symbol(s) not found for architecture arm64 5clang: error: linker command failed with exit code 1 (use -v to see invocation) 4. Logical Errors Lá»—i nÃ y xáº£y ra khi chÃºng ta nhá»¡ tay gÃµ má»™t cÃ¡i gÃ¬ Ä‘Ã³ sai trÃ¡i lÃ m cho Ä‘oáº¡n chÆ°Æ¡ng trÃ¬nh khÃ´ng lÃ m Ä‘Ãºng theo logic Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t káº¿ tá»« trÆ°á»›c.\n1// C++ program to illustrate Logical error 2#include\u0026lt;iostream\u0026gt; 3using namespace std; 4 5int main(){ 6 // logical error : a semicolon after loop 7 int i=1; 8 while (true); 9 { 10 i++; 11 if(i\u0026gt;10)return i; 12 } 13 14 return 0; 15} 16//MÃ£ nguá»“n nÃ y Ä‘Æ°á»£c viáº¿t vÃ  chia sáº» bá»Ÿi Pháº¡m Duy TÃ¹ng. VÃ­ dá»¥ trÃªn, mÃ¬nh Ä‘Ã£ nhá»¡ tay gÃµ thÃªm kÃ½ tá»± ; sau vÃ²ng láº·p while, lÃ m chÆ°Æ¡ng trÃ¬nh láº·p vÃ´ táº­n vÃ  khÃ´ng cÃ³ lá»‘i thoÃ¡t.\n1main.cpp:7:17: warning: while loop has empty body [-Wempty-body] 2 while (true); 3 ^ 4main.cpp:7:17: note: put the semicolon on a separate line to silence this warning 51 warning generated. Trong trÆ°á»ng há»£p mÃ¬nh máº¯c cÃ¡c lá»—i phá»• biáº¿n, trÃ¬nh biÃªn dá»‹ch cÃ³ thá»ƒ Ä‘Æ°a ra cáº£nh bÃ¡o vÃ  Ä‘Æ°a ra nháº¯c nhá»Ÿ cho chÃºng ta.\nCÃ¢u lá»‡nh vÃ  hÃ m CÃ¢u lá»‡nh CÃ¢u lá»‡nh lÃ  má»™t pháº§n chÆ°Æ¡ng trÃ¬nh c/c++, Ä‘Æ°á»£c thá»±c thi má»™t cÃ¡ch tuáº§n tá»±.\nVÃ­ dá»¥\n1// C++ program to illustrate statement 2#include\u0026lt;iostream\u0026gt; 3using namespace std; 4 5int main(){ 6 // logical error : a semicolon after loop 7 int i=1; // cÃ¢u lá»‡nh khai bÃ¡o declaration statement 8 while (true) //CÃ¢u lá»‡nh Ä‘iá»u kiá»‡n 9 { 10 i++; //CÃ¢u lá»‡nh biá»ƒu thá»©c 11 if(i\u0026gt;10) //CÃ¢u lá»‡nh Ä‘iá»u kiá»‡n 12 return i; //CÃ¢u lá»‡nh return 13 } 14 15 return 0; //CÃ¢u lá»‡nh return. 16} 17//MÃ£ nguá»“n nÃ y Ä‘Æ°á»£c viáº¿t vÃ  chia sáº» bá»Ÿi Pháº¡m Duy TÃ¹ng. HÃ m HÃ m lÃ  nhÃ³m cÃ¡c cÃ¢u lá»‡nh láº¡i vá»›i nhau, Ä‘á»ƒ thá»±c hiá»‡n má»™t nhiá»‡m vá»¥. Má»™t chÆ°Æ¡ng trÃ¬nh c++ cÃ³ Ã­t nháº¥t 1 hÃ m main.\nBáº¡n cÃ³ thá»ƒ tÃ¹y Ã½ tÃ¡ch cÃ¡c Ä‘oáº¡n code nhá» ra thÃ nh nhiá»u hÃ m khÃ¡c nhau. Phá»¥ thuá»™c vÃ o phong cÃ¡ch code cá»§a báº¡n. KhÃ´ng ai quy Ä‘á»‹nh pháº£i tÃ¡ch hÃ m nhÆ° tháº¿ nÃ o cáº£. ThÃ´ng thÆ°á»ng, cÃ¡c láº­p trÃ¬nh viÃªn sáº½ tÃ¡ch hÃ m theo chá»©c nÄƒng, cÃ´ng dá»¥ng cá»§a hÃ m.\nCáº¥u trÃºc má»™t hÃ m bao gá»“m :\n1return_type function_name( parameter list ){ 2 body ; 3} Trong thÆ° viá»‡n c++ chuáº©n cÃ³ cung cáº¥p cho chÃºng ta kha khÃ¡ cÃ¡c hÃ m Ä‘Æ°á»£c xÃ¢y dá»±ng sáºµn, vÃ­ dá»¥ hÃ m lÃ m trÃ²n lÃªn ceil, hÃ m lÃ m trÃ²n xuá»‘ng floor. CÃ¡c báº¡n cÃ³ tham kháº£o trong https://en.cppreference.com/w/cpp/header.\nNháº­p, xuáº¥t dá»¯ liá»‡u ThÆ° viá»‡n C++ há»— trá»£ chÃºng ta nhiá»u thÆ° viá»‡n nháº­p xuáº¥t. Trong C++, dá»¯ liá»‡u Ä‘Æ°á»£c thá»±c hiá»‡n lÃ  má»™t chuá»—i tuáº§n tá»± cÃ¡c byte. Tá»« chuyÃªn ngÃ nh lÃ  streams. VÃ¬ vÃ¢y, nÃªn chia lÃ m 2 dáº¡ng.\nInput stream: Chuá»—i cÃ¡c byte Ä‘Æ°á»£c Ä‘Æ°a tá»« bÃªn ngoÃ i (bÃ n phÃ­m, máº¡ng lan, file \u0026hellip;) vÃ o trong bá»™ nhá»› -\u0026gt; gá»i lÃ  chuá»—i dá»¯ liá»‡u nháº­p , hay gá»i lÃ  nháº­p liá»‡u.\nOutput stream: chuá»—i cÃ¡c byte tá»« bá»™ nhá»› chÃ­nh Ä‘i ra (hiá»ƒn thá»‹ lÃªn mÃ n hÃ¬nh, , qua máº¡ng lan, ra Ä‘Ã¨n led \u0026hellip; ) -\u0026gt; gá»i lÃ  chuá»—i dá»¯ liá»‡u xuáº¥t.\ná» Ä‘Ã¢y, mÃ¬nh sáº½ sá»­ dá»¥ng iostream cÃ³ trong thÆ° viá»‡n cÆ¡ sá»Ÿ cá»§a C++ lÃ m vÃ­ dá»¥ minh há»a, ngoÃ i ra, c++ cÃ²n cÃ³ iomanip vÃ  fstream, cÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m hiá»ƒu thÃªm\n1 2// C++ program to illustrate data stream 3#include\u0026lt;iostream\u0026gt; 4using namespace std; 5 6int main(){ 7 int age; 8 9 cout \u0026lt;\u0026lt; \u0026#34;nhap vao so tuoi cua ban: \u0026#34;; 10 cin \u0026gt;\u0026gt; age; 11 cout \u0026lt;\u0026lt; endl\u0026lt;\u0026lt;\u0026#34;Tuoi cua ban la: \u0026#34; \u0026lt;\u0026lt; age\u0026lt;\u0026lt;endl; 12 13 return 0; 14} 15 16//MÃ£ nguá»“n nÃ y Ä‘Æ°á»£c viáº¿t vÃ  chia sáº» bá»Ÿi Pháº¡m Duy TÃ¹ng. Trong vÃ­ dá»¥ trÃªn, mÃ¬nh sá»­ dá»¥ng hÃ m nháº­p liá»‡u lÃ  cin ( Ä‘á»c lÃ  xi in), cÃ³ sáºµn trong iostream. HÃ m sáº½ nháº­n cÃ¡c kÃ½ tá»± mÃ¬nh gÃµ trÃªn bÃ n phÃ­m, káº¿t thÃºc bá»Ÿi dáº¥u enter ( giáº£ sá»­ mÃ¬nh nháº­p sá»‘ 5 rá»“i áº¥n enter). Báº£n cháº¥t bÃªn trong lÃ  cÃ¡c kÃ½ tá»± mÃ¬nh gÃµ trÃªn bÃ n phÃ­m sáº½ biáº¿n thÃ nh má»—i chuá»—i tuáº§n tá»± cÃ¡c byte (stream) vÃ  Ä‘áº©y vÃ o trong bá»™ nhá»› ram.\nÄá»ƒ hiá»ƒn thá»‹ lÃªn mÃ n hÃ¬nh, chÃºng ta dÃ¹ng hÃ m cout ( Ä‘á»c lÃ  xi ao). Báº£n cháº¥t bÃªn trong lÃ  dá»¯ liá»‡u chÃºng ta muá»‘n hiá»ƒn thá»‹ lÃªn mÃ n hÃ¬nh sáº½ mÃ£ hÃ³a thÃ nh chuá»—i tuáº§n tá»± byte vÃ  Ä‘áº©y ra cÃ¡c thiáº¿t bá»‹ ngoáº¡i vi.\n1nhap vao so tuoi cua ban: 5 2 3Tuoi cua ban la: 5 PhÃ¢n biá»‡t C++ Standard library vÃ  STL STL vÃ  C++ Standard library lÃ  2 Ã´ng khÃ¡c biá»‡t hoÃ n toÃ n, phÃ¢n biá»‡t nhÆ° sau.\nC++ Standard library C++ Standard library lÃ  táº­p cÃ¡c thÆ° viá»‡n chuáº©n cá»§a C Standard Library, Ä‘Æ°á»£c viáº¿t láº¡i dÆ°á»›i dáº¡ng tÃªn khÃ¡c, thÃ´ng thÆ°á»ng lÃ  bá»‹ xÃ³a .h Ä‘i vÃ  thÃªm chá»¯ c á»Ÿ Ä‘áº§u. VÃ­ dá»¥ thÆ° viá»‡n time.h trong c sáº½ Ä‘Æ°á»£c xÃ o náº¥u thÃ nh ctime\nSTL STL lÃ  tá»« viáº¿t táº¯t cá»§a Standard Template Library , lÃ  thÆ° viá»‡n bao gá»“m 4 thÃ nh pháº§n chÃ­nh lÃ  algorithms, containers, Numeric, vÃ  iterators. GiÃºp tÄƒng sá»± linh hoáº¡t vÃ  má»m dáº»o cá»§a C++. Cá»¥ thá»ƒ\nContainer Containers - tiáº¿ng viá»‡t dá»‹ch ra lÃ  thÃ¹ng chá»©a, lÃ  Ä‘á»‘i tÆ°á»£ng dÃ¹ng Ä‘á»ƒ chá»©a cÃ¡c Ä‘á»‘i tÆ°á»£ng khÃ¡c. Container lÆ°u trá»¯ vÃ  quáº£n lÃ½ cÃ¡c Ä‘á»‘i tÆ°á»£ng, cung cáº¥p cÃ¡c hÃ m Ä‘á»ƒ truy xuáº¥t Ä‘áº¿n cÃ¡c Ä‘á»‘i tÆ°á»£ng.\nContainer Ä‘Æ°á»£c phÃ¢n loáº¡i nhÆ° sau:\nSequence containers\nvector deque list Associative containers\nset multiset map multimap hash_set hash_map hash_multiset hash_multimap Containers adpators\nStack Queue Priority_queue Phá»¥ thuá»™c vÃ o bÃ i toÃ¡n mÃ  chÃºng ta sáº½ lá»±a chá»n container phÃ¹ há»£p Ä‘á»ƒ Ä‘Ã¡p á»©ng Ä‘á»™ phá»©c táº¡p vÃ  thá»i gian thá»±c thi. KhÃ´ng nÃªn xÃ i Ä‘áº¡i 1 loáº¡i container nÃ o Ä‘Ã³.\nIterators Iterators lÃ  Ä‘á»‘i tÆ°á»£ng giÃºp láº­p trÃ¬nh viÃªn duyá»‡t containers. Chá»‰ cÃ³ 2 loáº¡i nhÃ³m container lÃ  Sequence container vÃ  Associative container má»›i cÃ³ iterator\nCÃ³ 5 loáº¡i iterators Ä‘Æ°á»£c há»— trá»£ trong c++ lÃ :\ninput (dÃ¹ng Ä‘á»ƒ Ä‘á»c chuá»—i giÃ¡ trá»‹) output (dÃ¹ng Ä‘á»ƒ ghi chuá»—i giÃ¡ trá»‹) forward ( Ä‘á»c, ghi, di chuyá»ƒn lÃªn Ä‘áº¿n 1 vÃ¹ng khÃ¡c) bidirectional (Ä‘á»c, ghi , di chuyá»ƒn lÃªn, di chuyá»ƒn xuá»‘ng) random access (nháº£y tá»± do Ä‘áº¿n 1 bÆ°á»›c khÃ¡c) Algorithms Algorithms chá»©a táº­p cÃ¡c hÃ m giÃºp xá»­ lÃ½ nhiá»u pháº§n tá»­. VÃ­ dá»¥ sort dÃ¹ng Ä‘á»ƒ xáº¯p xáº¿p cÃ¡c pháº§n tá»­ theo thá»© tá»±. binary_search giÃºp tÃ¬m kiáº¿m dá»¯ liá»‡u dáº¡ng nhá»‹ phÃ¢n, cho tá»‘c Ä‘á»™ tÃ¬m kiáº¿m cao hÆ¡n\u0026hellip;.\nNumeric LÃ  táº­p cÃ¡c thÆ° viá»‡n há»— trá»£ láº­p trÃ¬nh viÃªn thá»±c hiá»‡n cÃ¡c phÃ©p toÃ¡n trÃªn sá»‘. VÃ­ dá»¥ complex há»— trá»£ cÃ¡c template vÃ  cÃ¡c hÃ m tÃ­nh toÃ¡n sá»‘ phá»©c.\n","date":"Feb 20, 2022","img":"","permalink":"/courses/cplusplus/3_steep/","series":["KhÃ³a há»c c++ cÄƒn báº£n"],"tags":["c++"],"title":"BÃ i 3: LÃ m Quen Vá»›i C++"},{"categories":null,"content":"Tools sinh máº­t kháº©u thÃ´ng minh, tá»± Ä‘á»™ng, trÃ¡nh lÃ m lá»™ máº­t kháº©u\nChiá»u dÃ i: Generate Password KÃ½ tá»± thÆ°á»ng: abcd KÃ½ tá»± hoa: ABCD KÃ½ sá»‘: 1234 KÃ½ tá»± Ä‘áº·c biá»‡t @#$! Pass cá»§a báº¡n: copy \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; Má»™t sá»‘ lÆ°u Ã½ khi Ä‘áº·t máº­t kháº©u Äá»ƒ trÃ¡nh cho máº­t kháº©u bá»‹ táº¥n cÃ´ng bá»Ÿi yáº¿u hacker báº±ng ká»¹ thuáº­t táº¥n cÃ´ng tá»« Ä‘iá»ƒn, táº¥n cÃ´ng tá»« Ä‘iá»ƒn, táº¥n cÃ´ng báº±ng social engineering, vÃ  giá»¯ cho tÃ i khoáº£ng online cá»§a báº¡n Ä‘Æ°á»£c an toÃ n, báº¡n nÃªn thá»±c hiá»‡n nhá»¯ng Ä‘iá»u sau:\nKhÃ´ng nÃªn sá»­ dá»¥ng chung máº­t kháº©u, cÃ¢u há»i báº£o máº­t, cÃ¢u tráº£ lá»i báº£o nháº­t cho cÃ¹ng cÃ¡c tÃ i khoáº£ng quang trá»ng nhÆ° ngÃ¢n hÃ ng, email, facebook\u0026hellip; Sá»­ dá»¥ng máº­t kháº©u cÃ³ chiá»u dÃ i Ã­t nháº¥t lÃ  16 kÃ½ tá»±, trong Ä‘Ã³ Ã­t nháº¥t pháº£i chá»©a 1 kÃ½ sá»‘, 1 kÃ½ tá»± viáº¿t hoa vÃ  1 kÃ½ tá»± Ä‘áº·c biá»‡t. KhÃ´ng nÃªn sá»­ dá»¥ng há»/tÃªn cá»§a mÃ¬nh hoáº·c nhá»¯ng ngÆ°á»i trong gia Ä‘Ã¬nh, tÃªn thÃº cÆ°ng, ngÃ y thÃ¡ng nÄƒm sinh cá»§a mÃ¬nh/gia Ä‘Ã¬nh mÃ¬nh Ä‘á»ƒ Ä‘áº·t máº­t kháº©u KhÃ´ng nÃªn sá»­ dá»¥ng mÃ£ bÆ°u chÃ­nh, sá»‘ nhÃ , tÃªn Ä‘Æ°á»ng, sá»‘ Ä‘iá»‡n thoáº¡i, ngÃ y sinh nháº­t, sá»‘ chá»©ng minh nhÃ¢n dÃ¢n / cÄƒn cÆ°á»›c cÃ´ng dÃ¢n, sá»‘ báº£o hiá»ƒm xÃ£ há»™i, sá»‘ báº£o hiá»ƒm y táº¿, báº¥t ká»³ sá»‘ gÃ¬ mÃ  cÃ³ thá»ƒ Ä‘á»‹nh danh lÃ  báº¡n lÃ m máº­t kháº©u. KhÃ´ng nÃªn sá»­ dá»¥ng nhá»¯ng máº­t kháº©u Ä‘Ã£ bá»‹ cÃ´ng bá»‘ tÃªn internet lÃ m máº­t kháº©u. VÃ­ dá»¥ nhÆ° 123456, iloveyou, qwerty\u0026hellip; KhÃ´ng nÃªn sá»­ dá»¥ng máº­t kháº©u cÃ³ Ä‘oáº¡n kÃ½ tá»± trÃ¹ng nhau, vÃ­ dá»¥ iloveyoupacpac, cualolocua, \u0026hellip; KhÃ´ng nÃªn sá»­ dá»¥ng nhá»¯ng thá»© cÃ³ thá»ƒ bá»‹ copy (mÃ  báº¡n khÃ´ng thá»ƒ thay Ä‘á»•i) lÃ m máº­t kháº©u. vÃ­ dá»¥ nhÆ° lÃ  xÃ¡c thá»±c báº±ng vÃ¢n tay, khuÃ´n máº·t (Trong Ä‘iá»u kiá»‡n báº¡n muá»‘n an toÃ n tuyá»‡t Ä‘á»‘i, thÃ¬ khÃ´ng nÃªn báº­t xÃ¡c thá»±c vÃ¢n tay vÃ  xÃ¡c thá»±c khuÃ´n máº·t trÃªn iphone , hi hi). KhÃ´ng nÃªn cho phÃ©p trÃ¬nh duyá»‡t lÆ°u toÃ n bá»™ máº­t kháº©u (cÃ¡c trÃ¬nh duyá»‡t há»— trá»£ lÆ°u máº­t kháº©u nhÆ° FireFox, Chrome, Safari, Opera, IE, Microsoft Edge ). bá»Ÿi vÃ¬ chÃºng ta cÃ³ thá»ƒ dá»… dÃ ng láº¥y láº¡i máº­t kháº©u tá»« trÃ¬nh duyá»‡t. KhÃ´ng nÃªn Ä‘Äƒng nháº­p vÃ o tÃ i khoáº£ng quang trá»ng trÃªn mÃ¡y ngÆ°á»i láº¡. KhÃ´ng nÃªn Ä‘Äƒng nháº­p vÃ o tÃ i khoáº£ng quang trá»ng khi sá»­ dá»¥ng wifi cÃ´ng cá»™ng, free VPN, free web proxy, tor\u0026hellip; KhÃ´ng nÃªn gá»­i cÃ¡c thÃ´ng tin quang trá»ng qua cÃ¡c giao thá»©c chÆ°a Ä‘Æ°á»£c mÃ£ hÃ³a( vÃ­ dá»¥ HTTP, FTP ), bá»Ÿi vÃ¬ cÃ¡c thÃ´ng tin Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘Ã¡nh cáº¯p má»™t cÃ¡ch dá»… dÃ ng qua ká»¹ thuáº­t sniffed. Báº¡n nÃªn sá»­ dá»¥ng cÃ¡c giao thá»©c Ä‘Ã£ Ä‘Æ°á»£c mÃ£ hÃ³a nhÆ° lÃ  HTTPS, SFTP, FTPS, SMTPS, IPSec báº¥t cá»© khi nÃ o cÃ³ thá»ƒ. Khi Ä‘i du lá»‹ch, vÃ  sá»­ dá»¥ng máº¡ng internet / wifi miá»…n phÃ­, náº¿u cÃ³ thá»ƒ, hÃ£y mÃ£ hÃ³a thÃ´ng tin cá»§a báº¡n trÆ°á»›c khi gá»­i Ä‘i. VÃ­ dá»¥, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng pháº§n má»m há»— trá»£ táº¡o VPN cÃ¡ nhÃ¢n há»— trá»£ giao thá»©c WireGuard( hoáº·c IKEv2, OpenVPN, SSTP, L2TP over IPSec ) vÃ o server cÃ¡ nhÃ¢n cá»§a báº¡n( mÃ¡y tÃ­nh á»Ÿ nhÃ , server báº¡n dá»±ng trÃªn AWS, VPS\u0026hellip;). Hoáº·c báº¡n cÃ³ thá»ƒ thiáº¿t láº­p mÃ£ hÃ³a káº¿t ná»‘i SSH giá»¯a mÃ¡y báº¡n vÃ  server cá»§a báº¡n, vÃ  sau Ä‘Ã³ cáº¥u hÃ¬nh cho Chrome hoáº·c FireFox sá»­ dá»¥ng socks proxy cá»§a báº¡n. Do Ä‘Ã³, ngay cáº£ khi ngÆ°á»i xáº¥u Ä‘Ã£ sniff Ä‘Æ°á»£c máº£nh dá»¯ liá»‡u thÃ´ng tin cá»§a báº¡n, há» cÅ©ng khÃ´ng thá»ƒ xem Ä‘Æ°á»£c nÃ³, bá»Ÿi vÃ¬ dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c mÃ£ hÃ³a. ThÃ´ng thÆ°á»ng, ngÆ°á»i dÃ¹ng sáº½ ráº¥t tá»± tin ráº±ng máº­t kháº©u há» Ä‘áº·t ráº¥t máº¡nh vÃ  khÃ³ bá»‹ hack. NhÆ°ng trong thá»±c táº¿, khÃ´ng cÃ³ gÃ¬ cÃ³ thá»ƒ báº£o Ä‘áº£m Ä‘Æ°á»£c Ä‘iá»u Ä‘Ã³. Má»™t trong nhá»¯ng cÃ¡ch cÃ³ thá»ƒ kiá»ƒm tra lÃ  báº¡n sá»­ dá»¥ng má»™t chÆ°Æ¡ng trÃ¬nh hash md5 máº­t kháº©u cá»§a báº¡n láº¡i, kiá»ƒm tra trÃªn cÃ¡c tráº¡ng MD5 decryption website, vÃ  kiá»ƒm tra xem Ä‘oáº¡n md5 cá»§a báº¡n sáº½ bá»‹ crack trong vÃ²ng bao lÃ¢u. Khuyáº¿n cÃ¡o lÃ  nÃªn Ä‘á»•i máº­t kháº©u má»—i 10 tuáº§n 1 láº§n, Ä‘á»‘i vá»›i cÃ¡c tÃ i khoáº£ng quang trá»ng. Má»™t sá»‘ tá»• chá»©c ngÃ¢n hÃ ng nhÆ° techcombank á»Ÿ Viá»‡t Nam cÃ³ thá»±c hiá»‡n theo khuyáº¿n nghá»‹ nÃ y, nhÆ°ng vá»›i sá»‘ tuáº§n dÃ i hÆ¡n. ThÃ´ng thÆ°á»ng, chÃºng ta khÃ´ng thá»ƒ nhá»› háº¿t táº¥t cáº£ toÃ n bá»™ máº­t kháº©u cá»§a chÃºng ta dÃ£ Ä‘áº·t ra. VÃ¬ váº­y, cÃ³ má»™t cÃ¡ch khÃ¡c Ä‘á»ƒ thá»±c hiá»‡n lÃ  chá»‰ nhá»› máº­t kháº©u cá»§a nhá»¯ng tÃ i khoáº£ng quang trá»ng. Äá»‘i vá»›i nhá»¯ng tÃ i khoáº£ng Ã­t quang trá»ng hÆ¡n, chÃºng ta cÃ³ thá»ƒ lÆ°u dÆ°á»›i dáº¡ng text file vÃ  mÃ£ hÃ³a file text nÃ y báº±ng cÃ¡c pháº§n má»m nhÆ° 7-zip, GPG hoáº·c BitLocker. NÃªn sao lÆ°u báº£n mÃ£ hÃ³a file text máº­t kháº©u á»Ÿ má»™t vÃ i nÆ¡i, vÃ­ dá»¥ Ä‘áº©y lÃªn email, lÆ°u á»Ÿ á»• phá»¥. Äá»ƒ nhá»¡ xui rá»§i, vÃ¬ má»™t lÃ½ do nÃ o Ä‘Ã³, báº¡n khÃ´ng thá»ƒ truy xuáº¥t vÃ o mÃ¡y tÃ­nh cá»§a báº¡n vÃ  láº¥y láº¡i máº­t kháº©u. ThÃ¬ báº¡n cÃ³ thá»ƒ dá»… dÃ ng xem vÃ  láº¥y láº¡i máº­t kháº©u cá»§a nhá»¯ng tÃ i khoáº£ng khÃ¡c. Báº­t xÃ¡c minh hai bÆ°á»›c báº¥t cá»© khi nÃ o cÃ³ thá»ƒ. KhÃ´ng nÃªn lÆ°u máº­t kháº©u quang trá»ng trÃªn mÃ¢y Truy cáº­p nhá»¯ng trang web quan trá»ng nhÆ° paypal, ngÃ¢n hÃ ng, mail\u0026hellip; tá»« bookmark. Náº¿u truy cáº­p tá»« link láº¡i, nÃªn check ká»¹ domain xem Ä‘Ã£ chÃ­nh xÃ¡c hay chÆ°a. Má»™t máº¹o nhá» lÃ  chÃºng ta cÃ³ thá»ƒ kiá»ƒm tra Ä‘á»™ phá»• biáº¿n cá»§a website báº±ng cÃ´ng cá»¥ Alexa toolbar Ä‘á»ƒ cháº¯c cháº¯n ráº±ng domail báº¡n Ä‘ang truy cáº­p khÃ´ng pháº£i lÃ  hÃ ng giáº£ Báº£o vá»‡ mÃ¡y tÃ­nh báº¡n báº±ng tÆ°á»ng lá»­a vÃ  chÆ°Æ¡ng trÃ¬nh diá»‡t virus. Cháº·n táº¥t cáº£ cÃ¡c káº¿t ná»‘i vÃ o vÃ  táº¥t cáº£ cÃ¡c káº¿t ná»‘i ra khÃ´ng cáº§n thiáº¿t báº±ng tÆ°á»ng lá»­a. Táº£i cÃ¡c pháº§n má»m tá»« cÃ¡c site chÃ­nh thá»‘ng. Check mÃ£ MD5 / SHA1 / SHA256 checksum hoáº·c GPG signature cá»§a pháº§n má»m náº¿u cÃ³ thá»ƒ. Cáº­p nháº­t há»‡ Ä‘iá»u hÃ nh, cÃ¡c pháº§n má»m duyá»‡t web trong mÃ¡y tÃ­nh cá»§a báº¡n lÃªn phiÃªn báº£n má»›i nháº¥t Ä‘á»ƒ fix cÃ¡c lá»—i báº£o máº­t Náº¿u trong mÃ¡y cá»§a báº¡n cÃ³ lÆ°u nhá»¯ng file cá»±c ká»³ quang trá»ng, vÃ­ dá»¥ nhÆ° báº£ng lÆ°Æ¡ng cá»§a cÃ´ng ty, tin nháº¯n private vá»›i trÃ  xanh \u0026hellip; , thÃ¬ nÃ£y kiá»ƒm tra ká»¹ xem trong mÃ¡y cÃ³ chá»©a pháº§n má»m keyloggers, hoáº·c pháº§n cá»©ng keyloggers( vd wireless keyboard sniffer ), hoáº·c camera áº©n. Nhá»¯ng thá»© vÃ­ dá»¥ á»Ÿ trÃªn lÃ  má»™t má»‘i nguy háº¡i ráº¥t lá»›n. Báº­t tÃ­nh nÄƒng khÃ³a mÃ n hÃ¬nh mÃ¡y tÃ­nh / mÃ¡y tÃ­nh báº£ng/ Ä‘iá»‡n thoáº¡i ngay khi báº¡n khÃ´ng sá»­ dá»¥ng chÃºng MÃ£ hÃ³a toÃ n bá»™ á»• Ä‘Ä©a cá»©ng báº±ng cÃ¡c pháº§n má»m mÃ£ hÃ³a nhÆ° VeraCrypt, FileVault, LUKS, \u0026hellip; Ä‘á»ƒ báº£o vá»‡ cÃ¡c file quan trá»ng trong mÃ¡y. HÃ£y há»§y váº­t lÃ½ á»• cá»©ng cÅ© cÃ³ chá»©a thÃ´ng tin quan trá»ng cá»§a báº¡n (thay vÃ¬ nÃ©m vÃ o sá»t rÃ¡c, bÃ¡n ve chai) Náº¿u Ä‘Æ°á»£c, hÃ£y dÃ¹ng Ã­t nháº¥t 3 email Ä‘á»ƒ nháº­n mail. Má»™t mail Ä‘á»ƒ nháº­n cÃ¡c thÃ´ng tin quang trá»ng tá»« ngÃ¢n hÃ ng, paypal hoáº·c nhá»¯ng gÃ¬ cÃ³ yáº¿u tá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n tÃºi tiá»n cá»§a báº¡n. Mail thá»© hai dÃ¹ng Ä‘á»ƒ xÃ¡c thá»±c/ nháº­n mail tá»« nhá»¯ng site khÃ´ng quan trá»ng. Mail thá»© 3 nháº­n pasword - reset mail khi mail sá»‘ 1 bá»‹ hack. Má»™t lÆ°u Ã½ lÃ  mail thá»© 3 nÃªn dÃ¹ng má»™t ná»n táº£ng mail khÃ¡c mail 1. VÃ­ dá»¥ mail 1 dÃ¹ng gmail thÃ¬ mail 3 dÃ¹ng outlook. Náº¿u Ä‘Æ°á»£c, hÃ£y sá»­ dá»¥ng Ã­t nháº¥t 2 sá»‘ Ä‘iá»‡n thoáº¡i. Sá»‘ Ä‘iá»‡n thoáº¡i Ä‘áº§u tiÃªn Ä‘á»ƒ xÃ¡c thá»±c 2 bÆ°á»›c vá»›i cÃ¡c site quang trá»ng nhÆ° ngÃ¢n hÃ ng. KhÃ´ng cho gia Ä‘Ã¬nh, ngÆ°á»i thÃ¢n, báº¡n bÃ¨, Ä‘á»“ng nghiá»‡p biáº¿t sá»‘ Ä‘iá»‡n thoáº¡i sá»‘ 1. Sá»‘ Ä‘iá»‡n thoáº¡i 2 lÃ  sá»‘ Ä‘iá»‡n thoáº¡i public, cho báº¡n bÃ¨ ngÆ°á»i thÃ¢n liÃªn láº¡c, Ä‘Äƒng kÃ½ cÃ¡c app/ web Ã­t quang trá»ng hÆ¡n, vd lÃ  sá»‘ Ä‘iá»‡n thoáº¡i Ä‘áº·t hÃ ng tiki, shopee, bÃ¡ch hÃ³a xanh, Ä‘iá»‡n mÃ¡y xanh, mua trÃ  sá»­a, tÃ¡n anh hÃ ng xÃ³m\u0026hellip;. Äá»«ng click vÃ o link trong email/SMS, hÃ£y kiá»ƒm tra Ä‘Æ°á»ng dáº«n tháº­t ká»¹, vÃ  copy paste vÃ o new tab náº¿u link chÃ­nh xÃ¡c, khÃ´ng pháº£i giáº£ máº¡o. Náº¿u báº¡n xÃ¡c Ä‘á»‹nh nÃ³ giáº£ máº¡o, nÃ£y xÃ³a nÃ³ Ä‘i, hoáº·c Ä‘Ã¡nh dáº¥u spam rá»“i xÃ³a nÃ³ Ä‘i. KhÃ´ng gá»­i máº­t kháº©u cá»§a báº¡n cho ngÆ°á»i khÃ¡c qua email. Cáº©n tháº­n vá»›i cÃ¡c chÆ°Æ¡ng trÃ¬nh online paste tools vÃ  chÆ°Æ¡ng trÃ¬nh chá»¥p áº£nh mÃ n hÃ¬nh download á»Ÿ trÃªn máº¡ng. Náº¿u báº¡n dev web, hÃ£y lÃ m cÃ³ tÃ¢m má»™t chÃºt, Ä‘á»«ng lÆ°u máº­t kháº©u cá»§a ngÆ°á»i dÃ¹ng dáº¡ng plain text vÃ o database. Báº¡n nÃªn lÆ°u báº£n mÃ£ hÃ³a SHA1, SHA256 hoáº·c SHA512, kÃ¨m thÃªm má»™t chÃºt muá»‘i, tiÃªu, Ä‘á»ƒ báº£o vá»‡ ngÆ°á»i dÃ¹ng. Má»™t Ã½ tÆ°á»Ÿng hay lÃ  lÆ°u thÃªm mÃ£ hash Ä‘á»‹nh danh thiáº¿t bá»‹ ngÆ°á»i dÃ¹ng Ä‘ang sá»­ dá»¥ng (vd há»‡ Ä‘iá»u hÃ nh, kÃ­ch thÆ°á»›c mÃ n hÃ¬nh, sá»‘ cpu/ram \u0026hellip;). Khi ngÆ°á»i dÃ¹ng Ä‘Äƒng nháº­p sai máº­t kháº©u, vÃ  thiáº¿t bá»‹ ngÆ°á»i dÃ¹ng sá»­ dá»¥ng khÃ´ng giá»‘ng vá»›i thiáº¿t bá»‹ Ä‘Ã£ sá»­ dá»¥ng trÆ°á»›c Ä‘Ã³. ThÃ¬ hÃ£y báº­t xÃ¡c thá»±c 2 bÆ°á»›c qua sá»‘ Ä‘iá»‡n thoáº¡i/ email sau khi ngÆ°á»i dÃ¹ng Ä‘Ã£ Ä‘Äƒng nháº­p Ä‘Æ°á»£c. Náº¿u báº¡n lÃ  nhÃ  phÃ¡t triá»ƒn pháº§n má»m, hÃ£y cá»‘ gáº¯ng cung cáº¥p mÃ£ private key sá»­ dá»¥ng GnuPG hoáº·c SHA-256 file á»©ng dá»¥ng cá»§a báº¡n Ä‘á»ƒ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ kiá»ƒm tra xem file Ä‘Ã£ bá»‹ chá»‰nh sá»­a hay chÆ°a. Náº¿u báº¡n kinh doanh online, hÃ£y Ä‘Äƒng kÃ½ má»™t domain, thiáº¿t láº­p tÃ i khoáº£ng email tÆ°Æ¡ng á»©ng vá»›i domain. Äiá»u nÃ y lÃ  cáº§n thiáº¿t bá»Ÿi vÃ¬ báº¡n sáº½ khÃ´ng Ä‘Ã¡nh máº¥t cÃ¡c thÃ´ng tin liÃªn láº¡c, vÃ  tÃ i khoáº£ng email cá»§a báº¡n sáº½ khÃ´ng bá»‹ nhÃ  cung cáº¥p nÃ o cÃ³ thá»ƒ xÃ³a Ä‘i cáº£. ","date":"Feb 20, 2022","img":"","permalink":"/utils/gen_paswords/","series":null,"tags":["password","random password","password generator"],"title":"ChÆ°Æ¡ng TrÃ¬nh Sinh Pasword Ngáº«u NhiÃªn"},{"categories":"python","content":"Ná»™i dung khÃ³a há»c BÃ i 1: Giá»›i thiá»‡u vá» C++\nTá»•ng quan ngÃ´n ngá»¯ C++ Táº¡i sao nÃªn há»c ngÃ´n ngá»¯ C++ BÃ i 2: CÃ i Ä‘áº·t mÃ´i trÆ°á»ng phÃ¡t triá»ƒn (IDE) Visual studio 2015\nGiá»›i thiá»‡u Microsoft Visual Studio HÆ°á»›ng dáº«n download vÃ  cÃ i Ä‘áº·t visual studio BÃ i 3: XÃ¢y dá»±ng chÆ°Æ¡ng trÃ¬nh C++ Ä‘áº§u tiÃªn vá»›i Visual Studio 2015\nMá»™t sá»‘ kiáº¿n thá»©c cáº§n lÆ°u Ã½ CÃ¡ch táº¡o vÃ  biÃªn dá»‹ch chÆ°Æ¡ng trÃ¬nh C++ Ä‘áº§u tiÃªn trÃªn Visual Studio Má»™t sá»‘ váº¥n Ä‘á» thÆ°á»ng gáº·p Ä‘á»‘i vá»›i láº­p trÃ¬nh viÃªn má»›i BÃ i 4: Cáº¥u trÃºc má»™t chÆ°Æ¡ng trÃ¬nh C++ (Structure of a program)\nCáº¥u trÃºc cá»§a má»™t chÆ°Æ¡ng trÃ¬nh C++ CÃº phÃ¡p vÃ  lá»—i cÃº phÃ¡p trong C++ (Syntax and syntax errors) BÃ i 5: Ghi chÃº trong C++ (Comments in C++)\nCÃº phÃ¡p comment trong C++ Má»™t sá»‘ kinh nghiá»‡m khi comment trong láº­p trÃ¬nh BÃ i 6: Biáº¿n trong C++ (Variables in C++)\nBiáº¿n trong C++ Khá»Ÿi táº¡o biáº¿n trong C++ (Defining a variable) Äá»‹nh nghÄ©a biáº¿n á»Ÿ Ä‘Ã¢u (Where to define variables) BÃ i 7: Sá»‘ tá»± nhiÃªn vÃ  Sá»‘ cháº¥m Ä‘á»™ng trong C++ (Integer, Floating point)\nTá»•ng quan vá» kiá»ƒu dá»¯ liá»‡u cÆ¡ báº£n trong C++ Kiá»ƒu sá»‘ nguyÃªn (Integer) Sá»‘ cháº¥m Ä‘á»™ng (Floating point numbers) BÃ i 8: Kiá»ƒu kÃ½ tá»± trong C++ (Character)\nTá»•ng quan vá» kiá»ƒu kÃ½ tá»± (Character) Khai bÃ¡o, khá»Ÿi táº¡o vÃ  gÃ¡n giÃ¡ trá»‹ má»™t biáº¿n kÃ½ tá»± In kÃ½ tá»± ra mÃ n hÃ¬nh In kÃ½ tá»± tá»« sá»‘ nguyÃªn vÃ  ngÆ°á»£c láº¡i (Casting) Escape sequences Newline â€˜\\nâ€™ vÃ  std::endl Dáº¥u nhÃ¡y Ä‘Æ¡n â€˜Kâ€™ vÃ  dáº¥u nhÃ¡y kÃ©p â€œKteamâ€ BÃ i 9: Kiá»ƒu luáº­n lÃ½ vÃ  cÆ¡ báº£n vá» CÃ¢u Ä‘iá»u kiá»‡n If (Boolean and If statements)\nTá»•ng quan vá» kiá»ƒu luáº­n lÃ½ (Boolean) CÆ¡ báº£n vá» cÃ¢u Ä‘iá»u kiá»‡n If vÃ  Boolean BÃ i 10: Nháº­p, Xuáº¥t vÃ  Äá»‹nh dáº¡ng dá»¯ liá»‡u trong C++ (Input and Output)\nXuáº¥t dá»¯ liá»‡u vá»›i std::cout trong C++ Nháº­p dá»¯ liá»‡u vá»›i std::cin trong C++ Äá»‹nh dáº¡ng dá»¯ liá»‡u nháº­p xuáº¥t trong C++ BÃ i 11: Háº±ng sá»‘ trong C++ (Constants)\nTá»•ng quan háº±ng sá»‘ (Constants) Háº±ng sá»‘ vá»›i tá»« khÃ³a const Háº±ng sá»‘ vá»›i chá»‰ thá»‹ tiá»n xá»­ lÃ½ #define NÃªn Ä‘á»‹nh nghÄ©a háº±ng sá»‘ á»Ÿ Ä‘Ã¢u BÃ i 12: ToÃ¡n tá»­ sá»‘ há»c, toÃ¡n tá»­ tÄƒng giáº£m, toÃ¡n tá»­ gÃ¡n sá»‘ há»c trong C++ (Operators)\nTá»•ng quan vá» toÃ¡n tá»­ ToÃ¡n tá»­ sá»‘ há»c trong C++ (Arithmetic operators) ToÃ¡n tá»­ gÃ¡n sá»‘ há»c trong C++ (Arithmetic assignment operators) BÃ i 13: ToÃ¡n tá»­ quan há»‡, logic, bitwise, misc vÃ  Ä‘á»™ Æ°u tiÃªn toÃ¡n tá»­ trong C++\nToÃ¡n tá»­ quan há»‡ trong C++ (Relational operators) ToÃ¡n tá»­ logic trong C++ (Logical operators) ToÃ¡n tá»­ trÃªn bit trong C++ (Bitwise operators) CÃ¡c toÃ¡n tá»­ há»—n há»£p trong C++ (Misc Operators) Äá»™ Æ°u tiÃªn vÃ  quy táº¯c káº¿t há»£p toÃ¡n tá»­ trong C++ BÃ i 14: CÆ¡ báº£n vá» chuá»—i kÃ½ tá»± trong C++ (An introduction to std::string)\nTá»•ng quan vá» chuá»—i kÃ½ tá»± (std::string) Khai bÃ¡o, khá»Ÿi táº¡o vÃ  gÃ¡n giÃ¡ trá»‹ má»™t chuá»—i kÃ½ tá»± Xuáº¥t má»™t chuá»—i kÃ½ tá»± (string output): Nháº­p má»™t chuá»—i kÃ½ tá»± (string input) Má»™t sá»‘ thao tÃ¡c cÆ¡ báº£n vá»›i chuá»—i kÃ½ tá»± BÃ i 15: Biáº¿n cá»¥c bá»™ trong C++ (Local variables in C++)\nTá»•ng quan vá» táº§m vá»±c cá»§a biáº¿n Biáº¿n cá»¥c bá»™ (Local variables) BÃ i 16: Biáº¿n toÃ n cá»¥c trong C++ (Global variables in C++)\nTá»•ng quan vá» táº§m vá»±c cá»§a biáº¿n Biáº¿n toÃ n cá»¥c (Global variables) Sá»­ dá»¥ng biáº¿n toÃ n cá»¥c lÃ  nguy hiá»ƒm Khi nÃ o cáº§n sá»­ dá»¥ng biáº¿n toÃ n cá»¥c (non-const) BÃ i 17: Biáº¿n tÄ©nh trong C++ (Static variables in C++)\nTá»•ng quan vá» biáº¿n tÄ©nh (static variables) Khi nÃ o nÃªn sá»­ dá»¥ng biáº¿n tÄ©nh BÃ i 18: Ã‰p kiá»ƒu ngáº§m Ä‘á»‹nh trong C++ (Implicit type conversion in C++)\nTá»•ng quan vá» Ã©p kiá»ƒu dá»¯ liá»‡u Ã‰p kiá»ƒu ngáº§m Ä‘á»‹nh trong C++ (Implicit type conversion) BÃ i 19: Ã‰p kiá»ƒu tÆ°á»ng minh trong C++ (Explicit type conversion in C++)\nÃ‰p kiá»ƒu tÆ°á»ng minh trong C++ (Explicit type conversion) BÃ i 20: CÆ¡ báº£n vá» HÃ m vÃ  GiÃ¡ trá»‹ tráº£ vá» (Basic of functions and return values)\nTá»•ng quan vá» hÃ m (functions overview) GiÃ¡ trá»‹ tráº£ vá» (return values) GiÃ¡ trá»‹ tráº£ vá» cá»§a kiá»ƒu void (return values of type void) BÃ i 21: Truyá»n GiÃ¡ Trá»‹ cho HÃ m (Passing Arguments by Value)\nTham sá»‘ vÃ  Ä‘á»‘i sá»‘ cá»§a hÃ m (Function parameters and arguments) Truyá»n giÃ¡ trá»‹ cho hÃ m (Passing arguments by value) Tá»•ng káº¿t vá» phÆ°Æ¡ng phÃ¡p truyá»n giÃ¡ trá»‹ cho hÃ m (Passing argument by value) BÃ i 22: Truyá»n Tham Chiáº¿u cho HÃ m (Passing Arguments by Reference)\nTruyá»n tham chiáº¿u cho hÃ m (Passing arguments by reference) Truyá»n tham chiáº¿u háº±ng (Pass by const reference) Tá»•ng káº¿t vá» phÆ°Æ¡ng phÃ¡p truyá»n tham chiáº¿u cho hÃ m (Passing arguments by reference) BÃ i 23: Tiá»n khai bÃ¡o vÃ  Äá»‹nh nghÄ©a HÃ m (Forward declarations and Definitions of Functions)\nLá»—i â€œidentifier not foundâ€ Tiá»n khai bÃ¡o vÃ  nguyÃªn máº«u hÃ m (Forward declaration and function prototypes) Khai bÃ¡o vÃ  Ä‘á»‹nh nghÄ©a trong C++ (Declarations and definitions in C++) BÃ i 24: Giá»›i thiá»‡u vá» cáº¥u trÃºc Ä‘iá»u khiá»ƒn (Control flow introduction)\nTá»•ng quan vá» cáº¥u trÃºc Ä‘iá»u khiá»ƒn trong C++ CÃ¢u lá»‡nh dá»«ng (halt) CÃ¢u lá»‡nh nháº£y (Jumps) Cáº¥u trÃºc ráº½ nhÃ¡nh cÃ³ Ä‘iá»u kiá»‡n (Conditional branches) Cáº¥u trÃºc vÃ²ng láº·p (Loops) Xá»­ lÃ½ ngoáº¡i lá»‡ (Exceptions handling) BÃ i 25: CÃ¢u Ä‘iá»u kiá»‡n If vÃ  ToÃ¡n tá»­ Ä‘iá»u kiá»‡n (If statements and Conditional operator)\nCÃ¢u Ä‘iá»u kiá»‡n If ToÃ¡n tá»­ Ä‘iá»u kiá»‡n (Conditional operator) BÃ i 26: CÃ¢u Ä‘iá»u kiá»‡n Switch trong C++ (Switch statements)\nCÃ¢u Ä‘iá»u kiá»‡n Switch (Switch statements) Khai bÃ¡o vÃ  khá»Ÿi táº¡o biáº¿n bÃªn trong case statement BÃ i 27: CÃ¢u lá»‡nh Goto trong C++ (Goto statements)\nTá»•ng quan vá» cÃ¢u lá»‡nh Goto trong C++ Má»™t sá»‘ váº¥n Ä‘á» cá»§a cÃ¢u lá»‡nh Goto BÃ i 28: VÃ²ng láº·p While trong C++ (While statements)\nTá»•ng quan vá» cáº¥u trÃºc vÃ²ng láº·p VÃ²ng láº·p while (while statements) BÃ i 29: VÃ²ng láº·p Do while trong C++ (Do while statements)\nVÃ²ng láº·p do while (do while statements) BÃ i 30: VÃ²ng láº·p For trong C++ (For statements)\nVÃ²ng láº·p for (for statements) BÃ i 31: Tá»« khÃ³a Break and continue trong C++\nTá»« khÃ³a break Tá»« khÃ³a continue BÃ i 32: PhÃ¡t sinh sá»‘ ngáº«u nhiÃªn trong C++ (Random number generation)\nTá»•ng quan vá» phÃ¡t sinh sá»‘ ngáº«u nhiÃªn PhÃ¡t sinh sá»‘ ngáº«u nhiÃªn trong C++ PhÃ¡t sinh sá»‘ ngáº«u nhiÃªn trong C++ 11 BÃ i 33: Máº£ng 1 chiá»u trong C++ (Arrays)\nTáº¡i sao láº¡i sá»­ dá»¥ng máº£ng? Tá»•ng quan vá» máº£ng 1 chiá»u Khai bÃ¡o vÃ  khá»Ÿi táº¡o máº£ng 1 chiá»u Xuáº¥t cÃ¡c pháº§n tá»­ máº£ng 1 chiá»u Nháº­p dá»¯ liá»‡u cho máº£ng 1 chiá»u PhÃ¡t sinh dá»¯ liá»‡u ngáº«u nhiÃªn cho máº£ng 1 chiá»u BÃ i 34: CÃ¡c thao tÃ¡c trÃªn Máº£ng má»™t chiá»u\nTruyá»n máº£ng vÃ o hÃ m (passing arrays to functions) Nháº­p vÃ  xuáº¥t máº£ng 1 chiá»u Sao chÃ©p máº£ng 1 chiá»u TÃ¬m kiáº¿m pháº§n tá»­ trong máº£ng Sáº¯p xáº¿p máº£ng 1 chiá»u ThÃªm vÃ  xÃ³a má»™t pháº§n tá»­ trong máº£ng BÃ i 35: Máº£ng 2 chiá»u trong C++ (Two-dimensional arrays)\nMáº£ng 2 chiá»u lÃ  gÃ¬? Khai bÃ¡o vÃ  khá»Ÿi táº¡o máº£ng 2 chiá»u Xuáº¥t cÃ¡c pháº§n tá»­ máº£ng 2 chiá»u Nháº­p cÃ¡c pháº§n tá»­ máº£ng 2 chiá»u BÃ i 36: CÃ¡c thao tÃ¡c trÃªn Máº£ng 2 chiá»u\nTruyá»n máº£ng vÃ o hÃ m (passing arrays to functions) Nháº­p vÃ  xuáº¥t máº£ng 2 chiá»u TÃ­nh tá»•ng cÃ¡c pháº§n tá»­ trong máº£ng TÃ¬m giÃ¡ trá»‹ lá»›n nháº¥t cá»§a máº£ng 2 chiá»u BÃ i 37: Máº£ng kÃ½ tá»± trong C++ (C-style strings)\nMáº£ng kÃ½ tá»± (C-style strings) lÃ  gÃ¬? Khai bÃ¡o vÃ  khá»Ÿi táº¡o máº£ng kÃ½ tá»± (C-style strings) Xuáº¥t máº£ng kÃ½ tá»± (C-style strings) vá»›i std::cout Nháº­p máº£ng kÃ½ tá»± (C-style strings) vá»›i std::cin BÃ i 38: CÃ¡c thao tÃ¡c trÃªn Máº£ng kÃ½ tá»± (C-style strings)\nMá»™t sá»‘ thao tÃ¡c vá»›i máº£ng kÃ½ tá»± (C-style strings)\nhttps://www.freecodecamp.org/news/learn-c-with-free-31-hour-course/\nâŒ¨ï¸ (0:00:00) Introduction to data structures âŒ¨ï¸ (0:06:33) Data Structures: List as abstract data type âŒ¨ï¸ (0:19:40) Introduction to linked list âŒ¨ï¸ (0:36:50) Arrays vs Linked Lists âŒ¨ï¸ (0:49:05) Linked List - Implementation in C/C++ âŒ¨ï¸ (1:03:02) Linked List in C/C++ - Inserting a node at beginning âŒ¨ï¸ (1:15:50) Linked List in C/C++ - Insert a node at nth position âŒ¨ï¸ (1:31:04) Linked List in C/C++ - Delete a node at nth position âŒ¨ï¸ (1:43:32) Reverse a linked list - Iterative method âŒ¨ï¸ (1:57:21) Print elements of a linked list in forward and reverse order using recursion âŒ¨ï¸ (2:11:43) Reverse a linked list using recursion âŒ¨ï¸ (2:20:38) Introduction to Doubly Linked List âŒ¨ï¸ (2:27:50) Doubly Linked List - Implementation in C/C++ âŒ¨ï¸ (2:43:09) Introduction to stack âŒ¨ï¸ (2:51:34) Array implementation of stacks âŒ¨ï¸ (3:04:42) Linked List implementation of stacks âŒ¨ï¸ (3:15:39) Reverse a string or linked list using stack. âŒ¨ï¸ (3:32:03) Check for balanced parentheses using stack âŒ¨ï¸ (3:46:14) Infix, Prefix and Postfix âŒ¨ï¸ (3:59:14) Evaluation of Prefix and Postfix expressions using stack âŒ¨ï¸ (4:14:00) Infix to Postfix using stack âŒ¨ï¸ (4:32:17) Introduction to Queues âŒ¨ï¸ (4:41:35) Array implementation of Queue âŒ¨ï¸ (4:56:33) Linked List implementation of Queue âŒ¨ï¸ (5:10:48) Introduction to Trees âŒ¨ï¸ (5:26:37) Binary Tree âŒ¨ï¸ (5:42:51) Binary Search Tree âŒ¨ï¸ (6:02:17) Binary search tree - Implementation in C/C++ âŒ¨ï¸ (6:20:52) BST implementation - memory allocation in stack and heap âŒ¨ï¸ (6:33:55) Find min and max element in a binary search tree âŒ¨ï¸ (6:39:41) Find height of a binary tree âŒ¨ï¸ (6:46:50) Binary tree traversal - breadth-first and depth-first strategies âŒ¨ï¸ (6:58:43) Binary tree: Level Order Traversal âŒ¨ï¸ (7:10:05) Binary tree traversal: Preorder, Inorder, Postorder âŒ¨ï¸ (7:24:33) Check if a binary tree is binary search tree or not âŒ¨ï¸ (7:41:01) Delete a node from Binary Search Tree âŒ¨ï¸ (7:59:27) Inorder Successor in a binary search tree âŒ¨ï¸ (8:17:23) Introduction to graphs âŒ¨ï¸ (8:34:05) Properties of Graphs âŒ¨ï¸ (8:49:19) Graph Representation part 01 - Edge List âŒ¨ï¸ (9:03:03) Graph Representation part 02 - Adjacency Matrix âŒ¨ï¸ (9:17:46) Graph Representation part 03 - Adjacency List\n","date":"Feb 20, 2022","img":"","permalink":"/courses/python/1_introduction/introduction/","series":["KhÃ³a há»c python cÄƒn báº£n"],"tags":["c++"],"title":"Giá»›i Thiá»‡u Vá» Python"},{"categories":null,"content":"Tools sinh sá»‘ ngáº«u nhiÃªn Viá»‡c phÃ¡t sinh má»™t con sá»‘ Ä‘Æ°á»£c gá»i lÃ  ngáº«u nhiÃªn Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i vÃ¬ nhiá»u thá»© trong tháº¿ giá»›i thá»±c Ä‘Æ°á»£c xem lÃ  Ä‘Æ°á»£c xuáº¥t hiá»‡n má»™t cÃ¡ch ngáº«u nhiÃªn. VÃ¬ váº­y, Ä‘á»ƒ mÃ´ phá»ng nhá»¯ng quÃ¡ trÃ¬nh xáº£y ra nhÆ° á»Ÿ tháº¿ giá»›i thá»±c, chÃºng ta cáº§n sinh cÃ¡c con sá»‘ má»™t cÃ¡ch ngáº«u nhiÃªn. VÃ­ dá»¥, hÃ¬nh dáº¡ng cá»§a Ä‘Ã¡m mÃ¢y, hÃ¬nh dáº¡ng cá»§a cÃ¡c dÃ£y nÃºi, rá»«ng cÃ¢y, khá»‘i Ä‘Ã¡, quÃ¡ trÃ¬nh phÃ¡t triá»ƒn táº¿ bÃ o, quÃ¡ trÃ¬nh tiáº¿n hÃ³a, vÃ¢n vÃ¢n vÃ  mÃ¢y mÃ¢y.\nhttps://en.wikipedia.org/wiki/Randomized_algorithm CÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m Ä‘á»c Ä‘á»ƒ hiá»ƒu thÃªm vá» cÃ¡c thuáº­t toÃ¡n random/giáº£ random.\nQuay \u0026nbsp; ","date":"Feb 20, 2022","img":"","permalink":"/utils/random/","series":null,"tags":["tools"],"title":"Sinh Sá»‘ Ngáº«u NhiÃªn"},{"categories":null,"content":" Giá»›i thiá»‡u BÆ°á»›c 1: Táº¡o bÃ n cá» vÃ  sinh nÆ°á»›c Ä‘i BÆ°á»›c 2: HÃ m lÆ°á»£ng giÃ¡ BÆ°á»›c 3. TÃ¬m kiáº¿m cÃ¢y sá»­ dá»¥ng minimax BÆ°á»›c 4: Cáº¯t tá»‰a Alpha - Beta Giá»›i thiá»‡u Cá» tÆ°á»›ng lÃ  má»™t mÃ´n thá»ƒ thao khÃ¡ phá»• biáº¿n á»Ÿ Viá»‡t Nam. CÃ¡c báº¡n cÃ³ thá»ƒ báº¯t gáº·p cÃ¡c bÃ n cá» á»Ÿ cÃ¡c con háº»m cá»§a má»—i gÃ³c phá»‘. Hoáº·c lÃ  khi cÃ¡c bá»™ bÃ n gháº¿ Ä‘Ã¡ thÃ¬ ngÆ°á»i mua cÅ©ng thÆ°á»ng nhá» thá»£ kháº¯c lÃªn bÃ n cá» tÆ°á»›ng Ä‘á»ƒ hÃ ng xÃ³m lÃ¡ng giá»ng giáº£i trÃ­ ngÃ y cuá»‘i tuáº§n. Trong bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ hÆ°á»›ng dáº«n step by step á»©ng dá»¥ng chÆ¡i game cá» tÆ°á»›ng Ä‘Æ¡n giáº£n vá»›i má»™t chÃºt AI. Hi vá»ng sáº½ giÃºp Ä‘Æ°á»£c cÃ¡c báº¡n trÃªn con Ä‘Æ°á»ng thá»±c hÃ nh mÃ¡y há»c.\nCÃ¡c viá»‡c cáº§n lÃ m:\nTáº¡o bÃ n cá» vÃ  sinh nÆ°á»›c Ä‘i\nLÆ°á»£ng giÃ¡ bÃ n cá»\nÃp dá»¥ng minimax\nÃp dá»¥ng cáº¯t tá»‰a alpha, beta\nBáº¡n cÃ³ thá»ƒ chÆ¡i thá»­ game cá» tÆ°á»›ng mÃ¬nh cÃ³ post á»Ÿ Ä‘Ã¢y: https://www.phamduytung.com/games/china_chess/\nBÆ°á»›c 1: Táº¡o bÃ n cá» vÃ  sinh nÆ°á»›c Ä‘i MÃ¬nh khÃ´ng cÃ³ gá»i láº¯m trong viá»‡c thiáº¿t káº¿ máº¥y icon cho máº¥y con tÆ°á»›ng, sÄ©, tÆ°á»£ng. NgoÃ i ra, cÃ´ng viá»‡c chÃ­nh cá»§a chÃºng ta lÃ  pháº§n lÃ m sao cho mÃ¡y tá»± Ä‘Ã¡nh Ä‘Æ°á»£c, nÃªn pháº§n nÃ y mÃ¬nh sáº½ xÃ i cÃ¡c open source cÃ³ sáºµn, lÆ°á»£n lá» má»™t chÃºt trÃªn máº¡ng thÃ¬ mÃ¬nh Ä‘Ã£ lá»¥m Ä‘Æ°á»£c cÃ¡i bÃ n cá» á»Ÿ link https://github.com/lengyanyu258/xiangqiboardjs vÃ  thÆ° viá»‡n sinh nÆ°á»›c Ä‘i xiangqi.js. ThÆ° viá»‡n xiangqi.js Ä‘Ã£ cÃ³ sáºµn cÃ¡c hÃ m kiá»ƒm tra tÃ­nh há»£p lá»‡ cá»§a nÆ°á»›c Ä‘i, nÃªn mÃ¬nh chá»‰ viá»‡c láº¥y ra rá»“i dÃ¹ng thÃ´i, khá»i máº¥t cÃ´ng pháº£i viáº¿t láº¡i.\nBÃ n cá» Ä‘Æ°á»£c chia lÃ m 2 Ä‘á»™i, lÃ  Ä‘á»™i Ä‘en (black, kÃ½ hiá»‡u b) vÃ  Ä‘á»™i Ä‘á» (red , kÃ½ hiá»‡u r), má»—i Ä‘á»™i gá»“m 16 quÃ¢n, bao gá»“m 1 con tÆ°á»›ng (General hoáº·c king , kÃ½ hiá»‡u k), 2 con sá»¹ (Advisor hoáº·c guards, ministers, kÃ½ hiá»‡u lÃ  a), 2 con tÆ°á»£ng (Elephants hoáº·c bishops - kÃ½ hiá»‡u lÃ  b), 2 con mÃ£ (Horses hoáº·c knights - kÃ½ hiá»‡u lÃ  n, do chá»¯ k trÃ¹ng vá»›i king lÃ  con tÆ°á»›ng, nÃªn ngÆ°á»i ta xÃ i chá»¯ n), 2 con xe (Chariot hoáº·c rooks - kÃ½ hiá»‡u lÃ  r), 2 con phÃ¡o (canons, kÃ½ hiá»‡u lÃ  c ), 5 con chá»‘t (Soldiers , kÃ½ hiá»‡u lÃ  p ( do con chá»‘t á»Ÿ cá» Ä‘en vÃ  cá» Ä‘á» cÃ³ phiÃªn Ã¢m tiáº¿ng trung khÃ¡c nhau, chá»‘t cá» Ä‘en Ä‘á»c gáº§n giá»‘ng chá»¯ \u0026ldquo;zÃº\u0026rdquo; (\u0026ldquo;pawn\u0026rdquo; hoáº·c \u0026ldquo;private\u0026rdquo; - tiáº¿ng anh), cÃ²n chá»‘t cá» Ä‘á» Ä‘á»c lÃ  bing (\u0026ldquo;soldier\u0026rdquo; - tiáº¿ng anh) )).\nTá»•ng cá»™ng, ta cÃ³ tÆ°á»›ng, sá»¹, tÆ°á»£ng, mÃ£, xe, phÃ¡o, chá»‘t, 7 loáº¡i quÃ¢n, tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 7 kÃ½ hiá»‡u, tá»• há»£p vá»›i 2 Ä‘á»™i lÃ  Ä‘á» vÃ  Ä‘en, tá»• há»£p vá»›i nhau, ta xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c\nÄá»ƒ báº¯t Ä‘áº§u, chÃºng ta sáº½ code má»™t hÃ m random bÆ°á»›c Ä‘i Ä‘Æ¡n giáº£n. HÃ m cÃ³ nhiá»‡m vá»¥ láº¥y ngáº«u nhiÃªn má»™t bÆ°á»›c Ä‘i trong danh sÃ¡ch cÃ¡c bÆ°á»›c cÃ³ thá»ƒ Ä‘i, sau Ä‘Ã³ mÃ¡y sáº½ Ä‘Ã¡nh bÆ°á»›c Ä‘i Ä‘Ã³.\n1 2 3function makeRandomMove () { 4 let possibleMoves = game.moves(); 5 6 // game over 7 if (possibleMoves.length === 0) return; // KhÃ´ng cÃ²n nÆ°á»›c nÃ o cÃ³ thá»ƒ Ä‘i, end game 8 9 let randomIdx = Math.floor(Math.random() * possibleMoves.length); // bá»‘c Ä‘áº¡i 1 nÆ°á»›c Ä‘i trong danh sÃ¡ch cÃ¡c bÆ°á»›c cÃ³ thá»ƒ Ä‘i 10 game.move(possibleMoves[randomIdx]); 11 board.position(game.fen()); 12} Do thuáº­t toÃ¡n chÃºng ta cho mÃ¡y cháº¡y khÃ¡ lÃ  ngá»‘c, nÃªn nÃ³ Ä‘Ã¡nh cÅ©ng hÆ¡i ngá»‘c. :)\nBÆ°á»›c 2: HÃ m lÆ°á»£ng giÃ¡ Dá»±a vÃ o má»©c Ä‘á»™ cÆ¡ Ä‘á»™ng, táº§m quang trá»ng cá»§a má»—i quÃ¢n lÃ­nh trÃªn bÃ n cá», chÃºng ta sáº½ gÃ¡n cho má»—i quÃ¢n cá» má»™t trá»ng sá»‘ khÃ¡c nhau thá»ƒ hiá»‡n Ä‘iá»u Ä‘Ã³.\nVÃ­ dá»¥, chÃºng ta set cÃ¡c trá»ng sá»‘ nhÆ° sau:\ntÆ°á»›ng cá»§a ta lÃ  900 Ä‘iá»ƒm, tÆ°á»›ng cá»§a Ä‘á»‘i thá»§ lÃ  -900 Ä‘iá»ƒm\nsá»¹ cá»§a ta lÃ  20 Ä‘iá»ƒm, sá»¹ cá»§a Ä‘á»‘i thá»§ lÃ  -20 Ä‘iá»ƒm\ntÆ°á»£ng cá»§a ta lÃ  20 Ä‘iá»ƒm, tÆ°á»£ng cá»§a Ä‘á»‘i thá»§ lÃ  -20 Ä‘iá»ƒm\nmÃ£ cá»§a ta lÃ  40 Ä‘iá»ƒm, mÃ£ cá»§a Ä‘á»‘i thá»§ lÃ  -40 Ä‘iá»ƒm\nxe cá»§a ta lÃ  90 Ä‘iá»ƒm, xe cá»§a Ä‘á»‘i thá»§ lÃ  -90 Ä‘iá»ƒm\nphÃ¡o cá»§a ta lÃ  45 Ä‘iá»ƒm, phÃ¡o cá»§a Ä‘á»‘i thá»§ lÃ  -45 Ä‘iá»ƒm\nchá»‘t cá»§a ta lÃ  15 Ä‘iá»ƒm, chá»‘t cá»§a Ä‘á»‘i thá»§ lÃ  -15 Ä‘iá»ƒm\nHÃ m lÆ°á»£ng giÃ¡ á»Ÿ trÃªn khÃ¡ ngÃ¢y thÆ¡, má»i quÃ¢n cá» Ä‘á»u cÃ³ Ä‘iá»ƒm ngang nhau, khÃ´ng quan tÃ¢m vá»‹ trÃ­ Ä‘á»©ng cá»§a nÃ³.\nTrÃªn thá»±c táº¿, chÃºng ta tháº¥y ráº±ng, con tÆ°á»›ng á»Ÿ vá»‹ trÃ­ trung tÃ¢m thÆ°á»ng lÃ  an toÃ n nháº¥t, má»™t khi tÆ°á»›ng leo lÃªn láº§u 1 hoáº·c leo láº§u 2, nghÄ©a lÃ  con tÆ°á»›ng cÃ³ kháº£ nÄƒng bá»‹ Ä‘á»™t tá»­ cao hÆ¡n, nÃªn chÃºng ta pháº£i tinh chá»‰nh láº¡i Ä‘iá»ƒm cá»§a con tÆ°á»›ng trong trÆ°á»ng há»£p nÃ y.\nMá»™t vÃ­ dá»¥ ná»¯a lÃ  vá»‹ trÃ­ con mÃ£, mÃ£ gáº§n vá»›i thÃ nh cá»§a tÆ°á»›ng Ä‘á»‹ch hÆ¡n thÃ¬ kháº£ nÄƒng con xe chiáº¿u bÃ­ tÆ°á»›ng Ä‘á»‹ch sáº½ cao hÆ¡n con mÃ£ chÆ°a qua sÃ´ng.\nGiÃ¡ trá»‹ lÆ°á»£ng giÃ¡ cho cá» tÆ°á»›ng, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o á»Ÿ link https://github.com/markdirish/xiangqi/blob/master/evaluate.js\nChÃºng ta sáº½ duyá»‡t láº§n lÆ°á»£t tá»« trÃ¡i qua pháº£i, tá»« trÃªn xuá»‘ng dÆ°á»›i, tÃ­nh Ä‘iá»ƒm cá»§a bÃ n cá» hiá»‡n táº¡i.\nHÃ m lÆ°á»£ng giÃ¡ cá»§a bÃ n cá» xÃ©t nhÆ° sau:\n1 2 3 4function evaluateBoard(board) { 5 var totalEvaluation = 0; 6 for (var i = 0; i \u0026lt; 10; i++) { 7 for (var j = 0; j \u0026lt; 9; j++) { 8 totalEvaluation = totalEvaluation + getPieceValue(board[i][j], i ,j); 9 } 10 } 11 return totalEvaluation; 12} 13 14 15 16function getPieceValue(piece, x, y) { 17 if (piece === null) { 18 return 0; 19 } 20 var getAbsoluteValue = function (piece, isRed, x ,y) { 21 if (piece.type === \u0026#39;p\u0026#39;) { //chá»‘t 22 return 15 + ( isRed ? pEvalRed[x][y] : pEvalBlack[x][y] ); 23 } else if (piece.type === \u0026#39;r\u0026#39;) { //Xe 24 return 90 +( isRed ? rEvalRed[x][y] : rEvalBlack[x][y] ); 25 } else if (piece.type === \u0026#39;c\u0026#39;) { //phÃ¡o 26 return 45 +( isRed ? cEvalRed[x][y] : cEvalBlack[x][y] ); 27 } else if (piece.type === \u0026#39;n\u0026#39;) { // mÃ£ 28 return 40 +( isRed ? nEvalRed[x][y] : nEvalBlack[x][y] ); 29 } else if (piece.type === \u0026#39;b\u0026#39;) { // tÆ°á»£ng 30 return 20 +( isRed ? bEvalRed[x][y] : bEvalBlack[x][y] ); 31 } else if (piece.type === \u0026#39;a\u0026#39;) { // sá»¹ 32 return 20 +( isRed ? aEvalRed[x][y] : aEvalBlack[x][y] ); 33 } else if (piece.type === \u0026#39;k\u0026#39;) { // tÆ°á»›ng 34 return 900 +( isRed ? kEvalRed[x][y] : kEvalBlack[x][y] ); 35 } 36 throw \u0026#34;Unknown piece type: \u0026#34; + piece.type; 37 }; 38 39 var absoluteValue = getAbsoluteValue(piece, piece.color === \u0026#39;r\u0026#39;, x ,y); 40 return piece.color === \u0026#39;r\u0026#39; ? absoluteValue : -absoluteValue; 41} BÃ¢y giá», chÃºng ta chá»‰ cáº§n duyá»‡t qua toÃ n bá»™ cÃ¡c nÆ°á»›c cÃ³ thá»ƒ Ä‘i, tÃ­nh xem nÆ°á»›c Ä‘i nÃ o cÃ³ Ä‘iá»ƒm sá»‘ lÃ  lá»›n nháº¥t, thÃ¬ mÃ¡y sáº½ Ä‘i theo nÆ°á»›c Ä‘i Ä‘Ã³.\n1 2 3function getBestMove(game) { 4 5var newGameMoves = game.moves(); 6var bestMove = null; 7// set Ä‘áº¡i má»™t sá»‘ Ã¢m vÃ´ háº¡n 8var bestValue = -9999; 9 10for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 11 var newGameMove = newGameMoves[i]; 12 game.move(newGameMove); 13 14 var boardValue = -evaluateBoard(game.board()) 15 game.undo(); 16 if (boardValue \u0026gt; bestValue) { 17 bestValue = boardValue; 18 bestMove = newGameMove 19 } 20} 21 22return bestMove; 23 24}; VÃ¬ váº­y, ngoÃ i viá»‡c xÃ©t Ä‘iá»ƒm cho cÃ¡c loáº¡i quÃ¢n, chÃºng ta sáº½ cÃ³ má»™t báº£ng xÃ©t Ä‘iá»ƒm cho cÃ¡c con\nKáº¿t quáº£ cÃ³ váº» tá»‘t hÆ¡n so vá»›i viá»‡c random bÆ°á»›c Ä‘i trÆ°á»›c Ä‘Ã³, nhÆ°ng thuáº­t toÃ¡n váº«n cÃ²n hÆ¡i dá»‘t dá»‘t xÃ­u, do mÃ¡y chá»‰ tÃ­nh 1 nÆ°á»›c Ä‘i vÃ  chá»n ra nÆ°á»›c Ä‘i tá»‘t nháº¥t. NÃªn mÃ¡y chÆ°a cÃ³ cÃ¡i nhÃ¬n dÃ i hÆ¡n. CÃ³ nhiá»u cÃ¡ch Ä‘á»ƒ cho mÃ¡y cÃ³ thá»ƒ cÃ³ gÃ³c nhÃ¬n xa hÆ¡n vá» tháº¿ cá»¥c cá»§a bÃ n cá», má»™t trong cÃ¡c cÃ¡ch Ä‘Æ°á»£c giá»›i thiá»‡u á»Ÿ Ä‘Ã¢y lÃ  sá»­ dá»¥ng minimax\nBÆ°á»›c 3. TÃ¬m kiáº¿m cÃ¢y sá»­ dá»¥ng minimax Thuáº­t toÃ¡n minimax thuá»™c nhÃ³m duyá»‡t theo chiá»u sÃ¢u (depth first search). Hai ngÆ°á»i chÆ¡i, má»™t ngÆ°á»i Ä‘Æ°á»£c gá»i lÃ  MAX, ngÆ°á»i cÃ²n láº¡i gá»i lÃ  MIN. Thuáº­t toÃ¡n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tÃ¬m nÆ°á»›c Ä‘i tá»‘i Æ°u cho ngÆ°á»i MAX. NgÆ°á»i MAX sáº½ giá»¯ node gá»‘c, láº§n lÆ°á»£t duyá»‡t Ä‘á»‡ quy qua táº¥t cáº£ cÃ¡c node con theo chiá»u sÃ¢u nháº¥t Ä‘á»‹nh Ä‘áº¿n khi duyá»‡t qua táº¥t cáº£ cÃ¡c node hoáº·c lÃ  tÃ¬m Ä‘Æ°á»£c má»™t Ä‘Æ°á»ng Ä‘i mÃ  Ä‘áº¡t MAX.\nChi tiáº¿t hÆ¡n, ngÆ°á»i MAX sáº½ Ä‘i Ä‘áº§u tiÃªn. Nhiá»‡m vá»¥ cá»§a MAX lÃ  tÃ¬m nÆ°á»›c Ä‘i sao cho Ä‘iá»ƒm sá»‘ cá»§a mÃ¬nh lÃ  cao nháº¥t, nhiá»‡m vá»¥ cá»§a MIN lÃ  tÃ¬m nÆ°á»›c Ä‘i Ä‘á»ƒ cá»±c tiá»ƒu hoÃ¡ Ä‘iá»ƒm sá»‘ cá»§a MAX.\nCÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c thÃªm á»Ÿ link https://en.wikipedia.org/wiki/Minimax.\nÄá»ƒ triá»ƒn khai minimax, Ä‘áº§u tiÃªn, chÃºng ta sáº½ sá»­a láº¡i hÃ m getBestMove á»Ÿ trÃªn, thay vÃ¬ gá»i lÆ°á»£ng giÃ¡ bÃ n cá» evaluateBoard, chÃºng ta sáº½ gá»i hÃ m minimax\n1 2 3function minimaxRoot(depth, game, isMaximisingPlayer) { 4 var newGameMoves = game.moves(); 5 var bestMove = -9999; 6 var bestMoveFound; 7 8 for(var i = 0; i \u0026lt; newGameMoves.length; i++) { 9 var newGameMove = newGameMoves[i] 10 game.move(newGameMove); 11 var value = minimax(depth - 1, game, !isMaximisingPlayer); 12 game.undo(); 13 if(value \u0026gt;= bestMove) { 14 bestMove = value; 15 bestMoveFound = newGameMove; 16 } 17 } 18 return bestMoveFound; 19} vá»›i hÃ m minimax cÅ©ng cÃ¹ng Ã½ tÆ°á»Ÿng vá»›i hÃ m getBestMove á»Ÿ trÃªn, nhÆ°ng ta sáº½ gá»i Ä‘á»‡ quy, luÃ¢n phiÃªn tÃ­nh Ä‘iá»ƒm mÃ¡y, sau Ä‘Ã³ tÃ­nh Ä‘iá»ƒm ngÆ°á»i \u0026hellip; theo Ä‘á»™ sÃ¢u ta Ä‘Ã£ thiáº¿t láº­p, Ä‘á»ƒ tÃ¬m ra Ä‘Æ°á»ng Ä‘i cÃ³ sá»‘ Ä‘iá»ƒm lÃ  lá»›n nháº¥t.\n1 2function minimax (depth, game, isMaximisingPlayer) { 3 if (depth === 0) { 4 return -evaluateBoard(game.board()); 5 } 6 var newGameMoves = game.moves(); 7 if (isMaximisingPlayer) { 8 var bestMove = -9999; 9 for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 10 game.move(newGameMoves[i]); 11 bestMove = Math.max(bestMove, minimax(depth - 1, game, !isMaximisingPlayer)); 12 game.undo(); 13 } 14 return bestMove; 15 } else { 16 var bestMove = 9999; 17 for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 18 game.move(newGameMoves[i]); 19 bestMove = Math.min(bestMove, minimax(depth - 1, game, !isMaximisingPlayer)); 20 game.undo(); 21 } 22 return bestMove; 23 } 24}; Thuáº­t toÃ¡n nÃ y hoáº¡t Ä‘á»™ng khÃ¡ hiá»‡u quáº£, nhÆ°ng cÃ³ má»™t Ä‘iá»ƒm yáº¿u lÃ  nÃ³ sáº½ vÃ©t cáº¡n toÃ n bá»™ cÃ¡c trÆ°á»ng há»£p Ä‘á»ƒ tÃ¬m ra Ä‘Æ°á»ng Ä‘i tá»‘i Æ°u nháº¥t. VÃ¬ váº­y, vá»›i giÃ¡ trá»‹ Ä‘á»™ sÃ¢u cÃ ng lá»›n thÃ¬ thuáº­t toÃ¡n cháº¡y cÃ ng cháº­m.\nBÆ°á»›c 4: Cáº¯t tá»‰a Alpha - Beta Cáº¯t tá»‰a Alpha - Beta lÃ  má»™t phÆ°Æ¡ng phÃ¡p tá»‘i Æ°u hoÃ¡ cá»§a thuáº­t toÃ¡n minimax, phÆ°Æ¡ng phÃ¡p nÃ y giÃºp chÃºng ta bá» qua má»™t vÃ i nhÃ¡nh trong quÃ¡ trÃ¬nh tÃ¬m kiáº¿m, lÃ m giá»›i háº¡n pháº¡m vi tÃ¬m kiáº¿m, giÃºp mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng nhanh hÆ¡n.\nThuáº­t toÃ¡n sáº½ hoáº¡t Ä‘á»™ng hiá»‡u quáº£ hÆ¡n náº¿u nhá»¯ng bÆ°á»›c tÃ¬m kiáº¿m Ä‘áº§u tiÃªn lÃ  nhá»¯ng nÆ°á»›c Ä‘i tá»‘t nháº¥t :)\nHÃ m minimax vá»›i alpla, beta Ä‘Æ°á»£c viáº¿t láº¡i nhÆ° sau\n1 2 3 4function minimax(depth, game, alpha, beta, isMaximisingPlayer) { 5 positionCount++; 6 if (depth === 0) { 7 return -evaluateBoard(game.board()); 8 } 9 10 var newGameMoves = game.moves(); 11 12 if (isMaximisingPlayer) { 13 var bestMove = -9999; 14 for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 15 game.moves(newGameMoves[i]); 16 bestMove = Math.max(bestMove, minimax(depth - 1, game, alpha, beta, !isMaximisingPlayer)); 17 game.undo(); 18 alpha = Math.max(alpha, bestMove); 19 if (beta \u0026lt;= alpha) { 20 return bestMove; 21 } 22 } 23 return bestMove; 24 } else { 25 var bestMove = 9999; 26 for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 27 game.moves(newGameMoves[i]); 28 bestMove = Math.min(bestMove, minimax(depth - 1, game, alpha, beta, !isMaximisingPlayer)); 29 game.undo(); 30 beta = Math.min(beta, bestMove); 31 if (beta \u0026lt;= alpha) { 32 return bestMove; 33 } 34 } 35 return bestMove; 36 } 37} Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t. Xin chÃ o vÃ  háº¹n gáº·p láº¡i cÃ¡c báº¡n á»Ÿ bÃ i viáº¿t káº¿ tiáº¿p.\nCÃ¡c báº¡n cÃ³ thá»ƒ chÆ¡i game á»Ÿ Ä‘Ã¢y nha , link https://www.phamduytung.com/games/china_chess/\nMÃ¬nh sáº½ update dáº§n giao diá»‡n Ä‘á»ƒ cho game trá»Ÿ nÃªn Ä‘áº¹p Ä‘áº¹p hÆ¡n.\n","date":"Aug 12, 2021","img":"https://unsplash.it/1920/1080?image=30","permalink":"/blog/2021-08-12-china_chess_alpha_beta_ai/","series":null,"tags":["Machine Learning","Normalization","Deep Learning","China Chess","Cá» TÆ°á»›ng","MiniMax","Alpha Beta Pruning"],"title":"XÃ¢y Dá»±ng ChÆ°Æ¡ng TrÃ¬nh AI ÄÆ¡n Giáº£n Cho Game Cá» TÆ°á»›ng"},{"categories":null,"content":" Giá»›i thiá»‡u VÃ²ng Ä‘á»i khi xÃ¢y dá»±ng chÆ°Æ¡ng trÃ¬nh mÃ¡y há»c MLOps lÃ  gÃ¬ VÃ­ dá»¥ sá»­ dá»¥ng Pycaret Business Problem Exploratory Data Analysis Data Preparation Model Training \u0026amp; Selection Deployment \u0026amp; Monitoring Giá»›i thiá»‡u PyCaret lÃ  thÆ° viá»‡n open-source machinelearning trong python, ThÆ° viá»‡n tÃ­ch há»£p sáºµn cÃ¡c mÃ´ hÃ¬nh cáº§n thiáº¿t, giÃºp chÃºng ta train mÃ´ hÃ¬nh má»™t láº§n trÃªn nhiá»u thuáº­t toÃ¡n mÃ¡y há»c khÃ¡c nhau. ThÆ° viá»‡n cÃ³ há»— trá»£ train trÃªn GPU. PhiÃªn báº£n hiá»‡n táº¡i lÃºc mÃ¬nh viáº¿t bÃ i viáº¿t nÃ y lÃ  2.3.3. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o thÃ´ng tin thÃªm cá»§a thÆ° viá»‡n á»Ÿ link github https://github.com/pycaret/pycaret\nÄá»ƒ cÃ i Ä‘áº·t pycaret, cÃ¡c báº¡n sá»­ dá»¥ng lá»‡nh sau\n1 2pip install pycaret 3 4pip install pycaret[full] Báº£n full cÃ³ cÃ i thÃªm nhiá»u gÃ³i thÆ° viá»‡n khÃ¡c, cÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o cÃ¡c gÃ³i thÆ° viá»‡n Ä‘Æ°á»£c cÃ i thÃªm á»Ÿ báº£n full qua link https://github.com/pycaret/pycaret/blob/master/requirements-optional.txt\nMÃ¬nh quan sÃ¡t sÆ¡ qua thÃ¬ bÃ n full cÃ³ cÃ i thÃªm máº¥y cÃ¡i thÆ° viá»‡n káº¿t ná»‘i aws vÃ  gcs khÃ¡ dÆ° thá»«a, mÃ¬nh khÃ´ng xÃ i tá»›i, vá»›i á»• cá»©ng mÃ¡y mÃ¬nh cÅ©ng cÃ³ háº¡n. NÃªn mÃ¬nh chá»‰ cÃ i báº£n cÆ¡ báº£n vÃ  cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t nhÆ° scikit-optimize, tune-sklearn, xgboost \u0026hellip;\nVÃ²ng Ä‘á»i khi xÃ¢y dá»±ng chÆ°Æ¡ng trÃ¬nh mÃ¡y há»c Business Problem : NhÆ° nhá»¯ng á»©ng dá»¥ng khÃ¡c, má»™t á»©ng dá»¥ng mÃ¡y há»c cÅ©ng Ä‘Æ°á»£c báº¯t Ä‘áº§u báº±ng má»™t váº¥n Ä‘á» thá»±c táº¿ trong cuá»™c sá»‘ng, trong cÃ´ng viá»‡c. Phá»¥ thuá»™c vÃ o sá»± phá»©c táº¡p cá»§a váº¥n Ä‘á», vÃ  cÃ¡c chi phÃ­ liÃªn quan vá» máº·t kinh doanh, chÃºng ta sáº½ phÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ liÃªn quan Ä‘á»ƒ xem xÃ©t cÃ³ cáº§n thiáº¿t pháº£i phÃ¡t triá»ƒn chÆ°Æ¡ng trÃ¬nh sá»­ dá»¥ng mÃ¡y há»c hoáº·c tÃ¬m má»™t giáº£i phÃ¡p thay tháº¿ tá»‘t hÆ¡n theo toÃ n bá»™ tiÃªu chÃ­ (thuyáº¿t vá»‹ lá»£i).\nData Sourcing \u0026amp; ETL : Sau khi hiá»ƒu bÃ i toÃ¡n, chÃºng ta sáº½ thu tháº­p cÃ¡c dá»¯ liá»‡u cáº§n thiáº¿t.\nExploratory Data Analysis (EDA) : Dá»¯ liá»‡u á»Ÿ trÃªn lÃ  dá»¯ liá»‡u thÃ´, chÆ°a qua xá»­ lÃ½, nÃªn cÃ³ thá»ƒ sáº½ bá»‹ thu tháº­p khÃ´ng Ä‘á»§, thu tháº­p thiáº¿u. ChÃºng ta cáº§n pháº£i náº¯m rÃµ dá»¯ liá»‡u, phÃ¢n tÃ­ch sá»± cÃ¢n báº±ng/ Ä‘á»™ lá»‡ch cá»§a dá»¯ liá»‡u, xá»­ lÃ½ nhiá»…u, xem phÃ¢n bá»‘ cá»§a dá»¯ liá»‡u, xem Ä‘á»™ tÆ°Æ¡ng quan giá»¯a cÃ¡c Ä‘áº·c trÆ°ng, \u0026hellip;\nData Preparation : Sau khi phÃ¢n tÃ­ch, xÃ o náº¥u dá»¯ liá»‡u Ä‘áº¹p Ä‘áº½, trÆ¡n tru, chÃºng ta sáº½ báº¯t Ä‘áº§u chuáº©n bá»‹ dá»¯ liá»‡u cho mÃ´ hÃ¬nh train, vÃ­ dá»¥ chia dá»¯ liá»‡u thÃ nh táº­p train,test,validation, one-hot encoding, feature engineering, feature selection \u0026hellip;\nModel Training \u0026amp; Selection : ÄÃ¢y lÃ  pháº§n nhÃ m chÃ¡n nháº¥t, thá»­ nghiá»‡m dá»¯ liá»‡u vá»›i cÃ¡c mÃ´ hÃ¬nh vÃ  tham sá»‘ khÃ¡c nhau, lá»±a chá»n mÃ´ hÃ¬nh cÃ³ káº¿t quáº£ tá»‘t nháº¥t trÃªn táº­p validation. chá» mÃ´ hÃ¬nh train xong\nDeployment \u0026amp; Monitoring : Sau khi cÃ³ Ä‘Æ°á»£c mÃ´ hÃ¬nh tá»‘t nháº¥t, chÃºng ta sáº½ deploy á»©ng dá»¥ng, vÃ  theo dÃµi, tÆ°Æ¡ng tá»± nhÆ° nhá»¯ng á»©ng dá»¥ng khÃ¡c thÃ´i.\nTrong viá»‡c phÃ¡t triá»ƒn pháº§n má»m, cÃ³ má»™t khÃ¡i niá»‡m Ä‘ang ná»•i gáº§n Ä‘Ã¢y (lÃºc mÃ¬nh Ä‘ang viáº¿t bÃ i viáº¿t nÃ y) lÃ  devops. GiÃºp cho má»™t sá»‘ cÃ´ng viá»‡c nhÃ m chÃ¡m Ä‘Æ°á»£c thá»±c hiá»‡n má»™t cÃ¡ch tá»± Ä‘á»™ng. Trong mÃ¡y há»c, chÃºng ta sáº½ cÃ³ khÃ¡i niá»‡m MLOps.\nMLOps lÃ  gÃ¬ Äá»‹nh nghÄ©a theo wikipedia:\n1 2MLOps or ML Ops is a set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently Má»™t bá»©c hÃ¬nh báº±ng váº¡n cÃ¢u chá»¯, xem bá»©c hÃ¬nh trÃªn, cÃ¡c báº¡n cháº¯c vá» cÆ¡ báº£n cÅ©ng hiá»ƒu cÃ´ng viá»‡c cá»§a MLOps lÃ  gÃ¬ rá»“i hen.\nÃ€, Ä‘á»c Ä‘áº¿n Ä‘Ã¢y, cÃ¡c báº¡n cÃ³ láº½ sáº½ tháº¯c máº¯c lÃ  sao Ä‘ang giá»›i thiá»‡u Pycaret, mÃ  sao láº¡i lang mang qua MLOps lÃ m gÃ¬? ThÃ¬ mÃ¬nh cÅ©ng tráº£ lá»i luÃ´n lÃ  Pycaret lÃ  má»™t trong nhá»¯ng package giÃºp chÃºng ta MLOps ==\u0026gt; bá»›t nhÃ m chÃ¡n khi phÃ¡t triá»ƒn á»©ng dá»¥ng machine learning rá»“i Ä‘Ã³.\nVÃ­ dá»¥ sá»­ dá»¥ng Pycaret MÃ¬nh sáº½ trÃ¬nh bÃ y pháº§n nÃ y Ä‘Ãºng theo machine learning life cycle, Ä‘á»ƒ Ä‘áº£m báº£o viá»‡c giáº£ láº­p sÃ¡t vá»›i thá»±c táº¿.\nBusiness Problem BÃ i toÃ¡n Sarah Gets a Diamond, link chi tiáº¿t cá»§a bÃ i toÃ¡n á»Ÿ https://hbsp.harvard.edu/product/UV0869-PDF-ENG. BÃ i toÃ¡n nÃ y giÃºp ngÆ°á»i há»c khoÃ¡ Ä‘Ã³ hiá»ƒu Ä‘Æ°á»£c sá»± khÃ¡c nhau cá»§a linear-model, log-liner model, log-log mode. Náº¿u cÃ¡c báº¡n cÃ³ nhu cáº§u tÃ¬m hiá»ƒu cÃ¡c model trÃªn, cÃ³ thá»ƒ Ä‘Äƒng kÃ½ khoÃ¡ há»c trÃªn hen. á» Ä‘Ã¢y, mÃ¬nh chá»‰ láº¥y mÃ´ táº£ chi tiáº¿t vÃ  data cá»§a khoÃ¡ há»c.\nBá»‘i cáº£nh cá»§a bÃ i toÃ¡n diá»…n ra nhÆ° sau. Grey muá»‘n mua má»™t chiáº¿c nháº«n Ä‘á»ƒ cáº§u hÃ´n Sarah. Sau má»™t há»“i tham kháº£o máº¥y tháº±ng báº¡n tá»« thá»i ná»‘i khá»‘, Grey quyáº¿t Ä‘á»‹nh sáº½ mua nháº«n kim cÆ°Æ¡ng. Grey tiáº¿n hÃ nh Ä‘i thu tháº­p thÃ´ng tin cá»§a 6000 chiáº¿c nháº«n kim cÆ°Æ¡ng khÃ¡c nhau vá» giÃ¡, mÃ u sáº¯c, hÃ¬nh dáº¡ng \u0026hellip;\nMay máº¯n thay Grey cÃ³ share dá»¯ liá»‡u nÃ y cho Pycaret, vÃ  chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng dá»¯ liá»‡u trÃªn báº±ng cÃ¡ch load tá»« dataset cá»§a Pycaret\n1 2# load the dataset from pycaret 3from pycaret.datasets import get_data 4data = get_data(\u0026#39;diamond\u0026#39;) VÃ  top 5 dá»¯ liá»‡u máº«u mÃ  Grey thu tháº­p lÃ :\n1 2Carat Weight\tCut\tColor\tClarity\tPolish\tSymmetry\tReport\tPrice 30\t1.10\tIdeal\tH\tSI1\tVG\tEX\tGIA\t5169 41\t0.83\tIdeal\tH\tVS1\tID\tID\tAGSL\t3470 52\t0.85\tIdeal\tH\tSI1\tEX\tEX\tGIA\t3183 63\t0.91\tIdeal\tE\tSI1\tVG\tVG\tGIA\t4370 74\t0.83\tIdeal\tG\tSI1\tEX\tEX\tGIA\t3171 Exploratory Data Analysis BÆ°á»›c nÃ y sáº½ phá»¥ thuá»™c vÃ o kinh nghiá»‡m cá»§a ngÆ°á»i lÃ m data. Kinh nghiá»‡m cá»§a mÃ¬nh thÃ¬ Ä‘áº§u tiÃªn sáº½ phÃ¢n tÃ­ch phÃ¢n bá»‘ dá»¯ liá»‡u vÃ  phÃ¢n tÃ­ch má»‘i tÆ°Æ¡ng quan giá»¯a cÃ¡c biáº¿n liÃªn tá»¥c trÆ°á»›c Ä‘Ã£, sau Ä‘Ã³ sáº½ phÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ chuyÃªn sÃ¢u hÆ¡n dá»±a vÃ o cáº£m quan nháº­n Ä‘Æ°á»£c tá»« hai cÃ¡i trÃªn.\nQuan sÃ¡t dá»¯ liá»‡u, chÃºng ta tháº¥y ráº±ng chá»‰ cÃ³ hai thuá»™c tÃ­nh Carat Weight vÃ  Price thuá»™c nhÃ³m numerical variable, cÃ¡c thuá»™c tÃ­nh cÃ²n láº¡i thuá»™c nhÃ³m categorical variable, nÃªn mÃ¬nh khÃ´ng cáº§n tÃ­nh Ä‘á»™ tÆ°Æ¡ng quan lÃ m gÃ¬ háº¿t.\nMÃ¬nh cÃ³ há»c tá»« link á»Ÿ tÃ i liá»‡u tham kháº£o phÃ­a dÆ°á»›i, thÆ° viá»‡n plotly.express, mÃ¬nh tham kháº£o thá»­ thÃ¬ tháº¥y hÃ m váº½ scatter cá»§a thÆ° viá»‡n cÃ³ nhiá»u thuá»™c tÃ­nh khÃ¡ hay. VÃ­ dá»¥ mÃ¬nh thá»­ phÃ¢n tÃ­ch kÃ­ch thÆ°á»›c viÃªn Ä‘Ã¡ kim cÆ°Æ¡ng vá»›i giÃ¡ cá»§a chiáº¿c nháº«n, chia theo mÃ u sáº¯c thÃ¬ nhÆ° tháº¿ nÃ o\n1fig = px.scatter(data,x=\u0026#39;Carat Weight\u0026#39;, y=\u0026#39;Price\u0026#39;, animation_group=\u0026#39;Color\u0026#39;, 2 facet_col = \u0026#39;Color\u0026#39;, opacity = 0.25, template = \u0026#39;plotly_dark\u0026#39;, trendline=\u0026#39;ols\u0026#39;, 3 color=\u0026#34;Color\u0026#34;, trendline_color_override = \u0026#39;red\u0026#39;, title = \u0026#39;SARAH GETS A DIAMOND - A CASE STUDY\u0026#39;) 4fig.show() NhÃ¬n hÃ¬nh trÃªn, mÃ¬nh tháº¥y ráº±ng cÃ¹ng 1 kÃ­ch thÆ°á»›c, mÃ u H vÃ  mÃ u I cÃ³ giÃ¡ xÃªm xÃªm nhau, mÃ u E vÃ  F cÅ©ng tÆ°Æ¡ng tá»±, mÃ u D cÃ³ má»©c giÃ¡ cao nháº¥t. vá»›i kÃ­ch thÆ°á»›c 2.74, giÃ¡ cá»§a chiáº¿c nháº«n kim cÆ°Æ¡ng mÃ u D cao hÆ¡n gáº¥p Ä‘Ã´i so vá»›i giÃ¡ cá»§a nháº«n kim cÆ°Æ¡ng cÃ³ mÃ u H hoáº·c mÃ u I\nCÃ¡c báº¡n cÃ³ thá»ƒ thay thuá»™c tÃ­nh facet_col = \u0026lsquo;Color\u0026rsquo; cá»§a hÃ m scatter báº±ng cÃ¡c tÃªn cá»™t nhÆ° Cut\thoáº·c Clarity\thoáº·c\tSymmetry, sáº½ cÃ³ vÃ i thá»© hay ho cÃ³ thá»ƒ rÃºt ra Ä‘Ã³.\nSau khi phÃ¢n tÃ­ch dá»¯ liá»‡u, cÃ³ cÃ¡i nhÃ¬n sÆ¡ lÆ°á»£c vá» cÃ¡c thuá»™c tÃ­nh cÅ©ng nhÆ° má»‘i tÆ°Æ¡ng quang giá»¯a chÃºng, chÃºng ta thÆ°á»ng sáº½ thÆ°á»ng thá»±c hiá»‡n cÃ¡c phÃ©p biáº¿n Ä‘á»•i Ä‘á»ƒ chuáº©n hoÃ¡ dá»¯ liá»‡u. CÃ¡c phÃ©p biáº¿n Ä‘á»•i thÆ°á»ng Ä‘Æ°á»£c xÃ i lÃ :\nChuáº©n hoÃ¡ dá»¯ liá»‡u: Scale dá»¯ liá»‡u vá» cÃ¹ng má»™t Ä‘oáº¡n, vÃ­ dá»¥ [-1,1] hoáº·c [0-1], 2 phÆ°Æ¡ng phÃ¡p phá»• biáº¿n hay Ä‘Æ°á»£c sá»­ dá»¥ng:\nMin-Max Z score Xá»­ lÃ½ dá»¯ liá»‡u lá»‡ch: CÃ¡c cá»™t thuá»™c tÃ­nh numberric sáº½ Ä‘Æ°á»£c chuáº©n hoÃ¡ vá» phÃ¢n phá»‘i chuáº©n.\nTá»•ng há»£p dá»¯ liá»‡u: Sá»­ dá»¥ng cÃ¡c thuá»™c tÃ­nh cÃ³ sáºµn, káº¿t há»£p láº¡i Ä‘á»ƒ táº¡o nÃªn cÃ¡c thuá»™c tÃ­nh má»›i.\nTrÆ°á»›c háº¿t, chÃºng ta sáº½ xem histogram cá»§a biáº¿n Price\nTa tháº¥y ráº±ng, phÃ¢n phá»‘i cÃ³ Ã­t quan sÃ¡t hÆ¡n á»Ÿ phÃ­a bÃªn pháº£i =\u0026gt; mÃ´ hÃ¬nh bá»‹ lá»‡ch pháº£i (right-skewed hoáº·c skewed right, positively skewed distribution). Vá»›i dá»¯ liá»‡u bá»‹ bá»‹nh nÃ y thÃ¬ chÃºng ta sáº½ dÃ¹ng thuá»‘c chá»¯a lÃ  cÄƒn báº­c hai, cÄƒn báº­c ba hoáº·c lÃ  log.\nMÃ¬nh sáº½ xÃ i thuá»‘c log. Sá»­ dá»¥ng hÃ m log trong thÆ° viá»‡n numpy\n1 2import numpy as np 3# create a copy of data 4data_copy = data.copy() 5# create a new feature Log_Price 6data_copy[\u0026#39;Log_Price\u0026#39;] = np.log(data[\u0026#39;Price\u0026#39;]) 7# plot histogram 8fig = px.histogram(data_copy, x=[\u0026#34;Log_Price\u0026#34;], title = \u0026#39;Histgram of Log Price\u0026#39;, template = \u0026#39;plotly_dark\u0026#39;) 9fig.show() Dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘Æ°a vá» dáº¡ng giá»‘ng giá»‘ng cÃ¡i chuÃ´ng Ãºp, hÃ¬nh dáº¡ng cá»§a phÃ¢n phá»‘i chuáº©n.\nData Preparation XÃ i thÆ° viá»‡n PyCaret khÃ¡ sÆ°á»›ng, chÃºng ta chá»‰ cáº§n gá»i hÃ m setup cá»§a thÆ° viá»‡n lÃ  Ä‘á»§\n1 2# initialize setup 3from pycaret.regression import * 4s = setup(data, target = \u0026#39;Price\u0026#39;, transform_target = True,transform_target_method=\u0026#34;yeo-johnson\u0026#34;, log_experiment = True, experiment_name = \u0026#39;diamond\u0026#39;) BÃ i toÃ¡n thuá»™c dáº¡ng há»“i quy, nÃªn mÃ¬nh sáº½ load toÃ n bá»™ cÃ¡c hÃ m thuá»™c regression vÃ o.\nMá»i viá»‡c cÃ²n láº¡i, tá»« viá»‡c tÃ­nh log cá»§a cá»™t Price, Ä‘áº¿n viá»‡c tiá»n xá»­ lÃ½ dá»¯ liá»‡u , \u0026hellip; Ä‘Ã£ Ä‘Æ°á»£c PyCaret lo háº¿t. ChÃºng ta chá»‰ cáº§n chá»‹u khÃ³ Ä‘á»c doc cá»§a thÆ° viá»‡n Ä‘á»ƒ hiá»ƒu cÃ¡c tham sá»‘ vÃ  á»©ng dá»¥ng nÃ³ vÃ o lÃ  á»•n.\nMá»™t lÆ°u Ã½ lÃ  hÃ m transform máº·c Ä‘á»‹nh xÃ i box-cox, vÃ  pycaret á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i chá»‰ há»— trá»£ \u0026ldquo;box-cox\u0026rdquo; hoáº·c \u0026ldquo;yeo-johnson\u0026rdquo;. Náº¿u cÃ¡c báº¡n muá»‘n xÃ i log cho cá»™t Price, thÃ¬ pháº£i thÃªm cá»™t má»›i. MÃ¬nh sáº½ xÃ i yeo-johnson thay cho máº·c Ä‘á»‹nh box-cox.\nModel Training \u0026 Selection Tiáº¿p Ä‘áº¿n viá»‡c train model vÃ  lá»±a chá»n model cÅ©ng háº¿t sá»©c Ä‘Æ¡n giáº£n, chÃºng ta chá»‰ cáº§n gá»i 1 dÃ²ng lá»‡nh duy nháº¥t\n1 2# compare all models 3best = compare_models() Xong. ThÆ° viá»‡n tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh tham sá»‘, lá»±a chá»n tham sá»‘ tá»‘t nháº¥t vÃ  mÃ´ hÃ¬nh tá»‘t nháº¥t cho chÃºng ta. ChÃºng ta chá»‰ cáº§n ngá»“i, Ä‘á»£i mÃ¡y cháº¡y, xem káº¿t quáº£.\nMá»™t lÆ°u Ã½ lÃ  cÃ¡c báº¡n náº¿u khÃ´ng cÃ i báº£n full thÃ¬ nÃªn xem file log Ä‘á»ƒ xem cÃ³ bÃ¡o lá»—i thiáº¿u thÆ° viá»‡n hay khÃ´ng hen.\nSau khi cÃ³ Ä‘Æ°á»£c thuáº­t toÃ¡n vá»›i mÃ´ hÃ¬nh tá»‘t nháº¥t , vÃ  cÃ¡c trá»ng sá»‘ tá»‘t nháº¥t, chÃºng ta sáº½ lÆ°u mÃ´ hÃ¬nh láº¡i vÃ o file Ä‘á»ƒ sau nÃ y sá»­ dá»¥ng.\n1 2# finalize the model 3final_best = finalize_model(best) 4# save model to disk 5save_model(final_best, \u0026#39;diamond-pipeline\u0026#39;) Deployment \u0026 Monitoring Äáº¿n pháº§n nÃ y thÃ¬ Ä‘Æ¡n giáº£n rá»“i, cÃ¡c báº¡n cÃ³ thá»ƒ viáº¿t webapi nhÆ° flask hoáº·c fastapi Ä‘á»ƒ sá»­ dá»¥ng.\nPycaret cÃ³ há»— trá»£ mlflow, dÃ¹ng Ä‘á»ƒ xem Ä‘Æ°á»ng dáº«n cÃ¡c model Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n, cÅ©ng nhÆ° chi tiáº¿t cÃ¡c thÃ´ng tin tham sá»‘, Ä‘á»™ lá»—i. CÃ¡c báº¡n hÃ£y gÃµ lá»‡nh\n1!mlflow ui Náº¿u báº¡n cháº¡y báº±ng terminal , thÃ¬ chá»‰ cáº§n gÃµ mlflow ui thÃ´i, khÃ´ng cáº§n dáº¥u ! Ä‘Ã¢u, do mÃ¬nh cháº¡y trÃªn jupiter notebook nÃªn pháº£i thÃªm dáº¥u ! cÃ¢u lá»‡nh má»›i hoáº¡t Ä‘á»™ng.\nSau khi cháº¡y lá»‡n trÃªn, báº¡n hÃ£y má»Ÿ trÃ¬nh duyá»‡t web lÃªn vÃ  nháº­p vÃ  Ä‘á»‹a chá»‰ http://localhost:5000, cÃ¡i nÃ y cÅ©ng khÃ´ng cÃ³ gÃ¬ nhiá»u Ä‘á»ƒ Ä‘á» cáº­p, nÃªn mÃ¬nh khÃ´ng show chi tiáº¿t á»Ÿ Ä‘Ã¢y, cÃ¡c báº¡n cá»© vÃ o Ä‘Ã³ vá»c váº¡ch, quáº­y phÃ¡ hen.\nCÃ¡c báº¡n cÃ³ thá»ƒ testing best model báº±ng cÃ¢u lá»‡nh sau\n1 2# create a copy of data and drop Price 3data1 = data.copy() 4# data1.drop(\u0026#39;Price\u0026#39;, axis=1, inplace=True) 5# generate predictions 6from pycaret.regression import predict_model 7predictions = predict_model(final_best, data=data1) 8predictions.head() Cá»™t Label chÃ­nh lÃ  cá»™t giÃ¡ cá»§a mÃ´ hÃ¬nh. MÃ¬nh giá»¯ láº¡i cá»™t giÃ¡ Ä‘á»ƒ tiá»‡n so sÃ¡nh.\n1 2\tCarat Weight\tCut\tColor\tClarity\tPolish\tSymmetry\tReport\tPrice\tLabel 30\t1.10\tIdeal\tH\tSI1\tVG\tEX\tGIA\t5169\t5365.265635 41\t0.83\tIdeal\tH\tVS1\tID\tID\tAGSL\t3470\t3525.863059 52\t0.85\tIdeal\tH\tSI1\tEX\tEX\tGIA\t3183\t3352.882096 63\t0.91\tIdeal\tE\tSI1\tVG\tVG\tGIA\t4370\t4485.753572 74\t0.83\tIdeal\tG\tSI1\tEX\tEX\tGIA\t3171\t3327.363225 Top 5 pháº§n tá»­ Ä‘áº§u tiÃªn hiá»‡n ra cho mÃ¬nh tháº¥y ráº±ng, cÃ³ váº» mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n giÃ¡ cao hÆ¡n má»™t chÃºt so vá»›i giÃ¡ gá»‘c.\nCáº£m Æ¡n cÃ¡c báº¡n nhiá»u. Háº¹n gáº·p láº¡i trong cÃ¡c bÃ i viáº¿t tiáº¿p theo\nTham kháº£o\nhttps://github.com/pycaret/pycaret\nhttps://towardsdatascience.com/build-with-pycaret-deploy-with-fastapi-333c710dc786\nhttps://towardsdatascience.com/easy-mlops-with-pycaret-mlflow-7fbcbf1e38c6\n","date":"Jul 28, 2021","img":"https://unsplash.it/1920/1080?image=32","permalink":"/blog/2021-07-28-pycaret-flaskapi/","series":null,"tags":["Machine Learning","Deep Learning","PyCaret"],"title":"TÃ¬m Hiá»ƒu Package PyCaret Trong Python"},{"categories":null,"content":" Giá»›i thiá»‡u Danh sÃ¡ch Ä‘iá»u khiá»ƒn truy cáº­p - Access Control List (ACL) Äiá»u khiá»ƒn truy cáº­p báº¯t buá»™c - Mandatory Access Control (MAC) Äiá»u khiá»ƒn truy cáº­p tÃ¹y quyá»n - Discretionary Access Control (DAC) Äiá»u khiá»ƒn truy cáº­p theo vai - Role Based Access Control (RBAC) Äiá»u khiá»ƒn truy cáº­p theo thuá»™c tÃ­nh - Attribute Based Access Control (ABAC) Giá»›i thiá»‡u Danh sÃ¡ch Ä‘iá»u khiá»ƒn truy cáº­p - Access Control List Äiá»u khiá»ƒn truy cáº­p báº¯t buá»™c - Mandatory Access Control Äiá»u khiá»ƒn truy cáº­p tÃ¹y quyá»n - Discretionary Access Control (DAC) Äiá»u khiá»ƒn truy cáº­p theo vai - Role Based Access Control (RBAC) Äiá»u khiá»ƒn truy cáº­p theo thuá»™c tÃ­nh - Attribute Based Access Control (ABAC) Danh sÃ¡ch Ä‘iá»u khiá»ƒn truy cáº­p - Access Control List (ACL) LÃ  mÃ´ hÃ¬nh cáº¥p quyá»n truy cáº­p dá»±a vÃ o danh sÃ¡ch cÃ¡c quyá»n\nMÃ´ hÃ¬nh:\nSubject Ä‘Æ°á»£c quyá»n ( action ) trÃªn object\rTuá»³ tá»«ng bÃ i toÃ¡n khÃ¡c nhau mÃ  subject, action, object lÃ  khÃ¡c nhau\rVÃ­ dá»¥:\rTrong mÃ´i trÆ°á»ng phÃ¢n quyá»n táº­p tin linux, subject lÃ  user, thread, action lÃ  READ/WRITE/ EXECUTE object lÃ  file, directory, tcp/udp port, thiáº¿t bá»‹ nháº­p xuáº¥t ...\rVÃ­ dá»¥:\nTrong há»‡ thá»‘ng phÃ¢n quyá»n cá»§a linux\rUser Alice Ä‘Æ°á»£c quyá»n Ä‘á»c/ghi/thá»±c thi trÃªn file alice.sh\rUser Bob Ä‘Æ°á»£c quyá»n Ä‘á»c trÃªn file alice.sh\rá»¨ng dá»¥ng:\nMÃ´ hÃ¬nh Ä‘Æ°á»£c á»©ng dá»¥ng trong Filesystem ACLs, POSIX ACL, NFSv4 ACL, Active Directory ACLs, Networking ACLs, SQL implementations.\rTham kháº£o:\nhttps://en.wikipedia.org/wiki/Access-control_list Äiá»u khiá»ƒn truy cáº­p báº¯t buá»™c - Mandatory Access Control (MAC) Vá» cÆ¡ báº£n thÃ¬ mÃ´ hÃ¬nh nÃ y cÅ©ng \u0026quot; lÃ  mÃ´ hÃ¬nh cáº¥p quyá»n truy cáº­p dá»±a vÃ o danh sÃ¡ch cÃ¡c quyá»n\u0026quot;. Tuy nhiÃªn, mÃ´ hÃ¬nh nÃ y sáº½ kiá»ƒm soÃ¡t quyá»n truy cáº­p Ä‘áº¿n tá»«ng object cá»§a subject\nMÃ´ hÃ¬nh:\nSubject Ä‘Æ°á»£c quyá»n ( action ) trÃªn object\rObject Ä‘Æ°á»£c quyá»n (action) bá»Ÿi object\rVÃ¬ rÃ ng á»Ÿ má»©c 2 Ä‘áº§u, nÃªn mÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c rÃ ng cháº·c cháº½ hÆ¡n\rVÃ­ dá»¥:\nVÃ­ dá»¥: á» má»™t sá»‘ tá»• chá»©c, user cÃ³ quyá»n Ä‘á»c ghi file (subject - action - object), tuy nhiÃªn, cÃ³ má»™t sá»‘ file tuyá»‡t máº­t Ä‘Æ°á»£c phÃ¢n quyá»n Ä‘á»c/ ghi cho giÃ¡m Ä‘á»‘c (object - action - subject), nÃªn user bÃ¬nh thÆ°á»ng khÃ´ng thá»ƒ Ä‘á»c Ä‘Æ°á»£c.\rCÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c thÃªm 3 vÃ­ dá»¥ trong link cá»§a cornell mÃ¬nh cÃ³ Ä‘á»ƒ bÃªn dÆ°á»›i\rá»¨ng dá»¥ng:\nSELinux\rWindows Vista vÃ  Windows Server 2008\r...\rTham kháº£o:\nhttps://en.wikipedia.org/wiki/Mandatory_access_control\rhttp://www.cs.cornell.edu/courses/cs5430/2015sp/notes/mac.php\rÄiá»u khiá»ƒn truy cáº­p tÃ¹y quyá»n - Discretionary Access Control (DAC) LÃ  mÃ´ hÃ¬nh cáº¥p quyá»n truy cáº­p dá»±a vÃ o danh sÃ¡ch cÃ¡c quyá»n. MÃ´ hÃ¬nh nÃ y giá»‘ng vá»›i ACL, chá»‰ cÃ³ 1 Ä‘iá»ƒm khÃ¡c lÃ  subject cÃ³ thá»ƒ chuyá»ƒn quyá»n mÃ¬nh Ä‘ang cÃ³ cho má»™t subject khÃ¡c\nMÃ´ hÃ¬nh:\nSubject Ä‘Æ°á»£c quyá»n ( action ) trÃªn object\rSubject gÃ¡n quyá»n (grant : action - object) cho Subject khÃ¡c\rVÃ­ dá»¥: Alice cÃ³ quyá»n Ä‘á»c, ghi, thá»±c thi file Alice.sh\nAlice gÃ¡n quyá»n Ä‘á»c file Alice.sh cho Bob\rá»¨ng dá»¥ng:\nPhÃ¢n quyá»n file trong há»‡ Ä‘iá»u hÃ nh\r...\rÄiá»u khiá»ƒn truy cáº­p theo vai - Role Based Access Control (RBAC) MÃ´ hÃ¬nh cÃ²n cÃ³ tÃªn gá»i khÃ¡c lÃ  Role Based Security, lÃ  mÃ´ hÃ¬nh cáº¥p quyá»n truy cáº­p dá»±a vÃ o danh sÃ¡ch cÃ¡c quyá»n. Tuy nhiÃªn, cÃ¡c subject sáº½ Ä‘Æ°á»£c gÃ¡n vÃ o trong cÃ¡c Role vÃ  chÃºng ta sáº½ cáº¥p quyá»n cho cÃ¡c role.\nMÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ káº¿t há»£p vá»›i mÃ´ hÃ¬nh DAC (Ä‘á»ƒ tÄƒng kháº£ nÄƒng cáº¥p quyá»n), hoáº·c MAC (Ä‘á»ƒ tÄƒng tÃ­nh báº£o máº­t) mÃ  khÃ´ng xung Ä‘á»™t vá»›i 2 mÃ´ hÃ¬nh trÃªn.\nMÃ´ hÃ¬nh:\nSubject thuá»™c Roles\rRoles Ä‘Æ°á»£c quyá»n ( action ) trÃªn object\r=\u0026gt; cÃ¡c subject thuá»™c Roles Ä‘Æ°á»£c quyá»n (action) trÃªn object\rVÃ­ dá»¥:\nAlice thuá»™c Role NhanVienTuyenDung, NhanVienIT\nRole NhanVienTuyenDung cÃ³ quyá»n read, execute file\nRole NhanVienIT cÃ³ quyá»n write file\n=\u0026gt; Alice cÃ³ quyá»n read, write, execute file\ná»¨ng dá»¥ng:\nCÃ³ ráº¥t nhiá»u á»©ng dá»¥ng cá»§a mÃ´ hÃ¬nh nÃ y, vÃ­ dá»¥ cÃ¡c forum mÃ£ nguá»“n má»Ÿ, cáº¥p quyá»n trong há»‡ Ä‘iá»u hÃ nh ....\rÄá»ƒ tÃ¬m hiá»ƒu ká»¹ hÆ¡n vá» mÃ´ hÃ¬nh RBAC, cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c quyá»ƒn sÃ¡ch tham kháº£o á»Ÿ dÆ°á»›i\nTham kháº£o :\nDavid F. Ferraiolo; D. Richard Kuhn; Ramaswamy Chandramouli (2007). Role-based Access Control (2nd ed.). Artech House. ISBN 978-1-59693-113-8.\rhttps://en.wikipedia.org/wiki/Role-based_access_control\rÄiá»u khiá»ƒn truy cáº­p theo thuá»™c tÃ­nh - Attribute Based Access Control (ABAC) MÃ´ hÃ¬nh cÃ²n cÃ³ tÃªn gá»i khÃ¡c lÃ  Policy Based Access Control hoáº·c Claims Based Access Control (CBAC), lÃ  mÃ´ hÃ¬nh cáº¥p quyá»n truy cáº­p dá»±a vÃ o danh sÃ¡ch cÃ¡c quyá»n káº¿t há»£p vá»›i cÃ¡c thuá»™c tÃ­nh.\nKiáº¿n trÃºc: Theo NIST Ä‘á» xuáº¥t, kiáº¿n trÃºc cá»§a ABAC nÃªn cÃ³ cÃ¡c thÃ nh pháº§n sau:\n- Policy Enforcement Point PEP: chá»‹u trÃ¡ch nhiá»‡m phÃ¢n tÃ­ch cÃ¡c yÃªu cáº§u truy xuáº¥t vÃ  gá»­i Ä‘áº¿n PDP Ä‘á»ƒ chá»©ng thá»±c.\r- Policy Decision Point PDP: nháº­n thÃ´ng tin tá»« PEP vÃ  chá»‹u trÃ¡ch nhiá»‡m chá»©ng thá»±c yÃªu cáº§u cÃ³ quyá»n truy xuáº¥t tá»›i cÃ¡c tÃ i nguyÃªn hay khÃ´ng, tráº£ vá» Ä‘á»“ng Ã½ hoáº·c tá»« chá»‘i. Náº¿u thiáº¿u tÃ´ng tin thÃ¬\r- Policy Information Point PIP: tráº£ vá» cÃ¡c attribute mÃ  PDP yÃªu cáº§u.\rThuá»™c tÃ­nh: Báº¥t ká»ƒ thá»© gÃ¬ trÃªn Ä‘á»i nÃ y Ä‘á»u cÃ³ thá»ƒ lÃ  thuá»™c tÃ­nh. Tuy nhiÃªn, chÃºng sáº½ thÆ°á»ng Ä‘Æ°á»£c phÃ¢n lÃ m 4 nhÃ³m chÃ­nh sau:\n- Subject attributes: CÃ¡c thuá»™c tÃ­nh vá» thÃ´ng tin ngÆ°á»i dÃ¹ng, vÃ­ dá»¥ há» tÃªn, ngÃ y thÃ¡ng nÄƒm sinh, quÃª quÃ¡n, quá»‘c tá»‹ch, Ä‘á»‹a chá»‰, phÃ²ng ban, chá»©c vá»¥, tÃªn cÃ´ng viá»‡c, sá»‘ cmnd, ....\r- Action attributes: CÃ¡c thuá»™c tÃ­nh vá» hÃ nh Ä‘á»™ng nhÆ° cháº¡y , náº£y, xoÃ¡, thÃªm, Ä‘á»c, ghi ...\r- Object attributes: CÃ¡c thuá»™c tÃ­nh vá» thÃ´ng tin cá»§a Ä‘á»‘i tÆ°á»£ng muá»‘n truy xuáº¥t, vÃ­ dá»¥ nhÆ° loáº¡i file, pháº§n Ä‘uÃ´i má»Ÿ rá»™ng, vá»‹ trÃ­, ....\r- Contextual (environment) attributes: CÃ¡c thuá»™c tÃ­nh liÃªn quan Ä‘áº¿n ká»‹ch báº£n diá»…n ra. VÃ­ dá»¥ há»‡ Ä‘iá»u hÃ nh, ram, cpu, thá»i gian, mÃºi giá», ...\rVÃ­ dá»¥:\nToÃ n bá»™ nhÃ¢n viÃªn khÃ´ng Ä‘Æ°á»£c truy xuáº¥t database sau 21h Ä‘Ãªm\rNhÃ¢n viÃªn Nguyá»…n Thá»‹ Lá»¥a cá»§a GHN Ä‘Æ°á»£c quyá»n Ä‘á»• danh sÃ¡ch freelancer á»Ÿ HÃ  Ná»™i, Háº£i PhÃ²ng, HÆ°ng YÃªn\rá»¨ng dá»¥ng:\nCÃ³ thá»ƒ á»©ng dá»¥ng ABAC vÃ o ráº¥t nhiá»u á»©ng dá»¥ng khÃ¡c nhau Ä‘á»ƒ kiá»ƒm soÃ¡t luá»“ng truy cáº­p tÃ i nguyÃªn cá»§a há»‡ thá»‘ng. Tuy nhiÃªn, viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh ACBA khÃ¡ tá»‘n kÃ©m vá» tÃ i nguyÃªn vÃ  Ä‘Ã²i há»i ngÆ°á»i quáº£n lÃ½ pháº£i cÃ³ tÆ° duy há»‡ thá»‘ng vá»¯ng cháº¯c\rÄá»ƒ tÃ¬m hiá»ƒu ká»¹ hÆ¡n vá» mÃ´ hÃ¬nh ABAC, cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c quyá»ƒn sÃ¡ch tham kháº£o á»Ÿ dÆ°á»›i\nTham kháº£o :\nhttps://nvlpubs.nist.gov/nistpubs/specialpublications/NIST.SP.800-162.pdf\rhttps://arxiv.org/pdf/1306.2401.pdf\rhttps://en.wikipedia.org/wiki/Attribute-based_access_control\rCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ chÃº Ã½ quan tÃ¢m theo dÃµi. Xin chÃ o vÃ  háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Jul 2, 2021","img":"https://unsplash.it/1920/1080?image=33","permalink":"/blog/2021-07-02-mo-hinh-phan-quyen/","series":null,"tags":["ACL","mac","dac","rbac","abac"],"title":"MÃ´ HÃ¬nh PhÃ¢n Quyá»n - Access Control"},{"categories":null,"content":" Giá»›i thiá»‡u YÃªu cáº§u Giá»›i thiá»‡u Microsoft Ä‘Ã£ trÃ¬nh lÃ ng phiÃªn báº£n WLS 2 vá»›i nhiá»u Ä‘iá»ƒm cáº£i tiáº¿n ná»•i trá»™i. Trong bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ hÆ°á»›ng dáº«n cÃ¡c báº¡n cÃ i Ä‘áº·t wls 2 vÃ  upgrade cÃ¡c distro linux cá»§a mÃ¬nh xÃ i WLS 2. MÃ¬nh cÃ³ má»™t lÆ°u Ã½ nhá» lÃ  náº¿u cÃ¡c distro linux cá»§a báº¡n khÃ´ng bá»‹ rÃ ng gÃ¬ thÃ¬ cÃ¡c báº¡n nÃªn xÃ³a cÃ¡c linux distro hiá»‡n táº¡i vÃ  cÃ i má»›i láº¡i linux. VÃ¬ quÃ¡ trÃ¬nh upgrade cháº¡y ráº¥t lÃ  lÃ¢u.\nYÃªu cáº§u Äá»ƒ cÃ i Ä‘áº·t WLS 2, CÃ¡c báº¡n báº¯c buá»™c pháº£i nÃ¢ng cáº¥p lÃªn cÃ¡c phiÃªn báº£n \u0026ldquo;Windows 10 May 2020 (2004), Windows 10 May 2019 (1903), or Windows 10 November 2019 (1909)\u0026rdquo; hoáº·c cÃ¡c báº£n cáº­p nháº­t sau Ä‘Ã³.\nÄá»‚ xÃ¡c Ä‘á»‹nh xem mÃ¡y báº¡n Ä‘ang xÃ i phiÃªn báº£n bao nhiÃªu, báº¡n nÃ£y gÃµ má»Ÿ cmd lÃªn vÃ  gÃµ lá»‡nh\n1systeminfo | findstr \u0026#34;OS\u0026#34; 2 3------ 4 5OS Name: Microsoft Windows 10 Home Single Language 6OS Version: 10.0.19043 N/A Build 19043 7OS Manufacturer: Microsoft Corporation 8OS Configuration: Standalone Workstation 9OS Build Type: Multiprocessor Free 10BIOS Version: American Megatrends Inc. S551LN.209, 7/8/2014 Náº¿u thá»a mÃ£n cÃ¡c Ä‘iá»u kiá»‡n trÃªn, thÃ¬ cÃ¡c bÆ°á»›c chÃºng ta pháº£i lÃ m lÃ :\n1dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 2 3------ 4 5Deployment Image Servicing and Management tool 6Version: 10.0.19041.844 7 8Image Version: 10.0.19043.1023 9 10Enabling feature(s) 11[==========================100.0%==========================] 12The operation completed successfully. Tiáº¿p theo, chÃºng ta cháº¡y lá»‡nh\n1 2 3dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 4 5---------- 6 7Deployment Image Servicing and Management tool 8Version: 10.0.19041.844 9 10Image Version: 10.0.19043.1023 11 12Enabling feature(s) 13[==========================100.0%==========================] 14The operation completed successfully. Sau Ä‘Ã³, báº¡n pháº£i khá»Ÿi Ä‘á»™ng láº¡i mÃ¡y Ä‘á»ƒ window tiáº¿n hÃ nh cáº­p nháº­t cÃ¡c gÃ³i thÆ° viá»‡n cáº§n thiáº¿t.\nSau khi khá»Ÿi Ä‘á»™ng láº¡i mÃ¡y xong, chÃºng ta sáº½ gá»i lá»‡nh set phiÃªn báº£n máº·c Ä‘á»‹nh cá»§a wsl lÃ  báº£n 2 báº±ng lá»‡nh:\n1 2wsl --set-default-version 2 Sau khi cháº¡y lá»‡nh nÃ y, sáº½ cÃ³ 1 trong 2 trÆ°á»ng há»£p xáº£y ra. TrÆ°á»ng há»£p 1\n1For information on key differences with WSL 2 please visit https://aka.ms/wsl2 ThÃ¬ chÃºc má»«ng báº¡n, báº¡n Ä‘Ã£ enable thÃ nh cÃ´ng WSL 2\nTrÆ°á»ng há»£p thá»© 2, báº¡n sáº½ gáº·p output nhÆ° tháº¿ nÃ y:\n1WSL 2 requires an update to its kernel component. For information please visit https://aka.ms/wsl2kernel. ThÃ¬ báº¡n nÃ y vÃ o trang https://aka.ms/wsl2kernel nhÆ° hÆ°á»›ng dáº«n, Ä‘á»c ká»¹ file, down vá» file msi Ä‘á»ƒ cÃ i Linux kernel vÃ o. Sau Ä‘Ã³ cháº¡y láº¡i lá»‡nh \u0026ldquo;wsl \u0026ndash;set-default-version 2\u0026rdquo;\nSau Ä‘Ã³, cÃ¡c báº¡n tiáº¿n hÃ nh check láº¡i phiÃªn báº£n linux mÃ¬nh Ä‘ang sá»­ dá»¥ng\n1 2 wsl --list --verbose 3 4 ----- 5 6 NAME STATE VERSION 7* Ubuntu-18.04 Running 1 8 kali-linux Stopped 1 NhÆ° cÃ¡c báº¡n tháº¥y á»Ÿ trÃªn, báº£n ubuntu 18.4 mÃ¬nh Ä‘ang sá»­ dá»¥ng Ä‘ang á»Ÿ version 1. MÃ¬nh sáº½ convert qua version 2 báº±ng lá»‡nh\n1 2wsl --set-version Ubuntu-18.04 2 3 4------- 5Conversion in progress, this may take a few minutes... 6For information on key differences with WSL 2 please visit https://aka.ms/wsl2 Sau khi cháº¡y dÃ²ng lá»‡nh trÃªn, cÃ¡c báº¡n chá»‹u khÃ³ ngá»“i chá» má»™t xÃ­u, nÃ³ phá»¥ thuá»™c vÃ o cáº¥u hÃ¬nh mÃ¡y cá»§a cÃ¡c báº¡n. Kinh nghiá»‡m cá»§a mÃ¬nh khi upgrade vÃ i mÃ¡y lÃ  nÃªn táº¯t chÆ°Æ¡ng trÃ¬nh diá»‡t virus nhÆ° kaspersky, norton, BKAV, bit \u0026hellip;. Ä‘i. Táº¯t nhá»¯ng á»©ng dá»¥ng sá»­ dá»¥ng nhiá»u ram thÃ¬ viá»‡c convert sáº½ cháº¡y nhanh hÆ¡n má»™t chÃºt.\nKáº¿t quáº£ sau khi mÃ¬nh convert.\n1 2 NAME STATE VERSION 3* Ubuntu-18.04 Stopped 2 4 kali-linux Stopped 1 Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ chÃº Ã½ theo dÃµi. Háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\nLink hÆ°á»›ng dáº«n gá»‘c tá»« trang chá»§ microsoft\nhttps://docs.microsoft.com/en-us/windows/wsl/install-win10\n","date":"May 30, 2021","img":"https://unsplash.it/1920/1080?image=34","permalink":"/blog/2021-05-30-upgrade-wls-to-wls2/","series":null,"tags":["wls2"],"title":"NÃ¢ng Cáº¥p WSL LÃªn Báº£n WSL 2 TrÃªn Window 10"},{"categories":null,"content":" Giá»›i thiá»‡u Báº¯t Ä‘áº§u Tiáº¿n hÃ nh turning Giá»›i thiá»‡u Trong quÃ¡ trÃ¬nh giáº£i cÃ¡c bÃ i toÃ¡n cÃ³ sá»­ dá»¥ng machine learning, vÃ¬ Ä‘á»ƒ lÃ m nhanh nÃªn Ä‘Ã´i khi mÃ¬nh sáº½ sá»­ dá»¥ng cÃ¡c tham sá»‘ máº·c Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh Ä‘á»ƒ train. Má»™t pháº§n vÃ¬ lÃ½ do chÃºng ta khÃ´ng biáº¿t cÃ¡ch chá»‰nh cÃ¡c tham sÃ³ nhÆ° tháº¿ nÃ o, so vá»›i cÃ¡i gÃ¬ Ä‘á»ƒ cÃ³ mÃ´ hÃ¬nh huáº¥n luyá»‡n lÃ  tá»‘t nháº¥t. á» bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ sá»­ dá»¥ng Learning Curves Ä‘á»ƒ tá»‘i Æ°u hÃ³a cÃ¡c tham sá»‘ cá»§a XGBoost. CÃ¡c mÃ´ hÃ¬nh khÃ¡c cÅ©ng lÃ m tÆ°Æ¡ng tá»± thÃ´i. MÃ¬nh chá»n XGBoost vÃ¬ mÃ´ hÃ¬nh nÃ y thÆ°á»ng cho káº¿t quáº£ khÃ¡ tá»‘t trÃªn cÃ¡c cuá»™c thi á»Ÿ Kaggle.\nBáº¯t Ä‘áº§u Äá»ƒ báº¯t Ä‘áº§u thÃ­ nghiá»‡m, chÃºng ta sáº½ sinh ngáº«u nhiÃªn 60 ngÃ n dá»¯ liá»‡u cÃ³ 1 ngÃ n thuá»™c tÃ­nh báº±ng cÃ¡ch sá»­ dá»¥ng hÃ m make_classification, sau Ä‘Ã³ sáº½ chia dá»¯ liá»‡u thÃ nh 2 táº­p train vÃ  test vá»›i tá»· lá»‡ 10% lÃ  táº­p test\n1X, y = make_classification(n_samples=60000, n_features=1000, n_informative=50, n_redundant=0, random_state=1) 2# split data into train and test sets 3X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1) Load mÃ´ hÃ¬nh XGBClassifier vá»›i cÃ¡c tham sá»‘ lÃ  máº·c Ä‘á»‹nh. MÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c xem nhÆ° lÃ  baseline vÃ  cÃ¡c cáº£i tiáº¿n tham sá»‘ á»Ÿ sau sáº½ so sÃ¡nh káº¿t quáº£ trÃªn mÃ´ hÃ¬nh nÃ y.\n1 2 3model = XGBClassifier() 4 5evalset = [(X_train, y_train), (X_test, y_test)] 6 7model.fit(X_train, y_train, eval_metric=\u0026#39;logloss\u0026#39;, eval_set=evalset) 8# evaluate performance 9yhat = model.predict(X_test) 10score = accuracy_score(y_test, yhat) 11print(\u0026#39;Accuracy: %.3f\u0026#39; % score) 12# retrieve performance metrics 13results = model.evals_result() 14# plot learning curves 15pyplot.plot(results[\u0026#39;validation_0\u0026#39;][\u0026#39;logloss\u0026#39;], label=\u0026#39;train\u0026#39;) 16pyplot.plot(results[\u0026#39;validation_1\u0026#39;][\u0026#39;logloss\u0026#39;], label=\u0026#39;test\u0026#39;) 17# show the legend 18pyplot.legend() 19# show the plot 20pyplot.show() Äá»™ chÃ­nh xÃ¡c: Accuracy: 0.962. LÆ°u Ã½ rÃ ng Ä‘á»™ chÃ­nh xÃ¡c khi thá»±c nghiá»‡m cá»§a má»—i láº§n cháº¡y sáº½ khÃ¡c nhau, do data sinh ngáº«u nhiÃªn vÃ  má»™t pháº§n do sá»± ngáº«u nhiÃªn trong XGBoost.\nNhÃ¬n vÃ o hÃ¬nh trÃªn, chÃºng ta tháº¥y ráº±ng Ä‘Æ°á»ng cong cá»§a táº­p train (Ä‘Æ°á»ng mÃ u xanh) cÃ³ Ä‘á»™ lá»—i tá»‘t hÆ¡n so vá»›i Ä‘Æ°á»ng cong cá»§a táº­p test( Ä‘Æ°á»ng mÃ u Ä‘á»)\nTiáº¿n hÃ nh turning Äáº§u tiÃªn, nhÃ¬n vÃ o Ä‘á»“ thá»‹, ta tháº¥y ráº±ng Ä‘Æ°á»ng cong váº«n cÃ²n cÃ³ Ä‘á»™ dá»‘c, nÃªn viá»‡c tÄƒng sá»‘ láº§n láº·p cÃ³ thá»ƒ sáº½ lÃ m tÄƒng thÃªm Ä‘á»™ chÃ­nh xÃ¡c, thá»­ thay Ä‘á»•i sá»‘ láº§n láº·p lÃªn 500 xem sao.\nTrong XGBoost sá»‘ láº§n láº·p Ä‘Æ°á»£c tham sá»‘ hÃ³a bá»Ÿi tham sá»‘ n_estimators, chá»‰nh láº¡i Ä‘oáº¡n mÃ£ lá»‡nh á»Ÿ trÃªn vá»›i má»™t thay Ä‘á»•i nhá» rá»“i cháº¡y láº¡i\n1 2model = XGBClassifier(n_estimators=500) Äá»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh tÄƒng lÃªn 1 chÃºt, Ä‘á»‘i vá»›i thá»±c nghiá»‡m cá»§a mÃ¬nh lÃ  Accuracy: 0.981\nQuan sÃ¡t Ä‘Æ°á»ng cong cá»§a hÃ¬nh trÃªn, ta tháº¥y pháº§n Ä‘uÃ´i Ä‘oáº¡n sá»‘ láº§n láº·p tá»« 270 Ä‘áº¿n 500 cÃ³ Ä‘á»™ dá»‘c nhá», háº§u nhÆ° lÃ  báº±ng pháº³ng, cÃ³ thá»ƒ káº¿t luáº­n lÃ  viá»‡c huáº¥n luyá»‡n á»Ÿ Ä‘oáº¡n nÃ y háº§u nhÆ° khÃ´ng cáº£i tiáº¿n gÃ¬ nhiá»u.\nMá»™t nháº­n xÃ©t ná»¯a lÃ  Ä‘oáº¡n trÆ°á»›c 150 cÃ³ Ä‘á»™ dá»‘c khÃ¡ lá»›n, cÃ³ kháº£ nÄƒng lÃ  há»‡ sá»‘ há»c (learning reate) quÃ¡ lá»›n, lÃ m cho mÃ´ hÃ¬nh chÆ°a Ä‘áº¡t Ä‘Æ°á»£c cá»±c tiá»ƒu, thá»­ Ä‘iá»u chá»‰nh há»‡ sá»‘ há»c nÃ y nhá» hÆ¡n lÃ  0.01, thay vÃ¬ 0.3 nhÆ° giÃ¡ trá»‹ máº·c Ä‘á»‹nh xem sao.\nMá»™t lÆ°u Ã½ lÃ  há»‡ sá»‘ há»c nhá» thÃ¬ sáº½ lÃ¢u há»™i tá»¥, nÃªn chÃºng ta pháº£i tÄƒng sá»‘ láº§n láº·p lÃªn. á» Ä‘Ã¢y Ä‘á»“ng thá»i vá»›i viá»‡c giáº£m há»‡ sá»‘ há»c xuá»‘ng 0.01, mÃ¬nh cÃ²n tÄƒng sá»‘ láº§n láº·p lÃªn 1000.\nTrong XGBoost há»‡ sá»‘ há»c Ä‘Æ°á»£c tham sá»‘ hÃ³a bá»Ÿi tham sá»‘ eta\n1 2model = XGBClassifier(n_estimators=1000, eta=0.01) Äá»™ chÃ­nh xÃ¡c Ä‘áº¡t Ä‘Æ°á»£c: Accuracy: 0.954\nTuy mÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c giáº£m, nhÆ°ng nhÃ¬n vÃ o Ä‘á»“ thá»‹ thÃ¬ ta tháº¥y mÃ´ hÃ¬nh váº«n cÃ²n Ä‘á»™ dá»‘c, nghÄ©a lÃ  mÃ´ hÃ¬nh sáº½ cho káº¿t quáº£ tá»‘t hÆ¡n ná»¯a náº¿u ta tÄƒng sá»‘ vÃ²ng láº·p.\nMá»™t cÃ¡ch khÃ¡ch lÃ  thay Ä‘á»•i cÃ¡c chuáº©n hÃ³a (regularization ) báº±ng cÃ¡ch giáº£m cÃ¡c tham sá»‘ sá»‘ máº«u ( samples) vÃ  sá»‘ Ä‘áº·c trÆ°ng (features) Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ xÃ¢y dá»±ng cÃ¢y trong táº­p há»£p. Hai tham sá»‘ nÃ y Ä‘Æ°á»£c tham sá»‘ hÃ³a bá»Ÿi tham sá»‘ subsample vÃ  colsample_bytree. GiÃ¡ trá»‹ máº·c Ä‘á»‹nh cá»§a chÃºng lÃ  1. ChÃºng ta sáº½ thay Ä‘á»•i thÃ nh 0.35 xem sao nhÃ©\n1 2model = XGBClassifier(n_estimators=5000, eta=0.01, subsample=0.35, colsample_bytree=0.35) Káº¿t quáº£ Accuracy: 0.970 á» hai láº§n thÃ­ nghiá»‡m trÃªn, mÃ¬nh cÃ³ cÃ¡c hÆ°á»›ng xá»­ lÃ½ cÃ³ thá»ƒ Ä‘i tiáº¿p, má»™t lÃ  tÄƒng sá»‘ láº§n láº·p lÃªn, vÃ¬ Ä‘á»™ dá»‘c cá»§a mÃ´ hÃ¬nh váº«n cÃ²n, nÃªn chÃºng ta hoÃ n toÃ n cÃ³ thá»ƒ thu Ä‘Æ°á»£c káº¿t quáº£ tá»‘t hÆ¡n. Má»™t cÃ¡ch khÃ¡c lÃ  tÄƒng learning rate lÃªn Ä‘á»ƒ quÃ¡ trÃ¬nh há»™i tá»¥ Ä‘Æ°á»£c xáº£y ra nhanh hÆ¡n, vÃ­ dá»¥ Ä‘á»ƒ eta = 0.05 hoáº·c 0.75 cháº³n háº¡n.\nQuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ tiáº¿p tá»¥c, dá»±a vÃ o quan sÃ¡t cá»§a cÃ¡c báº¡n trÃªn Ä‘Æ°á»ng cong vÃ  hÆ¡n háº¿t lÃ  sá»± hiá»‡u biáº¿t tháº¥u Ä‘Ã¡o cá»§a cÃ¡c báº¡n trÃªn cÃ¡c tham sá»‘ mÃ  mÃ´ hÃ¬nh cá»§a báº¡n Ä‘ang sá»­ dá»¥ng. ChÃºc cÃ¡c báº¡n sáº½ cÃ³ má»™t hÆ°á»›ng Ä‘i tá»‘t Ä‘á»ƒ giáº£m thiá»ƒu thá»i gian mÃ² máº«m.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ chÃº Ã½ theo dÃµi. Háº¹n gáº·p láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\nNguá»“n tham kháº£o\nhttps://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\nhttps://machinelearningmastery.com/tune-xgboost-performance-with-learning-curves/\nhttps://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\n","date":"Apr 11, 2021","img":"https://unsplash.it/1920/1080?image=35","permalink":"/blog/2021-04-11-xgboost_learning_curves/","series":null,"tags":["Machine Learning","XGBoost"],"title":"Tinh Chá»‰nh Thuáº­t ToÃ¡n XGBoost  Vá»›i Learning Curves"},{"categories":null,"content":" Giá»›i thiá»‡u SGD - Stochastic Gradient Descent Adam - Adaptive Moment Estimation AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients Káº¿t luáº­n Giá»›i thiá»‡u Hi cÃ¡c báº¡n, láº¡i lÃ  mÃ¬nh Ä‘Ã¢y, hÃ´m nay mÃ¬nh sáº½ cÃ¹ng cÃ¡c báº¡n tÃ¬m hiá»ƒu thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a AdaBelief. Thuáº­t toÃ¡n nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ thay cho thuáº­t toÃ¡n Adam optimizer mÃ  cÃ¡c báº¡n hiá»‡n Ä‘ang xÃ i Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh Deep learning. NÃ o, chÃºng ta cÃ¹ng báº¯t Ä‘áº§u tÃ¬m hiá»ƒu nhÃ©.\náº¨n sÃ¢u bÃªn trong cÃ¡c thuáº­t toÃ¡n sá»­ dá»¥ng Neural Network vÃ  má»™t vÃ i thuáº­t toÃ¡n machine learning Ä‘á»u sá»­ dá»¥ng cÃ¡c hÃ m tá»‘i Æ°u hÃ³a. ChÃºng ta cÃ³ thá»ƒ liá»‡t kÃª ra má»™t vÃ i cÃ¡i tÃªn nhÆ° RMSprop, SGD (Stochastic Gradient Descent), Adam (Adaptive Moment Estimation).\nMá»™t vÃ i cÃ¡c yáº¿u tá»‘ hay Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»™t thuáº­t toÃ¡n optimizer:\nHá»™i tá»¥ nhanh (trong quÃ¡ trÃ¬nh train)\nSá»± tá»•ng quÃ¡t hÃ³a cao (váº«n nháº­n dáº¡ng Ä‘Æ°á»£c nhá»¯ng máº«u chÆ°a tá»«ng Ä‘Æ°á»£c huáº¥n luyá»‡n)\nÄá»™ chÃ­nh xÃ¡c cao\nCÃ¡c thuáº­t toÃ¡n tá»‘i Æ°u thuá»™c há» Adaptive thÆ°á»ng cÃ³ tá»‘c Ä‘á»™ há»™i tá»¥ nhanh. Trong khi Ä‘Ã³, cÃ¡c thuáº­t toÃ¡n thuá»™c há» SGD thÆ°á»ng cÃ³ sá»± tá»•ng quÃ¡t hÃ³a cao. Gáº§n Ä‘Ã¢y, Juntang Zhuang vÃ  cÃ¡c cá»™ng sá»± thuá»™c Ä‘áº¡i há»c Yale Ä‘Ã£ nghiÃªn cá»©u vÃ  táº¡o ra thuáº­t toÃ¡n AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients. Thuáº­t toÃ¡n nÃ y theo lá»i tÃ¡c giáº£, há»™i tá»¥ cáº£ hai Æ°u Ä‘iá»ƒm cá»§a há» Adaptive vÃ  SGD, lÃ  vá»«a cÃ³ tá»‘c Ä‘á»™ há»™i tá»¥ nhanh, vá»«a cÃ³ tÃ­nh tá»•ng quÃ¡t hÃ³a cao MÃ£ nguá»“n Ä‘Æ°á»£c tÃ¡c giáº£ cÃ´ng bá»‘ á»Ÿ link https://github.com/juntang-zhuang/Adabelief-Optimizer.\nLá»i cá»§a tÃ¡c giáº£:\nWe propose the AdaBelief optimizer, which adaptively scales the stepsize by the difference betweenpredicted gradient and observed gradient. To our knowledge, AdaBelief is the first optimizer toachieve three goals simultaneously: fast convergence as in adaptive methods, good generalization asin SGD, and training stability in complex settings such as GANs. Furthermore, Adabelief has the same parameters as Adam, hence is easy to tune. We validate the benefits of AdaBelief with intuitive examples, theoretical convergence analysis in both convex and non-convex cases, and extensiveexperiments on real-world datasets\nÄá»ƒ hiá»ƒu vá» AdaBelief, trÆ°á»›c tiÃªn, chÃºng ta pháº£i cÃ³ má»™t Ã­t kiáº¿n thá»©c cÆ¡ báº£n vá» SGD vÃ  Adam, nÃªn chÃºng ta sáº½ báº¯t Ä‘áº§u nÃ³i vá» SGD trÆ°á»›c\nSGD - Stochastic Gradient Descent Thuáº­t toÃ¡n SGD lÃ  thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a cÆ¡ báº£n theo há» gradient. Thuáº­t toÃ¡n nÃ y ráº¥t triá»ƒn khai, cÃ³ ná»n táº£ng lÃ½ thuyáº¿t vá»¯ng cháº¯c, cá»±c ká»³ á»•n Ä‘á»‹nh trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c cÃ³ thá»ƒ so sÃ¡nh vá»›i cÃ¡c thuáº­t toÃ¡n khÃ¡c. Ã tÆ°á»Ÿng cá»§a thuáº­t toÃ¡n khÃ¡ Ä‘Æ¡n giáº£n, Ä‘Ã³ lÃ  \u0026ldquo;tÃ­nh giÃ¡ trá»‹ gradient cá»§a má»—i tham sá»‘, vÃ  Ä‘i má»™t bÆ°á»›c nhá» theo chiá»u cá»§a gradient\u0026rdquo;. Náº¿u chÃºng ta láº·p Ä‘i láº·p láº¡i quÃ¡ trÃ¬nh nÃ y, vÃ  ngáº«u nhiÃªn chá»n (stochastic) má»™t táº­p batch trong táº­p huáº¥n luyá»‡n, mÃ´ hÃ¬nh chÃºng ta sáº½ Ä‘Æ°á»£c cáº£i tiáº¿n dáº§n Ä‘áº¿n Ä‘á»ƒm há»™i tá»¥.\nTrong quÃ¡ khá»©, pháº§n khÃ³ nháº¥t cá»§a SGD lÃ  viá»‡c tÃ­nh láº¡i giÃ¡ trá»‹ gradient cho toÃ n bá»™ cÃ¡c tham sá»‘ trong mÃ´ hÃ¬nh. NhÆ°ng hiá»‡n nay, cÃ¡c framwork mÃ¡y há»c nhÆ° Tensorflow, PyTouch, Caffee, Theano, \u0026hellip;. Ä‘Ã£ giÃºp chÃºng ta tÃ­nh cÃ¡c giÃ¡ trá»‹ gradient má»™t cÃ¡ch tá»± Ä‘á»™ng. Do Ä‘Ã³, cÃ´ng viá»‡c cá»§a chÃºng ta hiá»‡n thá»i Ä‘Æ¡n giáº£n hÆ¡n\n$$for \\text{ } i \\text{ } in \\text{ } range (m): $$ $$\\theta_i = \\theta_i - \\alpha ( \\hat y^{i} - y^i) x^i_j$$\nMá»™t váº¥n Ä‘á» chÃºng ta gáº·p pháº£i trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n DL vá»›i SGD lÃ  cháº­m, siÃªu cháº­m. Do thuáº­t toÃ¡n pháº£i cáº­p nháº­t toÃ n bá»™ cÃ¡c tham sá»‘, nÃªn sá»‘ lÆ°á»£ng phÃ©p tÃ­nh vÃ  lÆ°á»£ng tÃ i nguyÃªn pháº§n cá»©ng Ä‘Æ°á»£c sá»­ dá»¥ng ráº¥t lÃ  nhiá»u. Ráº¥t nhiá»u cÃ¡c biáº¿n thá»ƒ cá»§a SGD Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» trÃªn.\nAdam - Adaptive Moment Estimation Adam optimizer lÃ  má»™t thuáº­t toÃ¡n káº¿t há»£p ká»¹ thuáº­t cá»§a RMS prop vÃ  momentum. Thuáº­t toÃ¡n sá»­ dá»¥ng hai internal states momentum (m) vÃ  squared momentum (v) cá»§a gradient cho cÃ¡c tham sá»‘. Sau má»—i batch huáº¥n luyá»‡n, giÃ¡ trá»‹ cá»§a m vÃ  v Ä‘Æ°á»£c cáº­p nháº­t láº¡i sá»­ dá»¥ng exponential weighted averaging.\nMÃ£ giáº£i cá»§a viá»‡c cáº­p nháº­t m vÃ  v\n$$m_t = \\beta_1m_t-_1 + (1-\\beta_1)g_t $$ $$v_t = \\beta_2v_t-_1 + (1-\\beta_2)g^2_t$$\ntrong Ä‘Ã³, beta Ä‘Æ°á»£c xem nhÆ° lÃ  má»™t siÃªu tham sá»‘. CÃ´ng thá»©c cáº­p nháº­t theta nhÆ° sau:\n$$\\theta_t = \\theta_t-_1 - \\alpha\\frac{m_t}{\\sqrt{v_t}+ \\epsilon }$$\ntrong Ä‘Ã³, alpha lÃ  learning rate, epsion lÃ  giÃ¡ trá»‹ Ä‘Æ°á»£c thÃªm vÃ o Ä‘á»ƒ ngÄƒng viá»‡c chia cho 0\nÄá»ƒ viá»‡c descent Ä‘Æ°á»£c thá»±c hiá»‡n nhanh hÆ¡n, thuáº­t toÃ¡n Ä‘Ã£ sá»­ dá»¥ng hai ká»¹ thuáº­t:\nTÃ­nh exponential moving average cá»§a giÃ¡ trá»‹ Ä‘áº¡o hÃ m lÆ°u vÃ o biáº¿n m vÃ  sá»­ dá»¥ng nÃ³ lÃ  tá»­ sá»‘ cá»§a viá»‡c cáº­p nháº­t hÆ°á»›ng. Vá»›i Ã½ nghÄ©a lÃ  náº¿u m cÃ³ giÃ¡ trá»‹ lá»›n, thÃ¬ viá»‡c descent Ä‘ang Ä‘i Ä‘Ãºng hÆ°á»›ng vÃ  chÃºng ta cáº§n bÆ°á»›c nháº£y lá»›n hÆ¡n Ä‘á»ƒ Ä‘i nhanh hÆ¡n. TÆ°Æ¡ng tá»±, náº¿u giÃ¡ trá»‹ m nhá», pháº§n descent cÃ³ thá»ƒ khÃ´ng Ä‘i vá» hÆ°á»›ng tá»‘i tiá»ƒu vÃ  chÃºng ta nÃªn Ä‘i 1 bÆ°á»›c nhá» Ä‘á»ƒ thÄƒm dÃ². ÄÃ¢y lÃ  pháº§n momentum cá»§a thuáº­t toÃ¡n.\nTÃ­nh exponential moving average cá»§a bÃ¬nh phÆ°Æ¡ng gÃ­a trá»‹ Ä‘áº¡o hÃ m lÆ°u vÃ o biáº¿n v vÃ  sá»­ dá»¥ng nÃ³ lÃ  pháº§n máº«u sá»‘ cá»§a viá»‡c cáº­p nháº­t hÆ°á»›ng. Vá»›i Ã½ nghÄ©a nhÆ° sau: Giáº£ sá»­ gradient mang cÃ¡c giÃ¡ trá»‹ dÆ°Æ¡ng, Ã¢m láº«n lá»™n, thÃ¬ khi cá»™ng cÃ¡c giÃ¡ trá»‹ láº¡i theo cÃ´ng thá»©c tÃ­nh m ta sáº½ Ä‘Æ°á»£c giÃ¡ trá»‹ m gáº§n sá»‘ 0. Do Ã¢m dÆ°Æ¡ng láº«n lá»™n nÃªn nÃ³ bá»‹ triá»‡t tiÃªu láº«n nhau. NhÆ°ng trong trÆ°á»ng há»£p nÃ y thÃ¬ v sáº½ mang giÃ¡ trá»‹ lá»›n. Do Ä‘Ã³, trong trÆ°á»ng há»£p nÃ y, chÃºng ta sáº½ khÃ´ng hÆ°á»›ng tá»›i cá»±c tiá»ƒu, chÃºng ta sáº½ khÃ´ng muá»‘n Ä‘i theo hÆ°á»›ng Ä‘áº¡o hÃ m trong trÆ°á»ng há»£p nÃ y. ChÃºng ta Ä‘á»ƒ v á»Ÿ pháº§n máº«u vÃ¬ khi chia cho má»™t giÃ¡ trá»‹ cao, giÃ¡ trá»‹ cá»§a cÃ¡c pháº§n cáº­p nháº­t sáº½ nhá», vÃ  khi v cÃ³ giÃ¡ trá»‹ tháº¥p, pháº§n cáº­p nháº­t sáº½ lá»›n. ÄÃ¢y chÃ­nh lÃ  pháº§n tá»‘i Æ°u RMSProp cá»§a thuáº­t toÃ¡n.\ná» Ä‘Ã¢y, m Ä‘Æ°á»£c xem nhÆ° lÃ  moment thá»© nháº¥t, v xem nhÆ° lÃ  moment thá»© hai, nÃªn thuáº­t toÃ¡n cÃ³ tÃªn lÃ  \u0026ldquo;Adaptive moment estimation\u0026rdquo;.\nÄá»ƒ lÃ½ giáº£i vÃ¬ sao Adam láº¡i há»™i tá»¥ nhanh hÆ¡n so vá»›i SGD, chÃºng ta cÃ³ thá»ƒ giáº£i thÃ­ch nhÆ° sau: Exponential weighted averaging cho chÃºng ta giÃ¡ trá»‹ xáº¥p xá»‰ gradient mÆ°á»£t hÆ¡n qua má»—i láº§n láº·p, dáº«n tá»›i tÄƒng tÃ­nhs dá»«ng. Sau Ä‘Ã³, viá»‡c chia cho cÄƒng báº­c 2 cá»§a giÃ¡ trá»‹ v lÃ m sá»‘ lÆ°á»›c cá»§a chÃºng ta giáº£m máº¡nh khi phÆ°Æ¡ng sai cá»§a giÃ¡ trá»‹ gradient tÄƒng lÃªn. Äiá»u nÃ y , nhÆ° giáº£i thÃ­ch á»Ÿ trÃªn, cÃ³ nghÄ©a lÃ , khi hÆ°á»›ng Ä‘i cá»§a mÃ´ hÃ¬nh chá»‰ ra khÃ´ng rÃµ rÃ ng, thuáº­t toÃ¡n Adam thá»±c hiá»‡n cÃ¡c bÆ°á»›c Ä‘i nhá» coi nhÆ° lÃ  thÄƒm dÃ² thÃ´i. VÃ  sáº½ thá»±c hiá»‡n cÃ¡c bÆ°á»›c Ä‘i lá»›n, nhanh khi hÆ°á»›ng Ä‘i rÃµ rÃ ng.\nThuáº­t toÃ¡n Adam hoáº¡t Ä‘á»™ng khÃ¡ hiá»‡u quáº£, nhÆ°ng báº£n thÃ¢n nÃ³ cÅ©ng cÃ³ nhá»¯ng váº¥n Ä‘á». TÃ¡c giáº£ cá»§a AdaBelief Ä‘Ã£ chá»‰ ra má»™t vÃ i Ä‘iá»ƒm khÃ´ng hiá»‡u quáº£ cá»§a thuáº­t toÃ¡n\nAdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients ![HÃ¬nh áº£nh AdaBelief - Nguá»“n https://arxiv.org/pdf/2010.07468v5.pdf ] (adam_error.jpg)\nHÃ£y nhÃ¬n vÃ o hÃ¬nh trÃªn, á»Ÿ má»¥c Ä‘Ã¡nh dáº¥u lÃ  sá»‘ 3, giÃ¡ trá»‹ G lá»›n vÃ¬ Ä‘Æ°á»ng cong á»Ÿ Ä‘oáº¡n Ä‘Ã³ dá»‘c. GiÃ¡ trá»‹ v cÅ©ng lá»›n. Do Ä‘Ã³, náº¿u sá»­ dá»¥ng thuáº­t toÃ¡n Adam á»Ÿ Ä‘Ã¢y, bÆ°á»›c Ä‘i sáº½ ráº¥t nhá». Viá»‡c di chuyá»ƒn má»™t bÆ°á»›c Ä‘i nhá» á»Ÿ Ä‘Ã¢y sáº½ lÃ m cháº­m quÃ¡ trÃ¬nh há»™i tá»¥ vÃ  khÃ´ng cáº§n thiáº¿t. Bá»Ÿi vÃ¬ chÃºng ta tin tÆ°á»Ÿng ráº±ng chÃºng ta Ä‘ang Ä‘i Ä‘Ãºng hÆ°á»›ng, vÃ  chÃºng ta cáº§n má»™t bÆ°á»›c Ä‘i dÃ i hÆ¡n.\nAdaBelief sá»­a lá»—i nÃ y báº±ng má»™t thay Ä‘á»•i nhá» trong thuáº­t toÃ¡n cá»§a adam. Thay vÃ¬ tÃ­nh bÃ¬nh phÆ°Æ¡ng cá»§a gradient, AdaBelief sáº½ tÃ­nh phÆ°Æ¡ng sai cá»§a gradient. Má»™t sá»± thay Ä‘á»•i nhá» nhÆ°ng mang láº¡i giÃ¡ trá»‹ to lá»›n.\n$$v_t = \\beta_2v_t-_1 + (1-\\beta_2)g^2_t $$ $$s_t = \\beta_2v_t-_1 + (1-\\beta_2)(g_t-m_t)^2$$\nTÃ¡c giáº£ khÃ´ng dÃ¹ng biáº¿n v ná»¯a, mÃ  thay báº±ng biáº¿n s.\nVá»›i viá»‡c dÃ¹ng biáº¿n s. Trong trÆ°á»ng há»£p trÃªn, g lá»›n vÃ  m lá»›n, thÃ¬ s sáº½ nhá». VÃ  khi s á»Ÿ pháº§n máº«u nhá», chÃºng ta sáº½ cÃ³ bÆ°á»›c Ä‘i xa hÆ¡n. á» Ä‘Ã¢y, AdaBelief Ä‘Ã£ giáº£i quyáº¿t váº¥n Ä‘á»\nQua Ä‘Ã¢y, chÃºng ta cÅ©ng cÃ³ thá»ƒ giáº£i thÃ­ch vÃ¬ sao cÃ³ chá»¯ \u0026ldquo;belief\u0026rdquo; trong tá»« AdaBelief. GiÃ¡ trá»‹ phÆ°Æ¡ng sai Ä‘Æ°á»£c tÃ­nh dá»±a vÃ o ká»³ vá»ng cá»§a giÃ¡ trá»‹ gradient.\nMá»™t chÃº Ã½ nhá» á»Ÿ Ä‘Ã¢y lÃ  má»¥c sá»‘ 1 vÃ  má»¥c sá»‘ 3 Ä‘Æ°á»£c coi lÃ  cáº£i tiáº¿n cá»§a Adam so vá»›i momentum vÃ  SGD. Táº¥t nhiÃªn, AdaBelief cÅ©ng káº¿ thá»«a máº¥y cÃ¡i nÃ y.\ná» má»¥c Ä‘Ã¡nh dáº¥u sá»‘ 1 trÃªn hÃ¬nh, Ä‘Æ°á»ng cong khÃ¡ pháº³ng vÃ  giÃ¡ trá»‹ Ä‘áº¡o hÃ m gáº§n nhÆ° báº±ng 0. Náº¿u sá»­ dá»¥ng SGD, chÃºng ta sáº½ cÃ³ má»™t bÆ°á»›c Ä‘i nhá». Trong khi Ä‘Ã³, há» Adam sáº½ cho chÃºng ta bÆ°á»›c Ä‘i lá»›n hÆ¡n vÃ¬ giÃ¡ trá»‹ cÄƒng báº­c hai cá»§a s hoáº·c v á»Ÿ máº«u sá»‘ sáº½ cho ra má»™t káº¿t quáº£ ráº¥t nhá».\ná» má»¥c Ä‘Ã¡nh dáº¥u sá»‘ 2, Ä‘Æ°á»ng cong á»Ÿ Ä‘Ã¢y ráº¥t dá»‘c vÃ  háº¹p, g vÃ  delta g á»Ÿ Ä‘Ã¢y ráº¥t lá»›n, cho nÃªn á»Ÿ Ä‘Ã¢y chÃºng ta cáº§n má»™t bÆ°á»›c di chuyá»ƒn nhá». Náº¿u sá»­ dá»¥ng SGD hoáº·c momentum thÃ¬ sáº½ Ä‘i má»™t bÆ°á»›c Ä‘i ráº¥t lá»›n do nhÃ¢n vá»›i má»™t lÆ°á»£ng moving averages lá»›n. Trong khi Ä‘Ã³, vá»›i Adam hoáº·c AdaBelief, chÃºng ta sáº½ cÃ³ giÃ¡ trá»‹ cÄƒng báº­c hai cá»§a s hoáº·c v á»Ÿ máº«u sá»‘ lá»›n nÃªn bÆ°á»›c Ä‘i sáº½ nhá» hÆ¡n.\nVá» tá»‘c Ä‘á»™ há»™i tá»¥, tÃ¡c giáº£ cÃ³ Ä‘á» cáº­p rÃµ vÃ  chi tiáº¿t trong bÃ i bÃ¡o, mÃ¬nh khÃ´ng Ä‘á» cáº­p láº¡i nÃ³ ná»¯a á»Ÿ Ä‘Ã¢y. CÃ¡c báº¡n tá»± xem nhÃ©.\nKáº¿t luáº­n AdaBelief lÃ  thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a cÃ³ nguá»“n gá»‘c tá»« thuáº­t toÃ¡n Adam, khÃ´ng cÃ³ thÃªm tham sá»‘ ngoÃ i, chá»‰ thay Ä‘á»•i 1 dÃ²ng code.\nThuáº­t toÃ¡n Ä‘Ã£ tÄƒng tá»‘c Ä‘á»™ há»™i tá»¥ cÅ©ng nhÆ° má»©c tá»•ng quÃ¡t hÃ³a.\nThuáº­t toÃ¡n thá»±c hiá»‡n cÃ¡c bÆ°á»›c Ä‘i dá»±a vÃ o \u0026ldquo;belief\u0026rdquo; cá»§a hÆ°á»›ng gradient á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i.\nThuáº­t toÃ¡n giáº£i quyáº¿t váº¥n Ä‘á» \u0026ldquo;Large gradient, small curvature\u0026rdquo; báº±ng cÃ¡ch xem xÃ©t biÃªn Ä‘á»™ vÃ  dáº¥u cá»§a gradient.\nNguá»“n:\nhttps://arxiv.org/abs/2010.07468\nhttps://medium.com/the-dl/understanding-the-new-adabelief-optimizer-2db70ef6de1e\nhttps://towardsdatascience.com/adabelief-optimizer-fast-as-adam-generalizes-as-good-as-sgd-71a919597af\n","date":"Jan 15, 2021","img":"https://unsplash.it/1920/1080?image=36","permalink":"/blog/2021-01-15---adabelief-optimizer/","series":null,"tags":["Machine Learning","Optimizer","SGD","Opencv"],"title":"TÃ¬m Hiá»ƒu Thuáº­t ToÃ¡n Tá»‘i Æ¯u HÃ³a Adabelief Optimizer"},{"categories":null,"content":" Advantages of Reinforcement Learning Thiáº¿t láº­p bÃ n cá» Khá»Ÿi táº¡o bÃ n cá» Kiá»ƒm tra Reward Thiáº¿t láº­p ngÆ°á»i chÆ¡i Khá»Ÿi táº¡o Chá»n nÆ°á»›c Ä‘i Cáº­p nháº­t tráº¡ng thÃ¡i Huáº¥n luyá»‡n mÃ´ hÃ¬nh Advantages of Reinforcement Learning Trong khi trong cÃ¡c phÆ°Æ¡ng phÃ¡p lÃ½ thuyáº¿t trÃ² chÆ¡i nÃ³i chung, vÃ­ dá»¥ thuáº­t toÃ¡n min-max, thuáº­t toÃ¡n luÃ´n giáº£ Ä‘á»‹nh chÃºng ta cÃ³ má»™t Ä‘á»‘i thá»§ hoÃ n háº£o, cÃ´ng viá»‡c pháº£i thá»±c hiá»‡n lÃ  tá»‘i Ä‘a hÃ³a pháº§n thÆ°á»Ÿng cá»§a mÃ¬nh vÃ  giáº£m thiá»ƒu pháº§n thÆ°á»Ÿng cá»§a Ä‘á»‘i thá»§ ( tá»‘i Ä‘a hÃ³a Ä‘iá»ƒm cá»§a mÃ¬nh vÃ  tá»‘i thiá»ƒu hÃ³a Ä‘iá»ƒm cá»§a Ä‘á»‘i thá»§), trong há»c cá»§ng cá»‘, chÃºng ta khÃ´ng cáº§n giáº£ Ä‘á»‹nh Ä‘á»‘i thá»§ cá»§a chÃºng ta lÃ  1 thiÃªn tÃ i xuáº¥t chÃºng, nhÆ°ng chung ta váº«n thu Ä‘Æ°á»£c mÃ´ hÃ¬nh vá»›i káº¿t quáº£ ráº¥t tá»‘t.\nBáº±ng cÃ¡ch coi Ä‘á»‘i thá»§ lÃ  má»™t pháº§n cá»§a mÃ´i trÆ°á»ng mÃ  chÃºng ta cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c, sau má»™t sá»‘ láº§n láº·p láº¡i nháº¥t Ä‘á»‹nh, Ä‘á»‘i thá»§ cÃ³ thá»ƒ láº­p káº¿ hoáº¡ch trÆ°á»›c mÃ  khÃ´ng cáº§n chÃºng ta pháº£i lÃ m gÃ¬ cáº£. Æ¯u Ä‘iá»ƒm cá»§a phÆ°Æ¡ng phÃ¡p nÃ y lÃ  giáº£m sá»‘ lÆ°á»£ng khÃ´ng gian tÃ¬m kiáº¿m vÃ  giáº£m sá»‘ phÃ©p toÃ¡n suy luáº­n pháº£i thá»±c hiá»‡n, nhÆ°ng nÃ³ cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c ká»¹ nÄƒng hiá»‡n Ä‘áº¡i chá»‰ báº±ng cÃ¡ch thá»­ vÃ  há»c.\nTrong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ lÃ m cÃ¡c cÃ´ng viá»‡c sau:\nThá»© nháº¥t, huáº¥n luyá»‡n mÃ´ hÃ¬nh cho 2 mÃ¡y Ä‘áº¥u vá»›i nhau mÃ  thu Ä‘Æ°á»£c cÃ¡c trá»ng sá»‘ cáº§n thiáº¿t.\nThá»© hai, cho ngÆ°á»i Ä‘Ã¡nh vá»›i mÃ¡y\nÄá»ƒ hÃ¬nh thÃ nh bÃ i toÃ¡n há»c cá»§ng cá»‘ Reinforcement Learning , chÃºng ta cáº§n pháº£i xÃ¡c Ä‘á»‹nh rÃµ 3 thÃ nh pháº§n chÃ­nh:\nState\nAction\nReward\nVá»›i:\nState chÃ­nh lÃ  bÃ n cá» vá»›i cÃ¡c nÆ°á»›c Ä‘i cá»§a cÃ¡c ngÆ°á»i chÆ¡i. ChÃºng ta sáº½ táº¡o má»™t bÃ n cá» cÃ³ kÃ­ch thÆ°á»›c 3x3, giÃ¡ trá»‹ cá»§a má»—i Ã´ cá» Ä‘á»u lÃ  0. Vá»‹ trÃ­ ngÆ°á»i chÆ¡i 1 Ä‘áº·t quÃ¢n sáº½ Ä‘Æ°á»£c gÃ¡n lÃ  1. Vá»‹ trÃ­ ngÆ°á»i chÆ¡i 2 Ä‘áº·t quÃ¢n sáº½ Ä‘Æ°á»£c gÃ¡n lÃ  -1.\nAction lÃ  vá»‹ trÃ­ ngÆ°á»i chÆ¡i sáº½ Ä‘i quÃ¢n khi biáº¿t state hiá»‡n táº¡i (nghÄ©a lÃ  biáº¿t Ä‘á»‘i thá»§ Ä‘i nÆ°á»›c nÃ o, vÃ  cÃ³ nhá»¯ng nÆ°á»›c nÃ o hiá»‡n Ä‘ang trÃªn bÃ n cá»).\nReward: mang giÃ¡ trá»‹ 0 hoáº·c 1. Khi káº¿t thÃºc game sáº½ tráº£ vá» giÃ¡ trá»‹ cho reward.\ná» pháº§n dÆ°á»›i Ä‘Ã¢y, mÃ¬nh sáº½ note láº¡i code vÃ  sáº½ comment trong code Ä‘á»ƒ cho rÃµ Ã½\nThiáº¿t láº­p bÃ n cá» Khá»Ÿi táº¡o bÃ n cá» 1 2def __init__(self, p1, p2): 3 self.board = np.zeros((BOARD_ROWS, BOARD_COLS)) 4 self.p1 = p1 5 self.p2 = p2 6 self.isEnd = False 7 self.boardHash = None 8 # init p1 plays first 9 self.playerSymbol = 1 ChÃºng ta sáº½ táº¡o má»™t bÃ n cá» cÃ³ kÃ­ch thÆ°á»›c 3x3, 2 biáº¿n ngÆ°á»i chÆ¡i. NgÆ°á»i 1 lÃ  ngÆ°á»i chÆ¡i Ä‘áº§u tiÃªn.\n1 2# Tráº£ vá» danh sÃ¡ch cÃ¡c nÆ°á»›c cÃ³ thá»ƒ Ä‘i 3def availablePositions(self): 4 positions = [] 5 for i in range(BOARD_ROWS): 6 for j in range(BOARD_COLS): 7 if self.board[i, j] == 0: 8 positions.append((i, j)) # need to be tuple 9 return positions 10 11# Cáº­p nháº­t láº¡i lÃªn bÃ n cá» vá»‹ trÃ­ cá»§a ngÆ°á»i chÆ¡i Ä‘áº·t quÃ¢n 12 13def updateState(self, position): 14 self.board[position] = self.playerSymbol 15 # switch to another player 16 self.playerSymbol = -1 if self.playerSymbol == 1 else 1 Kiá»ƒm tra Reward Sau má»—i nÆ°á»›c Ä‘i cá»§a cÃ¡c ká»³ thá»§, chÃºng ta cáº§n 1 hÃ m Ä‘á»ƒ kiá»ƒm tra xem ká»³ thá»§ tháº¯ng hay thua vÃ  tráº£ vá» káº¿t quáº£ cho reward nhÆ° Ä‘á» cáº­p á»Ÿ trÃªn\n1 2def winner(self): 3 4\t# Kiá»ƒm tra theo dÃ²ng 5 6\tfor i in range(BOARD_ROWS): 7\tif sum(self.board[i, :]) == 3: 8\tself.isEnd = True 9\treturn 1 10\tif sum(self.board[i, :]) == -3: 11\tself.isEnd = True 12\treturn -1 13\t# kiá»ƒm tra theo cá»™t 14 15\tfor i in range(BOARD_COLS): 16\tif sum(self.board[:, i]) == 3: 17\tself.isEnd = True 18\treturn 1 19\tif sum(self.board[:, i]) == -3: 20\tself.isEnd = True 21\treturn -1 22 23\t# kiá»ƒm tra theo Ä‘Æ°á»ng chÃ©o chÃ­nh vÃ  theo Ä‘Æ°á»ng chÃ©o phá»¥ 24 25\tdiag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)]) # Ä‘Æ°á»ng chÃ©o chÃ­nh 26 27\tdiag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)]) # Ä‘Æ°á»ng chÃ©o phá»¥ 28 29\tdiag_sum = max(abs(diag_sum1), abs(diag_sum2)) # láº¥y trá»‹ tuyá»‡t Ä‘á»‘i cá»§a cÃ¡c nÆ°á»›c Ä‘i, náº¿u báº±ng 3 nghÄ©a lÃ  cÃ³ ngÆ°á»i chÆ¡i chiáº¿n tháº¯ng 30 31\tif diag_sum == 3: 32\tself.isEnd = True 33\tif diag_sum1 == 3 or diag_sum2 == 3: 34\treturn 1 35\telse: 36\treturn -1 37 38\t# Kiá»ƒm tra xem cÃ²n nÆ°á»›c Ä‘i hay khÃ´ng 39\tif len(self.availablePositions()) == 0: 40\tself.isEnd = True 41\treturn 0 42 43\t# not end 44\tself.isEnd = False 45\treturn None 46 47# only when game ends 48def giveReward(self): 49\tresult = self.winner() 50\t# backpropagate reward 51\tif result == 1: 52\tself.p1.feedReward(1) 53\tself.p2.feedReward(0) 54\telif result == -1: 55\tself.p1.feedReward(0) 56\tself.p2.feedReward(1) 57\telse: 58\tself.p1.feedReward(0.1) 59\tself.p2.feedReward(0.5) á» Ä‘Ã¢y cÃ³ má»™t lÆ°u Ã½. Khi cá» hÃ²a thÃ¬ chÃºng ta cÅ©ng xem ráº±ng ngÆ°á»i Ä‘i trÆ°á»›c thua, nÃªn há»‡ sá»‘ lÃºc cá» hÃ²a sáº½ lÃ  0.1-0.5. CÃ¡c báº¡n cÃ³ thá»ƒ thiáº¿t láº­p má»™t giÃ¡ trá»‹ khÃ¡c, vÃ­ dá»¥ 0.2-0.5 hoáº·c 0.5-0.5 tÃ¹y thÃ­ch.\nThiáº¿t láº­p ngÆ°á»i chÆ¡i NgÆ°á»i chÆ¡i cáº§n cÃ³ cÃ¡c phÆ°Æ¡ng thá»©c sau:\nChá»n nÆ°á»›c Ä‘i dá»±a trÃªn tráº¡ng thÃ¡i hiá»‡n táº¡i cá»§a bÃ n cá».\nLÆ°u láº¡i tráº¡ng thÃ¡i cá»§a vÃ¡n cá».\nCáº­p nháº­t láº¡i giÃ¡ trá»‹ tráº¡ng thÃ¡i sau má»—i vÃ¡n.\nLÆ°u vÃ  load cÃ¡c trá»ng sá»‘ lÃªn.\nKhá»Ÿi táº¡o 1 2def __init__(self, name, exp_rate=0.2): 3 self.name = name 4 self.states = [] # record all positions taken 5 self.lr = 0.2 6 self.exp_rate = exp_rate 7 self.decay_gamma = 0.9 8 self.states_value = {} # state -\u0026gt; value Chá»n nÆ°á»›c Ä‘i 1 2def chooseAction(self, positions, current_board, symbol): 3\trandValue = np.random.uniform(0, 1) 4\tvalue_max = value = -999 5\tif randValue\u0026gt; self.exp_rate: 6 7\tfor p in positions: 8\tnext_board = current_board.copy() 9\tnext_board[p] = symbol 10\tnext_boardHash = self.getHash(next_board) 11\tvalue = -999 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash) 12\t# print(\u0026#34;value\u0026#34;, value) 13\tif value \u0026gt;= value_max: 14\tvalue_max = value 15\taction = p 16 17\tif value_max == -999 : 18\t# take random action 19\tidx = np.random.choice(len(positions)) 20\taction = positions[idx] 21 22\t# print(\u0026#34;{} takes action {}\u0026#34;.format(self.name, action)) 23\treturn action Cáº­p nháº­t tráº¡ng thÃ¡i ChÃºng ta sáº½ cáº­p nháº­t tráº¡ng thÃ¡i vá»›i cÃ´ng thá»©c sau\n$$ V(S_t) = V(S_t) + \\alpha [V(S_{t+1}) - V(S_t)] $$\nDiá»…n giáº£i ra tiáº¿ng viá»‡t, giÃ¡ trá»‹ cá»§a tráº¡ng thÃ¡i táº¡i thá»i Ä‘iá»ƒm t báº±ng giÃ¡ trá»‹ táº¡i thá»i Ä‘iá»ƒm hiá»‡n táº¡i cá»™ng vá»›i Ä‘á»™ lá»‡ch cá»§a tráº¡ng thÃ¡i hiá»‡n táº¡i vÃ  tráº¡ng thÃ¡i tiáº¿p theo nhÃ¢n vá»›i má»™t há»‡ sá»‘ há»c alpha.\n1 2# at the end of game, backpropagate and update states value 3def feedReward(self, reward): 4 for st in reversed(self.states): 5 if self.states_value.get(st) is None: 6 self.states_value[st] = 0 7 self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st]) 8 reward = self.states_value[st] Huáº¥n luyá»‡n mÃ´ hÃ¬nh Pháº§n nÃ y náº±m trong lá»›p State. ChÃºng ta sáº½ láº§n lÆ°á»£t Ä‘i qua cÃ¡c quÃ¡ trÃ¬nh luÃ¢n phiÃªn nhau giá»¯a ngÆ°á»i chÆ¡i 1 vÃ  ngÆ°á»i chÆ¡i 2\nngÆ°á»i chÆ¡i chá»n nÆ°á»›c cÃ³ thá»ƒ Ä‘i -\u0026gt; cáº­p nháº­t tráº¡ng thÃ¡i -\u0026gt; kiá»ƒm tra tháº¯ng/thua -\u0026gt; ngÆ°á»i chÆ¡i chá»n nÆ°á»›c cÃ³ thá»ƒ Ä‘i \u0026hellip;\n1 2def play(self, rounds=100): 3\tfor i in range(rounds): 4\tif i % 1000 == 0: 5\tprint(\u0026#34;Rounds {}\u0026#34;.format(i)) 6\twhile not self.isEnd: 7\t# Player 1 8\tpositions = self.availablePositions() 9\tp1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 10\t# take action and upate board state 11\tself.updateState(p1_action) 12\tboard_hash = self.getHash() 13\tself.p1.addState(board_hash) 14\t# check board status if it is end 15 16\twin = self.winner() 17\tif win is not None: 18\t# self.showBoard() 19\t# ended with p1 either win or draw 20\tself.giveReward() 21\tself.p1.reset() 22\tself.p2.reset() 23\tself.reset() 24\tbreak 25 26\telse: 27\t# Player 2 28\tpositions = self.availablePositions() 29\tp2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol) 30\tself.updateState(p2_action) 31\tboard_hash = self.getHash() 32\tself.p2.addState(board_hash) 33 34\twin = self.winner() 35\tif win is not None: 36\t# self.showBoard() 37\t# ended with p2 either win or draw 38\tself.giveReward() 39\tself.p1.reset() 40\tself.p2.reset() 41\tself.reset() 42\tbreak Sau khi huáº¥n luyá»‡n 100 ngÃ n láº§n, chÃºng ta sáº½ chÆ¡i vá»›i mÃ¡y, chá»‰ lÃ  1 thay Ä‘á»•i nhá» trong hÃ m chooseAction lÃ  thay vÃ¬ láº¥y nÆ°á»›c Ä‘i cÃ³ trá»ng sá»‘ lá»›n nháº¥t, chÃºng ta sáº½ cho ngÆ°á»i dÃ¹ng nháº­p tá»« bÃ n phÃ­m dÃ²ng vÃ  cá»™t vÃ o\n1 2 3def chooseAction(self, positions): 4 while True: 5 row = int(input(\u0026#34;Input your action row:\u0026#34;)) 6 col = int(input(\u0026#34;Input your action col:\u0026#34;)) 7 action = (row, col) 8 if action in positions: 9 return action VÃ  sá»­a láº¡i hÃ m play má»™t chÃºt, bá» loop 100k láº§n Ä‘i, bá» gá»i hÃ m cáº­p nháº­t thÆ°á»Ÿng vÃ  bá» cÃ¡c hÃ m reset Ä‘i\n1 2 3# play with human 4def play2(self): 5\twhile not self.isEnd: 6\t# Player 1 7\tpositions = self.availablePositions() 8\tp1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 9\t# take action and upate board state 10\tself.updateState(p1_action) 11\tself.showBoard() 12\t# check board status if it is end 13\twin = self.winner() 14\tif win is not None: 15\tif win == 1: 16\tprint(self.p1.name, \u0026#34;wins!\u0026#34;) 17\telse: 18\tprint(\u0026#34;tie!\u0026#34;) 19\tself.reset() 20\tbreak 21 22\telse: 23\t# Player 2 24\tpositions = self.availablePositions() 25\tp2_action = self.p2.chooseAction(positions) 26 27\tself.updateState(p2_action) 28\tself.showBoard() 29\twin = self.winner() 30\tif win is not None: 31\tif win == -1: 32\tprint(self.p2.name, \u0026#34;wins!\u0026#34;) 33\telse: 34\tprint(\u0026#34;tie!\u0026#34;) 35\tself.reset() 36\tbreak MÃ£ nguá»“n hoÃ n chá»‰nh cá»§a chÆ°Æ¡ng trÃ¬nh\n1 2import numpy as np 3import pickle 4 5BOARD_ROWS = 3 6BOARD_COLS = 3 7 8 9class State: 10 def __init__(self, p1, p2): 11 self.board = np.zeros((BOARD_ROWS, BOARD_COLS)) 12 self.p1 = p1 13 self.p2 = p2 14 self.isEnd = False 15 self.boardHash = None 16 # init p1 plays first 17 self.playerSymbol = 1 18 19 # get unique hash of current board state 20 def getHash(self): 21 self.boardHash = str(self.board.reshape(BOARD_COLS * BOARD_ROWS)) 22 return self.boardHash 23 24 def winner(self): 25 # row 26 for i in range(BOARD_ROWS): 27 if sum(self.board[i, :]) == 3: 28 self.isEnd = True 29 return 1 30 if sum(self.board[i, :]) == -3: 31 self.isEnd = True 32 return -1 33 # col 34 for i in range(BOARD_COLS): 35 if sum(self.board[:, i]) == 3: 36 self.isEnd = True 37 return 1 38 if sum(self.board[:, i]) == -3: 39 self.isEnd = True 40 return -1 41 # diagonal 42 diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)]) 43 diag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)]) 44 diag_sum = max(abs(diag_sum1), abs(diag_sum2)) 45 if diag_sum == 3: 46 self.isEnd = True 47 if diag_sum1 == 3 or diag_sum2 == 3: 48 return 1 49 else: 50 return -1 51 52 # tie 53 # no available positions 54 if len(self.availablePositions()) == 0: 55 self.isEnd = True 56 return 0 57 # not end 58 self.isEnd = False 59 return None 60 61 def availablePositions(self): 62 positions = [] 63 for i in range(BOARD_ROWS): 64 for j in range(BOARD_COLS): 65 if self.board[i, j] == 0: 66 positions.append((i, j)) # need to be tuple 67 return positions 68 69 def updateState(self, position): 70 self.board[position] = self.playerSymbol 71 # switch to another player 72 self.playerSymbol = -1 if self.playerSymbol == 1 else 1 73 74 # only when game ends 75 def giveReward(self): 76 result = self.winner() 77 # backpropagate reward 78 if result == 1: 79 self.p1.feedReward(1) 80 self.p2.feedReward(0) 81 elif result == -1: 82 self.p1.feedReward(0) 83 self.p2.feedReward(1) 84 else: 85 self.p1.feedReward(0.1) 86 self.p2.feedReward(0.5) 87 88 # board reset 89 def reset(self): 90 self.board = np.zeros((BOARD_ROWS, BOARD_COLS)) 91 self.boardHash = None 92 self.isEnd = False 93 self.playerSymbol = 1 94 95 def play(self, rounds=100): 96 for i in range(rounds): 97 if i % 1000 == 0: 98 print(\u0026#34;Rounds {}\u0026#34;.format(i)) 99 while not self.isEnd: 100 # Player 1 101 positions = self.availablePositions() 102 p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 103 # take action and upate board state 104 self.updateState(p1_action) 105 board_hash = self.getHash() 106 self.p1.addState(board_hash) 107 # check board status if it is end 108 109 win = self.winner() 110 if win is not None: 111 # self.showBoard() 112 # ended with p1 either win or draw 113 self.giveReward() 114 self.p1.reset() 115 self.p2.reset() 116 self.reset() 117 break 118 119 else: 120 # Player 2 121 positions = self.availablePositions() 122 p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol) 123 self.updateState(p2_action) 124 board_hash = self.getHash() 125 self.p2.addState(board_hash) 126 127 win = self.winner() 128 if win is not None: 129 # self.showBoard() 130 # ended with p2 either win or draw 131 self.giveReward() 132 self.p1.reset() 133 self.p2.reset() 134 self.reset() 135 break 136 137 138 # play with human 139 def play2(self): 140 while not self.isEnd: 141 # Player 1 142 positions = self.availablePositions() 143 p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 144 # take action and upate board state 145 self.updateState(p1_action) 146 self.showBoard() 147 # check board status if it is end 148 win = self.winner() 149 if win is not None: 150 if win == 1: 151 print(self.p1.name, \u0026#34;wins!\u0026#34;) 152 else: 153 print(\u0026#34;tie!\u0026#34;) 154 self.reset() 155 break 156 157 else: 158 # Player 2 159 positions = self.availablePositions() 160 p2_action = self.p2.chooseAction(positions) 161 162 self.updateState(p2_action) 163 self.showBoard() 164 win = self.winner() 165 if win is not None: 166 if win == -1: 167 print(self.p2.name, \u0026#34;wins!\u0026#34;) 168 else: 169 print(\u0026#34;tie!\u0026#34;) 170 self.reset() 171 break 172 173 174 def showBoard(self): 175 # p1: x p2: o 176 for i in range(0, BOARD_ROWS): 177 print(\u0026#39;-------------\u0026#39;) 178 out = \u0026#39;| \u0026#39; 179 for j in range(0, BOARD_COLS): 180 token = \u0026#34;\u0026#34; 181 if self.board[i, j] == 1: 182 token = \u0026#39;x\u0026#39; 183 if self.board[i, j] == -1: 184 token = \u0026#39;o\u0026#39; 185 if self.board[i, j] == 0: 186 token = \u0026#39; \u0026#39; 187 out += token + \u0026#39; | \u0026#39; 188 print(out) 189 print(\u0026#39;-------------\u0026#39;) 190 191 192class Player: 193 def __init__(self, name, exp_rate=0.3): 194 self.name = name 195 self.states = [] # record all positions taken 196 self.lr = 0.3 197 self.exp_rate = exp_rate 198 self.decay_gamma = 0.9 199 self.states_value = {} # state -\u0026gt; value 200 201 def getHash(self, board): 202 boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS)) 203 return boardHash 204 205 def chooseAction(self, positions, current_board, symbol): 206 randValue = np.random.uniform(0, 1) 207 value_max = value = -999 208 if randValue\u0026gt; self.exp_rate: 209 210 for p in positions: 211 next_board = current_board.copy() 212 next_board[p] = symbol 213 next_boardHash = self.getHash(next_board) 214 value = -999 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash) 215 # print(\u0026#34;value\u0026#34;, value) 216 if value \u0026gt;= value_max: 217 value_max = value 218 action = p 219 220 if value_max == -999 : 221 # take random action 222 idx = np.random.choice(len(positions)) 223 action = positions[idx] 224 225 # print(\u0026#34;{} takes action {}\u0026#34;.format(self.name, action)) 226 return action 227 228 # append a hash state 229 def addState(self, state): 230 self.states.append(state) 231 232 # at the end of game, backpropagate and update states value 233 def feedReward(self, reward): 234 for st in reversed(self.states): 235 if self.states_value.get(st) is None: 236 self.states_value[st] = 0 237 self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st]) 238 reward = self.states_value[st] 239 240 def reset(self): 241 self.states = [] 242 243 def savePolicy(self): 244 fw = open(\u0026#39;policy_\u0026#39; + str(self.name), \u0026#39;wb\u0026#39;) 245 pickle.dump(self.states_value, fw) 246 fw.close() 247 248 def loadPolicy(self, file): 249 fr = open(file, \u0026#39;rb\u0026#39;) 250 self.states_value = pickle.load(fr) 251 fr.close() 252 253 254class HumanPlayer: 255 def __init__(self, name): 256 self.name = name 257 258 def chooseAction(self, positions): 259 while True: 260 row = int(input(\u0026#34;Input your action row:\u0026#34;)) 261 col = int(input(\u0026#34;Input your action col:\u0026#34;)) 262 action = (row, col) 263 if action in positions: 264 return action 265 266 # append a hash state 267 def addState(self, state): 268 pass 269 270 # at the end of game, backpropagate and update states value 271 def feedReward(self, reward): 272 pass 273 274 def reset(self): 275 pass 276 277 278if __name__ == \u0026#34;__main__\u0026#34;: 279 # training 280 p1 = Player(\u0026#34;p1\u0026#34;) 281 p2 = Player(\u0026#34;p2\u0026#34;) 282 283 st = State(p1, p2) 284 print(\u0026#34;training...\u0026#34;) 285 st.play(100000) 286 287 p1.savePolicy() 288 289 # play with human 290 p1 = Player(\u0026#34;computer\u0026#34;, exp_rate=0) 291 p1.loadPolicy(\u0026#34;policy_p1\u0026#34;) 292 293 p2 = HumanPlayer(\u0026#34;human\u0026#34;) 294 295 st = State(p1, p2) 296 st.play2() Nguá»“n\nReinforcement Learning: An Introduction phiÃªn báº£n 2 cá»§a Richard S. Sutton and Andrew G. Barto\nhttps://towardsdatascience.com/reinforcement-learning-implement-tictactoe-189582bea542\n","date":"Dec 27, 2020","img":"https://unsplash.it/1920/1080?image=39","permalink":"/blog/2020-12-26---tic-tac-toe/","series":null,"tags":["Reinforcement Learning","TicTacToe","Opencv"],"title":"Reinforcement Learning VÃ  Tictactoe"},{"categories":null,"content":" MÃ£ nguá»“n MÃ£ nguá»“n 1 2import cv2 3import numpy as np 4from random import choice 5 6def getColor(): 7\tlstColor = [[255,64,64],[255,165,0],[255,244,79],[102,255,0],[172,229,238],[148,87,235],[148,87,235],[241,156,187]] 8\treturn choice(lstColor) 9 10def getInfo(piece): 11\tif piece == \u0026#34;\u0026#34;: 12\tcoords = np.array([[0, 0]]) 13\telif piece == \u0026#34;I\u0026#34;: 14\tcoords = np.array([[0, 3], [0, 4], [0, 5], [0, 6]]) 15\telif piece == \u0026#34;T\u0026#34;: 16\tcoords = np.array([[1, 3], [1, 4], [1, 5], [0, 4]]) 17\telif piece == \u0026#34;L\u0026#34;: 18\tcoords = np.array([[1, 3], [1, 4], [1, 5], [0, 5]]) 19\telif piece == \u0026#34;J\u0026#34;: 20\tcoords = np.array([[1, 3], [1, 4], [1, 5], [0, 3]]) 21\telif piece == \u0026#34;S\u0026#34;: 22\tcoords = np.array([[1, 5], [1, 4], [0, 3], [0, 4]]) 23\telif piece == \u0026#34;Z\u0026#34;: 24\tcoords = np.array([[1, 3], [1, 4], [0, 4], [0, 5]]) 25\telse: 26\tcoords = np.array([[0, 4], [0, 5], [1, 4], [1, 5]]) 27 28\treturn coords, getColor() 29 30def display(board, coords, color, next_info, held_info, score, SPEED): 31\t# Generates the display 32 33\tborder = np.uint8(127 - np.zeros([20, 1, 3])) 34\tborder_ = np.uint8(127 - np.zeros([1, 23, 3])) 35 36\tdummy = board.copy() 37\tdummy[coords[:,0], coords[:,1]] = color 38 39\tright = np.uint8(np.zeros([20, 10, 3])) 40\tright[next_info[0][:,0] + 2, next_info[0][:,1]] = next_info[1] 41 42\tdummy = np.concatenate(( border, dummy, border, right, border), 1) 43\tdummy = np.concatenate((border_, dummy, border_), 0) 44\tdummy = dummy.repeat(20, 0).repeat(20, 1) 45\tdummy = cv2.putText(dummy, str(score), (325, 150), cv2.FONT_HERSHEY_DUPLEX, 1, [0, 0, 255], 2) 46 47\t# Instructions for the player 48\tindex_pos = 300 49\tx_index_pos = 300 50\tdummy = cv2.putText(dummy, \u0026#34;A - left\u0026#34;, (x_index_pos, index_pos), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 51\tdummy = cv2.putText(dummy, \u0026#34;D - right\u0026#34;, (x_index_pos, index_pos+25), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 52\tdummy = cv2.putText(dummy, \u0026#34;S - drain\u0026#34;, (x_index_pos, index_pos+50), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 53\tdummy = cv2.putText(dummy, \u0026#34;W - rotate\u0026#34;, (x_index_pos, index_pos+75), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 54\t# dummy = cv2.putText(dummy, \u0026#34;J - rotate left\u0026#34;, (45, 300), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 255]) 55\t# dummy = cv2.putText(dummy, \u0026#34;L - rotate right\u0026#34;, (45, 325), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 255]) 56\t# dummy = cv2.putText(dummy, \u0026#34;I - hold\u0026#34;, (45, 350), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 255]) 57 58\tcv2.imshow(\u0026#34;Tetris\u0026#34;, dummy) 59\tkey = cv2.waitKey(int(1000/SPEED)) 60 61\treturn key 62 63def getNextPiece(): 64\tnext_piece = choice([\u0026#34;O\u0026#34;, \u0026#34;I\u0026#34;, \u0026#34;S\u0026#34;, \u0026#34;Z\u0026#34;, \u0026#34;L\u0026#34;, \u0026#34;J\u0026#34;, \u0026#34;T\u0026#34;]) 65 66\treturn next_piece 67 68SPEED = 1 # Controls the speed of the tetris pieces 69 70# Make a board 71 72board = np.uint8(np.zeros([20, 10, 3])) 73 74# Initialize some variables 75 76quit = False 77place = False 78drop = False 79switch = False 80held_piece = \u0026#34;\u0026#34; 81flag = 0 82score = 0 83next_piece =\u0026#34;\u0026#34; 84current_piece = \u0026#34;\u0026#34; 85# All the tetris pieces 86 87 88 89if __name__ == \u0026#34;__main__\u0026#34;: 90\tnext_piece = getNextPiece() 91\twhile not quit: 92\t# Check if user wants to swap held and current pieces 93\tif switch: 94\t# swap held_piece and current_piece 95\theld_piece, current_piece = current_piece, held_piece 96\tswitch = False 97\telse: 98\t# Generates the next piece and updates the current piece 99\tcurrent_piece = next_piece 100\tnext_piece = getNextPiece() 101 102\tif flag \u0026gt; 0: 103\tflag -= 1 104 105\t# Determines the color and position of the current, next, and held pieces 106 107\theld_info = getInfo(held_piece) 108 109\tnext_info = getInfo(next_piece) 110 111\tcoords, color = getInfo(current_piece) 112\tif current_piece == \u0026#34;I\u0026#34;: 113\ttop_left = [-2, 3] 114 115\tif not np.all(board[coords[:,0], coords[:,1]] == 0): 116\tbreak 117 118\twhile True: 119\t# Shows the board and gets the key press 120\tkey = display(board, coords, color, next_info, held_info, score, SPEED) 121\t# Create a copy of the position 122\tdummy = coords.copy() 123\tprint(\u0026#34;speed \u0026#34;,SPEED, \u0026#34;key \u0026#34;,key,\u0026#34; \u0026#34;, ord(\u0026#34;s\u0026#34;)) 124 125\tif key == ord(\u0026#34;s\u0026#34;): 126\tdrop = True 127 128\telif key == ord(\u0026#34;a\u0026#34;): 129\t# Moves the piece left if it isn\u0026#39;t against the left wall 130\tif np.min(coords[:,1]) \u0026gt; 0: 131\tcoords[:,1] -= 1 132\tif current_piece == \u0026#34;I\u0026#34;: 133\ttop_left[1] -= 1 134\telif key == ord(\u0026#34;d\u0026#34;): 135\t# Moves the piece right if it isn\u0026#39;t against the right wall 136\tif np.max(coords[:,1]) \u0026lt; 9: 137\tcoords[:,1] += 1 138\tif current_piece == \u0026#34;I\u0026#34;: 139\ttop_left[1] += 1 140\t# elif key == ord(\u0026#34;j\u0026#34;) or key == ord(\u0026#34;l\u0026#34;): 141\t# # Rotation mechanism 142\t# # arr is the array of nearby points which get rotated and pov is the indexes of the blocks within arr 143 144\t# if current_piece != \u0026#34;I\u0026#34; and current_piece != \u0026#34;O\u0026#34;: 145\t# if coords[1,1] \u0026gt; 0 and coords[1,1] \u0026lt; 9: 146\t# arr = coords[1] - 1 + np.array([[[x, y] for y in range(3)] for x in range(3)]) 147\t# pov = coords - coords[1] + 1 148 149\t# elif current_piece == \u0026#34;I\u0026#34;: 150\t# # The straight piece has a 4x4 array, so it needs seperate code 151 152\t# arr = top_left + np.array([[[x, y] for y in range(4)] for x in range(4)]) 153\t# pov = np.array([np.where(np.logical_and(arr[:,:,0] == pos[0], arr[:,:,1] == pos[1])) for pos in coords]) 154\t# pov = np.array([k[0] for k in np.swapaxes(pov, 1, 2)]) 155 156\t# # Rotates the array and repositions the piece to where it is now 157 158\t# if current_piece != \u0026#34;O\u0026#34;: 159\t# if key == ord(\u0026#34;j\u0026#34;): 160\t# arr = np.rot90(arr, -1) 161\t# else: 162\t# arr = np.rot90(arr) 163\t# coords = arr[pov[:,0], pov[:,1]] 164 165\telif key == ord(\u0026#34;w\u0026#34;): 166\t# Rotation mechanism 167\t# arr is the array of nearby points which get rotated and pov is the indexes of the blocks within arr 168 169\tif current_piece != \u0026#34;I\u0026#34; and current_piece != \u0026#34;O\u0026#34;: 170\tif coords[1,1] \u0026gt; 0 and coords[1,1] \u0026lt; 9: 171\tarr = coords[1] - 1 + np.array([[[x, y] for y in range(3)] for x in range(3)]) 172\tpov = coords - coords[1] + 1 173 174\telif current_piece == \u0026#34;I\u0026#34;: 175\t# The straight piece has a 4x4 array, so it needs seperate code 176 177\tarr = top_left + np.array([[[x, y] for y in range(4)] for x in range(4)]) 178\tpov = np.array([np.where(np.logical_and(arr[:,:,0] == pos[0], arr[:,:,1] == pos[1])) for pos in coords]) 179\tpov = np.array([k[0] for k in np.swapaxes(pov, 1, 2)]) 180 181\t# Rotates the array and repositions the piece to where it is now 182 183\tif current_piece != \u0026#34;O\u0026#34;: 184\tif key == ord(\u0026#34;j\u0026#34;): 185\tarr = np.rot90(arr, -1) 186\telse: 187\tarr = np.rot90(arr) 188\tcoords = arr[pov[:,0], pov[:,1]] 189\t# Hard drop set to true 190\t# drop = True 191\t# elif key == ord(\u0026#34;i\u0026#34;): 192\t# # Goes out of the loop and tells the program to switch held and current pieces 193\t# if flag == 0: 194\t# if held_piece == \u0026#34;\u0026#34;: 195\t# held_piece = current_piece 196\t# else: 197\t# switch = True 198\t# flag = 2 199\t# break 200\telif key == 8 or key == 27: 201\tquit = True 202\tbreak 203 204\t# Checks if the piece is overlapping with other pieces or if it\u0026#39;s outside the board, and if so, changes the position to the position before anything happened 205 206\tif np.max(coords[:,0]) \u0026lt; 20 and np.min(coords[:,0]) \u0026gt;= 0: 207\tif not (current_piece == \u0026#34;I\u0026#34; and (np.max(coords[:,1]) \u0026gt;= 10 or np.min(coords[:,1]) \u0026lt; 0)): 208\tif not np.all(board[coords[:,0], coords[:,1]] == 0): 209\tcoords = dummy.copy() 210\telse: 211\tcoords = dummy.copy() 212\telse: 213\tcoords = dummy.copy() 214 215\tif drop: 216\t# Every iteration of the loop moves the piece down by 1 and if the piece is resting on the ground or another piece, then it stops and places it 217 218\twhile not place: 219\tif np.max(coords[:,0]) != 19: 220\t# Checks if the piece is resting on something 221\tfor pos in coords: 222\tif not np.array_equal(board[pos[0] + 1, pos[1]], [0, 0, 0]): 223\tplace = True 224\tbreak 225\telse: 226\t# If the position of the piece is at the ground level, then it places 227\tplace = True 228 229\tif place: 230\tbreak 231 232\t# Keeps going down and checking when the piece needs to be placed 233 234\tcoords[:,0] += 1 235 236\tif current_piece == \u0026#34;I\u0026#34;: 237\ttop_left[0] += 1 238 239\tdrop = False 240 241\telse: 242\t# Checks if the piece needs to be placed 243\tif np.max(coords[:,0]) != 19: 244\tfor pos in coords: 245\tif not np.array_equal(board[pos[0] + 1, pos[1]], [0, 0, 0]): 246\tplace = True 247\tbreak 248\telse: 249\tplace = True 250 251\tif place: 252\t# Places the piece where it is on the board 253\tfor pos in coords: 254\tboard[tuple(pos)] = color 255 256\t# Resets place to False 257\tplace = False 258\tbreak 259 260\t# Moves down by 1 261 262\tcoords[:,0] += 1 263\tif current_piece == \u0026#34;I\u0026#34;: 264\ttop_left[0] += 1 265 266\t# Clears lines and also counts how many lines have been cleared and updates the score 267 268\tlines = 0 269 270\tfor line in range(20): 271\tif np.all([np.any(pos != 0) for pos in board[line]]): 272\tlines += 1 273\tboard[1:line+1] = board[:line] 274 275 276\tscore += lines*10 MÃ£ nguá»“n nÃ y Ä‘Æ°á»£c káº¿ thá»«a tá»« bÃ i viáº¿t https://www.learnopencv.com/tetris-with-opencv-python/ vÃ  mÃ¬nh cÃ³ modify láº¡i theo sá»Ÿ thÃ­ch cÃ¡ nhÃ¢n cá»§a mÃ¬nh. CÃ²n má»™t sá»‘ bug mÃ  mÃ¬nh chÆ°a fix háº¿t. Báº¡n Ä‘á»c nÃ o ghÃ© ngang cÃ³ Ä‘Ã³ng gÃ³p gÃ¬ thÃ¬ Ä‘á»ƒ láº¡i comment giÃºp mÃ¬nh hen.\n","date":"Dec 26, 2020","img":"https://unsplash.it/1920/1080?image=40","permalink":"/blog/2020-12-25---tetric/","series":null,"tags":["Python","Tetris","Opencv"],"title":"XÃ¢y Dá»±ng Game Xáº¿p Gáº¡ch Báº±ng Opencv VÃ  Python"},{"categories":null,"content":" GiÃ¡ trá»‹ ngÆ°á»¡ng: Thuáº­t toÃ¡n Simple Thresholding Adaptive Thresholding GiÃ¡ trá»‹ ngÆ°á»¡ng: NÃ³i theo kiá»ƒu lÃºa hÃ³a, trong opencv, ngÆ°á»¡ng lÃ  má»™t sá»‘ náº±m trong Ä‘oáº¡n tá»« 0 Ä‘áº¿n 255. GiÃ¡ trá»‹ ngÆ°á»¡ng sáº½ chia tÃ¡ch giÃ¡ trá»‹ Ä‘á»™ xÃ¡m cá»§a áº£nh thÃ nh 2 miá»n riÃªng biá»‡t. Miá»n thá»© nháº¥t lÃ  táº­p há»£p cÃ¡c Ä‘iá»ƒm áº£nh cÃ³ giÃ¡ trá»‹ nhá» hÆ¡n giÃ¡ trá»‹ ngÆ°á»¡ng. Miá»n thá»© hai lÃ  táº­p há»£p cÃ¡c cÃ¡c Ä‘iá»ƒm áº£nh cÃ³ giÃ¡ trá»‹ lá»›n hÆ¡n hoáº·c báº±ng giÃ¡ trá»‹ ngÆ°á»¡ng.\nÄáº§u vÃ o cá»§a má»™t thuáº­t toÃ¡n phÃ¢n ngÆ°á»¡ng trong opencv thÆ°á»ng cÃ³ input lÃ  áº£nh nguá»“n (source image) vÃ  giÃ¡ trá»‹ ngÆ°á»¡ng. Äáº§u ra lÃ  áº£nh Ä‘Ã­ch Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n ngÆ°á»¡ng (destination image). Má»™t sá»‘ thuáº­t toÃ¡n phÃ¢n ngÆ°á»¡ng sáº½ kÃ¨m thÃªm vÃ i giÃ¡ trá»‹ rÃ¢u ria khÃ¡c ná»¯a, chÃºng ta sáº½ khÃ´ng quan tÃ¢m Ä‘áº¿n chÃºng\nMÃ£ giáº£i cá»§a thuáº­t toÃ¡n phÃ¢n ngÆ°á»¡ng:\n1if src[i] \u0026gt;= T: 2\tdest[i] = MAXVAL 3else: 4\tdest [i] = 0 CÃ³ ráº¥t nhiá»u thuáº­t toÃ¡n phÃ¢n ngÆ°á»¡ng dá»±a trÃªn cÃ¡ch chÃºng ta xÃ¡c Ä‘á»‹nh ngÆ°á»¡ng. ChÃºng ta sáº½ tÃ¬m hiá»ƒu láº§n lÆ°á»£t cÃ¡c thuáº­t toÃ¡n trÃªn.\nThuáº­t toÃ¡n Simple Thresholding Simple Thresholding thá»±c hiá»‡n phÃ¢n ngÆ°á»¡ng báº±ng cÃ¡ch thay tháº¿ giÃ¡ trá»‹ lá»›n hÆ¡n hoáº·c báº±ng vÃ  giÃ¡ trá»‹ bÃ© hÆ¡n giÃ¡ trá»‹ ngÆ°á»¡ng báº±ng má»™t giÃ¡ trá»‹ má»›i. Cá»¥ thá»ƒ chÃºng ta cÃ³ thá»ƒ xem mÃ£ nguá»“n bÃªn dÆ°á»›i\n1 2import cv2 3import numpy as np 4from matplotlib import pyplot as plt 5 6img = cv2.imread(\u0026#39;gradient.png\u0026#39;,0) 7ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY) 8ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV) 9ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC) 10ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO) 11ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV) 12 13titles = [\u0026#39;Original Image\u0026#39;,\u0026#39;BINARY\u0026#39;,\u0026#39;BINARY_INV\u0026#39;,\u0026#39;TRUNC\u0026#39;,\u0026#39;TOZERO\u0026#39;,\u0026#39;TOZERO_INV\u0026#39;] 14images = [img, thresh1, thresh2, thresh3, thresh4, thresh5] 15 16for i in xrange(6): 17 plt.subplot(2,3,i+1),plt.imshow(images[i],\u0026#39;gray\u0026#39;) 18 plt.title(titles[i]) 19 plt.xticks([]),plt.yticks([]) 20 21plt.show() HÃ¬nh áº£nh vÃ  thuáº­t toÃ¡n cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c láº¥y tá»« trang opencv-python-tutroals.readthedocs.io\ná» Ä‘oáº¡n code trÃªn, chÃºng ta thiáº¿t láº­p giÃ¡ trá»‹ ngÆ°á»¡ng lÃ  127, vá»›i cÃ¡c Ä‘iá»ƒm áº£nh cÃ³ giÃ¡ trá»‹ lá»›n hÆ¡n hoáº·c báº±ng 127, chÃºng ta sáº½ gÃ¡n láº¡i giÃ¡ trá»‹ cá»§a nÃ³ thÃ nh 255. VÃ  cÃ¡c Ä‘iá»ƒm áº£nh cÃ³ giÃ¡ trá»‹ bÃ© hÆ¡n 127 sáº½ Ä‘Æ°á»£c gÃ¡n báº±ng 0 (máº·c Ä‘á»‹nh).\n1 2 3double cv::threshold\t(\tInputArray src, 4OutputArray dst, 5double thresh, 6double maxval, 7int type 8) Thuáº­t toÃ¡n sample thresholding cá»§a opencv cÃ²n cÃ³ 1 tham sá»‘ ná»¯a khÃ¡ quan trá»ng ná»¯a lÃ  loáº¡i ngÆ°á»¡ng (type). Hiá»‡n táº¡i lÃºc mÃ¬nh viáº¿t bÃ i viáº¿t nÃ y thÃ¬ opencv há»— trá»£ 8 loáº¡i lÃ : THRESH_BINARY, THRESH_BINARY_INV, THRESH_TRUNC, THRESH_TOZERO, THRESH_TOZERO_INV, THRESH_MASK, THRESH_OTSU, THRESH_TRIANGLE. Ã nghÄ©a cá»§a tá»«ng loáº¡i nhÆ° sau:\nTHRESH_BINARY: CÃ³ thá»ƒ dá»‹ch lÃ  ngÆ°á»¡ng nhá»‹ phÃ¢n. Ã nghÄ©a y há»‡t nhá»¯ng gÃ¬ mÃ¬nh Ä‘á» cáº­p á»Ÿ trÃªn.\nTHRESH_BINARY_INV: NgÆ°á»¡ng nhá»‹ phÃ¢n Ä‘áº£o ngÆ°á»£c. CÃ³ thá»ƒ hiá»ƒu lÃ  nÃ³ sáº½ Ä‘áº£o ngÆ°á»£c láº¡i káº¿t quáº£ cá»§a THRESH_BINARY.\nTHRESH_TRUNC: Nhá»¯ng giÃ¡ trá»‹ Ä‘iá»ƒm áº£nh bÃ© hÆ¡n ngÆ°á»¡ng sáº½ giá»¯ nguyÃªn giÃ¡ trá»‹, nhá»¯ng Ä‘iá»ƒm áº£nh lá»›n hÆ¡n hoáº·c ngÆ°á»¡ng sáº½ Ä‘Æ°á»£c gÃ¡n láº¡i lÃ  maxvalue.\nTHRESH_TOZERO: Nhá»¯ng Ä‘iá»ƒm áº£nh bÃ© hÆ¡n ngÆ°á»¡ng sáº½ bá»‹ gÃ¡n thÃ nh 0, nhá»¯ng Ä‘iá»ƒm cÃ²n láº¡i giá»¯ nguyÃªn.\nTHRESH_TOZERO_INV: Nhá»¯ng Ä‘iá»ƒm áº£nh nhá» hÆ¡n giÃ¡ trá»‹ ngÆ°á»¡ng sáº½ Ä‘Æ°á»£c giá»¯ nguyÃªn, nhá»¯ng Ä‘iá»ƒm áº£nh cÃ²n láº¡i sáº½ bá»‹ gÃ¡n thÃ nh 0.\nTHRESH_MASK: á» báº¡n opencv4, háº§u nhÆ° khÃ´ng Ä‘Æ°á»£c xÃ i.\nTHRESH_OTSU: Sá»­ dá»¥ng thuáº­t toÃ¡n Otsu Ä‘á»ƒ xÃ¡c Ä‘á»‹nh giÃ¡ trá»‹ ngÆ°á»¡ng.\nTHRESH_TRIANGLE: Sá»­ dá»¥ng thuáº­t toÃ¡n Triangle Ä‘á»ƒ xÃ¡c Ä‘á»‹nh giÃ¡ trá»‹ ngÆ°á»¡ng.\nGiÃ¡ trá»‹ 127 lÃ  giÃ¡ trá»‹ trung bÃ¬nh cá»™ng cá»§a 0 vÃ  255 lÃ m trÃ²n xuá»‘ng. GiÃ¡ trá»‹ ngÆ°á»¡ng cá»§a thuáº­t toÃ¡n nÃ y Ä‘Ã²i há»i ngÆ°á»i sá»­ dá»¥ng pháº£i cÃ³ má»©c Ä‘á»™ hiá»ƒu biáº¿t nháº¥t Ä‘á»‹nh vá» cÃ¡c loáº¡i áº£nh mÃ¬nh Ä‘ang xá»­ lÃ½ Ä‘á»ƒ chá»n ngÆ°á»¡ng cho phÃ¹ há»£p.\nAdaptive Thresholding Thuáº­t toÃ¡n simple thresholding hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t. Tuy nhiÃªn, nÃ³ cÃ³ 1 nhÆ°á»£c Ä‘iá»ƒm lÃ  giÃ¡ trá»‹ ngÆ°á»¡ng bá»‹/Ä‘Æ°á»£c gÃ¡n toÃ n cá»¥c. Thá»±c táº¿ khi chá»¥p, hÃ¬nh áº£nh chÃºng ta nháº­n Ä‘Æ°á»£c thÆ°á»ng bá»‹ áº£nh hÆ°á»Ÿng cá»§a nhiá»…u, vÃ­ dá»¥ nhÆ° lÃ  bá»‹ phÆ¡i sÃ¡ng, bá»‹ Ä‘Ã¨n flask, \u0026hellip;\nMá»™t trong nhá»¯ng cÃ¡ch Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» trÃªn lÃ  chia nhá» bá»©c áº£nh thÃ nh nhá»¯ng vÃ¹ng nhá» (region), vÃ  Ä‘áº·t giÃ¡ trá»‹ ngÆ°á»¡ng trÃªn nhá»¯ng vÃ¹ng nhá» Ä‘Ã³ -\u0026gt; adaptive thresholding ra Ä‘á»i. Opencv cung cáº¥p cho chÃºng ta hai cÃ¡ch xÃ¡c Ä‘á»‹nh nhá»¯ng vÃ¹ng nhá»\n1import cv2 as cv 2import numpy as np 3from matplotlib import pyplot as plt 4img = cv.imread(\u0026#39;sudoku.png\u0026#39;,0) 5img = cv.medianBlur(img,5) 6ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY) 7th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\ 8 cv.THRESH_BINARY,11,2) 9th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\ 10 cv.THRESH_BINARY,11,2) 11titles = [\u0026#39;Original Image\u0026#39;, \u0026#39;Global Thresholding (v = 127)\u0026#39;, 12 \u0026#39;Adaptive Mean Thresholding\u0026#39;, \u0026#39;Adaptive Gaussian Thresholding\u0026#39;] 13images = [img, th1, th2, th3] 14for i in xrange(4): 15 plt.subplot(2,2,i+1),plt.imshow(images[i],\u0026#39;gray\u0026#39;) 16 plt.title(titles[i]) 17 plt.xticks([]),plt.yticks([]) 18plt.show() HÃ¬nh áº£nh vÃ  thuáº­t toÃ¡n cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c láº¥y tá»« trang docs.opencv.org\n1 2 3void cv::adaptiveThreshold\t(\tInputArray src, 4OutputArray dst, 5double maxValue, 6int adaptiveMethod, 7int thresholdType, 8int blockSize, 9double C 10) á» Ä‘Ã¢y:\nblockSize: KÃ­ch thÆ°á»›c cá»§a vÃ¹ng, báº¯t buá»™c pháº£i lÃ  má»™t sá»‘ láº» lá»›n hÆ¡n 0.\nC: háº±ng sá»‘, giÃ¡ trá»‹ tá»« -255 Ä‘áº¿n 255. CÃ³ thá»ƒ gÃ¡n C báº±ng 0 Ä‘á»ƒ Ä‘á»¡ rá»‘i.\nadaptiveMethod nháº­n vÃ o má»™t trong hai giÃ¡ trá»‹ lÃ  cv.ADAPTIVE_THRESH_MEAN_C vÃ  cv.ADAPTIVE_THRESH_GAUSSIAN_C, Ä‘Ã³ lÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p tÃ­nh ngÆ°á»¡ng.\nADAPTIVE_THRESH_MEAN_C: TÃ­nh trung bÃ¬nh cÃ¡c lÃ¡ng giá»ng xung quanh Ä‘iá»ƒm cáº§n xÃ©t trong vÃ¹ng blockSize * blockSize trá»« Ä‘i giÃ¡ trá»‹ háº±ng sá»‘ C.\nADAPTIVE_THRESH_GAUSSIAN_C: NhÃ¢n giÃ¡ trá»‹ xung quanh Ä‘iá»ƒm cáº§n xÃ©t vá»›i trá»ng sá»‘ gauss rá»“i tÃ­nh trung bÃ¬nh cá»§a nÃ³, sau Ä‘Ã³ trá»« Ä‘i giÃ¡ trá»‹ háº±ng sá»‘ C.\nthresholdType: TÆ°Æ¡ng tá»± nhÆ° Simple Thresholding Ä‘Ã£ trÃ¬nh bÃ y á»Ÿ trÃªn.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ quan tÃ¢m vÃ  theo dÃµi bÃ i viáº¿t, háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\nTham kháº£o\nhttps://www.geeksforgeeks.org/python-thresholding-techniques-using-opencv-set-1-simple-thresholding/\nhttps://www.learnopencv.com/opencv-threshold-python-cpp/\nhttps://medium.com/@anupriyam/basic-image-thresholding-in-opencv-5af9020f2472\n","date":"Dec 25, 2020","img":"","permalink":"/blog/2020-12-24-thresholding/","series":null,"tags":["python","thresholding","contour","opencv"],"title":"NgÆ°á»¡ng (Thresholding) Trong Opencv"},{"categories":null,"content":" XÃ¡c Ä‘á»‹nh bias vÃ  variance Bias Unavoidable bias Avoidable bias Variance Tradeoff giá»¯a bias vÃ  variance CÃ¡ch giáº£m bias vÃ  variance CÃ¡ch giáº£m bias Giáº£m variance Bá»©c tranh tá»•ng quÃ¡t Tá»•ng káº¿t Viá»‡c huáº¥n luyÃªn mÃ´ hÃ¬nh mÃ¡y há»c cÃ³ thá»ƒ sáº½ gÃ¢y ra cho báº¡n má»™t chÃºt khÃ³ khÄƒn náº¿u báº¡n khÃ´ng hiá»ƒu nhá»¯ng thá»© báº¡n dang lÃ m lÃ  Ä‘Ãºng hay sai. Trong háº§u háº¿t cÃ¡c trÆ°á»ng há»£p, cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y lÃ  cÃ¡c \u0026ldquo;há»™p Ä‘en\u0026rdquo;, chÃºng ta chá»‰ cÃ³ thá»ƒ \u0026ldquo;nhÃ¬n tháº¥y\u0026rdquo; dá»¯ liá»‡u Ä‘áº§u vÃ o vÃ  Ä‘á»™ chÃ­nh xÃ¡c mÃ  mÃ´ hÃ¬nh tráº£ ra. ChÃºng ta khÃ´ng biáº¿t bÃªn trong nÃ³ Ä‘ang lÃ m cÃ¡i gÃ¬. Viá»‡c hiá»ƒu lÃ½ do táº¡i sao mÃ´ hÃ¬nh cho ra káº¿t quáº£ tá»‡ háº¡i lÃ  chÃ¬a khÃ³a cho cÃ¡i \u0026ldquo;cÃ¡ch\u0026rdquo; mÃ  báº¡n cáº£i tiáº¿n nÃ³.\nTÃ¬m hiá»ƒu lÃ½ do \u0026ldquo;táº¡i sao\u0026rdquo; mÃ´ hÃ¬nh cho ra káº¿t quáº£ tá»‡ háº¡i báº±ng cÃ¡ch \u0026ldquo;xÃ¡c Ä‘á»‹nh bias vÃ  variance\u0026rdquo;.\nTÃ¬m hiá»ƒu \u0026ldquo;cÃ¡ch\u0026rdquo; cáº£i tiáº¿n mÃ´ hÃ¬nh báº±ng viá»‡c thá»±c hiá»‡n \u0026ldquo;giáº£m bias vÃ  variance\u0026rdquo;.\nXÃ¡c Ä‘á»‹nh bias vÃ  variance TrÆ°á»›c háº¿t, chÃºng ta hÃ£y báº¯t Ä‘áº§u nÃ³i vá» lá»—i. Lá»—i lÃ  pháº§n khÃ´ng chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trÃªn táº­p test.\n$$ error = 1 - testing accuracy $$\nNáº¿u mÃ´ hÃ¬nh Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c lÃ  86% trÃªn táº­p test, Ä‘iá»u Ä‘Ã³ Ä‘á»“ng nghÄ©a vá»›i Ä‘á»™ lá»—i lÃ  14%. Trong 14% Ä‘Ã³ bao gá»“m bias vÃ  variance.\nBiá»ƒu Ä‘á»“ bias - variance. Nguá»“n towardsdatascience.com\nHai Ã½ chÃ­nh cá»§a hÃ¬nh trÃªn cáº§n lÃ m rÃµ á»Ÿ Ä‘Ã¢y:\nBias lÃ  lá»—i trÃªn táº­p huáº¥n luyá»‡n.\nVariance lÃ  gap giá»¯a Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p train vÃ  Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p test.\nBáº¡n hÃ£y hÃ¬nh tháº­t ká»¹ vÃ o hÃ¬nh á»Ÿ trÃªn, nhÃ¬n Ä‘i nhÃ¬n láº¡i 2, 3 láº§n. Nháº¯m máº¯t láº¡i vÃ  nghiá»n ngáº«m tháº­t ká»¹ hai Ã½ chÃ­nh mÃ¬nh vá»«a Ä‘á» cáº­p á»Ÿ trÃªn.\nBias Bias mÃ´ táº£ kháº£ nÄƒng há»c cá»§a mÃ´ hÃ¬nh. GiÃ¡ trá»‹ bias lá»›n Ä‘á»“ng nghÄ©a vá»›i viá»‡c mÃ´ hÃ¬nh cáº§n pháº£i há»c nhiá»u hÆ¡n ná»¯a tá»« táº­p huáº¥n luyá»‡n.\nNáº¿u mÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c 90% trÃªn táº­p train, Ä‘iá»u Ä‘Ã³ Ä‘á»“ng nghÄ©a vá»›i viá»‡c báº¡n cÃ³ 10% bias. Bias cÅ©ng Ä‘Æ°á»£c chia lÃ m 2 nhÃ³m, nhÃ³m bias cÃ³ thá»ƒ trÃ¡nh Ä‘Æ°á»£c (avoidable bias) vÃ  nhÃ³m bias khÃ´ng thá»ƒ trÃ¡nh Ä‘Æ°á»£c (unavoidable bias).\n$$ bias = 1 - trainning accuracy $$\nUnavoidable bias Unavoidable bias hay cÃ²n Ä‘Æ°á»£c sá»­ dá»¥ng dÆ°á»›i tÃªn lÃ  optimal error rate. ÄÃ¢y lÃ  giá»›i háº¡n trÃªn cá»§a mÃ´ hÃ¬nh. Trong má»™t sá»‘ bÃ i toÃ¡n, vÃ­ dá»¥ nhÆ° lÃ  bÃ i toÃ¡n dá»± Ä‘oÃ¡n giÃ¡ chá»©ng khoÃ¡n, chÃºng ta - con ngÆ°á»i - khÃ´ng thá»ƒ dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c 100%. Do Ä‘Ã³, trong Ä‘iá»u kiá»‡n lÃ½ tÆ°á»Ÿng nháº¥t, táº¡i má»™t thá»i Ä‘iá»ƒm nÃ o Ä‘Ã³, mÃ´ hÃ¬nh cá»§a chÃºng ta váº«n cá»© tráº£ ra káº¿t quáº£ sai.\nNáº¿u báº¡n quyáº¿t Ä‘á»‹nh ráº±ng mÃ´ hÃ¬nh cÃ³ Ä‘á»™ sai Ã­t nháº¥t lÃ  4%. NghÄ©a lÃ  chÃºng ta cÃ³ 4% unavoidable bias.\nAvoidable bias KhÃ¡c vá»›i optimal error rate vÃ  trainning error. Äá»™ lá»—i nÃ y xáº£y ra khi mÃ´ hÃ¬nh chÃºng ta chÆ°a Ä‘á»§ Ä‘á»™ tá»›i. ChÃºng ta hoÃ n toÃ n cÃ³ thá»ƒ cÃ¡i tiáº¿n mÃ´ hÃ¬nh nÃ y Ä‘á»ƒ giáº£m Ä‘á»™ lá»—i nÃ y vá» má»©c 0, v\nBiá»ƒu Ä‘á»“ bias - variance. Nguá»“n towardsdatascience.com\nBáº¡n hÃ£y Ä‘á»ƒ Ã½ ká»¹ pháº§n bias á»Ÿ hÃ¬nh trÃªn. Bias Ä‘Æ°á»£c chia lÃ m 2 pháº§n. á» trÃªn pháº§n nÃ©t Ä‘á»©t lÃ  Unavoidable bias. NÃ³ lÃ  Ä‘iá»ƒm tá»›i háº¡n cá»§a mÃ´ hÃ¬nh. Viá»‡c cáº§n lÃ m cá»§a chÃºng ta lÃ  huáº¥n luyá»‡n, cáº£i tiáº¿n mÃ´ hÃ¬nh, Ä‘á»ƒ cho Ä‘Æ°á»ng trainning accuracy mÃ u Ä‘á» tiáº¿n sÃ¡t vá»›i Ä‘Æ°á»ng nÃ©t Ä‘á»©t.\nVariance Variance Ã½ nghÄ©a cá»§a nÃ³ lÃ  mÃ´ táº£ má»©c Ä‘á»™ tá»•ng quÃ¡t hÃ³a cá»§a mÃ´ hÃ¬nh cá»§a báº¡n Ä‘á»‘i vá»›i dá»¯ liá»‡u mÃ  nÃ³ chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. VÃ  Ä‘á»‹nh nghÄ©a cá»§a nÃ³ lÃ  pháº§n sai lá»‡ch giá»¯a Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p huáº¥n luyá»‡n vÃ  Ä‘á»™ chÃ­nh xÃ¡c tÃªn táº­p test.\n$$ Variance = trainning accuracy - testing accuracy $$\nBiá»ƒu Ä‘á»“ variance. Nguá»“n towardsdatascience.com\nTradeoff giá»¯a bias vÃ  variance Sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a bias vÃ  variace. Nguá»“n towardsdatascience.com\nMÃ¬nh nghÄ© hÃ¬nh trÃªn Ä‘á»§ nÃ³i lÃªn táº¥t cáº£ Ã½ mÃ¬nh muá»‘n nÃ³i. Khi mÃ´ hÃ¬nh cáº£ng trá»Ÿ nÃªn phá»©c táº¡p, thÃ¬ bias sáº½ giáº£m, nhÆ°ng má»©c Ä‘á»™ tá»•ng quÃ¡t hÃ³a cÅ©ng giáº£m theo (Ä‘á»“ng nghÄ©a vá»›i viá»‡c variace sáº½ tÄƒng).\nCÃ¡ch giáº£m bias vÃ  variance CÃ¡ch giáº£m bias NhÆ° Ä‘Ã£ nÃ³i á»Ÿ pháº§n trÃªn, bias Ä‘Æ°á»£c chia thÃ nh 2 nhÃ³m lÃ  Avoidable bias vÃ  unavoidable bias. ChÃºng ta khÃ´ng thá»ƒ nÃ o giáº£m Avoidable bias, nhÆ°ng chÃºng ta cÃ³ thá»ƒ giáº£m unavoidable bias báº±ng má»™t trong cÃ¡c cÃ¡ch sau.\nTÄƒng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh Viá»‡c tÄƒng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh lÃ  má»™t trong nhá»¯ng cÃ¡ch lÃ m giáº£m avoidable bias. MÃ´ hÃ¬nh cÃ ng lá»›n thÃ¬ cÃ³ cÃ ng nhiá»u tham sá»‘ pháº£i Ä‘iá»u chá»‰nh. CÃ³ nhiá»u tham sos Ä‘á»“ng nghÄ©a vá»›i viá»‡c mÃ´ hÃ¬nh sáº½ há»c Ä‘Æ°á»£c nhiá»u má»‘i quan há»‡ phá»©c táº¡p hÆ¡n. ChÃºng ta cÃ³ thá»ƒ tÄƒng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh báº±ng cÃ¡ch thÃªm nhiá»u layer hÆ¡n ná»¯a, hoáº·c thÃªm nhiá»u node hÆ¡n ná»¯a cho má»—i layer.\nGiáº£m Regulation Viá»‡c giáº£m regulation cÅ©ng giÃºp mÃ´ hÃ¬nh tÄƒng Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p huáº¥n luyÃªn. Tuy nhiÃªn, náº¿u chÃºng ta giáº£m regularization quÃ¡ Ä‘Ã , mÃ´ hÃ¬nh sáº½ khÃ´ng Ä‘áº¡t Ä‘Æ°á»£c má»©c Ä‘á»™ tá»•ng quÃ¡t hÃ³a, vÃ  lÃ m tÄƒng variance. ÄÃ¢y lÃ  vÃ­ dá»¥ dá»… tháº¥y nháº¥t nháº¥t vá» sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a bias vÃ  variance.\nGiáº£m Regulation . Nguá»“n towardsdatascience.com\nThay Ä‘á»•i kiáº¿n trÃºc mÃ´ hÃ¬nh Viá»‡c thay Ä‘á»•i kiáº¿n trÃºc mÃ´ hÃ¬nh cÅ©ng cÃ³ thá»ƒ giÃºp chÃºng ta Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n.\nMá»™t sá»‘ má»¥c cÃ³ thá»ƒ thay Ä‘á»•i:\nThay Ä‘á»•i activation function ( vÃ­ dá»¥ tanh, ReLU, sigmoid, LeakyReLU)\nThay Ä‘á»•i loáº¡i mÃ´ hÃ¬nh (ANN, CNN, RNN, KNNKNN, \u0026hellip;)\nThay Ä‘á»•i cÃ¡c tham sá»‘ (learning rate, image size, \u0026hellip;)\nThay Ä‘á»•i thuáº­t toÃ¡n tá»‘i Æ°u (Adam, SGD, RMSprop, â€¦)\nThÃªm Ä‘áº·c trÆ°ng má»›i Viá»‡c thÃªm Ä‘áº·c trÆ°ng má»›i giÃºp chÃºng ta cung cáº¥p cho mÃ´ hÃ¬nh nhiá»u thÃ´ng tin hÆ¡n. ChÃºng ta cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘iá»u nÃ y thÃ´ng qua ká»¹ thuáº­t feature engineering.\nGiáº£m variance ThÃªm nhiá»u dá»¯ liá»‡u ThÃªm dá»¯ liá»‡u lÃ  cÃ¡ch Ä‘Æ¡n giáº£n nháº¥t, thÆ°á»ng gáº·p nháº¥t Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trong trÆ°á»ng há»£p mÃ´ hÃ¬nh huáº¥n luyá»‡n cá»§a chÃºng ta bá»‹ hight variance. Hiá»‡u quáº£ cá»§a viá»‡c thÃªm nhiá»u dá»¯ liá»‡u vÃ o mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» cáº­p á»Ÿ bÃ i bÃ¡o cÃ³ tá»±a Ä‘á» lÃ  The Unreasonable Effectiveness of Recurrent Neural Networks cá»§a Andrej Karpathy (link: http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Viá»‡c thÃªm dá»¯ liá»‡u thÆ°á»ng khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n Ä‘á»™ lá»—i bias, giÃºp lÃ m giáº£m variance, nÃªn Ä‘Ã¢y lÃ  cÃ¡ch thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng nháº¥t.\nTÄƒng Regularization Viá»‡c tÄƒng Regularization giÃºp mÃ´ hÃ¬nh chá»‘ng overfitting. Qua Ä‘Ã³ giÃºp giáº£m variance, vÃ  tÄƒng bias :(. Má»™t sÃ³ cÃ¡ch Regularization hot á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n láº¡i lÃ  dropout ( vá»›i biáº¿n thá»ƒ lÃ  Monte Carlo Dropout), BatchNorm\u0026hellip;\nGiáº£m kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh Viá»‡c giáº£m kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh giÃºp cho chÃºng ta giáº£m overfitting trÃªn táº­p train. Má»¥c tiÃªu cá»§a Viá»‡c nÃ y lÃ m giáº£m kháº£ nÄƒng liÃªn káº¿t nhá»¯ng pattern cá»§a dá»¯ liá»‡u. Bá»Ÿi váº­y, má»¥c tiÃªu cá»§a nÃ³ hoÃ n toÃ n tÆ°Æ¡ng tá»± nhÆ° tÄƒng Regularization. Trong thá»±c táº¿, chÃºng ta thÆ°á»ng sá»­ dá»¥ng tÄƒng thÃªm Regularization hÆ¡n lÃ  giáº£m kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh Ä‘á»ƒ chá»‘ng variace.\nLá»±a chá»n Ä‘áº·c trÆ°ng (feature selection) Giáº£m chiá»u dá»¯ liá»‡u, báº±ng cÃ¡ch bá» Ä‘i cÃ¡c Ä‘áº·c trÆ°ng thá»«a, giÃºp giáº£m nhiá»…u, lÃ  cÃ¡ch thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giáº£m variace. ChÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng PCA (Principal Component Analysis) Ä‘á»ƒ lá»c ra cÃ¡c Ä‘áº·c trÆ°ng tá»‘t hoáº·c káº¿t há»£p chÃºng vá»›i nhau Ä‘á»ƒ táº¡o cÃ¡c Ä‘áº·c trÆ°ng tá»‘t hÆ¡n.\nBá»©c tranh tá»•ng quÃ¡t Sau táº¥t cáº£, chÃºng ta sáº½ xÃ¢y dá»±ng Ä‘Æ°á»£c má»™t bá»©c tranh tá»•ng quan vá» lá»—i chÃºng ta Ä‘ang máº¯c pháº£i lÃ  gÃ¬ vÃ  chÃºng ta nÃªn lÃ m gÃ¬ Ä‘á»ƒ giáº£m Ä‘á»™ lá»—i Ä‘Ã³.\nTá»•ng quan . Nguá»“n towardsdatascience.com\nTá»•ng káº¿t Reducing Bias\nIncrease model size\nReduce regularization\nChange model architecture\nAdd features\nReducing Variance\nAdd More data\nDecrease model size\nAdd regularization\nFeature selection\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ quan tÃ¢m vÃ  theo dÃµi bÃ i viáº¿t, háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\nBÃ i viáº¿t Ä‘Æ°á»£c lÆ°á»£c dá»‹ch tá»« link https://towardsdatascience.com/two-important-machine-learning-concepts-to-improve-every-model-62fd058916b\nNguá»“n tá»± liá»‡u tá»« bÃ i viáº¿t Ä‘Æ°á»£c sá»­ dá»¥ng trong cuá»‘n sÃ¡ch Machine Learning Yearning cá»§a Andrew Ng. CÃ¡c báº¡n cÃ³ thá»ƒ search theo tá»« khÃ³a trÃªn hoáº·c Ä‘Äƒng kÃ½ trÃªn site http://deeplearning.net/\n","date":"Apr 16, 2020","img":"","permalink":"/blog/2020-04-16-two-important-machine-learning-concepts-to-improve-every-model/","series":null,"tags":["machine learning","deep learning","bias","variance"],"title":"Hai KhÃ¡i Niá»‡m Quan Trá»ng GiÃºp TÄƒng Äá»™ ChÃ­nh XÃ¡c Cá»§a CÃ¡c MÃ´ HÃ¬nh Trong Machine Learning"},{"categories":null,"content":" Äáº·t váº¥n Ä‘á» BÃ i toÃ¡n tÃ¬m kiáº¿m vÄƒn báº£n tÆ°Æ¡ng Ä‘á»“ng VÃ¬ sao pháº£i dÃ¹ng Min-Hashing Thuáº­t toÃ¡n MinHash Äáº·t váº¥n Ä‘á» Giáº£ sá»­ báº¡n vÃ  tÃ´i Ä‘á»u thÃ­ch nghe nháº¡c trÃªn trang mp3.zing.vn. Má»—i ngÆ°á»i Ä‘á»u nghe khoáº£ng 100 bÃ i nháº¡c khÃ¡c nhau. Äá»ƒ Ä‘o sá»± giá»‘ng nhau giá»¯a danh sÃ¡ch bÃ i hÃ¡t báº¡n nghe vÃ  danh sÃ¡ch bÃ i hÃ¡t tÃ´i nghe, thÃ´ng thÆ°á»ng chÃºng ta sáº½ dÃ¹ng Ä‘á»™ Ä‘o Jaccard Similarity, Ä‘Æ°á»£c Ä‘o báº±ng cÃ¡ch láº¥y pháº§n giao (intersection ) chia cho pháº§n há»£p (union). NghÄ©a lÃ  Ä‘áº¿m sá»‘ lÆ°á»£ng bÃ i hÃ¡t cáº£ hai cÃ¹ng nghe (pháº§n giao) chia cho tá»•ng sá»‘ bÃ i hÃ¡t khÃ´ng láº·p cá»§a cáº£ hai.\nTrong trÆ°á»ng há»£p báº¡n vÃ  tÃ´i Ä‘á»u nghe 100 bÃ i, trong Ä‘Ã³ cÃ³ 30 bÃ i giá»‘ng nhau, váº­y pháº§n giao lÃ  30, pháº§n há»£p lÃ  170, giÃ¡ trá»‹ Jaccard Similarity sáº½ lÃ  30/170.\nÄá»™ Ä‘o Jaccard Similarity Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ phÆ°Æ¡ng phÃ¡p apriori , FP Growth, \u0026hellip; mÃ  cÃ¡c báº¡n Ä‘Ã£ cÃ³ dá»‹p há»c trong mÃ´n khai phÃ¡ dá»¯ liá»‡u á»Ÿ Äáº¡i há»c.\nBÃ i toÃ¡n tÃ¬m kiáº¿m vÄƒn báº£n tÆ°Æ¡ng Ä‘á»“ng Giáº£ sá»­ báº¡n quáº£n lÃ½ má»™t sá»‘ lÆ°á»£ng lá»›n vÄƒn báº£n (N= 1 tá»·), vÃ  xáº¿p cá»§a báº¡n cÃ³ nhu cáº§u nhÃ³m nhá»¯ng bÃ i viáº¿t giá»‘ng nhau thÃ nh tá»«ng cá»¥m. Äá»ƒ:\nLoáº¡i bá» bá»›t nhá»¯ng káº¿t quáº£ trÃ¹ng trong khung search.\nNhÃ³m nhá»¯ng bÃ i viáº¿t vÃ o tá»«ng nhÃ³m sá»± kiá»‡n theo dÃ²ng thá»i gian, vÃ­ dá»¥ sá»± kiá»‡n \u0026lsquo;cÃ´ gÃ¡i giao gÃ \u0026rsquo;, sá»± kiá»‡n \u0026lsquo;dá»‹ch cÃºm corona\u0026rsquo;, \u0026hellip;\nVÃ¬ má»™t báº¥t ká»ƒ lÃ½ do nÃ o Ä‘Ã³ mÃ  trong lÃºc viáº¿t bÃ i nÃ y tÃ¡c giáº£ chÆ°a nghÄ© ra.\nKhi Ä‘Ã³, cÃ¡c váº¥n Ä‘á»u sau cÃ³ thá»ƒ sáº½ phÃ¡t sinh:\nNhiá»u pháº§n nhá» cá»§a vÄƒn báº£n nÃ y xuáº¥t hiá»‡n á»Ÿ má»™t vá»‹ trÃ­ lá»™n xá»™n nÃ o á»Ÿ má»™t hoáº·c nhiá»u vÄƒn báº£n khÃ¡c.\nVÄƒn báº£n quÃ¡ dÃ i nÃªn khÃ´ng thá»ƒ lÆ°u trá»¯ háº¿t lÃªn bá»™ nhá»› chÃ­nh (RAM).\nCÃ³ quÃ¡ nhiá»u cáº·p vÄƒn báº£n cáº§n pháº£i so sÃ¡nh.\nÄá»ƒ giáº£i quyáº¿t bÃ i toÃ¡n trÃªn, chÃºng ta sáº½ tiáº¿p cáº­n theo hÆ°á»›ng sau:\nShingling: Chuyá»ƒn vÄƒn báº£n thÃ nh táº­p kÃ½ tá»±, táº­p tá»« \u0026hellip;.\nMin-Hashing: Chuyá»ƒn táº­p kÃ½ tá»± thÃ nh 1 chuá»—i sá»‘ hash Ä‘á»‹nh danh.\nLocality-Sensitive Hashing: TÃ¬m cÃ¡c vÄƒn báº£n tÆ°Æ¡ng Ä‘á»“ng dá»±a vÃ o chuá»—i sá»‘ Ä‘á»‹nh danh.\ná» bÃ i viáº¿t nÃ y, mÃ¬nh chá»‰ Ä‘á» cáº­p bÆ°á»›c thá»© 2 lÃ  Min-Hashing. BÆ°á»›c 1 vÃ  bÆ°á»›c 3 báº¡n cÃ³ thá»ƒ tham kháº£o thÃªm trong khÃ³a há»c, mÃ¬nh cÃ³ Ä‘á»ƒ link bÃªn dÆ°á»›i.\nVÃ¬ sao pháº£i dÃ¹ng Min-Hashing NhÆ° bÃ i toÃ¡n Ä‘áº·t ra á»Ÿ trÃªn, chÃºng ta cÃ³ 1 tá»· vÄƒn báº£n, chÃºng ta cáº§n N(N-1)/2 = 5*10^17 phÃ©p tÃ­nh Jaccard Similarity. ChÃºng ta cÃ³ má»™t server cÃ³ thá»ƒ thá»±c hiá»‡n 5x10^6 phÃ©p so sÃ¡nh, thÃ¬ chÃºng ta pháº£i máº¥t 10^11 giÃ¢y tÆ°Æ¡ng Ä‘Æ°Æ¡ng 31,710 nÄƒm Ä‘á»ƒ thá»±c hiá»‡n xong.\nThuáº­t toÃ¡n MinHash sáº½ giÃºp chÃºng ta má»™t giÃ¡ trá»‹ xáº¥p xá»‰ giÃ¡ trá»‹ cá»§a Jaccard Similarity cá»§a hai táº­p dá»¯ liá»‡u. Æ¯u Ä‘iá»ƒm cá»§a MinHash:\nCÃ³ chiá»u dÃ i Ä‘áº§u ra cá»‘ Ä‘á»‹nh\nKhÃ´ng phá»¥ thuá»™c vÃ o chiá»u dÃ i Ä‘áº§u vÃ o.\nÄá»ƒ tÃ­nh giÃ¡ trá»‹ xáº¥p xá»‰ Jaccard Similarity (MinHash signatures), Ä‘áº§u tiÃªn ta sáº½ tÃ­nh MinHash cá»§a hai táº­p data, Ä‘Æ°á»£c 2 giÃ¡ trá»‹ hash, sau Ä‘Ã³ Ä‘áº¿m giÃ¡ trá»‹ trÃ¹ng nhau cá»§a 2 chuá»—i hash vÃ  chia chiá»u dÃ i gÃ­a trá»‹ hash, chÃºng ta sáº½ Ä‘Æ°á»£c má»™t giÃ¡ trá»‹ xáº¥p xá»‰ giÃ¡ trá»‹ Jaccard Similarity.\nVÃ­ dá»¥ ta cÃ³ hai táº­p táº­p dá»¯ liá»‡u {a,x,c,d} vÃ  {a,x,d,e} hai giÃ¡ trá»‹ hash ta cÃ³ tÆ°Æ¡ng á»©ng lÃ  1234 vÃ  1235, sá»‘ kÃ½ tá»± trÃ¹ng nhau lÃ  3 (1,2,3), chiá»u dÃ i lÃ  4, váº­y ta cÃ³ giÃ¡ trá»‹ Jaccard Similarity lÃ  3/4.\nPhÃ©p tÃ­nh nÃ y sáº½ hÆ¡n viá»‡c tÃ­nh Jaccard Similarity truyá»n thá»‘ng, lÃ½ do lÃ  chÃºng ta khÃ´ng cáº§n pháº£i tÃ­nh pháº§n giao vÃ  pháº§n há»£p cá»§a hai táº­p dá»¯ liá»‡u ( trong trÆ°á»ng há»£p hai táº­p cÃ³ nhiá»u giÃ¡ trá»‹ thÃ¬ viá»‡c tÃ­nh cÃ ng lÃ¢u), vÃ  giÃ¡ trá»‹ hash thÆ°á»ng cÃ³ chiá»u dÃ i ngáº¯n hÆ¡n so vá»›i sá»‘ lÆ°á»£ng pháº§n trá»­ trong táº­p dá»¯ liá»‡u, ngoÃ i ra phÃ©p so sÃ¡nh cÅ©ng Ä‘Æ¡n giáº£n hÆ¡n nhiá»u.\nThuáº­t toÃ¡n MinHash Ã tÆ°á»Ÿng cá»§a thuáº­t toÃ¡n khÃ¡ Ä‘Æ¡n giáº£n:\nta cÃ³ hÃ m hash:\n$$ h(x) = (ax+b)%c $$\nTrong Ä‘Ã³:\nx lÃ  sá»‘ nguyÃªn Ä‘áº§u vÃ o, a vÃ  b lÃ  hai sá»‘ Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn vá»›i Ä‘iá»u kiá»‡n a vÃ  b \u0026lt; x\nc lÃ  sá»‘ nguyÃªn tá»‘ Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn, vá»›i Ä‘iá»u kiá»‡n c lá»›n hÆ¡n x.\nCÃ¡ch thuáº­t toÃ¡n thá»±c hiá»‡n nhÆ° sau:\nVá»›i 1 vÄƒn báº£n, cháº¡y thuáº­t toÃ¡n hash 10 láº§n, do ta cÃ³ sá»‘ a vÃ  b lÃ  ngáº«u nhiÃªn nÃªn 10 láº§n cháº¡y sáº½ cho ra cÃ¡c káº¿t quáº£ khÃ¡c nhau, láº¥y giÃ¡ trá»‹ hash nhá» nháº¥t (do Ä‘Ã³ thuáº­t toÃ¡n cÃ³ tÃªn lÃ  min hash) lÃ m thÃ nh pháº§n Ä‘áº§u tiÃªn cá»§a MinHash signature. Láº·p láº¡i quÃ¡ trÃ¬nh trÃªn 10 láº§n, chÃºng ta cÃ³ MinHash signature vá»›i 10 giÃ¡ trá»‹.\nXong thuáº­t toÃ¡n, quÃ¡ dá»….\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ quan tÃ¢m vÃ  theo dÃµi bÃ i viáº¿t, háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\nTham kháº£o\nKhÃ³a há»c Mining of Massive Datasets chÆ°Æ¡ng 3 http://www.mmds.org/\nhttps://mccormickml.com/2015/06/12/minhash-tutorial-with-python-code/\n","date":"Jan 26, 2020","img":"","permalink":"/blog/2020-01-26-simhash/","series":null,"tags":["python","hash"],"title":"Simhash"},{"categories":null,"content":" Built-In Hashing Checksums Secure Hashing MD5â€“ 16 bytes/128 bit SHA1â€“20 bytes/160 bits SHA256â€“32 bytes/256 bit vÃ  SHA512â€“64 bytes/512 bit Near-Duplicate Detection Perceptual Hashing Káº¿t luáº­n Built-In Hashing Python cÃ³ xÃ¢y dá»±ng sáºµn cho chÃºng ta má»™t hÃ m hash, chÃºng ta cá»© viá»‡c gá»i ra vÃ  sá»­ dá»¥ng.\n1hash(\u0026#34;pham duy tung\u0026#34;) 2-7141560399917772220 Má»™t lÆ°u Ã½ nhá» lÃ  giÃ¡ trá»‹ cá»§a hÃ m hash sáº½ khÃ¡c nhau giá»¯a cÃ¡c phiÃªn báº£n python. VÃ­ dá»¥ á»Ÿ trÃªn mÃ¬nh xÃ i python 3.8, vá»›i báº£n 3.6 sáº½ lÃ \n1hash(\u0026#34;pham duy tung\u0026#34;) 21568935795476364190 Checksums ChÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng checksums Ä‘á»ƒ hash dá»¯ liá»‡u. Checksum Ä‘Æ°á»£c sá»­ dá»¥ng trong thuáº­t toÃ¡n nÃ©n file ZIP Ä‘á»ƒ Ä‘áº£m báº£o toÃ n váº¹n dá»¯ liá»‡u sau khi nÃ©n. ThÆ° viá»‡n zlib cá»§a python há»— trá»£ 2 hÃ m tÃ­nh checksum lÃ  adler32 vÃ  crc32. Äá»ƒ Ä‘áº£m báº£o tá»‘c Ä‘á»™ chÆ°Æ¡ng trÃ¬nh vÃ  chá»‰ cáº§n láº¥y hash Ä‘Æ¡n giáº£n, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng hÃ m Adler32. Tuy nhiÃªn, náº¿u báº¡n muá»‘n chÆ°Æ¡ng trÃ¬nh cÃ³ Ä‘á»™ tin cáº­y cao hoáº·c Ä‘Æ¡n giáº£n lÃ  checksums, hÃ£y sá»­ dá»¥ng crc32. CÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c bÃ i viáº¿t á»Ÿ Ä‘Ã¢y https://www.leviathansecurity.com/blog/analysis-of-adler32 Ä‘á»ƒ hiá»ƒu hÆ¡n.\n1\u0026gt;\u0026gt;\u0026gt; import zlib 2\u0026gt;\u0026gt;\u0026gt; zlib.adler32(b\u0026#34;Pham Duy Tung\u0026#34;) 3524616855 4\u0026gt;\u0026gt;\u0026gt; zlib.crc32(b\u0026#34;Pham Duy Tung\u0026#34;) 53750031252 Secure Hashing MÃ£ hÃ³a an toÃ n (Secure Hashing) vÃ  báº£o máº­t dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c nghiÃªn cá»©u vÃ  á»©ng dá»¥ng tá»« nhiá»u nÄƒm vá» trÆ°á»›c. Tiá»n thÃ¢n lÃ  thuáº­t toÃ¡n MD5 Ä‘áº¿n SHA1, SHA256, SHA512\u0026hellip;. Má»—i thuáº­t toÃ¡n ra Ä‘á»i sau sáº½ cáº£i tiáº¿n Ä‘á»™ báº£o máº­t vÃ  giáº£m Ä‘á»¥ng Ä‘á»™ cá»§a cÃ¡c thuáº­t toÃ¡n trÆ°á»›c Ä‘Ã³.\nMá»™t sá»‘ hÃ m hash phá»• biáº¿n:\nMD5â€“ 16 bytes/128 bit Chuá»—i Ä‘áº§u ra cá»§a MD5 cÃ³ kÃ­ch thÆ°á»›c 16 bytes hay 16*8 = 128 bits. á» thá»i Ä‘iá»ƒm hiá»‡n táº¡i MD5 khÃ´ng cÃ²n lÃ  thuáº­t toÃ¡n phá»• biáº¿n vÃ  khÃ´ng Ä‘Æ°á»£c khuyáº¿n khÃ­ch dÃ¹ng bá»Ÿi cÃ¡c tá»• chá»©c báº£o máº­t.\n1\u0026gt;\u0026gt;\u0026gt; import hashlib 2\u0026gt;\u0026gt;\u0026gt; hashlib.md5(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 3\u0026#39;58067430b9caa44f5ac1220b171f45c8\u0026#39; 4\u0026gt;\u0026gt;\u0026gt; len(hashlib.md5(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) # Chiá»u dÃ i cá»§a Ä‘áº§u ra lÃ  16 bytes 516 ChÃº Ã½: HÃ m hexdigest biá»ƒu diá»…n má»™t byte thÃ nh má»™t kÃ½ tá»± hex (2 kÃ½ tá»± Ä‘áº§u 58 cá»§a vÃ­ dá»¥ trÃªn lÃ  giÃ¡ trá»‹ hex cá»§a sá»‘ 88 trong há»‡ tháº­p phÃ¢n)\nSHA1â€“20 bytes/160 bits Äáº§u ra cá»§a SHA1 cÃ³ chiá»u dÃ i lÃ  20 bytes tÆ°Æ¡ng á»©ng vá»›i 160 bit. CÅ©ng giá»‘ng nhÆ° MD5, SHA1 cÅ©ng khÃ´ng Ä‘Æ°á»£c khuyáº¿n khÃ­ch sá»­ dá»¥ng á»Ÿ trong cÃ¡c á»©ng dá»¥ng báº£o máº­t.\n1\u0026gt;\u0026gt;\u0026gt; import hashlib 2\u0026gt;\u0026gt;\u0026gt; hashlib.sha1(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 3\u0026#39;b95b8716f15d89b6db67e2e788dea42d3fba5ee8\u0026#39; 4\u0026gt;\u0026gt;\u0026gt; len(hashlib.sha1(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) 520 SHA256â€“32 bytes/256 bit vÃ  SHA512â€“64 bytes/512 bit ÄÃ¢y lÃ  hai hÃ m hash Ä‘Æ°á»£c khuyÃªn lÃ  nÃªn dÃ¹ng á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i\n1\u0026gt;\u0026gt;\u0026gt; hashlib.sha256(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 2\u0026#39;611b322b6b8ee570831c6061408ac5aa77fcdb572206d5d443855f5d3c1383c6\u0026#39; 3\u0026gt;\u0026gt;\u0026gt; len(hashlib.sha256(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) 432 5\u0026gt;\u0026gt;\u0026gt; hashlib.sha512(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 6\u0026#39;ac1f6a2dd234bc15c1fa2be1db4e55ad4af8c476abb8e3d9ac3d4c74d3e151c23314e20925616e90a0bcb13a38b5531e064c586d65fed54504d713fdabee03f9\u0026#39; 7\u0026gt;\u0026gt;\u0026gt; len(hashlib.sha512(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) 864 Near-Duplicate Detection CÃ¡c thuáº­t toÃ¡n Ä‘Æ°á»£c giá»›i thiá»‡u á»Ÿ trÃªn, khi chÃºng ta thay Ä‘á»•i giÃ¡ trá»‹ Ä‘áº§u vÃ o, dÃ¹ chá»‰ má»™t giÃ¡ trá»‹ nhá» thÃ´i á»Ÿ má»™t vÃ i vá»‹ trÃ­ nÃ o Ä‘Ã³, thÃ¬ káº¿t quáº£ tráº£ ra láº¡i khÃ¡c nhau khÃ¡ lá»›n. Tuy nhiÃªn, Ä‘Ã´i khi chÃºng ta gáº·p nhá»¯ng bÃ i toÃ¡n tÃ¬m ná»™i dung tÆ°Æ¡ng tá»± nhau hoáº·c gáº§n nhÆ° tÆ°Æ¡ng tá»± nhau. VÃ­ dá»¥ giá»‘ng nhÆ° google crawler dá»¯ liá»‡u xÃ¡c Ä‘á»‹nh nhá»¯ng bÃ i vÄƒn copy paste tá»« nhá»¯ng trang web khÃ¡c nhau, hoáº·c phÃ¡t hiá»‡n Ä‘áº¡o vÄƒn, phÃ¡t hiá»‡n Ä‘áº¡o nháº¡c \u0026hellip;\nMá»™t thuáº­t toÃ¡n khÃ¡ phá»• biáº¿n náº±m trong nhÃ³m nÃ y lÃ  SimHash. Thuáº­t toÃ¡n Ä‘Æ°á»£c google sá»­ dá»¥ng Ä‘á»ƒ tÃ¬m ra cÃ¡c trang gáº§n trÃ¹ng nhau (theo wiki https://en.wikipedia.org/wiki/SimHash). TÃ¡c giáº£ cá»§a thuáº­t toÃ¡n lÃ  Moses Charikar.\nÄá»ƒ dÃ¹ng Simhash, chÃºng ta pháº£i cÃ i Ä‘áº·t package tá»« kho cá»§a python\n1from simhash import Simhash 2 3\u0026gt;\u0026gt;\u0026gt; Simhash(\u0026#34;Pham Duy Tung\u0026#34;).value 417022061268703429674 5\u0026gt;\u0026gt;\u0026gt; Simhash(\u0026#34;Pham Duy Tung1\u0026#34;).value 617184261516160517290 Má»™t trong nhá»¯ng lÆ°u Ã½ quan trá»ng khi sá»­ dá»¥ng SimHash ( tham kháº£o https://stackoverflow.com/questions/49820228/how-to-compare-the-similarity-of-documents-with-simhash-algorithm/49831194#49831194)\nSimHash tháº­t sá»± há»¯u Ã­ch trong bÃ i toÃ¡n phÃ¡t hiá»‡n vÄƒn báº£n trÃ¹ng láº¯p.\nÄá»ƒ tÃ¬m vÄƒn báº£n trÃ¹ng láº¯p chÃ­nh xÃ¡c, dÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n Ä‘Æ¡n giáº£n mÃ  hiá»‡u quáº£ nhÆ° md5, sha1sha1.\nThuáº­t toÃ¡n phÃ¹ há»£p cÃ¡c vÄƒn báº£n lá»›n, khÃ´ng phÃ¹ há»£p cho cÃ¡c cÃ¢u vÄƒn nhá».\nÄoáº¡n code bÃªn dÆ°á»›i lÃ  má»™t vÃ­ dá»¥ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ tÃ¬m cÃ¡c vÄƒn báº£n cÃ³ Ä‘áº¡o ná»™i dung.\n1 #assuming that you have a dictionary with document id as the key and the document as the value: 2# documents = { doc_id: doc } you can do: 3 4from simhash import simhash 5 6def split_hash(str, num): 7 return [ str[start:start+num] for start in range(0, len(str), num) ] 8 9hashes = {} 10for doc_id, doc in documents.items(): 11 hash = simhash(doc) 12 13 # you can either use the whole hash for higher precision or split into chunks for higher recall 14 hash_chunks = split_hash(hash, 4) 15 16 for chunk in hash_chunks: 17 if chunk not in hashes: 18 hashes[chunk] = [] 19 hashes[chunk].append(doc_id) 20 21# now you can print the duplicate documents: 22for hash, doc_list in hashes: 23 if doc_list \u0026gt; 1: 24 print(\u0026#34;Duplicates documents: \u0026#34;, doc_list) NgoÃ i SimHash, cÃ²n má»™t thuáº­t toÃ¡n hash khÃ¡ ná»•i tiáº¿ng ná»¯a cÅ©ng Ä‘Æ°á»£c google sá»­ dá»¥ng trong viá»‡c cÃ¡ nhÃ¢n hÃ³a ngÆ°á»i dÃ¹ng, Ä‘Ã³ lÃ  MinHash. á» cÃ¡c bÃ i viáº¿t tiáº¿p theo mÃ¬nh sáº½ viáº¿t vá» thuáº­t toÃ¡n nÃ y.\nPerceptual Hashing Loáº¡i hash cuá»‘i cÃ¹ng chÃºng ta Ä‘á» cáº­p á»Ÿ Ä‘Ã¢y lÃ  perceptual hashing. Loáº¡i hash nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¡t hiá»‡n sá»± khÃ¡c nhau trong táº­p hÃ¬nh áº£nh hoáº·c trong video.\nMá»™t vÃ­ dá»¥ cá»§a cÃ¡c thuáº­t toÃ¡n thuá»™c nhÃ³m lÃ  lÃ  Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c frame áº£nh trÃ¹ng láº¯p trong video. Thuáº­t toÃ¡n Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ loáº¡i bá» nhá»¯ng ná»™i dung trÃ¹ng láº¯p, giÃºp tiáº¿t kiá»‡m lÆ°u trá»¯. Hoáº·c dÃ¹ng trong cÃ¡c thuáº­t toÃ¡n tÃ³m táº¯t video.\náº¢nh 1 áº¢nh 2\n1\u0026gt;\u0026gt;\u0026gt; import hashlib 2\u0026gt;\u0026gt;\u0026gt; from PIL import Image 3\u0026gt;\u0026gt;\u0026gt; image1 = Image.open(\u0026#34;google_free_ds1.png\u0026#34;) 4\u0026gt;\u0026gt;\u0026gt; image1 = Image.open(\u0026#34;google_free_ds_1.png\u0026#34;) 5\u0026gt;\u0026gt;\u0026gt; image2 = Image.open(\u0026#34;google_free_ds_2.png\u0026#34;) 6\u0026gt;\u0026gt;\u0026gt; hashlib.sha256(image1.tobytes()).hexdigest() 7\u0026#39;c57d0b5b1ca64077b45bdb65f817497834675232a2fc2ed76d6b8aa7955126b9\u0026#39; 8\u0026gt;\u0026gt;\u0026gt; hashlib.sha256(image2.tobytes()).hexdigest() 9\u0026#39;02ea5e51b19cf3748f91f9bbe26976e9e14dca4b47e0aaff88ab20030a695f44\u0026#39; GiÃ¡ trá»‹ hash khÃ¡c xa nhau, cÃ³ váº» chÃºng ta khÃ´ng thá»ƒ nÃ o sá»­ dá»¥ng SHA256 trong bÃ i toÃ¡n nÃ y Ä‘Æ°á»£c. LÃºc nÃ y, chÃºng ta sáº½ tÃ¬m tá»›i cÃ¡c thÆ° viá»‡n thuá»™c nhÃ³m Perceptual Hashing, má»™t trong sá»‘ chÃºng lÃ  ImageHash.\n1\u0026gt;\u0026gt;\u0026gt; import imagehash 2\u0026gt;\u0026gt;\u0026gt; hash1 = imagehash.average_hash(image1) 3\u0026gt;\u0026gt;\u0026gt; hash2 = imagehash.average_hash(image2) 4\u0026gt;\u0026gt;\u0026gt; hash1-hash2 524 GiÃ¡ trá»‹ hash cá»§a hai áº£nh trÃªn lÃ  khÃ¡c nhau, nhÆ°ng sá»± khÃ¡c nhau lÃ  ráº¥t Ã­t. Chá»©ng tá» hai áº£nh trÃªn cÃ³ thá»ƒ lÃ  báº£n sao cá»§a nhau.\nKáº¿t luáº­n Trong bÃ i viáº¿t nÃ y, chÃºng ta Ä‘Ã£ Ä‘á» cáº­p qua cÃ¡c cÃ¡ch khÃ¡c nhau Ä‘á»ƒ hash dá»¯ liá»‡u trong Python. Phá»¥ thuá»™c vÃ o bÃ i toÃ¡n, chÃºng ta sáº½ sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n vá»›i cÃ¡c tham sá»‘ phÃ¹ há»£p. Hi vá»ng bÃ i viáº¿t nÃ y sáº½ Ã­t nhiá»u giÃºp Ã­ch Ä‘Æ°á»£c cho cÃ¡c báº¡n.\nChÃº thÃ­ch:\náº¢nh cover cá»§a bÃ i viáº¿t lÃ  áº£nh cá»§a chÃ¹m sao tháº¥t tinh báº¯c Ä‘áº©u mÃ¬nh chá»¥p tá»« trang https://stellarium-web.org/.\nhash collision : Khi cho 2 input khÃ¡c nhau vÃ o hÃ m hash mÃ  cÃ¹ng ra má»™t output -\u0026gt; collision.\nNguá»“n bÃ i viáº¿t:\nhttps://medium.com/better-programming/how-to-hash-in-python-8bf181806141\n","date":"Jan 25, 2020","img":"","permalink":"/blog/2020-01-13-hash-in-python/","series":null,"tags":["python","hash"],"title":"CÃ¡c HÃ m Hash CÃ³ Sáºµn Trong Python"},{"categories":null,"content":" Äáº·t váº¥n Ä‘á» Thuáº­t toÃ¡n NMS Äáº·t váº¥n Ä‘á» Sau khi thá»±c hiá»‡n object detection feed má»™t áº£nh qua máº¡ng neural, chÃºng ta sáº½ thu Ä‘Æ°á»£c ráº¥t nhiá»u proposals (nhÆ° hÃ¬nh á»Ÿ dÆ°á»›i). á» tráº¡ng thÃ¡i nÃ y, cÃ³ ráº¥t nhiá»u proposals lÃ  boding box cho má»™t object duy nháº¥t, Ä‘iá»u nÃ y dáº«n tá»›i viá»‡c dÆ° thá»«a. ChÃºng ta sá»­ dá»¥ng thuáº­t toÃ¡n Non-maximum suppression (NMS) Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n nÃ y.\nHÃ¬nh 1: Proposals box, hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»« bÃ i bÃ¡o\nThuáº­t toÃ¡n NMS Äáº§u vÃ o:\nTáº­p danh sÃ¡ch cÃ¡c proposals box kÃ½ hiá»‡u lÃ  B vá»›i B ={b1,b2,\u0026hellip;,bn}, vá»›i bi lÃ  proposal thá»© i.\nTáº­p Ä‘iá»ƒm cá»§a má»—i proposal box kÃ½ hiá»‡u lÃ  S vá»›i S={s1,s2,\u0026hellip;,sn}, si lÃ  Ä‘iá»ƒm confidence cá»§a box bi\nGiÃ¡ trá»‹ ngÆ°á»¡ng overlap threshold N.\nCáº£ hai giÃ¡ trá»‹ bi vÃ  si Ä‘á»u lÃ  output cá»§a máº¡ng neural network.\nÄáº§u ra:\nMá»™t táº­p cÃ¡c proposals box D lÃ  táº­p cÃ¡c proposals Ä‘Ã£ loáº¡i bá» dÆ° thá»«a tÆ°Æ¡ng á»©ng vá»›i tá»«ng object trong hÃ¬nh.\nThuáº­t toÃ¡n:\nBÆ°á»›c 1: Khá»Ÿi táº¡o táº­p output D = {}\nBÆ°á»›c 2: Chá»n ra proposal box cÃ³ Ä‘iá»ƒm confidence cao nháº¥t trong táº­p S, loáº¡i box Ä‘Ã³ ra khá»i táº­p S, B vÃ  thÃªm nÃ³ vÃ o táº­p D.\nBÆ°á»›c 3: TÃ­nh giÃ¡ trá»‹ IOU giá»¯a proposal box má»›i vá»«a loáº¡i ra á»Ÿ bÆ°á»›c 2 vá»›i toÃ n bá»™ proposal box trong táº­p B. Náº¿u cÃ³ báº¥t ká»³ box nÃ o Ä‘Ã³ cÃ³ giÃ¡ trá»‹ IOU lá»›n hÆ¡n giÃ¡ trá»‹ ngÆ°á»¡ng N thÃ¬ loáº¡i box Ä‘Ã³ ra khá»i B, S.\nBÆ°á»›c 4: Láº·p láº¡i bÆ°á»›c 2 Ä‘áº¿n khi nÃ o khÃ´ng cÃ²n box nÃ o cÃ³ trong táº­p B.\nÄiá»ƒm yáº¿u cá»§a thuáº­t toÃ¡n:\nNáº¿u báº¡n Ä‘á»c ká»¹ thuáº­t toÃ¡n, báº¡n sáº½ tháº¥y ráº±ng toÃ n bá»™ quÃ¡ trÃ¬nh loai bá» nhá»¯ng box dÆ° thá»«a Ä‘á»u phá»¥ thuá»™c vÃ o giÃ¡ trá»‹ ngÆ°á»¡ng N. Viá»‡c chá»n lá»±a giÃ¡ trá»‹ N chÃ­nh lÃ  chÃ¬a khÃ³a thÃ nh cÃ´ng cá»§a mÃ´ hÃ¬nh. Tuy nhiÃªn, viá»‡c chá»n giÃ¡ trá»‹ ngÆ°á»¡ng nÃ y trong cÃ¡c bÃ i toÃ¡n khÃ¡ khÃ³. VÃ  vá»›i viá»‡c chá»‰ sá»­ dá»¥ng giÃ¡ trá»‹ N, chÃºng ta sáº½ gáº·p trÆ°á»ng há»£p dÆ°á»›i Ä‘Ã¢y.\nGiáº£ sá»­a giÃ¡ trá»‹ ngÆ°á»¡ng N báº¡n chá»n lÃ  0.5. CÃ³ nghÄ©a lÃ  náº¿u box cÃ³ giÃ¡ trá»‹ lá»›n IOU Ä‘á»u bá»‹ loáº¡i bá», ngay cáº£ vá»›i trÆ°á»ng há»£p Ä‘iá»ƒm score si cá»§a nÃ³ cÃ³ giÃ¡ trá»‹ cao. NgÆ°á»£c láº¡i, giáº£ sá»­ box cÃ³ Ä‘iá»ƒm score si tháº¥p nhÆ°ng IOU cá»§a nÃ³ nhá» hÆ¡n 0.5, vÃ­ dá»¥ o.49, thÃ¬ nÃ³ láº¡i Ä‘Æ°á»£c nháº­n.\nVÃ  Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n nÃ y Navaneeth Bodla Ä‘Ã£ Ä‘á» xuáº¥t má»™t cáº£i tiáº¿n nhá» vÃ  Ä‘áº·t tÃªn thuáº­t toÃ¡n lÃ  Soft-NMS. Ã½ tÆ°á»Ÿng Ä‘Æ°á»£c Ä‘á» ra nhÆ° sau: Thay vÃ¬ pháº£i loáº¡i bá» hoÃ n toÃ n proposal, chÃºng ta sáº½ giáº£m giÃ¡ trá»‹ confidence cá»§a box Ä‘i.\nsoft-nms, hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»« bÃ i bÃ¡o\nVá»›i giÃ¡ trá»‹ si Ä‘Æ°á»£c cáº­p nháº­t láº¡i nhÆ° sau:\nsoft-nms, hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»« bÃ i bÃ¡o\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t. Háº¹n gáº·p láº¡i cÃ¡c báº¡n á»Ÿ nhá»¯ng bÃ i viáº¿t tiáº¿p theo.\nTham kháº£o\nhttps://medium.com/@yusuken/object-detction-1-nms-ed00d16fdcf9\nhttps://towardsdatascience.com/non-maximum-suppression-nms-93ce178e177c\nhttps://arxiv.org/pdf/1704.04503.pdf\nhttps://arxiv.org/pdf/1705.02950.pdf\n","date":"Dec 25, 2019","img":"","permalink":"/blog/2019-12-25-nms/","series":null,"tags":["Machine learning","Deeplearning","AlexNet"],"title":"TÃ¬m Hiá»ƒu Non-Maximum Suppression (NMS)"},{"categories":null,"content":" Kiáº¿n trÃºc máº¡ng AlexNet Cáº£i tiáº¿n cá»§a mÃ´ hÃ¬nh Ä‘á»ƒ giáº£m error rate Sá»­ dá»¥ng ReLU thay cho TanH Local Response Normalization Overlapping Pooling Sá»­ dá»¥ng Data Augmentation Dropout Sá»­ dá»¥ng nhiá»u GPU Má»™t sá»‘ chi tiáº¿t khÃ¡c vá» cÃ¡c learning param Káº¿t quáº£ Máº¡ng CaffeNet Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ tÃ¬m hiá»ƒu mÃ´ hÃ¬nh AlexNet tá»« nhÃ³m cá»§a giÃ¡o sÆ° Hinton. Tá»›i thá»i Ä‘iá»ƒm hiá»‡n táº¡i (2019-05-27), bÃ i viáº¿t cá»§a giÃ¡o sÆ° Ä‘Ã£ cÃ³ hÆ¡n 40316 lÆ°á»£t trÃ­ch dáº«n. BÃ i bÃ¡o nÃ y cÃ³ bÆ°á»›c Ä‘Ã³ng gÃ³p cá»±c ká»³ quan trá»ng, lÃ  má»™t Ä‘á»™t phÃ¡ lá»›n trong lÄ©nh vá»±c deep learning, má»Ÿ Ä‘áº§u cho sá»± quay láº¡i cá»§a máº¡ng neural network vÃ  Ä‘Ã³ng gÃ³p trá»±c tiáº¿p vÃ o thÃ nh cÃ´ng cá»§a nhá»¯ng chÆ°Æ¡ng trÃ¬nh trÃ­ tuá»‡ nhÃ¢n táº¡o táº¡i thá»i Ä‘iá»ƒm hiá»‡n táº¡i.\nVá» bÃ i bÃ¡o gá»‘c cá»§a tÃ¡c giáº£, mÃ¬nh cÃ³ Ä‘á»ƒ á»Ÿ pháº§n trÃ­ch dáº«n bÃªn dÆ°á»›i. CÃ¡c báº¡n cÃ³ nhu cáº§u tÃ¬m hiá»ƒu cÃ³ thá»ƒ tÃ¬m vÃ  Ä‘á»c. Theo Ã½ kiáº¿n riÃªng cá»§a mÃ¬nh, Ä‘Ã¢y lÃ  má»™t bÃ i bÃ¡o ráº¥t nÃªn Ä‘á»c vÃ  pháº£i Ä‘á»c. TrÆ°á»›c Ä‘Ã¢y mÃ¬nh Ä‘Ã£ cÃ³ viáº¿t 1 bÃ i vá» táº­p AlexNet nhÆ°ng chÆ°a Ä‘áº§y Ä‘á»§, bÃ i Ä‘Ã³ mÃ¬nh chá»‰ giá»›i thiá»‡u phá»›t phá»›t qua máº¡ng AlexNet. Trong bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ trÃ¬nh bÃ y ká»¹ hÆ¡n.\nSÆ¡ lÆ°á»£c má»™t chÃºt, táº­p dá»¯ liá»‡u ImageNet lÃ  táº­p dataset cÃ³ khoáº£ng 15 triá»‡u hÃ¬nh áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i cao Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n (cÃ³ khoáº£ng 22000 nhÃ£n). Cuá»™c thi ILSVRC sá»­ dá»¥ng má»™t pháº§n nhá» cá»§a táº­p ImageNet vá»›i khoáº£ng 1.2 triá»‡u áº£nh cá»§a 1000 nhÃ£n (trung bÃ¬nh má»—i nhÃ£n cÃ³ khoáº£ng 1.2 ngÃ n hÃ¬nh áº£nh) lÃ m táº­p train, 50000 áº£nh lÃ m táº­p validation vÃ  150000 áº£nh lÃ m táº­p test (táº­p validation vÃ  táº­p test Ä‘á»u cÃ³ 1000 nhÃ£n thuá»™c táº­p train).\nKiáº¿n trÃºc máº¡ng AlexNet Kiáº¿n trÃºc mÃ´ hÃ¬nh AlexNet\nMáº¡ng AlexNet bao gá»“m 8 lá»›p (tÃ­nh luÃ´n lá»›p input lÃ  9), bao gá»“m:\nInput: cÃ³ kÃ­ch thÆ°á»›c 224x224x3 (Scale áº£nh Ä‘áº§u vÃ o vá» dáº¡ng 224x224x3, thá»±c cháº¥t áº£nh cá»§a táº­p ImageNet cÃ³ size tÃ¹y Ã½)\nLá»›p thá»© nháº¥t:\nConvolution Layer cÃ³ kÃ­ch thÆ°á»›c 11x11x3 vá»›i stride size = 4 vÃ  pad = 0. Káº¿t quáº£ sau bÆ°á»›c nÃ y ta Ä‘Æ°á»£c táº­p feature map cÃ³ kÃ­ch thÆ°á»›c 55x55x96 (mÃ¬nh nghÄ© lÃ  cÃ¡c báº¡n sáº½ biáº¿t cÃ¡ch tÃ­nh sao cho ra sá»‘ 55, mÃ¬nh cÅ©ng Ä‘Ã£ Ä‘á» cáº­p váº¥n Ä‘á» cÃ¡ch tÃ­nh nÃ y á»Ÿ 1 bÃ i viáº¿t trÆ°á»›c Ä‘Ã¢y).\rTiáº¿p theo lÃ  má»™t Overlapping Max Pooling 3x3 cÃ³ stride =2 =\u0026gt; feature maps = 27x27x96.\rTiáº¿p theo lÃ  Local Response Normalization =\u0026gt; feature maps = 27x27x96.\rXong lá»›p thá»© nháº¥t\rLá»›p thá»© hai:\nConvolutional Layer: 256 kernels cÃ³ kÃ­ch thÆ°á»›c 5x5x48 (stride size = 1, pad = 2) =\u0026gt; 27x27x256 feature maps.\rOverlapping Max Pooling 3x3 cÃ³ stride =2 =\u0026gt; feature maps = 13x13x256.\rTiáº¿p theo lÃ  Local Response Normalization =\u0026gt; feature maps = 13x13x256.\rLá»›p thá»© ba:\nConvolutional Layer: 384 kernels cÃ³ kÃ­ch thÆ°á»›c 3x3x256 (stride size = 1, pad = 1) =\u0026gt; 13x13x384 feature maps.\rLá»›p thá»© bá»‘n: 384 kernels cÃ³ kÃ­ch thÆ°á»›c 3x3x192 (stride size = 1, pad = 1) =\u0026gt; 13x13x384 feature maps.\nLá»›p thá»© nÄƒm:\nConvolutional Layer: 256 kernels cÃ³ kÃ­ch thÆ°á»›c 3x3x192 (stride size = 1, pad = 1) =\u0026gt; 13x13x256 feature maps.\rOverlapping Max Pooling 3x3 cÃ³ stride =2 =\u0026gt; feature maps = 6x6x256.\rLá»›p thá»© sÃ¡u:\nFull connected (hay cÃ²n gá»i lÃ  Dense layer) vá»›i 4096 neurals\rLá»›p thá»© báº£y:\nFull connected vá»›i 4096 neurals\rLá»›p thá»© tÃ¡m:\nFull connected ra output 1000 neural (do cÃ³ 1000 lá»›p)\rHÃ m Ä‘á»™ lá»—i Ä‘Æ°á»£c sá»­ dá»¥ng lÃ  Softmax.\nTá»•ng cá»™ng, chÃºng ta cÃ³ 60 triá»‡u tham sá»‘ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n.\nCáº£i tiáº¿n cá»§a mÃ´ hÃ¬nh Ä‘á»ƒ giáº£m error rate Sá»­ dá»¥ng ReLU thay cho TanH HÃ m kÃ­ch hoáº¡t ReLU vÃ  TanH\nCÃ¡c mÃ´ hÃ¬nh neural network trÆ°á»›c khi bÃ i bÃ¡o ra Ä‘á»i thÆ°á»ng sá»­ dá»¥ng hÃ m Tanh lÃ m hÃ m kÃ­ch hoáº¡t. MÃ´ hÃ¬nh AlexNet khÃ´ng sá»­ dá»¥ng hÃ m TanH mÃ  giá»›i thiá»‡u má»™t hÃ m kÃ­ch hoáº¡t má»›i lÃ  ReLU. ReLU giÃºp cho quÃ¡ trÃ¬nh huáº¥n luyá»‡n cháº¡y nhanh hÆ¡n gáº¥p 6 láº§n so vá»›i kiáº¿n trÃºc tÆ°Æ¡ng tá»± sá»­ dá»¥ng TanH, gÃ³p má»™t pháº§n vÃ o viá»‡c Ä‘á»™ lá»—i trÃªn táº­p huáº¥n luyá»‡n lÃ  25%.\nLocal Response Normalization Local Response Normalization vÃ  Batch Normalization\nTrong máº¡ng AlexNet, nhÃ³m tÃ¡c giáº£ sá»­ dá»¥ng hÃ m chuáº©n hÃ³a lÃ  Local Response Normalization. HÃ m nÃ y khÃ´ng pháº£i lÃ  Batch Normalization mÃ  cÃ¡c báº¡n hay sá»­ dá»¥ng á»Ÿ thá»i Ä‘iá»ƒm hiá»‡n táº¡i (xem hÃ¬nh á»Ÿ trÃªn, hai hÃ m cÃ³ cÃ´ng thá»©c tÃ­nh toÃ¡n hoÃ n toÃ n khÃ¡c nhau). Viá»‡c sá»­ dá»¥ng chuáº©n hÃ³a (Normalization) giÃºp tÄƒng tá»‘c Ä‘á»™ há»™i tá»¥. NgÃ y nay, chÃºng ta khÃ´ng cÃ²n sá»­ dá»¥ng Local Response Normalization ná»¯a. Thay vÃ o Ä‘Ã³, chÃºng ta sá»­ dá»¥ng Batch Normalization lÃ m hÃ m chuáº©n hÃ³a.\nVá»›i viá»‡c sá»­ dá»¥ng hÃ m chuáº©n hÃ³a Local Response Normalization, Ä‘á»™ lá»—i top-1 error rate giáº£m 1.4%, top-5 giáº£m 1.2%.\nOverlapping Pooling Overlapping Pooling lÃ  pooling vá»›i stride nhá» hÆ¡n kernel size. Má»™t khÃ¡i niá»‡m ngÆ°á»£c vá»›i Overlapping Pooling lÃ  Non-Overlapping Pooling vá»›i stride lá»›n hoÄƒn hoáº·c báº±ng kernel.\nMáº¡ng AlexNet sá»­ dá»¥ng Overlapping Pooling á»Ÿ hidden layer thá»© 1, 2 vÃ  5 (Kernel size = 3x3, stride =2).\nVá»›i viá»‡c sá»­ dá»¥ng overlapping pooling, top-1 error rates giáº£m 0.4%, top-5 error rate giáº£m 0.3%.\nSá»­ dá»¥ng Data Augmentation Dá»¯ liá»‡u cá»§a táº­p huáº¥n luyá»‡n khÃ¡ nhiá»u, 1.2 triá»‡u máº«u. NhÆ°ng chia ra cho 1000 lá»›p thÃ¬ má»—i lá»›p cÃ³ khoáº£ng 1200, khÃ¡ khiÃªm tá»‘n pháº£i khÃ´ng. Cho nÃªn, tÃ¡c giáº£ Ä‘Ã£ nghÄ© ra má»™t cÃ¡ch khÃ¡ hay Ä‘á»ƒ tÄƒng sá»‘ lÆ°á»£ng hÃ¬nh áº£nh mÃ  váº«n giá»¯ Ä‘Æ°á»£c tÃ­nh IID cá»§a dá»¯ liá»‡u, Ä‘Ã³ lÃ  sá»­ dá»¥ng cÃ¡c phÃ©p biáº¿n Ä‘á»•i affine trÃªn dá»¯ liá»‡u áº£nh gá»‘c Ä‘á»ƒ thu thÃªm nhiá»u áº£nh hÆ¡n.\nCÃ³ hai dáº¡ng Data Augentation Ä‘Æ°á»£c tÃ¡c giáº£ sá»­ dá»¥ng\nDáº¡ng thá»© nháº¥t: Image translation vÃ  horizontal reflection (mirroring)\nImage translation Ä‘Æ°á»£c hiá»ƒu nhÆ° sau: áº£nh ImageNet gá»‘c cÃ³ kÃ­ch thÆ°á»›c 256x256 pixel, tÃ¡c giáº£ rÃºt ra má»™t áº£nh con cÃ³ kÃ­ch thÆ°á»›c 224x224 pixel, sau Ä‘Ã³ dá»‹ch qua trÃ¡i 1 pixel vÃ  láº¥y 1 áº£nh con tiáº¿p theo cÃ³ kÃ­ch thÆ°á»›c 224x224. LÃ m nhÆ° váº­y theo hÃ ng, háº¿t hÃ ng lÃ m theo cá»™t. Cuá»‘i cÃ¹ng tÃ¡c giáº£ cÃ³ thá»ƒ tá»« má»™t bá»©c hÃ¬nh 256x256 ban Ä‘áº§u rÃºt trÃ­ch thÃ nh 1024 hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c 224x224\nhorizontal reflection (mirroring) Ä‘Æ°á»£c hiá»ƒu lÃ  láº¥y áº£nh pháº£n chiáº¿u cá»§a Ã¡nh gá»‘c qua Ä‘Æ°á»ng chÃ©o chÃ­nh. VÃ­ dá»¥ con bÃ¡o dang cÃ³ hÆ°á»›ng tai cá»§a nÃ³ tá»« trÃ¡i qua pháº£i, ta láº¥y horizontal reflection cá»§a áº£nh Ä‘Ã³ thÃ¬ sáº½ Ä‘Æ°á»£c con bÃ¡o hÆ°á»›ng tai tá»« pháº£i qua trÃ¡i.\nVá»›i viá»‡c káº¿t há»£p Image translation vÃ  horizontal reflection (mirroring), tÃ¡c giáº£ cÃ³ thá»ƒ rÃºt tá»‘i Ä‘a 2048 bá»©c áº£nh khÃ¡c nhau chá»‰ tá»« 1 bá»©c áº£nh gá»‘c =\u0026gt; vá»›i hÆ¡n 1000 bá»©c áº£nh cá»§a 1 nhÃ£n cÃ³ thá»ƒ sinh ra tá»‘i Ä‘a lÃ  2048000 bá»©c áº£nh, má»™t con sá»‘ khÃ¡ lá»›n pháº£i khÃ´ng cÃ¡c báº¡n.\ná» táº­p test, tÃ¡c giáº£ sá»­ dá»¥ng 4 hÃ¬nh 224x224 á»Ÿ bá»‘n gÃ³c cá»™ng vá»›i 1 hÃ¬nh 224x224 á»Ÿ trung tÃ¢m =\u0026gt; Ä‘Æ°á»£c 5 hÃ¬nh, Ä‘em 5 hÃ¬nh Ä‘Ã³ sá»­ dá»¥ng horizontal reflection thÃ¬ thu Ä‘Æ°á»£c 10 hÃ¬nh cho má»—i file test.\nDáº¡ng thá»© hai: Thay Ä‘á»•i Ä‘á»™ sÃ¡ng\nThá»±c hiá»‡n tÃ­nh PCA trÃªn táº­p train. Vá»›i má»—i hÃ¬nh trÃªn táº­p train, thay Ä‘á»•i giÃ¡ trá»‹ Ä‘á»™ sÃ¡ng\n$$[p_1, p_2, p_3][\\alpha_1 \\gamma_1, \\alpha_2 \\gamma_2, \\alpha_3 \\gamma_3]^T$$\nvá»›i pi vÃ  gammai lÃ  giÃ¡ trá»‹ trá»‹ riÃªng vÃ  vector riÃªng thá»© i cá»§a ma tráº­n hiá»‡p phÆ°Æ¡ng sai 3x3 cá»§a áº£nh, vÃ  alpha i lÃ  má»™t giÃ¡ trá»‹ ngáº«u nhiÃªn thuá»™c Ä‘oáº¡n 1 vÃ  Ä‘á»™ lá»‡ch chuáº©n 0.1..\nVá»›i viá»‡c sá»­ dá»¥ng data augmentation, top-1 error rate giáº£m 1% Ä‘á»™ lá»—i.\nDropout Dropout\nVá»›i má»—i layer sá»­ dá»¥ng dropout, má»—i neural sáº½ cÃ³ cÆ¡ há»™i khÃ´ng Ä‘Ã³ng gÃ³p vÃ o feed forward vÃ  backpropagation. Do Ä‘Ã³, má»—i neural Ä‘á»u cÃ³ cÆ¡ há»™i ráº¥t lá»›n Ä‘Ã³ng gÃ³p vÃ o thuáº­t toÃ¡n, vÃ  chÃºng ta sáº½ giáº£m thiá»ƒu tÃ¬nh tráº¡ng phá»¥ thuá»™c vÃ o má»™t vÃ i neural.\nKhÃ´ng sá»­ dá»¥ng dropout trong táº­p quÃ¡ trÃ¬nh test.\nMáº¡ng AlexNet sá»­ dá»¥ng giÃ¡ trá»‹ xÃ¡c xuáº¥t cá»§a dropout lÃ  0.5 á»Ÿ hai fully-connected layer. Dopout Ä‘Æ°á»£c xem nhÆ° lÃ  má»™t ká»¹ thuáº­t chuáº©n hÃ³a nháº±m má»¥c Ä‘Ã­ch giáº£m overfitting.\nSá»­ dá»¥ng nhiá»u GPU Táº¡i nÄƒm 2012, nhÃ³m tÃ¡c giáº£ sá»­ dá»¥ng card Ä‘á»“ há»a NIVIDIA GTX 580 cÃ³ 3GB bá»™ nhá»› RAM. Cho nÃªn, Ä‘á»ƒ cÃ³ thá»ƒ huáº¥n luyá»‡n Ä‘Æ°á»£c mÃ´ hÃ¬nh AlexNet trÃªn GPU, mÃ´ hÃ¬nh cáº§n sá»­ dá»¥ng 2 GPU.\nvÃ¬ váº­y viá»‡c sá»­ dá»¥ng 2 hoáº·c nhiá»u GPU lÃ  do váº¥n Ä‘á» thiáº¿u bá»™ nhá»›, chá»© khÃ´ng pháº£i lÃ  váº¥n Ä‘á» tÄƒng tá»‘c quÃ¡ trÃ¬nh train hÆ¡n so vá»›i 1 GPU\nNgoÃ i ra, do giá»›i háº¡n cá»§a GPU, nÃªn mÃ´ hÃ¬nh AlexNet Ä‘Æ°á»£c tÃ¡ch ra lÃ m 2 pháº§n, má»—i pháº§n Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn 1 GPU. PhiÃªn báº£n 1 GPU cá»§a mÃ´ hÃ¬nh cÃ³ tÃªn lÃ  CaffeNet, vÃ  Ä‘Ã²i há»i chÃºng ta pháº£i sá»­ dá»¥ng GPU cÃ³ bá»™ nhá»› RAM lá»›n hÆ¡n hoáº·c báº±ng 6GB.\nMá»™t sá»‘ chi tiáº¿t khÃ¡c vá» cÃ¡c learning param Batch size: 128\nMomemtum: 0.9\nWeight Decay: 0.0005\nLearning rate: 0.01, giÃ¡ trá»‹ learning rate sáº½ giáº£m Ä‘i 10 láº§n náº¿u validation error rate khÃ´ng thay Ä‘á»•i trong 1 khoáº£ng thá»i gian. Sá»‘ láº§n giáº£m lÃ  3.\nEpoch: 90\nNhÃ³m tÃ¡c giáº£ Ä‘Ã£ sá»­ dá»¥ng 2 GPU 580 cÃ³ 3GB GPU RAM vÃ  tá»‘n 6 ngÃ y Ä‘á»ƒ huáº¥n luyá»‡n.\nKáº¿t quáº£ Äá»™ lá»—i cá»§a AlexNet trÃªn ILSVRC 2010\nTrong cuá»™c thi ILSVRC 2010, AlexNet Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c top-1 error 37.5% vÃ  top-5 error lÃ  17.0%, káº¿t quáº£ nÃ y tá»‘t hÆ¡n vÆ°á»£t trá»™i so vá»›i cÃ¡c cÃ¡ch tiáº¿p cáº­n khÃ¡c.\nÄá»™ lá»—i cá»§a AlexNet trÃªn ILSVRC 2012\nÄáº¿n cuá»™c thi ILSVRC 2012, Ä‘á»™ lá»—i cá»§a AlexNet trÃªn táº­p validation giáº£m cÃ²n 18.2%.\nNáº¿u láº¥y trung bÃ¬nh cá»§a dá»± Ä‘oÃ¡n trÃªn 5 máº¡ng AlexNet Ä‘Æ°á»£c huáº¥n luyá»‡n khÃ¡c nhau, Ä‘á»™ lá»—i giáº£m cÃ²n 16.4%. CÃ¡c láº¥y trung bÃ¬nh trÃªn nhiá»u hÆ¡n 1 máº¡ng CNN lÃ  má»™t ká»¹ thuáº­t boosting vÃ  Ä‘Æ°á»£c sá»­ dá»¥ng trÆ°á»›c Ä‘Ã³ á»Ÿ bÃ i toÃ¡n phÃ¢n loáº¡i sá»‘ cá»§a máº¡ng LeNet.\ná» dÃ²ng sá»‘ 3 lÃ  máº¡ng AlexNet nhÆ°ng Ä‘Æ°á»£c thÃªm 1 convolution layer ná»¯a (nÃªn Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  1CNN*), Ä‘á»™ lá»—i trÃªn táº­p validation giáº£m cÃ²n 16.4%.\nNáº¿u láº¥y káº¿t quáº£ trung bÃ¬nh cá»§a 2 máº¡ng neural net Ä‘Æ°á»£c chá»‰nh sá»­a (thÃªm 1 convolution layer) vÃ  5 máº¡ng AlexNet gá»‘c (=\u0026gt; chÃºng ta cÃ³ 7CNN*), Ä‘á»™ lá»—i trÃªn táº­p validation giáº£m xuá»‘ng 15.4%\nDemo káº¿t quáº£ top-5 cá»§a máº¡ng AlexNet\nMáº¡ng CaffeNet Máº¡ng nÃ y lÃ  phiÃªn báº£n kiáº¿n trÃºc 1-GPU cá»§a AlexNet. Kiáº¿n trÃºc cá»§a máº¡ng caffeNet nhÆ° hÃ¬nh bÃªn dÆ°á»›i:\nMáº¡ng caffeNet\nBáº¡n tháº¥y Ä‘Ã³, thay vÃ¬ cÃ³ 2 pháº§n trÃªn vÃ  dÆ°á»›i nhÆ° mÃ´ Ã¬nh AlexNet á»Ÿ trÃªn, mÃ´ hÃ¬nh CaffeNet chá»‰ cÃ³ 1 pháº§n. VÃ­ dá»¥ lá»›p hidden layer thá»© 7 máº¡ng AlexNet gá»“m 2 pháº§n, má»—i pháº§n cÃ³ kÃ­ch thÆ°á»›c 2048, cÃ²n á»Ÿ phiÃªn báº£n CaffeNet thÃ¬ Ä‘Ã£ gá»™p láº¡i thÃ nh 1 pháº§n.\nTÃ i liá»‡u tham kháº£o\nhttps://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\nhttp://www.image-net.org/challenges/LSVRC/\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, cÃ³ chá»— nÃ o báº¡n chÆ°a rÃµ hoáº·c mÃ¬nh viáº¿t bá»‹ sai, cÃ¡c báº¡n vui lÃ²ng Ä‘á»ƒ láº¡i comment Ä‘á»ƒ mÃ¬nh sá»­a láº¡i cho Ä‘Ãºng.\n","date":"May 27, 2019","img":"","permalink":"/blog/2019-05-27-alexnet/","series":null,"tags":["machine learning","deep learning","AlexNet","ILSVRC","dropout"],"title":"TÃ¬m Hiá»ƒu Máº¡ng AlexNet, MÃ´ HÃ¬nh GiÃ nh Chiáº¿n Tháº¯ng Táº¡i Cuá»™c Thi ILSVRC 2012"},{"categories":null,"content":" Contour lÃ  gÃ¬ Sá»­ dá»¥ng contour trong opencv VÃ­ dá»¥: Äáº¿m sá»‘ lÆ°á»£ng quáº£ bÃ³ng bay trong hÃ¬nh Contour lÃ  gÃ¬ CÃ¡c báº¡n cÃ³ thá»ƒ hiá»ƒu contour lÃ  \u0026ldquo;táº­p cÃ¡c Ä‘iá»ƒm-liÃªn-tá»¥c táº¡o thÃ nh má»™t Ä‘Æ°á»ng cong (curve) (boundary), vÃ  khÃ´ng cÃ³ khoáº£ng há»Ÿ trong Ä‘Æ°á»ng cong Ä‘Ã³, Ä‘áº·c Ä‘iá»ƒm chung trong má»™t contour lÃ  cÃ¡c cÃ¡c Ä‘iá»ƒm cÃ³ cÃ¹ng /gáº§n xáº¥u xá»‰ má»™t giÃ¡ trá»‹ mÃ u, hoáº·c cÃ¹ng máº­t Ä‘á»™. Contour lÃ  má»™t cÃ´ng cá»¥ há»¯u Ã­ch Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ phÃ¢n tÃ­ch hÃ¬nh dáº¡ng Ä‘á»‘i tÆ°á»£ng, phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng vÃ  nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng\u0026rdquo;.\nÄá»ƒ tÃ¬m contour chÃ­nh xÃ¡c, chÃºng ta cáº§n pháº£i nhá»‹ phÃ¢n hÃ³a bá»©c áº£nh (nhá»› lÃ  áº£nh nhá»‹ phÃ¢n nha cÃ¡c báº¡n, khÃ´ng pháº£i áº£nh grayscale Ä‘Ã¢u). CÃ¡c ká»¹ thuáº­t nhá»‹ phÃ¢n hÃ³a áº£nh á»Ÿ xá»­ lÃ½ áº£nh cÆ¡ báº£n cÃ³ thá»ƒ liá»‡t kÃª Ä‘áº¿n lÃ  Ä‘áº·t ngÆ°á»¡ng, hoáº·c candy edge detection. ChÃºng ta sáº½ khÃ´ng bÃ n ká»¹ vá» cÃ¡c cÃ¡ch Ä‘áº·t ngÆ°á»¡ng ( máº·c dÃ¹ cÃ³ khÃ¡ nhiá»u cÃ¡ch Ä‘áº·t ngÆ°á»¡ng, vÃ  trong opencv cÅ©ng cÃ³ implement má»™t vÃ i phÆ°Æ¡ng phÃ¡p, nhÆ°ng nÃ³ khÃ´ng pháº£i lÃ  má»¥c tiÃªu cá»§a bÃ i nÃ y, nÃªn mÃ¬nh khÃ´ng Ä‘á» cáº­p á»Ÿ Ä‘Ã¢y) hoáº·c edge detection á»Ÿ bÃ i viáº¿t nÃ y, mÃ  chÃºng ta sáº½ Ä‘i vÃ o cÃ¡c tÃ¬m contours báº±ng cÃ¡c sá»­ dá»¥ng opencv luÃ´n.\nTrong opencv, viá»‡c tÃ¬m má»™t contour lÃ  viá»‡c tÃ¬m má»™t Ä‘á»‘i tÆ°á»£ng cÃ³ mÃ u tráº¯ng trÃªn ná»n Ä‘en. Cho nÃªn, cÃ¡c báº¡n hÃ£y nhá»› ráº±ng hÃ£y set Ä‘á»‘i tÆ°á»£ng thÃ nh mÃ u tráº¯ng vÃ  Ä‘á»ƒ ná»n lÃ  mÃ u Ä‘en, Ä‘á»«ng lÃ m ngÆ°á»£c láº¡i nha.\nMá»™t lÆ°u Ã½ nhá» lÃ  táº¡i thá»i Ä‘iá»ƒm mÃ¬nh viáº¿t bÃ i viáº¿t nÃ y, mÃ¬nh sá»­ dá»¥ng phiÃªn báº£n opencv3.6. CÃ¡c báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng phiÃªn báº£n opencv má»›i hÆ¡n, nhÆ°ng cÃ³ thá»ƒ nhá»¯ng sample code mÃ¬nh Ä‘á»ƒ bÃªn dÆ°á»›i sáº½ khÃ´ng work, do khÃ´ng tÆ°Æ¡ng thÃ­ch.\nSá»­ dá»¥ng contour trong opencv Opencv há»— trá»£ cho chÃºng ta hÃ m Ä‘á»ƒ tÃ¬m contour cá»§a má»™t bá»©c áº£nh\n1modifiedImage, contours, hierarchy = cv2.findContours(binaryImage, typeofContour, methodofContour) Trong Ä‘Ã³:\ncontours: Danh sÃ¡ch cÃ¡c contour cÃ³ trong bá»©c áº£nh nhá»‹ phÃ¢n. Má»—i má»™t contour Ä‘Æ°á»£c lÆ°u trá»¯ dÆ°á»›i dáº¡ng vector cÃ¡c Ä‘iá»ƒm\nhierarchy: Danh sÃ¡ch cÃ¡c vector, chá»©a má»‘i quan há»‡ giá»¯a cÃ¡c contour.\nmodifiedImage: áº¢nh sau khi sá»­ dá»¥ng contour, thÆ°á»ng chÃºng ta khÃ´ng xÃ i Ä‘á»‘i sá»‘ nÃ y\nbinaryImage: áº¢nh nhá»‹ phÃ¢n gá»‘c. Má»™t chÃº Ã½ quan trá»ng á»Ÿ Ä‘Ã¢y lÃ  sau khi sá»­ dá»¥ng hÃ m findContours thÃ¬ giÃ¡ trá»‹ cá»§a binaryImage cÅ©ng thay Ä‘á»•i theo, nÃªn khi sá»­ dá»¥ng báº¡n cÃ³ thá»ƒ Ã¡p dá»¥ng binaryImage.copy() Ä‘á»ƒ khÃ´ng lÃ m thay Ä‘á»•i giÃ¡ trá»‹ cá»§a binaryImage\ntypeofContour: cÃ³ cÃ¡c dáº¡ng sau: RETR_EXTERNAL, RETR_LIST, RETR_CCOMP, RETR_TREE, RETR_FLOODFILL.\nmethodofContour: CÃ³ cÃ¡c phÆ°Æ¡ng thá»©c sau: CHAIN_APPROX_NONE, CHAIN_APPROX_SIMPLE, CHAIN_APPROX_TC89_L1, CHAIN_APPROX_TC89_KCOS.\nVÃ­ dá»¥ vá» cÃ¡c sá»­ dá»¥ng hÃ m\n1 2import numpy as np 3import cv2 4 5im = cv2.imread(\u0026#39;test.jpg\u0026#39;) # Ä‘á»c áº£nh mÃ u 6imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) # chuyá»ƒn áº£nh mÃ u sang dáº¡ng grayscale 7ret,thresh = cv2.threshold(imgray,127,255,0) # nhá»‹ phÃ¢n hÃ³a bá»©c áº£nh báº±ng cÃ¡ch Ä‘áº·t ngÆ°á»¡ng, vá»›i giÃ¡ trá»‹ cá»§a ngÆ°á»¡ng lÃ  127 8im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) # tÃ¬m contour Opencv há»— trá»£ chÃºng ta hÃ m Ä‘á»ƒ váº½ contor lÃªn bá»©c áº£nh, giÃºp chÃºng ta nhÃ¬n rÃµ rÃ ng hÆ¡n\n1cv2.drawContours(image, contours, contourIndex, colorCode, thickness) Vá»›i:\nimgage: áº£nh, cÃ³ thá»ƒ lÃ  áº£nh grayscale hoáº·c áº£nh mÃ u.\ncontours: danh sÃ¡ch cÃ¡c contour, lÃ  vector, náº¿u báº¡n muá»‘n váº½ má»™t contour, thÃ¬ báº¡n pháº£i cho nÃ³ vÃ o trong má»™t list.\ncontourIndex Vá»‹ trÃ­ cá»§a contor, thÃ´ng thÆ°á»ng chÃºng ta Ä‘á»ƒ -1\ncolorCode: GiÃ¡ trá»‹ mÃ u cá»§a contour chÃºng ta muá»‘n váº½, á»Ÿ dáº¡ng BGR, náº¿u báº¡n muá»‘n váº½ contour mÃ u xanh lÃ¡ cÃ¢y thÃ¬ set lÃ  (0,255,0).\nthickness : Ä‘á»™ dÃ y cá»§a Ä‘Æ°á»ng contour cáº§n váº½, giÃ¡ trá»‹ thickness cÃ ng lá»›n thÃ¬ Ä‘Æ°á»ng contor váº½ cÃ ng bá»±\nVÃ­ dá»¥: Äáº¿m sá»‘ lÆ°á»£ng quáº£ bÃ³ng bay trong hÃ¬nh Giáº£ sá»­ chÃºng ta cÃ³ bá»©c áº£nh Bong bÃ³ng bay\nChÃºng ta thá»±c hiá»‡n tÃ¬m contour cá»§a áº£nh trÃªn báº±ng cÃ¡ch\n1 2import numpy as np 3import cv2 4 5im = cv2.imread(\u0026#39;colorfull_ballon.jpg\u0026#39;) 6imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) # chuyá»ƒn áº£nh xÃ¡m thÃ nh áº£nh grayscale 7thresh = cv2.Canny(imgray, 127, 255) # nhá»‹ phÃ¢n hÃ³a áº£nh 8_, contours, _ = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) 9 10cv2.drawContours(im, contours, -1, (0, 255, 0), 2) # váº½ láº¡i áº£nh contour vÃ o áº£nh gá»‘c 11 12# show áº£nh lÃªn 13cv2.imshow(\u0026#34;ballons\u0026#34;, im) 14cv2.waitKey(0) Káº¿t quáº£:\nContour mÃ u xanh lÃ  Ä‘Æ°á»ng curve bao quanh dá»¯ liá»‡u Ä‘Æ°á»£c rÃºt trÃ­ch Ä‘Æ°á»£c\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ nhá»¯ng bÃ i viáº¿t tiáº¿p theo.\n","date":"May 26, 2019","img":"","permalink":"/blog/2019-05-26-contours/","series":null,"tags":["Machine Learning","Deep Learning","Opencv","Image Processing"],"title":"Contour"},{"categories":null,"content":" Chi tiáº¿t vá» máº¡ng MobileNet MÃ´ hÃ¬nh kiáº¿n trÃºc Depthwise Separable Convolution LÃ m mÃ´ hÃ¬nh gá»n nháº¹ hÆ¡n ná»¯a So sÃ¡nh MobileNet vá»›i cÃ¡c State-of-the-art Ä‘Æ°Æ¡ng thá»i Káº¿t luáº­n Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ tÃ¬m hiá»ƒu mÃ´ hÃ¬nh MobileNetV1 tá»« nhÃ³m tÃ¡c giáº£ Ä‘áº¿n tá»« Google. Äiá»ƒm cáº£i tiáº¿n (cháº¯c lÃ  cáº£i tiáº¿n :) cá»§a mÃ´ hÃ¬nh lÃ  sá»­ dá»¥ng má»™t cÃ¡ch tÃ­nh tÃ­ch cháº­p cÃ³ tÃªn lÃ  Depthwise Separable Convolution Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh vÃ  giáº£m Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n. Do Ä‘Ã³, mÃ´ hÃ¬nh sáº½ há»¯u Ã­ch khi cháº¡y cÃ¡c á»©ng dá»¥ng trÃªn di Ä‘á»™ng vÃ  cÃ¡c thiáº¿t bá»‹ nhÃºng.\nLÃ½ do:\nMÃ´ hÃ¬nh cÃ³ Ã­t tham sá»‘ hÆ¡n -\u0026gt; kÃ­ch thÆ°á»›c model sáº½ nhá» hÆ¡n.\nMÃ´ hÃ¬nh cÃ³ Ã­t phÃ©p tÃ­nh cá»™ng trá»« nhÃ¢n chia hÆ¡n -\u0026gt; Ä‘á»™ phá»©c táº¡p sáº½ nhá» hÆ¡n.\nHiá»‡n táº¡i (2019-05-26), táº¡i thá»i Ä‘iá»ƒm viáº¿t bÃ i, bÃ i viáº¿t gá»‘c cá»§a tÃ¡c giáº£ Ä‘Ã£ Ä‘Æ°á»£c 1594 lÆ°á»£t trÃ­ch dáº«n. CÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m Ä‘á»c bÃ i bÃ¡o gá»‘c cá»§a tÃ¡c giáº£ táº¡i trang https://arxiv.org/abs/1704.04861\nSá»‘ lÆ°á»£t trÃ­ch dáº«n bÃ i bÃ¡o MobileNets Efficient Convolutional Neural Networks for Mobile Vision Applications\nChi tiáº¿t vá» máº¡ng MobileNet MÃ´ hÃ¬nh kiáº¿n trÃºc Kiáº¿n trÃºc máº¡ng MobileNet Ä‘Æ°á»£c trÃ¬nh bÃ y bÃªn dÆ°á»›i. HÃ¬nh bÃªn dÆ°á»›i Ä‘Æ°á»£c trÃ­ch tá»« bÃ i bÃ¡o gá»‘c cá»§a tÃ¡c giáº£\nMÃ´ hÃ¬nh kiáº¿n trÃºc máº¡ng MobileNet\nDiá»…n dá»‹ch ra ngÃ´n ngá»¯ tá»± nhiÃªn, chÃºng ta tháº¥y ráº±ng mÃ´ hÃ¬nh cÃ³ 30 lá»›p vá»›i cÃ¡c Ä‘áº·c Ä‘iá»ƒm sau:\nLá»›p 1: Convolution layer vá»›i stride báº±ng 2\nLá»›p 2: Depthwise layer\nLá»›p 3: Pointwise layer\nLá»›p 4: Depthwise layer vá»›i stride báº±ng 2 (khÃ¡c vá»›i bÆ°á»›c 2, dw lá»›p 2 cÃ³ stride size báº±ng 1)\nLá»›p 5: Pointwise layer\nLá»›p 30: Softmax, dÃ¹ng Ä‘á»ƒ phÃ¢n lá»›p.\nDepthwise Separable Convolution Depthwise separable convolution lÃ  má»™t depthwise convolution theo sau bá»Ÿi má»™t pointwise convolution nhÆ° hÃ¬nh bÃªn dÆ°á»›i:\nCáº¥u trÃºc cá»§a má»™t Depthwise Separable Convolution\nDepthwise convolution: lÃ  má»™t channel-wise DKÃ—DK spatial convolution. VÃ­ dá»¥ á»Ÿ hÃ¬nh trÃªn, ta cÃ³ 5 channels (cÃ¡c báº¡n Ä‘á»ƒ Ã½ cá»¥c Ä‘áº§u tiÃªn cÃ³ 5 khá»‘i há»™p, cá»¥c thá»© 2 lÃ  phÃ¢n tÃ¡ch 5 khá»‘i há»™p ra thÃ nh ma tráº­n mxn, cá»¥c thá»© 3 lÃ  spatial convolution cÃ³ kÃ­ch thÆ°á»›c kxk, cá»¥c thá»© 4 lÃ  káº¿t quáº£ sau khi convolution, cá»¥c thá»© 5 lÃ  rÃ¡p 5 cÃ¡i káº¿t quáº£ cá»§a convolution láº¡i ), do Ä‘Ã³ chÃºng ta sáº½ cÃ³ 5 DKÃ—DK spatial convolution tÆ°Æ¡ng á»©ng vá»›i 5 channel trÃªn.\nPointwise convolution: Ä‘Æ¡n giáº£n lÃ  má»™t convolution cÃ³ kÃ­ch thÆ°á»›c 1x1 (nhÆ° hÃ¬nh á»Ÿ trÃªn).\nVá»›i M lÃ  sá»‘ lÆ°á»£ng input channel, N lÃ  sá»‘ lÆ°á»£ng output channel, Dk lÃ  kernel size, Df lÃ  feature map size (vá»›i dataset ImageNet thÃ¬ input cÃ³ kÃ­ch thÆ°á»›c lÃ  224, do Ä‘Ã³ feature map ban Ä‘áº§u cÃ³ Df = 224), chÃºng ta cÃ³ thá»ƒ tÃ­nh Ä‘Æ°á»£c:\nChi phÃ­ tÃ­nh toÃ¡n cá»§a Depthwise convolution lÃ  :\n$$D_k \\cdot D_k \\cdot M \\cdot D_f \\cdot D_f$$\nChi phÃ­ tÃ­nh toÃ¡n cá»§a Pointwise convolution lÃ  :\n$$M \\cdot N \\cdot D_f \\cdot D_f$$\nTá»•ng chi phÃ­ tÃ­nh toÃ¡n cá»§a Depthwise Separable Convolution lÃ :\n$$D_k \\cdot D_k \\cdot M \\cdot D_f \\cdot D_f + M \\cdot N \\cdot D_f \\cdot D_f$$\nNáº¿u chÃºng ta khÃ´ng sá»­ dá»¥ng Depthwise Separable Convolution mÃ  sá»­ dá»¥ng phÃ©p convolution nhÆ° bÃ¬nh thÆ°á»ng, chi phÃ­ tÃ­nh toÃ¡n lÃ \n$$ D_k \\cdot D_k \\cdot M \\cdot N \\cdot D_f \\cdot D_f$$\nDo Ä‘Ã³, chi phÃ­ tÃ­nh toÃ¡n sáº½ giáº£m:\n$$\\frac{D_k \\cdot D_k \\cdot M \\cdot D_f \\cdot D_f + M \\cdot N \\dot D_f \\cdot D_f}{D_k \\cdot D_k \\cdot M \\cdot N \\cdot D_f \\cdot D_f} = \\frac{1}{N} + \\frac{1}{D^2_k}$$\nGiáº£ sá»­, chÃºng ta chá»n kernel size Dk = 3, chÃºng ta sáº½ giáº£m tá»« 8 Ä‘áº¿n 9 láº§n phÃ©p tÃ­nh nhÃ¢n =\u0026gt; giáº£m chi phÃ­ tÃ­nh toÃ¡n Ä‘i ráº¥t nhiá»u.\nMá»™t chÃº Ã½ nhá» vá» kiáº¿n trÃºc á»Ÿ Ä‘Ã¢y, lÃ  sau má»—i convolution MobileNet sáº½ sá»­ dá»¥ng Batch Normalization (BN) vÃ  ReLU nhÆ° hÃ¬nh bÃªn dÆ°á»›i:\nStandard Convolution bÃªn trÃ¡i, Depthwise separable convolution vá»›i BN vÃ  ReLU bÃªn pháº£i\nSo sÃ¡nh káº¿t quáº£ cá»§a viá»‡c sá»­ dá»¥ng máº¡ng 30 layer sá»­ dá»¥ng thuáº§n Convolution vÃ  máº¡ng 30 layer sá»­ dá»¥ng Depthwise Separable Convolution (MobileNet) trÃªn táº­p dá»¯ liá»‡u ImageNet, chÃºng ta cÃ³ báº£ng káº¿t quáº£ bÃªn dÆ°á»›i\nStandard Convolution bÃªn trÃ¡i, Depthwise separable convolution vá»›i BN vÃ  ReLU bÃªn pháº£i\nMobileNet giáº£m 1% Ä‘á»™ chÃ­nh xÃ¡c, nhÆ°ng sá»‘ lÆ°á»£ng tham sá»‘ cá»§a mÃ´ hÃ¬nh vÃ  sá»‘ lÆ°á»£ng phÃ©p tÃ­nh toÃ¡n giáº£m Ä‘i ráº¥t ráº¥t nhiá»u, gáº§n xáº¥p xá»‰ 90%. Má»™t con sá»‘ Ä‘Ã¡ng kinh ngáº¡c.\nLÃ m mÃ´ hÃ¬nh gá»n nháº¹ hÆ¡n ná»¯a Vá»›i mong muá»‘n lÃ m mÃ´ hÃ¬nh gá»n nháº¹ hÆ¡n ná»¯a, nhÃ³m tÃ¡c giáº£ Ä‘Ã£ thÃªm vÃ o hai tham sá»‘ alpha vÃ  rho.\nTham sá»‘ alpha: Äiá»u khiá»ƒn sá»‘ lÆ°á»£ng channel (M vÃ  N).\nChi phÃ­ tÃ­nh toÃ¡n cá»§a depthwise separable convolution khi sá»­ dá»¥ng thÃªm tham sá»‘ alpha.\n$$D_k \\cdot D_k \\cdot \\alpha M \\cdot D_f \\cdot D_f + \\alpha M \\cdot \\alpha N \\cdot D_f \\cdot D_f$$\nGiÃ¡ trá»‹ alpha náº±m trong Ä‘oáº¡n [0,1], nhÃ³m tÃ¡c giáº£ set giÃ¡ trá»‹ alpha cÃ³ bÆ°á»›c nháº£y lÃ  0.25, cÃ¡c giÃ¡ trá»‹ cáº§n xÃ©t lÃ  0.25, 0.5, 0.75, 1. TrÆ°á»ng há»£p alpha = 1 chÃ­nh lÃ  máº¡ng MobileNet baseline cá»§a mÃ¬nh. Trong trÆ°á»ng há»£p thay Ä‘á»•i alpha, sá»‘ phÃ©p tÃ­nh toÃ¡n, sá»‘ tham sá»‘, cÅ©ng giáº£m Ä‘i ráº¥t nhiá»u, vÃ  táº¥t nhiÃªn, Ä‘á»™ chÃ­nh xÃ¡c cÅ©ng giáº£m Ä‘i tÆ°Æ¡ng á»©ng.\nMáº¡ng MobileNet vá»›i alpha thay Ä‘á»•i\nPhÃ¢n tÃ­ch ká»¹ hÃ¬nh á»Ÿ trÃªn, ta tháº¥y ráº±ng vá»›i alpha báº±ng 0.75 vÃ  0.5 giÃ¡ trá»‹ Ä‘á»™ chÃ­nh xÃ¡c cÃ²n náº±m á»Ÿ má»©c miá»…n cÆ°á»¡ng cÃ³ thá»ƒ cháº¥p nháº­n Ä‘Æ°á»£c. NhÆ°ng vá»›i alpha báº±ng 0.25 thÃ¬ khÃ³ mÃ  cÃ³ thá»ƒ cháº¥p nháº­n Ä‘Æ°á»£c káº¿t quáº£ Ä‘Ã³. Viá»‡c giáº£m phÃ©p tÃ­nh toÃ¡n vÃ  sá»‘ lÆ°á»£ng tham sá»‘ dáº«n Ä‘áº¿n káº¿t quáº£ tá»‡ nhÆ° trÃªn quáº£ lÃ  má»™t Ä‘iá»u khÃ´ng nÃªn. MÃ¬nh nghÄ© á»Ÿ Ä‘Ã¢y nhÃ³m tÃ¡c giáº£ Ä‘á»ƒ con sá»‘ Ä‘á»ƒ cÃ³ Ã½ nghÄ©a so sÃ¡nh.\nTham sá»‘ rho: Tham sá»‘ nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘iá»u khiá»ƒn Ä‘á»™ phÃ¢n giáº£i cá»§a áº£nh input.\nChi phÃ­ tÃ­nh toÃ¡n cá»§a depthwise separable convolution khi sá»­ dá»¥ng thÃªm tham sá»‘ rho.\n$$D_k \\cdot D_k \\cdot \\alpha M \\cdot \\rho D_f \\cdot \\rho D_f + \\alpha M \\cdot \\alpha N \\cdot \\rho D_f \\cdot \\rho D_f$$\nGiÃ¡ trá»‹ rho cÅ©ng náº±m trong Ä‘oáº¡n [0,1]. NhÃ³m tÃ¡c giáº£ sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ Ä‘á»™ phÃ¢n giáº£i lÃ  224 (Ä‘á»™ phÃ¢n giáº£i gá»‘c, tÆ°Æ¡ng á»©ng vá»›i rho =1), 192, 160, 128.\nMáº¡ng MobileNet vá»›i rho thay Ä‘á»•i\nGiÃ¡ trá»‹ Ä‘á»™ chÃ­nh xÃ¡c thay Ä‘á»•i theo hÆ°á»›ng giáº£m khÃ¡ mÆ°á»£t. Viá»‡c thay Ä‘á»•i rho chá»‰ lÃ m giáº£m sá»‘ lÆ°á»£ng phÃ©p tÃ­nh toÃ¡n, khÃ´ng lÃ m giáº£m sá»‘ lÆ°á»£ng tham sá»‘. Viá»‡c giáº£m Ä‘á»™ chÃ­nh xÃ¡c cÃ³ thá»ƒ lÃ½ giáº£i lÃ½ do lÃ  cÃ³ má»™t sá»‘ hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c nhá» nÃªn khi giáº£m kÃ­ch thÆ°á»›c sáº½ lÃ m máº¥t nhá»¯ng Ä‘áº·c trÆ°ng cáº§n thiáº¿t cá»§a Ä‘á»‘i tÆ°á»£ng cáº§n xÃ©t.\nSo sÃ¡nh MobileNet vá»›i cÃ¡c State-of-the-art Ä‘Æ°Æ¡ng thá»i Khi so sÃ¡nh 1.0 MobileNet-224 vá»›i GoogleNet vÃ  VGG 16 (hÃ¬nh bÃªn dÆ°á»›i), chÃºng ta tháº¥y ráº±ng Ä‘á»™ chÃ­nh xÃ¡c cá»§a cáº£ 3 thuáº­t toÃ¡n lÃ  háº§u nhÆ° tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhau. NhÆ°ng 1.0 MobileNet-224 cÃ³ sá»‘ lÆ°á»£ng tham sá»‘ Ã­t (75% so vá»›i GoogleNet) vÃ  sá»‘ lÆ°á»£ng phÃ©p toÃ¡n nhá» hÆ¡n ráº¥t nhiá»u =\u0026gt; cháº¡y nhanh hÆ¡n.\nSo sÃ¡nh 1.0 MobileNet-224 vá»›i GoogleNet vÃ  VGG 16 trÃªn táº­p ImageNet\nVá»›i mÃ´ hÃ¬nh 0.50 MobileNet-160, chÃºng ta cÃ³ thá»ƒ so sÃ¡nh vá»›i mÃ´ hÃ¬nh Squeezenet vÃ  AlexNet (mÃ´ hÃ¬nh tháº¯ng giáº£i nháº¥t cuá»™c thi ILSVRC 2012). Má»™t láº§n ná»¯a, mÃ´ hÃ¬nh 0.50 MobileNet-160 cho káº¿t quáº£ tá»‘t hÆ¡n, nhÆ°ng cÃ³ sá»‘ lÆ°á»£ng phÃ©p tÃ­nh toÃ¡n Ã­t hÆ¡n ráº¥t nhiá»u (hÆ¡i Ä‘Ã¡ng buá»“n lÃ  sá»‘ lÆ°á»£ng tham sá»‘ cá»§a mÃ´ hÃ¬nh 0.50 MobileNet-160 khÃ¡ cao, sá»‘ lÆ°á»£ng tham sá»‘ gáº¥p Ä‘Ã´i so vá»›i AlexNet vÃ  gáº§n báº±ng Squeezenet) =\u0026gt; 0.50 MobileNet-160 train nhanh hÆ¡n, predict cÅ©ng nhanh hÆ¡n so vá»›i Squeezenet vÃ  AlexNet, nhÆ°ng tá»‘n bá»™ nhá»› RAM hÆ¡n.\nSo sÃ¡nh 0.50 MobileNet-160 vá»›i Squeezenet vÃ  AlexNet trÃªn táº­p ImageNet\nSo vá»›i mÃ´ hÃ¬nh Inception-v3 (mÃ´ hÃ¬nh tháº¯ng giáº£i nháº¥t cuá»™c thi ILSVRC 2015), MobileNet cho káº¿t quáº£ khÃ¡ tá»‘t, nhÆ°ng sá»‘ tham sá»‘ vÃ  sá»‘ lÆ°á»£ng phÃ©p tÃ­nh toÃ¡n nhá» hÆ¡n ráº¥t nhiá»u\nSo sÃ¡nh Mobile net vÃ  Inception-v3 trÃªn táº­p Stanford Dog\nCÃ¡c thÃ­ nghiá»‡m á»Ÿ dÆ°á»›i trÃªn cÃ¡c táº­p dataset khÃ¡c nhau chá»©ng minh má»©c Ä‘á»™ hiá»‡u quáº£ cá»§a MobileNet GPS Localization Via Photos\nFace Attribute Classification\nMMicrosoft COCO Object Detection Dataset\nFace Recognition\nKáº¿t luáº­n MobileNet cho káº¿t quáº£ tá»‘t ngang ngá»¯a cÃ¡c state-of-the-art tháº¯ng giáº£i nháº¥t á»Ÿ quÃ¡ khá»©, nhÆ°ng vá»›i mÃ´ hÃ¬nh cÃ³ sá»‘ lÆ°á»£ng tham sá»‘ nhá» hÆ¡n vÃ  sá»‘ phÃ©p tÃ­nh toÃ¡n Ã­t hÆ¡n. Äiá»u nÃ y Ä‘áº¡t Ä‘Æ°á»£c lÃ  nhá» vÃ o viá»‡c sá»­ dá»¥ng Depthwise Separable Convolution.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t, cÃ³ chá»— nÃ o báº¡n chÆ°a rÃµ hoáº·c mÃ¬nh viáº¿t bá»‹ sai, cÃ¡c báº¡n vui lÃ²ng Ä‘á»ƒ láº¡i comment Ä‘á»ƒ mÃ¬nh sá»­a láº¡i cho Ä‘Ãºng.\n","date":"May 25, 2019","img":"","permalink":"/blog/2019-05-26-mobilenetv1/","series":null,"tags":["machine learning","deep learning","MobileNetV1","Depthwise Separable Convolution","Light Weight Model","Width Multiplier","Resolution Multiplier"],"title":"TÃ¬m Hiá»ƒu Máº¡ng MobileNetV1"},{"categories":null,"content":" 1. Táº¡o chÆ°Æ¡ng trÃ¬nh Ä‘áº§u tiÃªn báº±ng PredictionIO 1. Táº¡o chÆ°Æ¡ng trÃ¬nh Ä‘áº§u tiÃªn báº±ng PredictionIO Äáº§u tiÃªn, cÃ¡c báº¡n hÃ£y táº¡o thÆ° má»¥c template á»Ÿ Ä‘Ã¢u Ä‘Ã³. MÃ¬nh sáº½ táº¡o á»Ÿ trong thÆ° má»¥c /data/pio. ÄÆ°á»ng dáº«n cá»§a mÃ¬nh sáº½ lÃ  /data/pio/template\n1mdkir /data/pio/template Tiáº¿p theo, chÃºng ta sáº½ clone templte trÃªn github vá», cÃ¡c báº¡n thá»±c hiá»‡n lá»‡nh sau\n1git clone https://github.com/apache/predictionio-template-recommender.git 2cd predictionio-template-recommender Tiáº¿p theo, chÃºng ta sáº½ táº¡o má»™t app Ä‘áº§u tiÃªn, mÃ¬nh Ä‘áº·t tÃªn lÃ  ourrecommendation, cÃ¡c báº¡n thÃ­ch Ä‘áº·t tÃªn gÃ¬ thÃ¬ Ä‘áº·t nha.\n1pio app new ourrecommendation Äá»ƒ liá»‡t kÃª danh sÃ¡ch app Ä‘ang cÃ³ trong há»‡ thá»‘ng, cÃ¡c báº¡n dÃ¹ng lá»‡nh\n1pio app list Káº¿t quáº£ trong mÃ¡y mÃ¬nh táº¡i thá»i Ä‘iá»ƒm viáº¿t bÃ i lÃ \n1[INFO] [Pio$] Name | ID | Access Key | Allowed Event(s) 2[INFO] [Pio$] ourrecommendation | 1 | Z93rJZ7Xq2pXiQwVC6B5nRK6jRykcfyMI5huOijKbdDJeUeKEnVT-ph5nabptIX1 | (all) 3[INFO] [Pio$] Finished listing 1 app(s). MÃ¬nh má»›i táº¡o app Ä‘áº§u tiÃªn tÃªn lÃ  ourrecommendation nÃªn chá»‰ cÃ³ 1 app trong há»‡ thá»‘ng. Sau nÃ y sáº½ cÃ³ nhiá»u hÆ¡n. Ã€, sau khi táº¡o app, thÃ¬ há»‡ thá»‘ng sáº½ generate tá»± Ä‘á»™ng cho app vá»›i má»™t Access Key, vÃ­ dá»¥ access key cá»§a app ourrecommendateion cá»§a mÃ¬nh lÃ  Z93rJZ7Xq2pXiQwVC6B5nRK6jRykcfyMI5huOijKbdDJeUeKEnVT-ph5nabptIX1. CÃ¡c báº¡n sáº½ cÃ³ access key khÃ¡c vá»›i access key cá»§a mÃ¬nh, nÃªn Ä‘á»«ng copy cá»§a mÃ¬nh vá» lÃ m gÃ¬ háº¿t :).\nSau khi khá»Ÿi táº¡o app xong, chÃºng ta sáº½ import data vÃ o há»‡ thá»‘ng. á» Ä‘Ã¢y, mÃ¬nh sáº½ download dá»¯ liá»‡u máº«u tá»« nguá»“n https://gist.githubusercontent.com/vaghawan/0a5fb8ddb85e03631dd500d7c8f0677d/raw/17487437dd8269588d9dd1ac859b129a43842ba5/data-sample.json. Sau khi download vá» cÃ¡c báº¡n import dá»¯ liá»‡u vÃ o há»‡ thá»‘ng báº±ng lá»‡nh\n1pio import â€” appid 1 â€” input data-sample.json Vá»›i appod 1 lÃ  id cá»§a ourrecommendation chÃºng ta vá»«a má»›i táº¡o. Náº¿u quÃªn appid, cÃ¡c báº¡n cÃ³ thá»ƒ xem láº¡i báº±ng lá»‡nh pio app list.\nSau khi import thÃ nh cÃ´ng, chÃºng ta sáº½ thay Ä‘á»•i giÃ¡ trá»‹ cá»§a trÆ°á»ng appname trong file engine.json thÃ nh tÃªn cá»§a app mÃ¬nh, lÃ  ourrecommendation\n1nano engine.json 2 3{ 4 \u0026#34;id\u0026#34;: \u0026#34;default\u0026#34;, 5 \u0026#34;description\u0026#34;: \u0026#34;Default settings\u0026#34;, 6 \u0026#34;engineFactory\u0026#34;: \u0026#34;org.example.recommendation.RecommendationEngine\u0026#34;, 7 \u0026#34;datasource\u0026#34;: { 8 \u0026#34;params\u0026#34; : { 9 \u0026#34;appName\u0026#34;: \u0026#34;ourrecommendation\u0026#34; 10 } 11 }, 12 \u0026#34;algorithms\u0026#34;: [ 13 { 14 \u0026#34;name\u0026#34;: \u0026#34;als\u0026#34;, 15 \u0026#34;params\u0026#34;: { 16 \u0026#34;rank\u0026#34;: 10, 17 \u0026#34;numIterations\u0026#34;: 20, 18 \u0026#34;lambda\u0026#34;: 0.01, 19 \u0026#34;seed\u0026#34;: 3 20 } 21 } 22 ] 23} Má»™t lÆ°u Ã½ quang trá»ng lÃ  giÃ¡ trá»‹ \u0026ldquo;org.example.recommendation.RecommendationEngine\u0026rdquo; trong \u0026ldquo;engineFactory\u0026rdquo; lÃ  cá»§a há»‡ thá»‘ng. VÃ  báº¡n Ä‘á»«ng sá»­a, thay Ä‘á»•i chÃºng. NÃ³i chung lÃ  ngoÃ i giÃ¡ trá»‹ cá»§a \u0026ldquo;appName\u0026rdquo; ra, báº¡n khÃ´ng nÃªn thay Ä‘á»•i báº¥t ká»³ thá»©c gÃ¬ khÃ¡c trong file engine.json.\nSau khi import file thÃ nh cÃ´ng. ChÃºng ta sáº½ build app. Lá»‡nh build cÃ³ tÃ¡c dá»¥ng kiá»ƒm tra láº¡i há»‡ thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘Ãºng vÃ  Ä‘á»§ chÆ°a.\n1pio build Náº¿u build thÃ nh cÃ´ng, chÃºng ta sáº½ tháº¥y dÃ²ng chá»¯ nÃ y.\n1 2[INFO] [Engine$] Build finished successfully. 3[INFO] [Pio$] Your engine is ready for training. Sau khi build thÃ nh cÃ´ng, chÃºng ta sáº½ tiáº¿n hÃ nh huáº¥n luyá»‡n mÃ´ hÃ¬nh\n1pio build VÃ  chá» Ä‘á»£i dÃ²ng nÃ y xuáº¥t hiá»‡n\n1 2[INFO] [CoreWorkflow$] Training completed successfully. Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ nhá»¯ng bÃ i viáº¿t tiáº¿p theo.\n","date":"May 7, 2019","img":"","permalink":"/blog/2019-05-07-predictio-mini-demo/","series":null,"tags":["Machine Learning","Deep Learning","PredictionIO","Forecast"],"title":"PredictionIO Pháº§n 2 - CÃ i Äáº·t ChÆ°Æ¡ng TrÃ¬nh Demo"},{"categories":null,"content":" 1. Dropout lÃ  gÃ¬, nÃ³ cÃ³ Ã½ nghÄ©a gÃ¬ trong máº¡ng neural network 2. Táº¡o sao chÃºng ta cáº§n dropout 3. Dropout 4. Má»™t sá»‘ Ä‘áº·c Ä‘iá»ƒm rÃºt ra Ä‘Æ°á»£c khi huáº¥n luyá»‡n nhiá»u mÃ´ hÃ¬nh khÃ¡c nhau sá»­ dá»¥ng dropout 5. Thá»±c nghiá»‡m trong keras 1. Dropout lÃ  gÃ¬, nÃ³ cÃ³ Ã½ nghÄ©a gÃ¬ trong máº¡ng neural network Theo Wikipedia, thuáº­t ngá»¯ \u0026ldquo;dropout\u0026rdquo; Ä‘á» cáº­p Ä‘áº¿n viá»‡c bá» qua cÃ¡c Ä‘Æ¡n vá»‹ (unit) (cáº£ hai hidden unit vÃ  visible unit) trong máº¡ng neural network.\nHiá»ƒu Ä‘Æ¡n giáº£n lÃ , trong máº¡ng neural network, ká»¹ thuáº­t dropout lÃ  viá»‡c chÃºng ta sáº½ bá» qua má»™t vÃ i unit trong suá»‘t quÃ¡ trÃ¬nh train trong mÃ´ hÃ¬nh, nhá»¯ng unit bá»‹ bá» qua Ä‘Æ°á»£c lá»±a chá»n ngáº«u nhiÃªn. á» Ä‘Ã¢y, chÃºng ta hiá»ƒu \u0026ldquo;bá» qua - ignoring\u0026rdquo; lÃ  unit Ä‘Ã³ sáº½ khÃ´ng tham gia vÃ  Ä‘Ã³ng gÃ³p vÃ o quÃ¡ trÃ¬nh huáº¥n luyá»‡n (lan truyá»n tiáº¿n vÃ  lan truyá»n ngÆ°á»£c).\nVá» máº·t ká»¹ thuáº­t, táº¡i má»—i giai Ä‘oáº¡n huáº¥n luyá»‡n, má»—i node cÃ³ xÃ¡c suáº¥t bá»‹ bá» qua lÃ  1-p vÃ  xÃ¡c suáº¥t Ä‘Æ°á»£c chá»n lÃ  p\n2. Táº¡o sao chÃºng ta cáº§n dropout Giáº£ sá»­ ráº±ng báº¡n hiá»ƒu hoÃ n toÃ n nhá»¯ng gÃ¬ Ä‘Ã£ nÃ³i á»Ÿ pháº§n 1, cÃ¢u há»i Ä‘áº·t ra lÃ  táº¡i sao chÃºng ta cáº§n Ä‘áº¿n dropout, táº¡i sao chÃºng ta cáº§n pháº£i loáº¡i bá» má»™t vÃ i cÃ¡c unit nÃ o Ä‘Ã³ trong máº¡ng neural network?\nCÃ¢u tráº£ lá»i cho cÃ¢u há»i nÃ y lÃ  Ä‘á»ƒ chá»‘ng over-fitting\nKhi chÃºng ta sá»­ dá»¥ng full connected layer, cÃ¡c neural sáº½ phá»¥ thuá»™c \u0026ldquo;máº¡nh\u0026rdquo; láº«n nhau trong suá»‘t quÃ¡ trÃ¬nh huáº¥n luyá»‡n, Ä‘iá»u nÃ y lÃ m giáº£m sá»©c máº¡ng cho má»—i neural vÃ  dáº«n Ä‘áº¿n bá»‹ over-fitting táº­p train.\n3. Dropout Äá»c Ä‘áº¿n Ä‘Ã¢y, báº¡n Ä‘Ã£ cÃ³ má»™t khÃ¡i niá»‡m cÆ¡ báº£n vá» dropout vÃ  Ä‘á»™ng lá»±c - Ä‘á»™ng cÆ¡ Ä‘á»ƒ chÃºng ta sá»­ dá»¥ng nÃ³. Náº¿u báº¡n chá»‰ muá»‘n cÃ³ cÃ¡i nhÃ¬n tá»•ng quan vá» dropout trong neural network, hai sections trÃªn Ä‘Ã£ cung cáº¥p Ä‘áº§y Ä‘á»§ thÃ´ng tin cho báº¡n, báº¡n cÃ³ thá»ƒ dá»«ng táº¡i Ä‘Ã¢y. Pháº§n tiáº¿p theo, chÃºng ta sáº½ nÃ³i ká»¹ hÆ¡n vá» máº·t ká»¹ thuáº­t cá»§a dropout.\nTrÆ°á»›c Ä‘Ã¢y, trong machine learning, ngÆ°á»i ta thÆ°á»ng sá»­ dá»¥ng regularization Ä‘á»ƒ ngÄƒng cháº·n over-fititng. Regularization lÃ m giáº£m over-fitting báº±ng cÃ¡ch thÃªm yáº¿u tá»‘ \u0026ldquo;pháº¡t\u0026rdquo; vÃ o hÃ m Ä‘á»™ lá»—i (loss function). Báº±ng viá»‡c thÃªm vÃ o Ä‘iá»ƒm pháº¡t nÃ y, mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n sáº½ giÃºp cÃ¡c features weights giáº£m Ä‘i sá»± phá»¥ thuá»™c láº«n nhau. Äá»‘i vá»›i nhá»¯ng ai Ä‘Ã£ sá»­ dá»¥ng Logistic Regression rá»“i thÃ¬ sáº½ khÃ´ng xa láº¡ vá»›i thuáº­t ngá»¯ pháº¡t L1(Laplacian) vÃ  L2 (Gaussian).\nDropout lÃ  má»™t ká»¹ thuáº­t khÃ¡c, má»™t cÃ¡ch tiáº¿p cáº­n khÃ¡c Ä‘á»ƒ regularization trong máº¡ng neural netwoks.\nKá»¹ thuáº­t dropout Ä‘Æ°á»£c thá»±c hiá»‡n nhÆ° sau:\nTrong pha train: vá»›i má»—i hidden layer, vá»›i má»—i trainning sample, vá»›i má»—i láº§n láº·p, chá»n ngáº«u nhiÃªn p pháº§n trÄƒm sá»‘ node vÃ  bá» qua nÃ³ (bá» qua luÃ´n hÃ m kÃ­ch hoáº¡t cho cÃ¡c node bá»‹ bá» qua).\nTrong pha test: Sá»­ dá»¥ng toÃ n bá»™ activations, nhÆ°ng giáº£m chÃºng vá»›i tá»· lá»‡ p (do chÃºng ta bá»‹ miss p% hÃ m activation trong quÃ¡ trÃ¬nh train).\nMÃ´ táº£ vá» kiáº¿n trÃºc máº¡ng cÃ³ vÃ  khÃ´ng cÃ³ dropout\n4. Má»™t sá»‘ Ä‘áº·c Ä‘iá»ƒm rÃºt ra Ä‘Æ°á»£c khi huáº¥n luyá»‡n nhiá»u mÃ´ hÃ¬nh khÃ¡c nhau sá»­ dá»¥ng dropout Dropout Ã©p máº¡ng neural pháº£i tÃ¬m ra nhiá»u robust features hÆ¡n, vá»›i Ä‘áº·c Ä‘iá»ƒm lÃ  chÃºng pháº£i há»¯u Ã­ch hÆ¡n, tá»‘t hÆ¡n, ngon hÆ¡n khi káº¿t há»£p vá»›i nhiá»u neuron khÃ¡c.\nDropout Ä‘Ã²i há»i pháº£i gáº¥p Ä‘Ã´i quÃ¡ trÃ¬nh huáº¥n luyá»‡n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± há»™i tá»¥. Tuy nhiÃªn, thá»i gian huáº¥n luyá»‡n cho má»—i epoch sáº½ Ã­t hÆ¡n.\nVá»›i H unit trong mÃ´ hÃ¬nh, má»—i unit Ä‘á»u cÃ³ xÃ¡c xuáº¥t bá»‹ bá» qua hoáº·c Ä‘Æ°á»£c chá»n, chÃºng ta sáº½ cÃ³ 2^H mÃ´ hÃ¬nh cÃ³ thá»ƒ cÃ³. Trong pha test, toÃ n bá»™ network Ä‘Æ°á»£c sá»­ dá»¥ng vÃ  má»—i hÃ m activation Ä‘Æ°á»£c giáº£m Ä‘i vá»›i há»‡ sá»‘ p.\nMá»™t sá»‘ nghiÃªn cá»©u chá»‰ ra ráº±ng, khi sá»­ dá»¥ng Dropout vÃ  Batch Normalization (BN) cÃ¹ng nhau thÃ¬ káº¿t quáº£ ráº¥t tá»‡, trong cáº£ lÃ½ thuyáº¿t vÃ  thá»±c nghiá»‡m, vÃ­ dá»¥ nghiÃªn cá»©u á»Ÿ papper \u0026ldquo;Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift\u0026rdquo;, nguá»“n https://arxiv.org/abs/1801.05134, nhÃ³m tÃ¡c giáº£ giáº£i thÃ­ch vá» máº·t lÃ½ thuyáº¿t ráº±ng: \u0026ldquo;Ä‘á»‘i vá»›i má»™t neural, Dropout sáº½ thay Ä‘á»•i phÆ°Æ¡ng sai cá»§a nÃ³ khi chÃºng ta chuyá»ƒn tráº¡ng thÃ¡i tá»« trian sang test. CÃ²n BN thÃ¬ khÃ´ng, BN váº«n tÃ­ch luá»¹ Ä‘áº§y Ä‘á»§ thÃ´ng tin trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Do Dropout lÃ m thay Ä‘á»•i phÆ°Æ¡ng sai nÃªn sáº½ xáº£y ra hiá»‡n tÆ°á»£ng khÃ´ng Ä‘á»“ng nháº¥t vá» phÆ°Æ¡ng sai, dáº«n Ä‘áº¿n hÃ nh vi suy luáº­n khÃ´ng cháº¯c cháº¯n dáº«n Ä‘áº¿n suy luáº­n bá»‹ sai nhiá»u. Äáº·c biá»‡t lÃ  khi káº¿t há»£p dropout vÃ  BN thÃ¬ khiáº¿n cho suy luáº­n cÃ ng sai láº§m tráº§m trá»ng. \u0026ldquo;. Cho nÃªn, trong má»™t sá»‘ trÆ°á»ng há»£p/bÃ i toÃ¡n chÃºng ta cÃ³ thá»ƒ dÃ¹ng Dropout, trong má»™t sá»‘ trÆ°á»ng há»£p/ bÃ i toÃ¡n, ngÆ°á»i ta sá»­ dá»¥ng BN vÃ  khÃ´ng sá»­ dá»¥ng dropout.\nNgÆ°á»i ta thÆ°á»ng dÃ¹ng há»‡ sá»‘ dropout lÃ  0.5. LÃ½ giáº£i cho viá»‡c nÃ y, báº¡n cÃ³ thá»ƒ Ä‘á»c bÃ i bÃ¡o http://papers.nips.cc/paper/4878-understanding-dropout.pdf. NÃ³i nÃ´m lÃ  viá»‡c sá»­ dá»¥ng giáº£m 50% cá»§a dropout giÃºp káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c lÃ  tá»‘t nháº¥t so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p chuáº©n hoÃ¡ khÃ¡c.\n5. Thá»±c nghiá»‡m trong keras Nhá»¯ng váº¥n Ä‘á» nÃ³i á»Ÿ trÃªn chá»‰ lÃ  lÃ½ thuyáº¿t. BÃ¢y giá» chÃºng ta sáº½ báº¯t tay vÃ o lÃ m thá»±c táº¿. Äá»ƒ xem thá»­ dropout hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o, chÃºng ta sáº½ xÃ¢y dá»±ng mÃ´ hÃ¬nh deep net sá»­ dá»¥ng keras vÃ  sá»­ dá»¥ng táº­p dá»¯ liá»‡u cifar-10. MÃ´ hÃ¬nh chÃºng ta xÃ¢y dá»±ng cÃ³ 3 hidden layer vá»›i kÃ­ch thÆ°á»›c láº§n lÆ°á»£t lÃ  64, 128, 256 vÃ  1 full connected layer cÃ³ kÃ­ch thÆ°á»›c 512 vÃ  output layer cÃ³ kÃ­ch thÆ°á»›c 10 (do mÃ¬nh cÃ³ 10 lá»›p).\nChÃºng ta sá»­ dá»¥ng hÃ m kÃ­ch hoáº¡t lÃ  ReLU trÃªn cÃ¡c hidden layer vÃ  sá»­ dá»¥ng hÃ m sigmoid trÃªn output layer. Sá»­ dá»¥ng hÃ m lá»—i categorical cross-entropy.\nTrong trÆ°á»ng há»£p mÃ´ hÃ¬nh cÃ³ sá»­ dá»¥ng dropout, chÃºng ta sáº½ set dropout á»Ÿ táº¥t cáº£ cÃ¡c layer vÃ  thay Ä‘á»•i tá»· lá»‡ dropout náº±m trong khoáº£ng tá»« 0.0 Ä‘áº¿n 0.9 vá»›i bÆ°á»›c nháº£y lÃ  0.1.\nMÃ´ hÃ¬nh setup vá»›i sá»‘ epochs lÃ  20. Báº¯t Ä‘áº§u xem nÃ o.\nÄáº§u tiÃªn, chÃºng ta sáº½ load má»™t vÃ i thÆ° viá»‡n cáº§n thiáº¿t\n1import numpy as np 2import os 3 4import keras 5 6from keras.datasets import cifar10 7from keras.models import Sequential 8from keras.layers import Dense, Dropout, Activation, Flatten 9from keras.layers import Convolution2D, MaxPooling2D 10from keras.optimizers import SGD 11from keras.utils import np_utils 12from keras.preprocessing.image import ImageDataGenerator 13import matplotlib.pyplot as plt 14 15from pylab import rcParams 16rcParams[\u0026#39;figure.figsize\u0026#39;] = 20, 20 17 18from keras.datasets import cifar10 19 20(X_train, y_train), (X_test, y_test) = cifar10.load_data() 21 22 23print(\u0026#34;Training data:\u0026#34;) 24print(\u0026#34;Number of examples: \u0026#34;, X_train.shape[0]) 25print(\u0026#34;Number of channels:\u0026#34;,X_train.shape[3]) 26print(\u0026#34;Image size:\u0026#34;,X_train.shape[1], X_train.shape[2], X_train.shape[3]) 27 28print(\u0026#34;Test data:\u0026#34;) 29print(\u0026#34;Number of examples:\u0026#34;, X_test.shape[0]) 30print(\u0026#34;Number of channels:\u0026#34;, X_test.shape[3]) 31print(\u0026#34;Image size:\u0026#34;,X_test.shape[1], X_test.shape[2], X_test.shape[3]) Káº¿t quáº£\n1Training data: 2Number of examples: 50000 3Number of channels: 3 4Image size: 32 32 3 5Test data: 6Number of examples: 10000 7Number of channels: 3 8Image size: 32 32 3 ChÃºng ta cÃ³ 50000 hÃ¬nh train, vÃ  10000 hÃ¬nh test. Má»—i hÃ¬nh lÃ  má»™t áº£nh RGB cÃ³ kÃ­ch thÆ°á»›c 33x32x3 pixel.\ndataset cifar 10\nTiáº¿p theo, chÃºng ta sáº½ chuáº©n hoÃ¡ dá»¯ liá»‡u. ÄÃ¢y lÃ  1 bÆ°á»›c quan trá»ng trÆ°á»›c khi huáº¥n luyá»‡n mÃ´ hÃ¬nh\n1print( \u0026#34;mean before normalization:\u0026#34;, np.mean(X_train)) 2print( \u0026#34;std before normalization:\u0026#34;, np.std(X_train)) 3 4mean=[0,0,0] 5std=[0,0,0] 6newX_train = np.ones(X_train.shape) 7newX_test = np.ones(X_test.shape) 8for i in range(3): 9 mean[i] = np.mean(X_train[:,i,:,:]) 10 std[i] = np.std(X_train[:,i,:,:]) 11 12for i in range(3): 13 newX_train[:,i,:,:] = X_train[:,i,:,:] - mean[i] 14 newX_train[:,i,:,:] = newX_train[:,i,:,:] / std[i] 15 newX_test[:,i,:,:] = X_test[:,i,:,:] - mean[i] 16 newX_test[:,i,:,:] = newX_test[:,i,:,:] / std[i] 17 18 19X_train = newX_train 20X_test = newX_test 21 22print(\u0026#34;mean after normalization:\u0026#34;, np.mean(X_train)) 23print(\u0026#34;std after normalization:\u0026#34;, np.std(X_train)) 1mean before normalization: 120.70756512369792 2std before normalization: 64.1500758911213 3mean after normalization: 0.9062499999999979 4std after normalization: 0.4227421643271468 Full code Ä‘oáº¡n huáº¥n luyá»‡n\n1 2 3# In[3]:Specify Training Parameters 4 5batchSize = 512 #-- Training Batch Size 6num_classes = 10 #-- Number of classes in CIFAR-10 dataset 7num_epochs = 100 #-- Number of epochs for training 8learningRate= 0.001 #-- Learning rate for the network 9lr_weight_decay = 0.95 #-- Learning weight decay. Reduce the learn rate by 0.95 after epoch 10 11 12img_rows, img_cols = 32, 32 #-- input image dimensions 13 14Y_train = np_utils.to_categorical(y_train, num_classes) 15Y_test = np_utils.to_categorical(y_test, num_classes) 16 17 18 19batchSize = 512 #-- Training Batch Size 20num_classes = 10 #-- Number of classes in CIFAR-10 dataset 21num_epochs = 100 #-- Number of epochs for training 22learningRate= 0.001 #-- Learning rate for the network 23lr_weight_decay = 0.95 #-- Learning weight decay. Reduce the learn rate by 0.95 after epoch 24 25 26img_rows, img_cols = 32, 32 #-- input image dimensions 27 28Y_train = np_utils.to_categorical(y_train, num_classes) 29Y_test = np_utils.to_categorical(y_test, num_classes) 30 31 32# In[4]:VGGnet-10 33 34 35from keras.layers import Conv2D 36import copy 37result = {} 38y = {} 39loss = [] 40acc = [] 41dropouts = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] 42for dropout in dropouts: 43 print(\u0026#34;Dropout: \u0026#34;, (dropout)) 44 model = Sequential() 45 46 #-- layer 1 47 model.add(Conv2D(64, (3, 3), 48 border_mode=\u0026#39;valid\u0026#39;, 49 input_shape=( img_rows, img_cols,3))) 50 model.add(Dropout(dropout)) 51 model.add(Conv2D(64, (3, 3))) 52 model.add(Dropout(dropout)) 53 model.add(Activation(\u0026#39;relu\u0026#39;)) 54 model.add(MaxPooling2D(pool_size=(2, 2))) 55 56 ##--layer 2 57 model.add(Conv2D(128, (3, 3))) 58 model.add(Dropout(dropout)) 59 model.add(Activation(\u0026#39;relu\u0026#39;)) 60 model.add(MaxPooling2D(pool_size=(2, 2))) 61 62 ##--layer 3 63 model.add(Conv2D(256, (3, 3))) 64 model.add(Dropout(dropout)) 65 model.add(Activation(\u0026#39;relu\u0026#39;)) 66 model.add(MaxPooling2D(pool_size=(2, 2))) 67 68 ##-- layer 4 69 model.add(Flatten()) 70 model.add(Dense(512)) 71 model.add(Activation(\u0026#39;relu\u0026#39;)) 72 73 #-- layer 5 74 model.add(Dense(num_classes)) 75 76 #-- loss 77 model.add(Activation(\u0026#39;softmax\u0026#39;)) 78 79 sgd = SGD(lr=learningRate, decay = lr_weight_decay) 80 model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, 81 optimizer=\u0026#39;sgd\u0026#39;, 82 metrics=[\u0026#39;accuracy\u0026#39;]) 83 84 model_cce = model.fit(X_train, Y_train, batch_size=batchSize, epochs=20, verbose=1, shuffle=True, validation_data=(X_test, Y_test)) 85 score = model.evaluate(X_test, Y_test, verbose=0) 86 y[dropout] = model.predict(X_test) 87 print(\u0026#39;Test score:\u0026#39;, score[0]) 88 print(\u0026#39;Test accuracy:\u0026#39;, score[1]) 89 result[dropout] = copy.deepcopy(model_cce.history) 90 loss.append(score[0]) 91 acc.append(score[1]) 92 93 94 95# In[5]: plot dropout 96import numpy as np 97import matplotlib.pyplot as plt 98 99width = 0.1 100 101plt.bar(dropouts, acc, width, align=\u0026#39;center\u0026#39;) 102 103plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;major\u0026#39;, labelsize=35) 104plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;minor\u0026#39;, labelsize=35) 105 106plt.ylabel(\u0026#39;Accuracy\u0026#39;,size = 30) 107plt.xlabel(\u0026#39;Dropout\u0026#39;, size = 30) 108plt.show() 109 110 111# In[6]: plot non drop out 112 113import numpy as np 114import matplotlib.pyplot as plt 115 116width = 0.1 117 118plt.bar(dropouts, loss, width, align=\u0026#39;center\u0026#39;,color = \u0026#39;green\u0026#39;) 119 120plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;major\u0026#39;, labelsize=35) 121plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;minor\u0026#39;, labelsize=35) 122 123plt.ylabel(\u0026#39;Loss\u0026#39;,size = 30) 124plt.xlabel(\u0026#39;Dropout\u0026#39;, size = 30) 125plt.show() Káº¿t quáº£\nNhÃ¬n hÃ¬nh káº¿t quáº£ á»Ÿ trÃªn, chÃºng ta cÃ³ má»™t sá»‘ káº¿t luáº­n nhá» nhÆ° sau:\nGiÃ¡ trá»‹ dropout tá»‘t nháº¥t lÃ  0.2, khoáº£ng dropout cho giÃ¡ trá»‹ cháº¥p nháº­n Ä‘Æ°á»£c lÃ  náº±m trong Ä‘oáº¡n tá»« 0 Ä‘áº¿n 0.5. Náº¿u dropout lá»›n hÆ¡n 0.5 thÃ¬ káº¿t quáº£ hÃ m huáº¥n luyá»‡n tráº£ vá» khÃ¡ tá»‡.\nGiÃ¡ trá»‹ Ä‘á»™ chÃ­nh xÃ¡c cÃ²n khÃ¡ tháº¥p =\u0026gt; 20 epochs lÃ  chÆ°a Ä‘á»§, cáº§n huáº¥n luyá»‡n nhiá»u hÆ¡n ná»¯a.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ nhá»¯ng bÃ i viáº¿t tiáº¿p theo.\n","date":"May 5, 2019","img":"","permalink":"/blog/2019-05-05-deep-learning-dropout/","series":null,"tags":["machine learning","deep learning","dropout","deep net"],"title":"TÃ¬m Hiá»ƒu Vá» Dropout Trong Deep Learning, Machine Learning"},{"categories":null,"content":" 1. Giá»›i thiá»‡u vá» PredictionIO 2. CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng cá»§a PredictionIO Event Server Engine 3. CÃ i Ä‘áº·t PredictionIO trÃªn mÃ´i trÆ°á»ng Ubuntu Download vÃ  build Apache Prediction IO BiÃªn dá»‹ch Prediction IO Download vÃ  giáº£i nÃ©n cÃ¡c Dependencies Cáº¥u hÃ¬nh chÆ°Æ¡ng trÃ¬nh 4.Khá»Ÿi cháº¡y há»‡ thá»‘ng 1. Giá»›i thiá»‡u vá» PredictionIO PredictionIO lÃ  má»™t \u0026ldquo;open source Machine Learning Server built on top of a state-of-the-art open source stack\u0026rdquo; giÃºp cho cÃ¡c developers vÃ  cÃ¡c data scientists táº¡o ra cÃ¡c engine dá»± Ä‘oÃ¡n trong há»c mÃ¡y. PredictionIO giÃºp chÃºng ta\nXÃ¢y dá»±ng vÃ  triá»ƒn khai cÃ¡c á»©ng dá»¥ng, dá»‹ch vá»¥ má»™t cÃ¡ch nhanh chÃ³ng báº±ng cÃ¡ch tuá»³ chá»‰nh láº¡i cÃ¡c template Ä‘Ã£ sáºµn cÃ³.\nTráº£ lá»i cÃ¡c cÃ¢u truy váº¥n Ä‘á»™ng trong thá»i gian thá»±c.\nhuáº¥n luyá»‡n vÃ  so sÃ¡nh/Ä‘Ã¡nh giÃ¡ nhiá»u mÃ´ hÃ¬nh khÃ¡c nhau dá»… dÃ ng.\nHá»£p nháº¥t hoÃ¡ dá»¯ liá»‡u tá»« nhiá»u ná»n táº£ng khÃ¡c nhau hoáº·c trong thá»i gian thá»±c Ä‘á»ƒ thá»±c hiá»‡n phÃ¢n tÃ­ch dá»± Ä‘oÃ¡n.\nHá»— trá»£ cÃ¡c thÆ° viá»‡n mÃ¡y há»c vÃ  xá»­ lÃ½ dá»¯ liá»‡u nhÆ° Spark MLLib vÃ  OpenNLP\nTá»± xÃ¢y dá»±ng, triá»ƒn khai, customize má»™t mÃ´ hÃ¬nh machine learning\n2. CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng cá»§a PredictionIO PredictionIO bao gá»“m cÃ¡c thÃ nh pháº§n sau:\nPredictionIO platform: lÃ  ná»n táº£ng open source Ä‘Æ°á»£c apache xÃ¢y dá»±ng sáºµn giÃºp chÃºng ta triá»ƒn khai, xÃ¢y dá»±ng, Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh mÃ¡y há»c.\nEvent Server: lÃ  nÆ¡i giÃºp chÃºng ta chuáº©n hoÃ¡ cÃ¡c sá»± kiá»‡n tá»« nhiá»u nguá»“n khÃ¡c nhau\nTemplate Gallery: lÃ  nÆ¡i chÃºng ta download cÃ¡c engine template mÃ¡y há»c vá». PredictionIO há»— trá»£ cho chÃºng ta ráº¥t nhiá»u template máº«u khÃ¡c nhau. ChÃºng ta sáº½ láº§n lÆ°á»£t tÃ¬m hiá»ƒu vÃ  implement á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\nEvent Server PredictionIO Event Server chá»‹u trÃ¡ch nhiá»‡u thu tháº­p dá»¯ liá»‡u tá»« cÃ¡c á»©ng dá»¥ng cá»§a báº¡n. Báº¡n cÃ³ thá»ƒ nhÃ¬n ká»¹ hÆ¡n á»Ÿ hÃ¬nh bÃªn dÆ°á»›i, cÃ¡c á»©ng dá»¥ng web, mobile app \u0026hellip; khi ngÆ°á»i dÃ¹ng tÆ°Æ¡ng tÃ¡c sáº½ phÃ¡t sinh cÃ¡c sá»± kiá»‡n (Event Data), vÃ­ dá»¥ sá»± kiá»‡n ngÆ°á»i dÃ¹ng thÃªm 1 Ä‘Æ¡n hÃ ng vÃ o giá» hÃ ng, ngÆ°á»i dÃ¹ng xem sáº£n pháº©n A, ngÆ°á»i dÃ¹ng xem sáº£n pháº©m C sau khi xem sáº£n pháº©m A\u0026hellip; Event Server sáº½ ghi nháº­n láº¡i Ä‘á»‘ng dá»¯ liá»‡u nÃ y, chuáº©n hoÃ¡ láº¡i. PredictionIO engine sau Ä‘Ã³ sáº½ xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n dá»±a trÃªn cÃ¡c dá»¯ liá»‡u chÃºng ta thu tháº­p Ä‘Æ°á»£c. Sau khi báº¡n cÃ³ Ä‘Æ°á»£c mÃ´ hÃ¬nh tá»‘i Æ°u, chÃºng ta sáº½ deploy cÃ¡c predict webservice, láº¯ng nghe cÃ¡c truy váº¥n tá»« cÃ¡c á»©ng dá»¥ng vÃ  tráº£ vá» káº¿t quáº£ trong thá»i gian thá»±c.\nHÃ¬nh 1: Event server trong predictionio\nEvent Server sáº½ thu tháº­p dá»¯ liá»‡u cá»§a báº¡n trong thá»i gian thá»±c hoáº·c theo chu ká»³. Sau Ä‘Ã³, nÃ³ sáº½ chuáº©n hoÃ¡ dá»¯ liá»‡u há»—n Ä‘á»™n cá»§a báº¡n tá»« nhiá»u nguá»“n khÃ¡c nhau thÃ nh má»™t dáº¡ng chuáº©n chung. Event Server chá»§ yáº¿u phá»¥c vá»¥ hai má»¥c Ä‘Ã­nh chÃ­nh:\nCung cáº¥p dá»¯ liá»‡u cho cÃ¡c engine Ä‘á»ƒ huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡\nCung cáº¥p dá»¯ liá»‡u dáº¡ng chuáº©n Ä‘á»ƒ data analysis\nCÅ©ng giá»‘ng nhÆ° má»™t database server, Event Server cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phá»¥c vá»¥ cho nhiá»u á»©ng dá»¥ng khÃ¡c nhau. Dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n tÃ¡ch cho cÃ¡c á»©ng dá»¥ng báº±ng \u0026ldquo;app_name\u0026rdquo; duy nháº¥t. CÃ¡i nÃ y sáº½ nÃ³i láº¡i lÃºc xÃ¢y dá»±ng á»©ng dá»¥ng á»Ÿ bÃªn dÆ°á»›i.\nKhi má»™t Event Server Ä‘Æ°á»£c triá»ƒn khai, báº¡n cÃ³ thá»ƒ gá»­i dá»¯ liá»‡u cho má»™t \u0026lsquo;app_name\u0026rsquo; cá»¥ thá»ƒ nÃ o Ä‘Ã³, app-name Ä‘Æ°á»£c Ä‘á»‹nh danh báº±ng access key. Dá»¯ liá»‡u Ä‘Æ°á»£c gá»­i Ä‘áº¿n Event Server sá»­ dá»¥ng EventAPI sá»­ dá»¥ng giao thá»©c http (tham kháº£o thÃªm á»Ÿ https://predictionio.apache.org/datacollection/eventapi/) hoáº·c sá»­ dá»¥ng cÃ¡c PredictionIO SDK. Tham kháº£o thÃªm cÃ¡c SDK á»Ÿ https://predictionio.apache.org/sdk/.\nTrong má»™t sá»‘ trÆ°á»ng há»£p, báº¡n muá»‘n engine Ä‘á»c dá»¯ liá»‡u tá»« má»™t datastore nÃ o Ä‘Ã³ thay vÃ¬ Event Server. Báº¡n cÃ³ thá»ƒ thá»±c hiá»‡n thÃ´ng qua hÆ°á»›ng dáº«n á»Ÿ https://predictionio.apache.org/start/customize/\nEngine Engine lÃ  nÆ¡i chá»‹u trÃ¡ch nhiá»‡u Ä‘Æ°a ra cÃ¡c quyáº¿t Ä‘á»‹nh. NÃ³ gá»“m má»™t hoáº·c nhiá»u thuáº­t toÃ¡n há»c mÃ¡y há»c khÃ¡c nhau. CÃ¡c Engine sáº½ huáº¥n luyá»‡n dá»¯ liá»‡u vÃ  xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n. Sau Ä‘Ã³ sáº½ phÃ¡t triá»ƒn thÃ nh cÃ¡c webservice. CÃ¡c webservice sáº½ nháº­n cÃ¡c truy váº¥n tá»« á»©ng dá»¥ng, dá»± Ä‘oÃ¡n vÃ  tráº£ vá» káº¿t quáº£ cho á»©ng dá»¥ng.\nPredictionIO\u0026rsquo;s cung cáº¥p cho chÃºng ta ráº¥t nhiá»u cÃ¡c template khÃ¡c nhau Ä‘Ã¡p á»©ng gáº§n nhÆ° lÃ  Ä‘áº©y Ä‘á»§ cÃ¡c mÃ´ hÃ¬nh mÃ¡y há»c mÃ  chÃºng ta cáº§n. Báº¡n cÃ³ thá»ƒ dá»… dÃ ng táº¡o má»™t mÃ´ hÃ¬nh mÃ¡y há»c tá»« cÃ¡c template. CÃ¡c thÃ nh pháº§n cá»§a má»™t template dÆ°á»£c Ä‘áº·t tÃªn lÃ  Data Source, Data Preparator, Algorithm(s), Serving, cÃ¡c báº¡n cÃ³ thá»ƒ dá»… dÃ ng customize láº¡i tuá»³ thuá»™c nhu cáº§u cá»§a báº¡n.\n3. CÃ i Ä‘áº·t PredictionIO trÃªn mÃ´i trÆ°á»ng Ubuntu Trong thá»i Ä‘áº¡i docker, cÃ¡c báº¡n cÃ³ thá»ƒ cÃ i Ä‘áº·t PredictionIO dá»±a vÃ o cÃ¡c docker Ä‘Æ°á»£c xÃ¢y dá»±ng sáºµn Ä‘áº§y ráº«y trÃªn máº¡ng, chÃºng giÃºp báº¡n Ä‘á»¡ tá»‘n cÃ´ng sá»©c hÆ¡n. Tuy nhiÃªn, trong bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ cÃ i Ä‘áº·t tá»«ng thÃ nh pháº§n PredictiIO trÃªn ubuntu, khÃ´ng sá»­ dá»¥ng docker.\nDownload vÃ  build Apache Prediction IO ChÃºng ta sáº½ download Prediction IO tá»« trang github chÃ­nh chá»§. PhiÃªn báº£n hiá»‡n táº¡i lÃ  0.14.0. CÃ¡c báº¡n cÃ³ thá»ƒ lÆ°u dá»¯ liá»‡u á»Ÿ Ä‘Ã¢u tuá»³ Ã½ cÃ¡c báº¡n. MÃ¬nh lÆ°u á»Ÿ thÆ° má»¥c /data/pio. VÃ  trong suá»‘t bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ lÆ°u cÃ¡c thá»© liÃªn quan trong thÆ° má»¥c /data/pio. CÃ¡c báº¡n cÃ³ cÃ i Ä‘áº·t theo hÆ°á»›ng dáº«n cá»§a mÃ¬nh thÃ¬ nhá»› sá»­a láº¡i cho Ä‘Ãºng Ä‘Æ°á»ng dáº«n cá»§a cÃ¡c báº¡n. ChÃºng ta sáº½ clone nguá»“n tá»« trang github predictionio. vÃ  sáº½ switch qua branch release. ÄÃ¢y lÃ  branch chÃ­nh thÃ nh pháº©m, cÃ¡c branch khÃ¡c Ä‘ang trong giai Ä‘oáº¡n phÃ¡t triá»ƒn nÃªn cÃ³ thá»ƒ build khÃ´ng Ä‘Æ°á»£c. LÃºc cÃ¡c báº¡n lÃ m cÃ³ thá»ƒ nÃ³ Ä‘Ã£ phÃ¡t triá»ƒn lÃªn báº£n 15, 16 hoáº·c 1.0 gÃ¬ Ä‘Ã³ rá»“i. CÃ¡c báº¡n cá»© tá»± tin sá»­ dá»¥ng phiÃªn báº£n má»›i nháº¥t.\n1git clone https://github.com/apache/predictionio.git 2git checkout release/0.14.0 BiÃªn dá»‹ch Prediction IO Sau khi táº£i vá» bá»™ nguá»“n cá»§a Prediction IO, chÃºng ta sáº½ tiá»n hÃ nh biÃªn dá»‹ch. QuÃ¡ trÃ¬nh biÃªn dá»‹ch sáº½ xáº£y ra khÃ¡ lÃ¢u, cÃ¡c báº¡n kiÃªn nháº«n chá» Ä‘á»£i\n1cd predictionio 2./make-distribution.sh Káº¿t thÃºc quÃ¡ trÃ¬nh biÃªn dá»‹ch, cÃ¡c báº¡n sáº½ tháº¥y dÃ²ng chá»¯\n1PredictionIO binary distribution created at PredictionIO-0.14.0.tar.gz Váº­y lÃ  chÃºng ta Ä‘Ã£ thÃ nh cÃ´ng. Viá»‡c tiáº¿p theo lÃ  giáº£i nÃ©n file PredictionIO-0.14.0.tar.gz Ä‘á»ƒ sá»­ dá»¥ng\n1tar xvzf PredictionIO-0.14.0.tar.gz -C /data/pio Nháº¯c láº¡i 1 láº§n ná»¯a lÃ  do thá»i Ä‘iá»ƒm hiá»‡n táº¡i mÃ¬nh viáº¿t bÃ i viáº¿t nÃ y, PredictionIO má»›i release báº£n 0.14.0 nÃªn file táº­p tin sáº½ lÃ  PredictionIO-0.14.0.tar.gz. CÃ¡c báº¡n nhá»› giáº£i nÃ©n Ä‘Ãºng vá»›i tÃªn file á»©ng vá»›i phiÃªn báº£n PredictionIO tÆ°Æ¡ng á»©ng nhÃ©.\nDownload vÃ  giáº£i nÃ©n cÃ¡c Dependencies MÃ¬nh sáº½ sá»­ dá»¥ng Spark, ElasticSearch, Hbase vÃ  zookeeper, nÃªn mÃ¬nh download háº¿t vá». MÃ¬nh cÃ³ thÃ³i quen sá»­ dá»¥ng phiÃªn báº£n má»›i nháº¥t. NÃªn mÃ¬nh lÃªn trang chá»§ vÃ  láº¥y link download má»›i nháº¥t cá»§a chÃºng thÃ´i. Táº¥t cáº£ cÃ¡c Dependencies mÃ¬nh dÃ¹ng Ä‘á»u Ä‘Æ°á»£c bá» vÃ o trong thÆ° má»¥c vendors\n1 2cd PredictionIO-0.14.0 3mkdir vendors 4cd vendors 5wget https://archive.apache.org/dist/spark/spark-2.4.2/spark-2.4.2-bin-hadoop2.7.tgz 6 7wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.9.tar.gz 8 9wget https://www.apache.org/dyn/closer.lua/hbase/2.1.4/hbase-2.1.4-bin.tar.gz 10 11wget https://www-us.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz 12 13tar xvzf spark-2.4.2-bin-hadoop2.7.tgz 14 15tar xvzf elasticsearch-5.6.9.tar.gz 16 17tar xvzf hbase-2.1.4-bin.tar.gz 18 19tar xvzf zookeeper-3.4.14/zookeeper-3.4.14.tar.gz Cáº¥u hÃ¬nh chÆ°Æ¡ng trÃ¬nh Cáº¥u hÃ¬nh dependency ChÃºng ta sáº½ cáº¥u hÃ¬nh má»™t chÃºt Ä‘á»ƒ PredictionIO nháº­n ra cÃ¡c dependency cá»§a mÃ¬nh vÃ  cáº¥u hÃ¬nh cÃ¡c dependency\nÄáº§u tiÃªn, chÃºng ta sáº½ chá»‰nh sá»­a file hbase-site.xml cá»§a HBase\n1nano /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/conf/hbase-site.xml Thay Ä‘oáº¡n\n1\u0026lt;configuration\u0026gt; 2\u0026lt;/configuration\u0026gt; báº±ng Ä‘oáº¡n\n1\u0026lt;configuration\u0026gt; 2 \u0026lt;property\u0026gt; 3 \u0026lt;name\u0026gt;hbase.rootdir\u0026lt;/name\u0026gt; 4 \u0026lt;value\u0026gt;file:///data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4\u0026lt;/value\u0026gt; 5 \u0026lt;/property\u0026gt; 6 \u0026lt;property\u0026gt; 7 \u0026lt;name\u0026gt;hbase.zookeeper.property.dataDir\u0026lt;/name\u0026gt; 8 \u0026lt;value\u0026gt;/data/pio/PredictionIO-0.14.0/vendors/zookeeper-3.4.14\u0026lt;/value\u0026gt; 9 \u0026lt;/property\u0026gt; 10\u0026lt;/configuration\u0026gt; Tiáº¿p theo, chÃºng ta sáº½ add Ä‘Æ°á»ng dáº«n java cho hbase\n1nano /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/conf/hbase-env.sh ThÃªm Ä‘oáº¡n\n1 export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre/ cÃ¡c báº¡n hÃ£y thay Ä‘Æ°á»ng dáº«n java tÆ°Æ¡ng á»©ng vá»›i Ä‘Æ°á»ng dáº«n trong mÃ¡y báº¡n. Náº¿u chÆ°a cÃ³ java thÃ¬ cÃ¡c báº¡n hÃ£y cÃ i vÃ o, náº¿u cÃ¡c báº¡n Ä‘Ã£ cÃ i java mÃ  khÃ´ng biáº¿t nÃ³ náº±m á»Ÿ Ä‘Ã¢u, cÃ¡c báº¡n cÃ³ thá»ƒ gá»i lá»‡nh bÃªn dÆ°á»›i Ä‘á»ƒ xem Ä‘Æ°á»ng dáº«n\n1update-alternatives --config java Äá»ƒ cháº¯c cháº¯n ráº±ng trong mÃ¡y cá»§a báº¡n cÃ³ cÃ i java báº¡n hÃ£y gá»i lá»‡n java -version\nVÃ­ dá»¥ trong mÃ¡y mÃ¬nh\n1$java -version 2openjdk version \u0026#34;1.8.0_191\u0026#34; 3OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-2ubuntu0.16.04.1-b12) 4OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode) CÃ¡c báº¡n cá»‘ gáº¯ng sá»­ dá»¥ng phiÃªn báº£n java má»›i nháº¥t. NÃ³ sáº½ tÆ°Æ¡ng thÃ­ch tá»‘t hÆ¡n vá»›i phiÃªn báº£n má»›i nháº¥t cá»§a HBase, hoáº·c Ä‘á»c phiÃªn báº£n java Ä‘á» nghá»‹ trong trang chá»§ HBase. TrÃ¡nh trÆ°á»ng há»£p sá»­ dá»¥ng phiÃªn báº£n java quÃ¡ cÅ© HBase khÃ´ng há»— trá»£.\nCáº¥u hÃ¬nh Prediction IO Chá»‰nh sá»­a file pio-env.sh.\n1 2nano /data/pio/PredictionIO-0.14.0/conf/pio-env.sh Máº·c Ä‘á»‹nh PredictionIO sá»­ dá»¥ng PosgresSQl lÃ m event server. MÃ¬nh khÃ´ng dÃ¹ng nÃ³ mÃ  thay tháº¿ báº±ng HBASE vÃ  ELASTICSEARCH.\nMá»™t sá»‘ thay Ä‘á»•i mÃ¬nh sáº½ liá»‡t kÃª bÃªn dÆ°á»›i\n1SPARK_HOME=$PIO_HOME/vendors/spark-2.3.2-bin-hadoop2.7 2 3HBASE_CONF_DIR=$PIO_HOME/vendors/hbase-2.1.4/conf 4 5PIO_STORAGE_REPOSITORIES_METADATA_NAME=pio_meta 6PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH 7 8PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=pio_event 9PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE 10 11PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_model 12PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS 13 14#Comment cÃ¡c dÃ²ng nÃ y láº¡i, do khÃ´ng dÃ¹ng postgres 15# PIO_STORAGE_SOURCES_PGSQL_PASSWORD accordingly 16# PIO_STORAGE_SOURCES_PGSQL_TYPE=jdbc 17# PIO_STORAGE_SOURCES_PGSQL_URL=jdbc:postgresql://localhost/pio 18# PIO_STORAGE_SOURCES_PGSQL_USERNAME=pio 19# PIO_STORAGE_SOURCES_PGSQL_PASSWORD=pio 20 21PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=$PIO_HOME/vendors/elasticsearch-5.6.9 22PIO_STORAGE_SOURCES_HBASE_HOME=$PIO_HOME/vendors/hbase-2.1.4 4.Khá»Ÿi cháº¡y há»‡ thá»‘ng ChÃºng ta sáº½ add path cá»§a PredictIO vÃ o biáº¿n mÃ´i trÆ°á»ng Ä‘á»ƒ sá»­ dá»¥ng cho cÃ¡c láº§n sau\n1 2nano ~/.bashrc 3erport PATH=/data/pio/PredictionIO-0.14.0/bin:$PATH Hoáº·c cÃ³ thá»ƒ add path trong má»—i session\n1PATH=$PATH:/data/pio/PredictionIO-0.14.0/bin; export PATH Tiáº¿p theo, chÃºng ta sáº½ cáº¥p quyá»n cho thÆ° má»¥c PredictionIO\n1sudo chmod -R 775 /data/pio Náº¿u khÃ´ng cáº¥p quyá»n write cho thÆ° má»¥c thÃ¬ PredictionIO khÃ´ng thá»ƒ write log file Ä‘Æ°á»£c.\nCháº¡y PredictionIO Server báº±ng cÃ¡ch gá»i cÃ¢u lá»‡nh\n1pio-start-all Káº¿t quáº£\n1Stopping PredictionIO Event Server... 2Stopping HBase... 3stopping hbase............. 4Stopping Elasticsearch... 5tgdd@U1604:/data/pio/PredictionIO-0.14.0/bin$ pio-start-all 6Starting Elasticsearch... 7Starting HBase... 8running master, logging to /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/bin/../logs/hbase-tgdd-master-U1604.out 9Waiting 10 seconds for Storage Repositories to fully initialize... 10Starting PredictionIO Event Server... Äá»ƒ kiá»ƒm tra há»‡ thá»‘ng khi start cÃ³ lá»—i láº§m gÃ¬ khÃ´ng, chÃºng ta sá»­ dá»¥ng lá»‡nh\n1pio status Káº¿t quáº£\n1[INFO] [Management$] Inspecting PredictionIO... 2[INFO] [Management$] PredictionIO 0.14.0 is installed at /data/pio/PredictionIO-0.14.0 3[INFO] [Management$] Inspecting Apache Spark... 4[INFO] [Management$] Apache Spark is installed at /data/spark-2.3.2-bin-hadoop2.7 5[INFO] [Management$] Apache Spark 2.3.2 detected (meets minimum requirement of 2.0.2) 6[INFO] [Management$] Inspecting storage backend connections... 7[INFO] [Storage$] Verifying Meta Data Backend (Source: ELASTICSEARCH)... 8[INFO] [Storage$] Verifying Model Data Backend (Source: LOCALFS)... 9[INFO] [Storage$] Verifying Event Data Backend (Source: HBASE)... 10[INFO] [Storage$] Test writing to Event Store (App Id 0)... 11[INFO] [HBLEvents] The table pio_event:events_0 doesn\u0026#39;t exist yet. Creating now... 12[INFO] [HBLEvents] Removing table pio_event:events_0... 13[INFO] [Management$] Your system is all ready to go. Báº¡n tháº¥y dÃ²ng chá»¯ [INFO] [Management$] Your system is all ready to go. thÃ¬ yÃªn tÃ¢m, há»‡ thá»‘ng Ä‘Ã£ cháº¡y thÃ nh cÃ´ng.\nÄá»ƒ stop há»‡ thá»‘ng, cÃ¡c báº¡n gá»i lá»‡nh\n1pio-stop-all Káº¿t quáº£ khi stop\n1Stopping PredictionIO Event Server... 2Stopping HBase... 3stopping hbase............. 4Stopping Elasticsearch... Váº­y lÃ  chÃºng ta Ä‘Ã£ tiáº¿n hÃ nh cÃ i Ä‘áº·t thÃ nh cÃ´ng PredictionIO Server rá»“i. Háº¹n gáº·p báº¡n á»Ÿ bÃ i thá»© hai, cÃ i Ä‘áº·t cÃ¡c template cho PredictionIO vÃ  tiáº¿n hÃ nh dá»± Ä‘oÃ¡n.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ nhá»¯ng bÃ i viáº¿t tiáº¿p theo.\n","date":"May 4, 2019","img":"","permalink":"/blog/2019-05-04-setup-predictio/","series":null,"tags":["machine learning","deep learning","PredictionIO","forecast","dá»± Ä‘oÃ¡n"],"title":"PredictionIO Pháº§n 1 - HÆ°á»›ng Dáº«n CÃ i Äáº·t"},{"categories":null,"content":" Láº¥y máº«u ngáº«u nhiÃªn Láº¥y máº«u phi ngáº«u nhiÃªn Láº¥y máº«u dá»¯ liá»‡u lÃ  má»™t ká»¹ thuáº­t ráº¥t quang trá»ng trong thá»‘ng kÃª, lÃ  yáº¿u tá»‘ quan trá»ng gÃ³p pháº§n xÃ¡c Ä‘á»‹nh Ä‘á»™ chÃ­nh xÃ¡c cá»§a research/ survey. Náº¿u cÃ³ báº¥t ká»³ sai sÃ³t gÃ¬ trong quÃ¡ trÃ¬nh láº¥y máº«u, nÃ³ sáº½ áº£nh hÆ°á»Ÿng trá»±c tiáº¿p Ä‘áº¿n káº¿t quáº£ cuá»‘i cÃ¹ng. CÃ³ ráº¥t nhiá»u ká»¹ thuáº­t giÃºp chÃºng ta thu tháº­p máº«u dá»±a trÃªn nhu cáº§u vÃ  tÃ¬nh huá»‘ng chÃºng ta cáº§n. BÃ i viáº¿t nÃ y sáº½ giáº£i thÃ­ch má»™t sá»‘ ká»¹ thuáº­t phá»• biáº¿n nháº¥t.\nÄá»ƒ báº¯t Ä‘áº§u bÃ i viáº¿t, chÃºng ta sáº½ lÃ m rÃµ má»‘t sá»‘ khÃ¡i niá»‡m cÆ¡ báº£n lÃ  Quáº§n thá»ƒ - Population,máº«u - Sample vÃ  láº¥y máº«u - sampling\nQuáº§n thá»ƒ - population lÃ  táº­p há»£p cá»§a cÃ¡c cÃ¡ thá»ƒ cÃ³ má»™t hoáº·c má»™t sá»‘ Ä‘áº·c Ä‘iá»ƒm chung. KÃ­ch thÆ°á»›c cá»§a má»™t quáº§n thá»ƒ lÃ  sá»‘ lÆ°á»£ng cÃ¡ thá»ƒ trong quáº§n thá»ƒ Ä‘Ã³.\nMáº«u - sample lÃ  má»™t táº­p con cá»§a quáº§n thá»ƒ. QuÃ¡ trÃ¬nh chá»n má»™t máº«u Ä‘Æ°á»£c gá»i lÃ  láº¥y máº«u -sampling. KÃ­ch thÆ°á»›c máº«u lÃ  sá»‘ lÆ°á»£ng cÃ¡ thá»ƒ trong táº­p máº«u.\nHÃ¬nh 1: VÃ­ dá»¥ vá» láº¥y máº«u dá»¯ liá»‡u\nCÃ³ ráº¥t nhiá»u ká»¹ thuáº­t láº¥y máº«u dá»¯ liá»‡u khÃ¡c nhau, nhÆ°ng chÃºng ta cÃ³ thá»ƒ gom chÃºng vÃ o 2 nhÃ³m chÃ­nh:\nLáº¥y máº«u ngáº«u nhiÃªn - Probability Sampling\nLáº¥y máº«u phi ngáº«u nhiÃªn - non-probability sampling\nHÃ¬nh 2: VÃ­ dá»¥ so vá» láº¥y máº«u ngáº«u nhiÃªn vÃ  láº¥y máº«u phi ngáº«u nhiÃªn\nSá»± khÃ¡c biá»‡t cá»§a hai nhÃ³m trÃªn lÃ  phÆ°Æ¡ng phÃ¡p láº¥y máº«u cÃ³ sá»­ dá»¥ng \u0026ldquo;hÃ m ngáº«u nhiÃªn\u0026rdquo; hay khÃ´ng. Vá»›i viá»‡c sá»­ dá»¥ng hÃ m ngáº«u nhiÃªn, má»—i cÃ¡ thá»ƒ Ä‘á»u cÃ³ cÆ¡ há»™i Ä‘Æ°á»£c lá»±a chá»n ngang nhau vÃ  Ä‘á»u cÃ³ cÆ¡ há»™i lÃ  má»™t cÃ¡ thá»ƒ trong táº­p máº«u.\nLáº¥y máº«u ngáº«u nhiÃªn Nhá»¯ng thuáº­t toÃ¡n trong nhÃ³m nÃ y sá»­ dá»¥ng hÃ m \u0026ldquo;ngáº«u nhiÃªn\u0026rdquo; Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng má»i pháº§n tá»­ Ä‘á»u cÃ³ cÆ¡ há»™i lá»±a chá»n ngang nhau. Má»™t tÃªn khÃ¡c cá»§a phÆ°Æ¡ng phÃ¡p nÃ y lÃ  random sampling.\nMá»™t sá»‘ phÆ°Æ¡ng phÃ¡p thuá»™c nhÃ³m nÃ y\nSimple Random Sampling\nStratified sampling\nSystematic sampling\nCluster Sampling\nMulti stage Sampling\nSimple Random Sampling Má»—i cÃ¡ thá»ƒ Ä‘á»u cÃ³ cÆ¡ há»™i lá»±a chá»n ngang nhau vÃ o táº­p máº«u. PhÆ°Æ¡ng phÃ¡p nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng khi chÃºng ta khÃ´ng cÃ³ báº¥t ká»³ thÃ´ng tin gÃ¬ vá» táº­p population.\nVÃ­ dá»¥: Chá»n ngáº«u nhiÃªn 20 sinh viÃªn trong lá»›p há»c 50 sinh viÃªn. Má»—i sinh viÃªn Ä‘á»u cÃ³ cÆ¡ há»™i Ä‘Æ°á»£c chá»n ngang nhau lÃ  1/50.\nStratified sampling Ká»¹ thuáº­t nÃ y phÃ¢n chia má»—i cÃ¡ thá»ƒ trong quáº§n thá»ƒ thÃ nh tá»«ng nhÃ³m nhá» dá»±a trÃªn sá»± tÆ°Æ¡ng Ä‘á»“ng (similarity), nghÄ©a lÃ  cÃ¡c cÃ¡ thá»ƒ trong cÃ¹ng 1 nhÃ³m sáº½ Ä‘á»“ng nháº¥t vá»›i nhau vá» má»™t khÃ­a cáº¡nh nÃ o Ä‘Ã³, vÃ  sáº½ khÃ´ng giá»‘ng vá»›i cÃ¡c nhÃ³m khÃ¡c vá» khÃ­a cáº¡nh Ä‘Ã³. VÃ  chÃºng ta sáº½ chá»n ngáº«u nhiÃªn cÃ¡c cÃ¡c thá»ƒ trong má»—i nhÃ³m. á» phÆ°Æ¡ng phÃ¡p nÃ y, chÃºng ta cáº§n thÃ´ng tin cho trÆ°á»›c vá» táº­p quáº§n thá»ƒ Ä‘á»ƒ táº¡o cÃ¡c nhÃ³m con.\nHÃ¬nh 2: láº¥y máº«u Stratified sampling\ná» vÃ­ dá»¥ trÃªn, chÃºng ta sáº½ chia táº­p quáº§n thá»ƒ thÃ nh cÃ¡c nhÃ³m con máº·c Ã¡o Ä‘á», máº·c Ã¡o xanh, máº·c Ã¡o vÃ ng (pháº£i biáº¿t trÆ°á»›c Ä‘Æ°á»£c trong quáº§n thá»ƒ tháº±ng nÃ o máº·c Ã¡o mÃ u gÃ¬). Sau Ä‘Ã³ sáº½ lá»±a chá»n ngáº«u nhiÃªn 2 cÃ¡c thá»ƒ trong má»—i nhÃ³m.\nCluster Sampling ToÃ n bá»™ táº­p quáº§n thá»ƒ sáº½ Ä‘Æ°á»£c chia thÃ nh tá»« cá»¥m hoáº·c thÃ nh tá»«ng pháº§n. Sau Ä‘Ã³ chÃºng ta sáº½ chá»n ngáº«u nhiÃªn tá»«ng cá»¥m. Táº¥t cáº£ cÃ¡c cÃ¡ thá»ƒ trong cá»¥m Ä‘Ã³ sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m táº­p máº«u. CÃ¡c cá»¥m Ä‘Æ°á»£c Ä‘á»‹nh danh dá»±a trÃªn cÃ¡c yáº¿u tá»‘ xÃ¡c Ä‘á»‹nh trÆ°á»›c. VÃ­ dá»¥ á»Ÿ trong hÃ¬nh á»Ÿ trÃªn, cÃ¡c cá»¥m Ä‘Æ°á»£c Ä‘á»‹nh danh dá»±a vÃ o mÃ u sáº¯c cá»§a Ã¡o mÃ  ngÆ°á»i Ä‘Ã³ máº·c. Äiá»ƒm khÃ¡c biá»‡t á»Ÿ phÆ°Æ¡ng phÃ¡p nÃ y so vá»›i phÆ°Æ¡ng phÃ¡p á»Ÿ trÃªn lÃ  phÆ°Æ¡ng phÃ¡p á»Ÿ trÃªn lá»±a chá»n ngáº«u nhiÃªn má»™t sá»‘ cÃ¡c cÃ¡ thá»ƒ trong má»—i cá»¥m. CÃ²n phÆ°Æ¡ng phÃ¡p nÃ y sáº½ lá»±a chá»n ngáº«u nhiÃªn cÃ¡c cá»¥m, vÃ  chá»n háº¿t táº¥t cáº£ cÃ¡c cÃ¡c thá»ƒ trong cá»¥m Ä‘Ã³.\nMá»™t sá»‘ chiáº¿n lÆ°á»£c Ä‘á»ƒ lá»±a chá»n cá»¥m:\nSingle Stage Cluster Sampling: CÃ¡c cá»¥m Ä‘Æ°á»£c lá»±a chá»n ngáº«u nhiÃªn\nHÃ¬nh 3: Single Stage Cluster Sampling\nTwo Stage Cluster Sampling: á» phÆ°Æ¡ng phÃ¡p nÃ y, chÃºng ta sáº½ lá»±a chá»n ngáº«u nhiÃªn cÃ¡c cá»¥m, sau Ä‘Ã³, trong má»—i cá»¥m, chÃºng ta sáº½ lá»±a chá»n ngáº«u nhiÃªn cÃ¡c cÃ¡ thá»ƒ trong má»—i cá»¥m\nHÃ¬nh 4: Two Stage Cluster Sampling\nSystematic Clustering á» phÆ°Æ¡ng phÃ¡p nÃ y, viá»‡c lá»±a chá»n cÃ¡ thá»ƒ lÃ  cÃ³ quy luáº­t vÃ  khÃ´ng ngáº«u nhiÃªn, tá»« cÃ¡ thá»ƒ Ä‘áº§u tiÃªn. CÃ¡c cÃ¡ thá»ƒ cá»§a táº­p máº«u Ä‘Æ°á»£c chá»n ra tá»« táº­p quáº§n thá»ƒ dá»±a vÃ o má»™t quy luáº­t nÃ o Ä‘Ã³. Äáº§u tiÃªn, táº¥t cáº£ cÃ¡c cÃ¡ thá»ƒ trong táº­p quáº§n thá»ƒ pháº£i Ä‘Æ°á»£c xáº¯p xáº¿p cÃ³ thá»© tá»±. Sau Ä‘Ã³ chÃºng ta sáº½ lá»±a chá»n ngáº«u nhiÃªn cÃ¡ thá»ƒ Ä‘áº§u tiÃªn (má»—i cÃ¡ thá»ƒ Ä‘á»u cÃ³ xÃ¡c suáº¥t ngang nhau á»Ÿ Ä‘Ã¢y), vÃ  sá»­ dá»¥ng quy luáº­t nÃ o Ä‘Ã³ Ä‘á»ƒ rÃºt ra cÃ¡c cÃ¡ thá»ƒ tiáº¿p theo.\nHÃ¬nh 5: Systematic Clustering\nNhÆ° vÃ­ dá»¥ á»Ÿ trÃªn, chÃºng ta xáº¯p xáº¿p cÃ¡c nhÃ¢n váº­t Ã¡o vÃ ng, xanh, Ä‘á» ngáº«u nhiÃªn tuá»³ Ã½ theo sá»± lá»±a chá»n cá»§a ngÆ°á»i ta. Quy luáº­t lÃ  cá»© 4 ngÆ°á»i sáº½ láº¥y ngÆ°á»i cuá»‘i. áº¤n nÃºt ngáº«u nhiÃªn \u0026hellip; ta Ä‘Æ°á»£c sá»‘ 3. Váº­y lÃ  cÃ¡ thá»ƒ Ä‘áº§u tiÃªn lÃ  nhÃ¢n váº­t á»Ÿ vá»‹ trÃ­ sá»‘ 3, tiáº¿p theo sáº½ lÃ  nhÃ¢n váº­t á»Ÿ vá»‹ trÃ­ 7, 11, 15,19, 5, \u0026hellip;\nMulti-Stage Sampling PhÆ°Æ¡ng phÃ¡p nÃ y lÃ  sá»± káº¿t há»£p cá»§a má»™t hoáº·c nhiá»u phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c mÃ´ táº£ á»Ÿ trÃªn.\nQuáº§n thá»ƒ Ä‘Æ°á»£c chia thÃ nh nhiá»u cá»¥m (cluster) vÃ  má»—i cá»¥m Ä‘Æ°á»£c chia vÃ o tá»«ng nhÃ³m con (subgrop - strata) dá»±a trÃªn sá»± tÆ°Æ¡ng Ä‘á»“ng =\u0026gt; chÃºng ta Ä‘Æ°á»£c má»™t táº­p cÃ¡c cá»¥m con Ä‘Æ°á»£c gá»i lÃ  stratum. ChÃºng ta sáº½ lá»±a nhá»n má»™t hoáº·c má»™t vÃ i strata trong stratum. QuÃ¡ trÃ¬nh nÃ y sáº½ Ä‘Æ°á»£c láº·p Ä‘i láº·p láº¡i Ä‘áº¿n khi khÃ´ng cÃ²n cá»¥m nÃ o cÃ³ thá»ƒ phÃ¢n chia Ä‘Æ°á»£c ná»¯a.\nVÃ­ dá»¥, cÃ¡c quá»‘c gia cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n chia thÃ nh tá»«ng bang, thÃ nh phá»‘, thÃ nh thá»‹, nÃ´ng thÃ´n. VÃ  táº¥t cáº£ cÃ¡c khu vá»±c cÃ³ cÃ¹ng kÃ½ tá»± Ä‘áº§u cÃ³ thá»ƒ Ä‘Æ°á»£c gom láº¡i thÃ nh vá»›i nhau táº¡o thÃ nh má»™t strata.\nHÃ¬nh 6: Multi-Stage Sampling\nLáº¥y máº«u phi ngáº«u nhiÃªn Nhá»¯ng ká»¹ thuáº­t náº±m trong nhÃ³m nÃ y khÃ´ng sá»­ dá»¥ng hÃ m ngáº«u nhiÃªn. Ká»¹ thuáº­t nÃ y phá»¥ thuá»™c vÃ o kháº£ nÄƒng hiá»ƒu biáº¿t cá»§a cÃ¡c nhÃ  nghiÃªn cá»©u (researcher) trÃªn táº­p quáº§n thá»ƒ há» Ä‘ang cÃ³ Ä‘á»ƒ chá»n lá»±a cÃ¡ thá»ƒ cho táº­p máº«u. Káº¿t quáº£ cá»§a viá»‡c láº¥y máº«u cÃ³ thá»ƒ bá»‹ lá»‡ch.\nMá»™t sá»‘ phÆ°Æ¡ng phÃ¡p thuá»™c nhÃ³m nÃ y lÃ :\nConvenience Sampling\nPurposive Sampling\nQuota Sampling\nReferral /Snowball Sampling\nConvenience Sampling CÃ¡c cÃ¡ thá»ƒ Ä‘Æ°á»£c chá»n dá»±a trÃªn tÃ­nh kháº£ dá»¥ng cá»§a dá»¯ liá»‡u. PhÆ°Æ¡ng phÃ¡p nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng khi tÃ­nh kháº£ dá»¥ng cá»§a dá»¯ liá»‡u lÃ  hiáº¿m vÃ  tá»‘n kÃ©m. Do váº­y, chÃºng ta sáº½ lá»±a chá»n máº«u dá»±a trÃªn sá»± tiá»‡n lá»£i.\nVÃ­ dá»¥, CÃ¡c nhÃ  nghiÃªn cá»©u thÆ°á»ng hay sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y trong cÃ¡c giai Ä‘oáº¡n Ä‘áº§u cá»§a cÃ¡c nghiÃªn cá»©u kháº£o sÃ¡t, vÃ¬ nÃ³ dá»… dÃ ng, nhanh chÃ³ng vÃ  cho ra káº¿t quáº£ nhanh.\nPurposive Sampling PhÆ°Æ¡ng phÃ¡p láº¥y máº«u nÃ y dá»±a trÃªn má»¥c Ä‘Ã­ch cá»§a nghiÃªn cá»©u. Chá»‰ chá»n ra nhá»¯ng cÃ¡ thá»ƒ trong quáº§n thá»ƒ phÃ¹ há»£p nháº¥t vá»›i má»¥c Ä‘Ã­ch nghiÃªn cá»©u .\nVÃ­ dá»¥: Náº¿u chÃºng ta muá»‘n hiá»ƒu Ä‘Æ°á»£c \u0026ldquo;suy nghÄ© cá»§a nhá»¯ng ngÆ°á»i quan tÃ¢m Ä‘áº¿n báº±ng tháº¡c sá»¹\u0026rdquo; thÃ¬ tiÃªu chÃ­ lá»±a chá»n cÃ¡ thá»ƒ lÃ  nhá»¯ng ngÆ°á»i say yes trong cÃ¢u há»i \u0026ldquo;báº¡n cÃ³ há»©ng thÃº vá»›i báº­c tháº¡c sá»¹ trong lÄ©nh vá»±c \u0026hellip; khÃ´ng?\u0026rdquo;. Nhá»¯ng ngÆ°á»i say \u0026ldquo;No\u0026rdquo; sáº½ bá»‹ loáº¡i khá»i táº­p máº«u cá»§a chÃºng ta.\nQuota Sampling PhÆ°Æ¡ng phÃ¡p láº¥y máº«u nÃ y phá»¥ thuá»™c vÃ o má»™t sá»‘ tiÃªu chuáº©n thiáº¿t láº­p tá»« trÆ°á»›c. Tá»· lá»‡ cá»§a cÃ¡c nhÃ³m cÃ¡ thá»ƒ trong táº­p máº«u pháº£i giá»‘ng háº¿t trong táº­p quáº§n thá»ƒ. CÃ¡c cÃ¡ thá»ƒ Ä‘Æ°á»£c chá»n cho Ä‘áº¿n khi chÃºng Ä‘áº¡t Ä‘Ãºng tá»· lá»‡ cá»§a má»™t loáº¡i dá»¯ liá»‡u.\nVÃ­ dá»¥: Giáº£ sá»­ chÃºng ta biáº¿t ráº±ng trÃªn trÃ¡i Ä‘áº¥t nÃ y cÃ³ 6 tá»· ngÆ°á»i, vÃ  45% trong sá»‘ Ä‘Ã³ lÃ  nam giá»›i vÃ  55% lÃ  ná»¯ giá»›i. Váº­y thÃ¬ chÃºng ta sáº½ láº¥y máº«u lÃ m sao cho táº­p máº«u chÃºng ta cÅ©ng pháº£n Ã¡nh sá»‘ Ä‘Ã³, nghÄ©a lÃ  trong táº­p máº«u cÃ³ 1000 ngÆ°á»i thÃ¬ 45% trong sá»‘ 1000 ngÆ°á»i Ä‘Ã³ pháº£i lÃ  nam vÃ  55% trong sá»‘ 1000 ngÆ°á»i Ä‘Ã³ lÃ  ná»¯.\nReferral /Snowball Sampling Ká»¹ thuáº­t nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng khi chÃºng ta khÃ´ng biáº¿t gÃ¬ vá» táº­p quáº§n thá»ƒ hoáº·c táº­p quáº§n thá»ƒ hiáº¿m. LÃºc Ä‘Ã³ chÃºng ta sáº½ tÃ¬m ra cÃ¡ thá»ƒ Ä‘áº§u tiÃªn trong quáº§n thá»ƒ, rá»“i nhá» cÃ¡ thá»ƒ Ä‘áº§u tiÃªn Ä‘Ã³ gá»£i Ã½ cÃ¡c cÃ¡ thá»ƒ tiáº¿p theo vá»›i Ä‘iá»u kiá»‡n thoáº£ nhu cáº«u láº¥y máº«u cá»§a nghiÃªn cá»©u. Cá»© tiáº¿p tá»¥c nhÆ° váº­y thÃ¬ kÃ­ch thÆ°á»›c cá»§a táº­p máº«u sáº½ tÄƒng lÃªn theo cáº¥p nhÃ¢n nhÆ° kÃ­ch thÆ°á»›c quáº£ quáº£ cáº§u tuyáº¿t, nÃªn ká»¹ thuáº­t nÃ y cÃ²n cÃ³ tÃªn gá»i khÃ¡c lÃ  Snowball Sampling.\nHÃ¬nh 7: VÃ­ dá»¥ vá» Snowball Sampling\nVÃ­ dá»¥: Trong tÃ¬nh huá»‘ng, ngá»¯ cáº£nh lÃ  báº¡n muá»‘n lÃ m 1 bÃ i kháº£o sÃ¡t vá» nhá»¯ng ngÆ°á»i bá»‹ nhiá»…m HIV, nhá»¯ng ngÆ°á»i nÃ y thÆ°á»ng cÃ³ khuynh hÆ°á»›ng khÃ´ng cá»Ÿi má»Ÿ á»Ÿ má»©c Ä‘á»™ cÃ´ng cá»™ng vÃ  khÃ³ cho chÃºng ta tiáº¿p cáº­n Ä‘á»ƒ thu tháº­p thÃ´ng tin trá»±c tiáº¿p tá»« há».\nNhÃ³m kháº£o sÃ¡t sáº½ tiáº¿n hÃ nh liÃªn há»‡ 1 ngÆ°á»i nÃ o Ä‘Ã³ mÃ  há» biáº¿t hoáº·c ngÆ°á»i nÃ o Ä‘Ã³ xung phong lÃ m cáº§u ná»‘i vá»›i cÃ¡c ngÆ°á»i bá»‹ nhiá»…m vÃ  thu tháº­p thÃ´ng tin tá»« há» (nhá»¯ng ngÆ°á»i bá»‹ nhiá»…n tin tÆ°á»Ÿng ngÆ°á»i Ä‘Æ°á»£c xung phong hÆ¡n nhÃ³m kháº£o sÃ¡t. VÃ¬ nhÃ³m kháº£o sÃ¡t lÃ  ngÆ°á»i láº¡).\nHi vá»ng sau bÃ i viáº¿t nÃ y, cÃ¡c báº¡n cÃ³ thÃªm nhiá»u Ã½ tÆ°á»Ÿng hÆ¡n ná»¯a vá» viá»‡c láº¥y máº«u vÃ  cÃ¡c cÃ¡ch Ä‘á»ƒ láº¥y máº«u trong á»©ng dá»¥ng thá»±c táº¿.\nBÃ i viáº¿t Ä‘Æ°á»£c lÆ°á»£c dá»‹ch vÃ  má»™t sá»‘ hÃ¬nh áº£nh Ä‘Æ°á»£c láº¥y tá»« nguá»“n https://towardsdatascience.com/sampling-techniques-a4e34111d808\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ nhá»¯ng bÃ i viáº¿t tiáº¿p theo.\n","date":"May 4, 2019","img":"","permalink":"/blog/2019-05-04-sampling-method/","series":null,"tags":["machine learning","deep learning","sampleing","Probability Sampling","non-probability sampling"],"title":"CÃ¡c Ká»¹ Thuáº­t Láº¥y Máº«u"},{"categories":null,"content":" 1.\tPhÃ¢n nhÃ³m dá»±a trÃªn phÆ°Æ¡ng thá»©c há»c a.\tHá»c cÃ³ giÃ¡m sÃ¡t PhÃ¢n lá»›p Há»“i quy b. Há»c khÃ´ng giÃ¡m sÃ¡t PhÃ¢n cá»¥m Luáº­t káº¿t há»£p c.\tHá»c bÃ¡n giÃ¡m sÃ¡t d.\tHá»c tÄƒng cÆ°á»ng 2.\tPhÃ¢n nhÃ³m dá»±a trÃªn sá»± tÆ°Æ¡ng Ä‘á»“ng a.\tCÃ¡c thuáº­t toÃ¡n há»“i quy (Regression Algorithms) b.\tThuáº­t toÃ¡n dá»±a trÃªn máº«u (Instance-based Algorithms) c.\tThuáº­t toÃ¡n chuáº©n hoÃ¡ (Regularization Algorithms) d.\tThuáº­t toÃ¡n cÃ¢y quyáº¿t Ä‘á»‹nh (Decision Tree Algorithms) e.\tThuáº­t toÃ¡n Bayes (Bayesian Algorithms) f.\tThuáº­t toÃ¡n phÃ¢n cá»¥m (Clustering Algorithms) g.\tCÃ¡c thuáº­t toÃ¡n luáº­t káº¿t há»£p (Association Rule Learning Algorithms) h.\tThuáº­t toÃ¡n máº¡ng nÆ¡ron nhÃ¢n táº¡o (Artificial Neural Network Algorithms) i.\tThuáº­t toÃ¡n há»c sÃ¢u (Deep Learning Algorithms) j.\tNhÃ³m thuáº­t toÃ¡n Giáº£m chiá»u dá»¯ liá»‡u (Dimensionality Reduction Algorithms) k.\tThuáº­t toÃ¡n táº­p há»£p (Ensemble Algorithms) l.\tCÃ¡c thuáº­t toÃ¡n khÃ¡c á» bÃ i trÆ°á»›c mÃ¬nh Ä‘Ã£ trÃ¬nh bÃ y Ä‘á»‹nh nghÄ©a vÃ  má»™t sá»‘ á»©ng dá»¥ng cá»§a MÃ¡y há»c (Machine Learning â€“ ML), phÃ¢n biá»‡t ML vá»›i TrÃ­ tuá»‡ nhÃ¢n táº¡o (Artificial Intelligence â€“ AI) cÅ©ng nhÆ° má»‘i quan há»‡ giá»¯a AI, ML vÃ  Big Data. Tá»« bÃ i viáº¿t nÃ y trá»Ÿ Ä‘i mÃ¬nh sáº½ táº­p trung viáº¿t vá» ML, cÃ¡c thuáº­t toÃ¡n, cÃ¡ch sá»­ dá»¥ng cÃ´ng cá»¥ kÃ¨m theo má»™t vÃ i demo nhá» giÃºp báº¡n Ä‘á»c dá»… hÃ¬nh dung vÃ  Ã¡p dá»¥ng. Äá»ƒ má»Ÿ Ä‘áº§u cho chuá»—i bÃ i viáº¿t sáº¯p tá»›i, hÃ´m nay mÃ¬nh sáº½ trÃ¬nh bÃ y cÃ¡ch phÃ¢n nhÃ³m cÃ¡c thuáº­t toÃ¡n ML.\nVá»›i Ä‘a sá»‘ má»i ngÆ°á»i, trÆ°á»›c khi báº¯t Ä‘áº§u giáº£i quyáº¿t má»™t váº¥n Ä‘á» nÃ o Ä‘Ã³, viá»‡c Ä‘áº§u tiÃªn lÃ  chÃºng ta sáº½ tÃ¬m hiá»ƒu xem liá»‡u cÃ³ ai Ä‘Ã£ gáº·p váº¥n Ä‘á» nÃ y hoáº·c váº¥n Ä‘á» tÆ°Æ¡ng tá»± nhÆ° váº­y hay khÃ´ng vÃ  cÃ¡ch há» giáº£i quyáº¿t tháº¿ nÃ o. Sau khi náº¯m Ä‘Æ°á»£c thÃ´ng tin khÃ¡i quÃ¡t, cÃ´ng viá»‡c káº¿ tiáº¿p lÃ  chá»n lá»±a vÃ  Ä‘iá»u chá»‰nh giáº£i phÃ¡p sao cho phÃ¹ há»£p vá»›i váº¥n Ä‘á» cá»§a báº£n thÃ¢n. Trong trÆ°á»ng há»£p váº¥n Ä‘á» cÃ²n quÃ¡ má»›i máº» thÃ¬ chÃºng ta má»›i pháº£i báº¯t tay lÃ m tá»« Ä‘áº§u, Ä‘iá»u nÃ y háº§u nhÆ° ráº¥t hiáº¿m, Ä‘áº·c biá»‡t lÃ  trong thá»i Ä‘áº¡i cÃ´ng nghá»‡ nÃ y, khi mÃ  chá»‰ báº±ng má»™t cÃº nháº¥p chuá»™t, hÃ ng ngÃ n thÃ´ng tin, tÆ° liá»‡u vá» Ä‘á» tÃ i chÃºng ta quan tÃ¢m sáº½ xuáº¥t hiá»‡n. CÅ©ng giá»‘ng nhÆ° tháº¿, ML hiá»‡n Ä‘Ã£ Ä‘Æ°á»£c nghiÃªn cá»©u rá»™ng kháº¯p, ráº¥t nhiá»u cÃ´ng trÃ¬nh khoa há»c, thuáº­t toÃ¡n Ä‘Æ°á»£c cho ra Ä‘á»i. Vá»›i ngÆ°á»i má»›i báº¯t Ä‘áº§u mÃ  nÃ³i thÃ¬ chÃºng ta chÆ°a cáº§n pháº£i lÃ m gÃ¬ cáº£ ngoÃ i viá»‡c náº¯m Ä‘Æ°á»£c cÃ¡c thuáº­t toÃ¡n cÆ¡ báº£n, Ä‘áº·c Ä‘iá»ƒm cá»§a chÃºng Ä‘á»ƒ khi Ä‘á»‘i diá»‡n vá»›i má»™t bÃ i toÃ¡n cá»¥ thá»ƒ trong thá»±c táº¿ chÃºng ta cÃ³ thá»ƒ biáº¿t Ä‘Æ°á»£c mÃ¬nh nÃªn lá»±a chá»n thuáº­t toÃ¡n nÃ o cho phÃ¹ há»£p Ä‘Ã£ lÃ  Ä‘iá»u ráº¥t tá»‘t rá»“i.\nMáº·c dÃ¹ cÃ³ ráº¥t nhiá»u thuáº­t toÃ¡n há»c nhÆ°ng dá»±a vÃ o phÆ°Æ¡ng thá»©c há»c (learning style) hoáº·c sá»± tÆ°Æ¡ng Ä‘á»“ng (similarity) vá» hÃ¬nh thá»©c hay chá»©c nÄƒng mÃ  chÃºng cÃ³ thá»ƒ Ä‘Æ°á»£c gom thÃ nh tá»«ng nhÃ³m. Sau Ä‘Ã¢y mÃ¬nh sáº½ trÃ¬nh bÃ y tá»•ng quan cáº£ hai cÃ¡ch phÃ¢n nhÃ³m thuáº­t toÃ¡n há»c nÃ y.\n1.\tPhÃ¢n nhÃ³m dá»±a trÃªn phÆ°Æ¡ng thá»©c há»c XÃ©t theo phÆ°Æ¡ng thá»©c há»c, cÃ¡c thuáº­t toÃ¡n ML Ä‘Æ°á»£c chia lÃ m bá»‘n nhÃ³m, bao gá»“m â€œHá»c cÃ³ giÃ¡m sÃ¡tâ€ (Supervised Learning), â€œHá»c khÃ´ng giÃ¡m sÃ¡tâ€ (Unsupervised Learning), â€œHá»c bÃ¡n giÃ¡m sÃ¡tâ€ (hay há»c káº¿t há»£p - Semi-supervised Learning) vÃ  â€œHá»c tÄƒng cÆ°á»ngâ€ (Reinforcement Learning).\na.\tHá»c cÃ³ giÃ¡m sÃ¡t Há»c cÃ³ giÃ¡m sÃ¡t hay cÃ²n gá»i lÃ  há»c cÃ³ tháº§y lÃ  thuáº­t toÃ¡n dá»± Ä‘oÃ¡n nhÃ£n (label)/Ä‘áº§u ra (output) cá»§a má»™t dá»¯ liá»‡u má»›i dá»±a trÃªn táº­p dá»¯ liá»‡u huáº¥n luyá»‡n mÃ  trong Ä‘Ã³ má»—i máº«u dá»¯ liá»‡u Ä‘á»u Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n nhÆ° minh hoáº¡ á»Ÿ HÃ¬nh 1. Khi Ä‘Ã³, thÃ´ng qua má»™t quÃ¡ trÃ¬nh huáº¥n luyá»‡n, má»™t mÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c xÃ¢y dá»±ng Ä‘á»ƒ cho ra cÃ¡c dá»± Ä‘oÃ¡n vÃ  khi cÃ¡c dá»± Ä‘oÃ¡n bá»‹ sai thÃ¬ mÃ´ hÃ¬nh nÃ y sáº½ Ä‘Æ°á»£c tinh chá»‰nh láº¡i. Viá»‡c huáº¥n luyá»‡n sáº½ tiáº¿p tá»¥c cho Ä‘áº¿n khi mÃ´ hÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c má»©c Ä‘á»™ chÃ­nh xÃ¡c mong muá»‘n trÃªn dá»¯ liá»‡u huáº¥n luyá»‡n. Äiá»u nÃ y cÅ©ng giá»‘ng nhÆ° khi chÃºng ta Ä‘i há»c trÃªn lá»›p, ta biáº¿t cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c tá»« giÃ¡o viÃªn (táº­p dá»¯ liá»‡u cÃ³ nhÃ£n) vÃ  tá»« Ä‘Ã³ ta sáº½ sá»­a chá»¯a náº¿u lÃ m sai. Há»c cÃ³ giÃ¡m sÃ¡t lÃ  nhÃ³m phá»• biáº¿n nháº¥t trong cÃ¡c thuáº­t toÃ¡n ML.\nHÃ¬nh 1: Supervised Learning Algorithms\nMá»™t cÃ¡ch toÃ¡n há»c, há»c cÃ³ giÃ¡m sÃ¡t lÃ  khi chÃºng ra cÃ³ má»™t táº­p há»£p biáº¿n Ä‘áº§u vÃ o $ X={x_1,x_2,â€¦,x_N} $ vÃ  má»™t táº­p há»£p nhÃ£n tÆ°Æ¡ng á»©ng $ Y={y_1,y_2,â€¦,y_N} $, trong Ä‘Ã³ $ x_i$, $y_i $ lÃ  cÃ¡c vector. CÃ¡c cáº·p dá»¯ liá»‡u biáº¿t trÆ°á»›c $( x_i, y_i ) \\in X \\times Y $ Ä‘Æ°á»£c gá»i lÃ  táº­p dá»¯ liá»‡u huáº¥n luyá»‡n (training data). Tá»« táº­p dá»¯ liá»‡u huáº¥n luyá»‡n nÃ y, chÃºng ta cáº§n táº¡o ra má»™t hÃ m sá»‘ Ã¡nh xáº¡ má»—i pháº§n tá»­ tá»« táº­p X sang má»™t pháº§n tá»­ (xáº¥p xá»‰) tÆ°Æ¡ng á»©ng cá»§a táº­p Y:\n$$ y_i \\approx f(x_i), \\forall i=1, 2, â€¦, N $$\nMá»¥c Ä‘Ã­ch lÃ  xáº¥p xá»‰ hÃ m sá»‘ $f$ tháº­t tá»‘t Ä‘á»ƒ khi cÃ³ má»™t dá»¯ liá»‡u x má»›i, chÃºng ta cÃ³ thá»ƒ tÃ­nh Ä‘Æ°á»£c nhÃ£n tÆ°Æ¡ng á»©ng cá»§a nÃ³ $y=f(x)$.\nVÃ­ dá»¥: Trong nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay, ta cÃ³ áº£nh cá»§a hÃ ng nghÃ¬n trÆ°á»ng há»£p á»©ng vá»›i má»—i chá»¯ sá»‘ Ä‘Æ°á»£c viáº¿t bá»Ÿi nhiá»u ngÆ°á»i khÃ¡c nhau. Ta Ä‘Æ°a cÃ¡c bá»©c áº£nh nÃ y vÃ o má»™t thuáº­t toÃ¡n há»c vÃ  chá»‰ cho nÃ³ biáº¿t â€œmá»—i bá»©c áº£nh tÆ°Æ¡ng á»©ng vá»›i chá»¯ sá»‘ nÃ oâ€. Sau khi thuáº­t toÃ¡n táº¡o ra má»™t mÃ´ hÃ¬nh, tá»©c lÃ  má»™t hÃ m sá»‘ nháº­n Ä‘áº§u vÃ o lÃ  má»™t bá»©c áº£nh vÃ  cho ra káº¿t quáº£ lÃ  má»™t chá»¯ sá»‘. Khi nháº­n Ä‘Æ°á»£c má»™t bá»©c áº£nh má»›i mÃ  mÃ´ hÃ¬nh â€œchÆ°a tá»«ng gáº·p quaâ€ vÃ  nÃ³ sáº½ dá»± Ä‘oÃ¡n xem bá»©c áº£nh Ä‘Ã³ tÆ°Æ¡ng á»©ng vá»›i chá»¯ sá»‘ nÃ o.\nHÃ¬nh 2: áº¢nh minh hoáº¡ cho táº­p dá»¯ liá»‡u chá»¯ sá»‘ viáº¿t tay - MNIST\nÄá»‘i vá»›i nhá»¯ng ai sá»­ dá»¥ng máº¡ng xÃ£ há»™i Facebook thÃ¬ khÃ¡ quen thuá»™c vá»›i tÃ­nh nÄƒng phÃ¡t hiá»‡n khuÃ´n máº·t trong má»™t bá»©c áº£nh, báº£n cháº¥t cá»§a thuáº­t toÃ¡n dÃ² tÃ¬m cÃ¡c khuÃ´n máº·t nÃ y lÃ  má»™t thuáº­t toÃ¡n há»c cÃ³ giÃ¡m sÃ¡t vá»›i táº­p huáº¥n luyá»‡n lÃ  vÃ´ sá»‘ áº£nh Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n lÃ  máº·t ngÆ°á»i hay khÃ´ng pháº£i máº·t ngÆ°á»i.\nCÃ¡c thuáº­t toÃ¡n há»c cÃ³ giÃ¡m sÃ¡t cÃ²n Ä‘Æ°á»£c phÃ¢n ra thÃ nh hai loáº¡i chÃ­nh lÃ  phÃ¢n lá»›p (Classification) vÃ  há»“i quy (Regression).\nPhÃ¢n lá»›p Má»™t bÃ i toÃ¡n Ä‘Æ°á»£c gá»i lÃ  phÃ¢n lá»›p náº¿u cÃ¡c nhÃ£n cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o Ä‘Æ°á»£c chia thÃ nh má»™t sá»‘ há»¯u háº¡n lá»›p (miá»n giÃ¡ trá»‹ lÃ  rá»i ráº¡c). Cháº³ng háº¡n nhÆ° tÃ­nh nÄƒng xÃ¡c Ä‘á»‹nh xem má»™t email cÃ³ pháº£i lÃ  spam hay khÃ´ng cá»§a Gmail; xÃ¡c Ä‘á»‹nh xem hÃ¬nh áº£nh cá»§a con váº­t lÃ  chÃ³ hay mÃ¨o. Hoáº·c vÃ­ dá»¥ nháº­n dáº¡ng kÃ½ sá»‘ viáº¿t tay á»Ÿ trÃªn cÅ©ng thuá»™c bÃ i toÃ¡n phÃ¢n lá»›p, bao gá»“m mÆ°á»i lá»›p á»©ng vá»›i cÃ¡c sá»‘ tá»« 0 Ä‘áº¿n 9. TÆ°Æ¡ng tá»± cho vÃ­ dá»¥ nháº­n dáº¡ng khuÃ´n máº·t vá»›i hai lá»›p lÃ  pháº£i vÃ  khÃ´ng pháº£i khuÃ´n máº·t, â€¦\nHá»“i quy Má»™t bÃ i toÃ¡n Ä‘Æ°á»£c xem lÃ  há»“i quy náº¿u nhÃ£n khÃ´ng Ä‘Æ°á»£c chia thÃ nh cÃ¡c nhÃ³m mÃ  lÃ  má»™t giÃ¡ trá»‹ thá»±c cá»¥ thá»ƒ (miá»n giÃ¡ trá»‹ lÃ  liÃªn tá»¥c). Háº§u háº¿t cÃ¡c bÃ i toÃ¡n dá»± bÃ¡o (giÃ¡ cá»• phiáº¿u, giÃ¡ nhÃ , â€¦) thÆ°á»ng Ä‘Æ°á»£c xáº¿p vÃ o bÃ i toÃ¡n há»“i quy. VÃ­ nhÆ°, náº¿u má»™t cÄƒn nhÃ  rá»™ng 150 m^2, cÃ³ 7 phÃ²ng vÃ  cÃ¡ch trung tÃ¢m thÃ nh phá»‘ 10 km sáº½ cÃ³ giÃ¡ lÃ  bao nhiÃªu? LÃºc nÃ y káº¿t quáº£ dá»± Ä‘oÃ¡n sáº½ lÃ  má»™t sá»‘ thá»±c.\nNáº¿u nhÆ° phÃ¡t hiá»‡n khuÃ´n máº·t lÃ  bÃ i toÃ¡n phÃ¢n lá»›p thÃ¬ dá»± Ä‘oÃ¡n tuá»•i lÃ  bÃ i toÃ¡n há»“i quy. Tuy nhiÃªn dá»± Ä‘oÃ¡n tuá»•i cÅ©ng cÃ³ thá»ƒ coi lÃ  phÃ¢n lá»›p náº¿u ta cho tuá»•i lÃ  má»™t sá»‘ nguyÃªn dÆ°Æ¡ng N vÃ  khi Ä‘Ã³ ta sáº½ cÃ³ N lá»›p khÃ¡c nhau tÃ­nh tá»« 1. Má»™t sá»‘ thuáº­t toÃ¡n ná»•i tiáº¿ng thuá»™c vá» nhÃ³m há»c cÃ³ giÃ¡m sÃ¡t nhÆ°:\nPhÃ¢n lá»›p: k-Nearest Neighbors, máº¡ng nÆ¡ron nhÃ¢n táº¡o, SVM, â€¦\nHá»“i quy: Linear Regression, Logistic Regression, â€¦\nb. Há»c khÃ´ng giÃ¡m sÃ¡t TrÃ¡i vá»›i Supervised learning, há»c khÃ´ng giÃ¡m sÃ¡t hay há»c khÃ´ng tháº§y lÃ  thuáº­t toÃ¡n dá»± Ä‘oÃ¡n nhÃ£n cá»§a má»™t dá»¯ liá»‡u má»›i dá»±a trÃªn táº­p dá»¯ liá»‡u huáº¥n luyá»‡n mÃ  trong Ä‘Ã³ táº¥t cáº£ cÃ¡c máº«u dá»¯ liá»‡u Ä‘á»u chÆ°a Ä‘Æ°á»£c gÃ¡n nhÃ£n hay nÃ³i cÃ¡ch khÃ¡c lÃ  ta khÃ´ng biáº¿t cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c cho má»—i dá»¯ liá»‡u Ä‘áº§u vÃ o nhÆ° minh hoáº¡ á»Ÿ HÃ¬nh 3. Äiá»u nÃ y cÅ©ng giá»‘ng nhÆ° khi ta há»c mÃ  khÃ´ng cÃ³ tháº§y cÃ´, sáº½ khÃ´ng ai cho ta biáº¿t Ä‘Ã¡p Ã¡n Ä‘Ãºng lÃ  gÃ¬.\nHÃ¬nh 3: Unsupervised Learning Algorithms\nKhi Ä‘Ã³, má»¥c tiÃªu cá»§a thuáº­t toÃ¡n unsupervised learning khÃ´ng pháº£i lÃ  tÃ¬m Ä‘áº§u ra chÃ­nh xÃ¡c mÃ  sáº½ hÆ°á»›ng tá»›i viá»‡c tÃ¬m ra cáº¥u trÃºc hoáº·c sá»± liÃªn há»‡ trong dá»¯ liá»‡u Ä‘á»ƒ thá»±c hiá»‡n má»™t cÃ´ng viá»‡c nÃ o Ä‘Ã³, vÃ­ nhÆ° gom cá»¥m (clustering) hoáº·c giáº£m sá»‘ chiá»u cá»§a dá»¯ liá»‡u (dimension reduction) Ä‘á»ƒ thuáº­n tiá»‡n trong viá»‡c lÆ°u trá»¯ vÃ  tÃ­nh toÃ¡n.\nCÃ¡c bÃ i toÃ¡n Unsupervised learning tiáº¿p tá»¥c Ä‘Æ°á»£c chia nhá» thÃ nh hai loáº¡i lÃ  phÃ¢n cá»¥m (Clustering) vÃ  luáº­t káº¿t há»£p (Association Rule).\nPhÃ¢n cá»¥m Má»™t bÃ i toÃ¡n phÃ¢n cá»¥m / phÃ¢n nhÃ³m toÃ n bá»™ dá»¯ liá»‡u X thÃ nh cÃ¡c nhÃ³m/cá»¥m nhá» dá»±a trÃªn sá»± liÃªn quan giá»¯a cÃ¡c dá»¯ liá»‡u trong má»—i nhÃ³m. Cháº³ng háº¡n nhÆ° phÃ¢n nhÃ³m khÃ¡ch hÃ ng dá»±a vÃ o Ä‘á»™ tuá»•i, giá»›i tÃ­nh. Äiá»u nÃ y cÅ©ng giá»‘ng nhÆ° viá»‡c ta Ä‘Æ°a cho má»™t Ä‘á»©a tráº» ráº¥t nhiá»u máº£nh ghÃ©p vá»›i cÃ¡c hÃ¬nh dáº¡ng vÃ  mÃ u sáº¯c khÃ¡c nhau, cÃ³ thá»ƒ lÃ  tam giÃ¡c, vuÃ´ng, trÃ²n vá»›i mÃ u xanh, Ä‘á», tÃ­m, vÃ ng, sau Ä‘Ã³ yÃªu cáº§u tráº» phÃ¢n chÃºng thÃ nh tá»«ng nhÃ³m. Máº·c dÃ¹ ta khÃ´ng dáº¡y tráº» máº£nh nÃ o tÆ°Æ¡ng á»©ng vá»›i hÃ¬nh nÃ o hoáº·c mÃ u nÃ o, nhÆ°ng nhiá»u kháº£ nÄƒng tráº» váº«n cÃ³ thá»ƒ phÃ¢n loáº¡i cÃ¡c máº£nh ghÃ©p theo mÃ u sáº¯c hoáº·c hÃ¬nh dáº¡ng.\nLuáº­t káº¿t há»£p LÃ  bÃ i toÃ¡n mÃ  khi chÃºng ta muá»‘n khÃ¡m phÃ¡ ra má»™t quy luáº­t dá»±a trÃªn nhiá»u dá»¯ liá»‡u cho trÆ°á»›c. VÃ­ nhÆ° nhá»¯ng khÃ¡ch hÃ ng mua máº·t hÃ ng nÃ y sáº½ mua thÃªm máº·t hÃ ng kia; hoáº·c khan giáº£ xem phim nÃ y sáº½ cÃ³ xu hÆ°á»›ng thÃ­ch xem phim kia, dá»±a vÃ o Ä‘Ã³ ta cÃ³ thá»ƒ xÃ¢y dá»±ng nhá»¯ng há»‡ thá»‘ng gá»£i Ã½ khÃ¡ch hÃ ng (Recommendation System) nháº±m thÃºc Ä‘áº©y nhu cáº§u mua sáº¯m hoáº·c xem phim\u0026hellip;.\nMá»™t sá»‘ thuáº­t toÃ¡n thuá»™c nhÃ³m há»c khÃ´ng giÃ¡m sÃ¡t nhÆ° Apriori (Association Rule), k-Means (Clustering), â€¦\nc.\tHá»c bÃ¡n giÃ¡m sÃ¡t LÃ  bÃ i toÃ¡n mÃ  khi táº­p dá»¯ liá»‡u Ä‘áº§u vÃ o X lÃ  há»—n há»£p cÃ¡c máº«u cÃ³ nhÃ£n vÃ  khÃ´ng cÃ³ nhÃ£n, trong Ä‘Ã³ sá»‘ lÆ°á»£ng cÃ³ nhÃ£n chá»‰ chiáº¿m má»™t pháº§n nhá» nhÆ° minh hoáº¡ á»Ÿ HÃ¬nh 4.\nPháº§n lá»›n cÃ¡c bÃ i toÃ¡n thá»±c táº¿ cá»§a ML thuá»™c nhÃ³m nÃ y vÃ¬ viá»‡c thu tháº­p dá»¯ liá»‡u cÃ³ nhÃ£n tá»‘n ráº¥t nhiá»u thá»i gian vÃ  cÃ³ chi phÃ­ cao. Ráº¥t nhiá»u loáº¡i dá»¯ liá»‡u tháº­m chÃ­ cáº§n pháº£i cÃ³ chuyÃªn gia má»›i gÃ¡n nhÃ£n Ä‘Æ°á»£c, cháº³ng háº¡n nhÆ° áº£nh y há»c hoáº·c cÃ¡c cáº·p cÃ¢u song ngá»¯. NgÆ°á»£c láº¡i, dá»¯ liá»‡u chÆ°a cÃ³ nhÃ£n cÃ³ thá»ƒ Ä‘Æ°á»£c thu tháº­p vá»›i chi phÃ­ tháº¥p tá»« internet.\nHÃ¬nh 4: Semi-supervised Learning Algorithms\nVá»›i bÃ i toÃ¡n nÃ y, mÃ´ hÃ¬nh pháº£i tÃ¬m hiá»ƒu cÃ¡c cáº¥u trÃºc Ä‘á»ƒ tá»• chá»©c dá»¯ liá»‡u cÅ©ng nhÆ° Ä‘Æ°a ra dá»± Ä‘oÃ¡n. VÃ¬ Ä‘áº·c Ä‘iá»ƒm trung gian nÃªn ta cÃ³ thá»ƒ sá»­ dá»¥ng unsupervised learning Ä‘á»ƒ khÃ¡m phÃ¡ vÃ  tÃ¬m hiá»ƒu cáº¥u trÃºc trong dá»¯ liá»‡u Ä‘áº§u vÃ o, Ä‘á»“ng thá»i sá»­ dá»¥ng supervised learning Ä‘á»ƒ dá»± Ä‘oÃ¡n cho dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c gÃ¡n nhÃ£n. Sau Ä‘Ã³ Ä‘Æ°a dá»¯ liá»‡u vá»«a dá»± Ä‘oÃ¡n trá»Ÿ láº¡i lÃ m dá»¯ liá»‡u huáº¥n luyá»‡n cho supervised learning vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh sau khi huáº¥n luyá»‡n Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n vá» dá»¯ liá»‡u má»›i.\nMá»™t sá»‘ thuáº­t toÃ¡n há»c tÄƒng cÆ°á»ng nhÆ°: Self Training, Generative models, S3VMs, Graph-Based Algorithms, Multiview Algorithms, â€¦\nd.\tHá»c tÄƒng cÆ°á»ng Há»c tÄƒng tÆ°á»ng hay há»c cá»§ng cá»‘ lÃ  bÃ i toÃ¡n giÃºp cho má»™t há»‡ thá»‘ng tá»± Ä‘á»™ng xÃ¡c Ä‘á»‹nh hÃ nh vi dá»±a trÃªn hoÃ n cáº£nh Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c lá»£i Ã­ch cao nháº¥t. Hiá»‡n táº¡i, reinforcement learning chá»§ yáº¿u Ä‘Æ°á»£c Ã¡p dá»¥ng vÃ o LÃ½ Thuyáº¿t TrÃ² ChÆ¡i (Game Theory), cÃ¡c thuáº­t toÃ¡n cáº§n xÃ¡c Ä‘á»‹nh nÆ°á»›c Ä‘i tiáº¿p theo Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»ƒm sá»‘ cao nháº¥t. HÃ¬nh 5 lÃ  má»™t vÃ­ dá»¥ Ä‘Æ¡n giáº£n sá»­ dá»¥ng há»c tÄƒng cÆ°á»ng.\nHÃ¬nh 5: Minh hoáº¡ cho há»c tÄƒng cÆ°á»ng Ä‘Æ°á»£c Ã¡p dá»¥ng trong lÃ½ thuyáº¿t trÃ² chÆ¡i.\nAlphaGo - má»™t pháº§n má»m chÆ¡i cá» vÃ¢y trÃªn mÃ¡y tÃ­nh Ä‘Æ°á»£c xÃ¢y dá»±ng bá»Ÿi Google DeepMind hay chÆ°Æ¡ng trÃ¬nh dáº¡y mÃ¡y tÃ­nh chÆ¡i game Mario lÃ  nhá»¯ng á»©ng dá»¥ng sá»­ dá»¥ng há»c tÄƒng cÆ°á»ng.\nCá» váº­y Ä‘Æ°á»£c xem lÃ  trÃ² chÆ¡i cÃ³ Ä‘á»™ phá»©c táº¡p cá»±c ká»³ cao vá»›i tá»•ng sá»‘ nÆ°á»›c Ä‘i lÃ  xáº¥p xá»‰ 1076110761, so vá»›i cá» vua lÃ  1012010120, vÃ¬ váº­y thuáº­t toÃ¡n pháº£i chá»n ra má»™t nÆ°á»›c Ä‘i tá»‘i Æ°u trong sá»‘ hÃ ng tá»‰ tá»‰ lá»±a chá»n. Vá» cÆ¡ báº£n, AlphaGo bao gá»“m cÃ¡c thuáº­t toÃ¡n thuá»™c cáº£ Supervised learning vÃ  Reinforcement learning. Trong pháº§n Supervised learning, dá»¯ liá»‡u tá»« cÃ¡c vÃ¡n cá» do con ngÆ°á»i chÆ¡i vá»›i nhau Ä‘Æ°á»£c Ä‘Æ°a vÃ o Ä‘á»ƒ huáº¥n luyá»‡n. Tuy nhiÃªn, má»¥c tiÃªu cuá»‘i cÃ¹ng cá»§a AlphaGo khÃ´ng pháº£i lÃ  chÆ¡i nhÆ° con ngÆ°á»i mÃ  pháº£i tháº¯ng Ä‘Æ°á»£c con ngÆ°á»i. VÃ¬ váº­y, sau khi há»c xong cÃ¡c vÃ¡n cá» cá»§a con ngÆ°á»i, AlphaGo tá»± chÆ¡i vá»›i chÃ­nh nÃ³ thÃ´ng qua hÃ ng triá»‡u vÃ¡n cá» Ä‘á»ƒ tÃ¬m ra cÃ¡c nÆ°á»›c Ä‘i má»›i tá»‘i Æ°u hÆ¡n. Thuáº­t toÃ¡n trong pháº§n tá»± chÆ¡i nÃ y Ä‘Æ°á»£c xáº¿p vÃ o loáº¡i Reinforcement learning.\nÄÆ¡n giáº£n hÆ¡n cá» vÃ¢y, táº¡i má»™t thá»i Ä‘iá»ƒm cá»¥ thá»ƒ, ngÆ°á»i chÆ¡i game Mario chá»‰ cáº§n báº¥m má»™t sá»‘ lÆ°á»£ng nhá» cÃ¡c nÃºt (di chuyá»ƒn, nháº£y, báº¯n Ä‘áº¡n) hoáº·c khÃ´ng cáº§n báº¥m nÃºt nÃ o á»©ng vá»›i má»™t chÆ°á»›ng ngáº¡i váº­t cá»‘ Ä‘á»‹nh á»Ÿ má»™t vá»‹ trÃ­ cá»‘ Ä‘á»‹nh. Khi Ä‘Ã³ thuáº­t toÃ¡n trong á»©ng dá»¥ng dáº¡y mÃ¡y tÃ­nh chÆ¡i game Mario sáº½ nháº­n Ä‘áº§u vÃ o lÃ  sÆ¡ Ä‘á»“ cá»§a mÃ n hÃ¬nh táº¡i thá»i Ä‘iá»ƒm hiá»‡n hÃ nh, nhiá»‡m vá»¥ cá»§a thuáº­t toÃ¡n lÃ  tÃ¬m ra tá»• há»£p phÃ­m nÃªn Ä‘Æ°á»£c báº¥m á»©ng vá»›i Ä‘áº§u vÃ o Ä‘Ã³. Viá»‡c huáº¥n luyá»‡n nÃ y Ä‘Æ°á»£c dá»±a trÃªn Ä‘iá»ƒm sá»‘ cho viá»‡c di chuyá»ƒn Ä‘Æ°á»£c bao xa vá»›i thá»i gian bao lÃ¢u trong game, cÃ ng xa vÃ  cÃ ng nhanh thÃ¬ Ä‘iá»ƒm thÆ°á»Ÿng Ä‘áº¡t Ä‘Æ°á»£c cÃ ng cao, táº¥t nhiÃªn Ä‘iá»ƒm thÆ°á»Ÿng nÃ y khÃ´ng pháº£i lÃ  Ä‘iá»ƒm cá»§a trÃ² chÆ¡i mÃ  lÃ  Ä‘iá»ƒm do chÃ­nh ngÆ°á»i láº­p trÃ¬nh táº¡o ra. ThÃ´ng qua huáº¥n luyá»‡n, thuáº­t toÃ¡n sáº½ tÃ¬m ra má»™t cÃ¡ch tá»‘i Æ°u Ä‘á»ƒ tá»‘i Ä‘a sá»‘ Ä‘iá»ƒm trÃªn, qua Ä‘Ã³ Ä‘áº¡t Ä‘Æ°á»£c má»¥c Ä‘Ã­ch cuá»‘i cÃ¹ng lÃ  cá»©u cÃ´ng chÃºa.\nCÃ³ nhiá»u cÃ¡ch khÃ¡c nhau Ä‘á»ƒ thuáº­t toÃ¡n cÃ³ thá»ƒ mÃ´ hÃ¬nh hÃ³a má»™t váº¥n Ä‘á» dá»±a trÃªn sá»± tÆ°Æ¡ng tÃ¡c cá»§a nÃ³ vá»›i dá»¯ liá»‡u Ä‘áº§u vÃ o. PhÃ¢n loáº¡i hoáº·c cÃ¡ch tá»• chá»©c thuáº­t toÃ¡n há»c mÃ¡y nÃ y ráº¥t há»¯u Ã­ch vÃ¬ nÃ³ buá»™c chÃºng ta pháº£i suy nghÄ© vá» vai trÃ² cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o vÃ  quy trÃ¬nh chuáº©n bá»‹ mÃ´ hÃ¬nh vÃ  chá»n má»™t thuáº­t toÃ¡n phÃ¹ há»£p nháº¥t cho váº¥n Ä‘á» cá»§a chÃºng ta Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t nháº¥t.\n2.\tPhÃ¢n nhÃ³m dá»±a trÃªn sá»± tÆ°Æ¡ng Ä‘á»“ng Dá»±a vÃ o sá»± tÆ°Æ¡ng Ä‘á»“ng vá» chá»©c nÄƒng hay cÃ¡ch thá»©c hoáº¡t Ä‘á»™ng mÃ  cÃ¡c thuáº­t toÃ¡n sáº½ Ä‘Æ°á»£c gom nhÃ³m vá»›i nhau. Sau Ä‘Ã¢y lÃ  danh sÃ¡ch cÃ¡c nhÃ³m vÃ  cÃ¡c thuáº­t toÃ¡n theo tá»«ng nhÃ³m.\na.\tCÃ¡c thuáº­t toÃ¡n há»“i quy (Regression Algorithms) Há»“i quy lÃ  quÃ¡ trÃ¬nh tÃ¬m má»‘i quan há»‡ phá»¥ thuá»™c cá»§a má»™t biáº¿n (Ä‘Æ°á»£c gá»i lÃ  biáº¿n phá»¥ thuá»™c hay biáº¿n Ä‘Æ°á»£c giáº£i thÃ­ch, biáº¿n Ä‘Æ°á»£c dá»± bÃ¡o, biáº¿n Ä‘Æ°á»£c há»“i quy, biáº¿n pháº£n á»©ng, biáº¿n ná»™i sinh) vÃ o má»™t hoáº·c nhiá»u biáº¿n khÃ¡c (Ä‘Æ°á»£c gá»i lÃ  biáº¿n Ä‘á»™c láº­p, biáº¿n giáº£i thÃ­ch, biáº¿n dá»± bÃ¡o, biáº¿n há»“i quy, biáº¿n tÃ¡c nhÃ¢n hay biáº¿n kiá»ƒm soÃ¡t, biáº¿n ngoáº¡i sinh) nháº±m má»¥c Ä‘Ã­ch Æ°á»›c lÆ°á»£ng hoáº·c tiÃªn Ä‘oÃ¡n giÃ¡ trá»‹ ká»³ vá»ng cá»§a biáº¿n phá»¥ thuá»™c khi biáº¿t trÆ°á»›c giÃ¡ trá»‹ cá»§a biáº¿n Ä‘á»™c láº­p. HÃ¬nh 6 tÆ°á»£ng trÆ°ng cho Ã½ tÆ°á»Ÿng cá»§a cÃ¡c thuáº­t toÃ¡n há»“i quy.\nVÃ­ dá»¥ nhÆ°, dá»± Ä‘oÃ¡n ráº±ng náº¿u tÄƒng lÃ£i suáº¥t tiá»n gá»­i thÃ¬ sáº½ huy Ä‘á»™ng Ä‘Æ°á»£c lÆ°á»£ng tiá»n gá»­i nhiá»u hÆ¡n, khi Ä‘Ã³ ngÃ¢n hÃ ng A cáº§n biáº¿t má»‘i quan há»‡ giá»¯a lÆ°á»£ng tiá»n gá»­i vÃ  lÃ£i suáº¥t tiá»n gá»­i, cá»¥ thá»ƒ hÆ¡n há» muá»‘n biáº¿t khi tÄƒng lÃ£i suáº¥t thÃªm 0.1% thÃ¬ lÆ°á»£ng tiá»n gá»­i sáº½ tÄƒng trung bÃ¬nh lÃ  bao nhiÃªu.\nCÃ¡c thuáº­t toÃ¡n há»“i quy phá»• biáº¿n nháº¥t lÃ :\nLinear Regression\nLogistic Regression\nLocally Estimated Scatterplot Smoothing (LOESS)\nMultivariate Adaptive Regression Splines (MARS)\nOrdinary Least Squares Regression (OLSR)\nStepwise Regression\nHÃ¬nh 6: Regression Algorithms\nb.\tThuáº­t toÃ¡n dá»±a trÃªn máº«u (Instance-based Algorithms) MÃ´ hÃ¬nh há»c táº­p dá»±a trÃªn máº«u hay thá»±c thá»ƒ lÃ  bÃ i toÃ¡n ra quyáº¿t Ä‘á»‹nh dá»±a vÃ o cÃ¡c trÆ°á»ng há»£p hoáº·c cÃ¡c máº«u dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘Æ°á»£c coi lÃ  quan trá»ng hay báº¯t buá»™c Ä‘á»‘i vá»›i mÃ´ hÃ¬nh.\nNhÃ³m thuáº­t toÃ¡n nÃ y thÆ°á»ng xÃ¢y dá»±ng cÆ¡ sá»Ÿ dá»¯ liá»‡u vá» dá»¯ liá»‡u máº«u vÃ  so sÃ¡nh dá»¯ liá»‡u má»›i vá»›i cÆ¡ sá»Ÿ dá»¯ liá»‡u báº±ng cÃ¡ch sá»­ dá»¥ng thÆ°á»›c Ä‘o tÆ°Æ¡ng tá»± Ä‘á»ƒ tÃ¬m káº¿t quáº£ phÃ¹ há»£p nháº¥t vÃ  Ä‘Æ°a ra dá»± Ä‘oÃ¡n. Khi Ä‘Ã³ trá»ng tÃ¢m Ä‘Æ°á»£c Ä‘áº·t vÃ o Ä‘áº¡i diá»‡n cá»§a cÃ¡c thá»ƒ hiá»‡n Ä‘Æ°á»£c lÆ°u trá»¯ nhÆ° minh hoáº¡ á»Ÿ HÃ¬nh 7.\nHÃ¬nh 7: Instance-based Algorithms\nCÃ¡c thuáº­t toÃ¡n dá»±a trÃªn thá»±c thá»ƒ phá»• biáº¿n nháº¥t lÃ :\nk-Nearest Neighbor (kNN â€“ k lÃ¡ng giá»ng gáº§n nháº¥t)\nLearning Vector Quantization (LVQ)\nLocally Weighted Learning (LWL)\nSelf-Organizing Map (SOM)\nc.\tThuáº­t toÃ¡n chuáº©n hoÃ¡ (Regularization Algorithms) CÃ¡c thuáº­t toÃ¡n chuáº©n hoÃ¡ ra Ä‘á»i tá»« sá»± má»Ÿ rá»™ng cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Ã£ cÃ³ (Ä‘iá»ƒn hÃ¬nh lÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p há»“i quy) báº±ng cÃ¡ch xá»­ pháº¡t cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn má»©c Ä‘á»™ phá»©c táº¡p cá»§a chÃºng. Viá»‡c Æ°u tiÃªn cÃ¡c mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n hÆ¡n cÅ©ng tá»‘t hÆ¡n trong viá»‡c khÃ¡i quÃ¡t hÃ³a. HÃ¬nh 8 tÆ°á»£ng trÆ°ng cho Ã½ tÆ°á»Ÿng cá»§a thuáº­t toÃ¡n chuáº©n hoÃ¡.\nHÃ¬nh 8: Regularization Algorithms\nCÃ¡c thuáº­t toÃ¡n chÃ­nh quy phá»• biáº¿n nháº¥t lÃ :\nElastic Net\nLeast Absolute Shrinkage and Selection Operator (LASSO)\nLeast-Angle Regression (LARS)\nRidge Regression\nd.\tThuáº­t toÃ¡n cÃ¢y quyáº¿t Ä‘á»‹nh (Decision Tree Algorithms) ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p xÃ¢y dá»±ng mÃ´ hÃ¬nh ra quyáº¿t Ä‘á»‹nh dá»±a trÃªn cÃ¡c giÃ¡ trá»‹ thá»±c cá»§a nhá»¯ng thuá»™c tÃ­nh trong dá»¯ liá»‡u. Sá»± quyáº¿t Ä‘á»‹nh Ä‘Æ°á»£c ráº½ nhÃ¡nh trong cáº¥u trÃºc cÃ¢y cho Ä‘áº¿n khi quyáº¿t Ä‘á»‹nh dá»± Ä‘oÃ¡n Ä‘Æ°á»£c Ä‘Æ°a ra cho má»™t máº«u nháº¥t Ä‘á»‹nh nhÆ° minh hoáº¡ á»Ÿ HÃ¬nh 9. PhÆ°Æ¡ng phÃ¡p nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng trong viá»‡c huáº¥n luyá»‡n dá»¯ liá»‡u cho bÃ i toÃ¡n phÃ¢n lá»›p vÃ  há»“i quy. VÃ¬ sá»± nhanh chÃ³ng, chÃ­nh xÃ¡c nÃªn phÆ°Æ¡ng phÃ¡p nÃ y ráº¥t Ä‘Æ°á»£c Æ°a chuá»™ng trong ML.\nHÃ¬nh 9: Decision Tree Algorithms\nCÃ¡c thuáº­t toÃ¡n cÃ¢y quyáº¿t Ä‘á»‹nh phá»• biáº¿n nháº¥t bao gá»“m:\nChi-squared Automatic Interaction Detection (CHAID)\nClassification vÃ  Regression Tree â€“ CART\nConditional Decision Trees\nC4.5 vÃ  C5.0\nDecision Stump\nIterative Dichotomiser 3 (ID3)\nM5\ne.\tThuáº­t toÃ¡n Bayes (Bayesian Algorithms) ÄÃ¢y lÃ  nhÃ³m cÃ¡c thuáº­t toÃ¡n Ã¡p dá»¥ng Äá»‹nh lÃ½ Bayes cho bÃ i toÃ¡n phÃ¢n loáº¡i vÃ  há»“i quy.\nHÃ¬nh 10: Bayesian Algorithms\nCÃ¡c thuáº­t toÃ¡n phá»• biáº¿n nháº¥t lÃ :\nAveraged One-Dependence Estimators (AODE)\nBayesian Belief Network (BBN)\nBayesian Network (BN)\nGaussian Naive Bayes\nMultinomial Naive Bayes\nNaive Bayes\nf.\tThuáº­t toÃ¡n phÃ¢n cá»¥m (Clustering Algorithms) Táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘á»u sá»­ dá»¥ng cÃ¡c cáº¥u trÃºc vá»‘n cÃ³ trong dá»¯ liá»‡u Ä‘á»ƒ tá»• chá»©c tá»‘t nháº¥t dá»¯ liá»‡u thÃ nh cÃ¡c nhÃ³m cÃ³ má»©c Ä‘á»™ phá»• biáº¿n tá»‘i Ä‘a dá»±a vÃ o trá»ng tÃ¢m (centroid) vÃ  thá»© báº­c (hierarchal) nhÆ° thá»ƒ hiá»‡n á»Ÿ HÃ¬nh 11.\nHÃ¬nh 11: Clustering Algorithms\nCÃ¡c thuáº­t toÃ¡n phÃ¢n cá»¥m phá»• biáº¿n nháº¥t lÃ :\nExpectation Maximisation (EM â€“ cá»±c Ä‘áº¡i hoÃ¡ ká»³ vá»ng)\nHierarchical Clustering\nk-Means\nk-Medians\ng.\tCÃ¡c thuáº­t toÃ¡n luáº­t káº¿t há»£p (Association Rule Learning Algorithms) ÄÃ¢y lÃ  nhá»¯ng thuáº­t toÃ¡n sáº½ rÃºt trÃ­ch ra cÃ¡c quy táº¯c giáº£i thÃ­ch tá»‘t nháº¥t má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n trong dá»¯ liá»‡u. CÃ¡c quy táº¯c nÃ y cÃ³ thá»ƒ giÃºp khÃ¡m phÃ¡ ra cÃ¡c tÃ­nh cháº¥t quan trá»ng vÃ  há»¯u Ã­ch trong cÃ¡c táº­p dá»¯ liá»‡u lá»›n vÃ  cao chiá»u trong thÆ°Æ¡ng máº¡i cÃ¹ng cÃ¡c lÄ©nh vá»±c khÃ¡c. HÃ¬nh 12 minh hoáº¡ cho Ã½ tÆ°á»Ÿng cá»§a thuáº­t toÃ¡n luáº­t káº¿t há»£p.\nHÃ¬nh 12: Association Rule Learning Algorithms\nCÃ¡c thuáº­t toÃ¡n luáº­t káº¿t há»£p phá»• biáº¿n nháº¥t lÃ :\nApriori algorithm\nEclat algorithm\nFP-Growth algorithm\nh.\tThuáº­t toÃ¡n máº¡ng nÆ¡ron nhÃ¢n táº¡o (Artificial Neural Network Algorithms) Máº¡ng nÆ¡ron nhÃ¢n táº¡o lÃ  cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« cáº¥u trÃºc vÃ  chá»©c nÄƒng cá»§a máº¡ng lÆ°á»›i tháº§n kinh sinh há»c. HÃ¬nh 13 minh hoáº¡ cho má»™t máº¡ng truyá»n tháº³ng. NhÃ³m thuáº­t toÃ¡n nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho bÃ i toÃ¡n phÃ¢n lá»›p vÃ  há»“i quy vá»›i ráº¥t nhiá»u biáº¿n thá»ƒ khÃ¡c nhau cho háº§u háº¿t cÃ¡c váº¥n Ä‘á». Tuy nhiÃªn, trong bÃ i viáº¿t nÃ y mÃ¬nh chá»‰ trÃ¬nh bÃ y cÃ¡c thuáº­t toÃ¡n cá»• Ä‘iá»ƒn vÃ  phá»• biáº¿n nháº¥t:\nBack-Propagation (máº¡ng lan truyá»n ngÆ°á»£c)\nPerceptron (Máº¡ng lan truyá»n tháº³ng)\nMulti-layer perceptron (Máº¡ng truyá»n tháº³ng Ä‘a lá»›p)\nHopfield Network\nRadial Basis Function Network (RBFN)\nHÃ¬nh 13: Artificial Neural Network Algorithms\ni.\tThuáº­t toÃ¡n há»c sÃ¢u (Deep Learning Algorithms) Thá»±c cháº¥t Deep Learning lÃ  má»™t báº£n cáº­p nháº­t hiá»‡n Ä‘áº¡i cho Artificial Neural Networks nháº±m khai thÃ¡c kháº£ nÄƒng tÃ­nh toÃ¡n cá»§a mÃ¡y tÃ­nh, tuy nhiÃªn vÃ¬ sá»± phÃ¡t triá»ƒn lá»›n máº¡nh cá»§a chÃºng nÃªn mÃ¬nh tÃ¡ch ra thÃ nh má»™t nhÃ³m riÃªng.\nDeep Learning quan tÃ¢m Ä‘áº¿n viá»‡c xÃ¢y dá»±ng cÃ¡c máº¡ng tháº§n kinh lá»›n hÆ¡n, phá»©c táº¡p hÆ¡n nhiá»u, vÃ  lÃ m sao Ä‘á»ƒ khai thÃ¡c hiá»‡u quáº£ cÃ¡c bá»™ dá»¯ liá»‡u lá»›n chá»©a ráº¥t Ã­t dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n. HÃ¬nh 14 minh hoáº¡ cho Ã½ tÆ°á»Ÿng cá»§a Deep learning.\nHÃ¬nh 14: Deep Learning Algorithms\nCÃ¡c thuáº­t toÃ¡n há»c sÃ¢u phá»• biáº¿n nháº¥t lÃ :\nConvolutional Neural Network (CNN)\nDeep Belief Networks (DBN)\nDeep Boltzmann Machine (DBM)\nStacked Auto-Encoders\nj.\tNhÃ³m thuáº­t toÃ¡n Giáº£m chiá»u dá»¯ liá»‡u (Dimensionality Reduction Algorithms) Giá»‘ng nhÆ° cÃ¡c phÆ°Æ¡ng phÃ¡p phÃ¢n cá»¥m, giáº£m khÃ´ng gian tÃ¬m kiáº¿m vÃ  khai thÃ¡c cáº¥u trÃºc vá»‘n cÃ³ trong dá»¯ liá»‡u nhÆ°ng theo cÃ¡ch khÃ´ng giÃ¡m sÃ¡t hoáº·c Ä‘á»ƒ tÃ³m táº¯t hay mÃ´ táº£ dá»¯ liá»‡u sá»­ dá»¥ng Ã­t thÃ´ng tin hÆ¡n lÃ  má»¥c tiÃªu cá»§a nhÃ³m phÆ°Æ¡ng phÃ¡p nÃ y. HÃ¬nh 15 minh hoáº¡ cho viá»‡c giáº£m chiá»u dá»¯ liá»‡u.\nÄiá»u nÃ y cÃ³ thá»ƒ há»¯u Ã­ch Ä‘á»ƒ trá»±c quan hÃ³a dá»¯ liá»‡u hoáº·c Ä‘Æ¡n giáº£n hÃ³a dá»¯ liá»‡u mÃ  sau Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng trong phÆ°Æ¡ng phÃ¡p há»c cÃ³ giÃ¡m sÃ¡t. Nhiá»u trong sá»‘ cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh Ä‘á»ƒ sá»­ dá»¥ng trong phÃ¢n lá»›p vÃ  há»“i quy.\nHÃ¬nh 15: Dimensional Reduction Algorithms\nCÃ¡c thuáº­t toÃ¡n Giáº£m chiá»u dá»¯ liá»‡u phá»• biáº¿n nhÆ°:\nFlexible Discriminant Analysis (FDA)\nLinear Discriminant Analysis (LDA)\nMixture Discriminant Analysis (MDA)\nMultidimensional Scaling (MDS)\nPartial Least Squares Regression (PLSR)\nPrincipal Component Analysis (PCA)\nPrincipal Component Regression (PCR)\nProjection Pursuit\nQuadratic Discriminant Analysis (QDA)\nSammon Mapping\nk.\tThuáº­t toÃ¡n táº­p há»£p (Ensemble Algorithms) Ensemble methods lÃ  nhá»¯ng phÆ°Æ¡ng phÃ¡p káº¿t há»£p cÃ¡c mÃ´ hÃ¬nh yáº¿u hÆ¡n Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»™c láº­p vÃ  pháº§n dá»± Ä‘oÃ¡n cá»§a chÃºng sáº½ Ä‘Æ°á»£c káº¿t há»£p theo má»™t cÃ¡ch nÃ o Ä‘Ã³ Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n tá»•ng thá»ƒ nhÆ° minh há»a á»Ÿ HÃ¬nh 16.\nNhÃ³m thuáº­t toÃ¡n nÃ y khÃ¡ máº¡nh vÃ  Ä‘Æ°á»£c nghiÃªn cá»©u nhiá»u, Ä‘áº·c biá»‡t lÃ  vá» cÃ¡ch Ä‘á»ƒ káº¿t há»£p cÃ¡c mÃ´ hÃ¬nh vá»›i nhau.\nHÃ¬nh 16: Ensemble Algorithms\nMá»™t sá»‘ thuáº­t toÃ¡n phá»• biáº¿n nhÆ°:\nAdaBoost\nBoosting\nBootstrapped Aggregation (Bagging)\nGradient Boosting Machines (GBM)\nGradient Boosted Regression Trees (GBRT)\nRandom Forest\nStacked Generalization (blending)\nl.\tCÃ¡c thuáº­t toÃ¡n khÃ¡c CÃ²n ráº¥t nhiá»u cÃ¡c thuáº­t toÃ¡n khÃ¡c khÃ´ng Ä‘Æ°á»£c liá»‡t kÃª á»Ÿ Ä‘Ã¢y, cháº³ng háº¡n nhÆ° Support Vector Machines (SVM), mÃ¬nh Ä‘ang phÃ¢n vÃ¢n ráº±ng liá»‡u thuáº­t toÃ¡n nÃ y nÃªn Ä‘Æ°á»£c Ä‘Æ°a vÃ o nhÃ³m nÃ o Ä‘Ã³ hay Ä‘á»©ng má»™t mÃ¬nh. Náº¿u dá»±a vÃ o danh sÃ¡ch cÃ¡c biáº¿n thá»ƒ vÃ  má»©c Ä‘á»™ phÃ¡t triá»ƒn thÃ¬ SVM cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¡ch thÃ nh má»™t nhÃ³m riÃªng â€“ nhÃ³m thuáº­t toÃ¡n sá»­ dá»¥ng vÃ©ctÆ¡ há»— trá»£.\nThÃªm vÃ o Ä‘Ã³, cÃ¡c thuáº­t toÃ¡n Ä‘Æ°á»£c hÃ¬nh thÃ nh tá»« cÃ¡c nhiá»‡m vá»¥ Ä‘áº·c biá»‡t, hoÄƒc cÃ¡c thuáº­t toÃ¡n tá»« nhá»¯ng nhÃ¡nh con Ä‘áº·c biá»‡t cá»§a ML cÅ©ng khÃ´ng Ä‘Æ°á»£c liá»‡t kÃª vÃ o cÃ¡c nhÃ³m, cháº³ng háº¡n nhÆ°:\nFeature selection algorithms\nAlgorithm accuracy evaluation\nPerformance measures\nCÃ³ dá»‹p mÃ¬nh sáº½ bá»• sung hoáº·c Ä‘á» cáº­p Ä‘áº¿n nhá»¯ng thuáº­t toÃ¡n nÃ y á»Ÿ má»™t bÃ i viáº¿t khÃ¡c.\nMáº·c dÃ¹ ráº¥t há»¯u Ã­ch (dá»±a vÃ o nhÃ³m, ngÆ°á»i dÃ¹ng sáº½ dá»… dÃ ng nhá»› Ä‘Æ°á»£c báº£n cháº¥t cá»§a thuáº­t toÃ¡n) nhÆ°ng phÆ°Æ¡ng phÃ¡p phÃ¢n nhÃ³m nÃ y chÆ°a hoÃ n háº£o á»Ÿ Ä‘iá»ƒm cÃ³ nhá»¯ng thuáº­t toÃ¡n cÃ³ thá»ƒ phÃ¹ há»£p vá»›i nhiá»u danh má»¥c nhÆ° Learning Vector Quantization, vá»«a lÃ  phÆ°Æ¡ng phÃ¡p láº¥y cáº£m há»©ng tá»« máº¡ng tháº§n kinh (neural network), vá»«a lÃ  phÆ°Æ¡ng phÃ¡p dá»±a trÃªn cÃ¡ thá»ƒ (instance-based). Hoáº·c lÃ  thuáº­t toÃ¡n cÃ³ cÃ¹ng tÃªn mÃ´ táº£ bÃ i toÃ¡n vÃ  nhÃ³m thuáº­t toÃ¡n nhÆ° Há»“i quy (Regression) vÃ  PhÃ¢n cá»¥m (Clustering). Äá»‘i vá»›i nhá»¯ng trÆ°á»ng há»£p nÃ y ta cÃ³ thá»ƒ giáº£i quyáº¿t báº±ng cÃ¡ch liá»‡t kÃª cÃ¡c thuáº­t toÃ¡n hai láº§n hoáº·c báº±ng cÃ¡ch chá»n nhÃ³m má»™t cÃ¡ch chá»§ quan. Äá»ƒ trÃ¡nh trÃ¹ng láº·p cÃ¡c thuáº­t toÃ¡n vÃ  giá»¯ cho má»i thá»© Ä‘Æ¡n giáº£n thÃ¬ cÃ³ láº½ chá»n nhÃ³m theo cÃ¡ch chá»§ quan sáº½ phÃ¹ há»£p hÆ¡n.\nÄá»ƒ giÃºp cÃ¡c báº¡n dá»… nhá»› cÅ©ng nhÆ° tá»•ng káº¿t cho pháº§n nÃ y mÃ¬nh Ä‘Ã£ váº½ má»™t sÆ¡ Ä‘á»“ cÃ¡c thuáº­t toÃ¡n phÃ¢n theo nhÃ³m vÃ  sáº¯p xáº¿p theo alphabet, cÃ¡c báº¡n cÃ³ thá»ƒ xem thá»ƒm á»Ÿ HÃ¬nh 17 bÃªn dÆ°á»›i.\nHÃ¬nh 17: SÆ¡ Ä‘á»“ phÃ¢n nhÃ³m thuáº­t toÃ¡n theo sá»± tÆ°Æ¡ng Ä‘á»“ng\nHy vá»ng bÃ i viáº¿t nÃ y sáº½ mang láº¡i há»¯u Ã­ch cho báº¡n Ä‘á»c, nháº¥t lÃ  giÃºp báº¡n cÃ³ dÆ°á»£c cÃ¡i nhÃ¬n tá»•ng quan vá» nhá»¯ng gÃ¬ hiá»‡n cÃ³ vÃ  má»™t sá»‘ Ã½ tÆ°á»Ÿng vá» cÃ¡ch liÃªn káº¿t cÃ¡c thuáº­t toÃ¡n vá»›i nhau.\nDanh sÃ¡ch cÃ¡c nhÃ³m vÃ  thuáº­t toÃ¡n Ä‘Æ°á»£c liá»‡t kÃª trong bÃ i viáº¿t chá»‰ Ä‘áº£m báº£o Ä‘Æ°á»£c yáº¿u tá»‘ phá»• biáº¿n tuy nhiÃªn sáº½ khÃ´ng Ä‘áº§y Ä‘á»§. Váº­y nÃªn náº¿u báº¡n biáº¿t thÃªm thuáº­t toÃ¡n hoáº·c nhÃ³m nÃ o chÆ°a Ä‘Æ°á»£c liá»‡t kÃª á»Ÿ Ä‘Ã¢y hoáº·c ká»ƒ cáº£ cÃ¡ch phÃ¢n nhÃ³m thuáº­t toÃ¡n khÃ¡c, cÅ©ng nhÆ° sau khi Ä‘á»c mÃ  cÃ¡c báº¡n cÃ³ báº¥t ká»³ gÃ³p Ã½, cÃ¢u há»i giÃºp cáº£i thiá»‡n bÃ i viáº¿t tá»‘t hÆ¡n, cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»ƒ láº¡i bÃ¬nh luáº­n nháº±m chia sáº» cÃ¹ng mÃ¬nh vÃ  nhá»¯ng báº¡n Ä‘á»c khÃ¡c nhÃ©.\nTÃ i liá»‡u tham kháº£o: A Tour of Machine Learning Algorithms by Jason Brownlee in Understand Machine Learning Algorithms\nSemi-Supervised Learning Tutorial by Xiaojin Zhu\nhttps://en.wikipedia.org/wiki/Outline_of_machine_learning#Machine_learning_algorithms\nTop 10 algorithms in data mining by Xindong Wu Â· Vipin Kumar Â· J. Ross Quinlan Â· Joydeep Ghosh Â· Qiang Yang Â· Hiroshi Motoda Â· Geoffrey J. McLachlan Â· Angus Ng Â· Bing Liu Â· Philip S. Yu Â· Zhi-Hua Zhou Â· Michael Steinbach Â· David J. Hand Â· Dan Steinberg.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ nhá»¯ng bÃ i viáº¿t tiáº¿p theo.\n","date":"Apr 19, 2019","img":"","permalink":"/blog/2019-04-19-deep-learning-view/","series":null,"tags":["machine learning","deep learning","há»c cÃ³ giÃ¡m sÃ¡t","há»c khÃ´ng giÃ¡m sÃ¡t","há»c tÄƒng cÆ°á»ng"],"title":"PhÃ¢n NhÃ³m CÃ¡c Thuáº­t ToÃ¡n Há»c MÃ¡y"},{"categories":null,"content":" NghiÃªn cá»©u dá»¯ liá»‡u PhÃ¢n tÃ­ch dá»¯ liá»‡u LÃ m sáº¡ch dá»¯ liá»‡u Xá»­ lÃ½ missing values Táº¡o Ä‘áº·c trÆ°ng Huáº¥n luyá»‡n mÃ´ hÃ¬nh NghiÃªn cá»©u dá»¯ liá»‡u Trong thá»±c táº¿, Walmart Ä‘Ã£ cháº¡y cÃ¡c chÆ°Æ¡ng trÃ¬nh khuyáº¿n mÃ£i trong cÃ¡c ngÃ y lá»… lá»›n trong nÄƒm. CÃ³ 4 ngÃ y lá»… lá»›n Ä‘Ã³ lÃ  SiÃªu cÃºp bÃ³ng báº§u dá»¥c Má»¹ (Super Bowl - tá»• chá»©c vÃ o chá»§ nháº­t Ä‘áº§u tiÃªn cá»§a thÃ¡ng Hai. ÄÃ¢y lÃ  má»™t sá»± kiá»‡n thá»ƒ thao lá»›n vÃ  ngÃ y tá»• chá»©c Super Bowl Ä‘Æ°á»£c ngÆ°á»i Má»¹ coi lÃ  ngÃ y lá»… quá»‘c gia cá»§a Hoa Ká»³ (theo wiki https://vi.wikipedia.org/wiki/Super_Bowl)), ngÃ y lá»… lao Ä‘á»™ng (Labor Day - ngÃ y má»™t thÃ¡ng 5), lá»… táº¡ Æ¡n (Thanksgiving, ngÃ y lá»… táº¡ Æ¡n á»Ÿ Má»¹ Ä‘Æ°á»£c tá»• chá»©c vÃ o ngÃ y thá»© NÄƒm láº§n thá»© tÆ° cá»§a thÃ¡ng 11, cÃ²n á»Ÿ Canada ngÃ y lá»… táº¡ Æ¡n Ä‘Æ°á»£c tá»• chá»©c vÃ o ngÃ y thá»© hai láº§n thá»© hai cá»§a thÃ¡ng 10, theo wiki https://en.wikipedia.org/wiki/Thanksgiving), lá»… giÃ¡ng sinh (Christmas ngÃ y 24 vÃ  25 thÃ¡ng 12 theo wiki https://en.wikipedia.org/wiki/Christmas ). Nhá»¯ng tuáº§n cÃ³ chá»©a nhá»¯ng ngÃ y lá»… lá»›n nÃ y Ä‘Æ°á»£c Ä‘Ã¡nh trá»ng sá»‘ gáº¥p 5 láº§n nhá»¯ng tuáº§n khÃ¡c. ChÃºng ta pháº£i xÃ¢y dá»±ng mÃ´ hÃ¬nh Ä‘á»ƒ mÃ´ hÃ¬nh hoÃ¡ cÃ¡c tÃ¡c Ä‘á»™ng cá»§a viá»‡c giáº£m giÃ¡ trong cÃ¡c tuáº§n lá»… nÃ y khi khÃ´ng cÃ³ dá»¯ liá»‡u lá»‹ch sá»­ Ä‘áº§y Ä‘á»§.\nTáº­p dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p bao gá»“m:\nTáº­p train: chá»©a dá»¯ liá»‡u sá»‘ bÃ¡n tá»« 05-02-2010 Ä‘áº¿n 01-11-2012. CÃ¡c trÆ°á»ng dá»¯ liá»‡u lÃ : store number - mÃ£ cá»­a hÃ ng, Dept number - mÃ£ sáº£n pháº©m, Date - Tuáº§n, Weekly_Sales - sá»‘ bÃ¡n, IsHoliday - Náº¿u tuáº§n Ä‘Ã³ cÃ³ chá»©a cÃ¡c holidate thÃ¬ Ä‘Ã¡nh 1 ngÆ°á»£c láº¡i Ä‘Ã¡nh 0.\nTáº­p test: Chá»©a dá»¯ liá»‡u test, cÃ³ cÃ¡c cá»™t thuá»™c tÃ­nh nhÆ° táº­p train\nTáº­p features: Chá»©a thÃ´ng tin thÃªm vá» cá»§a hÃ ng, bao gá»“m store - mÃ£ cá»­a hÃ ng, Date - ngÃ y, Temperature - Nhiá»‡t Ä‘á»™, Fuel_Price - giÃ¡ dáº§u (á»Ÿ má»¹, má»—i khu vá»±c khÃ¡c nhau sáº½ cÃ³ giÃ¡ nhiÃªn liá»‡u khÃ¡c nhau), MarkDown1, MarkDown2,\u0026hellip; , MarkDown5 - má»™t chá»‰ sá»‘ gÃ¬ Ä‘Ã³ mÃ  tÃ¡c giáº£ khÃ´ng cung cáº¥p Ä‘á»‹nh nghÄ©a cho chÃºng ta, CPI - chá»‰ sá»‘ giÃ¡ tiÃªu dÃ¹ng, Unemployment - tÃ¬nh tráº¡ng tháº¥t nghiá»‡p, IsHoliday - Tuáº§n cÃ³ chá»©a ngÃ y nghá»‰.\nPhÃ¢n tÃ­ch dá»¯ liá»‡u MÃ¬nh sáº½ import má»™t sá»‘ thÆ° viá»‡n cáº§n thiáº¿t\n1import pandas as pd 2import numpy as np 3 4#Do some statistics 5from scipy.misc import imread 6from scipy import sparse 7import scipy.stats as ss 8import math 9 10#Nice graphing tools 11import matplotlib 12import matplotlib.pyplot as plt 13import seaborn as sns Äá»c cÃ¡c file data lÃªn, merge cÃ¡c file láº¡i vá»›i nhau\n1 2 3train = pd.read_csv(\u0026#39;data/train.csv\u0026#39;) 4test = pd.read_csv(\u0026#39;data/test.csv\u0026#39;) 5feature = pd.read_csv(\u0026#39;data/features.csv\u0026#39;) 6 7train = train.merge(feature, how=\u0026#39;left\u0026#39;, on=[\u0026#39;Store\u0026#39;,\u0026#39;Date\u0026#39;]) 8test = test.merge(feature, how=\u0026#39;left\u0026#39;, on=[\u0026#39;Store\u0026#39;,\u0026#39;Date\u0026#39;]) 9 10 11# Merge in store info 12stores = pd.read_csv(\u0026#34;data/stores.csv\u0026#34;) 13train = train.merge(stores, how=\u0026#39;left\u0026#39;, on=\u0026#39;Store\u0026#39;) 14test = test.merge(stores, how=\u0026#39;left\u0026#39;, on=\u0026#39;Store\u0026#39;) 15print(train.head()) Káº¿t quáº£\n1 Store Dept Date Weekly_Sales IsHoliday_x Temperature Fuel_Price MarkDown1 MarkDown2 MarkDown3 MarkDown4 MarkDown5 CPI Unemployment IsHoliday_y Type Size Split 20 1 1 2010-02-05 24924.50 False 42.31 2.572 NaN NaN NaN NaN NaN 211.096358 8.106 False A 151315 Train 31 1 1 2010-02-12 46039.49 True 38.51 2.548 NaN NaN NaN NaN NaN 211.242170 8.106 True A 151315 Train 42 1 1 2010-02-19 41595.55 False 39.93 2.514 NaN NaN NaN NaN NaN 211.289143 8.106 False A 151315 Train 53 1 1 2010-02-26 19403.54 False 46.63 2.561 NaN NaN NaN NaN NaN 211.319643 8.106 False A 151315 Train 64 1 1 2010-03-05 21827.90 False 46.50 2.625 NaN NaN NaN NaN NaN 211.350143 8.106 False A 151315 Train Má»›i cÃ³ 5 dÃ²ng Ä‘áº§u tiÃªn mÃ  tháº¥y cÃ¡c chá»‰ sá»‘ markdown Nan rá»“i.\nChÃºng ta tiáº¿n hÃ nh má»™t sá»‘ phÃ¢n tÃ­ch dá»¯ liá»‡u. Ã€, MÃ¬nh sáº½ merge dá»¯ liá»‡u train vÃ  test láº¡i rá»“i phÃ¢n tÃ­ch thá»‘ng kÃª\n1df = pd.concat([train,test],axis=0) # Join train and test 2 3print(df.describe()) Káº¿t quáº£\n1 CPI Dept Fuel_Price MarkDown1 MarkDown2 MarkDown3 MarkDown4 MarkDown5 Size Store Temperature Unemployment Weekly_Sales 2count 498472.000000 536634.000000 536634.000000 265596.000000 197685.000000 242326.000000 237143.000000 266496.000000 536634.00000 536634.000000 536634.000000 498472.000000 421570.000000 3mean 172.090481 44.277301 3.408310 7438.004144 3509.274827 1857.913525 3371.556866 4324.021158 136678.55096 22.208621 58.771762 7.791888 15981.258123 4std 39.542149 30.527358 0.430861 9411.341379 8992.047197 11616.143274 6872.281734 13549.262124 61007.71180 12.790580 18.678716 1.865076 22711.183519 5min 126.064000 1.000000 2.472000 -2781.450000 -265.760000 -179.260000 0.220000 -185.170000 34875.00000 1.000000 -7.290000 3.684000 -4988.940000 625% 132.521867 18.000000 3.041000 2114.640000 72.500000 7.220000 336.240000 1570.112500 93638.00000 11.000000 45.250000 6.623000 2079.650000 750% 182.442420 37.000000 3.523000 5126.540000 385.310000 40.760000 1239.040000 2870.910000 140167.00000 22.000000 60.060000 7.795000 7612.030000 875% 213.748126 74.000000 3.744000 9303.850000 2392.390000 174.260000 3397.080000 5012.220000 202505.00000 33.000000 73.230000 8.549000 20205.852500 9max 228.976456 99.000000 4.468000 103184.980000 104519.540000 149483.310000 67474.850000 771448.100000 219622.00000 45.000000 101.950000 14.313000 693099.360000 PhÃ¢n tÃ­ch má»™t chÃºt:\nBá» qua cá»™t Dept vÃ  Store vÃ¬ nÃ³ lÃ  mÃ£ sáº£n pháº©m vÃ  mÃ£ cá»§a hÃ ng, ngÆ°á»i ta thÃ­ch Ä‘áº·t sá»‘ bao nhiÃªu thÃ¬ Ä‘áº·t.\nCÃ¡c chá»‰ sá»‘ MarkDown cÃ³ Ä‘á»™ lá»‡ch chuáº©n khÃ¡ cao.\nNhiá»‡t Ä‘á»™ min lÃ  -7.29, max lÃ  101.95, trung bÃ¬nh lÃ  58, nÃªn khÃ´ng thá»ƒ lÃ  Ä‘á»™ C Ä‘Æ°á»£c, cÃ³ thá»ƒ lÃ  Ä‘á»™ F\nXem thá»­ há»‡ sá»‘ tÆ°Æ¡ng quan giá»¯a cÃ¡c column nhÆ° tháº¿ nÃ o\n1sns.set(style=\u0026#34;white\u0026#34;) 2 3# Compute the correlation matrix 4corr = df.corr() 5 6# Generate a mask for the upper triangle 7mask = np.zeros_like(corr, dtype=np.bool) 8mask[np.triu_indices_from(mask)] = True 9 10# Set up the matplotlib figure 11f, ax = plt.subplots(figsize=(11, 9)) 12 13# Generate a custom diverging colormap 14cmap = sns.diverging_palette(220, 10, as_cmap=True) 15 16# Draw the heatmap with the mask and correct aspect ratio 17sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, 18 square=True, linewidths=.5, cbar_kws={\u0026#34;shrink\u0026#34;: .5}) 19 20plt.show() Há»‡ sá»‘ tÆ°Æ¡ng quan giá»¯a cÃ¡c cá»™t trong dá»¯ liá»‡u\nPhÃ¢n tÃ­ch má»™t chÃºt, chÃºng ta tháº¥y ráº±ng MarkDown5 háº§u nhÆ° khÃ´ng cÃ³ liÃªn quan gÃ¬ Ä‘áº¿n cÃ¡c column cÃ²n láº¡i. Há»‡ sá»‘ tráº£i tá»« -0.3 Ä‘áº¿n 0.3 chá»©ng tá» má»•i quan há»‡ giá»¯a cÃ¡c cá»™t lÃ  khÃ¡ lá»ng láº»o. Chá»‰ sá»‘ giÃ¡ tiÃªu dÃ¹ng tÆ°Æ¡ng quan tá»· lá»‡ nghá»‹ch vá»›i tÃ¬nh tráº¡ng tháº¥t nghiá»‡p (há»£p lÃ½ khÃ´ng nhá»‰). KÃ­ch thÆ°á»›c cá»­a hÃ ng cÃ ng bá»± thÃ¬ bÃ¡n cÃ ng nhiá»u (ok hiá»ƒn nhiÃªn), sáº£n pháº©m cÃ³ mÃ£ cÃ ng lá»›n thÃ¬ bÃ¡n cÃ ng nhiá»u (? cÃ³ láº½ lÃ  sáº£n pháº©m má»›i, ngÆ°á»i má»¹ thÃ­ch mua sáº£n pháº©m má»›i chÄƒng). VÃ  má»™t váº¥n Ä‘á» quan trá»ng lÃ  giÃ¡ nhiÃªn liá»‡u, isHoliday, nhiá»‡t Ä‘á»™ khÃ´ng cÃ³ má»‘i tÆ°Æ¡ng quan vá»›i weekly sales. Chá»‰ sá»‘ CPI vÃ  tÃ¬nh tráº¡ng tháº¥t nghiá»‡p cÅ©ng áº£nh hÆ°á»Ÿng khÃ´ng lá»›n vá»›i weekly sales.\nThá»­ plot lÃªn hÃ¬nh áº£nh vá» sá»‘ lÆ°á»£ng bÃ¡n vÃ  kÃ­ch thÆ°á»›c cá»­a hÃ ng xem sao\n1plt.scatter( df[\u0026#39;Size\u0026#39;],df[\u0026#39;Weekly_Sales\u0026#39;]) 2plt.show() TÆ°Æ¡ng quan giá»¯a sá»‘ bÃ¡n vÃ  kÃ­ch thÆ°á»›c cá»­a hÃ ng\nNhÃ¬n vÃ o hÃ¬nh trÃªn, chÃºng ta tháº¥y ráº±ng cá»­a hÃ ng cÃ³ kÃ­ch thÆ°á»›c nhá» sá»‘ bÃ¡n cÅ©ng khÃ´ng tÄƒng Ä‘á»™t biáº¿n khi gáº·p ngÃ y lá»…, cá»­a hÃ ng kÃ­ch thÆ°á»›c siÃªu bá»± cÃ³ tá»· lá»‡ Ä‘á»™t biáº¿n tháº¥p, cá»­a hÃ ng trung trung cÃ³ Ä‘á»™t biáº¿n, á»Ÿ khÃºc size 125000 vÃ  sá»‘ bÃ¡n lÃ  700000. ChÃºng ta hÃ£y xem nhá»¯ng ngÃ y cÃ³ sá»‘ bÃ¡n lá»›n rÆ¡i vÃ o ngÃ y nÃ o. Dá»±a vÃ o báº£ng desription á»Ÿ phÃ­a trÃªn Ä‘Ã£ phÃ¢n tÃ­ch, trung bÃ¬nh cá»§a sá»‘ bÃ¡n lÃ  15981 vÃ  lá»‡ch chuáº©n lÃ  22711, cá»™ng láº¡i lÃ  15981 + 22711 = 38692, nhÃ¬n trÃªn Ä‘Ã´ thá»‹ thÃ¬ pháº§n Ä‘á»™t biáº¿n khÃ¡ lá»›n. Max lÃ  700000, min lÃ  0 (cÃ¡i nÃ y nhÃ¬n hÃ¬nh, khÃ´ng pháº£i sá»‘ thá»±c táº¿ á»Ÿ báº£ng mÃ´ táº£), mÃ¬nh sáº½ láº¥y ra nhá»¯ng ngÃ y cÃ³ sá»‘ bÃ¡n lá»›n hÆ¡n 350000 (vÆ°á»£t qua ngÆ°á»¡ng trung bÃ¬nh + Ä‘á»™ lá»‡ch chuáº©n ráº¥t nhá»u -\u0026gt; ngoáº¡i lá»‡ lÃ  Ä‘Ã¢y) xem nhá»¯ng ngÃ y Ä‘Ã³ lÃ  ngÃ y gÃ¬\n1 2print(df.loc[df[\u0026#39;Weekly_Sales\u0026#39;] \u0026gt;350000].head(10)) In ra top 10 tháº±ng Ä‘áº§u tiÃªn\n1 2 CPI Date Dept Fuel_Price IsHoliday_x IsHoliday_y MarkDown1 MarkDown2 MarkDown3 MarkDown4 MarkDown5 Size Split Store Temperature Type Unemployment Weekly_Sales 337201 126.669267 2010-11-26 72 2.752 True True NaN NaN NaN NaN NaN 205863 Train 4 48.08 A 7.127 381072.11 437253 129.836400 2011-11-25 72 3.225 True True 561.45 137.88 83340.33 44.04 9239.23 205863 Train 4 47.96 A 5.143 385051.04 588428 126.983581 2010-12-24 7 3.236 False False NaN NaN NaN NaN NaN 126512 Train 10 57.06 B 9.003 406988.63 695373 126.669267 2010-11-26 72 3.162 True True NaN NaN NaN NaN NaN 126512 Train 10 55.33 B 9.003 693099.36 795377 126.983581 2010-12-24 72 3.236 False False NaN NaN NaN NaN NaN 126512 Train 10 57.06 B 9.003 404245.03 895425 129.836400 2011-11-25 72 3.760 True True 174.72 329.00 141630.61 79.00 1009.98 126512 Train 10 60.68 B 7.874 630999.19 9115222 126.669267 2010-11-26 72 3.162 True True NaN NaN NaN NaN NaN 112238 Train 12 47.66 B 14.313 359995.60 10115274 129.836400 2011-11-25 72 3.622 True True 5391.83 8.00 63143.29 49.27 2115.67 112238 Train 12 53.25 B 12.890 360140.66 11128984 182.544590 2010-12-24 7 3.141 False False NaN NaN NaN NaN NaN 200898 Train 14 30.59 A 8.724 356867.25 12135665 182.783277 2010-11-26 72 3.039 True True NaN NaN NaN NaN NaN 200898 Train 14 46.15 A 8.724 474330.10 NhÃ¬n vÃ o báº£ng trÃªn, chÃºng ta tháº¥y ráº±ng 10 ngÃ y Ä‘áº§u tiÃªn táº­p trung chá»§ yáº¿u á»Ÿ thÃ¡ng 11 vÃ  thÃ¡ng 12, thÃ¡ng 12 lÃ  24-25 thÃ¡ng 12 -\u0026gt; ngÃ y noel, cÃ²n thÃ¡ng 11 lÃ  25-26 thÃ¡ng 11 (ngÃ y gÃ¬ váº­y ta, trong mÃ´ táº£ khÃ´ng tháº¥y) Tra lá»‹ch thÃ¬ ngÃ y 25 thÃ¡ng 11 nÄƒm 2011 trÃºng thá»© sÃ¡u, tra trÃªn máº¡ng má»™t thÃ´ng tin khÃ¡ quan trong lÃ  \u0026ldquo;Black Friday sáº½ rÆ¡i vÃ o khoáº£ng ngÃ y 23-29 thÃ¡ng 11\u0026rdquo; -\u0026gt; khÃ´ng nghi ngá» gÃ¬ ná»¯a cÃ³ thá»ƒ lÃ  ngÃ y nÃ y Ä‘Ã¢y. Thá»­ tra tiáº¿p ngÃ y 26 thÃ¡ng 11 nÄƒm 2010, cÅ©ng lÃ  thá»© sÃ¡u luÃ´n -\u0026gt; ngÃ y black friday vÃ  ngÃ y noel cÃ³ sá»©c mua Ä‘iÃªn cuá»“ng quÃ¡.\nMÃ¬nh dÃ¹ng má»™t ká»¹ thuáº­t nhá» lÃ  giáº£m dáº§n sá»‘ bÃ¡n, Ä‘á»ƒ ra sá»‘ bÃ¡n tá»‘i thiá»ƒu mÃ  ngÃ y black friday vÃ  ngÃ y nodel váº«n cÃ²n giá»¯ vá»‹ trÃ­ thá»‘ng trá»‹. Ká»¹ thuáº­t khÃ¡ Ä‘Æ¡n giáº£n thÃ´i, tá»« giÃ¡ trá»‹ 350000, má»—i láº§n mÃ¬nh sáº½ giáº£m Ä‘i 10000, vÃ  Ä‘áº¿m sá»‘ láº§n xuáº¥t hiá»‡n cá»§a cÃ¡c ngÃ y, náº¿u cÃ³ ngÃ y nÃ o Ä‘Ã³ náº±m ngoÃ i tuáº§n chá»©a black friday vÃ  nodel thÃ¬ mÃ¬nh dá»«ng. Sau má»™t há»“i tÃ¬m kiáº¿m vÃ  sá»‘ bÃ¡n Ä‘Ã£ xuáº¥t hiá»‡n, Ä‘Ã³ lÃ  290000\n1print(df.loc[df[\u0026#39;Weekly_Sales\u0026#39;] \u0026gt;290000,\u0026#34;Date\u0026#34;].value_counts()) 12010-11-26 16 22011-11-25 14 32010-12-24 8 42011-12-23 3 52010-02-05 1 LÃ m sáº¡ch dá»¯ liá»‡u Xá»­ lÃ½ missing values Má»™t váº¥n Ä‘á» khÃ¡ quan trá»ng lÃ  trong táº­p dá»¯ liá»‡u nÃ y missing value khÃ¡ nhiá»u, thá»­ Ä‘áº¿m sá»‘ lÆ°á»£ng null trong data cho ta biáº¿t Ä‘Æ°á»£c ráº±ng\n1CPI 38162 2Date 0 3Dept 0 4Fuel_Price 0 5IsHoliday_x 0 6IsHoliday_y 0 7MarkDown1 271038 8MarkDown2 338949 9MarkDown3 294308 10MarkDown4 299491 11MarkDown5 270138 12Size 0 13Split 0 14Store 0 15Temperature 0 16Type 0 17Unemployment 38162 18Weekly_Sales 115064 CÃ¡c giÃ¡ trá»‹ MarkDown bá»‹ null khÃ¡ nhiá»u, cÃ¡ch Ä‘Æ¡n giáº£n nháº¥t lÃ  set 0 cho táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ null ( MÃ¬nh lÆ°u log láº¡i nhá»¯ng index null cá»§a cÃ¡c markdown).\n1df = df.assign(md1_present = df[\u0026#39;MarkDown1\u0026#39;]notnull()) 2df = df.assign(md2_present = df[\u0026#39;MarkDown2\u0026#39;]notnull()) 3df = df.assign(md3_present = df[\u0026#39;MarkDown3\u0026#39;]notnull()) 4df = df.assign(md4_present = df[\u0026#39;MarkDown4\u0026#39;]notnull()) 5df = df.assign(md5_present = df[\u0026#39;MarkDown5\u0026#39;].notnull()) 6 7df.fillna(0, inplace=True) Táº¡o Ä‘áº·c trÆ°ng Äáº·c trÆ°ng holiday\n1df[\u0026#39;IsHoliday\u0026#39;] = \u0026#39;IsHoliday_\u0026#39; + df[\u0026#39;IsHoliday_x\u0026#39;].map(str) 2holiday_dummies = pd.get_dummies(df[\u0026#39;IsHoliday\u0026#39;]) Äáº·c trÆ°ng ngÃ y thÃ¡ng\nRÃºt trÃ­ch thÃ¡ng\n1df[\u0026#39;DateType\u0026#39;] = [datetime.strptime(date, \u0026#39;%Y-%m-%d\u0026#39;).date() for date in df[\u0026#39;Date\u0026#39;].astype(str).values.tolist()] 2df[\u0026#39;Month\u0026#39;] = [date.month for date in df[\u0026#39;DateType\u0026#39;]] 3df[\u0026#39;Month\u0026#39;] = \u0026#39;Month_\u0026#39; + df[\u0026#39;Month\u0026#39;].map(str) 4Month_dummies = pd.get_dummies(df[\u0026#39;Month\u0026#39;] ) RÃºt trÃ­ch ngÃ y trÆ°á»›c giÃ¡ng sinh vÃ  black friday\n1df[\u0026#39;Black_Friday\u0026#39;] = np.where((df[\u0026#39;DateType\u0026#39;]==datetime(2010, 11, 26).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2011, 11, 25).date()), \u0026#39;yes\u0026#39;, \u0026#39;no\u0026#39;) 2df[\u0026#39;Pre_christmas\u0026#39;] = np.where((df[\u0026#39;DateType\u0026#39;]==datetime(2010, 12, 23).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2010, 12, 24).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2011, 12, 23).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2011, 12, 24).date()), \u0026#39;yes\u0026#39;, \u0026#39;no\u0026#39;) 3df[\u0026#39;Black_Friday\u0026#39;] = \u0026#39;Black_Friday_\u0026#39; + df[\u0026#39;Black_Friday\u0026#39;].map(str) 4df[\u0026#39;Pre_christmas\u0026#39;] = \u0026#39;Pre_christmas_\u0026#39; + df[\u0026#39;Pre_christmas\u0026#39;].map(str) 5Black_Friday_dummies = pd.get_dummies(df[\u0026#39;Black_Friday\u0026#39;] ) 6Pre_christmas_dummies = pd.get_dummies(df[\u0026#39;Pre_christmas\u0026#39;] ) ThÃªm cÃ¡c Ä‘áº·c trÆ°ng vÃ o trong dá»¯ liá»‡u\n1 2df = pd.concat([df,holiday_dummies,Pre_christmas_dummies,Black_Friday_dummies],axis=1) ThÃªm Ä‘áº·c trÆ°ng trung vá»‹ cá»§a tá»«ng loáº¡i cá»­a hÃ ng vÃ o tá»«ng thÃ¡ng, do má»™t sá»‘ cá»§a hÃ ng sáº½ bá»‹ NA á»Ÿ cá»™t sá»‘ bÃ¡n á»Ÿ má»™t thá»i Ä‘iá»ƒm nÃ o Ä‘Ã³, nÃªn chÃºng ta replace sá»‘ bÃ¡n lÃ  0 cÃ³ váº» khÃ´ng há»£p lÃ½ láº¯m. MÃ¬nh chá»n cÃ¡ch lÃ  thay tháº¿ báº±ng trung bÃ¬nh cá»§a sá»‘ bÃ¡n trong thÃ¡ng cá»§a cá»­a hÃ ng cÃ¹ng loáº¡i. NhÆ°ng trÆ°á»›c tiÃªn thÃ¬ tÃ­nh trung bÃ¬nh sá»‘ bÃ¡n cá»§a tá»«ng loáº¡i cá»­a hÃ ng cÃ¡i Ä‘Ã£.\n1 2medians = pd.DataFrame({\u0026#39;Median Sales\u0026#39; :df.loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Train\u0026#39;].groupby(by=[\u0026#39;Type\u0026#39;,\u0026#39;Dept\u0026#39;,\u0026#39;Store\u0026#39;,\u0026#39;Month\u0026#39;,\u0026#39;IsHoliday\u0026#39;])[\u0026#39;Weekly_Sales\u0026#39;].median()}).reset_index() 3print(medians.head()) Káº¿t quáº£\n1 Type Dept Store Month IsHoliday Median Sales 20 Type_A Dept_1 Store_1 Month_1 IsHoliday_False 17350.585 31 Type_A Dept_1 Store_1 Month_10 IsHoliday_False 23388.030 42 Type_A Dept_1 Store_1 Month_11 IsHoliday_False 19551.115 53 Type_A Dept_1 Store_1 Month_11 IsHoliday_True 19865.770 64 Type_A Dept_1 Store_1 Month_12 IsHoliday_False 39109.390 thÃªm dá»¯ liá»‡u vÃ o trong data chÃ­nh, loáº¡i bá» NA vÃ  táº¡o key cho má»—i dÃ²ng Ä‘á»ƒ dá»… dÃ ng truy xuáº¥t\n1df = df.merge(medians, how = \u0026#39;outer\u0026#39;, on = [\u0026#39;Type\u0026#39;,\u0026#39;Dept\u0026#39;,\u0026#39;Store\u0026#39;,\u0026#39;Month\u0026#39;,\u0026#39;IsHoliday\u0026#39;]) 2 3# Fill NA 4df[\u0026#39;Median Sales\u0026#39;].fillna(df[\u0026#39;Median Sales\u0026#39;].loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Train\u0026#39;].median(), inplace=True) 5 6# Create a key for easy access 7 8df[\u0026#39;Key\u0026#39;] = df[\u0026#39;Type\u0026#39;].map(str)+df[\u0026#39;Dept\u0026#39;].map(str)+df[\u0026#39;Store\u0026#39;].map(str)+df[\u0026#39;Date\u0026#39;].map(str)+df[\u0026#39;IsHoliday\u0026#39;].map(str) ChÃºng ta sáº½ dá»± Ä‘oÃ¡n sá»‘ bÃ¡n cá»§a tuáº§n káº¿ tiáº¿p dá»±a vÃ o káº¿t quáº£ sá»‘ bÃ¡n cá»§a tuáº§n hiá»‡n táº¡i, nÃªn trong dá»¯ liá»‡u sáº½ lÆ°u trÃªn ngÃ y cá»§a tuáº§n trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ dá»… truy xuáº¥t. VÃ¬ 1 tuáº§n cÃ³ 7 ngÃ y, chÃºng ta sáº½ lÆ°u giÃ¡ trá»‹ lÃ  ngÃ y á»Ÿ cá»™t hiá»‡n táº¡i - 7\n1df[\u0026#39;DateLagged\u0026#39;] = df[\u0026#39;DateType\u0026#39;]- timedelta(days=7) VÃ  giá» Ä‘Ã¢y, chÃºng ta sáº½ láº·p qua toÃ n bá»™ cÃ¡c dÃ²ng trÃªn táº­p dá»¯ liá»‡u, kiá»ƒm tra xem cÃ³ dÃ²ng nÃ o sá»‘ bÃ¡n nan hÃ´ng, náº¿u cÃ³ thÃ¬ sáº½ thay báº±ng trung bÃ¬nh Ä‘Ã£ tÃ­nh á»Ÿ trÃªn. á» Ä‘Ã¢y mÃ¬nh táº¡o má»™t sorted dataset Ä‘á»ƒ truy xuáº¥t cho nhanh\n1 2#Make a sorted dataframe. This will allow us to find lagged variables much faster! 3sorted_df = df.sort_values([\u0026#39;Store\u0026#39;, \u0026#39;Dept\u0026#39;,\u0026#39;DateType\u0026#39;], ascending=[1, 1,1]) 4sorted_df = sorted_df.reset_index(drop=True) # Reinitialize the row indices for the loop to work 5 6sorted_df[\u0026#39;LaggedSales\u0026#39;] = np.nan # Initialize column 7sorted_df[\u0026#39;LaggedAvailable\u0026#39;] = np.nan # Initialize column 8last=df.loc[0] # intialize last row for first iteration. Doesn\u0026#39;t really matter what it is 9row_len = sorted_df.shape[0] 10for index, row in sorted_df.iterrows(): 11 lag_date = row[\u0026#34;DateLagged\u0026#34;] 12 # Check if it matches by comparing last weeks value to the compared date 13 # And if weekly sales aren\u0026#39;t 0 14 if((last[\u0026#39;DateType\u0026#39;]== lag_date) \u0026amp; (last[\u0026#39;Weekly_Sales\u0026#39;]\u0026gt;0)): 15 sorted_df.set_value(index, \u0026#39;LaggedSales\u0026#39;,last[\u0026#39;Weekly_Sales\u0026#39;]) 16 sorted_df.set_value(index, \u0026#39;LaggedAvailable\u0026#39;,1) 17 else: 18 sorted_df.set_value(index, \u0026#39;LaggedSales\u0026#39;,row[\u0026#39;Median Sales\u0026#39;]) # Fill with median 19 sorted_df.set_value(index, \u0026#39;LaggedAvailable\u0026#39;,0) 20 21 last = row #Remember last row for speed 22 if(index%int(row_len/10)==0): #See progress by printing every 10% interval 23 print(str(int(index*100/row_len))+\u0026#39;% loaded\u0026#39;) 24 25print(sorted_df[[\u0026#39;Dept\u0026#39;, \u0026#39;Store\u0026#39;,\u0026#39;DateType\u0026#39;,\u0026#39;LaggedSales\u0026#39;,\u0026#39;Weekly_Sales\u0026#39;,\u0026#39;Median Sales\u0026#39;]].head()) 19% loaded 219% loaded 329% loaded 439% loaded 549% loaded 659% loaded 769% loaded 879% loaded 989% loaded 1099% loaded 11 Dept Store DateType LaggedSales Weekly_Sales Median Sales 120 Dept_1 Store_1 2010-02-05 23510.49 24924.50 23510.49 131 Dept_1 Store_1 2010-02-12 24924.50 46039.49 37887.17 142 Dept_1 Store_1 2010-02-19 46039.49 41595.55 23510.49 153 Dept_1 Store_1 2010-02-26 41595.55 19403.54 23510.49 164 Dept_1 Store_1 2010-03-05 19403.54 21827.90 21280.40 CÃ´ng viá»‡c Ä‘Æ¡n giáº£n tiáº¿p theo lÃ  merge dá»¯ liá»‡u vÃ o data chÃ­nh vÃ  tÃ­nh Ä‘á»™ lá»‡ch giá»¯a 2 tuáº§n bÃ¡n\n1# Merge by store and department 2df = df.merge(sorted_df[[\u0026#39;Dept\u0026#39;, \u0026#39;Store\u0026#39;,\u0026#39;DateType\u0026#39;,\u0026#39;LaggedSales\u0026#39;,\u0026#39;LaggedAvailable\u0026#39;]], how = \u0026#39;inner\u0026#39;, on = [\u0026#39;Dept\u0026#39;, \u0026#39;Store\u0026#39;,\u0026#39;DateType\u0026#39;]) 3df[\u0026#39;Sales_dif\u0026#39;] = df[\u0026#39;Median Sales\u0026#39;] - df[\u0026#39;LaggedSales\u0026#39;] VÃ  bÃ¢y giá» , thay vÃ¬ ta Æ°á»›c lÆ°á»£ng weekly sales, chÃºng ta sáº½ Æ°á»›c lÆ°á»£ng Ä‘á»™ lá»‡ch giá»¯a week sales vÃ  median sales (Ä‘Ã¢y lÃ  má»™t cÃ¡ch trong nhá»¯ng cÃ¡ch Ä‘á»ƒ tÃ­nh Ä‘iá»ƒm dá»«ng cá»§a dá»¯ liá»‡u time series)\n1df[\u0026#39;Difference\u0026#39;] = df[\u0026#39;Median Sales\u0026#39;] - df[\u0026#39;Weekly_Sales\u0026#39;] Huáº¥n luyá»‡n mÃ´ hÃ¬nh Lá»±a chá»n cÃ¡c Ä‘áº·c trÆ°ng huáº¥n luyá»‡n\n1selector = [ 2 #\u0026#39;Month\u0026#39;, 3 \u0026#39;CPI\u0026#39;, 4 \u0026#39;Fuel_Price\u0026#39;, 5 \u0026#39;MarkDown1\u0026#39;, 6 \u0026#39;MarkDown2\u0026#39;, 7 \u0026#39;MarkDown3\u0026#39;, 8 \u0026#39;MarkDown4\u0026#39;, 9 \u0026#39;MarkDown5\u0026#39;, 10 \u0026#39;Size\u0026#39;, 11 \u0026#39;Temperature\u0026#39;, 12 \u0026#39;Unemployment\u0026#39;, 13 14 15 16 \u0026#39;md1_present\u0026#39;, 17 \u0026#39;md2_present\u0026#39;, 18 \u0026#39;md3_present\u0026#39;, 19 \u0026#39;md4_present\u0026#39;, 20 \u0026#39;md5_present\u0026#39;, 21 22 \u0026#39;IsHoliday_False\u0026#39;, 23 \u0026#39;IsHoliday_True\u0026#39;, 24 \u0026#39;Pre_christmas_no\u0026#39;, 25 \u0026#39;Pre_christmas_yes\u0026#39;, 26 \u0026#39;Black_Friday_no\u0026#39;, 27 \u0026#39;Black_Friday_yes\u0026#39;, 28 \u0026#39;LaggedSales\u0026#39;, 29 \u0026#39;Sales_dif\u0026#39;, 30 \u0026#39;LaggedAvailable\u0026#39; 31 ] TÃ¡ch dá»¯ liá»‡u train vÃ  test riÃªng ra\n1 2train = df.loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Train\u0026#39;] 3test = df.loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Test\u0026#39;] Láº¥y ngáº«u nhiÃªn 20% dá»¯ liá»‡u á»Ÿ táº­p train Ä‘á»ƒ validation\n1# Set seed for reproducability 2np.random.seed(42) 3X_train, X_val, y_train, y_val = train_test_split(train[selector], train[\u0026#39;Difference\u0026#39;], test_size=0.2, random_state=42) Huáº¥n luyá»‡n báº±ng neural network sá»­ dá»¥ng lstm\n1 2adam_regularized = Sequential() 3 4 # First hidden layer now regularized 5 model.add(Dense(32,activation=\u0026#39;relu\u0026#39;, 6 input_dim=X_train.shape[1], 7 kernel_regularizer = regularizers.l2(0.01))) 8 9 # Second hidden layer now regularized 10 adam_regularized.add(Dense(16,activation=\u0026#39;relu\u0026#39;, 11 kernel_regularizer = regularizers.l2(0.01))) 12 13 # Output layer stayed sigmoid 14 adam_regularized.add(Dense(1,activation=\u0026#39;linear\u0026#39;)) 15 16 # Setup adam optimizer 17 adam_optimizer=keras.optimizers.Adam(lr=0.01, 18 beta_1=0.9, 19 beta_2=0.999, 20 epsilon=1e-08) 21 22 # Compile the model 23 adam_regularized.compile(optimizer=adam_optimizer, 24 loss=\u0026#39;mean_absolute_error\u0026#39;, 25 metrics=[\u0026#39;acc\u0026#39;]) 26 27 # Train 28 history=adam_regularized.fit(X_train, y_train, # Train on training set 29 epochs=10, # We will train over 1,000 epochs 30 batch_size=2048, # Batch size 31 verbose=0) # Suppress Keras output 32 print(\u0026#39;eval\u0026#39;,model.evaluate(x=X_val,y=y_val)) 33 34 # Plot network 35 plt.plot(history.history[\u0026#39;loss\u0026#39;], label=\u0026#39;Adam Regularized\u0026#39;) 36 plt.xlabel(\u0026#39;Epochs\u0026#39;) 37 plt.ylabel(\u0026#39;loss\u0026#39;) 38 plt.legend() 39 plt.show() 1eval: [1457.0501796214685, 0.002312783168124545] Äá»™ lá»—i trÃªn táº­p train\nÄá»™ lá»—i trÃªn táº­p train giáº£m xuá»‘ng Ä‘áº¿n gáº§n 1450 thÃ¬ Ä‘á»«ng háº³n, khÃ´ng thá»ƒ giáº£m Ä‘Æ°á»£c ná»¯a\nGiÃ¡ trá»‹ Ä‘á»™ lá»‡ch trÃªn táº­p evaluation lÃ  1457.0501796214685\nThá»­ huáº¥n luyá»‡n báº±ng random forest\n1regr = RandomForestRegressor(n_estimators=20, criterion=\u0026#39;mse\u0026#39;, max_depth=None, 2 min_samples_split=2, min_samples_leaf=1, 3 min_weight_fraction_leaf=0.0, max_features=\u0026#39;auto\u0026#39;, 4 max_leaf_nodes=None, min_impurity_decrease=0.0, 5 min_impurity_split=None, bootstrap=True, 6 oob_score=False, n_jobs=1, random_state=None, 7 verbose=2, warm_start=False) 8 9 #Train on data 10 regr.fit(X_train, y_train.ravel()) 11 y_pred_random = regr.predict(X_val) 12 13 y_val = y_val.to_frame() 14 15 # Transform forest predictions to observe direction of change 16 direction_true1= y_val.values 17 direction_predict = y_pred_random 18 19 y_val[\u0026#39;Predicted\u0026#39;] = y_pred_random 20 df_out = pd.merge(train,y_val[[\u0026#39;Predicted\u0026#39;]],how = \u0026#39;left\u0026#39;,left_index = True, right_index = True,suffixes=[\u0026#39;_True\u0026#39;,\u0026#39;_Pred\u0026#39;]) 21 df_out = df_out[~pd.isnull(df_out[\u0026#39;Predicted\u0026#39;])] 22 23 df_out[\u0026#39;prediction\u0026#39;] = df_out[\u0026#39;Median Sales\u0026#39;]-df_out[\u0026#39;Predicted\u0026#39;] 24 25 print(\u0026#34;Medians: \u0026#34;+str(sum(abs(df_out[\u0026#39;Difference\u0026#39;]))/df_out.shape[0])) 26 print(\u0026#34;Random Forest: \u0026#34;+str(sum(abs(df_out[\u0026#39;Weekly_Sales\u0026#39;]-df_out[\u0026#39;prediction\u0026#39;]))/df_out.shape[0])) Káº¿t quáº£\n1 29% loaded 319% loaded 429% loaded 539% loaded 649% loaded 759% loaded 869% loaded 979% loaded 1089% loaded 1199% loaded 12 Dept Store DateType LaggedSales Weekly_Sales Median Sales 130 Dept_1 Store_1 2010-02-05 23510.49 24924.50 23510.49 141 Dept_1 Store_1 2010-02-12 24924.50 46039.49 37887.17 152 Dept_1 Store_1 2010-02-19 46039.49 41595.55 23510.49 163 Dept_1 Store_1 2010-02-26 41595.55 19403.54 23510.49 174 Dept_1 Store_1 2010-03-05 19403.54 21827.90 21280.40 18[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. 19building tree 1 of 20 20[Parallel(n_jobs=1)]: Done 1 out of 1 | elapsed: 6.5s remaining: 0.0s 21building tree 2 of 20 22building tree 3 of 20 23building tree 4 of 20 24building tree 5 of 20 25building tree 6 of 20 26building tree 7 of 20 27building tree 8 of 20 28building tree 9 of 20 29building tree 10 of 20 30building tree 11 of 20 31building tree 12 of 20 32building tree 13 of 20 33building tree 14 of 20 34building tree 15 of 20 35building tree 16 of 20 36building tree 17 of 20 37building tree 18 of 20 38building tree 19 of 20 39building tree 20 of 20 40[Parallel(n_jobs=1)]: Done 20 out of 20 | elapsed: 2.2min finished 41[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. 42[Parallel(n_jobs=1)]: Done 1 out of 1 | elapsed: 0.0s remaining: 0.0s 43[Parallel(n_jobs=1)]: Done 20 out of 20 | elapsed: 1.1s finished 44Medians: 1545.7406070759525 45Random Forest: 1356.4670052620745 Trung bÃ¬nh lá»‡ch cá»§a random forest lÃ  1356, giÃ¡ trá»‹ nÃ y nhá» hÆ¡n so vá»›i giÃ¡ trá»‹ output cá»§a lstm tráº£ vá».\nThá»­ huáº¥n luyá»‡n báº±ng XGBoost\n1 2param_dist = { \u0026#39;max_depth\u0026#39;:5} 3 4 model = XGBRegressor(**param_dist) 5 6 #Train on data 7 model.fit(X_train, y_train.ravel()) 8 y_pred_random = model.predict(X_val) 9 10 y_val = y_val.to_frame() 11 12 # Transform forest predictions to observe direction of change 13 direction_true1= y_val.values 14 direction_predict = y_pred_random 15 16 y_val[\u0026#39;Predicted\u0026#39;] = y_pred_random 17 df_out = pd.merge(train,y_val[[\u0026#39;Predicted\u0026#39;]],how = \u0026#39;left\u0026#39;,left_index = True, right_index = True,suffixes=[\u0026#39;_True\u0026#39;,\u0026#39;_Pred\u0026#39;]) 18 df_out = df_out[~pd.isnull(df_out[\u0026#39;Predicted\u0026#39;])] 19 20 df_out[\u0026#39;prediction\u0026#39;] = df_out[\u0026#39;Median Sales\u0026#39;]-df_out[\u0026#39;Predicted\u0026#39;] 21 22 print(\u0026#34;Medians: \u0026#34;+str(sum(abs(df_out[\u0026#39;Difference\u0026#39;]))/df_out.shape[0])) 23 print(\u0026#34;XGB Regressor: \u0026#34;+str(sum(abs(df_out[\u0026#39;Weekly_Sales\u0026#39;]-df_out[\u0026#39;prediction\u0026#39;]))/df_out.shape[0])) Káº¿t quáº£\n1 2Medians: 1545.7406070759525 3XGB Regressor: 1354.1976755192593 Káº¿t quáº£ cÅ©ng gáº§n nhÆ° báº±ng Random forest :).\nGiá» mÃ¬nh sáº½ dÃ¹ng random forest Ä‘á»ƒ táº¡o file submission\n1 2 3rf_model = RandomForestRegressor(n_estimators=80, criterion=\u0026#39;mse\u0026#39;, max_depth=None, 4 min_samples_split=2, min_samples_leaf=1, 5 min_weight_fraction_leaf=0.0, max_features=\u0026#39;auto\u0026#39;, 6 max_leaf_nodes=None, min_impurity_decrease=0.0, 7 min_impurity_split=None, bootstrap=True, 8 oob_score=False, n_jobs=1, random_state=None, 9 verbose=0, warm_start=False) 10 11#Train on data 12rf_model.fit(train[selector], train[\u0026#39;Difference\u0026#39;]) 13final_y_prediction = rf_model.predict(test[selector]) 14 15testfile = pd.concat([test.reset_index(drop=True), pd.DataFrame(final_y_prediction)], axis=1) 16testfile[\u0026#39;prediction\u0026#39;] = testfile[\u0026#39;Median Sales\u0026#39;]-testfile[0] 17 18submission = pd.DataFrame({\u0026#39;id\u0026#39;:pd.Series([\u0026#39;\u0026#39;.join(list(filter(str.isdigit, x))) for x in testfile[\u0026#39;Store\u0026#39;]]).map(str) + \u0026#39;_\u0026#39; + 19 pd.Series([\u0026#39;\u0026#39;.join(list(filter(str.isdigit, x))) for x in testfile[\u0026#39;Dept\u0026#39;]]).map(str) + \u0026#39;_\u0026#39; + 20 testfile[\u0026#39;Date\u0026#39;].map(str), 21 \u0026#39;Weekly_Sales\u0026#39;:testfile[\u0026#39;prediction\u0026#39;]}) 22 23submission.to_csv(\u0026#39;submission.csv\u0026#39;,index=False) Sau khi submit mÃ´ hÃ¬nh, mÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ lÃ  4455.96312 trÃªn private board, vÃ  4419.17292 trÃªn publish board. ÄÃ¢y lÃ  má»™t káº¿t quáº£ khÃ¡ tá»‡ (Ä‘á»©ng háº¡ng khoáº£ng top 300). Sau khi mÃ¬nh nhÃ¬n láº¡i mÃ´ hÃ¬nh thÃ¬ phÃ¡t hiá»‡n má»™t sá»‘ váº¥n Ä‘á».\nCÃ¡c Ä‘áº·c trÆ°ng trong file features.csv nÃ³ khÃ´ng cÃ³ má»‘i tÆ°Æ¡ng quan gÃ¬ háº¿t vá»›i sá»‘ bÃ¡n nhÆ° phÃ¢n tÃ­ch á»Ÿ trÃªn -\u0026gt; mÃ¬nh máº¡nh dáº¡ng bá» luÃ´n file features.csv, khÃ´ng quan tÃ¢m Ä‘áº¿n nÃ³ ná»¯a, táº­p trung vÃ o file chÃ­nh.\nBá» máº¥y cÃ¡i lag luÃ´n, thá»­ forecast chÃ­nh vÃ o cÃ¡i sá»‘ bÃ¡n luÃ´n xem sao\nVá»›i cá»­a hÃ ng nÃ o thÃ¬ xÃ¢y dá»±ng mÃ´ hÃ¬nh cho cá»­a hÃ ng vÃ  sáº£n pháº©m Ä‘Ã³, khÃ´ng xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh tá»•ng quÃ¡t Ã¡p dá»¥ng cho toÃ n cá»­a hÃ ng. vá»›i nhá»¯ng cá»­a hÃ ng khÃ´ng cÃ³ trong táº­p train hoáº·c nhá»¯ng sáº£n pháº©m mÃ  cá»­a hÃ ng Ä‘Ã³ chÆ°a bÃ¡n trÆ°á»›c Ä‘Ã¢y (nÃ³i chung lÃ  khÃ´ng cÃ³ trong táº­p train) thÃ¬ má»›i Ã¡p dá»¥ng mÃ´ hÃ¬nh cá»§a toÃ n cá»­a hÃ ng cho nÃ³.\nKáº¿t quáº£ lÃ  mÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c 2736 trÃªn private board vÃ  2657.40087 trÃªn publish board (top 30), káº¿t quáº£ trÃªn váº«n lÃ m cho mÃ¬nh chÆ°a hÃ i lÃ²ng láº¯m.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Apr 17, 2019","img":"","permalink":"/blog/2019-04-17-walmart-store-sales-forecasting/","series":null,"tags":["walmart","forecast","dá»± Ä‘oÃ¡n"],"title":"Dá»± ÄoÃ¡n Doanh Sá»‘ BÃ¡n Cá»§a CÃ¡c Cá»­a HÃ ng Walmart"},{"categories":null,"content":" Thá»±c hiá»‡n Thu tháº­p hÃ¬nh áº£nh vÃ  tiá»n xá»­ lÃ½ Thá»±c hiá»‡n ÄÃ¢y lÃ  má»™t bÃ i toÃ¡n tiáº¿p cáº­n báº±ng Deep Learning, nÃªn viá»‡c thu tháº­p nhiá»u dá»¯ liá»‡u cÃ³ Ã½ nghÄ©a ráº¥t quang trá»ng trong viá»‡c Ä‘Ã³ng gÃ³p vÃ o Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh. á» Ä‘Ã¢y, chÃºng ta sáº½ download táº­p dá»¯ liá»‡u áº£nh cá»§a http://places2.csail.mit.edu/download.html vÃ  sá»­ dá»¥ng máº¡ng UNet Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh.\nThu tháº­p hÃ¬nh áº£nh vÃ  tiá»n xá»­ lÃ½ Dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c download táº¡i Ä‘á»‹a chá»‰ http://data.csail.mit.edu/places/places365/train_256_places365challenge.tar. Táº­p trÃªn cÃ³ kÃ­ch thÆ°á»›c 108 GB. ÄÃ¢y lÃ  táº­p áº£nh thuá»™c há»‡ mÃ u RGB. ChÃºng ta sáº½ chuyá»ƒn táº­p áº£nh trÃªn vá» há»‡ mÃ u grayscale lÃ m áº£nh gá»‘c cho quÃ¡ trÃ¬nh huáº¥n luyá»‡n. CÃ³ má»™t máº¹o nhá» cho chÃºng ta rÃºt ngáº¯n quÃ¡ trÃ¬nh huáº¥n luyá»‡n nhÆ°ng váº«n Ä‘áº£m báº£o Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh lÃ  ngoÃ i kÃªnh mÃ u RGB mÃ  chÃºng ta hay xÃ i, trÃªn tháº¿ giá»›i cÃ²n cÃ³ kÃªnh mÃ u HSV, trong Ä‘Ã³ náº¿u chÃºng ta chuyá»ƒn má»™t áº£nh á»Ÿ kÃªnh mÃ u RGB vá» há»‡ mÃ u HSV, vÃ  bá» Ä‘i cÃ¡c giÃ¡ trá»‹ H, S, chá»‰ giá»¯ láº¡i giÃ¡ trá»‹ V, thÃ¬ cháº¥t lÆ°á»£ng áº£nh xÃ¡m cá»§a nÃ³ gáº§n nhÆ° lÃ  tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i áº£nh grayscale sá»­ dá»¥ng cÃ´ng thá»©c \u0026ldquo;tháº§n thÃ¡nh\u0026rdquo; mÃ  chÃºng ta Ä‘Æ°á»£c há»c á»Ÿ mÃ´n xá»­ lÃ½ áº£nh grayscale =0.30*R + 0.59*G + 0.11*B\nVÃ¬ váº­y, thay vÃ¬ viá»‡c input lÃ  giÃ¡ trá»‹ xÃ¡m cá»§a áº£nh, output lÃ  giÃ¡ trá»‹ cá»§a cÃ¡c kÃªnh mÃ u RGB, chÃºng ta sáº½ chuyá»ƒn Ä‘á»•i bÃ i toÃ¡n láº¡i lÃ  input lÃ  giÃ¡ trá»‹ xÃ¡m, output lÃ  giÃ¡ trá»‹ H vÃ  S.\nMÃ´ hÃ¬nh máº¡ng Unet\nMáº¡ng UNet lÃ  má»™t máº¡ng neural network Ä‘Æ°á»£c dÃ¹ng khÃ¡ phá»• biáº¿n trong cÃ¡c cuá»™c thi phÃ¢n Ä‘oáº¡n áº£nh, Ä‘á»™ chÃ­nh xÃ¡c cá»§a nÃ³ so vá»›i cÃ¡c thuáº­t toÃ¡n khÃ¡c lÃ  vÆ°á»£t trá»™i hoÃ n toÃ n. á» Ä‘Ã¢y, chÃºng ta cÃ³ 2 hÆ°á»›ng tiáº¿p cáº­n, má»™t lÃ  build má»™t máº¡ng Unet vÃ  random init weight rá»“i huáº¥n luyá»‡n nÃ³, cÃ¡ch thá»© hai lÃ  build máº¡ng unet sá»­ dá»¥ng pretrain model rá»“i huáº¥n luyá»‡n. Bá»Ÿi vÃ¬ Ä‘áº·c trÆ°ng cá»§a cÃ¡c pretrain model hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t vÃ  Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn táº­p dataset lá»›n, nÃªn mÃ¬nh sáº» sá»­ dá»¥ng nÃ³ á»Ÿ bÃ i viáº¿t nÃ y. Song song Ä‘Ã³, mÃ¬nh sáº½ cung cáº¥p má»™t giáº£i phÃ¡p kÃ¨m theo sá»­ Ä‘á»ƒ sá»­ dá»¥ng máº¡ng mÃ  khÃ´ng dÃ¹ng pretrain model.\nÃš tÆ°á»Ÿng chÃ­nh cá»§a máº¡ng UNet tá»±a tá»±a nhÆ° auto-encoder, tá»« áº£nh gá»‘c ban Ä‘áº§u, chÃºng sáº½ Ä‘Æ°á»£c nÃ©n thÃ´ng tin láº¡i qua cÃ¡c phÃ©p biáº¿n Ä‘á»•i Conv2D (nhÆ° cÃ¡c chÃº thÃ­ch mÃ u sáº¯c cá»§a mÅ©i tÃªn trong hÃ¬nh trÃªn), sau Ä‘Ã³ sáº½ Ä‘Æ°á»£c \u0026ldquo;giáº£i nÃ©n\u0026rdquo; vá» láº¡i áº£nh gá»‘c ban Ä‘áº§u. Viá»‡c huáº¥n luyá»‡n coi nhÆ° lÃ  hoÃ n táº¥t 100% náº¿u áº£nh gá»‘c vá»›i áº£nh giáº£i nÃ©n lÃ  lÃ  giá»‘ng nhau hoÃ n toÃ n.\nBÃ i viáº¿t sáº½ Ä‘Æ°á»£c cáº­p nháº­t\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Apr 16, 2019","img":"","permalink":"/blog/2019-04-16-colorfull-grayscale-to-color/","series":null,"tags":["machine learning","deep learning","neural network","amazone","tháº¿ giá»›i di Ä‘á»™ng","mwg"],"title":"Thá»­ LÃ m á»¨ng Dá»¥ng TÃ´ MÃ u áº¢nh XÃ¡m ThÃ nh áº¢nh MÃ u Sá»­ Dá»¥ng Tensorflow"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Thá»±c hiá»‡n Lá»i má»Ÿ Ä‘áº§u á» trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ sá»­ dá»¥ng táº­p dá»¯ liá»‡u lÃ  táº­p dá»¯ liá»‡u á»Ÿ á»Ÿ link https://www.kaggle.com/alxmamaev/flowers-recognition. Táº­p dá»¯ liá»‡u nÃ y bao gá»“m 4242 hÃ¬nh cáº£nh cá»§a 5 loáº¡i hoa há»“ng (rose), hoa máº·t trá»i (sunflower), hoa bá»“ cÃ´ng anh (dandelion), hoa cÃºc (daisy) vÃ  hoa tulip. NhÃ³m tÃ¡c giáº£ Ä‘Ã£ thu tháº­p dá»¯ liá»‡u dá»±a trÃªn cÃ¡c trang web flicr, google images, yandex. Táº­p hÃ¬nh áº£nh Ä‘Æ°á»£c chia thÃ nh 5 lá»›p, má»—i lá»›p cÃ³ khoáº£ng 800 hÃ¬nh, cÃ³ kÃ­ch thÆ°á»›c xáº¥p xá»‰ 320x320 pixel. CÃ¡c hÃ¬nh áº£nh cÃ³ kÃ­ch thÆ°á»›c khÃ´ng Ä‘á»“ng nháº¥t vá»›i nhau.\nThá»±c hiá»‡n Dá»¯ liá»‡u sau khi giáº£n nÃ©n cÃ³ dáº¡ng\n1data_dir/classname1/*.* 2data_dir/classname2/*.* 3... Cáº¥u trÃºc lÆ°u trÅ© nhÆ° nÃ y Ä‘Ãºng vá»›i mÃ´ hÃ¬nh cá»§a mÃ¬nh nÃªn chÃºng ta cáº§n nÃªn chÃºng ta khÃ´ng thay Ä‘á»•i gÃ¬ vá» cÃ¢u trÃºc ná»¯a, tiáº¿n hÃ nh viáº¿t code\nÄáº§u tiÃªn, chÃºng ta sáº½ load dataset lÃªn vÃ  tranform nÃ³ Ä‘á»ƒ Ä‘Æ°a vÃ o huáº¥n luyá»‡n.\n1import sys 2import os 3from collections import defaultdict 4import numpy as np 5import scipy.misc 6 7 8def preprocess_input(x0): 9 x = x0 / 255. 10 x -= 0.5 11 x *= 2. 12 return x 13 14 15def reverse_preprocess_input(x0): 16 x = x0 / 2.0 17 x += 0.5 18 x *= 255. 19 return x 20 21 22def dataset(base_dir, n): 23 print(\u0026#34;base dir: \u0026#34;+base_dir) 24 print(\u0026#34;n: \u0026#34;+str(n)) 25 n = int(n) 26 d = defaultdict(list) 27 for root, subdirs, files in os.walk(base_dir): 28 for filename in files: 29 file_path = os.path.join(root, filename) 30 assert file_path.startswith(base_dir) 31 32 suffix = file_path[len(base_dir):] 33 34 suffix = suffix.lstrip(\u0026#34;/\u0026#34;) 35 suffix = suffix.lstrip(\u0026#34;\\\\\u0026#34;) 36 if(suffix.find(\u0026#39;/\u0026#39;)\u0026gt;-1): #linux 37 label = suffix.split(\u0026#34;/\u0026#34;)[0] 38 else: #window 39 label = suffix.split(\u0026#34;\\\\\u0026#34;)[0] 40 d[label].append(file_path) 41 print(\u0026#34;walk directory complete\u0026#34;) 42 tags = sorted(d.keys()) 43 44 processed_image_count = 0 45 useful_image_count = 0 46 47 X = [] 48 y = [] 49 50 for class_index, class_name in enumerate(tags): 51 filenames = d[class_name] 52 for filename in filenames: 53 processed_image_count += 1 54 if processed_image_count%100 ==0: 55 print(class_name+\u0026#34;\\tprocess: \u0026#34;+str(processed_image_count)+\u0026#34;\\t\u0026#34;+str(len(d[class_name]))) 56 img = scipy.misc.imread(filename) 57 height, width, chan = img.shape 58 assert chan == 3 59 aspect_ratio = float(max((height, width))) / min((height, width)) 60 if aspect_ratio \u0026gt; 2: 61 continue 62 # We pick the largest center square. 63 centery = height // 2 64 centerx = width // 2 65 radius = min((centerx, centery)) 66 img = img[centery-radius:centery+radius, centerx-radius:centerx+radius] 67 img = scipy.misc.imresize(img, size=(n, n), interp=\u0026#39;bilinear\u0026#39;) 68 X.append(img) 69 y.append(class_index) 70 useful_image_count += 1 71 print(\u0026#34;processed %d, used %d\u0026#34; % (processed_image_count, useful_image_count)) 72 73 X = np.array(X).astype(np.float32) 74 #X = X.transpose((0, 3, 1, 2)) 75 X = preprocess_input(X) 76 y = np.array(y) 77 78 perm = np.random.permutation(len(y)) 79 X = X[perm] 80 y = y[perm] 81 82 print(\u0026#34;classes:\u0026#34;,end=\u0026#34; \u0026#34;) 83 for class_index, class_name in enumerate(tags): 84 print(class_name, sum(y==class_index),end=\u0026#34; \u0026#34;) 85 print(\u0026#34;X shape: \u0026#34;,X.shape) 86 87 return X, y, tags Äoáº¡n code trÃªn khÃ¡ Ä‘Æ¡n giáº£n vÃ  dá»… hiá»ƒu. LÆ°u Ã½ á»Ÿ Ä‘Ã¢y lÃ  vá»›i nhá»¯ng bá»©c áº£nh cÃ³ tá»· lá»‡ width vÃ  height \u0026gt; 2 thÃ¬ mÃ¬nh sáº½ loáº¡i chÃºng ra khá»i táº­p dá»¯ liá»‡u.\nTiáº¿p theo, chÃºng ta sáº½ xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»±a trÃªn mÃ´ hÃ¬nh Resnet50 cÃ³ sáºµn cá»§a kares, do sá»­ dá»¥ng pretrain model, nÃªn n-1 lá»›p trÆ°á»›c Ä‘Ã³ sáº½ khÃ´ng Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  chÃºng ta sáº½ sá»­ dá»¥ng dá»¥ng cÃ¡c weight cÃ³ sáºµn Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn táº­p ImageNet rÃºt Ä‘áº·c trÆ°ng cho mÃ´ hÃ¬nh. ChÃºng ta chá»‰ cáº§n thÃªm má»™t lá»›p full connected vÃ  softmax Ä‘á»ƒ phÃ¢n lá»›p cÃ¡c loáº¡i hoa, cÃ´ng viá»‡c cá»§a chÃºng ta hiá»‡n táº¡i lÃ  tÃ¬m ra trá»ng sá»‘ cá»§a lá»›p full connected cuá»‘i cÃ¹ng (thay vÃ¬ huáº¥n luyá»‡n láº¡i háº¿t toÃ n bá»™ mÃ´ hÃ¬nh).\n1 2# create the base pre-trained model 3def build_model(nb_classes): 4 base_model = ResNet50(weights=\u0026#39;imagenet\u0026#39;, include_top=False) 5 6 # add a global spatial average pooling layer 7 x = base_model.output 8 x = GlobalAveragePooling2D()(x) 9 # let\u0026#39;s add a fully-connected layer 10 x = Dense(1024, activation=\u0026#39;relu\u0026#39;)(x) 11 # and a logistic layer 12 predictions = Dense(nb_classes, activation=\u0026#39;softmax\u0026#39;)(x) 13 14 # this is the model we will train 15 model = Model(inputs=base_model.input, outputs=predictions) 16 17 # first: train only the top layers (which were randomly initialized) 18 # i.e. freeze all convolutional ResNet50 layers 19 for layer in base_model.layers: 20 layer.trainable = False 21 22 return model Visualize má»™t chÃºt xÃ­u vá» kiáº¿n trÃºc inceptionV3 mÃ¬nh Ä‘ang dÃ¹ng.\n1__________________________________________________________________________________________________ 2Layer (type) Output Shape Param # Connected to 3================================================================================================== 4input_1 (InputLayer) (None, None, None, 3 0 5__________________________________________________________________________________________________ 6conv1_pad (ZeroPadding2D) (None, None, None, 3 0 input_1[0][0] 7__________________________________________________________________________________________________ 8conv1 (Conv2D) (None, None, None, 6 9472 conv1_pad[0][0] 9__________________________________________________________________________________________________ 10bn_conv1 (BatchNormalization) (None, None, None, 6 256 conv1[0][0] 11__________________________________________________________________________________________________ 12activation_1 (Activation) (None, None, None, 6 0 bn_conv1[0][0] 13__________________________________________________________________________________________________ 14pool1_pad (ZeroPadding2D) (None, None, None, 6 0 activation_1[0][0] 15__________________________________________________________________________________________________ 16max_pooling2d_1 (MaxPooling2D) (None, None, None, 6 0 pool1_pad[0][0] 17__________________________________________________________________________________________________ 18res2a_branch2a (Conv2D) (None, None, None, 6 4160 max_pooling2d_1[0][0] 19__________________________________________________________________________________________________ 20bn2a_branch2a (BatchNormalizati (None, None, None, 6 256 res2a_branch2a[0][0] 21__________________________________________________________________________________________________ 22activation_2 (Activation) (None, None, None, 6 0 bn2a_branch2a[0][0] 23__________________________________________________________________________________________________ 24res2a_branch2b (Conv2D) (None, None, None, 6 36928 activation_2[0][0] 25__________________________________________________________________________________________________ 26bn2a_branch2b (BatchNormalizati (None, None, None, 6 256 res2a_branch2b[0][0] 27__________________________________________________________________________________________________ 28activation_3 (Activation) (None, None, None, 6 0 bn2a_branch2b[0][0] 29__________________________________________________________________________________________________ 30res2a_branch2c (Conv2D) (None, None, None, 2 16640 activation_3[0][0] 31__________________________________________________________________________________________________ 32res2a_branch1 (Conv2D) (None, None, None, 2 16640 max_pooling2d_1[0][0] 33__________________________________________________________________________________________________ 34bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024 res2a_branch2c[0][0] 35__________________________________________________________________________________________________ 36bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024 res2a_branch1[0][0] 37__________________________________________________________________________________________________ 38add_1 (Add) (None, None, None, 2 0 bn2a_branch2c[0][0] 39 bn2a_branch1[0][0] 40__________________________________________________________________________________________________ 41activation_4 (Activation) (None, None, None, 2 0 add_1[0][0] 42__________________________________________________________________________________________________ 43res2b_branch2a (Conv2D) (None, None, None, 6 16448 activation_4[0][0] 44__________________________________________________________________________________________________ 45bn2b_branch2a (BatchNormalizati (None, None, None, 6 256 res2b_branch2a[0][0] 46__________________________________________________________________________________________________ 47activation_5 (Activation) (None, None, None, 6 0 bn2b_branch2a[0][0] 48__________________________________________________________________________________________________ 49res2b_branch2b (Conv2D) (None, None, None, 6 36928 activation_5[0][0] 50__________________________________________________________________________________________________ 51bn2b_branch2b (BatchNormalizati (None, None, None, 6 256 res2b_branch2b[0][0] 52__________________________________________________________________________________________________ 53activation_6 (Activation) (None, None, None, 6 0 bn2b_branch2b[0][0] 54__________________________________________________________________________________________________ 55res2b_branch2c (Conv2D) (None, None, None, 2 16640 activation_6[0][0] 56__________________________________________________________________________________________________ 57bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024 res2b_branch2c[0][0] 58__________________________________________________________________________________________________ 59add_2 (Add) (None, None, None, 2 0 bn2b_branch2c[0][0] 60 activation_4[0][0] 61__________________________________________________________________________________________________ 62activation_7 (Activation) (None, None, None, 2 0 add_2[0][0] 63__________________________________________________________________________________________________ 64res2c_branch2a (Conv2D) (None, None, None, 6 16448 activation_7[0][0] 65__________________________________________________________________________________________________ 66bn2c_branch2a (BatchNormalizati (None, None, None, 6 256 res2c_branch2a[0][0] 67__________________________________________________________________________________________________ 68activation_8 (Activation) (None, None, None, 6 0 bn2c_branch2a[0][0] 69__________________________________________________________________________________________________ 70res2c_branch2b (Conv2D) (None, None, None, 6 36928 activation_8[0][0] 71__________________________________________________________________________________________________ 72bn2c_branch2b (BatchNormalizati (None, None, None, 6 256 res2c_branch2b[0][0] 73__________________________________________________________________________________________________ 74activation_9 (Activation) (None, None, None, 6 0 bn2c_branch2b[0][0] 75__________________________________________________________________________________________________ 76res2c_branch2c (Conv2D) (None, None, None, 2 16640 activation_9[0][0] 77__________________________________________________________________________________________________ 78bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024 res2c_branch2c[0][0] 79__________________________________________________________________________________________________ 80add_3 (Add) (None, None, None, 2 0 bn2c_branch2c[0][0] 81 activation_7[0][0] 82__________________________________________________________________________________________________ 83activation_10 (Activation) (None, None, None, 2 0 add_3[0][0] 84__________________________________________________________________________________________________ 85res3a_branch2a (Conv2D) (None, None, None, 1 32896 activation_10[0][0] 86__________________________________________________________________________________________________ 87bn3a_branch2a (BatchNormalizati (None, None, None, 1 512 res3a_branch2a[0][0] 88__________________________________________________________________________________________________ 89activation_11 (Activation) (None, None, None, 1 0 bn3a_branch2a[0][0] 90__________________________________________________________________________________________________ 91res3a_branch2b (Conv2D) (None, None, None, 1 147584 activation_11[0][0] 92__________________________________________________________________________________________________ 93bn3a_branch2b (BatchNormalizati (None, None, None, 1 512 res3a_branch2b[0][0] 94__________________________________________________________________________________________________ 95activation_12 (Activation) (None, None, None, 1 0 bn3a_branch2b[0][0] 96__________________________________________________________________________________________________ 97res3a_branch2c (Conv2D) (None, None, None, 5 66048 activation_12[0][0] 98__________________________________________________________________________________________________ 99res3a_branch1 (Conv2D) (None, None, None, 5 131584 activation_10[0][0] 100__________________________________________________________________________________________________ 101bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048 res3a_branch2c[0][0] 102__________________________________________________________________________________________________ 103bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048 res3a_branch1[0][0] 104__________________________________________________________________________________________________ 105add_4 (Add) (None, None, None, 5 0 bn3a_branch2c[0][0] 106 bn3a_branch1[0][0] 107__________________________________________________________________________________________________ 108activation_13 (Activation) (None, None, None, 5 0 add_4[0][0] 109__________________________________________________________________________________________________ 110res3b_branch2a (Conv2D) (None, None, None, 1 65664 activation_13[0][0] 111__________________________________________________________________________________________________ 112bn3b_branch2a (BatchNormalizati (None, None, None, 1 512 res3b_branch2a[0][0] 113__________________________________________________________________________________________________ 114activation_14 (Activation) (None, None, None, 1 0 bn3b_branch2a[0][0] 115__________________________________________________________________________________________________ 116res3b_branch2b (Conv2D) (None, None, None, 1 147584 activation_14[0][0] 117__________________________________________________________________________________________________ 118bn3b_branch2b (BatchNormalizati (None, None, None, 1 512 res3b_branch2b[0][0] 119__________________________________________________________________________________________________ 120activation_15 (Activation) (None, None, None, 1 0 bn3b_branch2b[0][0] 121__________________________________________________________________________________________________ 122res3b_branch2c (Conv2D) (None, None, None, 5 66048 activation_15[0][0] 123__________________________________________________________________________________________________ 124bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048 res3b_branch2c[0][0] 125__________________________________________________________________________________________________ 126add_5 (Add) (None, None, None, 5 0 bn3b_branch2c[0][0] 127 activation_13[0][0] 128__________________________________________________________________________________________________ 129activation_16 (Activation) (None, None, None, 5 0 add_5[0][0] 130__________________________________________________________________________________________________ 131res3c_branch2a (Conv2D) (None, None, None, 1 65664 activation_16[0][0] 132__________________________________________________________________________________________________ 133bn3c_branch2a (BatchNormalizati (None, None, None, 1 512 res3c_branch2a[0][0] 134__________________________________________________________________________________________________ 135activation_17 (Activation) (None, None, None, 1 0 bn3c_branch2a[0][0] 136__________________________________________________________________________________________________ 137res3c_branch2b (Conv2D) (None, None, None, 1 147584 activation_17[0][0] 138__________________________________________________________________________________________________ 139bn3c_branch2b (BatchNormalizati (None, None, None, 1 512 res3c_branch2b[0][0] 140__________________________________________________________________________________________________ 141activation_18 (Activation) (None, None, None, 1 0 bn3c_branch2b[0][0] 142__________________________________________________________________________________________________ 143res3c_branch2c (Conv2D) (None, None, None, 5 66048 activation_18[0][0] 144__________________________________________________________________________________________________ 145bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048 res3c_branch2c[0][0] 146__________________________________________________________________________________________________ 147add_6 (Add) (None, None, None, 5 0 bn3c_branch2c[0][0] 148 activation_16[0][0] 149__________________________________________________________________________________________________ 150activation_19 (Activation) (None, None, None, 5 0 add_6[0][0] 151__________________________________________________________________________________________________ 152res3d_branch2a (Conv2D) (None, None, None, 1 65664 activation_19[0][0] 153__________________________________________________________________________________________________ 154bn3d_branch2a (BatchNormalizati (None, None, None, 1 512 res3d_branch2a[0][0] 155__________________________________________________________________________________________________ 156activation_20 (Activation) (None, None, None, 1 0 bn3d_branch2a[0][0] 157__________________________________________________________________________________________________ 158res3d_branch2b (Conv2D) (None, None, None, 1 147584 activation_20[0][0] 159__________________________________________________________________________________________________ 160bn3d_branch2b (BatchNormalizati (None, None, None, 1 512 res3d_branch2b[0][0] 161__________________________________________________________________________________________________ 162activation_21 (Activation) (None, None, None, 1 0 bn3d_branch2b[0][0] 163__________________________________________________________________________________________________ 164res3d_branch2c (Conv2D) (None, None, None, 5 66048 activation_21[0][0] 165__________________________________________________________________________________________________ 166bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048 res3d_branch2c[0][0] 167__________________________________________________________________________________________________ 168add_7 (Add) (None, None, None, 5 0 bn3d_branch2c[0][0] 169 activation_19[0][0] 170__________________________________________________________________________________________________ 171activation_22 (Activation) (None, None, None, 5 0 add_7[0][0] 172__________________________________________________________________________________________________ 173res4a_branch2a (Conv2D) (None, None, None, 2 131328 activation_22[0][0] 174__________________________________________________________________________________________________ 175bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024 res4a_branch2a[0][0] 176__________________________________________________________________________________________________ 177activation_23 (Activation) (None, None, None, 2 0 bn4a_branch2a[0][0] 178__________________________________________________________________________________________________ 179res4a_branch2b (Conv2D) (None, None, None, 2 590080 activation_23[0][0] 180__________________________________________________________________________________________________ 181bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024 res4a_branch2b[0][0] 182__________________________________________________________________________________________________ 183activation_24 (Activation) (None, None, None, 2 0 bn4a_branch2b[0][0] 184__________________________________________________________________________________________________ 185res4a_branch2c (Conv2D) (None, None, None, 1 263168 activation_24[0][0] 186__________________________________________________________________________________________________ 187res4a_branch1 (Conv2D) (None, None, None, 1 525312 activation_22[0][0] 188__________________________________________________________________________________________________ 189bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096 res4a_branch2c[0][0] 190__________________________________________________________________________________________________ 191bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096 res4a_branch1[0][0] 192__________________________________________________________________________________________________ 193add_8 (Add) (None, None, None, 1 0 bn4a_branch2c[0][0] 194 bn4a_branch1[0][0] 195__________________________________________________________________________________________________ 196activation_25 (Activation) (None, None, None, 1 0 add_8[0][0] 197__________________________________________________________________________________________________ 198res4b_branch2a (Conv2D) (None, None, None, 2 262400 activation_25[0][0] 199__________________________________________________________________________________________________ 200bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024 res4b_branch2a[0][0] 201__________________________________________________________________________________________________ 202activation_26 (Activation) (None, None, None, 2 0 bn4b_branch2a[0][0] 203__________________________________________________________________________________________________ 204res4b_branch2b (Conv2D) (None, None, None, 2 590080 activation_26[0][0] 205__________________________________________________________________________________________________ 206bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024 res4b_branch2b[0][0] 207__________________________________________________________________________________________________ 208activation_27 (Activation) (None, None, None, 2 0 bn4b_branch2b[0][0] 209__________________________________________________________________________________________________ 210res4b_branch2c (Conv2D) (None, None, None, 1 263168 activation_27[0][0] 211__________________________________________________________________________________________________ 212bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096 res4b_branch2c[0][0] 213__________________________________________________________________________________________________ 214add_9 (Add) (None, None, None, 1 0 bn4b_branch2c[0][0] 215 activation_25[0][0] 216__________________________________________________________________________________________________ 217activation_28 (Activation) (None, None, None, 1 0 add_9[0][0] 218__________________________________________________________________________________________________ 219res4c_branch2a (Conv2D) (None, None, None, 2 262400 activation_28[0][0] 220__________________________________________________________________________________________________ 221bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024 res4c_branch2a[0][0] 222__________________________________________________________________________________________________ 223activation_29 (Activation) (None, None, None, 2 0 bn4c_branch2a[0][0] 224__________________________________________________________________________________________________ 225res4c_branch2b (Conv2D) (None, None, None, 2 590080 activation_29[0][0] 226__________________________________________________________________________________________________ 227bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024 res4c_branch2b[0][0] 228__________________________________________________________________________________________________ 229activation_30 (Activation) (None, None, None, 2 0 bn4c_branch2b[0][0] 230__________________________________________________________________________________________________ 231res4c_branch2c (Conv2D) (None, None, None, 1 263168 activation_30[0][0] 232__________________________________________________________________________________________________ 233bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096 res4c_branch2c[0][0] 234__________________________________________________________________________________________________ 235add_10 (Add) (None, None, None, 1 0 bn4c_branch2c[0][0] 236 activation_28[0][0] 237__________________________________________________________________________________________________ 238activation_31 (Activation) (None, None, None, 1 0 add_10[0][0] 239__________________________________________________________________________________________________ 240res4d_branch2a (Conv2D) (None, None, None, 2 262400 activation_31[0][0] 241__________________________________________________________________________________________________ 242bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024 res4d_branch2a[0][0] 243__________________________________________________________________________________________________ 244activation_32 (Activation) (None, None, None, 2 0 bn4d_branch2a[0][0] 245__________________________________________________________________________________________________ 246res4d_branch2b (Conv2D) (None, None, None, 2 590080 activation_32[0][0] 247__________________________________________________________________________________________________ 248bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024 res4d_branch2b[0][0] 249__________________________________________________________________________________________________ 250activation_33 (Activation) (None, None, None, 2 0 bn4d_branch2b[0][0] 251__________________________________________________________________________________________________ 252res4d_branch2c (Conv2D) (None, None, None, 1 263168 activation_33[0][0] 253__________________________________________________________________________________________________ 254bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096 res4d_branch2c[0][0] 255__________________________________________________________________________________________________ 256add_11 (Add) (None, None, None, 1 0 bn4d_branch2c[0][0] 257 activation_31[0][0] 258__________________________________________________________________________________________________ 259activation_34 (Activation) (None, None, None, 1 0 add_11[0][0] 260__________________________________________________________________________________________________ 261res4e_branch2a (Conv2D) (None, None, None, 2 262400 activation_34[0][0] 262__________________________________________________________________________________________________ 263bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024 res4e_branch2a[0][0] 264__________________________________________________________________________________________________ 265activation_35 (Activation) (None, None, None, 2 0 bn4e_branch2a[0][0] 266__________________________________________________________________________________________________ 267res4e_branch2b (Conv2D) (None, None, None, 2 590080 activation_35[0][0] 268__________________________________________________________________________________________________ 269bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024 res4e_branch2b[0][0] 270__________________________________________________________________________________________________ 271activation_36 (Activation) (None, None, None, 2 0 bn4e_branch2b[0][0] 272__________________________________________________________________________________________________ 273res4e_branch2c (Conv2D) (None, None, None, 1 263168 activation_36[0][0] 274__________________________________________________________________________________________________ 275bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096 res4e_branch2c[0][0] 276__________________________________________________________________________________________________ 277add_12 (Add) (None, None, None, 1 0 bn4e_branch2c[0][0] 278 activation_34[0][0] 279__________________________________________________________________________________________________ 280activation_37 (Activation) (None, None, None, 1 0 add_12[0][0] 281__________________________________________________________________________________________________ 282res4f_branch2a (Conv2D) (None, None, None, 2 262400 activation_37[0][0] 283__________________________________________________________________________________________________ 284bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024 res4f_branch2a[0][0] 285__________________________________________________________________________________________________ 286activation_38 (Activation) (None, None, None, 2 0 bn4f_branch2a[0][0] 287__________________________________________________________________________________________________ 288res4f_branch2b (Conv2D) (None, None, None, 2 590080 activation_38[0][0] 289__________________________________________________________________________________________________ 290bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024 res4f_branch2b[0][0] 291__________________________________________________________________________________________________ 292activation_39 (Activation) (None, None, None, 2 0 bn4f_branch2b[0][0] 293__________________________________________________________________________________________________ 294res4f_branch2c (Conv2D) (None, None, None, 1 263168 activation_39[0][0] 295__________________________________________________________________________________________________ 296bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096 res4f_branch2c[0][0] 297__________________________________________________________________________________________________ 298add_13 (Add) (None, None, None, 1 0 bn4f_branch2c[0][0] 299 activation_37[0][0] 300__________________________________________________________________________________________________ 301activation_40 (Activation) (None, None, None, 1 0 add_13[0][0] 302__________________________________________________________________________________________________ 303res5a_branch2a (Conv2D) (None, None, None, 5 524800 activation_40[0][0] 304__________________________________________________________________________________________________ 305bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048 res5a_branch2a[0][0] 306__________________________________________________________________________________________________ 307activation_41 (Activation) (None, None, None, 5 0 bn5a_branch2a[0][0] 308__________________________________________________________________________________________________ 309res5a_branch2b (Conv2D) (None, None, None, 5 2359808 activation_41[0][0] 310__________________________________________________________________________________________________ 311bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048 res5a_branch2b[0][0] 312__________________________________________________________________________________________________ 313activation_42 (Activation) (None, None, None, 5 0 bn5a_branch2b[0][0] 314__________________________________________________________________________________________________ 315res5a_branch2c (Conv2D) (None, None, None, 2 1050624 activation_42[0][0] 316__________________________________________________________________________________________________ 317res5a_branch1 (Conv2D) (None, None, None, 2 2099200 activation_40[0][0] 318__________________________________________________________________________________________________ 319bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192 res5a_branch2c[0][0] 320__________________________________________________________________________________________________ 321bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192 res5a_branch1[0][0] 322__________________________________________________________________________________________________ 323add_14 (Add) (None, None, None, 2 0 bn5a_branch2c[0][0] 324 bn5a_branch1[0][0] 325__________________________________________________________________________________________________ 326activation_43 (Activation) (None, None, None, 2 0 add_14[0][0] 327__________________________________________________________________________________________________ 328res5b_branch2a (Conv2D) (None, None, None, 5 1049088 activation_43[0][0] 329__________________________________________________________________________________________________ 330bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048 res5b_branch2a[0][0] 331__________________________________________________________________________________________________ 332activation_44 (Activation) (None, None, None, 5 0 bn5b_branch2a[0][0] 333__________________________________________________________________________________________________ 334res5b_branch2b (Conv2D) (None, None, None, 5 2359808 activation_44[0][0] 335__________________________________________________________________________________________________ 336bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048 res5b_branch2b[0][0] 337__________________________________________________________________________________________________ 338activation_45 (Activation) (None, None, None, 5 0 bn5b_branch2b[0][0] 339__________________________________________________________________________________________________ 340res5b_branch2c (Conv2D) (None, None, None, 2 1050624 activation_45[0][0] 341__________________________________________________________________________________________________ 342bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192 res5b_branch2c[0][0] 343__________________________________________________________________________________________________ 344add_15 (Add) (None, None, None, 2 0 bn5b_branch2c[0][0] 345 activation_43[0][0] 346__________________________________________________________________________________________________ 347activation_46 (Activation) (None, None, None, 2 0 add_15[0][0] 348__________________________________________________________________________________________________ 349res5c_branch2a (Conv2D) (None, None, None, 5 1049088 activation_46[0][0] 350__________________________________________________________________________________________________ 351bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048 res5c_branch2a[0][0] 352__________________________________________________________________________________________________ 353activation_47 (Activation) (None, None, None, 5 0 bn5c_branch2a[0][0] 354__________________________________________________________________________________________________ 355res5c_branch2b (Conv2D) (None, None, None, 5 2359808 activation_47[0][0] 356__________________________________________________________________________________________________ 357bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048 res5c_branch2b[0][0] 358__________________________________________________________________________________________________ 359activation_48 (Activation) (None, None, None, 5 0 bn5c_branch2b[0][0] 360__________________________________________________________________________________________________ 361res5c_branch2c (Conv2D) (None, None, None, 2 1050624 activation_48[0][0] 362__________________________________________________________________________________________________ 363bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192 res5c_branch2c[0][0] 364__________________________________________________________________________________________________ 365add_16 (Add) (None, None, None, 2 0 bn5c_branch2c[0][0] 366 activation_46[0][0] 367__________________________________________________________________________________________________ 368activation_49 (Activation) (None, None, None, 2 0 add_16[0][0] 369__________________________________________________________________________________________________ 370global_average_pooling2d_1 (Glo (None, 2048) 0 activation_49[0][0] 371__________________________________________________________________________________________________ 372dense_1 (Dense) (None, 1024) 2098176 global_average_pooling2d_1[0][0] 373__________________________________________________________________________________________________ 374dense_2 (Dense) (None, 5) 5125 dense_1[0][0] 375================================================================================================== 376Total params: 25,691,013 377Trainable params: 2,103,301 378Non-trainable params: 23,587,712 379__________________________________________________________________________________________________ Pháº§n train láº¡i sáº½ cÃ³ khoáº£ng hÆ¡n 2 triá»‡u tham sá»‘, pháº§n layer á»Ÿ trÆ°á»›c Ä‘Ã³ khÃ´ng train lÃ  khoáº£ng 23 triá»‡u tham sá»‘.\nChia táº­p dá»¯ liá»‡u ra thÃ nh 5 pháº§n, 4 pháº§n lÃ m táº­p train, 1 pháº§n lÃ m táº­p validation.\n1X, y, tags = dataset.dataset(data_directory, n) 2nb_classes = len(tags) 3 4 5sample_count = len(y) 6train_size = sample_count * 4 // 5 7X_train = X[:train_size] 8y_train = y[:train_size] 9Y_train = np_utils.to_categorical(y_train, nb_classes) 10X_test = X[train_size:] 11y_test = y[train_size:] 12Y_test = np_utils.to_categorical(y_test, nb_classes) chÃºng ta tiáº¿n hÃ nh thá»±c hiá»‡n ImageDataGenerator Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c nhiá»u dá»¯ liá»‡u máº«u hÆ¡n vÃ  chá»‘ng overfit, trong keras Ä‘Ã£ cÃ³ sáºµn hÃ m\n1datagen = ImageDataGenerator( 2 featurewise_center=False, 3 samplewise_center=False, 4 featurewise_std_normalization=False, 5 samplewise_std_normalization=False, 6 zca_whitening=False, 7 rotation_range=45, 8 width_shift_range=0.25, 9 height_shift_range=0.25, 10 horizontal_flip=True, 11 vertical_flip=False, 12 channel_shift_range=0.5, 13 zoom_range=[0.5, 1.5], 14 brightness_range=[0.5, 1.5], 15 fill_mode=\u0026#39;reflect\u0026#39;) 16 17datagen.fit(X_train) Cuá»‘i cÃ¹ng, chÃºng ta sáº½ xÃ¢y dá»±ng mÃ´ hÃ¬nh vÃ  tiáº¿n hÃ nh huáº¥n luyá»‡n, lÆ°u mÃ´ hÃ¬nh. QuÃ¡ trÃ¬nh nÃ y tá»‘n hÆ¡i nhiá»u thá»i gian.\n1 2model = net.build_model(nb_classes) 3model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#34;accuracy\u0026#34;]) 4 5# train the model on the new data for a few epochs 6 7print(\u0026#34;training the newly added dense layers\u0026#34;) 8 9samples_per_epoch = X_train.shape[0]//batch_size*batch_size 10steps_per_epoch = samples_per_epoch//batch_size 11validation_steps = X_test.shape[0]//batch_size*batch_size 12 13model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True), 14 samples_per_epoch=samples_per_epoch, 15 epochs=nb_epoch, 16 steps_per_epoch = steps_per_epoch, 17 validation_data=datagen.flow(X_test, Y_test, batch_size=batch_size), 18 validation_steps=validation_steps, 19 ) 20 21 22net.save(model, tags, model_file_prefix) Thá»­ download má»™t vÃ i hÃ¬nh áº£nh trÃªn máº¡ng vá» rá»“i test thá»­ xem sao\n![HÃ¬nh áº£nh] (flower-classifition_demo.jpg)\nKáº¿t quáº£ khÃ¡ tá»‘t pháº£i khÃ´ng cÃ¡c báº¡n.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Apr 15, 2019","img":"","permalink":"/blog/2019-04-15-phan-loai-hoa/","series":null,"tags":["Machine learning","Deeplearning","hoa há»“ng","hoa máº·t trá»i","hoa bá»“ cÃ´ng anh","hoa cÃºc","hoa tulip"],"title":"PhÃ¢n Loáº¡i Hoa Sá»­ Dá»¥ng Pretrain Model"},{"categories":null,"content":" Dá»± Ä‘oÃ¡n chuá»—i thá»i gian CÃ¡c thuá»™c tÃ­nh cá»§a time series VÃ¬ sao chÃºng ta láº¡i quan tÃ¢m Ä‘áº¿n tÃ­nh dá»«ng cá»§a dá»¯ liá»‡u CÃ¡ch xÃ¡c Ä‘á»‹nh tÃ­nh dá»«ng cá»§a dá»¯ liá»‡u PhÆ°Æ¡ng phÃ¡p dá»± Ä‘oÃ¡n chuá»—i thá»i gian cÆ¡ báº£n PhÆ°Æ¡ng phÃ¡p dá»± Ä‘oÃ¡n dá»±a vÃ o máº¡ng neural network Sá»­ dá»¥ng máº¡ng Echo State Networks Dá»± doÃ¡n chuá»—i time series Tá»‘i Æ°u hoÃ¡ cÃ¡c tham sá»‘ Hyper parameters Trong cuá»‘n The West Wing Script Book cá»§a Aaron Sorkin, Ã´ng áº¥y Ä‘Ã£ cÃ³ má»™t cÃ¢u nhÆ° tháº¿ nÃ y \u0026ldquo;There (is) order and even great beauty in what looks like total chaos. If we look closely enough at the randomness around us, patterns will start to emerge.\u0026rdquo;. MÃ¬nh xin phÃ©p khÃ´ng dá»‹ch cÃ¢u nÃ³i trÃªn ra, bá»Ÿi vÃ¬ mÃ¬nh dá»‹ch khÃ¡ tá»‡, vÃ  cÃ¢u nÃ³i nÃ y khÃ¡ ná»•i tiáº¿ng (Ä‘Ã£ Ä‘Æ°á»£c trÃ­ch dáº«n khÃ¡ nhiá»u trÃªn cÃ¡c bÃ i viáº¿t cá»§a cÃ¡c bloger khÃ¡c). NhÆ°ng cÃ¢u nÃ³i Ä‘Ã³ khÃ¡ phÃ¹ há»£p vá»›i mÃ´i trÆ°á»ng chá»©ng khoÃ¡n, nÆ¡i mÃ  má»i thá»© Ä‘á»u khÃ´ng rÃµ rÃ ng vÃ  khÃ¡ \u0026ldquo;há»—n loáº¡n\u0026rdquo;.\nDá»± Ä‘oÃ¡n chuá»—i thá»i gian GiÃ¡ cá»• phiáº¿u trÃªn thá»‹ trÆ°á»ng chá»©ng khoÃ¡n thÆ°á»ng Ä‘Æ°á»£c quy vÃ o bÃ i toÃ¡n lÃ  time series. CÃ¡c cÃ´ng ty Ä‘áº§u tÆ° hoáº·c cÃ¡c nhÃ  nghiÃªn cá»©u, cÃ¡c nhÃ  Ä‘áº§u tÆ° hiá»‡n nay thÆ°á»ng sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p stochastic hoáº·c cÃ¡c cáº£i tiáº¿n cá»§a phÆ°Æ¡ng phÃ¡p stochastic (vÃ­ dá»¥ mÃ´ hÃ¬nh ARIMA, RegARIMA,\u0026hellip;) Ä‘á»ƒ Ä‘Æ°a ra cÃ¡c dá»± Ä‘oÃ¡n há»£p lÃ½ phÃ¹ há»£p vá»›i cÃ¡c giÃ¡ trá»‹ quÃ¡ khá»©. Má»¥c tiÃªu cuá»‘i cÃ¹ng lÃ  tÃ¬m ra má»™t mÃ´ hÃ¬nh kháº£ dÄ© nháº¥t Ä‘á»ƒ pháº£n Ã¡nh quy luáº­t cá»§a thá»‹ trÆ°á»ng vÃ  sá»­ dá»¥ng nÃ³ Ä‘á»ƒ sinh ra lá»£i nhuáº­n (trá»Ÿ nÃªn giÃ u cÃ³ hÆ¡n :)).\nCÃ¡c thuá»™c tÃ­nh cá»§a time series Má»™t trong cÃ¡c thuá»™c tÃ­nh cá»§a chuá»—i thá»i gian lÃ  tÃ­nh dá»«ng (stationary). Má»™t chuá»—i time series Ä‘Æ°á»£c gá»i lÃ  cÃ³ tÃ­nh dá»«ng náº¿u cÃ¡c thuá»™c tÃ­nh cÃ³ Ã½ nghÄ©a thá»‘ng kÃª cá»§a nÃ³ (vÃ­ dá»¥ nhÆ° lÃ  trung bÃ¬nh, Ä‘á»™ lá»‡ch chuáº©n) khÃ´ng Ä‘á»•i theo thá»i gian. á» Ä‘Ã¢y, chÃºng ta luáº­n bÃ n nho nhá» má»™t chÃºt vÃ¬ sao tÃ­nh dá»«ng ráº¥t quang trá»ng trong chuá»—i thá»i gian.\nTrÆ°á»›c háº¿t, háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh vá» time series hiá»‡n táº¡i Ä‘Æ°á»£c xÃ¢y dá»±ng trÃªn má»™t giáº£ Ä‘á»‹nh tÃ­nh dá»«ng cá»§a chuá»—i thá»i gian. CÃ³ nghÄ©a lÃ  náº¿u chuá»—i thá»i gian á»Ÿ trong quÃ¡ khá»© cÃ³ má»™t hÃ nh vi nÃ o Ä‘Ã³, thÃ¬ kháº£ nÄƒng cao lÃ  nÃ³ sáº½ láº·p láº¡i trong tÆ°Æ¡ng lai. NgoÃ i ra, cÃ¡c lÃ½ thuyáº¿t liÃªn quan Ä‘áº¿n tÃ­nh dá»«ng cá»§a chuá»—i time series Ä‘Ã£ Ä‘Æ°á»£c cÃ¡c nhÃ  nghiÃªn cá»©u khai thÃ¡c má»™t cÃ¡ch triá»‡t Ä‘á»ƒ vÃ  dá»… rÃ ng implement hÆ¡n lÃ  cÃ¡c lÃ½ thuyáº¿t vá» non-stationary trong time series.\nTÃ­nh dá»«ng Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a báº±ng cÃ¡c tiÃªu chÃ­ rÃµ rÃ ng vÃ  nghiÃªm ngáº·t. Tuy nhiÃªn, trong bÃ i toÃ¡n thá»±c táº¿, chÃºng ta cÃ³ thá»ƒ giáº£ Ä‘á»‹nh ráº±ng má»™t chuá»—i time series Ä‘Æ°á»£c coi lÃ  cÃ³ tÃ­nh dá»«ng náº¿u cÃ¡c thuá»™c tÃ­nh thá»‘ng kÃª khÃ´ng Ä‘á»•i theo thá»i gian, nghÄ©a lÃ :\nGiÃ¡ trá»‹ trung bÃ¬nh khÃ´ng thay Ä‘á»•i. Náº¿u giÃ¡ trá»‹ trung bÃ¬nh thay Ä‘á»•i, chuá»—i thá»i gian sáº½ cÃ³ khuynh hÆ°á»›ng Ä‘i lÃªn hoáº·c Ä‘i xuá»‘ng. HÃ¬nh áº£nh bÃªn dÆ°á»›i, mÃ´ táº£ trá»±c quan má»™t chuá»—i thá»i gian cÃ³ tÃ­nh dá»«ng (trung bÃ¬nh khÃ´ng thay Ä‘á»•i), vÃ  má»™t chuá»—i thá»i gian khÃ´ng cÃ³ tÃ­nh dá»«ng (trung bÃ¬nh thay Ä‘á»•i). GiÃ¡ trá»‹ phÆ°Æ¡ng sai khÃ´ng thay Ä‘á»•i. Thuá»™c tÃ­nh nÃ y cÃ²n Ä‘Æ°á»£c gá»i lÃ  Ä‘á»“ng Ä‘áº³ng (homoscedasticity). HÃ¬nh bÃªn dÆ°á»›i mÃ´ táº£ má»™t chuá»—i cÃ³ phÆ°Æ¡ng sai thay Ä‘á»•i (khÃ´ng cÃ³ tÃ­nh dá»«ng) vÃ  má»™t chuá»—i cÃ³ phÆ°Æ¡ng sai báº¥t biáº¿n (cÃ³ tÃ­nh dá»«ng). TÃ­nh tá»± tÆ°Æ¡ng tá»± khÃ´ng phá»¥ thuá»™c vÃ o thá»i gian VÃ¬ sao chÃºng ta láº¡i quan tÃ¢m Ä‘áº¿n tÃ­nh dá»«ng cá»§a dá»¯ liá»‡u ChÃºng ta quan tÃ¢m Ä‘áº¿n tÃ­nh dá»«ng cá»§a dá»¯ liá»‡u, Ä‘Æ¡n giáº£n lÃ  bá»Ÿi vÃ¬ náº¿u dá»¯ liá»‡u khÃ´ng cÃ³ tÃ­nh dá»«ng, chÃºng ta khÃ´ng thá»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh chuá»—i thá»i gian (nhÆ° Ä‘Ã£ nÃ³i á»Ÿ trÃªn, cÃ¡c nghiÃªn cá»©u hiá»‡n nay Ä‘á»u dá»±a trÃªn má»™t cÆ¡ sá»Ÿ lÃ  dá»¯ liá»‡u cÃ³ tÃ­nh dá»«ng). Trong trÆ°á»ng há»£p báº¡n cÃ³ trong tay dá»¯ liá»‡u thuá»™c dáº¡ng time series, vÃ  má»™t tiÃªu chÃ­ nÃ o Ä‘Ã³ trong 3 tiÃªu chÃ­ mÃ¬nh Ä‘Ã£ liá»‡u kÃª á»Ÿ trÃªn bá»‹ vi pháº¡m, suy ra lÃ  dá»¯ liá»‡u cá»§a báº¡n khÃ´ng cÃ³ tÃ­nh dá»«ng. Báº¡n pháº£i chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u báº¡n Ä‘ang cÃ³ Ä‘á»ƒ cho nÃ³ cÃ³ tÃ­nh dá»«ng. May máº¯n ráº±ng cÅ©ng cÃ³ nhiá»u nghiÃªn cá»©u thá»±c hiá»‡n viá»‡c nÃ y, vÃ­ dá»¥ nhÆ° \u0026ldquo;khá»­ xu hÆ°á»›ng (detrending)\u0026rdquo;, khá»­ sai biá»‡t (differencing)\u0026hellip;\nNáº¿u báº¡n má»›i chá»‰ báº¯t Ä‘áº§u phÃ¢n tÃ­ch chuá»—i thá»i gian, báº¡n sáº½ tháº¥y viá»‡c lÃ m trÃªn khÃ¡ lÃ  stupid. LÃ½ thuyáº¿t tá»‘t nháº¥t hiá»‡n nay cho chuá»—i thá»i gian lÃ  chia nhá» nÃ³ ra thÃ nh cÃ¡c thÃ nh pháº§n nhÆ° lÃ  xu hÆ°á»›ng (linear trend), mÃ¹a vá»¥ (seasonal), chu ká»³, vÃ  yáº¿u tá»‘ ngáº«u nhiÃªn. Dá»± Ä‘oÃ¡n cho tá»«ng pháº§n má»™t, sau Ä‘Ã³ láº¥y tá»•ng chÃºng láº¡i.\nÄá»‘i vá»›i nhá»¯ng ai Ä‘Ã£ quen thuá»™c vá»›i biáº¿n Ä‘á»•i Fourier, thÃ¬ sáº½ dá»… dÃ ng \u0026ldquo;cáº£m\u0026rdquo; hÆ¡n cÃ¡i mÃ¬nh vá»«a nÃ³i á»Ÿ trÃªn.\nCÃ¡ch xÃ¡c Ä‘á»‹nh tÃ­nh dá»«ng cá»§a dá»¯ liá»‡u KhÃ¡ khÃ³ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh má»™t biá»ƒu Ä‘á»“ chuá»—i time series cÃ³ tÃ­nh dá»«ng hay khÃ´ng (quan sÃ¡t biá»ƒu Ä‘á»“ báº±ng máº¯t). Cho nÃªn chÃºng ta sáº½ sá»­ dá»¥ng kiá»ƒm Ä‘á»‹nh Dickey-Fuller. ÄÃ¢y lÃ  má»™t kiá»ƒm Ä‘á»‹nh thá»‘ng kÃª Ä‘á»ƒ kiá»ƒm tra xem chuá»—i dá»¯ liá»‡u cÃ³ tÃ­nh dá»«ng hay khÃ´ng. Vá»›i giáº£ thuyáº¿t null lÃ  chuá»—i time series lÃ  má»™t chuá»—i khÃ´ng cÃ³ tÃ­nh dá»«ng. Náº¿u giÃ¡ trá»‹ nhá» hÆ¡n má»™t ngÆ°á»¡ng p-value nÃ o Ä‘Ã³ (thÆ°á»ng lÃ  0.05), chÃºng ta cÃ³ quyá»n bÃ¡c bá» giáº£ Ä‘á»‹nh null, vÃ  nÃ³i ráº±ng chuá»—i thá»i gian Ä‘ang cÃ³ lÃ  cÃ³ tÃ­nh dá»«ng. á» bÃ i viáº¿t nÃ y, mÃ¬nh khÃ´ng Ä‘á» cáº­p Ä‘áº¿n mÃ´ hÃ¬nh kiá»ƒm Ä‘á»‹nh - vá»‘n Ä‘Æ°á»£c há»c trong mÃ´n xÃ¡c xuáº¥t thá»‘ng kÃª. CÃ¡c báº¡n cÃ³ nhu cáº§u tÃ¬m hiá»ƒu thÃ¬ cÃ³ thá»ƒ search trÃªn google hoáº·c lÃ  xem láº¡i sÃ¡ch xÃ¡c suáº¥t thá»‘ng kÃª.\nPhÆ°Æ¡ng phÃ¡p dá»± Ä‘oÃ¡n chuá»—i thá»i gian cÆ¡ báº£n PhÆ°Æ¡ng phÃ¡p cÆ¡ báº£n nháº¥t, Ä‘Æ¡n giáº£n nháº¥t, vÃ  Ä‘á»ƒ Ã¡p dá»¥ng nháº¥t dÆ°á»£c sá»­ dá»¥ng Ä‘á»ƒ dá»± Ä‘oÃ¡n chuá»—i thá»i gian lÃ  moving average. MÃ´ hÃ¬nh nÃ y thá»±c hiá»‡n tÃ­nh trung bÃ¬nh cá»§a t giÃ¡ trá»‹ cuá»‘i cÃ¹ng lÃ m giÃ¡ trá»‹ dá»± Ä‘oÃ¡n cá»§a Ä‘iá»ƒm tiáº¿p theo. VÃ­ dá»¥ nhÆ° Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ chá»©ng khoÃ¡n cá»§a ngÃ y thá»© 2 cá»§a tuáº§n tiáº¿p theo, chÃºng ta sáº½ láº¥y trung bÃ¬nh giÃ¡ Ä‘Ã³ng cá»§a cá»§a 5 ngÃ y trÆ°á»›c Ä‘Ã³ (giÃ¡ tá»« thá»© hai Ä‘áº¿n thá»© sÃ¡u tuáº§n nÃ y).\nÄáº¿n Ä‘Ã¢y, cÃ¡c báº¡n Ä‘Ã£ cÃ³ má»™t sá»‘ hiá»ƒu biáº¿t vá» time series. Má»™t mÃ´ hÃ¬nh khÃ¡ ná»•i tiáº¿ng lÃ  ARIMA Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng nhiá»u Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  dá»± bÃ¡o. CÃ¡ch thá»±c hiá»‡n cá»§a mÃ´ hÃ¬nh trÃªn Ä‘Æ°á»£c trÃ¬nh bÃ y tÃ³m gá»n trong hÃ¬nh mÃ´ táº£ bÃªn dÆ°á»›i.\nPhÆ°Æ¡ng phÃ¡p dá»± Ä‘oÃ¡n dá»±a vÃ o máº¡ng neural network Thá»±c táº¿, cÃ³ ráº¥t nhiá»u máº¡ng neural network Ä‘Ã£ Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»ƒ dá»± Ä‘oÃ¡n mÃ´ hÃ¬nh chá»©ng khoÃ¡n. CÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m Ä‘á»c láº¡i cÃ¡c bÃ i viáº¿t trÆ°á»›c Ä‘Ã¢y cá»§a mÃ¬nh vá» sá»­ dá»¥ng LSTM trong dá»± bÃ¡o chá»©ng khoÃ¡n. MÃ´ hÃ¬nh chá»©ng khoÃ¡n báº±ng máº¡ng neural network nÃ³i chung pháº£i Ä‘á»‘i máº·t vá»›i má»™t váº¥n Ä‘á» khÃ¡ \u0026ldquo;xÆ°Æ¡ng xáº©u\u0026rdquo; lÃ  xá»­ lÃ½ nhiá»…u vÃ  vanishing gradients. Trong Ä‘Ã³, viá»‡c xá»­ lÃ½ vanishing gradients lÃ  quan trá»ng nháº¥t. Báº£n cháº¥t cá»§a máº¡ng neural network lÃ  tá»‘i Æ°u hoÃ¡ hÃ m lan truyá»n ngÆ°á»£c báº±ng cÃ¡ch sá»­ dá»¥ng Ä‘áº¡o hÃ m giá»¯a cÃ¡c lá»›p layer Ä‘á»ƒ chÃºng \u0026lsquo;há»c\u0026rsquo;. Tráº£i qua nhiá»u layer, giÃ¡ trá»‹ cá»§a Ä‘áº¡o hÃ m sáº½ cÃ ng ngÃ y nhá» dáº§n vÃ o xáº¥p xá»‰ báº±ng 0. Giáº£ sá»­ chÃºng ta cÃ³ má»™t mÃ´ hÃ¬nh cÃ³ 100 lá»›p hidden layer, chÃºng ta nhÃ¢n 100 láº§n sá»‘ 0.1 vá»›i nhau vÃ  boom, giÃ¡ trá»‹ cuá»‘i cÃ¹ng chung ta nháº­n Ä‘Æ°á»£c lÃ  0, nghÄ©a lÃ  chÃºng ta cháº³ng há»c Ä‘Æ°á»£c cÃ¡i gÃ¬ cáº£.\nMay máº¯n thay, tá»›i thá»i Ä‘iá»ƒm hiá»‡n táº¡i, chÃºng ta cÃ³ 3 cÃ¡ch Ä‘á»ƒ xá»­ lÃ½ váº¥n Ä‘á» trÃªn:\nClipping gradients\nLSTM (Long Short Term Memory) hoáº·c GRU (Gate Recurrent Units)\nEcho states RNNs\nKá»¹ thuáº­t clipping gradients sá»­ dá»¥ng má»™t máº¹o lÃ  khi giÃ¡ trá»‹ Ä‘áº¡o hÃ m quÃ¡ lá»›n hoáº·c quÃ¡ nhá», chÃºng ta sáº½ khÃ´ng láº¥y Ä‘áº¡o hÃ m ná»¯a. Ká»¹ thuáº­t nÃ y thoáº¡t nhÃ¬n cÃ³ váº» hay, nhÆ°ng nÃ³ khÃ´ng thá»ƒ ngÄƒn chÃºng ta máº¥t mÃ¡t thÃ´ng tin vÃ  Ä‘Ã¢y lÃ  má»™t Ã½ tÆ°á»Ÿng khÃ¡ tá»‡.\nRNN (LSTM hoáº·c GRU) lÃ  má»™t ká»¹ thuáº­t khÃ¡c lÃ  Ä‘iá»u chá»‰nh cÃ¡c káº¿t ná»‘i theo má»™t vÃ i quy luáº­t nháº¥t Ä‘á»‹nh, vÃ­ dá»¥ output cá»§a layer táº§ng 1 cÃ³ thá»ƒ lÃ  input cá»§a layer táº§ng 10, chá»© khÃ´ng nháº¥t thiáº¿t lÃ  input cá»§a layer táº§ng 2 nhÆ° cÃ¡ch thÃ´ng thÆ°á»ng. Ká»¹ thuáº­t nÃ y khÃ¡ tá»‘t vá» máº·t lÃ½ thuyáº¿t. Tuy nhiÃªn, cÃ³ má»™t váº¥n Ä‘á» khÃ¡ lá»›n khi sá»­ dá»¥ng lÃ  chÃºng ta pháº£i tÃ­nh toÃ¡n ká»¹ cÃ¡c káº¿t ná»‘i Ä‘á»ƒ Ä‘áº£m báº£o há»‡ thá»‘ng hoáº¡t Ä‘á»™ng á»•n Ä‘inh. MÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¢y dá»±ng trÃªn ká»¹ thuáº­t nÃ y khÃ¡ bá»±, lÃ m cho thuáº­t toÃ¡n cháº¡y cháº­m. NgoÃ i ra, tÃ­nh há»™i tá»¥ cá»§a thuáº­t toÃ¡n khÃ´ng Ä‘Æ°á»£c Ä‘áº£m báº£o. MÃ´ hÃ¬nh LSTM Ä‘Æ¡n giáº£n mÃ¬nh cÃ³ Ä‘á»ƒ á»Ÿ hÃ¬nh bÃªn dÆ°á»›i.\nMáº¡ng echo states network, lÃ  má»™t mÃ´ hÃ¬nh má»›i Ä‘Æ°á»£c nghiÃªn cá»©u gáº§n Ä‘Ã¢y, báº£n cháº¥t nÃ³ lÃ  má»™t máº£ng recurrent neural network vá»›i cÃ¡c hidden layer liÃªn káº¿t \u0026ldquo;lá»ng láº»o\u0026rdquo; vá»›i nhau. Lá»›p nÃ y Ä‘Æ°á»£c gá»i lÃ  \u0026lsquo;reservoir\u0026rsquo; (nhÆ° hÃ¬nh mÃ´ táº£ bÃªn dÆ°á»›i).\nTrong mÃ´ hÃ¬nh máº¡ng echo state network, chÃºng ta chá»‰ cáº§n huáº¥n luyá»‡n láº¡i trá»ng sá»‘ cá»§a lá»›p output, viá»‡c nÃ y giÃºp chÃºng ta rÃºt ngáº¯n thá»i gian huáº¥n luyá»‡n mÃ´ hÃ¬nh, vÃ  tÄƒng tá»‘c qusa trÃ¬nh training.\nSá»­ dá»¥ng máº¡ng Echo State Networks Vá» nguyÃªn lÃ½ hoáº¡t Ä‘á»™ng cá»§a mÃ´ hÃ¬nh nÃ y, mÃ¬nh sáº½ khÃ´ng Ä‘á» cáº­p á»Ÿ Ä‘Ã¢y. Chá»§ Ä‘á» vá» máº¡ng Echo State Networks mÃ¬nh sáº½ nghiÃªn cá»©u ká»¹ lÆ°á»¡ng vÃ  Ä‘á» cáº­p á»Ÿ trong bÃ i viáº¿t sáº¯p tá»›i. Má»¥c tiÃªu cá»§a bÃ i viáº¿t nÃ y lÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh Echo State Networks trong bÃ i toÃ¡n time series.\nDá»± doÃ¡n chuá»—i time series TrÆ°á»›c tiÃªn, chÃºng ta sáº½ import má»™t sá»‘ thÆ° viá»‡n cáº§n thiáº¿t, thÆ° viá»‡n ESN Ä‘Ã£ cÃ³ sáºµn táº¡i Ä‘Æ°á»ng dáº«n pyESN, cÃ¡c báº¡n download vá» rá»“i dÃ¹ng\n1 2 3import numpy as np 4import pandas as pd 5import seaborn as sns 6from matplotlib import pyplot as plt 7import warnings 8warnings.filterwarnings(\u0026#39;ignore\u0026#39;) 9 10# This is the library for the Reservoir Computing got it by: https://github.com/cknd/pyESN 11from pyESN import ESN Tiáº¿p theo chÃºng ta sáº½ Ä‘á»c file\n1 2data = open(\u0026#34;amazon.txt\u0026#34;).read().split() 3data = np.array(data).astype(\u0026#39;float64\u0026#39;) ChÃºng ta sáº½ xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh ESN Ä‘Æ¡n giáº£n\n1 2n_reservoir= 500 3sparsity=0.2 4rand_seed=23 5spectral_radius = 1.2 6noise = .0005 7 8 9esn = ESN(n_inputs = 1, 10 n_outputs = 1, 11 n_reservoir = n_reservoir, 12 sparsity=sparsity, 13 random_state=rand_seed, 14 spectral_radius = spectral_radius, 15 noise=noise) 16 17\t``` 18 19Äá»ƒ Ä‘Æ¡n giáº£n, mÃ¬nh sáº½ táº¡o mÃ´ hÃ¬nh vá»›i dá»¯ liá»‡u tÃ o lao nhÆ° sau:input lÃ  má»™t vector toÃ n sá»‘ 1, output lÃ  cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u cá»§a mÃ¬nh. Cho mÃ´ hÃ¬nh ESN há»c vá»›i sá»‘ lÆ°á»£ng pháº§n tá»­ lÃ  1500, sau Ä‘Ã³ sáº½ dá»± Ä‘oÃ¡n 10 Ä‘iá»ƒm dá»¯ liá»‡u tiáº¿p theo. Vá»›i bÆ°á»›c nháº£y lÃ  10, láº·p 10 láº§n. Sau quÃ¡ trÃ¬nh láº·p, mÃ¬nh thu Ä‘Æ°á»£c 100 Ä‘iá»ƒm dá»± Ä‘oÃ¡n 20 21 22```python 23trainlen = 1500 24future = 10 25futureTotal=100 26pred_tot=np.zeros(futureTotal) 27 28for i in range(0,futureTotal,future): 29 pred_training = esn.fit(np.ones(trainlen),data[i:trainlen+i]) # dá»¯ liá»‡u tá»« ngÃ y i Ä‘áº¿n ngÃ y i + trainlen 30 prediction = esn.predict(np.ones(future)) 31 pred_tot[i:i+future] = prediction[:,0] # dá»± Ä‘oÃ¡n cho ngÃ y i+ trainlen + 1 Ä‘áº¿n ngÃ y i + trainlen + future 32 33 34\t``` 35 36Váº½ mÃ´ hÃ¬nh cÃ¹i mÃ­a cá»§a mÃ¬nh má»›i lÃ m lÃªn Ä‘á»ƒ xem dá»¯ liá»‡u dá»± Ä‘oÃ¡n vÃ  dá»¯ liá»‡u thá»±c táº¿ chÃªnh lá»‡ch nhÆ° tháº¿ nÃ o 37 38```python 39plt.figure(figsize=(16,8)) 40plt.plot(range(1000,trainlen+futureTotal),data[1000:trainlen+futureTotal],\u0026#39;b\u0026#39;,label=\u0026#34;Data\u0026#34;, alpha=0.3) 41#plt.plot(range(0,trainlen),pred_training,\u0026#39;.g\u0026#39;, alpha=0.3) 42plt.plot(range(trainlen,trainlen+futureTotal),pred_tot,\u0026#39;k\u0026#39;, alpha=0.8, label=\u0026#39;Free Running ESN\u0026#39;) 43 44lo,hi = plt.ylim() 45plt.plot([trainlen,trainlen],[lo+np.spacing(1),hi-np.spacing(1)],\u0026#39;k:\u0026#39;, linewidth=4) 46 47plt.title(r\u0026#39;Ground Truth and Echo State Network Output\u0026#39;, fontsize=25) 48plt.xlabel(r\u0026#39;Time (Days)\u0026#39;, fontsize=20,labelpad=10) 49plt.ylabel(r\u0026#39;Price ($)\u0026#39;, fontsize=20,labelpad=10) 50plt.legend(fontsize=\u0026#39;xx-large\u0026#39;, loc=\u0026#39;best\u0026#39;) 51sns.despine() 52plt.show() Äá»™ phá»©c táº¡p cá»§a mÃ´ hÃ¬nh lÃ  khÃ¡ nhá» khi so vá»›i mÃ´ hÃ¬nh RNN. LÃ½ do lÃ  vá» báº£n cháº¥t, chÃºng ta chá»‰ huáº¥n luyá»‡n trÃªn trá»ng sá»‘ cá»§a output layer, nÃ³ lÃ  má»™t hÃ m tuyáº¿n tÃ­nh. Do váº­y, Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n chá»‰ giá»‘ng nhÆ° lÃ  viá»‡c tÃ­nh má»™t hÃ m há»“i quy tuyáº¿n tÃ­nh. Trong thá»±c táº¿, Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n sáº½ lÃ  O(N) vá»›i N lÃ  á»‘ lÆ°á»£ng hidden unit trong reservoir.\nTá»‘i Æ°u hoÃ¡ cÃ¡c tham sá»‘ Hyper parameters á» pháº§n trÆ°á»›c, chÃºng ta set Ä‘áº¡i cÃ¡c tham sá»‘ spectral_radius = 1.2 vÃ  noise = .0005. Trong thá»±c táº¿, chÃºng ta pháº£i tÃ¬m cÃ¡c siÃªu tham sá»‘ nÃ y báº±ng cÃ¡ch tÃ¬m ra mÃ´ hÃ¬nh tráº£ vá» MSE lÃ  nhá» nháº¥t.\nSá»­ dá»¥ng ká»¹ thuáº­t Grid Search vá»›i ngÆ°á»¡ng spectrum_radius náº±m trong Ä‘oáº¡n [0.5, 1.5] vÃ  noise náº±m trong Ä‘oáº¡n noise [0.0001, 0.01], chÃº Ã½ lÃ  cÃ¡c báº¡n cÃ³ thá»ƒ search á»Ÿ Ä‘oáº¡n lá»›n hÆ¡n. Káº¿t quáº£ thu Ä‘Æ°á»£c:\n1def MSE(yhat, y): 2 return np.sqrt(np.mean((yhat.flatten() - y)**2)) 3 4\tn_reservoir= 500 5sparsity = 0.2 6rand_seed = 23 7radius_set = [0.9, 1, 1.1] 8noise_set = [ 0.001, 0.004, 0.006] 9 10radius_set = [0.5, 0.7, 0.9, 1, 1.1,1.3,1.5] 11noise_set = [ 0.0001, 0.0003,0.0007, 0.001, 0.003, 0.005, 0.007,0.01] 12 13 14 15radius_set_size = len(radius_set) 16noise_set_size = len(noise_set) 17 18trainlen = 1500 19future = 2 20futureTotal= 100 21 22loss = np.zeros([radius_set_size, noise_set_size]) 23 24for l in range(radius_set_size): 25 rho = radius_set[l] 26 for j in range(noise_set_size): 27 noise = noise_set[j] 28 29 pred_tot=np.zeros(futureTotal) 30 31 esn = ESN(n_inputs = 1, 32 n_outputs = 1, 33 n_reservoir = n_reservoir, 34 sparsity=sparsity, 35 random_state=rand_seed, 36 spectral_radius = rho, 37 noise=noise) 38 39 for i in range(0,futureTotal,future): 40 pred_training = esn.fit(np.ones(trainlen),data[i:trainlen+i]) 41 prediction = esn.predict(np.ones(future)) 42 pred_tot[i:i+future] = prediction[:,0] 43 44 loss[l, j] = MSE(pred_tot, data[trainlen:trainlen+futureTotal]) 45 print(\u0026#39;rho = \u0026#39;, radius_set[l], \u0026#39;, noise = \u0026#39;, noise_set[j], \u0026#39;, MSE = \u0026#39;, loss[l][j] ) Káº¿t quáº£\n1 2(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 20.367056799629353) 3(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 22.44956008062169) 4(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 24.574909979223666) 5(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 25.862558649155638) 6(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 29.882933676750657) 7(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 32.63942614291128) 8(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 36.441245548726) 9(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 44.77637915282457) 10(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 19.560517902720054) 11(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 20.12742795009036) 12(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 20.81801427735713) 13(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 21.26142619965559) 14(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 23.270880660885513) 15(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 26.061347331527354) 16(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 30.298361979419834) 17(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 39.17074955771047) 18(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 18.612970860501118) 19(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 18.681815816990774) 20(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.835785386862582) 21(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.982346096338105) 22(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 20.81632098844061) 23(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 24.60968377490799) 24(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 30.231007189936882) 25(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 41.28587340583505) 26(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 18.23852181110818) 27(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 18.27010615150326) 28(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.36078059388596) 29(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.47920006882226) 30(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 20.613227951906246) 31(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 25.153712109142973) 32(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 31.700838835741898) 33(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 44.23736750779224) 34(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 17.981571756431556) 35(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 18.009398312163942) 36(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.09054736889828) 37(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.218795249276663) 38(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 20.82610561349463) 39(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 26.272452530336505) 40(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 33.91532767431614) 41(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 48.22002405965967) 42(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 17.72839068197909) 43(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 17.799908079894703) 44(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 17.92917208443474) 45(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.143905288756557) 46(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 22.20343747458126) 47(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 30.05977704513729) 48(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 40.56654468067572) 49(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 59.43231026660687) 50(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 17.627409489404897) 51(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 17.835052829116567) 52(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.100099619981393) 53(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.481406587483956) 54(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 24.887601182697498) 55(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 36.34166374510305) 56(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 50.99612645577753) 57(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 75.94229622771246) Káº¿t quáº£ thu Ä‘Æ°á»£c lÃ  giÃ¡ trá»‹ MSE tá»‘t nháº¥t lÃ  spectrum radius = 1.5 vÃ  nnoise = 0.0001\nThá»­ dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u cá»§a táº­p Ä‘oÃ n tháº¿ giá»›i di Ä‘á»™ng (MÃ£ cá»• phiáº¿u MWG) xem sao\ná» hÃ¬nh trÃªn, mÃ¬nh khÃ´ng tiáº¿n hÃ nh grid search mÃ  láº¥y láº¡i cÃ¡c hyper parameters cÅ© Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. Káº¿t quáº£ nhÆ° hÃ¬nh trÃªn mÃ¬nh tháº¥y cÅ©ng khÃ¡ tá»‘t rá»“i, nÃªn mÃ¬nh khÃ´ng tiáº¿n hÃ nh grid search láº¡i Ä‘á»ƒ tÃ¬m káº¿t quáº£ tá»‘t hÆ¡n.\nDá»±a vÃ o káº¿t quáº£ chÃºng ta thu Ä‘Æ°á»£c, cÃ³ thá»ƒ nÃ³i ráº±ng mÃ´ hÃ¬nh ESN dá»± Ä‘oÃ¡n khÃ¡ tá»‘t dá»¯ liá»‡u thuá»™c dáº¡ng time series vá»›i Ä‘á»™ há»—n loáº¡n cao. ÄÃ¢y lÃ  má»™t káº¿t luáº­n nhá» cá»§a mÃ¬nh dá»±a vÃ o báº±ng chá»©ng trÃªn viá»‡c mÃ¬nh test trÃªn táº­p dá»¯ liá»‡u ngáº«u nhiÃªn mÃ  mÃ¬nh cÃ³.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Apr 4, 2019","img":"","permalink":"/blog/2019-04-04-predicting-stock-prices-with-echo-state-networks/","series":null,"tags":["machine learning","deep learning","neural network","amazone","tháº¿ giá»›i di Ä‘á»™ng","mwg"],"title":"Dá»± ÄoÃ¡n GiÃ¡ Cá»• Phiáº¿u Báº±ng MÃ´ HÃ¬nh Máº¡ng Echo State Networks"},{"categories":null,"content":" HÆ°á»›ng dáº«n ban Ä‘áº§u Báº¡n huáº¥n luyá»‡n má»™t hÃ¬nh máº¥t hÆ¡n 12 tiáº¿ng Ä‘á»“ng há»“. Má»i thá»© khÃ¡ á»•n: loss function giáº£m. NhÆ°ng khi báº¡n mang mÃ´ hÃ¬nh ra predict thÃ¬ Ä‘iá»u tá»“i tá»‡ nháº¥t xáº£y ra: Táº¥t cáº£ tráº£ vá» Ä‘á»u lÃ  0, khÃ´ng cÃ³ cÃ¡i nÃ o nháº­n dáº¡ng chÃ­nh xÃ¡c cáº£. \u0026ldquo;Äiá»u gÃ¬ Ä‘Ã£ xáº£y ra, báº¡n Ä‘Ã£ lÃ m gÃ¬ sai?\u0026rdquo;. Báº¡n há»i mÃ¡y tÃ­nh, nÃ³ khÃ´ng tráº£ lá»i báº¡n. Báº¡n Ä‘áº­p bÃ n, Ä‘áº­p gháº¿ trong cÆ¡n tá»©c giáº­n vÃ  cháº³ng giáº£i quyáº¿t Ä‘Æ°á»£c Ä‘iá»u gÃ¬ cáº£.\nCÃ³ ráº¥t nhiá»u nguyÃªn nhÃ¢n gÃ¢y ra váº¥n Ä‘á» nÃ y. Viá»‡c cáº§n lÃ m cá»§a cÃ¡c báº¡n lÃ  pháº£i tÃ¬m ra chÃ­nh xÃ¡c nguyÃªn nhÃ¢n vÃ  \u0026ldquo;sá»­a\u0026rdquo; nÃ³, sau Ä‘Ã³ tá»‘n hÆ¡n 12 tiáº¿ng Ä‘á»“ng há»“ Ä‘á»ƒ huáº¥n luyá»‡n láº¡i :), rá»“i láº¡i sá»­a \u0026hellip;\nHÆ°á»›ng dáº«n ban Ä‘áº§u Náº¿u báº¡n gáº·p tÃ¬nh tráº¡ng nhÆ° pháº§n mÃ´ táº£ á»Ÿ trÃªn, báº¡n hÃ£y thá»±c hiá»‡n cÃ¡c bÆ°á»›c mÃ¬nh mÃ´ táº£ bÃªn dÆ°á»›i thá»­ xem váº¥n Ä‘á» cá»§a báº¡n lÃ  gÃ¬?\nBáº¯t Ä‘áº§u huáº¥n luyá»‡n mÃ´ hÃ¬nh báº±ng má»™t mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n mÃ  báº¡n biáº¿t cháº¯c ráº±ng nÃ³ hoáº¡t Ä‘á»™ng tá»‘t vá»›i táº­p dá»¯ liá»‡u báº¡n Ä‘ang cÃ³. VÃ­ dá»¥, trong bÃ i toÃ¡n object detection, hÃ£y sá»­ dá»¥ng mÃ´ hÃ¬nh VGG. VÃ  báº¡n hÃ£y cá»‘ gáº¯ng sá»­a dá»¥ng standard loss náº¿u cÃ³ thá»ƒ.\nBá» qua nhá»¯ng thá»© rÃ¢u ria nhÆ° lÃ  regularization hoáº·c data augmentation. HÃ£y táº­p trung vÃ o xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh cho má»™t káº¿t quáº£ kháº£ quan cÃ¡i Ä‘Ã£, sau Ä‘Ã³ má»›i cáº£i tiáº¿n báº±ng cÃ¡c thá»© rÃ¢u ria trÃªn sau.\nNáº¿u báº¡n finetuning má»™t mÃ´ hÃ¬nh, báº¡n hÃ£y kiá»ƒm tra tháº­t ká»¹ quÃ¡ trÃ¬nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u. Cháº¯c cháº¯n ráº±ng quÃ¡ trÃ¬nh tiá»n xá»­ lÃ½ cá»§a báº¡n giá»‘ng y chang quÃ¡ trÃ¬nh tiá»n xá»­ lÃ½ cá»§a mÃ´ hÃ¬nh gá»‘c.\nCháº¯c cháº¯n 100% ráº±ng giÃ¡ trá»‹ Ä‘áº§u vÃ o lÃ  Ä‘Ãºng.\nBáº¯t Ä‘áº§u báº±ng má»™t táº­p sample nhá» (tá»« 2 Ä‘áº¿n 20 máº«u). Huáº¥n luyá»‡n nÃ³ Ä‘áº¿n khi bá»‹ overfit vÃ  bá»• sung thÃªm máº«u huáº¥n luyá»‡n sau khi mÃ´ hÃ¬nh cá»§a báº¡n bá»‹ overfit.\nBá»• sung thÃªn cÃ¡c yáº¿u tá»‘ rÃ¢u ria nhÆ° augmentation/regularization, custom loss functions, thá»­ vá»›i má»™t mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n.\nNáº¿u nhá»¯ng cÃ¡ch trÃªn váº«n khÃ´ng thÃ nh cÃ´ng. MÃ´ hÃ¬nh váº«n tráº£ vá» giÃ¡ trá»‹ zero. Báº¡n cÃ³ thá»ƒ máº¯c pháº£i má»™t sá»‘ lá»—i Ä‘Æ°á»£c liá»‡t kÃª bÃªn dÆ°á»›i.\nKiá»ƒm tra ráº±ng dá»¯ liá»‡u cá»§a báº¡n Ä‘Æ°a vÃ o máº¡ng neural netwok tháº­t sá»± cÃ³ Ã½ nghÄ©a vÃ  Ä‘Ãºng. VÃ­ dá»¥, hÃ£y Ä‘áº£m báº£o ráº±ng báº¡n khÃ´ng nháº§m láº«n / swap giÃ¡ trá»‹ giá»¯a width vÃ  height cá»§a hÃ¬nh áº£nh, hoáº·c má»™t lÃ½ do nÃ o Ä‘Ã³ báº¡n Ä‘Æ°a vÃ o má»™t zero image, hoáº·c báº¡n chá»‰ huáº¥n luyá»‡n duy nháº¥t má»™t batch (vÃ­ dá»¥ dá»¯ liá»‡u báº¡n lá»›n, chia lÃ m 10 batch, vÃ  code nháº§m sao Ä‘Ã³ chá»‰ Ä‘Æ°a input lÃ  batch sá»‘ 1 vÃ o).\nMá»™t trÆ°á»ng há»£p ná»¯a lÃ  khi input vÃ  output cá»§a báº¡n cháº³ng cÃ³ má»‘i liÃªn há»‡ gÃ¬ vá»›i nhau, vÃ  khÃ´ng cÃ¡ch nÃ o nháº­n biáº¿t ráº±ng nÃ³ phá»¥ thuá»™c nhau bá»Ÿi vÃ¬ báº£n cháº¥t cá»§a dá»¯ liá»‡u lÃ  nhÆ° váº­y, hoáº·c input cá»§a báº¡n Ä‘ang cÃ³ chÆ°a Ä‘á»§ chá»©ng cá»© Ä‘á»ƒ suy ra output. Má»™t vÃ­ dá»¥ cá»§a trÆ°á»ng há»£p nÃ y lÃ  giÃ¡ chá»©ng khoÃ¡ng.\nKiá»ƒm tra ká»¹ dá»¯ liá»‡u train Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng cÃ³ Ä‘Ã¡nh nhÃ£n sai\nKiá»ƒm tra xem dá»¯ liá»‡u cÃ³ bá»‹ máº¥t cÃ¢n báº±ng khÃ´ng. HÃ£y sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t Ä‘á»ƒ cÃ¢n báº±ng láº¡i dá»¯ liá»‡u.\nÄáº£m báº£o ráº±ng trong 1 batch chá»©a dá»¯ liá»‡u cá»§a nhiá»u hÆ¡n 1 nhÃ£n. HÃ£y xÃ¡o trá»™n ngáº«u nhiÃªn dá»¯ liá»‡u Ä‘á»ƒ trÃ¡nh lá»—i nÃ y.\nBÃ i bÃ¡o https://arxiv.org/abs/1609.04836 chá»‰ ra ráº±ng khi báº¡n huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i batch size lá»›n cÃ³ thá»ƒ lÃ m giáº£m tÃ­nh tá»•ng quÃ¡t cá»§a mÃ´ hÃ¬nh.\nKhoÃ¡ há»c CS231 Ä‘Ã£ chá»‰ ra má»™t lá»—i khÃ¡ phá»• biáº¿n: \u0026ldquo;Báº¥t ká»³ má»™t quÃ¡ trÃ¬nh tiá»n xá»­ lÃ½ nÃ o cÅ©ng pháº£i thá»±c hiá»‡n trÃªn táº­p train, vÃ  sau Ä‘Ã³ Ã¡p dá»¥ng vÃ o táº­p validation,test\u0026rdquo;. VÃ­ dá»¥, chÃºng ta tÃ­nh trung bÃ¬nh trÃªn toÃ n bá»™ dá»¯ liá»‡u, rá»“i sau Ä‘Ã³ chia táº­p dá»¯ liá»‡u thÃ nh train, test, predict lÃ  khÃ´ng Ä‘Ãºng. HÃ nh Ä‘á»™ng Ä‘Ãºng lÃ  chia táº­p dá»¯ liá»‡u thÃ nh train, test, vali trÆ°á»›c, sau Ä‘Ã³ tÃ­nh giÃ¡ trá»‹ trung bÃ¬nh trÃªn tá»«ng kÃªnh mÃ u trÃªn táº­p train, rá»“i má»›i láº¥y giÃ¡ trá»‹ trung bÃ¬nh Ä‘Ã³ Ã¡p cho táº­p test vÃ  táº­p validate.\nMá»™t váº¥n Ä‘á» khÃ¡c cÃ³ thá»ƒ lÃ  \u0026ldquo;Look for correct loss at chance performance\u0026rdquo;:\nVÃ­ dá»¥, vá»›i táº­p dá»¯ liá»‡u CIFAR-10 sá»­ dá»¥ng softmax classifier, á»Ÿ láº§n Ä‘áº§u tiÃªn, giÃ¡ trá»‹ loss mong Ä‘á»£i cá»§a chÃºng ta lÃ  2.303, bá»Ÿi vÃ¬ cÃ³ 1 tháº±ng Ä‘Ãºng, 10 tháº±ng sai, xÃ¡c suáº¥t lÃ  1/10 = 0.1. softmax loss lÃ  -ln(0.1) = 2.302.\nVá»›i dá»¯ liá»‡u CIFAR-10 dÃ¹ng SVM, á»Ÿ láº§n láº·p Ä‘áº§u tiÃªn, giÃ¡ trá»‹ loss chÃºng ta ká»³ vá»ng lÃ  9 (vá»›i má»—i lá»›p sai, giÃ¡ trá»‹ margin sáº½ lÃ  1).\nNáº¿u cÃ¡c giÃ¡ trá»‹ tráº£ ra khÃ´ng giá»‘ng nhÆ° mong Ä‘á»£i, váº¥n Ä‘á» xáº£y ra lÃ  do giÃ¡ trá»‹ init khÃ´ng Ä‘Ãºng.\nMá»™t váº¥n Ä‘á» ná»¯a lÃ  khi tÄƒng giÃ¡ trá»‹ regularization thÃ¬ cÅ©ng Ä‘á»“ng thá»i tÄƒng giÃ¡ trá»‹ loss. =\u0026gt; Náº¿u loss khÃ´ng tÄƒng =\u0026gt; cÃ³ váº¥n Ä‘á».\nBÃ i viáº¿t Ä‘Æ°á»£c lÆ°á»£c dá»‹ch tá»« https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607?fbclid=IwAR1Qj6jJW87oKi_LR7xWMDOMZDTx8xwLZEhCCMuvOw63ztwdD1MknZVjm_Q\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Apr 2, 2019","img":"","permalink":"/blog/2019-04-02-37-reason-neural-network-not-working/","series":null,"tags":["machine learning","deep learning","neural network"],"title":"CÃ¡c LÃ½ Do Máº¡ng Neural Network KhÃ´ng Hoáº¡t Äá»™ng KhÃ´ng ChÃ­nh XÃ¡c"},{"categories":null,"content":" TrÃ­ tuá»‡ nhÃ¢n táº¡o Dá»¯ liá»‡u lá»›n MÃ¡y há»c vÃ  má»‘i quan há»‡ vá»›i TrÃ­ tuá»‡ nhÃ¢n táº¡o cÃ¹ng Dá»¯ liá»‡u lá»›n Má»‘i quan há»‡ giá»¯a ML vá»›i AI vÃ  Big Data Trong vÃ i nÄƒm trá»Ÿ láº¡i Ä‘Ã¢y (khoáº£ng tá»« 2013) truyá»n thÃ´ng trong vÃ  ngoÃ i nÆ°á»›c cÃ³ khÃ¡ nhiá»u bÃ i viáº¿t giáº­t tÃ­t vá» â€œCÃ¡ch máº¡ng cÃ´ng nghiá»‡p láº§n thá»© tÆ°â€ hay â€œThá»i Ä‘áº¡i cÃ´ng nghiá»‡p 4.0â€. CÃ¹ng vá»›i cÃ¡c cá»¥m tá»« nÃ y, â€œTrÃ­ tuá»‡ nhÃ¢n táº¡oâ€, â€œMÃ¡y há»câ€, â€œDá»¯ liá»‡u lá»›nâ€ láº¡i Ä‘Æ°á»£c nháº¯c Ä‘áº¿n vá»›i táº§n suáº¥t cao hÆ¡n. Váº­y thÃ¬ nhá»¯ng thuáº­t ngá»¯ nÃ y cÃ³ Ã½ nghÄ©a gÃ¬ vÃ  giá»¯a chÃºng cÃ³ má»‘i liÃªn há»‡ nÃ o vá»›i nhau hay khÃ´ng? Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ cÃ¹ng tÃ¬m hiá»ƒu.\nTrÃ­ tuá»‡ nhÃ¢n táº¡o NÄƒm 2016, trong â€œTráº­n thÃ¡ch Ä‘áº¥u cá»§a Google DeepMindâ€ Ä‘Æ°á»£c tá»• chá»©c táº¡i HÃ n Quá»‘c, AlphaGo (má»™t pháº§n má»m chÆ¡i cá» vÃ¢y trÃªn mÃ¡y tÃ­nh Ä‘Æ°á»£c xÃ¢y dá»±ng bá»Ÿi Google DeepMind) Ä‘Ã£ dÃ nh chiáº¿n tháº¯ng 4/5 vÃ¡n trÆ°á»›c Lee Sedol (ngÆ°á»i tá»«ng 18 láº§n vÃ´ Ä‘á»‹ch giáº£i cá» vÃ¢y tháº¿ giá»›i) lÃ  sá»± kiá»‡n quan trá»ng khiáº¿n con ngÆ°á»i cÃ³ thá»ƒ tin tÆ°á»Ÿng vÃ o tÆ°Æ¡ng lai vÃ  sá»©c máº¡nh cá»§a trÃ­ tuá»‡ nhÃ¢n táº¡o.\nSau khi tráº­n Ä‘áº¥u káº¿t thÃºc, chÃ­nh phá»§ HÃ n Quá»‘c cÃ´ng bá»‘ ráº±ng há» sáº½ Ä‘áº§u tá»« 863 triá»‡u USD (khoáº£ng 1 nghÃ¬n tá»· won) vÃ o nghiÃªn cá»©u trÃ­ tuá»‡ nhÃ¢n táº¡o trong vÃ²ng vÃ i nÄƒm tiáº¿p theo.\nTÃ­nh tá»›i nay, lÆ°á»£ng dá»¯ liá»‡u cÃ¡c tráº­n Ä‘áº¥u cá» vÃ¢y Ä‘Æ°á»£c nháº­n vÃ o giÃºp AlphaGO cÃ³ kinh nghiá»‡m tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 80 nÄƒm chÆ¡i cá» vÃ¢y liÃªn tá»¥c. Má»™t con sá»‘ Ä‘Ã¡ng ngáº¡c nhiÃªn vÃ  ngÆ°á»¡ng má»™.\nNhÆ° váº­y trÃ­ tuá»‡ nhÃ¢n táº¡o lÃ  gÃ¬?\nTrÃ­ tuá»‡ nhÃ¢n táº¡o (AI - Artificial Intelligence) lÃ  má»™t nhÃ¡nh nghiÃªn cá»©u trong lÄ©nh vá»±c khoa há»c mÃ¡y tÃ­nh vÃ  tá»« lÃ¢u Ä‘Ã£ Ä‘Æ°á»£c ráº¥t nhiá»u cÃ¡c nhÃ  nghiÃªn cá»©u quan tÃ¢m. Thuáº­t ngá»¯ AI Ä‘Æ°á»£c Ä‘áº·t bá»Ÿi nhÃ  khoa há»c mÃ¡y tÃ­nh ngÆ°á»i Má»¹ - John McCarthy vÃ o nÄƒm 1956 táº¡i Há»™i nghá»‹ Dartmouth. Cho Ä‘áº¿n thá»i Ä‘iá»ƒm hiá»‡n táº¡i thÃ¬ cÃ³ khÃ¡ nhiá»u nhá»¯ng phÃ¡t biá»ƒu khÃ¡c nhau vá» AI bá»Ÿi cÃ¡c chuyÃªn gia, cháº³ng háº¡n nhÆ°:\nAI lÃ  khoa há»c nghiÃªn cá»©u giÃºp táº¡o ra mÃ¡y tÃ­nh cÃ³ kháº£ nÄƒng suy nghÄ©, Ä‘áº§y trÃ­ tuá»‡ nhÆ° tÃªn cá»§a chÃ­nh nÃ³ (Haugeland, 1985).\nAI lÃ  khoa há»c nghiÃªn cá»©u cÃ¡c hoáº¡t Ä‘á»™ng trÃ­ nÃ£o thÃ´ng qua cÃ¡c mÃ´ hÃ¬nh tÃ­nh toÃ¡n (Chaniaka vÃ  McDemott, 1985).\nAI lÃ  khoa há»c nghiÃªn cá»©u cÃ¡ch Ä‘á»ƒ mÃ¡y tÃ­nh cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘Æ°á»£c nhá»¯ng cÃ´ng viá»‡c mÃ  con ngÆ°á»i lÃ m tá»‘t hÆ¡n mÃ¡y (Rich vÃ  Knight, 1991).\nAI lÃ  khoa há»c nghiÃªn cá»©u cÃ¡c mÃ´ hÃ¬nh mÃ¡y tÃ­nh cÃ³ thá»ƒ nháº­n thá»©c, láº­p luáº­n vÃ  hÃ nh Ä‘á»™ng (Winston, 1992).\nAI lÃ  khoa há»c nghiÃªn cá»©u cÃ¡c hÃ nh vi thÃ´ng minh mÃ´ phá»ng cÃ¡c váº­t thá»ƒ nhÃ¢n táº¡o (Nilsson, 1998)\nAI lÃ  khoa há»c nghiÃªn cá»©u cÃ¡c hÃ nh vi thÃ´ng minh nháº±m giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» Ä‘Æ°á»£c Ä‘áº·t ra Ä‘á»‘i vá»›i cÃ¡c chÆ°Æ¡ng trÃ¬nh mÃ¡y tÃ­nh (Há»c viá»‡n Ká»¹ thuáº­t QuÃ¢n sá»±).\nNhÆ° váº­y, tá»« nhá»¯ng Ä‘á»‹nh nghÄ©a trÃªn chÃºng ta cÃ³ thá»ƒ rÃºt ra Ä‘á»‹nh nghÄ©a tá»•ng quÃ¡t ráº±ng trÃ­ tuá»‡ nhÃ¢n táº¡o hay trÃ­ thÃ´ng minh nhÃ¢n táº¡o lÃ  trÃ­ tuá»‡ Ä‘Æ°á»£c biá»ƒu diá»…n bá»Ÿi báº¥t ká»³ má»™t há»‡ thá»‘ng nhÃ¢n táº¡o nÃ o. Há»‡ thá»‘ng Ä‘Ã³ sáº½ mÃ´ phá»ng cÃ¡c quÃ¡ trÃ¬nh hoáº¡t Ä‘á»™ng trÃ­ tuá»‡ cá»§a con ngÆ°á»i, bao gá»“m quÃ¡ trÃ¬nh há»c táº­p, láº­p luáº­n vÃ  tá»± sá»­a lá»—i. Do Ä‘Ã³, trÃ­ thÃ´ng minh nhÃ¢n táº¡o liÃªn quan Ä‘áº¿n cÃ¡ch hÃ nh xá»­, sá»± há»c há»i vÃ  kháº£ nÄƒng thÃ­ch á»©ng thÃ´ng minh cá»§a mÃ¡y mÃ³c nÃ³i chung vÃ  mÃ¡y tÃ­nh nÃ³i riÃªng.\nCÃ¡ch Ä‘Ã¢y vÃ i nÄƒm, Ä‘á»‘i vá»›i pháº§n Ä‘Ã´ng chÃºng ta â€“ nhá»¯ng ngÆ°á»i khÃ´ng nghiÃªn cá»©u chuyÃªn sÃ¢u vá» AI sáº½ cho ráº±ng AI lÃ  má»™t phÆ°Æ¡ng thá»©c Ä‘á»ƒ nhÃ¢n báº£n con ngÆ°á»i báº±ng mÃ¡y mÃ³c vÃ  Ä‘Æ°á»£c á»©ng dá»¥ng trong cháº¿ táº¡o robot. Tuy nhiÃªn AI hiá»‡n táº¡i khÃ´ng pháº£i chá»‰ lÃ  nhá»¯ng con robot mÃ  nÃ³ cÃ³ thá»ƒ biá»ƒu hiá»‡n dÆ°á»›i báº¥t cá»© hÃ¬nh dáº¡ng nÃ o, tháº­m chÃ­ vÃ´ hÃ¬nh vÃ´ dáº¡ng, nháº±m cung cáº¥p lá»i giáº£i cho cÃ¡c váº¥n Ä‘á» cá»§a cuá»™c sá»‘ng thá»±c táº¿ trÃªn háº§u háº¿t cÃ¡c lÄ©nh vá»±c, cháº³ng háº¡n nhÆ°:\nTrong lÄ©nh vá»±c chÄƒm sÃ³c sá»©c khá»e: AI gÃ³p pháº§n cáº£i thiá»‡n tÃ¬nh tráº¡ng sá»©c khá»e bá»‡nh nhÃ¢n, vÃ  giÃºp giáº£m chi phÃ­ Ä‘iá»u trá»‹. Má»™t trong nhá»¯ng há»‡ thá»‘ng cÃ´ng nghá»‡ chÄƒm sÃ³c sá»©c khá»e tá»‘t nháº¥t pháº£i ká»ƒ Ä‘áº¿n lÃ  IBM Watson, Ä‘Æ°á»£c má»‡nh danh lÃ  â€œBÃ¡c sÄ© biáº¿t tuá»‘tâ€ khi mÃ  há»‡ thá»‘ng nÃ y cÃ³ kháº£ nÄƒng hiá»ƒu Ä‘Æ°á»£c cÃ¡c ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  cÃ³ kháº£ nÄƒng pháº£n há»“i cÃ¡c cÃ¢u há»i Ä‘Æ°á»£c yÃªu cáº§u hoáº·c cho phÃ©p bá»‡nh nhÃ¢n tra cá»©u thÃ´ng tin vá» tinh hÃ¬nh sá»©c khoáº» cá»§a mÃ¬nh. IBM Watson cÃ³ thá»ƒ lÆ°á»›t duyá»‡t cÃ¹ng lÃºc hÃ ng triá»‡u há»“ sÆ¡ bá»‡nh Ã¡n Ä‘á»ƒ cung cáº¥p cho cÃ¡c bÃ¡c sÄ© nhá»¯ng lá»±a chá»n Ä‘iá»u trá»‹ dá»±a trÃªn báº±ng chá»©ng chá»‰ trong vÃ²ng vÃ i giÃ¢y nhá» kháº£ nÄƒng tá»•ng há»£p dá»¯ liá»‡u khá»•ng lá»“ vÃ  tá»‘c Ä‘á»™ xá»­ lÃ½ máº¡nh máº½. â€œBÃ¡c sÄ© biáº¿t tuá»‘tâ€ khai thÃ¡c dá»¯ liá»‡u bá»‡nh nhÃ¢n vÃ  cÃ¡c nguá»“n dá»¯ liá»‡u sáºµn cÃ³ khÃ¡c nháº±m táº¡o ra giáº£ thuyáº¿t vÃ  tá»« Ä‘Ã³ xáº­y dá»±ng má»™t lÆ°á»£c Ä‘á»“ Ä‘iá»ƒm tin cáº­y giÃºp â€œBÃ¡c sÄ© tháº­tâ€ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh Ä‘iá»u trá»‹ cuá»‘i cÃ¹ng. NgoÃ i ra, á»©ng dá»¥ng AI ná»•i báº­c khÃ¡c trong lÄ©nh vá»±c nÃ y cáº§n pháº£i ká»ƒ Ä‘áº¿n lÃ  chatbot - chÆ°Æ¡ng trÃ¬nh mÃ¡y tÃ­nh trá»±c tuyáº¿n Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i vÃ  há»— trá»£ khÃ¡ch hÃ ng, sáº¯p xáº¿p cÃ¡c cuá»™c háº¹n hoáº·c trá»£ giÃºp bá»‡nh nhÃ¢n thÃ´ng qua quÃ¡ trÃ¬nh thanh toÃ¡n vÃ  cÃ¡c trá»£ lÃ½ y táº¿ áº£o cung cáº¥p pháº£n há»“i y táº¿ cÆ¡ báº£n.\nTrong lÄ©nh vá»±c kinh doanh: CÃ¡c tÃ¡c vá»¥ mÃ  con ngÆ°á»i thá»±c hiá»‡n láº·p Ä‘i láº·p láº¡i giá» Ä‘Ã¢y Ä‘Ã£ Ä‘Æ°á»£c tá»± Ä‘á»™ng hoÃ¡ quy trÃ¬nh báº±ng robot. CÃ¡c thuáº­t toÃ¡n Machine Learning Ä‘Æ°á»£c tÃ­ch há»£p trÃªn cÃ¡c ná»n táº£ng phÃ¢n tÃ­ch vÃ  CRM (Customer Relationship Management - quáº£n lÃ½ quan há»‡ khÃ¡ch hÃ ng) Ä‘á»ƒ khÃ¡m phÃ¡ cÃ¡c thÃ´ng tin vá» cÃ¡ch phá»¥c vá»¥ khÃ¡ch hÃ ng tá»‘t hÆ¡n. Chatbots Ä‘Æ°á»£c tÃ­ch há»£p trÃªn cÃ¡c trang web nháº±m cung cáº¥p dá»‹ch vá»¥ ngay láº­p tá»©c cho khÃ¡ch hÃ ng. Má»™t sá»‘ há»‡ thá»‘ng trá»£ lÃ½ áº£o ná»•i tiáº¿ng giÃºp sáº¯p xáº¿p, nháº¯c cuá»™c há»p, tÃ¬m kiáº¿m thÃ´ng tin nhÆ° Google Assistant, Alexa, Siri. Hiá»‡n nay cÃ¡c há»‡ thá»‘ng nÃ y Ä‘Ã£ báº¯t Ä‘áº§u Ä‘Æ°á»£c tÃ­ch há»£p vÃ o trong cÃ¡c thiáº¿t bá»‹ gia dá»¥ng nhÆ° mÃ¡y giáº·t, tá»§ láº¡nh, lÃ² vi sÃ³ng, â€¦ giÃºp ngÆ°á»i sá»­ dá»¥ng cÃ³ thá»ƒ Ä‘iá»u khiá»ƒn thiáº¿t bá»‹ báº±ng cÃ¢u lá»‡nh thoáº¡i.\nTrong lÄ©nh vá»±c giÃ¡o dá»¥c: CÃ´ng nghá»‡ thá»±c táº¿ áº£o lÃ m thay Ä‘á»•i cÃ¡ch dáº¡y vÃ  há»c. Sinh viÃªn cÃ³ thá»ƒ Ä‘eo kÃ­nh VR vÃ  cÃ³ cáº£m giÃ¡c nhÆ° Ä‘ang ngá»“i trong lá»›p nghe giáº£ng bÃ i hay nháº­p vai Ä‘á»ƒ chá»©ng kiáº¿n nhá»¯ng tráº­n Ä‘Ã¡nh giáº£ láº­p, ngáº¯m nhÃ¬n di tÃ­ch, Ä‘iá»u nÃ y giÃºp mang láº¡i cáº£m xÃºc vÃ  ghi nhá»› sÃ¢u sáº¯c ná»™i dung há»c. Hoáº·c khi Ä‘Ã o táº¡o nghá» phi cÃ´ng, há»c viÃªn Ä‘eo kÃ­nh sáº½ tháº¥y phÃ­a trÆ°á»›c lÃ  cabin vÃ  há»c lÃ¡i mÃ¡y bay nhÆ° tháº­t Ä‘á»ƒ thá»±c hÃ nh giÃºp giáº£m thiá»ƒu rá»§i ro trong quÃ¡ trÃ¬nh bay tháº­t.\nTrong lÄ©nh vá»±c tÃ i chÃ­nh: AI Ã¡p dá»¥ng cho cÃ¡c á»©ng dá»¥ng tÃ i chÃ­nh cÃ¡ nhÃ¢n nhÆ° Mint hay Turbo Tax giÃºp tÄƒng cÆ°á»ng cÃ¡c Ä‘á»‹nh cháº¿ tÃ i chÃ­nh.\nTrong lÄ©nh vá»±c phÃ¡p luáº­t: QuÃ¡ trÃ¬nh khÃ¡m phÃ¡, chá»n lá»c thÃ´ng qua cÃ¡c tÃ i liá»‡u trong luáº­t phÃ¡p thÆ°á»ng Ã¡p Ä‘áº£o Ä‘á»‘i vá»›i con ngÆ°á»i. Tá»± Ä‘á»™ng hÃ³a quÃ¡ trÃ¬nh nÃ y giÃºp tiáº¿t kiá»‡m thá»i gian vÃ  quÃ¡ trÃ¬nh lÃ m viá»‡c hiá»‡u quáº£ hÆ¡n. CÃ¡c trá»£ lÃ½ áº£o giÃºp tráº£ lá»i cÃ¡c cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c láº­p trÃ¬nh sáºµn.\nTrong lÄ©nh vá»±c sáº£n xuáº¥t: ÄÃ¢y lÃ  lÄ©nh vá»±c Ä‘i Ä‘áº§u trong viá»‡c káº¿t há»£p robot vÃ o luá»“ng cÃ´ng viá»‡c. Robot cÃ´ng nghiá»‡p Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c nhiá»‡m vá»¥ Ä‘Æ¡n láº» vÃ  Ä‘Ã£ Ä‘Æ°á»£c tÃ¡ch ra khá»i con ngÆ°á»i. Xe tá»± Ä‘á»™ng lÃ¡i Tesla lÃ  má»™t á»©ng dá»¥ng Ä‘iá»ƒn hÃ¬nh trong lÄ©nh vá»±c nÃ y.\nTrong lÄ©nh vá»±c báº£o máº­t thÃ´ng tin: ráº¥t nhiá»u há»‡ thá»‘ng nháº­n diá»‡n vÃ  báº£o máº­t thÃ´ng minh Ä‘Æ°á»£c xÃ¢y dá»±ng, pháº£i ká»ƒ Ä‘áº¿n nhÆ° FaceID - báº£o máº­t thÃ´ng qua nháº­n diá»‡n khuÃ´n máº·t cá»§a Apple, Facebook vá»›i kháº£ nháº­n diá»‡n khuÃ´n máº·t Ä‘á»ƒ gá»£i Ã½ tag. BÃªn cáº¡nh cÃ¡c nÆ°á»›c phÆ°Æ¡ng TÃ¢y thÃ¬ Trung Quá»‘c hiá»‡n Ä‘ang lÃ  quá»‘c gia Ä‘i Ä‘áº§u trong viá»‡c sá»­ dá»¥ng AI Ä‘á»ƒ nháº­n diá»‡n vÃ  quáº£n lÃ½ cÃ´ng dÃ¢n.\nTá»« nhá»¯ng á»©ng dá»¥ng trÃªn ta cÃ³ thá»ƒ tháº¥y ráº±ng nÃ³i Ä‘áº¿n AI lÃ  nÃ³i vá» nÃ£o bá»™ chá»© khÃ´ng pháº£i lÃ  nÃ³i vá» má»™t cÆ¡ thá»ƒ, lÃ  pháº§n má»m chá»© khÃ´ng pháº£i lÃ  pháº§n cá»©ng.\nDá»¯ liá»‡u lá»›n Má»™t cÃ¡ch tá»•ng quÃ¡t thÃ¬ dá»¯ liá»‡u lÃ  thÃ´ng tin dÆ°á»›i dáº¡ng kÃ½ hiá»‡u, chá»¯ viáº¿t, chá»¯ sá»‘, hÃ¬nh áº£nh, Ã¢m thanh hoáº·c dáº¡ng tÆ°Æ¡ng tá»±. Tá»« tháº¿ ká»· thá»© 3 trÆ°á»›c CN, ThÆ° viá»‡n Alexandria Ä‘Æ°á»£c coi lÃ  nÆ¡i chá»©a Ä‘á»±ng toÃ n bá»™ kiáº¿n thá»©c cá»§a loÃ i ngÆ°á»i. NgÃ y nay, tá»•ng lÆ°á»£ng dá»¯ liá»‡u trÃªn toÃ n tháº¿ giá»›i Ä‘á»§ Ä‘á»ƒ chia Ä‘á»u cho má»—i Ä‘áº§u ngÆ°á»i má»™t lÆ°á»£ng nhiá»u gáº¥p 320 láº§n lÆ°á»£ng dá»¯ liá»‡u mÃ  cÃ¡c sá»­ gia tin ráº±ng ThÆ° viá»‡n Alexandria tá»«ng lÆ°u trá»¯ â€“ Æ°á»›c tÃ­nh vÃ o khoáº£ng 120 exabyte. CÃ¡c nhÃ  thá»‘ng kÃª cho ráº±ng, náº¿u táº¥t cáº£ nhá»¯ng dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c ghi vÃ o Ä‘Ä©a CD vÃ  xáº¿p chá»“ng chÃºng lÃªn nhau thÃ¬ sáº½ cÃ³ tá»›i 5 chá»“ng Ä‘Ä©a mÃ  má»—i chá»“ng Ä‘á»u cÃ³ Ä‘á»™ cao báº±ng khoáº£ng cÃ¡ch tá»« TrÃ¡i Äáº¥t Ä‘áº¿n Máº·t TrÄƒng.\nSá»± bÃ¹ng ná»• dá»¯ liá»‡u nÃ y chá»‰ má»›i xuáº¥t hiá»‡n gáº§n Ä‘Ã¢y. CÃ¡ch Ä‘Ã¢y khÃ´ng lÃ¢u, vÃ o nÄƒm 2000, chá»‰ má»™t pháº§n tÆ° lÆ°á»£ng dá»¯ liá»‡u lÆ°u trá»¯ trÃªn toÃ n tháº¿ giá»›i á»Ÿ dáº¡ng ká»¹ thuáº­t sá»‘, ba pháº§n tÆ° cÃ²n láº¡i Ä‘Æ°á»£c ngÆ°á»i ta lÆ°u trÃªn giáº¥y tá», phim, vÃ  cÃ¡c phÆ°Æ¡ng tiá»‡n analog khÃ¡c. NhÆ°ng do lÆ°á»£ng dá»¯ liá»‡u ká»¹ thuáº­t sá»‘ bÃ¹ng ná»• quÃ¡ nhanh â€“ cá»© 3 nÄƒm láº¡i tÄƒng gáº¥p Ä‘Ã´i, lÃ m cho tá»‰ lá»‡ nÃ y nhanh chÃ³ng Ä‘áº£o ngÆ°á»£c. Hiá»‡n nay, chá»‰ dÆ°á»›i 2% tá»•ng lÆ°á»£ng dá»¯ liá»‡u chÆ°a Ä‘Æ°á»£c chuyá»ƒn sang lÆ°u trá»¯ á»Ÿ dáº¡ng ká»¹ thuáº­t sá»‘.\nDÆ°á»›i Ä‘Ã¢y lÃ  má»™t vÃ i vÃ­ dá»¥ nhá» minh hoáº¡ cho sá»± dÃ¹ng ná»• cá»§a dá»¯ liá»‡u hiá»‡n nay:\nTheo Forbes, lÆ°á»£ng dá»¯ liá»‡u mÃ  ngÆ°á»i dÃ¹ng táº¡o ra má»—i ngÃ y lÃ  2.5 tá»· tá»· bytes, má»™t con sá»‘ ráº¥t Ä‘Ã¡ng kinh ngáº¡c vÃ  dá»± Ä‘oÃ¡n con sá»‘ nÃ y sáº½ tiáº¿p tá»¥c bÃ¹ng ná»• ná»¯a cÃ¹ng vá»›i sá»± phÃ¡t triá»ƒn cá»§a Internet váº¡n váº­t (IoT â€“ Internet of thing), khi mÃ  há»‡ thá»‘ng cÃ¡c thiáº¿t bá»‹ thÃ´ng minh Ä‘Æ°á»£c káº¿t ná»‘i vÃ  tÆ°Æ¡ng tÃ¡c vá»›i nhau cÅ©ng nhÆ° tÆ°Æ¡ng tÃ¡c vá»›i ngÆ°á»i dÃ¹ng, Ä‘á»“ng thá»i thu tháº­p dá»¯ liá»‡u. Dá»± bÃ¡o cÃ³ khoáº£ng 200 tá»· thiáº¿t bá»‹ nhÆ° tháº¿ vÃ o nÄƒm 2020. Giáº£ sá»­ chá»‰ xÃ©t Ä‘áº¿n thiáº¿t bá»‹ tÃ¬m kiáº¿m báº±ng giá»ng nÃ³i, hiá»‡n táº¡i:\nCÃ³ 33 triá»‡u thiáº¿t bá»‹ qua giá»ng nÃ³i Ä‘ang lÆ°u thÃ´ng.\n8 triá»‡u ngÆ°á»i dÃ¹ng Ä‘iá»u khiá»ƒn giá»ng nÃ³i má»—i thÃ¡ng.\nCÃ¡c cÃ¢u lá»‡nh tÃ¬m kiáº¿m báº±ng giá»ng nÃ³i trÃªn Google trong nÄƒm 2016 tÄƒng 35 láº§n so vá»›i nÄƒm 2008.\nTheo thá»‘ng kÃª, hiá»‡n nay cÃ³ hÆ¡n 7 tá»· ngÆ°á»i sá»­ dá»¥ng internet. Trung bÃ¬nh Google xá»­ lÃ½ hÆ¡n 40.000 tÃ¬m kiáº¿m má»—i giÃ¢y (tá»©c khoáº£ng 3.5 tá»· tÃ¬m kiáº¿m má»—i ngÃ y, náº¿u tÃ­nh cáº£ nhá»¯ng cá»• mÃ¡y tÃ¬m kiáº¿m khÃ¡c ngoáº¡i trá»« Google thÃ¬ con sá»‘ nÃ y lÃªn tá»›i 5 tá»· lÆ°á»£t/ngÃ y, 100 tá»· lÆ°á»£t/thÃ¡ng) vÃ  nhá»¯ng con sá»‘ nÃ y sáº½ tiáº¿p tá»¥c tÄƒng lÃªn theo tá»«ng giÃ¢y.\nRáº¥t Ä‘Ã´ng ngÆ°á»i yÃªu thÃ­ch cÃ¡c phÆ°Æ¡ng tiá»‡n truyá»n thÃ´ng xÃ£ há»™i vÃ  dÄ© nhiÃªn viá»‡c sá»­ dá»¥ng chÃºng cÅ©ng sáº½ táº¡o ra dá»¯ liá»‡u. Theo bÃ¡o cÃ¡o Data Never SleÃ©p 5.0 cá»§a Domo, trÃªn cÃ¡c phÆ°Æ¡ng tiá»‡n truyá»n thÃ´ng cá»© má»—i má»™t phÃºt sáº½ cÃ³ (nguá»“n http://www.internetlivestats.com/google-search-statistics/):\n527.760 bá»©c áº£nh Ä‘Æ°á»£c chia sáº» bá»Ÿi ngÆ°á»i sá»­ dá»¥ng Snapchat .\n456.000 tweet Ä‘Æ°á»£c gá»­i lÃªn Twitter.\n46.740 bá»©c áº£nh Ä‘Æ°á»£c Ä‘Äƒng bá»Ÿi ngÆ°á»i dÃ¹ng Instagram.\nHÆ¡n 120 ngÆ°á»i cÃ³ cÃ´ng viá»‡c á»•n Ä‘á»‹nh tham gia LinkedIn.\nVá»›i khoáº£ng 2 tá»· ngÆ°á»i dÃ¹ng, Facebook váº«n lÃ  máº¡ng xÃ£ há»™i lá»›n nháº¥t hÃ nh tinh vÃ  dÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c sá»‘ liá»‡u liÃªn quan Ä‘áº¿n Facebook (nguá»“n http://newsroom.fb.com/company-info/):\nHÆ¡n 900 triá»‡u ngÆ°á»i tháº­t sá»± sá»­ dá»¥ng Facebook má»—i ngÃ y, 82.8% trong sá»‘ Ä‘Ã³ á»Ÿ ngoÃ i Má»¹ vÃ  Canada.\n307 triá»‡u / 2 tá»· lÃ  ngÆ°á»i ChÃ¢u Ã‚u.\nCá»© má»—i giÃ¢y láº¡i cÃ³ 5 tÃ i khoáº£n má»›i Ä‘Æ°á»£c táº¡o ra.\n510.000 bÃ¬nh luáº­n Ä‘Æ°á»£c Ä‘Äƒng táº£i vÃ  293.000 tráº¡ng thÃ¡i Ä‘Æ°á»£c cáº­p nháº­t má»—i phÃºt.\nHÆ¡n 300 triá»‡u bá»©c áº£nh Ä‘Æ°á»£c táº£i lÃªn má»—i ngÃ y.\n15.000 áº£nh GIF Ä‘Æ°á»£c gá»­i thÃ´ng qua Facebook Messenger.\nCÅ©ng thuá»™c sá»Ÿ há»¯u cá»§a Facebook, Instagram cÅ©ng cÃ³ nhá»¯ng con sá»‘ áº¥n tÆ°á»£ng:\n600 triá»‡u ngÆ°á»i dÃ¹ng.\n400 triá»‡u ngÆ°á»i hoáº¡t Ä‘á»™ng má»—i ngÃ y.\n100 triá»‡u ngÆ°á»i sá»­ dá»¥ng tÃ­nh nÄƒng Stories má»—i ngÃ y.\nLiÃªn quan Ä‘áº¿n sá»‘ lÆ°á»£ng ngÆ°á»i dÃ¹ng vÃ  dá»¯ liá»‡u chÃºng ta khÃ´ng thá»ƒ khÃ´ng nháº¯c Ä‘áº¿n Youtube khi mÃ  cá»© má»—i má»™t phÃºt sáº½ cÃ³ khoáº£ng 300 giá» video Ä‘Æ°á»£c Ä‘Äƒng táº£i trÃªn Youtube (nguá»“n https://www.youtube.com/yt/about/press/).\nTrong thá»i Ä‘áº¡i cÃ´ng nghá»‡, viá»‡c thÃ´ng qua cÃ¡c trang web háº¹n hÃ² Ä‘á»ƒ tÃ¬m ná»­a cÃ²n láº¡i khÃ´ng cÃ²n lÃ  Ä‘iá»u xa láº¡. Vá»›i hÆ¡n 20 tá»· lÆ°á»£t káº¿t Ä‘Ã´i, Tinder xá»©ng Ä‘Ã¡ng lÃ  nhá»‹p cáº§u cÃ´ng nghá»‡ thÃ nh cÃ´ng báº­c nháº¥t hiá»‡n táº¡i. Cá»© má»—i phÃºt trÃ´i qua Tinder cÃ³ khoáº£ng 990.000 lÆ°á»£t vuá»‘t vÃ  hÆ¡n 26 triá»‡u lÆ°á»£t háº¹n hÃ² má»—i ngÃ y.\nNgoÃ i viá»‡c liÃªn káº¿t, trao Ä‘á»•i vá»›i nhau qua máº¡ng xÃ£ há»™i, trong cÃ´ng viá»‡c má»i ngÆ°á»i thÆ°á»ng sá»­ dá»¥ng email, skype Ä‘á»ƒ thÆ° tá»«, liÃªn láº¡c. TÃ­nh Ä‘áº¿n nÄƒm 2019 cÃ³ khoáº£ng 9 tá»· ngÆ°á»i sá»­ dá»¥ng email vÃ  dÆ°á»›i Ä‘Ã¢y lÃ  má»™t vÃ i con sá»‘ thá»‘ng kÃª cÃ¡c sá»± kiá»‡n xáº£y ra trong má»™t phÃºt:\nNgÆ°á»i dÃ¹ng gá»­i Ä‘i 16 triá»‡u vÄƒn báº£n.\n156 triá»‡u email Ä‘Æ°á»£c gá»­i Ä‘i vá»›i khoáº£ng 16 triá»‡u vÄƒn báº£n.\n103.447.520 thÆ° rÃ¡c Ä‘Æ°á»£c gá»­i Ä‘i.\n154.200 cuá»™c gá»i Skype.\nKhÃ´ng cÃ²n quÃ¡ khÃ³ khÄƒn trong viá»‡c lÆ°u giá»¯ cÃ¡c khoáº£nh kháº¯c, ngÃ y nay khi mÃ  báº¥t cá»© ai cÅ©ng cÃ³ thá»ƒ sá»Ÿ há»¯u má»™t chiáº¿c Ä‘iá»‡n thoáº¡i thÃ´ng minh (smartphone) vÃ  ai cÅ©ng lÃ  nhiáº¿p áº£nh gia, cá»© nhÆ° tháº¿ cÃ³ hÃ ng nghÃ¬n tá»· bá»©c áº£nh Ä‘Æ°á»£c cho ra Ä‘á»i vÃ  lÆ°u trá»¯ trÃªn Ä‘iá»‡n thoáº¡i.\nThÃ´ng qua nhá»¯ng vÃ­ dá»¥ vá»«a nÃªu cÃ³ thá»ƒ chÃºng ta sáº½ nghÄ© ráº±ng dá»¯ liá»‡u lá»›n thuáº§n tuÃ½ chá»‰ lÃ  váº¥n Ä‘á» vá» kÃ­ch cá»¡, vÃ  náº¿u Ä‘iá»u nÃ y lÃ  Ä‘Ãºng thÃ¬ dá»¯ liá»‡u bao nhiÃªu Ä‘Æ°á»£c cho lÃ  â€œlá»›nâ€?\nÄá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y ta quay láº¡i má»™t chÃºt vá» lá»‹ch sá»­ cá»§a thuáº­t ngá»¯ â€œBig Dataâ€. KhÃ´ng giá»‘ng vá»›i AI vÃ  ML, Big Data khÃ´ng pháº£i lÃ  má»™t ngÃ nh khoa há»c chÃ­nh thá»‘ng mÃ  chá»‰ lÃ  má»™t thuáº­t ngá»¯ truyá»n thÃ´ng má»›i xuáº¥t hiá»‡n trong vÃ i nÄƒm trá»Ÿ láº¡i Ä‘Ã¢y. NÃ³ khÃ´ng khÃ¡c gÃ¬ thuáº­t ngá»¯ â€œká»· nguyÃªn pháº§n má»mâ€ hay â€œcÃ¡ch máº¡ng cÃ´ng nghiá»‡pâ€. Máº·c dÃ¹ thuáº­t ngá»¯ nÃ y má»›i xuáº¥t hiá»‡n nhÆ°ng khá»‘i lÆ°á»£ng dá»¯ liá»‡u tÃ­ch tá»¥ ká»ƒ tá»« khi máº¡ng Internet xuáº¥t hiá»‡n vÃ o cuá»‘i tháº¿ ká»· trÆ°á»›c cÅ©ng khÃ´ng pháº£i lÃ  nhá» tá»« vÃ­ dá»¥ vá» thÆ° viá»‡n Alexandria. Váº­y thÃ¬ cÃ¢u há»i Ä‘áº·t ra lÃ  táº¡i sao vá»›i khá»‘i lÆ°á»£ng khá»•ng lá»“ nhÆ° tháº¿ mÃ  thá»i Ä‘Ã³ váº«n khÃ´ng gá»i lÃ  Big Data? CÃ¢u tráº£ lá»i lÃ  máº·c dÃ¹ Ä‘Æ°á»£c bao quanh bá»Ÿi dá»¯ liá»‡u khá»•ng lá»“ nhÆ°ng á»Ÿ thá»i Ä‘iá»ƒm Ä‘Ã³ con ngÆ°á»i khÃ´ng biáº¿t lÃ m gÃ¬ vá»›i chÃºng ngoÃ i lÆ°u trá»¯ vÃ  sao chÃ©p. Cho Ä‘áº¿n khi cÃ¡c nhÃ  khoa há»c nháº­n ra ráº±ng trong Ä‘á»‘ng dá»¯ liá»‡u nÃ y Ä‘ang áº©n chá»©a má»™t khá»‘i lÆ°á»£ng tri thá»©c khá»•ng lá»“. Nhá»¯ng tri thá»©c áº¥y cÃ³ thá»ƒ giÃºp ta hiá»ƒu thÃªm vá» con ngÆ°á»i vÃ  xÃ£ há»™i. Cháº³ng háº¡n nhÆ° tá»« danh sÃ¡ch cÃ¡c bá»™ phim yÃªu thÃ­ch cá»§a má»™t cÃ¡ nhÃ¢n, chÃºng ta cÃ³ thá»ƒ rÃºt ra Ä‘Æ°á»£c sá»Ÿ thÃ­ch xem phem cá»§a ngÆ°á»i Ä‘Ã³ vÃ  gá»£i Ã½ nhá»¯ng bá»™ phim cÃ¹ng thá»ƒ loáº¡i. Hoáº·c tá»« danh sÃ¡ch tÃ¬m kiáº¿m cá»§a cá»™ng Ä‘á»“ng máº¡ng chÃºng ta sáº½ biáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» nÃ³ng há»•i nháº¥t Ä‘ang Ä‘Æ°á»£c quan tÃ¢m vÃ  sáº½ táº­p trung Ä‘Äƒng táº£i nhiá»u tin tá»©c hÆ¡n vá» váº¥n Ä‘á» Ä‘Ã³, â€¦\nNhÆ° váº­y, bÃ¹ng ná»• thÃ´ng tin khÃ´ng pháº£i lÃ  lÃ½ do duy nháº¥t dáº«n Ä‘áº¿n sá»± ra Ä‘á»i cá»§a cá»¥m tá»« Big Data mÃ  Big Data chá»‰ thá»±c sá»± báº¯t Ä‘áº§u khi chÃºng ta hiá»ƒu Ä‘Æ°á»£c giÃ¡ trá»‹ cá»§a thÃ´ng tin áº©n chá»©a trong dá»¯ liá»‡u vÃ  cÃ³ Ä‘á»§ tÃ i nguyÃªn cÅ©ng nhÆ° cÃ´ng nghá»‡ Ä‘á»ƒ cÃ³ thá»ƒ khai tÃ¡c chÃºng trÃªn quy mÃ´ lá»›n. VÃ  khÃ´ng cÃ³ gÃ¬ ngáº¡c nhiÃªn khi MÃ¡y há»c chÃ­nh lÃ  thÃ nh pháº§n máº¥u chá»‘t cá»§a cÃ´ng nghá»‡ Ä‘Ã³.\nMÃ¡y há»c vÃ  má»‘i quan há»‡ vá»›i TrÃ­ tuá»‡ nhÃ¢n táº¡o cÃ¹ng Dá»¯ liá»‡u lá»›n Äá»ƒ mÃ¡y tÃ­nh cÃ³ kháº£ nÄƒng suy nghÄ© vÃ  trÃ­ tuá»‡ nhÆ° con ngÆ°á»i thÃ¬ Ä‘Ã²i há»i mÃ¡y tÃ­nh pháº£i cÃ³ kháº£ nÄƒng â€œhá»câ€ mÃ  khÃ´ng cáº§n pháº£i láº­p trÃ¬nh Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ cá»¥ thá»ƒ Ä‘Ã³. Vá» phÃ­a cÃ¡c nhÃ  nghiÃªn cá»©u AI, há» muá»‘n xem thá»­ liá»‡u mÃ¡y tÃ­nh cÃ³ thá»ƒ há»c dá»¯ liá»‡u nhÆ° tháº¿ nÃ o? Tá»« Ä‘Ã³ thuáº­t ngá»¯ MÃ¡y há»c hay Há»c mÃ¡y (ML â€“ Machine Learning) Ä‘Æ°á»£c hÃ¬nh thÃ nh. Máº·c dÃ¹ khÃ´ng cÃ³ nhiá»u Ä‘á»‹nh nghÄ©a nhÆ° AI nhÆ°ng ML láº¡i cÃ³ 2 Ä‘á»‹nh nghÄ©a khÃ¡ tÆ°á»ng minh nhÆ° sau:\nMÃ¡y há»c lÃ  ngÃ nh há»c cung cáº¥p cho mÃ¡y tÃ­nh kháº£ nÄƒng há»c há»i mÃ  khÃ´ng cáº§n Ä‘Æ°á»£c láº­p trÃ¬nh má»™t cÃ¡ch rÃµ rÃ ng (Arthur Samuel, 1959).\nTheo GiÃ¡o sÆ° Tom Mitchell â€“ Carnegie Mellon University: MÃ¡y há»c lÃ  1 chÆ°Æ¡ng trÃ¬nh mÃ¡y tÃ­nh Ä‘Æ°á»£c nÃ³i lÃ  há»c há»i tá»« kinh nghiá»‡m E tá»« cÃ¡c tÃ¡c vá»¥ T vÃ  vá»›i Ä‘á»™ Ä‘o hiá»‡u suáº¥t P náº¿u hiá»‡u suáº¥t cá»§a nÃ³ Ã¡p dá»¥ng trÃªn tÃ¡c vá»¥ T vÃ  Ä‘Æ°á»£c Ä‘o lÆ°á»ng bá»Ÿi Ä‘á»™ Ä‘o P tÄƒng tá»« kinh nghiá»‡m E.\nMá»™t vÃ i vÃ­ dá»¥ minh hoáº¡ cho Ä‘á»‹nh nghÄ©a cá»§a Tom Mitchell:\nâ€¢\tVÃ­ dá»¥ 1: Giáº£ sá»­ nhÆ° ta muá»‘n mÃ¡y tÃ­nh xÃ¡c Ä‘á»‹nh má»™t tin nháº¯n cÃ³ pháº£i lÃ  SPAM hay khÃ´ng thÃ¬:\nTÃ¡c vá»¥ T: XÃ¡c Ä‘á»‹nh 1 tin nháº¯n cÃ³ pháº£i SPAM hay khÃ´ng?\nKinh nghiá»‡m E: Xem láº¡i nhá»¯ng tin nháº¯n Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u lÃ  SPAM xem cÃ³ nhá»¯ng Ä‘áº·c tÃ­nh gÃ¬ Ä‘á»ƒ cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh nÃ³ lÃ  SPAM.\nÄá»™ Ä‘o P: LÃ  pháº§n trÄƒm sá»‘ tin nháº¯n SPAM Ä‘Æ°á»£c phÃ¢n loáº¡i Ä‘Ãºng.\nâ€¢\tVÃ­ dá»¥ 2: ChÆ°Æ¡ng trÃ¬nh nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay (bao gá»“m cÃ¡c chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9)\nTÃ¡c vá»¥ T: nháº­n dáº¡ng Ä‘Æ°á»£c áº£nh chá»©a kÃ½ tá»± sá»‘.\nKinh nghiá»‡m E: Äáº·c trÆ°ng Ä‘á»ƒ phÃ¢n loáº¡i kÃ½ tá»± sá»‘ tá»« táº­p dá»¯ liá»‡u sá»‘ cho trÆ°á»›c.\nÄá»™ Ä‘o P: Äá»™ chÃ­nh xÃ¡c cá»§a quÃ¡ trÃ¬nh nháº­n dáº¡ng.\nMá»‘i quan há»‡ giá»¯a ML vá»›i AI vÃ  Big Data Trong pháº§n 1 vÃ  pháº§n 2 chÃºng ta luÃ´n tháº¥y sá»± xuáº¥t hiá»‡n cá»§a ML, Ä‘Ã¢y lÃ  lÃ½ do vÃ¬ sao mÃ¬nh khÃ´ng tÃ¡ch riÃªng má»‘i quan há»‡ giá»¯a cÃ¡c khÃ¡i niá»‡m nÃ y ra má»™t pháº§n riÃªng mÃ  Ä‘á»ƒ chung trong ná»™i dung cá»§a ML. Váº­y thÃ¬ má»‘i liÃªn há»‡ Ä‘Ã³ lÃ  gÃ¬?\nMá»™t cÃ¡ch hÃ n lÃ¢m thÃ¬ AI lÃ  ngÃ nh khoa há»c Ä‘Æ°á»£c sinh ra vá»›i má»¥c tiÃªu lÃ  lÃ m cho mÃ¡y tÃ­nh cÃ³ Ä‘Æ°á»£c trÃ­ thÃ´ng minh nhÆ° con ngÆ°á»i. Má»¥c tiÃªu nÃ y váº«n khÃ¡ mÆ¡ há»“ vÃ¬ khÃ´ng pháº£i ai cÅ©ng Ä‘á»“ng Ã½ vá»›i má»™t Ä‘á»‹nh nghÄ©a thá»‘ng nháº¥t vá» trÃ­ thÃ´ng minh. CÃ¡c nhÃ  khoa há»c pháº£i Ä‘á»‹nh nghÄ©a má»™t sá»‘ má»¥c tiÃªu cá»¥ thá»ƒ hÆ¡n, má»™t trong sá»‘ Ä‘Ã³ lÃ  viá»‡c lÃ m cho mÃ¡y tÃ­nh lá»«a Ä‘Æ°á»£c Turing Test. Turing Test Ä‘Æ°á»£c táº¡o ra bá»Ÿi Alan Turing (1912 â€“ 1954), ngÆ°á»i Ä‘Æ°á»£c xem lÃ  cha Ä‘á»ƒ cá»§a ngÃ nh khoa há»c mÃ¡y tÃ­nh hiá»‡n Ä‘áº¡i, nháº±m phÃ¢n biá»‡t xem ngÆ°á»i Ä‘á»‘i diá»‡n cÃ³ pháº£ lÃ  ngÆ°á»i hay khÃ´ng.\nNhÆ° váº­y, AI thá»ƒ hiá»‡n má»™t cá»§a má»¥c tiÃªu con ngÆ°á»i, trong khi ML lÃ  má»™t phÆ°Æ¡ng tiá»‡n Ä‘Æ°á»£c ká»³ vá»ng sáº½ giÃºp con ngÆ°á»i Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu Ä‘Ã³. VÃ  trÃªn thá»±c táº¿ thÃ¬ ML Ä‘Ã£ mang nhÃ¢n loáº¡i Ä‘i ráº¥t xa trÃªn quÃ£ng Ä‘Æ°á»ng chinh phá»¥c AI. DÃ¹ cÃ³ má»‘i quan há»‡ cháº·c cháº½ vá»›i nhau nhÆ°ng chÃºng khÃ´ng háº³n lÃ  trÃ¹ng khá»›p vÃ¬ mÃ´t bÃªn lÃ  má»¥c tiÃªu (AI), má»™t bÃªn lÃ  phÆ°Æ¡ng tiá»‡n (ML). Chinh phá»¥c AI máº·c dÃ¹ váº«n lÃ  má»¥c Ä‘Ã­ch tá»‘i thÆ°á»£ng cá»§a ML, nhÆ°ng hiá»‡n táº¡i ML táº­p trung vÃ o nhá»¯ng má»¥c tiÃªu ngáº¯n háº¡n hÆ¡n nhÆ° lÃ m cho mÃ¡y tÃ­nh cÃ³ kháº£ nÄƒng nháº­n thá»©c cÆ¡ báº£n cá»§a con ngÆ°á»i nhÆ° nghe, nhÃ¬n, hiá»ƒu Ä‘Æ°á»£c ngÃ´n ngá»¯, giáº£i toÃ¡n, láº­p trÃ¬nh, â€¦, cÃ¡c kháº£ nÄƒng nÃ y á»©ng vá»›i cÃ¡c lÄ©nh vá»±c cá»¥ thá»ƒ trong AI nhÆ°:\nThá»‹ giÃ¡c mÃ¡y tÃ­nh (computer vision): má»¥c tiÃªu cá»§a lÄ©nh vá»±c nÃ y lÃ  lÃ m cho mÃ¡y tÃ­nh cÃ³ thá»ƒ nhÃ¬n nhÆ° con ngÆ°á»i. Nhá»¯ng á»©ng dá»¥ng quan trá»ng cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n trong lÄ©nh vá»±c nÃ y nhÆ° lÃ  nháº­n dáº¡ng chá»¯/ chá»© sá»‘ viáº¿t tay, nháº­n dáº¡ng khuÃ´n máº·t, dÃ¡ng Ä‘i, cá»­ chá»‰, phÃ¢n loáº¡i loÃ i hoa, nhÃ£n hiá»‡u, phÃ¡t hiá»‡n Ä‘á»“ vÃ¢t, â€¦. Tá»« táº­p hÃ¬nh áº£nh ban Ä‘áº§u, cÃ¡c thuáº­t toÃ¡n ML sáº½ tiáº¿n hÃ nh xá»­ lÃ½, phÃ¢n tÃ­ch Ä‘á»ƒ rÃºt ra cÃ¡c Ä‘áº·c trÆ°ng chÃ­nh giÃºp nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng hoáº·c phÃ¢n biá»‡t cÃ¡c Ä‘á»‘i tÆ°á»£ng vá»›i nhau.\nXá»­ lÃ½ NgÃ´n ngá»¯ tá»± nhiÃªn (Natural Language Processing â€“ NLP): Má»¥c tiÃªu lÃ  giÃºp cho mÃ¡y tÃ­nh cÃ³ thá»ƒ hiá»ƒu nhÆ° con ngÆ°á»i. Dá»‹ch mÃ¡y lÃ  má»™t trong nhá»¯ng á»©ng dá»¥ng Ä‘iá»ƒn hÃ¬nh cá»§a NLP, dá»‹ch ná»™i dung cá»§a má»™t Ä‘oáº¡n vÄƒn báº£n tá»« ngÃ´n ngá»¯ nÃ y sang ngÃ´n ngá»¯ khÃ¡c (Google Translate). Xuáº¥t phÃ¡t tá»« â€œTá»« Ä‘iá»ƒnâ€ hoáº·c táº­p cÃ¡c cáº·p cÃ¢u song ngá»¯, táº­p luáº­t ngá»¯ phÃ¡p cá»§a má»—i ngÃ´n ngá»¯ Ä‘Æ°á»£c táº¡o bá»Ÿi ngÆ°á»i cÃ³ chuyÃªn mÃ´n vá» nhá»¯ng ngÃ´n ngá»¯ Ä‘Ã³, cÃ¡c thuáº­t toÃ¡n mÃ¡y há»c sáº½ tiáº¿n hÃ nh phÃ¢n tÃ­ch Ä‘á»ƒ tÃ¡ch cÃ¢u, tÃ¡ch tá»«, xÃ¡c Ä‘á»‹nh tá»« loáº¡i, phÃ¢n tÃ­ch cÃº phÃ¡p Ä‘á»ƒ tá»« Ä‘Ã³ láº¥y ra ngá»¯ nghÄ©a phÃ¹ há»£p rá»“i ghÃ©p láº¡i vá»›i nhau vÃ  cho ra ná»™i dung á»Ÿ ngÃ´n ngá»¯ tÆ°Æ¡ng á»©ng. NgoÃ i ra, tÃ³m táº¯t vÄƒn báº£n dá»±a vÃ o cÃ¡c tá»« khoÃ¡ cá»§a tá»«ng lÄ©nh vá»±c cÅ©ng lÃ  má»™t bÃ i toÃ¡n ML ráº¥t Ä‘Æ°á»£c quan tÃ¢m trong vÃ i nÄƒm trá»Ÿ láº¡i Ä‘Ã¢y, khi mÃ  má»—i ngÃ y lÆ°á»£ng tin tá»©c cáº§n pháº£i Ä‘á»c lÃ  quÃ¡ nhiá»u.\nXá»­ lÃ½ tiáº¿ng nÃ³i (Speech Language Processing): nháº±m lÃ m cho mÃ¡y tÃ­nh cÃ³ thá»ƒ nghe Ä‘Æ°á»£c nhÆ° ngÆ°á»i. Tá»•ng há»™p tiáº¿ng nÃ³i (text to speech) Ä‘á»ƒ Ä‘á»c sÃ¡ch cho ngÆ°á»i khiáº¿m thá»‹, táº¡o sub cho cÃ¡c video (speech to text) Ä‘á»ƒ há»— trá»£ cho ngÆ°á»i khiáº¿m thÃ­nh hoáº·c há»— trá»£ cho viá»‡c há»c ngÃ´n ngá»¯; nháº­n dáº¡ng giá»ng nÃ³i (speech recognition) giÃºp phÃ¡t hiá»‡n tá»™i pháº¡m lÃ  má»™t sá»‘ á»©ng dá»¥ng Ä‘iá»ƒn hÃ¬nh trong lÄ©nh vá»±c nÃ y.\nThay vÃ¬ cá»‘ gáº¯ng â€œdáº¡yâ€ mÃ¡y tÃ­nh cÃ¡ch lÃ m má»™t viá»‡c gÃ¬ Ä‘Ã³, cháº³ng háº¡n nhÆ° lÃ¡i xe hÆ¡i, Ä‘iá»u mÃ  cÃ¡c chuyÃªn gia AI cáº§n lÃ m lÃ  cung cáº¥p â€œÄ‘á»§â€ dá»¯ liá»‡u cho má»™t mÃ¡y tÃ­nh Ä‘á»ƒ nÃ³ cÃ³ thá»ƒ tÃ­nh ra xÃ¡c suáº¥t cá»§a táº¥t cáº£ má»i thá»© mÃ  ngÆ°á»i ta muá»‘n tÃ­nh toÃ¡n, vÃ­ nhÆ° xÃ¡c suáº¥t ngÆ°á»i Ä‘i Ä‘Æ°á»ng gáº·p Ä‘Ã¨n giao thÃ´ng mÃ u xanh, mÃ u Ä‘á», mÃ u vÃ ng, â€¦ thÃ¬ chuáº©n xÃ¡c hÆ¡n.\nDo Ä‘Ã³, nhiá»‡m vá»¥ thá»±c sá»± cá»§a ML trong AI lÃ  â€œhá»câ€ mÃ  thá»±c cháº¥t cá»§a viá»‡c há»c nÃ y lÃ  rÃºt trÃ­ch thÃ´ng tin há»¯u Ã­ch cho tá»«ng bÃ i toÃ¡n trong â€œtáº­p dá»¯ liá»‡uâ€ cho trÆ°á»›c. LÃºc nÃ y má»‘i quan há»‡ giá»¯a ML vÃ  Big Data sáº½ Ä‘Æ°á»£c bá»™c lá»™, Ä‘Ã³ lÃ  náº¿u khá»‘i lÆ°á»£ng dá»¯ liá»‡u cá»§a Big Data cÃ ng gia tÄƒng thÃ¬ ML sáº½ phÃ¡t triá»ƒn hÆ¡n, cÃ³ kháº£ nÄƒng rÃºt trÃ­ch Ä‘Æ°á»£c nhiá»u thÃ´ng tin giÃ¡ trá»‹ hÆ¡n hay dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c hÆ¡n, ngÆ°á»£c láº¡i thÃ¬ giÃ¡ trá»‹ cá»§a Big Data phá»¥ thuá»™c vÃ o kháº£ nÄƒng khai thÃ¡c tri thá»©c tá»« dá»¯ liá»‡u cá»§a ML, vÃ¬ nÃ³ sáº½ thá»±c sá»± lÃ  Big Data khi khá»‘i lÆ°á»£ng dá»¯ liá»‡u Ä‘Ã³ mang láº¡i thÃ´ng tin há»¯u Ã­ch.\nViá»‡c sá»­ dá»¥ng nhá»¯ng khá»‘i lÆ°á»£ng thÃ´ng tin theo cÃ¡ch nÃ y Ä‘Ã²i há»i chÃºng ta pháº£i cÃ³ sá»± thay Ä‘á»•i trong cÃ¡ch tiáº¿p cáº­n dá»¯ liá»‡u. Má»™t lÃ  thu tháº­p vÃ  sá»­ dá»¥ng tháº­t nhiá»u dá»¯ liá»‡u thay vÃ¬ cháº¥p nháº­n láº¥y nhá»¯ng máº«u thá»‘ng kÃª vá»›i sá»‘ lÆ°á»£ng nhá» nhÆ° cÃ¡c nhÃ  thá»‘ng kÃª váº«n lÃ m tá»« hÆ¡n má»™t tháº¿ ká»· nay. Hai lÃ  khÃ´ng nháº¥t thiáº¿t pháº£i kÃ©n chá»n sÃ ng lá»c ra dá»¯ liá»‡u sáº¡ch, vÃ¬ kinh nghiá»‡m thá»±c tiá»…n cho tháº¥y ráº±ng má»™t chÃºt sai lá»‡ch trong thÃ´ng tin váº«n cÃ³ thá»ƒ cháº¥p nháº­n Ä‘Æ°á»£c, vÃ  viá»‡c sá»­ dá»¥ng má»™t lÆ°á»£ng khá»•ng lá»“ nhá»¯ng dá»¯ liá»‡u Ã´ há»£p Ä‘em láº¡i nhiá»u Ã­ch lá»£i hÆ¡n lÃ  dá»¯ liá»‡u tuy chÃ­nh xÃ¡c nhÆ°ng dung lÆ°á»£ng quÃ¡ Ã­t. Ba lÃ  trong nhiá»u trÆ°á»ng há»£p, chÃºng ta khÃ´ng nháº¥t thiáº¿t pháº£i cá»‘ tÃ¬m ra nguyÃªn nhÃ¢n Ä‘áº±ng sau cÃ¡c hiá»‡n tÆ°á»£ng.VÃ­ dá»¥, khÃ´ng cáº§n pháº£i cá»‘ tÃ¬m hiá»ƒu chÃ­nh xÃ¡c vÃ¬ sao má»™t cá»— mÃ¡y bá»‹ há»ng, thay vÃ o Ä‘Ã³ cÃ¡c nhÃ  nghiÃªn cá»©u cÃ³ thá»ƒ thu tháº­p vÃ  phÃ¢n tÃ­ch tháº­t nhiá»u dá»¯ liá»‡u vá» chÃºng cÃ¹ng táº¥t cáº£ má»i thá»© liÃªn quan, tá»« Ä‘Ã³ rÃºt ra quy luáº­t lÃ m cÆ¡ sá»Ÿ dá»± Ä‘oÃ¡n cÃ¡c sá»± váº­t, sá»± viá»‡c trong tÆ°Æ¡ng lai.\nDÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ tÃ i liá»‡u mÃ¬nh Ä‘Ã£ sá»­ dá»¥ng Ä‘á»ƒ tham kháº£o trong qua trÃ¬nh viáº¿t bÃ i:\nIntroduction to Machine Learning of Alex Smola and S.V.N. Vishwanathan.\nArtificial Intelligence (third edition) of The McGraw-Hill Companies, write by Elaine Rich, Kevin Knight and Shivashankar B Nair.\nhttps://i4iam.files.wordpress.com/2013/08/artificial-intelligence-by-rich-and-knight.pdf\nhttps://en.wikipedia.org/wiki/Artificial_intelligence\nhttps://searchenterpriseai.techtarget.com/definition/AI-Artificial-Intelligence\nhttp://vienthongke.vn/tin-tuc/43-tin-tuc/2176-thoi-dai-cua-du-lieu-lon-big-data\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ nhá»¯ng bÃ i viáº¿t tiáº¿p theo.\n","date":"Apr 2, 2019","img":"","permalink":"/blog/2019-04-02-deep-learning-view/","series":null,"tags":["machine learning","deep learning"],"title":"TrÃ­ Tuá»‡ NhÃ¢n Táº¡o, MÃ¡y Há»c, Dá»¯ Liá»‡u Lá»›n"},{"categories":null,"content":" Báº¯t Ä‘áº§u Visualize dá»¯ liá»‡u Bounding Boxes Resize Images Mini Masks Anchors Prediction Báº¯t Ä‘áº§u Äáº§u tiÃªn, chÃºng ta sáº½ download táº­p dataset balloon táº¡i https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip, giáº£i nÃ©n vÃ  bá» trong thÆ° má»¥c datasets. Tiáº¿p Ä‘Ã³, cÃ¡c báº¡n donwload file balloon.py vÃ  visualize.py vá». File Ä‘áº§u tiÃªn há»— trá»£ chÃºng ta Ä‘á»c dá»¯ liá»‡u cá»§a dataset balloon vÃ  file thá»© hai há»— trá»£ visualize hÃ¬nh áº£nh má»™t cÃ¡ch trá»±c quan. Cáº£ hai file mÃ¬nh Ä‘á»u láº¥y mÃ£ nguá»“n cá»§a Matterport trÃªn https://github.com/matterport/Mask_RCNN/ Tiáº¿n hÃ nh import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t vá».\n1import os 2import sys 3import itertools 4import math 5import logging 6import json 7import re 8import random 9from collections import OrderedDict 10import numpy as np 11import matplotlib 12import matplotlib.pyplot as plt 13import matplotlib.patches as patches 14import matplotlib.lines as lines 15from matplotlib.patches import Polygon 16 17 18import balloon 19import utils 20import visualize 21 22config = balloon.BalloonConfig() 23BALLOON_DIR = \u0026#34;datasets/balloon\u0026#34; ThÃ´ng tin cá»§a táº­p train bao gá»“m\n1dataset = balloon.BalloonDataset() 2dataset.load_balloon(BALLOON_DIR, \u0026#34;train\u0026#34;) 3 4# Must call before using the dataset 5dataset.prepare() 6 7print(\u0026#34;Image Count: {}\u0026#34;.format(len(dataset.image_ids))) 8print(\u0026#34;Class Count: {}\u0026#34;.format(dataset.num_classes)) 9for i, info in enumerate(dataset.class_info): 10 print(\u0026#34;{:3}. {:50}\u0026#34;.format(i, info[\u0026#39;name\u0026#39;])) 1Image Count: 61 2Class Count: 2 3 0. BG 4 1. balloon Váº­y lÃ  cÃ³ tá»•ng cá»™ng 61 hÃ¬nh train. Dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘Ã¡nh lÃ m 2 nhÃ£n, má»™t nhÃ£n lÃ  background, má»™t nhÃ£n lÃ  balloon.\nVisualize dá»¯ liá»‡u ChÃºng ta sáº½ load má»™t vÃ i hÃ¬nh lÃªn xem ngÆ°á»i ta Ä‘Ã£ mask dá»¯ liá»‡u nhÆ° tháº¿ nÃ o. á» Ä‘Ã¢y, vá»›i má»—i hÃ¬nh áº£nh, mÃ¬nh sáº½ load 1 hÃ¬nh gá»‘c vÃ  4 hÃ¬nh cá»§a 4 quáº£ bÃ³ng tÆ°Æ¡ng á»©ng trong hÃ¬nh, náº¿u trong hÃ¬nh cÃ³ nhiá»u hÆ¡n 4 quáº£ bÃ³ng thÃ¬ chá»‰ váº½ 4 quáº£ bÃ³ng Ä‘áº§u tiÃªn\n1 2 3n_col = 5 4 5# Load and display random samples 6fig, axs = plt.subplots(nrows=4, ncols=n_col, figsize=(9.3, 6),subplot_kw={\u0026#39;xticks\u0026#39;: [], \u0026#39;yticks\u0026#39;: []}) 7fig.subplots_adjust(left=0.03, right=0.97, hspace=0.3, wspace=0.05) 8image_ids = np.random.choice(dataset.image_ids, 4) 9# for image_id in image_ids: 10# for ax, image_id in zip(axs.flat, image_ids): 11 12for index in range(0,4): 13 image_id = image_ids[index] 14 15 image = dataset.load_image(image_id) 16 mask, class_ids = dataset.load_mask(image_id) 17 print(mask.shape) 18 print(len(class_ids)) 19 20 axs.flat[index*n_col].imshow(image) 21 axs.flat[index*n_col].set_title(\u0026#39;img\u0026#39;) 22 23 for sub_index in range(0,len(class_ids)): 24 if sub_index \u0026gt;= n_col: 25 break 26 axs.flat[index*n_col +1 + sub_index].imshow(mask[:,:,sub_index]) 27 axs.flat[index*n_col + 1+sub_index].set_title(str(dataset.class_names[class_ids[sub_index]])) 28 29 30plt.tight_layout() 31plt.show() CÃ¡c báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng hÃ m display_top_masks cá»§a tÃ¡c giáº£ Mask R-CNN Ä‘á»ƒ xem thá»­, hÃ m cá»§a há» hÆ¡i khÃ¡c cá»§a mÃ¬nh má»™t chÃºt.\n1 2image_ids = np.random.choice(dataset.image_ids, 4) 3for image_id in image_ids: 4 image = dataset.load_image(image_id) 5 mask, class_ids = dataset.load_mask(image_id) 6 visualize.display_top_masks(image, mask, class_ids, dataset.class_names) Bounding Boxes ChÃºng ta cÃ³ 2 cÃ¡ch Ä‘á»ƒ láº¥y Bounding Boxes cá»§a cÃ¡c hÃ¬nh. Má»™t lÃ  láº¥y trá»±c tiáº¿p tá»« táº­p dataset (Ä‘á»‘i vá»›i nhá»¯ng dataset cÃ³ lÆ°u bounding box), hai lÃ  rÃºt trÃ­ch bounding box tá»« cÃ¡c toáº¡ Ä‘á»™ mask. ChÃºng ta nÃªn thá»±c hiá»‡n cÃ¡ch hai, lÃ½ do lÃ  chÃºng ta sáº½ dÃ¹ng cÃ¡c ká»¹ thuáº­t Data Generator Ä‘á»ƒ sinh nhiá»u áº£nh hÆ¡n cung cáº¥p cho thuáº­t toÃ¡n train. LÃºc nÃ y, viá»‡c tÃ­nh láº¡i bounding box sáº½ dá»… dÃ ng hÆ¡n.\n1 2# Load random image and mask. 3image_id = random.choice(dataset.image_ids) 4image = dataset.load_image(image_id) 5mask, class_ids = dataset.load_mask(image_id) 6 7# Compute Bounding box 8bbox = utils.extract_bboxes(mask) 9 10# Display image and additional stats 11print(\u0026#34;image_id \u0026#34;, image_id, dataset.image_reference(image_id)) 12 13# Display image and instances 14visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names) Resize Images CÃ¡c áº£nh trong táº­p train cÃ³ cÃ¡c kÃ­ch thÆ°á»›c khÃ¡c nhau. CÃ¡c báº¡n cÃ³ thá»ƒ xem cÃ¡c hÃ¬nh á»Ÿ trÃªn, cÃ³ áº£nh cÃ³ kÃ­ch thÆ°á»›c nÃ y, cÃ³ áº£nh cÃ³ kÃ­ch thÆ°á»›c kia. ChÃºng ta sáº½ resize chÃºng vá» cÃ¹ng má»™t kÃ­ch thÆ°á»›c (vÃ­ dá»¥ 1024x1024) Ä‘á»ƒ lÃ m Ä‘áº§u vÃ o cho táº­p huáº¥n luyá»‡n. VÃ  chÃºng ta sáº½ sá»­ dá»¥ng zero padding Ä‘á»ƒ láº¥p Ä‘áº§y nhá»¯ng khoáº£ng trá»‘ng cá»§a nhá»¯ng áº£nh khÃ´ng Ä‘á»§ kÃ­ch thÆ°á»›c.\n1 2 3 4# Load random image and mask. 5image_id = np.random.choice(dataset.image_ids, 1)[0] 6image = dataset.load_image(image_id) 7mask, class_ids = dataset.load_mask(image_id) 8original_shape = image.shape 9# Resize 10image, window, scale, padding, _ = utils.resize_image( 11 image, 12 min_dim=config.IMAGE_MIN_DIM, 13 max_dim=config.IMAGE_MAX_DIM, 14 mode=config.IMAGE_RESIZE_MODE) 15mask = utils.resize_mask(mask, scale, padding) 16# Compute Bounding box 17bbox = utils.extract_bboxes(mask) 18 19# Display image and additional stats 20print(\u0026#34;image_id: \u0026#34;, image_id, dataset.image_reference(image_id)) 21print(\u0026#34;Original shape: \u0026#34;, original_shape) 22print(\u0026#34;Resize shape: \u0026#34;, image.shape) 23# Display image and instances 24visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names) Káº¿t quáº£\n1image_id: 9 datasets/balloon\\train\\15290896925_884ab33fd3_k.jpg 2Original shape: (1356, 2048, 3) 3Resize shape: (1024, 1024, 3) LÆ°u Ã½ má»™t Ä‘iá»u lÃ  á»Ÿ Ä‘Ã¢y, mÃ¬nh sá»­ dá»¥ng random image, nÃªn náº¿u cÃ¡c báº¡n cháº¡y láº¡i cÃ¢u lá»‡nh nhÆ° mÃ¬nh thÃ¬ káº¿t quáº£ ra pháº§n nhiá»u sáº½ khÃ¡c mÃ¬nh. Tuy nhiÃªn, Resize shape luÃ´n lÃ  (1024, 1024, 3).\nMini Masks Má»™t váº¥n Ä‘á» khÃ¡ nghiÃªm trá»ng á»Ÿ Ä‘Ã¢y lÃ  chÃºng ta cáº§n khÃ¡ nhiá»u bá»™ nhá»› Ä‘á»ƒ lÆ°u cÃ¡c masks. Numpy sá»­ dá»¥ng 1 byte Ä‘á»ƒ lÆ°u 1 giÃ¡ trá»‹ bit. Do Ä‘Ã³, vá»›i kÃ­ch thÆ°á»›c áº£nh lÃ  1024x1024, chÃºng ta cáº§n 1MB bá»™ nhá»› ram Ä‘á»ƒ lÆ°u trá»¯. Náº¿u chÃºng ta cÃ³ táº­p dataset táº§m 1000 bá»©c áº£nh thÃ¬ cáº§n Ä‘áº¿n 1GB bá»™ nhá»›, khÃ¡ lÃ  lá»›n. NgoÃ i viá»‡c tá»‘n bá»™ nhá»› lá»¯u trá»¯, chÃºng cÃ²n lÃ m cháº­m tá»‘c Ä‘á»™ huáº¥n luyá»‡n mÃ´ hÃ¬nh ná»¯a.\nÄá»ƒ cáº£i tiáº¿n, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng má»™t trong hai cÃ¡ch sau:\nCÃ¡ch thá»© nháº¥t: Thay vÃ¬ lÆ°u toÃ n bá»™ mask cá»§a toÃ n bá»©c áº£nh, chÃºng ta chá»‰ lÆ°u nhá»¯ng pixel cá»§a mask trong bounding box. Vá»›i viá»‡c sá»­ dá»¥ng cÃ¡ch nÃ y, chÃºng ta sáº½ tiáº¿t kiá»‡m kha khÃ¡ bá»™ nhá»› chÃ­nh. CÃ¡ch thá»© hai: ChÃºng ta cÃ³ thá»ƒ resize mask vá» má»™t kÃ­ch thÆ°á»›c chuáº©n nÃ o Ä‘Ã³, vÃ­ dá»¥ 48x48 pixel. Vá»›i nhá»¯ng mask cÃ³ kÃ­ch thÆ°á»›c lá»›n hÆ¡n 48x48, chÃºng sáº½ bá»‹ máº¥t thÃ´ng tin. MÃ¬nh khÃ´ng thÃ­ch cÃ¡ch thá»© hai cho láº¯m. Tuy nhiÃªn, theo lÃ½ giáº£i cá»§a nhÃ³m tÃ¡c giáº£ Mask R-CNN, thÃ¬ háº§u háº¿t viá»‡c gÃ¡n cÃ¡c Ä‘Æ°á»ng biÃªn (object annotations) thÆ°á»ng khÃ´ng chÃ­nh xÃ¡c cho láº¯m (thá»«a hoáº·c thiáº¿u má»™t vÃ i chá»—), cho nÃªn, viá»‡c máº¥t mÃ¡t thÃ´ng tin vá»›i lÆ°á»£ng nhá» nÃ y háº§u nhÆ° lÃ  khÃ´ng Ä‘Ã¡ng ká»ƒ.\nÄá»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a hÃ m mask resizing, chÃºng ta sáº½ cháº¡y Ä‘oáº¡n code bÃªn dÆ°á»›i vÃ  xem áº£nh káº¿t quáº£. Äoáº¡n code trÃªn mÃ¬nh sá»­ dá»¥ng 2 hÃ m compose_image_meta vÃ  load_image_gt cá»§a tÃ¡c giáº£ á»Ÿ Ä‘Æ°á»ng dáº«n https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/model.py. MÃ¬nh cÃ³ modify láº¡i hÃ m load_image_gt má»™t chÃºt Ä‘á»ƒ há»£p vá»›i Ã½ mÃ¬nh hÆ¡n.\n1############################## 2# Data Formatting 3############################## 4 5def compose_image_meta(image_id, original_image_shape, image_shape, 6 window, scale, active_class_ids): 7 \u0026#34;\u0026#34;\u0026#34;Takes attributes of an image and puts them in one 1D array. 8 image_id: An int ID of the image. Useful for debugging. 9 original_image_shape: [H, W, C] before resizing or padding. 10 image_shape: [H, W, C] after resizing and padding 11 window: (y1, x1, y2, x2) in pixels. The area of the image where the real 12 image is (excluding the padding) 13 scale: The scaling factor applied to the original image (float32) 14 active_class_ids: List of class_ids available in the dataset from which 15 the image came. Useful if training on images from multiple datasets 16 where not all classes are present in all datasets. 17 \u0026#34;\u0026#34;\u0026#34; 18 meta = np.array( 19 [image_id] + # size=1 20 list(original_image_shape) + # size=3 21 list(image_shape) + # size=3 22 list(window) + # size=4 (y1, x1, y2, x2) in image cooredinates 23 [scale] + # size=1 24 list(active_class_ids) # size=num_classes 25 ) 26 return meta 27 28 29def load_image_gt(dataset, config, image_id, augment=False, augmentation=None, 30 use_mini_mask=False): 31 \u0026#34;\u0026#34;\u0026#34;Load and return ground truth data for an image (image, mask, bounding boxes). 32 augment: (deprecated. Use augmentation instead). If true, apply random 33 image augmentation. Currently, only horizontal flipping is offered. 34 augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation. 35 For example, passing imgaug.augmenters.Fliplr(0.5) flips images 36 right/left 50% of the time. 37 use_mini_mask: If False, returns full-size masks that are the same height 38 and width as the original image. These can be big, for example 39 1024x1024x100 (for 100 instances). Mini masks are smaller, typically, 40 224x224 and are generated by extracting the bounding box of the 41 object and resizing it to MINI_MASK_SHAPE. 42 Returns: 43 image: [height, width, 3] 44 shape: the original shape of the image before resizing and cropping. 45 class_ids: [instance_count] Integer class IDs 46 bbox: [instance_count, (y1, x1, y2, x2)] 47 mask: [height, width, instance_count]. The height and width are those 48 of the image unless use_mini_mask is True, in which case they are 49 defined in MINI_MASK_SHAPE. 50 \u0026#34;\u0026#34;\u0026#34; 51 # Load image and mask 52 image = dataset.load_image(image_id) 53 mask, class_ids = dataset.load_mask(image_id) 54 original_shape = image.shape 55 image, window, scale, padding, crop = utils.resize_image( 56 image, 57 min_dim=config.IMAGE_MIN_DIM, 58 min_scale=config.IMAGE_MIN_SCALE, 59 max_dim=config.IMAGE_MAX_DIM, 60 mode=config.IMAGE_RESIZE_MODE) 61 mask = utils.resize_mask(mask, scale, padding, crop) 62 63 # Random horizontal flips. 64 # TODO: will be removed in a future update in favor of augmentation 65 if augment: 66 logging.warning(\u0026#34;\u0026#39;augment\u0026#39; is deprecated. Use \u0026#39;augmentation\u0026#39; instead.\u0026#34;) 67 if random.randint(0, 1): 68 image = np.fliplr(image) 69 mask = np.fliplr(mask) 70 71 # Augmentation 72 # This requires the imgaug lib (https://github.com/aleju/imgaug) 73 if augmentation: 74 import imgaug 75 76 # Augmenters that are safe to apply to masks 77 # Some, such as Affine, have settings that make them unsafe, so always 78 # test your augmentation on masks 79 MASK_AUGMENTERS = [\u0026#34;Sequential\u0026#34;, \u0026#34;SomeOf\u0026#34;, \u0026#34;OneOf\u0026#34;, \u0026#34;Sometimes\u0026#34;, 80 \u0026#34;Fliplr\u0026#34;, \u0026#34;Flipud\u0026#34;, \u0026#34;CropAndPad\u0026#34;, 81 \u0026#34;Affine\u0026#34;, \u0026#34;PiecewiseAffine\u0026#34;] 82 83 def hook(images, augmenter, parents, default): 84 \u0026#34;\u0026#34;\u0026#34;Determines which augmenters to apply to masks.\u0026#34;\u0026#34;\u0026#34; 85 return augmenter.__class__.__name__ in MASK_AUGMENTERS 86 87 # Store shapes before augmentation to compare 88 image_shape = image.shape 89 mask_shape = mask.shape 90 # Make augmenters deterministic to apply similarly to images and masks 91 det = augmentation.to_deterministic() 92 image = det.augment_image(image) 93 # Change mask to np.uint8 because imgaug doesn\u0026#39;t support np.bool 94 mask = det.augment_image(mask.astype(np.uint8), 95 hooks=imgaug.HooksImages(activator=hook)) 96 # Verify that shapes didn\u0026#39;t change 97 assert image.shape == image_shape, \u0026#34;Augmentation shouldn\u0026#39;t change image size\u0026#34; 98 assert mask.shape == mask_shape, \u0026#34;Augmentation shouldn\u0026#39;t change mask size\u0026#34; 99 # Change mask back to bool 100 mask = mask.astype(np.bool) 101 102 # Note that some boxes might be all zeros if the corresponding mask got cropped out. 103 # and here is to filter them out 104 _idx = np.sum(mask, axis=(0, 1)) \u0026gt; 0 105 mask = mask[:, :, _idx] 106 class_ids = class_ids[_idx] 107 # Bounding boxes. Note that some boxes might be all zeros 108 # if the corresponding mask got cropped out. 109 # bbox: [num_instances, (y1, x1, y2, x2)] 110 bbox = utils.extract_bboxes(mask) 111 112 # Active classes 113 # Different datasets have different classes, so track the 114 # classes supported in the dataset of this image. 115 active_class_ids = np.zeros([dataset.num_classes], dtype=np.int32) 116 source_class_ids = dataset.source_class_ids[dataset.image_info[image_id][\u0026#34;source\u0026#34;]] 117 active_class_ids[source_class_ids] = 1 118 119 # Resize masks to smaller size to reduce memory usage 120 if use_mini_mask: 121 if USE_MINI_MASK_SHAPE: 122 mask = utils.minimize_mask(bbox, mask, MINI_MASK_SHAPE) 123 else: 124 mask = utils.minimize_mask(bbox, mask, mask.shape[:2]) 125 126 # Image meta data 127 image_meta = compose_image_meta(image_id, original_shape, image.shape, 128 window, scale, active_class_ids) 129 130 return image, image_meta, class_ids, bbox, mask 131 132 133image_id = np.random.choice(dataset.image_ids, 1)[0] 134image, image_meta, class_ids, bbox, mask = load_image_gt( 135 dataset, config, image_id, use_mini_mask=False) 136 137 138visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))]) 139 140image, image_meta, class_ids, bbox, mask = load_image_gt( 141 dataset, config, image_id, use_mini_mask=True) 142 143 144visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))]) 145 146USE_MINI_MASK_SHAPE = True 147 148image, image_meta, class_ids, bbox, mask = load_image_gt( 149 dataset, config, image_id, use_mini_mask=True) 150 151 152visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))]) 153 154mask = utils.expand_mask(bbox, mask, image.shape) 155visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names) Vá»›i áº£nh á»Ÿ line 1 lÃ  áº£nh gá»‘c ban Ä‘áº§u vÃ  cÃ¡c full mask cá»§a bá»©c áº£nh, áº£nh á»Ÿ line 2 lÃ  chá»‰ láº¥y mask cá»§a bounding box, áº£nh á»Ÿ line 3 lÃ  láº¥y mask á»Ÿ bounding box vÃ  scale áº£nh (do scale áº£nh nÃªn á»Ÿ line 3 cÃ¡c báº¡n sáº½ tháº¥y mask cÃ³ hÃ¬nh rÄƒng cÆ°a, khÃ¡c vá»›i cÃ¡c mask line 2). Line 4 lÃ  áº£nh á»Ÿ line 3 Ä‘Æ°á»£c revert back láº¡i hÃ¬nh gá»‘c ban Ä‘áº§u. CÃ¡c báº¡n cÃ³ Ä‘á»ƒ Ã½ tháº¥y ráº±ng nÃ³ sáº½ bá»‹ rÄƒng cÆ°a á»Ÿ biÃªn cáº¡nh chá»© khÃ´ng Ä‘Æ°á»£c smooth nhÆ° áº£nh gá»‘c. Náº¿u chÃºng ta khÃ´ng lÃ m object annotations ká»¹, thÃ¬ object cÅ©ng sáº½ bá»‹ rÄƒng cÆ°a nhÆ° trÃªn.\nAnchors Thá»© tá»± cá»§a cÃ¡c anchor tháº­t sá»± ráº¥t quan trá»ng. Trong quÃ¡ trÃ¬nh train, thá»© tá»± cá»§a cÃ¡c anchor nhÆ° tháº¿ nÃ o thÃ¬ trong quÃ¡ trÃ¬nh test, validation, prediction pháº£i dÃ¹ng y há»‡t váº­y.\nTrong máº¡ng FPN, cÃ¡c anchor pháº£i Ä‘Æ°á»£c xáº¯p xáº¿p theo cÃ¡ch mÃ  chÃºng ta cÃ³ thá»ƒ dá»… dÃ ng liÃªn káº¿t vá»›i giÃ¡ trá»‹ output\nXáº¯p xáº¿p cÃ¡c anchor theo thá»© tá»± cÃ¡c lá»›p cá»§a pyramid. Táº¥t cáº£ cÃ¡c anchor cá»§a level Ä‘áº§u tiÃªn, tiáº¿p theo lÃ  cÃ¡c anchor cá»§a cÃ¡c lá»›p thá»© hai, lá»›p thÆ° ba\u0026hellip; Viá»‡c xáº¯p xáº¿p theo cÃ¡ch nÃ y sáº½ giÃºp chÃºng ta dá»… dÃ ng phÃ¢n tÃ¡ch cÃ¡c lá»›p anchor vÃ  dá»… hiá»ƒu theo láº½ tá»± nhiÃªn.\nTrong má»—i level, xáº¯p xáº¿p cÃ¡c anchor trong má»—i level báº±ng thá»© tá»± xá»­ lÃ½ cá»§a cÃ¡c feature map. ThÃ´ng thÆ°á»ng, má»™t convolution layer sáº½ dá»‹ch chuyá»ƒn trÃªn feature map báº¯t Ä‘áº§u tá»« vá»‹ trÃ­ trÃ¡i - trÃªn (top - left) Ä‘i xuá»‘ng pháº£i dÆ°á»›i (tá»« trÃ¡i qua pháº£i, xuá»‘ng hÃ ng rá»“i láº¡i tá»« trÃ¡i qua pháº£i).\nTrÃªn má»—i cell cá»§a feature map, chÃºng ta sáº½ xáº¯p xáº¿p cÃ¡c anchor theo cÃ¡c ratios.\nAnchor Stride:\n1 2backbone_shapes = modellib.compute_backbone_shapes(config, config.IMAGE_SHAPE) 3anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES, 4 config.RPN_ANCHOR_RATIOS, 5 backbone_shapes, 6 config.BACKBONE_STRIDES, 7 config.RPN_ANCHOR_STRIDE) 8 9# Print summary of anchors 10num_levels = len(backbone_shapes) 11anchors_per_cell = len(config.RPN_ANCHOR_RATIOS) 12print(\u0026#34;Total anchors: \u0026#34;, anchors.shape[0]) 13print(\u0026#34;ANCHOR Scales: \u0026#34;, config.RPN_ANCHOR_SCALES) 14print(\u0026#34;BACKBONE STRIDE: \u0026#34;, config.BACKBONE_STRIDES) 15print(\u0026#34;ratios: \u0026#34;, config.RPN_ANCHOR_RATIOS) 16print(\u0026#34;Anchors per Cell: \u0026#34;, anchors_per_cell) 17# print(\u0026#34;Anchors stride: \u0026#34;, config.RPN_ANCHOR_STRIDE) 18print(\u0026#34;Levels: \u0026#34;, num_levels) 19anchors_per_level = [] 20for l in range(num_levels): 21 num_cells = backbone_shapes[l][0] * backbone_shapes[l][1] 22 print(\u0026#34;backbone_shapes in level \u0026#34;,l,\u0026#39; \u0026#39;,backbone_shapes[l][0],\u0026#39;x\u0026#39;,backbone_shapes[l][1]) 23 print(\u0026#34;num_cells in level \u0026#34;,l,\u0026#39; \u0026#39;,num_cells) 24 anchors_per_level.append(anchors_per_cell * num_cells // config.RPN_ANCHOR_STRIDE**2) 25 print(\u0026#34;Anchors in Level {}: {}\u0026#34;.format(l, anchors_per_level[l])) 1Total anchors: 261888 2ANCHOR Scales: (32, 64, 128, 256, 512) 3BACKBONE STRIDE: [4, 8, 16, 32, 64] 4ratios: [0.5, 1, 2] 5Anchors per Cell: 3 6Levels: 5 7backbone_shapes in level 0 256 x 256 8num_cells in level 0 65536 9Anchors in Level 0: 196608 10backbone_shapes in level 1 128 x 128 11num_cells in level 1 16384 12Anchors in Level 1: 49152 13backbone_shapes in level 2 64 x 64 14num_cells in level 2 4096 15Anchors in Level 2: 12288 16backbone_shapes in level 3 32 x 32 17num_cells in level 3 1024 18Anchors in Level 3: 3072 19backbone_shapes in level 4 16 x 16 20num_cells in level 4 256 21Anchors in Level 4: 768 Trong kiáº¿n trá»©c FPN, feature map táº¡i má»™t sá»‘ layer Ä‘áº§u tiÃªn lÃ  nhá»¯ng feature map cÃ³ Ä‘á»™ phÃ¢n giáº£i lá»›n. VÃ­ dá»¥, náº¿u bá»©c áº£nh Ä‘áº§u vÃ o cÃ³ kÃ­ch thÆ°á»›c lÃ  1024x1024 pixel, vÃ  kÃ­ch thÆ°á»›c cá»§a má»—i anchor lá»›p Ä‘áº§u tiÃªn lÃ  32x32 pixel (giÃ¡ trá»‹ Ä‘áº§u tiÃªn cá»§a RPN_ANCHOR_SCALES (32, 64, 128, 256, 512)) vÃ  bÆ°á»›c nháº£y (STRIDE) cá»§a lá»›p Ä‘áº§u tiÃªn lÃ  4 (giÃ¡ trá»‹ Ä‘áº§u tiÃªn cá»§a BACKBONE_STRIDES ([4, 8, 16, 32, 64])). Tá»« nhá»¯ng dá»¯ kiá»‡n nÃ y, ta cÃ³ thá»ƒ suy ra Ä‘Æ°á»£c lÃ  sáº½ sinh ra backbone cell cÃ³ kÃ­ch thÆ°á»›c 256x256 pixel =\u0026gt; 256x256 = 65536 anchor. Vá»›i má»—i backbone cell, chÃºng ta thá»±c hiá»‡n phÃ©p scale vá»›i 3 tá»· lá»‡ khÃ¡c nhau lÃ  [0.5, 1, 2], váº­y chÃºng ta cÃ³ tá»•ng cá»™ng lÃ  65536x3 = 196608 anchor (xáº¥p xá»‰ 200k anchor). Äá»ƒ Ã½ má»™t Ä‘iá»u lÃ  kÃ­ch thÆ°á»›c cá»§a má»™t anchor lÃ  32x32 pixel, vÃ  bÆ°á»›c nháº£y lÃ  4, cho nÃªn chÃºng ta sáº½ bá»‹ chá»‘ng láº¥n (overlap) 28 pixel cá»§a anchor 1 vÃ  anchor 2 ngay sau nÃ³.\nMá»™t Ä‘iá»u thÃº vá»‹ lÃ , náº¿u ta tÄƒng bÆ°á»›c nháº£y lÃªn gáº¥p 2 láº§n, vÃ­ dá»¥ tá»« 4 pixel láº¥y má»™t anchor lÃªn 8 pixel láº¥y má»™t anchor, thÃ¬ sá»‘ lÆ°á»£ng anchor giáº£m Ä‘i Ä‘áº¿n 4 láº§n (196608 anchor á»Ÿ level 0 so vá»›i 49152 anchor á»Ÿ level 1).\nThá»­ váº½ táº¥t cáº£ cÃ¡c anchor cá»§a táº¥t cáº£ cÃ¡c level á»Ÿ Ä‘iá»ƒm giá»¯a má»™t bá»©c áº£nh bá»©c ká»³ lÃªn, má»—i má»™t level sáº½ dÃ¹ng má»™t mÃ u khÃ¡c nhau, chÃºng ta Ä‘Æ°á»£c má»™t hÃ¬nh nhÆ° bÃªn dÆ°á»›i.\n1# Visualize anchors of one cell at the center of the feature map of a specific level 2 3# Load and draw random image 4image_id = np.random.choice(dataset.image_ids, 1)[0] 5image, image_meta, _, _, _ = modellib.load_image_gt(dataset, config, image_id) 6fig, ax = plt.subplots(1, figsize=(10, 10)) 7ax.imshow(image) 8levels = len(backbone_shapes) 9 10kn_color =np.array( [(255,0,0),(0,255,0),(0,0,255),(128,0,0),(0,128,0),(0,0,128)])/255. 11 12for level in range(levels): 13 # colors = visualize.random_colors(levels) 14 colors = kn_color 15 # Compute the index of the anchors at the center of the image 16 level_start = sum(anchors_per_level[:level]) # sum of anchors of previous levels 17 level_anchors = anchors[level_start:level_start+anchors_per_level[level]] 18 print(\u0026#34;Level {}. Anchors: {:6} Feature map Shape: {} \u0026#34;.format(level, level_anchors.shape[0], 19 backbone_shapes[level])) 20 center_cell = backbone_shapes[level] // 2 21 center_cell_index = (center_cell[0] * backbone_shapes[level][1] + center_cell[1]) 22 level_center = center_cell_index * anchors_per_cell 23 center_anchor = anchors_per_cell * ( 24 (center_cell[0] * backbone_shapes[level][1] / config.RPN_ANCHOR_STRIDE**2) \\ 25 + center_cell[1] / config.RPN_ANCHOR_STRIDE) 26 level_center = int(center_anchor) 27 28 # Draw anchors. Brightness show the order in the array, dark to bright. 29 for i, rect in enumerate(level_anchors[level_center:level_center+anchors_per_cell]): 30 y1, x1, y2, x2 = rect 31 p = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, facecolor=\u0026#39;none\u0026#39;, 32 edgecolor=np.array(colors[level]) / anchors_per_cell) 33 print(i) 34 ax.add_patch(p) 35 36 37plt.show() NhÃ¬n áº£nh trÃªn,cÃ¡c báº¡n pháº§n nÃ o Ä‘Ã³ mÆ°á»ng tÆ°á»£ng ra cÃ¡c anchor sáº½ nhÆ° tháº¿ nÃ o rá»“i pháº£i khÃ´ng.\nPrediction Äá»ƒ tiáº¿n hÃ nh detect vá»‹ trÃ­ quáº£ bÃ³ng vÃ  mask cá»§a quáº£ bÃ³ng, chÃºng ta download má»™t áº£nh small party nhá» trÃªn internet vá» vÃ  kiá»ƒm chá»©ng.\n1 2import os 3 4import tensorflow as tf 5 6import cv2 7 8DEVICE = \u0026#34;/cpu:0\u0026#34; 9ROOT_DIR = os.path.abspath(\u0026#34;../../\u0026#34;) 10MODEL_DIR = os.path.join(ROOT_DIR, \u0026#34;logs\u0026#34;) 11# Create model in inference mode 12 13class InferenceConfig(config.__class__): 14 # Run detection on one image at a time 15 GPU_COUNT = 1 16 IMAGES_PER_GPU = 1 17 18config = InferenceConfig() 19config.display() 20 21with tf.device(DEVICE): 22 model = modellib.MaskRCNN(mode=\u0026#34;inference\u0026#34;, model_dir=MODEL_DIR, 23 config=config) 24 25 26weights_path = \u0026#34;mask_rcnn_balloon.h5\u0026#34; 27 28# Load weights 29print(\u0026#34;Loading weights \u0026#34;, weights_path) 30# model.load_weights(weights_path, by_name=True) 31 32imgpath = \u0026#34;datasets\\\\balloon\\\\test\\\\t1.png\u0026#34; 33# imgpath = \u0026#34;datasets/balloon/val/14898532020_ba6199dd22_k.jpg\u0026#34; 34 35image = cv2.imread(imgpath) 36 37image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) 38 39 40 41ds_name = [\u0026#39;BG\u0026#39;, \u0026#39;balloon\u0026#39;] 42 43 44results = model.detect([image], verbose=1) 45 46def get_ax(rows=1, cols=1, size=16): 47 \u0026#34;\u0026#34;\u0026#34;Return a Matplotlib Axes array to be used in 48 all visualizations in the notebook. Provide a 49 central point to control graph sizes. 50 51 Adjust the size attribute to control how big to render images 52 \u0026#34;\u0026#34;\u0026#34; 53 _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows)) 54 return ax 55# Display results 56ax = get_ax(1) 57r = results[0] 58visualize.display_instances(image, r[\u0026#39;rois\u0026#39;], r[\u0026#39;masks\u0026#39;], r[\u0026#39;class_ids\u0026#39;], 59 dataset.class_names, r[\u0026#39;scores\u0026#39;], ax=ax, 60 title=\u0026#34;Predictions\u0026#34;) 61plt.show() Káº¿t quáº£ nháº­n dáº¡ng khÃ¡ chÃ­nh xÃ¡c pháº£i khÃ´ng cÃ¡c báº¡n.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Mar 25, 2019","img":"","permalink":"/blog/2019-03-25-mask-rcnn-balloon/","series":null,"tags":["machine learning","deep learning","Mask R-CNN","balloon","bÃ³ng bay"],"title":"TÃ¬m Hiá»ƒu Mask R-CNN VÃ  VÃ­ Dá»¥ PhÃ¢n VÃ¹ng Quáº£ BÃ³ng Bay Sá»­ Dá»¥ng Deep Learning"},{"categories":null,"content":" ThÃªm dáº¥u tiáº¿ng viá»‡t lÃ  má»™t trong nhá»¯ng bÃ i toÃ¡n khÃ¡ hay trong xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn. á» Ä‘Ã¢y, mÃ¬nh Ä‘Ã£ tiáº¿n hÃ nh thu tháº­p dá»¯ liá»‡u bÃ i bÃ¡o cá»§a nhiá»u nguá»“n khÃ¡c nhau nhÆ° zing.vn, vnexpress, kenh14.vn \u0026hellip; lÃ m kho ngá»¯ liá»‡u vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh.\nÄá»ƒ tiáº¿n hÃ nh thá»±c nghiá»‡m, mÃ¬nh sáº½ láº¥y má»™t sá»‘ Ä‘oáº¡n vÄƒn máº«u á»Ÿ trang tin tá»©c cá»§a tháº¿ giá»›i di Ä‘á»™ng (https.www.thegioididong.com) (mÃ¬nh khÃ´ng crawl ná»™i dung tin tá»©c á»Ÿ trang nÃ y lÃ m dá»¯ liá»‡u há»c).\ná» bÃ i viáº¿t link https://www.thegioididong.com/tin-tuc/3-ngay-cuoi-tuan-mua-laptop-online-tang-them-pmh-den-400k-tra-gop-0--1151334, mÃ¬nh láº¥y Ä‘oáº¡n má»Ÿ Ä‘áº§u \u0026ldquo;Tá»« ngÃ y 15/3 Ä‘áº¿n 17/3, nhiá»u máº«u laptop táº¡i Tháº¿ Giá»›i Di Äá»™ng sáº½ Ä‘Æ°á»£c Æ°u Ä‘Ã£i máº¡nh, táº·ng phiáº¿u mua hÃ ng Ä‘áº¿n 400 ngÃ n Ä‘á»“ng, tráº£ gÃ³p 0% vÃ  nhiá»u quÃ  táº·ng háº¥p dáº«n khÃ¡c khi mua theo hÃ¬nh thá»©c ONLINE. Náº¿u Ä‘ang cÃ³ nhu cáº§u mua laptop, báº¡n hÃ£y nhanh chÃ³ng xem qua danh sÃ¡ch sáº£n pháº©m dÆ°á»›i Ä‘Ã¢y nhÃ©.\u0026rdquo;, bá» dáº¥u cá»§a cÃ¢u Ä‘i, thÃ¬ mÃ¬nh Ä‘Æ°á»£c cÃ¢u\n\u0026ldquo;Tu ngay 15/3 den 17/3, nhieu mau laptop tai The Gioi Di Dong se duoc uu dai manh, tang phieu mua hang den 400 ngan dong, tra gop 0% va nhieu qua tang hap dan khac khi mua theo hinh thuc ONLINE. Neu dang co nhu cau mua laptop, ban hay nhanh chong xem qua danh sach san pham duoi day nhe.\u0026rdquo;\nSá»­ dá»¥ng mÃ´ hÃ¬nh mÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n, thu Ä‘Æ°á»£c káº¿t quáº£ nhÆ° sau:\n\u0026ldquo;Tá»« ngÃ y 15/3 Ä‘áº¿n 17/3 m t m, nhiá»u máº«u laptoP táº¡I tháº¿ giá»ši di Ä‘á»™ng sáº½ Ä‘Æ°á»£c Æ°u Ä‘Ã£i máº¡nh, tang phiáº¿u mua hÃ ng Ä‘áº¿n 400 ngÃ n Ä‘á»“ng, tráº£ gÃ³p 0 r% vÃ  nhiá»u quÃ  táº·ng háº¥p dáº«n khÃ¡c khi mua theo hÃ¬NH THá»¨c Onfine. náº¿u Ä‘ang cÃ³ nhu cáº§u mua laptop, báº¡n hÃ£y nhanh chÃ³ng xem qua danh sÃ¡ch sáº£n pháº©m dÆ°á»›i\u0026rdquo;\nKáº¿t quáº£ khÃ¡ kháº£ quan pháº£i khÃ´ng cÃ¡c báº¡n, cÃ²n má»™t sá»‘ lá»—i nhá» á»Ÿ pháº§n nháº­n dáº¡ng kÃ½ tá»± hoa ná»¯a. MÃ¬nh sáº½ fix láº¡i á»Ÿ cÃ¡c bÃ i viáº¿t sau.\nMÃ¬nh thÃ­ nghiá»‡m tiáº¿p vá»›i pháº§n Ä‘áº§u bÃ i viáº¿t https://www.thegioididong.com/tin-tuc/apple-ban-ra-thi-truong-35-trieu-cap-tai-nghe-airpods-nam-2018-1155181. Äoáº¡n \u0026ldquo;HÃ´m nay, bÃ¡o cÃ¡o cá»§a Counterpoint Research cho tháº¥y, trong nÄƒm 2018 Apple Ä‘Ã£ bÃ¡n Ä‘Æ°á»£c khoáº£ng 35 triá»‡u cáº·p tai nghe khÃ´ng dÃ¢y AirPods. Theo hÃ£ng phÃ¢n tÃ­ch nÃ y, AirPods hiá»‡n lÃ  tai nghe khÃ´ng dÃ¢y phá»• biáº¿n nháº¥t.\u0026rdquo;, bá» dáº¥u tiáº¿ng viá»‡t lÃ  thu Ä‘Æ°á»£c \u0026ldquo;Hom nay, bao cao cua Counterpoint Research cho thay, trong nam 2018 Apple da ban duoc khoang 35 trieu cap tai nghe khong day AirPods. Theo hang phan tich nay, AirPods hien la tai nghe khong day pho bien nhat.\u0026rdquo;\nKáº¿t quáº£ cá»§a mÃ´ hÃ¬nh: \u0026ldquo;HÃ´m nay, báº¡o cÃ¡o cá»§a Coorteenria eEeeroa c ttt, trong nÄƒm 2018 apple Ä‘Ã£ bÃ¡n Ä‘Æ°á»£c khoáº£ng 35 triá»‡u cáº·p táº¡i nghe khÃ´ng Ä‘áº§y aitcoDs. theo HÃ ng phÃ¢n tÃ­ch nÃ y, airxoDs Hiá»‡n lÃ  tai nghe khÃ´ng dáº¡y phá»• biáº¿n nháº¥t.\u0026rdquo;\nMÃ´ hÃ¬nh cá»§a mÃ¬nh cho láº·p 50 láº§n. MÃ¬nh tiáº¿n hÃ nh thÃ­ nghiá»‡m vÃ  publish mÃ´ hÃ¬nh á»Ÿ láº§n láº·p thá»© 10.\nMÃ£ nguá»“n file predict\n1from keras.models import load_model 2model = load_model(\u0026#39;a_best_weight.h5\u0026#39;) 3 4from collections import Counter 5 6import numpy as np 7 8import utils 9import string 10import re 11 12alphabet = set(\u0026#39;\\x00 _\u0026#39; + string.ascii_lowercase + string.digits + \u0026#39;\u0026#39;.join(utils.ACCENTED_TO_BASE_CHAR_MAP.keys())) 13 14print(\u0026#34;alphabet\u0026#34;,alphabet) 15codec = utils.CharacterCodec(alphabet, utils.MAXLEN) 16 17def guess(ngram): 18 text = \u0026#39; \u0026#39;.join(ngram) 19 text += \u0026#39;\\x00\u0026#39; * (utils.MAXLEN - len(text)) 20 if utils.INVERT: 21 text = text[::-1] 22 preds = model.predict_classes(np.array([codec.encode(text)]), verbose=0) 23 rtext = codec.decode(preds[0], calc_argmax=False).strip(\u0026#39;\\x00\u0026#39;) 24 if len(rtext)\u0026gt;0: 25 index = rtext.find(\u0026#39;\\x00\u0026#39;) 26 if index\u0026gt;-1: 27 rtext = rtext[:index] 28 return rtext 29 30 31def add_accent(text): 32 # lowercase the input text as we train the model on lowercase text only 33 # but we keep the map of uppercase characters to restore cases in output 34 is_uppercase_map = [c.isupper() for c in text] 35 text = utils.remove_accent(text.lower()) 36 37 outputs = [] 38 words_or_symbols_list = re.findall(\u0026#39;\\w[\\w ]*|\\W+\u0026#39;, text) 39 40 # print(words_or_symbols_list) 41 42 for words_or_symbols in words_or_symbols_list: 43 if utils.is_words(words_or_symbols): 44 outputs.append(_add_accent(words_or_symbols)) 45 else: 46 outputs.append(words_or_symbols) 47 # print(outputs) 48 output_text = \u0026#39;\u0026#39;.join(outputs) 49 50 # restore uppercase characters 51 output_text = \u0026#39;\u0026#39;.join(c.upper() if is_upper else c 52 for c, is_upper in zip(output_text, is_uppercase_map)) 53 return output_text 54 55def _add_accent(phrase): 56 grams = list(utils.gen_ngram(phrase.lower(), n=utils.NGRAM, pad_words=utils.PAD_WORDS_INPUT)) 57 58 guessed_grams = list(guess(gram) for gram in grams) 59 # print(\u0026#34;phrase\u0026#34;,phrase,\u0026#39;grams\u0026#39;,grams,\u0026#39;guessed_grams\u0026#39;,guessed_grams) 60 candidates = [Counter() for _ in range(len(guessed_grams) + utils.NGRAM - 1)] 61 for idx, gram in enumerate(guessed_grams): 62 for wid, word in enumerate(re.split(\u0026#39; +\u0026#39;, gram)): 63 candidates[idx + wid].update([word]) 64 output = \u0026#39; \u0026#39;.join(c.most_common(1)[0][0] for c in candidates if c) 65 return output.strip(\u0026#39;\\x00 \u0026#39;) 66 67 68 69# print(add_accent(\u0026#39;do,\u0026#39;)) 70# print(add_accent(\u0026#39;7.3 inch,\u0026#39;)) 71# print(add_accent(\u0026#39;Truoc do, tren san khau su kien SDC 2018, giam doc cao cap mang marketing san pham di dong cua Samsung, ong Justin Denison da cam tren tay nguyen mau cua thiet bi nay. Ve co ban, no chang khac gi mot chiec may tinh bang 7.3 inch, duoc cau thanh tu nhieu lop phu khac nhau nhu polyme, lop man chong soc, lop phan cuc voi do mong gan mot nua so voi the he truoc, lop kinh linh hoat va mot tam lung da nang co the bien thanh man hinh. Tat ca se duoc ket dinh bang mot loai keo cuc ben, cho phep chiec may nay co the gap lai hang tram ngan lan ma khong bi hu hong.\u0026#39;)) 72# print(add_accent(\u0026#39;man hinh. Tat ca se duoc ket dinh bang mot loai keo cuc ben, cho phep chiec may nay co the gap lai hang tram ngan lan ma khong bi hu hong.\u0026#39;)) 73print(add_accent(\u0026#39;Hom nay, bao cao cua Counterpoint Research cho thay, trong nam 2018 Apple da ban duoc khoang 35 trieu cap tai nghe khong day AirPods. Theo hang phan tich nay, AirPods hien la tai nghe khong day pho bien nhat.\u0026#39;)) MÃ£ nguá»“n file utils\n1import re 2import string 3import time 4from contextlib import contextmanager 5import numpy as np 6 7 8 9# maximum string length to train and predict 10# this is set based on our ngram length break down below 11MAXLEN = 32 12 13# minimum string length to consider 14MINLEN = 3 15 16# how many words per ngram to consider in our model 17NGRAM = 5 18 19# inverting the input generally help with accuracy 20INVERT = True 21 22# mini batch size 23BATCH_SIZE = 128 24 25# number of phrases set apart from training set to validate our model 26VALIDATION_SIZE = 100000 27 28# using g2.2xl GPU is ~5x faster than a Macbook Pro Core i5 CPU 29HAS_GPU = True 30 31PAD_WORDS_INPUT = True 32 33### Ãnh xáº¡ tá»« khÃ´ng dáº¥u sang cÃ³ dáº¥u 34 35ACCENTED_CHARS = { 36\t\u0026#39;a\u0026#39;: u\u0026#39;a Ã¡ Ã  áº£ Ã£ áº¡ Ã¢ áº¥ áº§ áº© áº« áº­ Äƒ áº¯ áº± áº³ áºµ áº·\u0026#39;, 37\t\u0026#39;o\u0026#39;: u\u0026#39;o Ã³ Ã² á» Ãµ á» Ã´ á»‘ á»“ á»• á»— á»™ Æ¡ á»› á» á»Ÿ á»¡ á»£\u0026#39;, 38\t\u0026#39;e\u0026#39;: u\u0026#39;e Ã© Ã¨ áº» áº½ áº¹ Ãª áº¿ á» á»ƒ á»… á»‡\u0026#39;, 39\t\u0026#39;u\u0026#39;: u\u0026#39;u Ãº Ã¹ á»§ Å© á»¥ Æ° á»© á»« á»­ á»¯ á»±\u0026#39;, 40\t\u0026#39;i\u0026#39;: u\u0026#39;i Ã­ Ã¬ á»‰ Ä© á»‹\u0026#39;, 41\t\u0026#39;y\u0026#39;: u\u0026#39;y Ã½ á»³ á»· á»¹ á»µ\u0026#39;, 42\t\u0026#39;d\u0026#39;: u\u0026#39;d Ä‘\u0026#39;, 43} 44 45### Ãnh xáº¡ tá»« cÃ³ dáº¥u sang khÃ´ng dáº¥u 46ACCENTED_TO_BASE_CHAR_MAP = {} 47for c, variants in ACCENTED_CHARS.items(): 48\tfor v in variants.split(\u0026#39; \u0026#39;): 49\tACCENTED_TO_BASE_CHAR_MAP[v] = c 50 51# \\x00 kÃ½ tá»± padding 52 53### Nhá»¯ng kÃ½ tá»± cÆ¡ báº£n, bao gá»“m kÃ½ tá»± padding, cÃ¡c chá»¯ cÃ¡i vÃ  cÃ¡c chá»¯ sá»‘ 54BASE_ALPHABET = set(\u0026#39;\\x00 _\u0026#39; + string.ascii_lowercase + string.digits) 55 56### Bá»™ kÃ½ tá»± bao gá»“m nhá»¯ng kÃ½ tá»± cÆ¡ báº£n vÃ  nhá»¯ng kÃ½ tá»± cÃ³ dáº¥u 57ALPHABET = BASE_ALPHABET.union(set(\u0026#39;\u0026#39;.join(ACCENTED_TO_BASE_CHAR_MAP.keys()))) 58 59 60def is_words(text): 61\treturn re.fullmatch(\u0026#39;\\w[\\w ]*\u0026#39;, text) 62 63# HÃ m bá» dáº¥u khá»i má»™t cÃ¢u 64def remove_accent(text): 65\t\u0026#34;\u0026#34;\u0026#34; remove accent from text \u0026#34;\u0026#34;\u0026#34; 66\treturn u\u0026#39;\u0026#39;.join(ACCENTED_TO_BASE_CHAR_MAP.get(char, char) for char in text) 67 68#hÃ m thÃªm padding vÃ o má»™t cÃ¢u 69def pad(phrase, maxlen): 70\t\u0026#34;\u0026#34;\u0026#34; right pad given string with \\x00 to exact \u0026#34;maxlen\u0026#34; length \u0026#34;\u0026#34;\u0026#34; 71\treturn phrase + u\u0026#39;\\x00\u0026#39; * (maxlen - len(phrase)) 72 73 74def gen_ngram(words, n=3, pad_words=True): 75\t\u0026#34;\u0026#34;\u0026#34; gen n-grams from given phrase or list of words \u0026#34;\u0026#34;\u0026#34; 76\tif isinstance(words, str): 77\twords = re.split(\u0026#39;\\s+\u0026#39;, words.strip()) 78 79\tif len(words) \u0026lt; n: 80\tif pad_words: 81\twords += [\u0026#39;\\x00\u0026#39;] * (n - len(words)) 82\tyield tuple(words) 83\telse: 84\tfor i in range(len(words) - n + 1): 85\tyield tuple(words[i: i + n]) 86 87def extract_phrases(text): 88\t\u0026#34;\u0026#34;\u0026#34; extract phrases, i.e. group of continuous words, from text \u0026#34;\u0026#34;\u0026#34; 89\treturn re.findall(r\u0026#39;\\w[\\w ]+\u0026#39;, text, re.UNICODE) 90 91 92@contextmanager 93def timing(label): 94\tbegin = time.monotonic() 95\tprint(label, end=\u0026#39;\u0026#39;, flush=True) 96\ttry: 97\tyield 98\tfinally: 99\tduration = time.monotonic() - begin 100\tprint(\u0026#39;: took {:.2f}s\u0026#39;.format(duration)) 101 102class CharacterCodec(object): 103 def __init__(self, alphabet, maxlen): 104 self.alphabet = list(sorted(set(alphabet))) 105 self.index_alphabet = dict((c, i) for i, c in enumerate(self.alphabet)) 106 self.maxlen = maxlen 107 108 def encode(self, C, maxlen=None): 109 maxlen = maxlen if maxlen else self.maxlen 110 X = np.zeros((maxlen, len(self.alphabet))) 111 for i, c in enumerate(C[:maxlen]): 112 X[i, self.index_alphabet[c]] = 1 113 return X 114 115 def try_encode(self, C, maxlen=None): 116 try: 117 return self.encode(C, maxlen) 118 except KeyError: 119 return None 120 121 def decode(self, X, calc_argmax=True): 122 if calc_argmax: 123 X = X.argmax(axis=-1) 124 return \u0026#39;\u0026#39;.join(self.alphabet[x] for x in X) link donwnload mÃ´ hÃ¬nh á»Ÿ láº§n láº·p thá»© 10 á»Ÿ https://github.com/AlexBlack2202/alexmodel/blob/master/a_best_weight.h5?raw=true\nÃ€, káº¿t quáº£ cá»§a cÃ¢u nÃ³i pháº§n má»Ÿ Ä‘áº§u lÃ  \u0026ldquo;máº¹ nÃ³i ráº±ng em ráº¥t Ä‘áº­m Ä‘ang\u0026rdquo;. Hi hi, may quÃ¡.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Mar 16, 2019","img":"","permalink":"/blog/2019-03-16-vietnamese-accent/","series":null,"tags":["machine learning","nlp","thÃªm dáº¥u tiáº¿ng viá»‡t"],"title":"ThÃªm Dáº¥u Tiáº¿ng Viá»‡t Cho CÃ¢u KhÃ´ng Dáº¥u"},{"categories":null,"content":"About Us ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i website www.phamduytung.com, nÆ¡i báº¡n cÃ³ thá»ƒ há»c vÃ  chia sáº» kiáº¿n thá»©c vá» machine learning má»™t cÃ¡ch dá»… dÃ ng vÃ  thÃº vá»‹.\nCÃ¢u chuyá»‡n cá»§a chÃºng tÃ´i website www.phamduytung.com Ä‘Æ°á»£c thÃ nh láº­p vÃ o nÄƒm 2017 . ChÃºng tÃ´i nháº­n tháº¥y ráº±ng machine learning lÃ  má»™t lÄ©nh vá»±c ráº¥t quan trá»ng vÃ  tiá»m nÄƒng trong thá»i Ä‘áº¡i cÃ´ng nghá»‡ sá»‘, nhÆ°ng cÅ©ng ráº¥t khÃ³ tiáº¿p cáº­n vÃ  há»c táº­p cho nhiá»u ngÆ°á»i, Ä‘áº·c biá»‡t lÃ  cÃ¡c há»c sinh sinh viÃªn. ChÃºng tÃ´i muá»‘n táº¡o ra má»™t website nÆ¡i má»i ngÆ°á»i cÃ³ thá»ƒ há»c machine learning má»™t cÃ¡ch dá»… hiá»ƒu, thá»±c hÃ nh vÃ  á»©ng dá»¥ng vÃ o thá»±c táº¿.\nÄá»™i ngÅ© cá»§a chÃºng tÃ´i website www.phamduytung.com lÃ  sá»± káº¿t há»£p cá»§a cÃ¡c thÃ nh viÃªn cÃ³ kinh nghiá»‡m vÃ  chuyÃªn mÃ´n vá» machine learning, giÃ¡o dá»¥c vÃ  thiáº¿t káº¿ web. ÄÃ¢y lÃ  nhá»¯ng ngÆ°á»i Ä‘Ã£ Ä‘Ã³ng gÃ³p cho sá»± phÃ¡t triá»ƒn cá»§a website cá»§a chÃºng tÃ´i:\nPháº¡m Duy TÃ¹ng: NgÆ°á»i sÃ¡ng láº­p vÃ  quáº£n lÃ½ website, cÃ³ báº±ng tháº¡c sÄ© vá» Computer Science / machine learning táº¡i Äáº¡i há»c Khoa há»c Tá»± NhiÃªn Há»“ ChÃ­ Minh, cÃ³ nhiá»u nÄƒm kinh nghiá»‡m lÃ m viá»‡c vá» machine learning cÆ¡ báº£n vÃ  deep learning.\nÄáº·ng Thá»‹ Háº±ng: ChuyÃªn gia ná»™i dung, cÃ³ báº±ng tháº¡c sÄ© vá» Computer Science táº¡i Äáº¡i há»c Khoa há»c Tá»± NhiÃªn Há»“ ChÃ­ Minh.\nSá»© má»‡nh cá»§a chÃºng tÃ´i Sá»© má»‡nh cá»§a chÃºng tÃ´i lÃ  mang Ä‘áº¿n cho báº¡n nhá»¯ng kiáº¿n thá»©c vÃ  ká»¹ nÄƒng vá» machine learning má»™t cÃ¡ch hiá»‡u quáº£ vÃ  thá»±c táº¿. ChÃºng tÃ´i cung cáº¥p cho báº¡n cÃ¡c bÃ i viáº¿t vÃ  cÃ¡c tÃ i nguyÃªn khÃ¡c vá» machine learning, tá»« cÆ¡ báº£n Ä‘áº¿n nÃ¢ng cao, tá»« lÃ½ thuyáº¿t Ä‘áº¿n thá»±c hÃ nh, tá»« phÃ¢n tÃ­ch Ä‘áº¿n á»©ng dá»¥ng. ChÃºng tÃ´i mong muá»‘n báº¡n cÃ³ thá»ƒ há»c machine learning má»™t cÃ¡ch tá»± tin, sÃ¡ng táº¡o vÃ  thÃ nh cÃ´ng.\nLiÃªn há»‡ vá»›i chÃºng tÃ´i ChÃºng tÃ´i luÃ´n sáºµn sÃ ng láº¯ng nghe vÃ  tráº£ lá»i cÃ¡c cÃ¢u há»i, gÃ³p Ã½, pháº£n há»“i vÃ  yÃªu cáº§u cá»§a báº¡n. Báº¡n cÃ³ thá»ƒ liÃªn há»‡ vá»›i chÃºng tÃ´i qua cÃ¡c kÃªnh sau:\nEmail: alexblack2202@gmail.com LinkedIn: Pháº¡m Duy TÃ¹ng HÃ£y báº¯t Ä‘áº§u há»c machine learning cÃ¹ng chÃºng tÃ´i Náº¿u báº¡n Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ há»c vÃ  chia sáº» kiáº¿n thá»©c vá» machine learning cÃ¹ng chÃºng tÃ´i. Báº¡n cÅ©ng cÃ³ thá»ƒ truy cáº­p cÃ¡c trang khÃ¡c trÃªn website cá»§a chÃºng tÃ´i Ä‘á»ƒ khÃ¡m phÃ¡ thÃªm nhiá»u ná»™i dung vÃ  dá»‹ch vá»¥ vá» machine learning. ChÃºng tÃ´i mong Ä‘Æ°á»£c Ä‘á»“ng hÃ nh cÃ¹ng báº¡n trÃªn con Ä‘Æ°á»ng há»c táº­p vÃ  nghiÃªn cá»©u machine learning.\n","date":"Feb 28, 2019","img":"","permalink":"/about/","series":null,"tags":null,"title":"About"},{"categories":null,"content":"Privacy Policy ==============\nLast updated: February 10, 2024\nThis Privacy Policy describes Our policies and procedures on the collection, use and disclosure of Your information when You use the Service and tells You about Your privacy rights and how the law protects You.\nWe use Your Personal data to provide and improve the Service. By using the Service, You agree to the collection and use of information in accordance with this Privacy Policy.\nInterpretation and Definitions Interpretation 1 2The words of which the initial letter is capitalized have meanings defined 3under the following conditions. The following definitions shall have the same 4meaning regardless of whether they appear in singular or in plural. 5 6## Definitions 7 8~~~~~~~~~~~ 9 10For the purposes of this Privacy Policy: 11 12 * Account means a unique account created for You to access our Service or 13 parts of our Service. 14 15 * Affiliate means an entity that controls, is controlled by or is under 16 common control with a party, where \u0026#34;control\u0026#34; means ownership of 50% or 17 more of the shares, equity interest or other securities entitled to vote 18 for election of directors or other managing authority. 19 20 * Company (referred to as either \u0026#34;the Company\u0026#34;, \u0026#34;We\u0026#34;, \u0026#34;Us\u0026#34; or \u0026#34;Our\u0026#34; in this 21 Agreement) refers to Pháº¡m Duy TÃ¹ng. 22 23 * Cookies are small files that are placed on Your computer, mobile device or 24 any other device by a website, containing the details of Your browsing 25 history on that website among its many uses. 26 27 * Country refers to: Vietnam 28 29 * Device means any device that can access the Service such as a computer, a 30 cellphone or a digital tablet. 31 32 * Personal Data is any information that relates to an identified or 33 identifiable individual. 34 35 * Service refers to the Website. 36 37 * Service Provider means any natural or legal person who processes the data 38 on behalf of the Company. It refers to third-party companies or 39 individuals employed by the Company to facilitate the Service, to provide 40 the Service on behalf of the Company, to perform services related to the 41 Service or to assist the Company in analyzing how the Service is used. 42 43 * Third-party Social Media Service refers to any website or any social 44 network website through which a User can log in or create an account to 45 use the Service. 46 47 * Usage Data refers to data collected automatically, either generated by the 48 use of the Service or from the Service infrastructure itself (for example, 49 the duration of a page visit). 50 51 * Website refers to Pháº¡m Duy TÃ¹ng, accessible from 52 \u0026lt;https://www.phamduytung.com/\u0026gt; 53 54 * You means the individual accessing or using the Service, or the company, 55 or other legal entity on behalf of which such individual is accessing or 56 using the Service, as applicable. 57 58 59# Collecting and Using Your Personal Data 60--------------------------------------- 61 62## Types of Data Collected Personal Data While using Our Service, We may ask You to provide Us with certain personally identifiable information that can be used to contact or identify You. Personally identifiable information may include, but is not limited to:\nUsage Data Usage Data Usage Data is collected automatically when using the Service.\nUsage Data may include information such as Your Device\u0026rsquo;s Internet Protocol address (e.g. IP address), browser type, browser version, the pages of our Service that You visit, the time and date of Your visit, the time spent on those pages, unique device identifiers and other diagnostic data.\nWhen You access the Service by or through a mobile device, We may collect certain information automatically, including, but not limited to, the type of mobile device You use, Your mobile device unique ID, the IP address of Your mobile device, Your mobile operating system, the type of mobile Internet browser You use, unique device identifiers and other diagnostic data.\nWe may also collect information that Your browser sends whenever You visit our Service or when You access the Service by or through a mobile device.\nInformation from Third-Party Social Media Services The Company allows You to create an account and log in to use the Service through the following Third-party Social Media Services:\nGoogle Facebook Instagram Twitter LinkedIn If You decide to register through or otherwise grant us access to a Third- Party Social Media Service, We may collect Personal data that is already associated with Your Third-Party Social Media Service\u0026rsquo;s account, such as Your name, Your email address, Your activities or Your contact list associated with that account.\nYou may also have the option of sharing additional information with the Company through Your Third-Party Social Media Service\u0026rsquo;s account. If You choose to provide such information and Personal Data, during registration or otherwise, You are giving the Company permission to use, share, and store it in a manner consistent with this Privacy Policy.\nTracking Technologies and Cookies We use Cookies and similar tracking technologies to track the activity on Our Service and store certain information. Tracking technologies used are beacons, tags, and scripts to collect and track information and to improve and analyze Our Service. The technologies We use may include:\nCookies or Browser Cookies. A cookie is a small file placed on Your Device. You can instruct Your browser to refuse all Cookies or to indicate when a Cookie is being sent. However, if You do not accept Cookies, You may not be able to use some parts of our Service. Unless you have adjusted Your browser setting so that it will refuse Cookies, our Service may use Cookies. Web Beacons. Certain sections of our Service and our emails may contain small electronic files known as web beacons (also referred to as clear gifs, pixel tags, and single-pixel gifs) that permit the Company, for example, to count users who have visited those pages or opened an email and for other related website statistics (for example, recording the popularity of a certain section and verifying system and server integrity). Cookies can be \u0026ldquo;Persistent\u0026rdquo; or \u0026ldquo;Session\u0026rdquo; Cookies. Persistent Cookies remain on Your personal computer or mobile device when You go offline, while Session Cookies are deleted as soon as You close Your web browser.\nWe use both Session and Persistent Cookies for the purposes set out below:\nNecessary / Essential Cookies\nType: Session Cookies\nAdministered by: Us\nPurpose: These Cookies are essential to provide You with services available through the Website and to enable You to use some of its features. They help to authenticate users and prevent fraudulent use of user accounts. Without these Cookies, the services that You have asked for cannot be provided, and We only use these Cookies to provide You with those services.\nCookies Policy / Notice Acceptance Cookies\nType: Persistent Cookies\nAdministered by: Us\nPurpose: These Cookies identify if users have accepted the use of cookies on the Website.\nFunctionality Cookies\nType: Persistent Cookies\nAdministered by: Us\nPurpose: These Cookies allow us to remember choices You make when You use the Website, such as remembering your login details or language preference. The purpose of these Cookies is to provide You with a more personal experience and to avoid You having to re-enter your preferences every time You use the Website.\nFor more information about the cookies we use and your choices regarding cookies, please visit our Cookies Policy or the Cookies section of our Privacy Policy.\nUse of Your Personal Data 1 2The Company may use Personal Data for the following purposes: 3 4 * To provide and maintain our Service , including to monitor the usage of 5 our Service. 6 7 * To manage Your Account: to manage Your registration as a user of the 8 Service. The Personal Data You provide can give You access to different 9 functionalities of the Service that are available to You as a registered 10 user. 11 12 * For the performance of a contract: the development, compliance and 13 undertaking of the purchase contract for the products, items or services 14 You have purchased or of any other contract with Us through the Service. 15 16 * To contact You: To contact You by email, telephone calls, SMS, or other 17 equivalent forms of electronic communication, such as a mobile 18 application\u0026#39;s push notifications regarding updates or informative 19 communications related to the functionalities, products or contracted 20 services, including the security updates, when necessary or reasonable for 21 their implementation. 22 23 * To provide You with news, special offers and general information about 24 other goods, services and events which we offer that are similar to those 25 that you have already purchased or enquired about unless You have opted 26 not to receive such information. 27 28 * To manage Your requests: To attend and manage Your requests to Us. 29 30 * For business transfers: We may use Your information to evaluate or conduct 31 a merger, divestiture, restructuring, reorganization, dissolution, or 32 other sale or transfer of some or all of Our assets, whether as a going 33 concern or as part of bankruptcy, liquidation, or similar proceeding, in 34 which Personal Data held by Us about our Service users is among the assets 35 transferred. 36 37 * For other purposes : We may use Your information for other purposes, such 38 as data analysis, identifying usage trends, determining the effectiveness 39 of our promotional campaigns and to evaluate and improve our Service, 40 products, services, marketing and your experience. 41 42 43We may share Your personal information in the following situations: 44 45 * With Service Providers: We may share Your personal information with 46 Service Providers to monitor and analyze the use of our Service, to 47 contact You. 48 * For business transfers: We may share or transfer Your personal information 49 in connection with, or during negotiations of, any merger, sale of Company 50 assets, financing, or acquisition of all or a portion of Our business to 51 another company. 52 * With Affiliates: We may share Your information with Our affiliates, in 53 which case we will require those affiliates to honor this Privacy Policy. 54 Affiliates include Our parent company and any other subsidiaries, joint 55 venture partners or other companies that We control or that are under 56 common control with Us. 57 * With business partners: We may share Your information with Our business 58 partners to offer You certain products, services or promotions. 59 * With other users: when You share personal information or otherwise 60 interact in the public areas with other users, such information may be 61 viewed by all users and may be publicly distributed outside. If You 62 interact with other users or register through a Third-Party Social Media 63 Service, Your contacts on the Third-Party Social Media Service may see 64 Your name, profile, pictures and description of Your activity. Similarly, 65 other users will be able to view descriptions of Your activity, 66 communicate with You and view Your profile. 67 * With Your consent : We may disclose Your personal information for any 68 other purpose with Your consent. 69 70## Retention of Your Personal Data The Company will retain Your Personal Data only for as long as is necessary for the purposes set out in this Privacy Policy. We will retain and use Your Personal Data to the extent necessary to comply with our legal obligations (for example, if we are required to retain your data to comply with applicable laws), resolve disputes, and enforce our legal agreements and policies.\nThe Company will also retain Usage Data for internal analysis purposes. Usage Data is generally retained for a shorter period of time, except when this data is used to strengthen the security or to improve the functionality of Our Service, or We are legally obligated to retain this data for longer time periods.\nTransfer of Your Personal Data 1 2Your information, including Personal Data, is processed at the Company\u0026#39;s 3operating offices and in any other places where the parties involved in the 4processing are located. It means that this information may be transferred to â€” 5and maintained on â€” computers located outside of Your state, province, country 6or other governmental jurisdiction where the data protection laws may differ 7than those from Your jurisdiction. 8 9Your consent to this Privacy Policy followed by Your submission of such 10information represents Your agreement to that transfer. 11 12The Company will take all steps reasonably necessary to ensure that Your data 13is treated securely and in accordance with this Privacy Policy and no transfer 14of Your Personal Data will take place to an organization or a country unless 15there are adequate controls in place including the security of Your data and 16other personal information. 17 18## Delete Your Personal Data 19~~~~~~~~~~~~~~~~~~~~~~~~~ 20 21You have the right to delete or request that We assist in deleting the 22Personal Data that We have collected about You. 23 24Our Service may give You the ability to delete certain information about You 25from within the Service. 26 27You may update, amend, or delete Your information at any time by signing in to 28Your Account, if you have one, and visiting the account settings section that 29allows you to manage Your personal information. You may also contact Us to 30request access to, correct, or delete any personal information that You have 31provided to Us. 32 33Please note, however, that We may need to retain certain information when we 34have a legal obligation or lawful basis to do so. 35 36## Disclosure of Your Personal Data Business Transactions If the Company is involved in a merger, acquisition or asset sale, Your Personal Data may be transferred. We will provide notice before Your Personal Data is transferred and becomes subject to a different Privacy Policy.\nLaw enforcement Under certain circumstances, the Company may be required to disclose Your Personal Data if required to do so by law or in response to valid requests by public authorities (e.g. a court or a government agency).\nOther legal requirements The Company may disclose Your Personal Data in the good faith belief that such action is necessary to:\nComply with a legal obligation Protect and defend the rights or property of the Company Prevent or investigate possible wrongdoing in connection with the Service Protect the personal safety of Users of the Service or the public Protect against legal liability Security of Your Personal Data 1 2The security of Your Personal Data is important to Us, but remember that no 3method of transmission over the Internet, or method of electronic storage is 4100% secure. While We strive to use commercially acceptable means to protect 5Your Personal Data, We cannot guarantee its absolute security. 6 7# Children\u0026#39;s Privacy 8------------------ 9 10Our Service does not address anyone under the age of 13. We do not knowingly 11collect personally identifiable information from anyone under the age of 13. 12If You are a parent or guardian and You are aware that Your child has provided 13Us with Personal Data, please contact Us. If We become aware that We have 14collected Personal Data from anyone under the age of 13 without verification 15of parental consent, We take steps to remove that information from Our 16servers. 17 18If We need to rely on consent as a legal basis for processing Your information 19and Your country requires consent from a parent, We may require Your parent\u0026#39;s 20consent before We collect and use that information. 21 22# Links to Other Websites 23----------------------- 24 25Our Service may contain links to other websites that are not operated by Us. 26If You click on a third party link, You will be directed to that third party\u0026#39;s 27site. We strongly advise You to review the Privacy Policy of every site You 28visit. 29 30We have no control over and assume no responsibility for the content, privacy 31policies or practices of any third party sites or services. 32 33# Changes to this Privacy Policy 34------------------------------ 35 36We may update Our Privacy Policy from time to time. We will notify You of any 37changes by posting the new Privacy Policy on this page. 38 39We will let You know via email and/or a prominent notice on Our Service, prior 40to the change becoming effective and update the \u0026#34;Last updated\u0026#34; date at the top 41of this Privacy Policy. 42 43You are advised to review this Privacy Policy periodically for any changes. 44Changes to this Privacy Policy are effective when they are posted on this 45page. 46 47# Contact Us 48---------- 49 50If you have any questions about this Privacy Policy, You can contact us: 51 52 * By email: alexblack2202@gmail.com 53 54 * By visiting this page on our website: 55 \u0026lt;https://www.phamduytung.com/contact/\u0026gt; ","date":"Feb 28, 2019","img":"","permalink":"/privacy/","series":null,"tags":null,"title":"Privacy Policy"},{"categories":null,"content":"Website Terms and Conditions of Use 1. Terms By accessing this Website, accessible from https://www.phamduytung.com/, you are agreeing to be bound by these Website Terms and Conditions of Use and agree that you are responsible for the agreement with any applicable local laws. If you disagree with any of these terms, you are prohibited from accessing this site. The materials contained in this Website are protected by copyright and trade mark law.\n2. Use License Permission is granted to temporarily download one copy of the materials on Pháº¡m Duy TÃ¹ng's Website for personal, non-commercial transitory viewing only. This is the grant of a license, not a transfer of title, and under this license you may not:\nmodify or copy the materials; use the materials for any commercial purpose or for any public display; attempt to reverse engineer any software contained on Pháº¡m Duy TÃ¹ng's Website; remove any copyright or other proprietary notations from the materials; or transferring the materials to another person or \"mirror\" the materials on any other server. This will let Pháº¡m Duy TÃ¹ng to terminate upon violations of any of these restrictions. Upon termination, your viewing right will also be terminated and you should destroy any downloaded materials in your possession whether it is printed or electronic format. These Terms of Service has been created with the help of the Terms Of Service Generator.\n3. Disclaimer All the materials on Pháº¡m Duy TÃ¹ng's Website are provided \"as is\". Pháº¡m Duy TÃ¹ng makes no warranties, may it be expressed or implied, therefore negates all other warranties. Furthermore, Pháº¡m Duy TÃ¹ng does not make any representations concerning the accuracy or reliability of the use of the materials on its Website or otherwise relating to such materials or any sites linked to this Website.\n4. Limitations Pháº¡m Duy TÃ¹ng or its suppliers will not be hold accountable for any damages that will arise with the use or inability to use the materials on Pháº¡m Duy TÃ¹ng's Website, even if Pháº¡m Duy TÃ¹ng or an authorize representative of this Website has been notified, orally or written, of the possibility of such damage. Some jurisdiction does not allow limitations on implied warranties or limitations of liability for incidental damages, these limitations may not apply to you.\n5. Revisions and Errata The materials appearing on Pháº¡m Duy TÃ¹ng's Website may include technical, typographical, or photographic errors. Pháº¡m Duy TÃ¹ng will not promise that any of the materials in this Website are accurate, complete, or current. Pháº¡m Duy TÃ¹ng may change the materials contained on its Website at any time without notice. Pháº¡m Duy TÃ¹ng does not make any commitment to update the materials.\n6. Links Pháº¡m Duy TÃ¹ng has not reviewed all of the sites linked to its Website and is not responsible for the contents of any such linked site. The presence of any link does not imply endorsement by Pháº¡m Duy TÃ¹ng of the site. The use of any linked website is at the user's own risk.\n7. Site Terms of Use Modifications Pháº¡m Duy TÃ¹ng may revise these Terms of Use for its Website at any time without prior notice. By using this Website, you are agreeing to be bound by the current version of these Terms and Conditions of Use.\n8. Your Privacy Please read our Privacy Policy.\n9. Governing Law Any claim related to Pháº¡m Duy TÃ¹ng's Website shall be governed by the laws of vn without regards to its conflict of law provisions.\n","date":"Feb 28, 2019","img":"","permalink":"/teamofservices/","series":null,"tags":null,"title":"Team of Services"},{"categories":null,"content":" BÃ i toÃ¡n ngÆ°á»i giao hÃ ng lÃ  gÃ¬ CÃ i Ä‘áº·t chÆ°Æ¡ng trÃ¬nh vÃ  thá»±c thi XÃ¢y dá»±ng vector state XÃ¢y dá»±ng hÃ m fitness function XÃ¡c Ä‘á»‹nh loáº¡i bÃ i toÃ¡n XÃ¡c Ä‘á»‹nh thuáº­t toÃ¡n tá»‘i Æ°u BÃ i toÃ¡n ngÆ°á»i giao hÃ ng lÃ  gÃ¬ NgÆ°á»i giao hÃ ng lÃ  bÃ i toÃ¡n cÆ¡ báº£n trong nhÃ³m bÃ i toÃ¡n tá»‘i Æ°u. BÃ i toÃ¡n Ä‘Æ°á»£c phÃ¡t biá»ƒu nhÆ° sau: CÃ³ má»™t ngÆ°á»i giao hÃ ng cáº§n Ä‘i giao hÃ ng táº¡i n thÃ nh phá»‘. Xuáº¥t phÃ¡t tá»« má»™t thÃ nh phá»‘ nÃ o Ä‘Ã³, Ä‘i qua cÃ¡c thÃ nh phá»‘ khÃ¡c Ä‘á»ƒ giao hÃ ng vÃ  trá»Ÿ vá» thÃ nh phá»‘ ban Ä‘áº§u. Má»—i thÃ nh phá»‘ chá»‰ Ä‘áº¿n má»™t láº§n, khoáº£ng cÃ¡ch tá»« má»™t thÃ nh phá»‘ Ä‘áº¿n cÃ¡c thÃ nh phá»‘ khÃ¡c lÃ  xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c. HÃ£y tÃ¬m má»™t chu trÃ¬nh (má»™t Ä‘Æ°á»ng Ä‘i khÃ©p kÃ­n thá»a mÃ£n Ä‘iá»u kiá»‡n trÃªn) sao cho tá»•ng Ä‘á»™ dÃ i cÃ¡c cáº¡nh lÃ  nhá» nháº¥t.\nCÃ³ ráº¥t nhiá»u cÃ¡ch Ä‘á»ƒ giáº£i bÃ i toÃ¡n nÃ y, cÃ¡c báº¡n Ä‘á»c cÃ³ thá»ƒ search google Ä‘á»ƒ tÃ¬m thÃªm cÃ¡ch giáº£i khÃ¡c, á»Ÿ Ä‘Ã¢y, mÃ¬nh sáº½ trÃ¬nh bÃ y cÃ¡ch sá»­ dá»¥ng thÆ° viá»‡n mlrose cá»§a python Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n trÃªn.\nCÃ i Ä‘áº·t chÆ°Æ¡ng trÃ¬nh vÃ  thá»±c thi ChÃºng ta giáº£ Ä‘á»‹nh ráº±ng ngÆ°á»i giao hÃ ng sáº½ Ä‘i qua 5 thÃ nh phá»‘, vÃ  má»—i thÃ nh phá»‘ sáº½ cÃ³ 2 giÃ¡ trá»‹ x vÃ  y tÆ°Æ¡ng á»©ng vá»›i toáº¡ Ä‘á»™ cá»§a cÃ¡c thÃ nh phá»‘ Ä‘Ã³ trÃªn báº£n Ä‘á»“.\n1input = [ 2[9, 12], 3[24, 15], 4[12 ,30], 5[4 ,3], 6[13, 27], 7] Theo pháº§n trÆ°á»›c, chÃºng ta sáº½ xÃ¢y dá»±ng 4 pháº§n\nXÃ¢y dá»±ng vector state ÄÆ¡n giáº£n lÃ  má»™t vector x cÃ³ sá»‘ lÆ°á»£ng pháº§n tá»­ báº±ng sá»‘ lÆ°á»£ng thÃ nh phá»‘ mÃ  ngÆ°á»i giao hÃ ng sáº½ viáº¿t thÄƒm\nx = [x0,x1,2,x3,x4], trong Ä‘Ã³, giÃ¡ trá»‹ x1 lÃ  chá»‰ sá»‘ cá»§a thÃ nh phá»‘ ngÆ°á»i giao hÃ ng sáº½ ghÃ© Ä‘áº§u tiÃªn, x0 lÃ  toáº¡ Ä‘á»™ thÃ nh phá»‘ báº¯t Ä‘áº§u\nXÃ¢y dá»±ng hÃ m fitness function Má»¥c tiÃªu cá»§a bÃ i toÃ¡n lÃ  tÃ¬m Ä‘Æ°á»ng Ä‘i ngÄƒn nháº¥t, nÃªn chÃºng ta cÃ³ thá»ƒ dá»… dÃ ng xÃ¢y dá»±ng hÃ n fitness báº±ng cÃ¡ch tÃ­nh khoáº£ng cÃ¡ch euclide giá»¯a cÃ¡c thÃ nh phá»‘.\n1 2def fitness_fun(state): 3 distance = 0 4 5 for index in range(1, len(state)): 6 dist = np.linalg.norm(input[state[index-1]]-input[state[index]]) 7 8 distance = distance + dist 9 10 dist = np.linalg.norm(input[state[0]]-input[state[len(state)-1]]) 11 distance = distance + dist 12 13 return distance 14 15fitness_cust = mlrose.CustomFitness(fitness_fun,\u0026#39;tsp\u0026#39;) XÃ¡c Ä‘á»‹nh loáº¡i bÃ i toÃ¡n ÄÃ¢y lÃ  bÃ i toÃ¡n rá»i ráº¡c khÃ´ng láº·p, nÃªn ta sáº½ sá»­ dá»¥ng hÃ m TSPOpt, length = 5 do sá»‘ lÆ°á»£ng pháº§n tá»­ cá»§a state lÃ  5, maximize=False do bÃ i toÃ¡n tÃ¬m Ä‘Æ°á»ng Ä‘i ngáº¯n nháº¥t .\n1problem_fit = mlrose.TSPOpt(length = 5, fitness_fn = fitness_cust, 2 maximize=False) XÃ¡c Ä‘á»‹nh thuáº­t toÃ¡n tá»‘i Æ°u ChÃºng ta váº«n tiáº¿p tá»¥c sá»­ dá»¥ng thuáº­t toÃ¡n simulated_annealing nhÆ° trÆ°á»›c xem káº¿t quáº£ nhÆ° tháº¿ nÃ o\n1#Define decay schedule 2schedule = mlrose.ExpDecay() 3 4# Define initial state 5init_state = np.array([0, 1, 2, 3, 4]) 6 7# Set random seed 8np.random.seed(1) 9 10# Solve problem using simulated annealing 11best_state, best_fitness = mlrose.simulated_annealing(problem, schedule = schedule, 12 max_attempts = 10, max_iters = 500, 13 init_state = init_state) 14 15print(\u0026#39;The best state found is: \u0026#39;, best_state) 16print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) Káº¿t quáº£\n1The best state found is: [1 4 2 0 3] 2The fitness at the best state is: 71.30882356753094 ÄÃ¢y lÃ  káº¿t quáº£ tá»‘i Æ°u cá»§a bÃ i toÃ¡n.\nThá»­ thay báº±ng giáº£i thuáº­t di truyá»n GA, vá»›i tá»· lá»‡ Ä‘á»™t biáº¿n lÃ  0.2\n1best_state, best_fitness = mlrose.genetic_alg(problem,mutation_prob = 0.2) 2 3print(\u0026#39;The best state found is: \u0026#39;, best_state) 4print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) Káº¿t quáº£\n1 2The best state found is: [0 2 4 1 3] 3The fitness at the best state is: 71.30882356753094 Thá»­ thay Ä‘á»•i táº­p dá»¯ liá»‡u input cÃ³ nhiá»u sá»‘ pháº§n tá»­ hÆ¡n\n1input =[(1, 1), (4, 2), (5, 2), (6, 4), (4, 4), (3, 6), (1, 5), (2, 3)] Káº¿t quáº£\n1The best state found is: [3 4 5 6 7 0 1 2] 2The fitness at the best state is: 17.34261754766733 Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Feb 8, 2019","img":"","permalink":"/blog/2019-02-08-randomized-optimization-in-python-v1/","series":null,"tags":["cháº¥m Ä‘iá»ƒm cÃ´ng dÃ¢n","china","China social credit system","credit system"],"title":"Tá»‘i Æ¯u HoÃ¡ Ngáº«u NhiÃªn - BÃ i ToÃ¡n NgÆ°á»i Giao HÃ ng"},{"categories":null,"content":" BÃ i toÃ¡n tá»‘i Æ°u hoÃ¡ lÃ  gÃ¬ VÃ­ dá»¥ Táº¡i sao láº¡i dÃ¹ng Randomized Optimization? Giáº£i bÃ i toÃ¡n tá»‘i Æ°u báº±ng thÆ° viá»‡n mlrose BÃ i toÃ¡n 8 háº­u Äá»‹nh nghÄ©a state Äá»‹nh nghÄ©a fitness funtion XÃ¡c Ä‘á»‹nh loáº¡i bÃ i toÃ¡n XÃ¡c Ä‘á»‹nh thuáº­t toÃ¡n tá»‘i Æ°u BÃ i toÃ¡n tá»‘i Æ°u hoÃ¡ lÃ  gÃ¬ Theo Russell and Norvig bÃ i toÃ¡n tá»‘i Æ°u hoÃ¡ lÃ  bÃ i toÃ¡n mÃ  \u0026ldquo;the aim is to find the best state according to an objective function\u0026rdquo; (mÃ¬nh xin phÃ©p Ä‘á»ƒ nguyÃªn cÃ¢u tiáº¿ng anh).\nTrong Ä‘Ã³, state trong tá»« best state phá»¥ thuá»™c vÃ o ngá»¯ cáº£nh cá»§a bÃ i toÃ¡n. VÃ­ dá»¥c\nTrong ngá»¯ cáº£nh lÃ  máº¡ng neural network, state chÃ­nh lÃ  cÃ¡c trá»ng sá»‘ (weight), best state lÃ  tÃ¬m cÃ¡c trá»ng sá»‘ tá»‘i Æ°u Trong bÃ i toÃ¡n 8 háº­u, state lÃ  vá»‹ trÃ­ cá»§a cÃ¡c con háº­u, best state lÃ  vá»‹ trÃ­ tá»‘t nháº¥t thoáº£ yÃªu cáº§u, cÅ©ng chÃ­nh lÃ  lá»i giáº£i. Trong bÃ i toÃ¡n ngÆ°á»i giao hÃ ng, state lÃ  cÃ¡c thÃ nh phá»‘ ngÆ°á»i giao hÃ ng Ä‘i qua. Trong bÃ i toÃ¡n tÃ´ mÃ u cho má»—i quá»‘c gia trÃªn báº£n Ä‘á»“, state lÃ  mÃ u Ä‘Æ°á»£c tÃ´ cho má»—i quá»‘c gia NÃ³i Ä‘áº¿n Ä‘Ã¢y, cÃ¡c báº¡n cháº¯c cÅ©ng Ä‘Ã£ hiá»ƒu Ä‘Æ°á»£c khÃ¡i niá»‡m state lÃ  gÃ¬ rá»“i. Äiá»u quan trá»ng á»Ÿ Ä‘Ã¢y lÃ  chÃºng ta cÃ³ thá»ƒ biá»ƒu diá»…n state dÆ°á»›i dáº¡ng má»™t con sá»‘, hoáº·c má»™t máº£ng cÃ¡c giÃ¡ trá»‹ sá»‘. (nghÄ©a lÃ  chÃºng ta pháº£i chuyá»ƒn Ä‘á»•i mÃ u, thÃ nh phá»‘, \u0026hellip; dÆ°á»›i dáº¡ng sá»‘) thÃ¬ má»›i cÃ³ thá»ƒ tÃ­nh toÃ¡n Ä‘Æ°á»£c.\nTá»« best trong chá»¯ best state Ä‘Æ°á»£c biá»ƒu diá»…n bá»Ÿi má»™t hÃ m toÃ¡n há»c (mÃ  chÃºng ta quen thuá»™c vá»›i cÃ¡c tá»« nhÆ° lÃ  objective funtion, fitness funtion, cost funtion, loss function , v.v). CÃ¡i mÃ  chÃºng ta muá»‘n lÃ  cá»±c Ä‘áº¡i hoáº·c cá»±c tiá»ƒu hoÃ¡ nÃ³ (Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c káº¿t quáº£ tá»‘t nháº¥t). HÃ m nÃ y nháº­n Ä‘áº§u vÃ o lÃ  state array vÃ  tráº£ vá» \u0026ldquo;fitness\u0026rdquo; value.\nCho nÃªn, chÃºng ta cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a Ä‘Æ¡n giáº£n bÃ i toÃ¡n tá»‘i Æ°u lÃ  viá»‡c tÃ¬m cÃ¡c giÃ¡ trá»‹ tá»‘i Æ°u Ä‘á»ƒ cá»±c Ä‘áº¡i/ cá»±c tiá»ƒu hoÃ¡ má»™t hÃ m toÃ¡n há»c.\nVÃ­ dá»¥ Má»™t vÃ­ dá»¥ xÃ m xÃ m nhÆ° sau\nTa cÃ³ má»™t (state) vector x = [x0,x1,x2,x3,x4] thuá»™c Ä‘oáº¡n [0,1] má»™t hÃ m f(x) = x0 + x1 + x2 + x3 + x4, tÃ¬m cÃ¡c giÃ¡ trá»‹ x Ä‘á»ƒ f Ä‘áº¡t cá»±c Ä‘áº¡i.\nRÃµ rÃ ng, báº±ng viá»‡c tÃ­nh nháº©m, chÃºng ta biáº¿t Ä‘Æ°á»£c ráº±ng giÃ¡ trá»‹ cá»±c Ä‘áº¡i cá»§a hÃ m trÃªn lÃ  5, vÃ  lá»i giáº£i cho bÃ i toÃ¡n trÃªn lÃ  x = [1,1,1,1,1].\nCÃ²n theo toÃ¡n há»c cáº¥p 3, ta sáº½ tÃ­nh Ä‘áº¡o hÃ m riÃªng pháº§n cá»§a tá»«ng pháº§n tá»­ (cÃ¡i nÃ y Ä‘Æ¡n giáº£n, mÃ¬nh khÃ´ng nháº¯c láº¡i), vÃ  cÅ©ng Ä‘áº¡t Ä‘Æ°á»£c x = [1,1,1,1,1]\nTáº¡i sao láº¡i dÃ¹ng Randomized Optimization? Trong bÃ i toÃ¡n á»Ÿ trÃªn, chÃºng ta cÃ³ thá»ƒ dá»… dÃ ng nháº©m Ä‘Æ°á»£c giÃ¡ trá»‹ tá»‘i Æ°u má»™t cÃ¡ch nhanh chÃ³ng. Tuy nhiÃªn, trong thá»±c táº¿, bÃ i toÃ¡n sáº½ khÃ³ hÆ¡n má»™t chÃºt, vÃ  cÃ³ nhiá»u hÃ m chÃºng ta khÃ´ng thá»ƒ dá»… dÃ ng tÃ¬m Ä‘Æ°á»£c giÃ¡ trá»‹ Ä‘áº¡o hÃ m má»™t cÃ¡ch nhanh chÃ³ng Ä‘Æ°á»£c (tá»‘n thá»i gian ráº¥t lÃ¢u Ä‘á»ƒ giáº£i bÃ i toÃ¡n ). LÃºc nÃ y, chÃºng ta sáº½ dÃ¹ng Randomized optimization.\nRandomized optimization sáº½ báº¯t Ä‘áº§u táº¡i má»™t Ä‘iá»ƒm ngáº«u nhiÃªn \u0026ldquo;best\u0026rdquo; state nÃ o Ä‘Ã³, sau Ä‘Ã³ sáº½ sinh ngáº«u nhiÃªn má»™t state khÃ¡c (thÆ°á»ng lÃ  lÃ¡ng giá»ng cá»§a \u0026ldquo;best\u0026rdquo; state hiá»‡n táº¡i). Náº¿u state má»›i Ä‘áº¡t giÃ¡ trá»‹ finest tá»‘t hÆ¡n \u0026ldquo;best\u0026rdquo; state hiá»‡n táº¡i thÃ¬ gÃ¡n \u0026ldquo;best\u0026rdquo; state báº±ng state má»›i. QuÃ¡ trÃ¬nh nÃ y láº·p Ä‘i láº·p láº¡i cho Ä‘áº¿n khi khÃ´ng thá»ƒ tÃ¬m Ä‘Æ°á»£c state má»›i nÃ y tá»‘t hÆ¡n \u0026ldquo;best\u0026rdquo; state hiá»‡n táº¡i.\nKhÃ´ng cÃ³ gÃ¬ báº£o Ä‘áº£m ráº±ng randomized optimization sáº½ tÃ¬m Ä‘Æ°á»£c lá»i giáº£i tá»‘i Æ°u. VÃ­ dá»¥ nhÆ° hÃ¬nh trÃªn, thuáº­t toÃ¡n chá»‰ cÃ³ thá»ƒ dá»«ng á»Ÿ local maximin, rá»“i Ä‘á»©ng yÃªn á»Ÿ Ä‘Ã³. Tuy nhiÃªn, náº¿u chÃºng ta thiáº¿t láº­p sá»‘ láº§n láº·p Ä‘á»§ lá»›n, thuáº­t toÃ¡n thÃ´ng thÆ°á»ng sáº½ tráº£ vá» káº¿t quáº£ tá»‘t hÆ¡n.\ná» Ä‘Ã¢y, chÃºng ta cÃ³ má»™t sá»± Ä‘Ã¡nh Ä‘á»•i trade-off giá»¯a thá»i gian tÃ¬m ra lá»i giáº£i tá»‘i Æ°u vÃ  cháº¥t lÆ°á»£ng cá»§a lá»i giáº£i.\nGiáº£i bÃ i toÃ¡n tá»‘i Æ°u báº±ng thÆ° viá»‡n mlrose Äá»ƒ giáº£i bÃ i toÃ¡n tá»‘i Æ°u báº±ng thÆ° viá»‡n mlrose, chÃºng ta sáº½ pháº£i Ä‘á»‹nh nghÄ©a 4 thá»©:\nÄá»‹nh nghÄ©a state vector Äá»‹nh nghÄ©a hÃ m fitness function XÃ¡c Ä‘á»‹nh loáº¡i bÃ i toÃ¡n Chá»n má»™t thuáº­t toÃ¡n tá»‘i Æ°u hoÃ¡ ngáº«u nhiÃªn Ä‘á»ƒ cháº¡y. Äá»ƒ Ä‘Æ¡n giáº£n, chÃºng ta sáº½ giáº£i quyáº¿t bÃ i toÃ¡n 8 háº­u báº±ng thÆ° viá»‡n mlrose.\nBÃ i toÃ¡n 8 háº­u Nháº¯c láº¡i má»™t chÃºt vá» bÃ i toÃ¡n 8 háº­u. Trong bÃ n cá» vua cÃ³ kÃ­ch thÆ°á»›c 8x8, chÃºng ta pháº£i chá»n vá»‹ trÃ­ Ä‘áº·t 8 con háº­u sao cho trÃªn má»—i dÃ²ng, cá»™t vÃ  Ä‘Æ°á»ng chÃ©o cá»§a má»™t con háº­u báº¥t ká»³ Ä‘ang Ä‘á»©ng khÃ´ng giÃ¡p máº·t vá»›i con háº­u khÃ¡c.\nÄá»‹nh nghÄ©a state ÄÃ¢y rÃµ rÃ ng lÃ  bÃ i toÃ¡n tá»‘i Æ°u, vÃ  bÆ°á»›c Ä‘áº§u tiÃªn ta sáº½ Ä‘á»‹nh nghÄ©a má»™t vector tráº¡ng thÃ¡i x = [x0, x1, x2, x3, x4, x5, x6, x7], quy Æ°á»›c toáº¡ Ä‘á»™ 0,0 lÃ  vá»‹ trÃ­ trÃ¡i dÆ°á»›i. GiÃ¡ trá»‹ cá»§a xi lÃ  vá»‹ trá»‹ cá»™t cá»§a con háº­u dÃ²ng i Ä‘ang Ä‘á»©ng.\nVÃ­ dá»¥, á»Ÿ hÃ¬nh trÃªn, ta cÃ³ x = [6, 1, 7, 5, 0, 2, 3, 4], vá»›i x0 = 6 nghÄ©a lÃ  con háº­u Ä‘ang á»Ÿ cá»™t 0 dÃ²ng 6 (gÃ³c toáº¡ Ä‘á»™ chÃºng ta kháº£o sÃ¡t lÃ  trÃ¡i dÆ°á»›i)\nHÃ¬nh trÃªn khÃ´ng pháº£i lÃ  lá»i giáº£i tá»‘i Æ°u cho bÃ i toÃ¡n, vÃ¬ con háº­u á»Ÿ cá»™t 5, cá»™t 6 vÃ  cá»™t 7 giÃ¡p máº·t nhau theo Ä‘Æ°á»ng chÃ©o.\nÄá»‹nh nghÄ©a fitness funtion Trong thÆ° viá»‡n mlrose Ä‘Ã£ Ä‘á»‹nh nghÄ©a sáºµn hÃ m fitness function cho má»™t sá»‘ bÃ i toÃ¡n Ä‘Æ¡n giáº£n, vÃ­ dá»¥ nhÆ° trong bÃ i toÃ¡n 8 háº­u vá»«a rá»“i. Tuy nhiÃªn, chÃºng ta sáº½ khÃ´ng sá»­ dá»¥ng hÃ m cÃ³ sáºµn Ä‘Ã³, mÃ  sáº½ tá»± viáº¿t má»™t hÃ m fitness riÃªng. CÃ³ nhiá»u cÃ¡ch Ä‘á»ƒ Ä‘á»‹nh nghÄ©a hÃ m fitness khÃ¡c nhau cho bÃ i toÃ¡n nÃ y. á» Ä‘ay, chÃºng ta sáº½ xÃ¢y dá»±ng má»™t hÃ m cÃ³ input lÃ  vá»‹ trÃ­ cá»§a cÃ¡c con háº­u output lÃ  má»™t con sá»‘ thÃ´ng bÃ¡o sá»‘ lÆ°á»£ng con háº­u khÃ´ng giÃ¡p nhau. Náº¿u sá»‘ lÆ°á»£ng lÃ  8 thÃ¬ input chÃ­nh lÃ  lá»i giáº£i cá»§a bÃ i toÃ¡n.\n1# Define alternative N-Queens fitness function for maximization problem 2def queens_max(state): 3 4 # Initialize counter 5 fitness = 0 6 7 # For all pairs of queens 8 for i in range(len(state) - 1): 9 for j in range(i + 1, len(state)): 10 11 # Check for horizontal, diagonal-up and diagonal-down attacks 12 if (state[j] == state[i]) \\ 13 or (state[j] == state[i] + (j - i)) \\ 14 or (state[j] == state[i] - (j - i)): 15 16 # If no attacks, then increment counter 17 fitness += 1 18 break 19 20 21 return fitness 22 23fitness_cust = mlrose.CustomFitness(queens_max) XÃ¡c Ä‘á»‹nh loáº¡i bÃ i toÃ¡n ThÆ° viá»‡n mlrose cung cáº¥p cho chÃºng ta cÃ¡c lá»›p Ä‘á»ƒ Ä‘á»‹nh nghÄ©a 3 loáº¡i bÃ i toÃ¡n tá»‘i Æ°u:\nDiscreteOpt: Lá»›p nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giáº£i cÃ¡c bÃ i toÃ¡n cÃ³ giÃ¡ trá»‹ tráº¡ng thÃ¡i lÃ  rá»i ráº¡c. VÃ  táº­p cÃ¡c tráº¡ng thÃ¡i sáº½ Ä‘Æ°á»£c cung cáº¥p trÆ°á»›c. Má»—i pháº§n tá»­ trong state chá»‰ nháº­n má»™t giÃ¡ trá»‹ trong táº­p tráº¡ng thÃ¡i. vÃ  má»—i pháº§n tá»­ trong táº­p tráº¡ng thÃ¡i chá»‰ thuá»™c vá» má»™t pháº§n tá»­ trong state.\nContinuousOpt: Lá»›p nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giáº£i cÃ¡c bÃ i toÃ¡n cÃ³ giÃ¡ trá»‹ tráº¡ng thÃ¡i lÃ  liÃªn tá»¥c.\nTSPOpt: Lá»›p nÃ y Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ giáº£i cÃ¡c bÃ i toÃ¡n vá» travelling. VÃ­ dá»¥ bÃ i toÃ¡n ngÆ°á»i giao hÃ ng. BÃ i toÃ¡n nÃ y khÃ¡c bÃ i toÃ¡n Discrete á»Ÿ chá»— chÃºng ta sáº½ pháº£i tÃ¬m ra thá»© tá»± tá»‘i Æ°u cá»§a cÃ¡c con sá»‘.\nBÃ i toÃ¡n 8 háº­u Ä‘Æ°á»£c xáº¿p vÃ o dáº¡ng bÃ i toÃ¡n tá»‘i Æ°u rá»i ráº¡c. Trong Ä‘Ã³, má»—i pháº§n tá»­ trong state vector chá»‰ mang má»™t con sá»‘ tá»« 0 Ä‘áº¿n 7.\n1 2problem = mlrose.DiscreteOpt(length = 8, fitness_fn = fitness, 3 maximize = False, max_val = 8) length chÃ­nh lÃ  sá»‘ lÆ°á»£ng pháº§n tá»­ trong state vector ( chÃºng ta cÃ³ 8 cá»™t nÃªn length = 8), max_val = 8 (Ä‘Ã£ nÃ³i á»Ÿ trÃªn, giÃ¡ trá»‹ tá»‘i Æ°u lÃ  khi 8 con háº­u khÃ´ng giÃ¡p máº·t nhau). Do bÃ i toÃ¡n cá»§a mÃ¬nh lÃ  cá»±c tiá»ƒu (lÃ½ do lÃ  fitness = 0 thÃ¬ khÃ´ng cÃ³ con háº­u nÃ o giÃ¡p máº·t nhau, nÃªn chÃºng ta set maximize = False)\nXÃ¡c Ä‘á»‹nh thuáº­t toÃ¡n tá»‘i Æ°u ThÆ° viá»‡n mlrose cung cáº¥p cho chÃºng ta cÃ¡c thuáº­t toÃ¡n nhÆ° leo Ä‘á»“i (hill climbing), leo Ä‘á»“i ngáº«u nhiÃªn (stochastic hill climbing),simulated annealing, thuáº­t giáº£i di truyá»n (genetic algorithm), MIMIC (Mutual-Information-Maximizing Input Clustering). Vá»›i dáº¡ng bÃ i toÃ¡n rá»i ráº¡c vÃ  travelling, chÃºng ta cÃ³ thá»ƒ chá»n báº¥t ká»³ thuáº­t toÃ¡n tá»‘i Æ°u nÃ o. Vá»›i bÃ i toÃ¡n liÃªn tá»¥c, thÃ¬ thuáº­t toÃ¡n MIMIC khÃ´ng há»— trá»£.\nVÃ­ dá»¥, chÃºng ta sáº½ sá»­ dá»¥ng simulated annealing Ä‘á»ƒ mÃ´ phá»ng hÃ m tá»‘i Æ°u, vá»›i tráº¡ng thÃ¡i init lÃ  x = [1,2,3,4,5,6,7], láº·p 1000 láº§n Ä‘á»ƒ tÃ¬m tráº¡ng thÃ¡i tá»‘t nháº¥t. CÃ³ 10 láº§n thá»­. Ä‘á»ƒ tÃ¬m hÃ ng xÃ³m tá»‘t nháº¥t trong má»—i láº§n láº·p.\n1# Define decay schedule 2schedule = mlrose.ExpDecay() 3 4# Define initial state 5init_state = np.array([0, 1, 2, 3, 4, 5, 6, 7]) 6 7# Set random seed 8np.random.seed(1) 9 10# Solve problem using simulated annealing 11best_state, best_fitness = mlrose.simulated_annealing(problem, schedule = schedule, 12 max_attempts = 10, max_iters = 1000, 13 init_state = init_state) 14 15print(\u0026#39;The best state found is: \u0026#39;, best_state) 16print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) Káº¿t quáº£\n1The best state found is: [0 7 6 4 7 1 3 5] 2The fitness at the best state is: 1.0 Do best state =1 , nÃªn cÃ³ 2 con háº­u cÃ³ thá»ƒ nhÃ¬n tháº¥y vÃ  táº¥n cÃ´ng nhau, ChÃºng ta sáº½ thá»­ thay dá»•i sá»‘ max_attempts =10 thÃ nh max_attempts = 50 xem sao.\n1 2The best state found is: [2 0 6 4 7 1 3 5] 3The fitness at the best state is: 0.0 Thá»­ thay báº±ng bÃ i toÃ¡n 12 háº­u\n1import mlrose 2 3import numpy as np 4 5# Define alternative N-Queens fitness function for maximization problem 6def queens_max(state): 7 8 # Initialize counter 9 fitness = 0 10 11 # For all pairs of queens 12 for i in range(len(state) - 1): 13 for j in range(i + 1, len(state)): 14 15 # Check for horizontal, diagonal-up and diagonal-down attacks 16 if (state[j] == state[i]) \\ 17 or (state[j] == state[i] + (j - i)) \\ 18 or (state[j] == state[i] - (j - i)): 19 20 # If no attacks, then increment counter 21 fitness += 1 22 break 23 24 25 return fitness 26 27fitness_cust = mlrose.CustomFitness(queens_max) 28 29problem = mlrose.DiscreteOpt(length = 12, fitness_fn = fitness_cust, maximize = False, max_val = 12) 30 31 32# Define decay schedule 33schedule = mlrose.ExpDecay() 34 35# Define initial state 36init_state = np.array([0, 1, 2, 3, 4, 5, 6, 7,8,9,10,11]) 37 38# Set random seed 39np.random.seed(1) 40 41# Solve problem using simulated annealing 42best_state, best_fitness = mlrose.simulated_annealing(problem, schedule = schedule, 43 max_attempts = 100, max_iters = 5000, 44 init_state = init_state) 45 46print(\u0026#39;The best state found is: \u0026#39;, best_state) 47print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) 48`` 49 50Káº¿t quáº£ 51 52```python 53The best state found is: [ 8 10 3 6 0 9 1 5 2 11 7 4] 54The fitness at the best state is: 0.0 Táº¥t nhiÃªn, á»Ÿ trÃªn chá»‰ lÃ  1 trong sá»‘ cÃ¡c lá»i giáº£i cá»§a bÃ i toÃ¡n trÃªn, chÃºng ta cÃ²n cÃ³ nhiá»u lá»i giáº£i khÃ¡c, do bÃ i toÃ¡n cÃ³ nhiá»u nghiá»‡m.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Feb 8, 2019","img":"","permalink":"/blog/2019-02-08-getting-started-with-randomized-optimization-in-python/","series":null,"tags":["tá»‘i Æ°u hÃ³a ngáº«u nhiÃªn","mlrose"],"title":"Tá»‘i Æ¯u HoÃ¡ Ngáº«u NhiÃªn"},{"categories":null,"content":" 1. Cáº¥m bay mÃ¡y bay hoáº·c Ä‘i tÃ u Ä‘iá»‡n ngáº§m 2. Äiá»u chá»‰nh tá»‘c Ä‘á»™ internet 3. Cáº¥m báº¡n, hoáº·c con cÃ¡i cá»§a báº¡n Ä‘Æ°á»£c há»c á»Ÿ nhá»¯ng trÆ°á»ng tá»‘t 4. KhÃ´ng cho báº¡n cÃ³ má»™t cÃ´ng viá»‡c tá»‘t 5. KhÃ´ng Ä‘Æ°á»£c thuÃª nhá»¯ng khÃ¡ch sáº¡n tá»‘t 6. Cáº¥m nuÃ´i chÃ³ 7. Bá»‹ bÃªu tÃªn trÆ°á»›c cÃ´ng chÃºng ChÃ­nh quyá»n Trung Quá»‘c Ä‘ang xÃ¢y dá»±ng má»™t há»‡ thá»‘ng xáº¿p háº¡ng cÃ³ tÃªn lÃ  \u0026quot; Há»‡ thá»‘ng tÃ­n dá»¥ng xÃ£ há»™i - social credit system\u0026quot;. Há»‡ thá»‘ng Ä‘Æ°á»£c xÃ¢y dá»±ng nháº±m má»¥c Ä‘Ã­ch theo dÃµi hÃ nh vi cá»§a cÃ´ng dÃ¢n vÃ  xáº¿p háº¡ng táº¥t cáº£ cÃ¡c hÃ nh vi trÃªn.\nTheo má»™t tÃ i liá»‡u cho biáº¿t,\u0026ldquo;Há»‡ thá»‘ng tÃ­n dá»¥ng xÃ£ há»™i\u0026rdquo;, láº§n Ä‘áº§u tiÃªn Ä‘Æ°á»£c cÃ´ng bá»‘ vÃ o nÄƒm 2014, nháº±m má»¥c Ä‘Ã­ch cá»§ng cá»‘ Ã½ tÆ°á»Ÿng ráº±ng \u0026ldquo;giá»¯ niá»m tin lÃ  vinh quang vÃ  phÃ¡ vá»¡ niá»m tin lÃ  Ã´ nhá»¥c\u0026rdquo;.\nHá»‡ thá»‘ng sáº½ Ä‘Æ°á»£c váº­n hÃ nh hoÃ n toÃ n trÃªn toÃ n quá»‘c vÃ o nÄƒm 2020, nhÆ°ng Ä‘Ã£ Ä‘Æ°á»£c thÃ­ Ä‘iá»ƒm á»Ÿ má»™t sá»‘ vÃ¹ng trÃªn Ä‘áº¥t nÆ°á»›c, vÃ  mang láº¡i káº¿t quáº£ khÃ¡ kháº£ quan.\nTáº¡i thá»i Ä‘iá»ƒm hiá»‡n táº¡i, há»‡ thá»‘ng Ä‘ang Ä‘Æ°á»£c Ä‘iá»u hÃ nh bá»Ÿi chÃ­nh phá»§, má»™t sá»‘ cÃ´ng ty tÆ° nhÃ¢n cÅ©ng Ä‘Æ°á»£c cáº¥p phÃ©p tham gia xÃ¢y dá»±ng vÃ  phÃ¡t triá»ƒn há»‡ thá»‘ng, nhÆ° alibaba, tencent.\nGiá»‘ng nhÆ° Ä‘iá»ƒm tÃ­n dá»¥ng tÆ° nhÃ¢n, Ä‘iá»ƒm xÃ£ há»™i cá»§a má»™t ngÆ°á»i cÃ³ thá»ƒ Ä‘i lÃªn xuá»‘ng tÃ¹y theo hÃ nh vi cá»§a há». CÃ¡ch thá»©c tÃ­nh Ä‘iá»ƒm vÃ  cÃ¡c hÃ nh vi Ä‘Æ°á»£c cho lÃ  tá»‘t/xáº¥u hiá»‡n thá»i váº«n chÆ°a Ä‘Æ°á»£c cÃ´ng bá»‘. NhÆ°ng cÃ¡c vÃ­ dá»¥ vá» vi pháº¡m Ä‘Ã£ bá»‹ trá»« Ä‘iá»ƒm bao gá»“m lÃ¡i xe áº©u, hÃºt thuá»‘c trong khu vá»±c cáº¥m hÃºt thuá»‘c, mua quÃ¡ nhiá»u trÃ² chÆ¡i video vÃ  Ä‘Äƒng tin tá»©c giáº£ lÃªn máº¡ng.\n1. Cáº¥m bay mÃ¡y bay hoáº·c Ä‘i tÃ u Ä‘iá»‡n ngáº§m ChÃ­nh phá»§ Trung Quá»‘c Ä‘Ã£ báº¯t Ä‘áº§u trá»«ng pháº¡t ngÆ°á»i dÃ¢n báº±ng cÃ¡ch háº¡n cháº¿ viá»‡c Ä‘i láº¡i cá»§a há».\nChÃ­n triá»‡u ngÆ°á»i cÃ³ Ä‘iá»ƒm tháº¥p Ä‘Ã£ bá»‹ cháº·n mua vÃ© cho cÃ¡c chuyáº¿n bay ná»™i Ä‘á»‹a, Channel News Asia Ä‘Æ°a tin vÃ o 16/Mar/2018 nguá»“n https://www.channelnewsasia.com/news/asia/china-bad-social-credit-barred-from-buying-train-plane-tickets-10050390.\nNgÆ°á»i dÃ¢n cÅ©ng cÃ³ thá»ƒ bá»‹ giá»›i háº¡n sá»­ dá»¥ng cÃ¡c dá»‹ch vá»¥ nÃ¢ng cao, vÃ­ dá»¥ ba triá»‡u ngÆ°á»i khÃ´ng Ä‘Æ°á»£c mua vÃ© háº¡ng thÆ°Æ¡ng gia (trÃ­ch cÃ¹ng nguá»“n trÃªn).\nHere\u0026#39;s a dystopian vision of the future: A real announcement I recorded on the Beijing-Shanghai bullet train. (I\u0026#39;ve subtitled it so you can watch in silence.) pic.twitter.com/ZoRWtdcSMy\n\u0026mdash; James O\u0026#39;Malley (@Psythor) October 29, 2018 video trÃªn, Ä‘Æ°á»£c Ä‘Äƒng bá»Ÿi nhÃ  bÃ¡o James O\u0026rsquo;Malley, cho tháº¥y má»™t thÃ´ng bÃ¡o trÃªn má»™t chuyáº¿n tÃ u cao tá»‘c tá»« Báº¯c Kinh Ä‘áº¿n ThÆ°á»£ng Háº£i cáº£nh bÃ¡o má»i ngÆ°á»i khÃ´ng nÃªn cÃ³ nhá»¯ng hÃ nh vi sai trÃ¡i - náº¿u khÃ´ng thÃ¬ \u0026ldquo;hÃ nh vi cá»§a há» sáº½ Ä‘Æ°á»£c ghi láº¡i trong há»‡ thá»‘ng thÃ´ng tin tÃ­n dá»¥ng cÃ¡ nhÃ¢n\u0026rdquo;.\n2. Äiá»u chá»‰nh tá»‘c Ä‘á»™ internet Theo nghiÃªn cá»©u cá»§a Rachel Botsman (nguá»“n https://www.wired.co.uk/article/chinese-government-social-credit-score-privacy-invasion) chÃ­nh quyá»n sáº½ giá»›i háº¡n tá»‘c Ä‘á»™, bÄƒng thÃ´ng cá»§a cÃ¡c dá»‹ch vá»¥ internet, 3G, 4G, \u0026hellip; cá»§a nhá»¯ng cÃ´ng dÃ¢n cÃ³ Ä‘iá»ƒm tÃ­nh dá»¥ng xÃ£ há»™i tháº¥p.\nTrong nghiÃªn cá»©u cá»§a tÃ¡c giáº£, má»™t sá»‘ hÃ nh vi sáº½ bá»‹ trá»«ng pháº¡t, bao gá»“m:\nCÃ´ng dÃ¢n cÃ³ thanh toÃ¡n hÃ³a Ä‘Æ¡n Ä‘Ãºng háº¡n hay khÃ´ng. DÃ nh quÃ¡ nhiá»u thá»i gian Ä‘á»ƒ chÆ¡i trÃ² chÆ¡i video LÃ£ng phÃ­ tiá»n mua hÃ ng tÃ o lao vÃ  Ä‘Äƒng lÃªn phÆ°Æ¡ng tiá»‡n truyá»n thÃ´ng xÃ£ há»™i (dáº¡ng nhÆ° tá»± sÆ°á»›ng á»Ÿ Viá»‡t Nam mÃ¬nh Ã¡). Truyá»n bÃ¡ tin tá»©c giáº£ máº¡o, cá»¥ thá»ƒ lÃ  vá» cÃ¡c cuá»™c táº¥n cÃ´ng khá»§ng bá»‘ hoáº·c an ninh sÃ¢n bay. 3. Cáº¥m báº¡n, hoáº·c con cÃ¡i cá»§a báº¡n Ä‘Æ°á»£c há»c á»Ÿ nhá»¯ng trÆ°á»ng tá»‘t Theo Beijing News reported(nguá»“n http://www.bjnews.com.cn/news/2018/03/19/479533.html), 17 ngÆ°á»i Ä‘Ã£ tá»« chá»‘i thá»±c hiá»‡n nghÄ©a vá»¥ quÃ¢n sá»± vÃ o nÄƒm ngoÃ¡i (2017) Ä‘Ã£ bá»‹ cáº¥m Ä‘Äƒng kÃ½ vÃ o giÃ¡o dá»¥c Ä‘áº¡i há»c, ná»™p Ä‘Æ¡n vÃ o trÆ°á»ng trung há»c hoáº·c tiáº¿p tá»¥c viá»‡c há»c táº­p cá»§a há».\nTheo nguá»“n https://www.businessinsider.com/china-social-credit-affects-childs-university-enrolment-2018-7?r=UK, vÃ o thÃ¡ng 7/2018, má»™t trÆ°á»ng Ä‘áº¡i há»c á»Ÿ Trung Quá»‘c, Ä‘Ã£ cáº¥m má»™t sinh viÃªn nháº­p há»c (dÃ¹ anh áº¥y Ä‘Ã£ thi Ä‘áº­u), vÃ¬ lÃ½ do lÃ  Ä‘iá»ƒm tÃ­n dá»¥ng xÃ£ há»™i cá»§a bá»‘ anh áº¥y \u0026ldquo;xáº¥u\u0026rdquo;.\n4. KhÃ´ng cho báº¡n cÃ³ má»™t cÃ´ng viá»‡c tá»‘t Theo nguá»“n cá»§a Botsman, cÃ¡c cÃ¡ nhÃ¢n cÃ³ Ä‘iá»ƒm tÃ­n nhiá»‡m tháº¥p sáº½ bá»‹ cáº¥m lÃ m quáº£n lÃ½ á»Ÿ cÃ¡c cÃ´ng ty nhÃ  nÆ°á»›c, cÃ¡c ngÃ¢n hÃ ng lá»›n.\nCÃ¡c hÃ nh vi nhÆ° gian láº­n thuáº¿, tham Ã´, \u0026hellip; cÅ©ng áº£nh hÆ°á»Ÿng Ä‘áº¿n Ä‘iá»ƒm xÃ£ há»™i.\n5. KhÃ´ng Ä‘Æ°á»£c thuÃª nhá»¯ng khÃ¡ch sáº¡n tá»‘t Theo Botsman, nhá»¯ng ngÆ°á»i gian láº­n nghÄ©a vá»¥ quÃ¢n sá»± sáº½ bá»‹ cáº¥m thuÃª khÃ¡ch sáº¡n tá»‘t khi Ä‘i du lá»‹ch.\nNhá»¯ng cÃ´ng dÃ¢n cÃ³ Ä‘iá»ƒm tÃ­n dá»¥ng tá»‘t sáº½ Ä‘Æ°á»£c thuÃª khÃ¡ch sáº¡n mÃ  khÃ´ng cáº§n pháº£i Ä‘áº·t cá»c, cÃ³ thá»ƒ kÃ©o dÃ i thá»i gian du lá»‹ch hÆ¡n.\n6. Cáº¥m nuÃ´i chÃ³ ThÃ nh phá»‘ Táº¿ Nam Ä‘Ã£ báº¯t Ä‘áº§u thá»±c thi má»™t há»‡ thá»‘ng tÃ­n dá»¥ng xÃ£ há»™i cho cÃ¡c chá»§ sá»Ÿ há»¯u chÃ³ vÃ o nÄƒm 2017. Theo Ä‘Ã³, chá»§ váº­t nuÃ´i sáº½ bá»‹ trá»« Ä‘iá»ƒm náº¿u nuÃ´i chÃ³ mÃ  khÃ´ng xÃ­ch, khÃ´ng rá» mÃµm, hoáº·c Ä‘á»ƒ cho chÃ³ Ä‘i báº­y nÆ¡i cÃ´ng cá»™ng.\nNhá»¯ng ngÆ°á»i bá»‹ zero Ä‘iá»ƒm sáº½ bá»‹ cáº¥m nuÃ´i chÃ³, con váº­t sáº½ bá»‹ tá»‹ch thu, ngÆ°á»i sá»Ÿ há»¯u pháº£i lÃ m bÃ i kiá»ƒm tra. Nguá»“n http://uk.businessinsider.com/china-dog-owners-social-credit-score-2018-10\n7. Bá»‹ bÃªu tÃªn trÆ°á»›c cÃ´ng chÃºng ChÃ­nh phá»§ Ä‘Ã£ vÃ  Ä‘ang xÃ¢y dá»±ng má»™t danh sÃ¡ch cÃ¡c cÃ¡ nhÃ¢n cÃ³ Ä‘iá»ƒm tÃ­n nhiá»‡m xáº¥u vÃ  sáºµn sÃ ng Ä‘Äƒng tÃªn kÃ¨m hÃ¬nh áº£nh cá»§a há» trÃªn cÃ¡c phÆ°Æ¡ng tiá»‡n thÃ´ng tin Ä‘áº¡i chÃºng. CÃ¡c cÃ´ng ty cÅ©ng Ä‘Æ°á»£c khuyáº¿n khÃ­ch tham kháº£o cÃ¡c thÃ´ng tin cá»§a cÃ´ng dÃ¢n trong há»‡ thá»‘ng trÆ°á»›c khi thuÃª há».\nÄÆ°á»£c biáº¿t, toÃ  Ã¡n sáº½ thÃ´ng bÃ¡o cho cÃ´ng dÃ¢n vá» hÃ nh vi cá»§a há» trÆ°á»›c khi tÃªn cá»§a há» Ä‘Æ°á»£c Ä‘Æ°a vÃ o danh sÃ¡ch Ä‘en. CÃ´ng dÃ¢n cÃ³ 10 ngÃ y khÃ¡ng cÃ¡o ká»ƒ tá»« khi nháº­n Ä‘Æ°á»£c thÃ´ng bÃ¡o.\nNguá»“n https://www.hrw.org/news/2017/12/12/chinas-chilling-social-credit-blacklist, http://zxgk.court.gov.cn/\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Feb 7, 2019","img":"","permalink":"/blog/2019-02-07-china-social-creadit-system/","series":null,"tags":["cháº¥m Ä‘iá»ƒm cÃ´ng dÃ¢n","china","China social credit system","credit system"],"title":"Há»‡ Thá»‘ng TÃ­n Dá»¥ng XÃ£ Há»™i Cá»§a Trung Quá»‘c - Nhá»¯ng áº¢nh HÆ°á»Ÿng Khi Báº¡n CÃ³ Äiá»ƒm XÃ£ Há»™i Tháº¥p"},{"categories":null,"content":" Má»Ÿ Ä‘áº§u Cháº©n bá»‹ dá»¯ liá»‡u XÃ¢y dá»±ng mÃ´ hÃ¬nh Má»Ÿ Ä‘áº§u Cháº©n bá»‹ dá»¯ liá»‡u XÃ¢y dá»±ng mÃ´ hÃ¬nh Má»Ÿ Ä‘áº§u Viá»‡c xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh machine learning chÆ°a bao giá» tháº­t sá»± dá»… dÃ ng. Ráº¥t nhiá»u bÃ i bÃ¡o chá»‰ \u0026ldquo;show hÃ ng\u0026rdquo; nhá»¯ng thá»© cao siÃªu, nhá»¯ng thá»© chá»‰ náº±m trong sá»± tÆ°á»Ÿng tÆ°á»£ng cá»§a chÃ­nh cÃ¡c nhÃ  bÃ¡o. CÃ²n khi Ä‘á»c cÃ¡c bÃ i bÃ¡o khoa há»c vá» machine learning, tÃ¡c giáº£ cÃ´ng bá»‘ cho chÃºng ta nhá»¯ng mÃ´ hÃ¬nh ráº¥t tá»‘t, giáº£i quyáº¿t má»™t domain nhá» váº¥n Ä‘á» cá»§a há». Tuy nhiÃªn, cÃ³ má»™t thá»© há» khÃ´ng/ chÆ°a cÃ´ng bá»‘. ÄÃ³ lÃ  cÃ¡ch thá»©c há» lá»±a chá»n sá»‘ lÆ°á»£ng note áº©n, sá»‘ lÆ°á»£ng layer trong mÃ´ hÃ¬nh neural network. Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ xÃ¢y dá»±ng mÃ´ hÃ¬nh LSTM Ä‘Æ¡n giáº£n Ä‘á»ƒ dá»± Ä‘oÃ¡n giá»›i tÃ­nh khi biáº¿t tÃªn má»™t ngÆ°á»i, vÃ  thá»­ tÃ¬m xem cÃ´ng thá»©c Ä‘á»ƒ chá»n ra tham sá»‘ \u0026ldquo;Ä‘á»§ tá»‘t\u0026rdquo; lÃ  nhÆ° tháº¿ nÃ o.\nCháº©n bá»‹ dá»¯ liá»‡u Táº­p dá»¯ liá»‡u á»Ÿ Ä‘Ã¢y cÃ³ khoáº£ng 500000 tÃªn kÃ¨m giá»›i tÃ­nh. Äáº§u tiÃªn mÃ¬nh sáº½ lÃ m sáº¡ch dá»¯ liá»‡u báº±ng cÃ¡ch chá»‰ láº¥y giá»›i tÃ­nh lÃ  \u0026rsquo;m\u0026rsquo; vÃ  \u0026lsquo;f\u0026rsquo;, loáº¡i bá» nhá»¯ng tÃªn quÃ¡ ngáº¯n (cÃ³ Ã­t hÆ¡n 3 kÃ½ tá»±)\n1filepath = \u0026#39;firstnames.csv\u0026#39; 2max_rows = 500000 # Reduction due to memory limitations 3 4df = (pd.read_csv(filepath, usecols=[\u0026#39;name\u0026#39;, \u0026#39;gender\u0026#39;],sep=\u0026#34;;\u0026#34;) 5 .dropna(subset=[\u0026#39;name\u0026#39;, \u0026#39;gender\u0026#39;]) 6 .assign(name = lambda x: x.name.str.strip()) 7 .assign(gender = lambda x: x.gender.str.lower()) 8 .head(max_rows)) 9 10df= df[df.gender.isin([\u0026#39;m\u0026#39;,\u0026#39;f\u0026#39;])] 11 12# In the case of a middle name, we will simply use the first name only 13df[\u0026#39;name\u0026#39;] = df[\u0026#39;name\u0026#39;].apply(lambda x: str(x).split(\u0026#39; \u0026#39;, 1)[0]) 14 15# Sometimes people only but the first letter of their name into the field, so we drop all name where len \u0026lt;3 16df.drop(df[df[\u0026#39;name\u0026#39;].str.len() \u0026lt; 3].index, inplace=True) Tiáº¿p theo, chÃºng ta sá»­ dá»¥ng má»™t ká»¹ thuáº­t khÃ¡ cÅ© trong NLP lÃ  one-hot encoding. Má»—i kÃ½ tá»± Ä‘Æ°á»£c biá»ƒu diá»…n bá»Ÿi má»™t vector nhá»‹ phÃ¢n. VÃ­ dá»¥ cÃ³ 26 kÃ½ tá»± trong báº£ng chá»¯ cÃ¡i tiáº¿ng anh, vector Ä‘áº¡i diá»‡n cho chá»¯ a lÃ  [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], kÃ½ tá»± b Ä‘Æ°á»£c biá»ƒu diá»…n lÃ  [0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], \u0026hellip; tÆ°Æ¡ng tá»± cho Ä‘áº¿n z.\nMá»™t tá»« Ä‘Æ°á»£c encode lÃ  má»™t táº­p cÃ¡c vector. VÃ­ dá»¥ chá»¯ hello Ä‘Æ°á»£c biá»ƒu diá»…n lÃ \n1[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #h, 2 [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #e, 3 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #l, 4 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #l, 5 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #o] Äá»c Ä‘áº¿n Ä‘Ã¢y, cháº¯c cÃ¡c báº¡n Ä‘Ã£ mÆ°á»n tÆ°á»£ng ra ráº±ng má»™t tá»« sáº½ Ä‘Æ°á»£c encode nhÆ° tháº¿ nÃ o rá»“i pháº£i khÃ´ng. Tiáº¿p theo, chÃºng ta sáº½ xÃ¢y dá»±ng hÃ m encode cho táº­p dá»¯ liá»‡u\n1# Define a mapping of chars to integers 2char_to_int = dict((c, i) for i, c in enumerate(accepted_chars)) 3int_to_char = dict((i, c) for i, c in enumerate(accepted_chars)) 4 5# Removes all non accepted characters 6def normalize(line): 7 return [c.lower() for c in line if c.lower() in accepted_chars] 8 9# Returns a list of n lists with n = word_vec_length 10def name_encoding(name): 11 12 # Encode input data to int, e.g. a-\u0026gt;1, z-\u0026gt;26 13 integer_encoded = [char_to_int[char] for i, char in enumerate(name) if i \u0026lt; word_vec_length] 14 15 # Start one-hot-encoding 16 onehot_encoded = list() 17 18 for value in integer_encoded: 19 # create a list of n zeros, where n is equal to the number of accepted characters 20 letter = [0 for _ in range(char_vec_length)] 21 letter[value] = 1 22 onehot_encoded.append(letter) 23 24 # Fill up list to the max length. Lists need do have equal length to be able to convert it into an array 25 for _ in range(word_vec_length - len(name)): 26 onehot_encoded.append([0 for _ in range(char_vec_length)]) 27 28 return onehot_encoded 29 30# Encode the output labels 31def lable_encoding(gender_series): 32 labels = np.empty((0, 2)) 33 for i in gender_series: 34 if i == \u0026#39;m\u0026#39;: 35 labels = np.append(labels, [[1,0]], axis=0) 36 else: 37 labels = np.append(labels, [[0,1]], axis=0) 38 return labels VÃ  tiáº¿n hÃ nh chia táº­p dá»¯ liá»‡u thÃ nh train, val, vÃ  test set\n1 2# Split dataset in 60% train, 20% test and 20% validation 3train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))]) 4 5# Convert both the input names as well as the output lables into the discussed machine readable vector format 6train_x = np.asarray([np.asarray(name_encoding(normalize(name))) for name in train[predictor_col]]) 7train_y = lable_encoding(train.gender) 8 9validate_x = np.asarray([name_encoding(normalize(name)) for name in validate[predictor_col]]) 10validate_y = lable_encoding(validate.gender) 11 12test_x = np.asarray([name_encoding(normalize(name)) for name in test[predictor_col]]) 13test_y = lable_encoding(test.gender) Váº­y lÃ  chÃºng ta Ä‘Ã£ cÃ³ chuáº©n bá»‹ xong dá»¯ liá»‡u Ä‘áº§y Ä‘á»§ rá»“i Ä‘Ã³. BÃ¢y giá» chÃºng ta xÃ¢y dá»±ng mÃ´ hÃ¬nh thÃ´i.\nXÃ¢y dá»±ng mÃ´ hÃ¬nh CÃ³ ráº¥t nhiá»u cÃ¡ch Ä‘á»ƒ chá»n tham sá»‘ cho mÃ´ hÃ¬nh, vÃ­ dá»¥ nhÆ° á»Ÿ https://stats.stackexchange.com/questions/95495/guideline-to-select-the-hyperparameters-in-deep-learning liá»‡t kÃª ra 4 cÃ¡ch lÃ  Manual Search, Grid Search, Random Search, Bayesian Optimization. Tuy nhiÃªn, nhá»¯ng cÃ¡ch trÃªn Ä‘á»u khÃ¡ tá»‘n thá»i gian vÃ  Ä‘Ã²i há»i ngÆ°á»i ká»¹ sÆ° pháº£i cÃ³ am hiá»ƒu nháº¥t Ä‘á»‹nh.\ná» Ä‘Ã¢y, chÃºng ta sá»­ dá»¥ng má»™t cÃ´ng thá»©c Ä‘Æ°á»£c Ä‘Æ°a ra trong link https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw/136542#136542, cá»¥ thá»ƒ\n$$ N_h = \\frac{N_s}{(\\alpha * (N_i + N_o))}$$\nTrong Ä‘Ã³ Ni lÃ  sá»‘ lÆ°á»£ng input neural, No lÃ  sá»‘ lÆ°á»£ng output neural, Ns lÃ  sá»‘ lÆ°á»£ng element trong táº­p dá»¯ liá»‡u train. alpha lÃ  má»™t con sá»‘ trade-off Ä‘áº¡i diá»‡n cho tá»· lá»‡ thuá»™c Ä‘oáº¡n [2-10].\nMá»™t lÆ°u Ã½ á»Ÿ Ä‘Ã¢y lÃ  báº¡n cÃ³ thá»ƒ dá»±a vÃ o cÃ´ng thá»©c vÃ  sá»‘ alpha mÃ  Æ°á»›c lÆ°á»£ng xem ráº±ng báº¡n Ä‘Ã£ cÃ³ Ä‘á»§ dá»¯ liá»‡u máº«u hay chÆ°a. Má»™t vÃ­ dá»¥ Ä‘Æ¡n giáº£n lÃ  giáº£ sá»­ báº¡n cÃ³ 10,000 máº«u dá»¯ liá»‡u, input sá»‘ tá»« 0 Ä‘áº¿n 9, output lÃ  64, chá»n alpha á»Ÿ má»©c nhá» nháº¥t lÃ  2, váº­y theo cÃ´ng thá»©c sá»‘ neural áº©n lÃ  10000/(26410) = 7.8 ~ 8. Náº¿u báº¡n tÄƒng sá»‘ alpha lÃªn thÃ¬ sá»‘ hidden layer cÃ²n Ã­t ná»¯a. Äiá»u trÃªn chá»©ng tá» ráº±ng sá»‘ lÆ°á»£ng máº«u cá»§a báº¡n chÆ°a Ä‘á»§, cÃ²n thiáº¿u quÃ¡ nhiá»u. Náº¿u báº¡n tÄƒng gáº¥p 100 láº§n sá»‘ dá»¯ liá»‡u máº«u, thÃ¬ con sá»‘ cÃ³ váº» há»£p lÃ½ hÆ¡n.\nTrong táº­p dá»¯ liá»‡u, mÃ¬nh cÃ³:\n1The input vector will have the shape {17} x {82} 2Train len: (21883, 17, 82) 36473 Tá»•ng cá»™ng N_s lÃ  21883, Ni lÃ  17, No lÃ  82, chá»n alpha lÃ  2 thÃ¬ mÃ¬nh cÃ³ 21883/(21782) = 7.8 ~ 8. Má»™t con sá»‘ khÃ¡ nhá», chá»©ng tá» dá»¯ liá»‡u cá»§a mÃ¬nh cÃ²n quÃ¡ Ã­t.\nÄá»‘i vá»›i táº­p dá»¯ liá»‡u nhá» nhÆ° tháº¿ nÃ y, mÃ¬nh thÆ°á»ng sáº½ Ã¡p dá»¥ng cÃ´ng thá»©c sau:\n$$ N_h= \\beta* (N_i + N_o) $$\nVá»›i beta lÃ  má»™t con sá»‘ thá»±c thuá»™c ná»­a Ä‘oáº¡n (0,1]. ThÃ´ng thÆ°á»ng sáº½ lÃ  2/3. Káº¿t quáº£ lÃ  sá»‘ lÆ°á»£ng neural cá»§a mÃ¬nh khoáº£ng 929.333 node. ThÃ´ng thÆ°á»ng, mÃ¬nh sáº½ chá»n sá»‘ neural lÃ  má»™t con sá»‘ lÃ  bá»™i sá»‘ cá»§a 2, á»Ÿ Ä‘Ã¢y 929 gáº§n vá»›i 2^10 nháº¥t, nÃªn mÃ¬nh chá»n sá»‘ neural lÃ  2^10.\nTÃ³m láº¡i, mÃ¬nh sáº½ theo quy táº¯c\nNáº¿u dá»¯ liá»‡u nhiá»u:\n$$ N_h = \\frac{N_s}{(\\alpha * (N_i + N_o))}$$\nNáº¿u dá»¯ liá»‡u Ã­t\n$$ N_h= \\frac{2}{3}* (N_i + N_o) $$\nLÃ m trÃ²n lÃªn báº±ng vá»›i bá»™i sá»‘ cá»§a 2 mÅ© gáº§n nháº¥t.\nMá»™t lÆ°u Ã½ nhá» lÃ  sá»‘ lÆ°á»£ng node cÃ ng nhiá»u thÃ¬ tá»· lá»‡ overfit cÃ ng cao, vÃ  thá»i gian huáº¥n luyá»‡n cÃ ng lÃ¢u. Do Ä‘Ã³, báº¡n nÃªn trang bá»‹ mÃ¡y cÃ³ cáº¥u hÃ¬nh kha khÃ¡ má»™t chÃºt, tá»‘t hÆ¡n háº¿t lÃ  nÃªn cÃ³ GPU Ä‘i kÃ¨m. NgoÃ i ra, báº¡n nÃªn chuáº©n bá»‹ cÃ ng nhiá»u dá»¯ liá»‡u cÃ ng tá»‘t. Má»™t kinh nghiá»‡m cá»§a mÃ¬nh rÃºt ra trong quÃ¡ trÃ¬nh lÃ m Machine Learning lÃ  náº¿u khÃ´ng cÃ³ nhiá»u dá»¯ liá»‡u, thÃ¬ Ä‘á»«ng cá»‘ thá»­ Ã¡p dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p ML trÃªn nÃ³.\nMÃ´ hÃ¬nh mÃ¬nh xÃ¢y dá»±ng nhÆ° sau:\n1 2hidden_nodes = 1024 3 4 5# Build the model 6print(\u0026#39;Build model...\u0026#39;) 7model = Sequential() 8model.add(LSTM(hidden_nodes, return_sequences=False, input_shape=(word_vec_length, char_vec_length))) 9model.add(Dropout(0.2)) 10model.add(Dense(units=output_labels)) 11model.add(Activation(\u0026#39;softmax\u0026#39;)) 12model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;acc\u0026#39;]) 13 14batch_size=1000 15model.fit(train_x, train_y, batch_size=batch_size, epochs=50, validation_data=(validate_x, validate_y)) Do bÃ i viáº¿t chá»‰ táº­p trung vÃ o váº¥n Ä‘á» lá»±a chá»n sá»‘ lÆ°á»£ng node, nÃªn mÃ¬nh sáº½ bá» qua nhá»¯ng pháº§n phá»¥ nhÆ° lÃ  early stoping, save each epochs \u0026hellip;, CÃ¡c váº¥n Ä‘á» trÃªn Ã­t nhiá»u mÃ¬nh Ä‘Ã£ Ä‘á» cáº­p á»Ÿ cÃ¡c bÃ i viáº¿t trÆ°á»›c.\nKáº¿t quáº£ cá»§a viá»‡c huáº¥n luyá»‡n mÃ´ hÃ¬nh\n121883/21883 [==============================] - 34s 2ms/step - loss: 0.6602 - acc: 0.6171 - val_loss: 0.6276 - val_acc: 0.7199 2Epoch 2/50 321883/21883 [==============================] - 30s 1ms/step - loss: 0.5836 - acc: 0.7056 - val_loss: 0.5625 - val_acc: 0.7193 4Epoch 3/50 521883/21883 [==============================] - 30s 1ms/step - loss: 0.5531 - acc: 0.7353 - val_loss: 0.5506 - val_acc: 0.7389 6Epoch 4/50 721883/21883 [==============================] - 31s 1ms/step - loss: 0.5480 - acc: 0.7446 - val_loss: 0.5664 - val_acc: 0.7313 8Epoch 5/50 921883/21883 [==============================] - 30s 1ms/step - loss: 0.5406 - acc: 0.7420 - val_loss: 0.5247 - val_acc: 0.7613 10Epoch 6/50 1121883/21883 [==============================] - 30s 1ms/step - loss: 0.5077 - acc: 0.7686 - val_loss: 0.4918 - val_acc: 0.7790 12Epoch 7/50 1321883/21883 [==============================] - 30s 1ms/step - loss: 0.4825 - acc: 0.7837 - val_loss: 0.4939 - val_acc: 0.7740 14Epoch 8/50 1521883/21883 [==============================] - 31s 1ms/step - loss: 0.4611 - acc: 0.7887 - val_loss: 0.4407 - val_acc: 0.8037 16Epoch 9/50 1721883/21883 [==============================] - 30s 1ms/step - loss: 0.4421 - acc: 0.7987 - val_loss: 0.4657 - val_acc: 0.8005 18Epoch 10/50 1921883/21883 [==============================] - 30s 1ms/step - loss: 0.4293 - acc: 0.8055 - val_loss: 0.4183 - val_acc: 0.8141 20Epoch 11/50 2121883/21883 [==============================] - 31s 1ms/step - loss: 0.4129 - acc: 0.8128 - val_loss: 0.4171 - val_acc: 0.8212 22Epoch 12/50 2321883/21883 [==============================] - 30s 1ms/step - loss: 0.4153 - acc: 0.8141 - val_loss: 0.4031 - val_acc: 0.8188 24Epoch 13/50 2521883/21883 [==============================] - 30s 1ms/step - loss: 0.3978 - acc: 0.8191 - val_loss: 0.3918 - val_acc: 0.8280 26Epoch 14/50 2721883/21883 [==============================] - 30s 1ms/step - loss: 0.3910 - acc: 0.8268 - val_loss: 0.3831 - val_acc: 0.8276 28Epoch 15/50 2921883/21883 [==============================] - 30s 1ms/step - loss: 0.3848 - acc: 0.8272 - val_loss: 0.3772 - val_acc: 0.8314 30Epoch 16/50 3121883/21883 [==============================] - 30s 1ms/step - loss: 0.3751 - acc: 0.8354 - val_loss: 0.3737 - val_acc: 0.8363 32Epoch 17/50 3321883/21883 [==============================] - 30s 1ms/step - loss: 0.3708 - acc: 0.8345 - val_loss: 0.3717 - val_acc: 0.8374 34Epoch 18/50 3521883/21883 [==============================] - 31s 1ms/step - loss: 0.3688 - acc: 0.8375 - val_loss: 0.3768 - val_acc: 0.8330 36Epoch 19/50 3721883/21883 [==============================] - 30s 1ms/step - loss: 0.3704 - acc: 0.8375 - val_loss: 0.3621 - val_acc: 0.8392 38Epoch 20/50 3921883/21883 [==============================] - 31s 1ms/step - loss: 0.3608 - acc: 0.8444 - val_loss: 0.3656 - val_acc: 0.8422 40Epoch 21/50 4121883/21883 [==============================] - 31s 1ms/step - loss: 0.3548 - acc: 0.8459 - val_loss: 0.3670 - val_acc: 0.8417 42Epoch 22/50 4321883/21883 [==============================] - 30s 1ms/step - loss: 0.3521 - acc: 0.8452 - val_loss: 0.3555 - val_acc: 0.8462 44Epoch 23/50 4521883/21883 [==============================] - 30s 1ms/step - loss: 0.3432 - acc: 0.8504 - val_loss: 0.3591 - val_acc: 0.8402 46Epoch 24/50 4721883/21883 [==============================] - 31s 1ms/step - loss: 0.3415 - acc: 0.8524 - val_loss: 0.3471 - val_acc: 0.8470 48Epoch 25/50 4921883/21883 [==============================] - 30s 1ms/step - loss: 0.3355 - acc: 0.8555 - val_loss: 0.3577 - val_acc: 0.8436 50Epoch 26/50 5121883/21883 [==============================] - 30s 1ms/step - loss: 0.3320 - acc: 0.8552 - val_loss: 0.3602 - val_acc: 0.8430 52Epoch 27/50 5321883/21883 [==============================] - 30s 1ms/step - loss: 0.3294 - acc: 0.8578 - val_loss: 0.3565 - val_acc: 0.8485 54Epoch 28/50 5521883/21883 [==============================] - 30s 1ms/step - loss: 0.3235 - acc: 0.8602 - val_loss: 0.3427 - val_acc: 0.8514 56Epoch 29/50 5721883/21883 [==============================] - 31s 1ms/step - loss: 0.3138 - acc: 0.8651 - val_loss: 0.3523 - val_acc: 0.8470 58Epoch 30/50 5921883/21883 [==============================] - 30s 1ms/step - loss: 0.3095 - acc: 0.8683 - val_loss: 0.3457 - val_acc: 0.8487 60Epoch 31/50 6121883/21883 [==============================] - 31s 1ms/step - loss: 0.3064 - acc: 0.8701 - val_loss: 0.3538 - val_acc: 0.8531 62Epoch 32/50 6321883/21883 [==============================] - 30s 1ms/step - loss: 0.2985 - acc: 0.8717 - val_loss: 0.3555 - val_acc: 0.8455 64Epoch 33/50 6521883/21883 [==============================] - 30s 1ms/step - loss: 0.2930 - acc: 0.8741 - val_loss: 0.3430 - val_acc: 0.8525 66Epoch 34/50 6721883/21883 [==============================] - 30s 1ms/step - loss: 0.2901 - acc: 0.8786 - val_loss: 0.3457 - val_acc: 0.8503 68Epoch 35/50 6921883/21883 [==============================] - 30s 1ms/step - loss: 0.2852 - acc: 0.8776 - val_loss: 0.3458 - val_acc: 0.8510 70Epoch 36/50 7121883/21883 [==============================] - 30s 1ms/step - loss: 0.2817 - acc: 0.8811 - val_loss: 0.3445 - val_acc: 0.8568 72Epoch 37/50 7321883/21883 [==============================] - 30s 1ms/step - loss: 0.2780 - acc: 0.8816 - val_loss: 0.3356 - val_acc: 0.8540 74Epoch 38/50 7521883/21883 [==============================] - 30s 1ms/step - loss: 0.2734 - acc: 0.8852 - val_loss: 0.3442 - val_acc: 0.8559 76Epoch 39/50 7721883/21883 [==============================] - 31s 1ms/step - loss: 0.2579 - acc: 0.8904 - val_loss: 0.3552 - val_acc: 0.8540 78Epoch 40/50 7921883/21883 [==============================] - 30s 1ms/step - loss: 0.2551 - acc: 0.8927 - val_loss: 0.3677 - val_acc: 0.8532 80Epoch 41/50 8121883/21883 [==============================] - 30s 1ms/step - loss: 0.2558 - acc: 0.8921 - val_loss: 0.3496 - val_acc: 0.8588 82Epoch 42/50 8321883/21883 [==============================] - 30s 1ms/step - loss: 0.2472 - acc: 0.8963 - val_loss: 0.3534 - val_acc: 0.8587 84Epoch 43/50 8521883/21883 [==============================] - 31s 1ms/step - loss: 0.2486 - acc: 0.8948 - val_loss: 0.3490 - val_acc: 0.8537 86Epoch 44/50 8721883/21883 [==============================] - 31s 1ms/step - loss: 0.2503 - acc: 0.8965 - val_loss: 0.3594 - val_acc: 0.8552 88Epoch 45/50 8921883/21883 [==============================] - 30s 1ms/step - loss: 0.2391 - acc: 0.8993 - val_loss: 0.3793 - val_acc: 0.8566 90Epoch 46/50 9121883/21883 [==============================] - 31s 1ms/step - loss: 0.2244 - acc: 0.9048 - val_loss: 0.3815 - val_acc: 0.8543 92Epoch 47/50 9321883/21883 [==============================] - 30s 1ms/step - loss: 0.2203 - acc: 0.9095 - val_loss: 0.3848 - val_acc: 0.8554 94Epoch 48/50 9521883/21883 [==============================] - 30s 1ms/step - loss: 0.2221 - acc: 0.9051 - val_loss: 0.3892 - val_acc: 0.8558 96Epoch 49/50 9721883/21883 [==============================] - 30s 1ms/step - loss: 0.2117 - acc: 0.9124 - val_loss: 0.3654 - val_acc: 0.8544 98Epoch 50/50 9921883/21883 [==============================] - 30s 1ms/step - loss: 0.2141 - acc: 0.9118 - val_loss: 0.3726 - val_acc: 0.8547 Äá»™ chÃ­nh xÃ¡c trÃªn táº­p train lÃ  hÆ¡n 90%, trÃªn táº­p val lÃ  hÆ¡n 85%. NhÃ¬n ká»¹ hÆ¡n vÃ o nhá»¯ng tá»« sai ta tháº¥y ráº±ng\n1 name gender predicted_gender 26750 Chiaki f m 328599 Naheed f m 411448 EspiridiÃ³n m f 5895 Akmaral f m 633778 Ros f m CÃ³ má»™t sá»± nháº­p nháº±ng á»Ÿ ngÃ´n ngá»¯ giá»¯a tÃªn nam vÃ  tÃªn ná»¯ á»Ÿ nhá»¯ng tá»« nÃ y. CÃ³ láº½ má»™t táº­p dá»¯ liá»‡u vá»›i Ä‘áº§y Ä‘á»§ há» vÃ  tÃªn sáº½ cho ra má»™t káº¿t quáº£ cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n. VÃ­ dá»¥, á»Ÿ Viá»‡t Nam, tÃªn Ngá»c thÃ¬ cÃ³ thá»ƒ Ä‘áº·t Ä‘Æ°á»£c cho cáº£ Nam láº«n Ná»¯.\nMÃ¬nh sáº½ cá»‘ gáº¯ng kiáº¿m má»™t bá»™ dataset tÃªn tiáº¿ng viá»‡t vÃ  thá»±c hiá»‡n viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh xÃ¡c Ä‘á»‹nh giá»›i tÃ­nh thÃ´ng qua tÃªn ngÆ°á»i dá»±a vÃ o mÃ´ hÃ¬nh LSTM.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Feb 6, 2019","img":"","permalink":"/blog/2019-02-06-choosing-the-right-hyperparameters-for-a-simple-lstm-using-keras/","series":null,"tags":["Machine learning","Deeplearning","python"],"title":"Lá»±a Chá»n SiÃªu Tham Sá»‘ Cho MÃ´ HÃ¬nh LSTM ÄÆ¡n Giáº£n Sá»­ Dá»¥ng Keras"},{"categories":null,"content":" Má»Ÿ Ä‘áº§u Giáº£m bá»™ nhá»› tiÃªu thá»¥ cá»§a má»™t Ä‘á»‘i tÆ°á»£ng trong python Má»Ÿ Ä‘áº§u Báº¯t Ä‘áº§u báº±ng má»™t class Ä‘Æ¡n giáº£n nhÆ° sau:\n1class DataItem(object): 2 def __init__(self, name, age, address): 3 self.name = name 4 self.age = age 5 self.address = address Báº¡n nghÄ© má»™t Ä‘á»‘i tÆ°á»£ng cá»§a class trÃªn sáº½ chiáº¿m bao nhiÃªu bá»™ nhá»›. ChÃºng ta cÃ¹ng tiáº¿n hÃ nh má»™t vÃ i thÃ­ nghiá»‡m nho nhá» bÃªn dÆ°á»›i.\n1dx = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;-\u0026#34;) 2print (\u0026#34;sys.getsizeof(dx):\u0026#34;, sys.getsizeof(dx)) 3\u0026gt;\u0026gt; sys.getsizeof(dx): 56 Káº¿t quáº£ ra lÃ  56 bytes, khÃ¡ há»£p lÃ½ pháº£i khÃ´ng cÃ¡c báº¡n. Thá»­ vá»›i má»™t vÃ­ dá»¥ khÃ¡c xem sao nhá»‰.\n1dy = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;I am working at MWG\u0026#34;) 2print (\u0026#34;sys.getsizeof(dy):\u0026#34;, sys.getsizeof(dy)) 3\u0026gt;\u0026gt; sys.getsizeof(dy): 56 Káº¿t quáº£ váº«n lÃ  56 bytes. CÃ³ cÃ¡i gÃ¬ Ä‘Ã³ sai sai á»Ÿ Ä‘Ã¢y khÃ´ng nhá»‰?\nChÃºng ta thá»±c nghiá»‡m má»™t vÃ i thÃ­ nghiá»‡m khÃ¡c Ä‘á»ƒ chá»©ng thá»±c.\n1print (sys.getsizeof(\u0026#34;\u0026#34;)) 2\u0026gt;\u0026gt; 49 3print (sys.getsizeof(\u0026#34;1\u0026#34;)) 4\u0026gt;\u0026gt; 50 5print (sys.getsizeof(1)) 6\u0026gt;\u0026gt; 28 7print (sys.getsizeof(dict())) 8\u0026gt;\u0026gt; 240 9print (sys.getsizeof({})) 10\u0026gt;\u0026gt; 240 11print (sys.getsizeof(list())) 12\u0026gt;\u0026gt; 64 13print (sys.getsizeof([])) 14\u0026gt;\u0026gt; 64 15print (sys.getsizeof(())) 16\u0026gt;\u0026gt; 48 Má»™t Ä‘iá»u cá»±c ká»³ báº¥t ngá» Ä‘Ã£ xuáº¥t hiá»‡n á»Ÿ Ä‘Ã¢y. Má»™t chuá»—i rá»—ng chiáº¿m Ä‘áº¿n táº­n 49 bytes, má»™t dictionary rá»—ng, khÃ´ng chá»©a pháº§n tá»­ nÃ o chiáº¿m Ä‘áº¿n 240 bytes, vÃ  má»™t list rá»—ng chiáº¿m tá»›i 64 bytes. RÃµ rÃ ng, python Ä‘Ã£ lÆ°u má»™t sá»‘ thá»© gÃ¬ Ä‘Ã³ ngoÃ i dá»¯ liá»‡u cá»§a mÃ¬nh.\nÄi sÃ¢u vÃ o thá»­ tÃ¬m hiá»ƒu nhá»¯ng thá»© \u0026rsquo;linh kiá»‡n\u0026rsquo; linh tinh mÃ  python Ä‘Ã£ kÃ¨m theo cho chÃºng ta lÃ  gÃ¬ nhÃ©.\nÄáº§u tiÃªn, chÃºng ta sáº½ cáº§n má»™t hÃ m in ra nhá»¯ng thá»© mÃ  python Ä‘Ã£ \u0026rsquo;nhÃºng\u0026rsquo; thÃªm vÃ o class DataItem chÃºng ta khai bÃ¡o á»Ÿ trÃªn.\n1def dump(obj): 2 for attr in dir(obj): 3 print(\u0026#34; obj.%s = %r\u0026#34; % (attr, getattr(obj, attr))) vÃ  dump biáº¿n dy ra thÃ´i\n1dump(dy) 2 3obj.__class__ = \u0026lt;class \u0026#39;__main__.DataItem\u0026#39;\u0026gt; 4 obj.__delattr__ = \u0026lt;method-wrapper \u0026#39;__delattr__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 5 obj.__dict__ = {\u0026#39;name\u0026#39;: \u0026#39;Alex Black\u0026#39;, \u0026#39;age\u0026#39;: 42, \u0026#39;address\u0026#39;: \u0026#39;i am working at MWG\u0026#39;} 6 obj.__dir__ = \u0026lt;built-in method __dir__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 7 obj.__doc__ = None 8 obj.__eq__ = \u0026lt;method-wrapper \u0026#39;__eq__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 9 obj.__format__ = \u0026lt;built-in method __format__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 10 obj.__ge__ = \u0026lt;method-wrapper \u0026#39;__ge__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 11 obj.__getattribute__ = \u0026lt;method-wrapper \u0026#39;__getattribute__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 12 obj.__gt__ = \u0026lt;method-wrapper \u0026#39;__gt__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 13 obj.__hash__ = \u0026lt;method-wrapper \u0026#39;__hash__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 14 obj.__init__ = \u0026lt;bound method DataItem.__init__ of \u0026lt;__main__.DataItem object at 0x000001A64A6DD0F0\u0026gt;\u0026gt; 15 obj.__init_subclass__ = \u0026lt;built-in method __init_subclass__ of type object at 0x000001A64A5DE738\u0026gt; 16 obj.__le__ = \u0026lt;method-wrapper \u0026#39;__le__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 17 obj.__lt__ = \u0026lt;method-wrapper \u0026#39;__lt__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 18 obj.__module__ = \u0026#39;__main__\u0026#39; 19 obj.__ne__ = \u0026lt;method-wrapper \u0026#39;__ne__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 20 obj.__new__ = \u0026lt;built-in method __new__ of type object at 0x000000005C2DC580\u0026gt; 21 obj.__reduce__ = \u0026lt;built-in method __reduce__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 22 obj.__reduce_ex__ = \u0026lt;built-in method __reduce_ex__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 23 obj.__repr__ = \u0026lt;method-wrapper \u0026#39;__repr__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 24 obj.__setattr__ = \u0026lt;method-wrapper \u0026#39;__setattr__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 25 obj.__sizeof__ = \u0026lt;built-in method __sizeof__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 26 obj.__str__ = \u0026lt;method-wrapper \u0026#39;__str__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 27 obj.__subclasshook__ = \u0026lt;built-in method __subclasshook__ of type object at 0x000001A64A5DE738\u0026gt; 28 obj.__weakref__ = None 29 obj.address = \u0026#39;i am working at MWG\u0026#39; 30 obj.age = 42 31 obj.name = \u0026#39;Alex Black\u0026#39; Wow, cÃ³ váº» khÃ¡ lÃ  Ä‘á»“ sá»™ nhá»‰.\nTrÃªn github, cÃ³ má»™t hÃ m cÃ³ sáºµn tÃ­nh toÃ¡n sá»‘ lÆ°á»£ng bá»™ nhá»› mÃ  object chiáº¿m Ä‘Æ°á»£c dá»±a vÃ o cÃ¡ch truy xuáº¥t trá»±c tiáº¿p tá»«ng trÆ°á»ng dá»¯ liá»‡u cá»§a Ä‘á»‘i tÆ°á»£ng vÃ  tÃ­nh toÃ¡n kÃ­ch thÆ°á»›c\n1import sys 2 3def get_size(obj, seen=None): 4 \u0026#34;\u0026#34;\u0026#34;Recursively finds size of objects\u0026#34;\u0026#34;\u0026#34; 5 size = sys.getsizeof(obj) 6 if seen is None: 7 seen = set() 8 obj_id = id(obj) 9 if obj_id in seen: 10 return 0 11 # Important mark as seen *before* entering recursion to gracefully handle 12 # self-referential objects 13 seen.add(obj_id) 14 if isinstance(obj, dict): 15 size += sum([get_size(v, seen) for v in obj.values()]) 16 size += sum([get_size(k, seen) for k in obj.keys()]) 17 elif hasattr(obj, \u0026#39;__dict__\u0026#39;): 18 size += get_size(obj.__dict__, seen) 19 elif hasattr(obj, \u0026#39;__iter__\u0026#39;) and not isinstance(obj, (str, bytes, bytearray)): 20 size += sum([get_size(i, seen) for i in obj]) 21 return size thá»­ vá»›i 2 biáº¿n dx vÃ  dy cá»§a chÃºng ta xem sao\n1\u0026gt;\u0026gt;\u0026gt; print (\u0026#34;get_size(d1):\u0026#34;, get_size(dx)) 2get_size(d1): 466 3\u0026gt;\u0026gt;\u0026gt; print (\u0026#34;get_size(d1):\u0026#34;, get_size(dy)) 4get_size(d1): 484 ChÃºng tá»‘n láº§n lÆ°á»£t lÃ  466 vÃ  484 bytes. CÃ³ váº» Ä‘Ãºng Ä‘Ã³ nhá»‰.\nÄiá»u chÃºng ta quan tÃ¢m lÃºc nÃ y lÃ  cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ giáº£m bá»™ nhá»› tiÃªu thá»¥ cá»§a má»™t object hay khÃ´ng?\nGiáº£m bá»™ nhá»› tiÃªu thá»¥ cá»§a má»™t Ä‘á»‘i tÆ°á»£ng trong python Táº¥t nhiÃªn lÃ  sáº½ cÃ³ cÃ¡ch giáº£m. Python lÃ  má»™t ngÃ´n ngá»¯ thÃ´ng dá»‹ch, vÃ  nÃ³ cho phÃ©p chÃºng ta má»Ÿ rá»™ng lá»›p báº¥t ká»ƒ lÃºc nÃ o báº±ng cÃ¡ch thÃªm má»™t/ nhiá»u trÆ°á»ng dá»¯ liá»‡u.\n1dz = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;-\u0026#34;) 2dz.height = 1.80 3print ( get_size(dz)) 4\u0026gt;\u0026gt; 484 ChÃ­nh vÃ¬ lÃ½ do nÃ y, trÃ¬nh biÃªn dá»‹ch sáº½ tá»‘n thÃªm má»™t Ä‘á»‘ng bá»™ nhá»› táº¡m Ä‘á»ƒ chÃºng ta cÃ³ thá»ƒ dá»… dÃ ng má»Ÿ rá»™ng má»™t lá»›p trong tÆ°Æ¡ng lai. Náº¿u chÃºng ta \u0026ldquo;Ã©p buá»™c\u0026rdquo; trÃ¬nh biÃªn dá»‹ch, nÃ³i ráº±ng chÃºng ta chá»‰ cÃ³ nhiÃªu Ä‘Ã³ trÆ°á»ng, vÃ  bá» pháº§n dÆ° thá»«a Ä‘i.\n1class DataItem(object): 2 __slots__ = [\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;address\u0026#39;] 3 def __init__(self, name, age, address): 4 self.name = name 5 self.age = age 6 self.address = address VÃ  thá»­ láº¡i\n1 2dz = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;i am working at MWG\u0026#34;) 3print (\u0026#34;sys.getsizeof(dz):\u0026#34;, get_size(dz)) 4 5\u0026gt;\u0026gt;sys.getsizeof(dz): 64 CÃ¡c báº¡n tháº¥y gÃ¬ khÃ´ng, bá»™ nhá»› tiÃªu thá»¥ chá»‰ lÃ  \u0026ldquo;64 bytes\u0026rdquo;. Dung lÆ°á»£ng Ä‘Ã£ giáº£m Ä‘i hÆ¡n \u0026ldquo;7 láº§n\u0026rdquo; so vá»›i model class ban Ä‘áº§u. Tuy nhiÃªn, chÃºng ta sáº½ khÃ´ng thá»ƒ má»Ÿ rá»™ng class dá»… dÃ ng nhÆ° xÆ°a ná»¯a.\n1\u0026gt;\u0026gt;\u0026gt; dz.height = 1.80 2Traceback (most recent call last): 3 File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; 4AttributeError: \u0026#39;DataItem\u0026#39; object has no attribute \u0026#39;height\u0026#39; Thá»­ táº¡o má»™t Ä‘á»‘i tÆ°á»£ng cÃ³ 1000 pháº§n tá»­ vÃ  kiá»ƒm tra thá»­.\n1class DataItem(object): 2 __slots__ = [\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;address\u0026#39;] 3 def __init__(self, name, age, address): 4 self.name = name 5 self.age = age 6 self.address = address 7 8 9data = [] 10 11tracemalloc.start() 12start =datetime.datetime.now() 13for p in range(100000): 14 data.append(DataItem(\u0026#34;Alex\u0026#34;, 42, \u0026#34;middle of nowhere\u0026#34;)) 15 16end =datetime.datetime.now() 17snapshot = tracemalloc.take_snapshot() 18top_stats = snapshot.statistics(\u0026#39;lineno\u0026#39;) 19total = sum(stat.size for stat in top_stats) 20print(\u0026#34;Total allocated size: %.1f MB\u0026#34; % (total / (1024*1024))) 21print(\u0026#34;Total execute time:\u0026#34;,(end-start).microseconds) 22 23\u0026gt;\u0026gt; Total allocated size: 6.9 MB 24\u0026gt;\u0026gt; Total execute time: 232565 Bá» dÃ²ng slots = [\u0026rsquo;name\u0026rsquo;, \u0026lsquo;age\u0026rsquo;, \u0026lsquo;address\u0026rsquo;] Ä‘i thá»­\n1 2class DataItem(object): 3 def __init__(self, name, age, address): 4 self.name = name 5 self.age = age 6 self.address = address 7 8 9data = [] 10 11tracemalloc.start() 12start =datetime.datetime.now() 13for p in range(100000): 14 data.append(DataItem(\u0026#34;Alex\u0026#34;, 42, \u0026#34;middle of nowhere\u0026#34;)) 15end =datetime.datetime.now() 16snapshot = tracemalloc.take_snapshot() 17top_stats = snapshot.statistics(\u0026#39;lineno\u0026#39;) 18total = sum(stat.size for stat in top_stats) 19print(\u0026#34;Total allocated size: %.1f MB\u0026#34; % (total / (1024*1024))) 20print(\u0026#34;Total execute time:\u0026#34;,(end-start).microseconds) 21 22\u0026gt;\u0026gt; Total allocated size: 16.8 MB 23\u0026gt;\u0026gt; Total execute time: 240772 So sÃ¡nh thá»­, chÃºng ta tháº¥y ráº±ng sá»‘ lÆ°á»£ng RAM giáº£m Ä‘i khÃ¡ nhiá»u, thá»i gian thá»±c thi khÃ¡ tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhau (cÃ³ giáº£m má»™t chÃºt).\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Feb 6, 2019","img":"","permalink":"/blog/2019-02-06-how-to-reduce-memory-consumption-by-half-by-adding-just-one-line-of-code/","series":null,"tags":["Machine learning","Deeplearning","python"],"title":"Giáº£m Bá»™ Nhá»› Sá»­ Dá»¥ng Trong Python"},{"categories":null,"content":" Má»Ÿ Ä‘áº§u Máº¹o sá»‘ 1: Sá»©c máº¡nh cá»§a má»™t dÃ²ng Máº¹o 2: CÃ¡c thao tÃ¡c nhanh trÃªn chuá»—i Máº¹o sá»‘ 3: Chuá»—i lá»“ng nhau Máº¹o 4: Cáº¥u trÃºc dá»¯ liá»‡u Ä‘Æ¡n giáº£n. Máº¹o 5: Xuáº¥t dá»¯ liá»‡u ra command line dá»… dÃ ng Má»Ÿ Ä‘áº§u Hiá»‡n nay, cÃ³ ráº¥t nhiá»u thÆ° viá»‡n do cá»™ng Ä‘á»“ng Ä‘Ã³ng gÃ³p vÃ  xÃ¢y dá»±ng. VÃ­ dá»¥ nhÆ° biopython trong tin sinh há»c, pandas (data science), keras/tensorflow (machine learning), astropy ( cho thiÃªn vÄƒn há»c - astronomy). TrÆ°á»›c khi báº¯t Ä‘áº§u Ä‘á»c bÃ i viáº¿t nÃ y, báº¡n Ä‘Ãªn Ä‘á»c \u0026ldquo;Python Tricks Book\u0026rdquo; cá»§a Dan Bader trÆ°á»›c (https://dbader.org/products/python-tricks-book/). Trong sÃ¡ch, anh áº¥y Ä‘Ã£ chia sáº» má»™t sá»‘ lá»i khuyÃªn vÃ  máº¹o vá» cÃ¡c code python hiá»‡u quáº£ hÆ¡n.\nMáº¹o sá»‘ 1: Sá»©c máº¡nh cá»§a má»™t dÃ²ng Khi báº¡n Ä‘á»c má»™t Ä‘oáº¡n giáº£i thuáº­t vá»›i nhiá»u dÃ²ng code, cÃ³ thá»ƒ báº¡n sáº½ bá»‹ quÃªn thÃ´ng tin nhá»¯ng dÃ²ng trÆ°á»›c Ä‘Ã³ Ä‘Ã£ viáº¿t gÃ¬, Ä‘áº·c biá»‡t lÃ  trong nhá»¯ng cÃ¢u lá»‡nh Ä‘iá»u kiá»‡n. VÃ­ dá»¥:\n1 2if alpha \u0026gt; 7: 3 beta = 999 4elif alpha == 7: 5 beta = 99 6else: 7 beta =0 ChÃ³ng ta cÃ³ thá»ƒ viáº¿t Ä‘Æ¡n giáº£n hÆ¡n chá»‰ vá»›i má»™t dÃ²ng code nhÆ° sau.\n1beta = 999 if alpha \u0026gt; 7 else 99 if alpha == 7 else 0 tháº­t Ä‘Æ¡n giáº£n pháº£i khÃ´ng. Báº¡n chá»‰ cáº§n nhÃ¬n Ä‘Ãºng má»™t dÃ²ng lÃ  náº±m Ä‘Æ°á»£c ná»™i dung Ã½ nghÄ©a cá»§a Ä‘oáº¡n code báº¡n cáº§n. Má»™t vÃ­ dá»¥ khÃ¡c vá» vÃ²ng láº·p for.\n1lst = [1, 2, 3, 4] 2lst_double = [] 3 4for num in lst: 5 lst_double.append(num * 2) Äoáº¡n code trÃªn cÃ³ thá»ƒ viáº¿t láº¡i dÆ°á»›i dáº¡ng 1 dÃ²ng nhÆ° sau.\n1lst_double = [num * 2 for num in lst] Táº¥t nhiÃªn, báº¡n khÃ´ng nÃªn \u0026ldquo;láº¡m dá»¥ng\u0026rdquo; one line má»™t cÃ¡ch thÃ¡i quÃ¡, vÃ­ dá»¥\n1import pprint; pprint.pprint(zip((\u0026#39;Byte\u0026#39;, \u0026#39;KByte\u0026#39;, \u0026#39;MByte\u0026#39;, \u0026#39;GByte\u0026#39;, \u0026#39;TByte\u0026#39;), (1 \u0026lt;\u0026lt; 10*i for i in xrange(5)))) TrÃ´ng nÃ³ cÃ³ váº» hÆ¡i \u0026ldquo;lá»‘ bá»‹ch\u0026rdquo; pháº£i khÃ´ng.\nMáº¹o 2: CÃ¡c thao tÃ¡c nhanh trÃªn chuá»—i Python cung cáº¥p cho chÃºng ta má»™t sá»‘ cÃ¡ch viáº¿t ngáº¯n gá»n giÃºp chÃºng ta cÃ³ thá»ƒ dá»ƒ dÃ ng thao tÃ¡c trÃªn chuá»—i. Äá»ƒ reverse má»™t chuá»—i, chÃºng ta sá»­ dá»¥ng toÃ¡n tá»­ ::-1\n1 2str = \u0026#39;i am alex\u0026#39; 3print(str[::-1]) 4\u0026gt;\u0026gt; xela ma i Máº¹o trÃªn cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»‘i vá»›i list sá»‘ nguyÃªn.\nÄá»ƒ ná»‘i cÃ¡c pháº§n tá»­ trong má»™t list thÃ nh má»™t chuá»—i, chÃºng ta cÃ³ thá»ƒ dÃ¹ng hÃ m join()\n1 2str1 = [\u0026#34;pig\u0026#34;, \u0026#34;year\u0026#34; , \u0026#34;2019\u0026#34;] 3str2 = \u0026#34;happy \u0026#34; 4str3 = \u0026#34;new \u0026#34; 5 6 7print( \u0026#39; \u0026#39;.join(str1)) 8\u0026gt;\u0026gt; pig year 2019 9 10print(str2+str3+\u0026#39; \u0026#39;.join(str1)) 11\u0026gt;\u0026gt; happy new year 2019 Tháº­t tuyá»‡t vá»i pháº£i khÃ´ng cÃ¡c báº¡n.\nNgoÃ i ra cÃ¡c báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng biáº¿u thá»©c chÃ­nh quy Ä‘á»ƒ tÃ¬m kiáº¿m chuá»—i vÃ  pattern. Vá» biá»ƒu thá»©c chÃ­nh quy trong python, cÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m hiá»ƒu á»Ÿ https://docs.python.org/3/library/re.html.\nMáº¹o sá»‘ 3: Chuá»—i lá»“ng nhau Thá»­ tÆ°á»Ÿng tÆ°á»£ng ráº±ng báº¡n cÃ³ hÃ ng tÃ¡ cÃ¡c list, vÃ  sau má»™t má»› cÃ¡c thao tÃ¡c, káº¿t quáº£ cá»§a báº¡n lÃ  má»™t list cÃ¡c list. ChÃºng ta sáº½ sá»­ dá»¥ng itertools - má»™t thÆ° viá»‡n Ä‘Æ°á»£c cung cáº¥p sáºµn trong python Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y giÃºp chÃºng ta.\n1 2import itertools 3flatten = lambda x: list(itertools.chain.from_iterable(x)) 4s =[[\u0026#34;this\u0026#34;,\u0026#34;is\u0026#34;],[\u0026#34;the\u0026#34;,\u0026#34;year\u0026#34;], [\u0026#34;of\u0026#34;, \u0026#34;pig\u0026#34;], [\u0026#34;in\u0026#34;], [\u0026#34;Viá»‡t\u0026#34;, \u0026#34;Nam\u0026#34;]] 5 6print(\u0026#39; \u0026#39;,join(flatten(s))) 7\u0026gt;\u0026gt; this is the year of pig in Viá»‡t Nam Náº¿u báº¡n cháº¡y dÃ²ng code trÃªn bá»‹ lá»—i, ráº¥t cÃ³ thá»ƒ lÃ  do terminal cá»§a báº¡n khÃ´ng há»— trá»£ tiáº¿ng viá»‡t font unicode. HÃ£y chuyá»ƒn qua font unicode trÃªn terminal hoáº·c dÃ¹ng terminal cá»§a ubuntu, bash (trÃªn window 10).\nNgoÃ i ra, itertools cÃ²n há»— trá»£ ráº¥t nhiá»u hÃ m khÃ¡c Ä‘á»ƒ giÃºp chÃºng ta thao tÃ¡c trÃªn chuá»—i lá»“ng dá»… dÃ ng hÆ¡n. CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o thÃªm á»Ÿ https://docs.python.org/2/library/itertools.html.\nMáº¹o 4: Cáº¥u trÃºc dá»¯ liá»‡u Ä‘Æ¡n giáº£n. ChÃºng ta cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t cÃ¢y Ä‘Æ¡n giáº£n chá»‰ vá»›i má»™t dÃ²ng mÃ£ lá»‡nh:\n1def tree(): return defaultdict(tree) Má»™t vÃ­ dá»¥ Ä‘Æ¡n giáº£n khÃ¡c lÃ  hÃ m táº¡o sá»‘ nguyÃªn chá»‰ vá»›i 1 dÃ²ng code ngáº¯n gá»n\n1reduce( (lambda r,x: r-set(range(x**2,N,x)) if (x in r) else r), 2 range(2,N), set(range(2,N))) Python cÃ³ há»— trá»£ nhiá»u thÆ° viá»‡n ráº¥t máº¡nh trong viá»‡c giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» trong tháº¿ giá»›i thá»±c. VÃ­ dá»¥ thÆ° viá»‡n Collections\n1from collections import Counter 2myList = [1,1,2,3,4,5,3,2,3,4,2,1,2,3] 3print(Counter(myList)) 4Counter({2: 4, 3: 4, 1: 3, 4: 2, 5: 1}) Má»™t lÆ°u Ã½ nhá» lÃ  cÃ¡c thÆ° viá»‡n nÃ y chá»‰ nÃªn sá»­ dá»¥ng khi táº­p dá»¯ liá»‡u cá»§a báº¡n nhá», náº¿u táº­p dá»¯ liá»‡u lá»›n, vÃ­ dá»¥ báº¡n cáº§n Ä‘áº¿m sá»‘ láº§n xuáº¥t hiá»‡n cá»§a cÃ¡c tá»« trong táº­p vÄƒn báº£n vá»›i 100GB dá»¯ liá»‡u. Báº¡n hÃ£y dÃ¹ng cÃ¡ch khÃ¡c, vÃ­ dá»¥ hadoop, hoáº·c tÄƒng bá»™ nhá»› ram cá»§a báº¡n lÃªn, vÃ­ dá»¥ 1 Tb cháº³ng háº¡n :)\nMáº¹o 5: Xuáº¥t dá»¯ liá»‡u ra command line dá»… dÃ ng Äá»ƒ xuáº¥t dá»¯ liá»‡u cá»§a má»™t list int ra command line, theo nhÆ° máº¹o á»Ÿ trÃªn, ta sáº½ dÃ¹ng hÃ m .join() vÃ  vÃ²ng láº·p.\n```python` lst_row = [1,2,3,4,5] print(\u0026rsquo;,\u0026rsquo;.join([str(x) for x in lst_row]) 1,2,3,4,5\n1 2CÃ¡ch Ä‘Æ¡n giáº£n hÆ¡n chá»‰ vá»›i má»™t dÃ²ng code (Æ¯á»›c gÃ¬ mÃ¬nh biáº¿t cÃ¡ch nÃ y sá»›m hÆ¡n, hix). 3 4```python 5print(*lst_row, sep=\u0026#39;,\u0026#39;) 61,2,3,4,5 Má»™t máº¹o khÃ¡c lÃ  trong má»™t sá»‘ trÆ°á»ng há»£p duyá»‡t máº£ng, báº¡n cáº§n láº¥y giÃ¡ trá»‹ vÃ  chá»‰ sá»‘ cá»§a máº£ng Ä‘Ã³ Ä‘á»ƒ lÃ m má»™t sá»‘ thao tÃ¡c khÃ¡c\n1 2lst_arr = [\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;d\u0026#39;] 3 4int_index = 0 5 6for item in lst_arr: 7 print(int_index, item) 8\tint_index = int_index + 1 9 10\u0026gt;\u0026gt; 0 a 111 b 122 c 133 d hoáº·c cÃ¡ch viáº¿t giá»‘ng c/c++\n1 2for int_index in len(lst_arr): 3 print(int_index, lst_arr[int_index]) 4 5\u0026gt;\u0026gt; 0 a 61 b 72 c 83 d Má»™t cÃ¡ch khÃ¡c lÃ  sá»­ dá»¥ng hÃ m cÃ³ sáºµn enumerate cá»§a python\n1for int_index, item in enumerate(lst_arr): 2 print(int_index, item) 3 4\u0026gt;\u0026gt; 0 a 51 b 62 c 73 d CÃ³ ráº¥t nhiá»u máº¹o hay Ä‘á»ƒ Ä‘Æ¡n giáº£n hoÃ¡ viá»‡c xuáº¥t dá»¯ liá»‡u ra terminal. HÃ£y thÃ´ng tin cho mÃ¬nh biáº¿t náº¿u báº¡n cÃ³ nhiá»u máº¹o hay khÃ¡c cáº§n chia sáº» nhÃ©.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Feb 5, 2019","img":"","permalink":"/blog/2019-02-05-5-python-tricks-you-need-to-know-today/","series":null,"tags":["Machine learning","Deeplearning","python"],"title":"5 Máº¹o Hay Sá»­ Dá»¥ng Python"},{"categories":null,"content":" Äáº·t váº¥n Ä‘á» PhÃ¢n tÃ­ch dá»¯ liá»‡u XÃ¢y dá»±ng chiáº¿n lÆ°á»£c tiáº¿p cáº­n bÃ i toÃ¡n 1. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u 2. XÃ¢y dá»±ng mÃ´ hÃ¬nh Content-Based Filtering a. XÃ¢y dá»±ng táº­p Ä‘áº·c trÆ°ng b. XÃ¢y dá»±ng mÃ´ hÃ¬nh 3. Collaborative Filtering Model a. XÃ¢y dá»±ng ma tráº­n donor - project b. Singular Value Decomposition c. XÃ¢y dá»±ng Collaborative Filtering Model 4. Hybrid Method 5. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Äáº·t váº¥n Ä‘á» DonorsChoose.org Ä‘Æ°á»£c thÃ nh láº­p vÃ o nÄƒm 2000 bá»Ÿi má»™t giÃ¡o viÃªn lá»‹ch sá»­ táº¡i Má»¹ tÃªn lÃ  Bronx vÃ  Ä‘Ã£ huy Ä‘á»™ng Ä‘Æ°á»£c 685 triá»‡u Ä‘Ã´ la cho cÃ¡c lá»›p há»c. 3/4 cÃ¡c giÃ¡o viÃªn á»Ÿ cÃ¡c trÆ°á»ng cÃ´ng láº­p á»Ÿ Hoa Ká»³ Ä‘Ã£ sá»­ dá»¥ng Donor Ä‘á»ƒ gá»­i cÃ¡c yÃªu cáº§u bÃ i táº­p cho há»c sinh. Tá»« Ä‘Ã³, Donor trá»Ÿ thÃ nh ná»n táº£ng giÃ¡o dá»¥c hÃ ng Ä‘áº§u há»— trá»£ cho cÃ¡c váº¥n Ä‘á» giÃ¡o dá»¥c cÃ´ng cá»™ng.\nÄáº¿n nay, hÆ¡n 3 triá»‡u ngÆ°á»i dÃ¹ng vÃ  Ä‘á»‘i tÃ¡c Ä‘Ã£ Ä‘Ã³ng gÃ³p hÆ¡n 1,1 triá»‡u dá»± Ã¡n cho Donor. NhÆ°ng cÃ¡c giÃ¡o viÃªn váº«n pháº£i tá»‘n hÃ ng tá»· Ä‘Ã´ tiá»n tÃºi Ä‘á»ƒ chuáº©n bá»‹ cÃ¡c dá»¥ng cá»¥ há»c táº­p trÃªn lá»›p (Ä‘á»ƒ truyá»n táº£i kiáº¿n thá»©c cho há»c sinh).\nGiáº£i phÃ¡p Ä‘Æ°á»£c Ä‘Æ°a ra á»Ÿ Ä‘Ã¢y lÃ  xÃ¢y dá»±ng má»™t chiáº¿n dá»‹ch gá»£i Ã½ cho cÃ¡c nhÃ  táº¡i trá»£.\nPhÃ¢n tÃ­ch dá»¯ liá»‡u ChÃºng ta cÃ³ cÃ¡c file sau:\nFile Donations.csv. Vá»›i má»—i dá»± Ã¡n (Project ID), sáº½ cÃ³ 1 hoáº·c nhiá»u nhÃ  quyÃªn gÃ³p (Donor ID) má»—i cáº·p (dá»± Ã¡n - nhÃ  quyÃªn gÃ³p sáº½ Ä‘á»‹nh dang báº±ng 1 mÃ£ chung (Donation ID) vÃ  cÃ³ cÃ¡c cá»™t thÃ´ng tin liÃªn quan Ä‘áº¿n viá»‡c quyÃªn gÃ³p Ä‘Ã³). File cÃ³ xáº¥p xá»‰ 4.67 triá»‡u dÃ²ng (chÃ­nh xÃ¡c lÃ  4687844 dÃ²ng) vÃ  7 cá»™t. (Project ID - Äá»‹nh danh dá»± Ã¡n, Donation ID - Äá»‹nh danh khoáº£ng Ä‘Ã³ng gÃ³p (tÆ°á»Ÿng tÆ°á»£ng nhÆ° khoÃ¡ tá»± tÄƒng cá»§a báº£ng nÃ y Ä‘Ã³ cÃ¡c báº¡n), Donor ID - MÃ£ Ä‘á»‹nh danh ngÆ°á»i Ä‘Ã³ng gÃ³p, Donation Included Option - há»— trá»£ website donoschoose 15% giÃ¡ trá»‹ quyÃªn gÃ³p, Donation Amount - Sá»‘ tiá»n quyÃªn gÃ³p, Donor Cart Sequence - Thá»© tá»± cá»§a dá»± Ã¡n trá»ng báº£ng danh sÃ¡ch quyÃªn gÃ³p,Donation Received Date - NgÃ y giá» quyÃªn gÃ³p).\nFile Donors.csv. File Ä‘á»‹nh danh ngÆ°á»i quyÃªn gÃ³p. Chá»©a tá»•ng cá»™ng hÆ¡n 2 triá»‡u dÃ²ng( chÃ­nh xÃ¡c lÃ  2122640 dÃ²ng) File cÃ³ kÃ­ch thÆ°á»›c 2122640 x 5 vá»›i cÃ¡c thÃ´ng tin cá»™t lÃ  Donor ID (khoÃ¡ chÃ­nh, khÃ´ng trÃ¹ng), Donor City (tÃªn thÃ nh phá»‘ nhÃ  Ä‘áº§u tÆ° Ä‘ang sinh sá»‘ng), Donor State (tiá»ƒu bang mÃ  ngÆ°á»i quyÃªn gÃ³p Ä‘ang sá»‘ng), Donor is teacher, Donor Zip (3 kÃ½ tá»± Ä‘áº§u cá»§a mÃ£ bÆ°u Ä‘iá»‡n nhÃ  tá»« thiá»‡n).\nFile Teacher.csv. File cÃ³ tá»•ng cá»™ng 402900 dÃ²ng vá»›i cÃ¡c cá»™t TeachId, Teacher Prefix (Mr, Mrs, Ms), Teacher First Project Posted Date.\nFile Schools.csv. File cÃ³ tá»•ng cá»™ng 72994 dÃ²ng vá»›i cÃ¡c cá»™t lÃ  SchoolID, SchoolName (tÃªn trÆ°á»ng cÃ³ thá»ƒ trÃ¹ng nhau), School Metro Type ( phÃ¢n loáº¡i trÆ°á»ng thuá»™c 1 trong 5 nhÃ³m : suburnban - ngoáº¡i Ã´, rural - nÃ´ng thÃ´n, uban - thÃ nh thá»‹, town - thá»‹ tráº¥n, unknow), School Percentage Free Lunch ( Sá»‘ nguyÃªn, mÃ´ táº£ tá»· lá»‡ pháº§n trÄƒm sá»‘ há»c sinh Ä‘á»§ Ä‘iá»u kiá»‡n Äƒn trÆ°a miá»…n phÃ­ hoáº·c Äƒn trÆ°a giáº£m phÃ­. Dá»¯ liá»‡u thu Ä‘Æ°á»£c cung cáº¥p bá»Ÿi má»™t Ä‘á»‘i tÃ¡c thá»‘ng kÃª Ä‘á»™c láº­p lÃ  NCES. Náº¿u trÆ°á»ng nÃ o khÃ´ng cÃ³ giÃ¡ trá»‹ do NCES cung cáº¥p, chÃºng ta sáº½ láº¥y sá»‘ pháº§n trÄƒm nÃ y lÃ  trung bÃ¬nh pháº§n trÄƒm cá»§a cÃ¡c trÆ°á»ng cÃ¹ng huyá»‡n), School State (TrÆ°á»ng Ä‘ang toáº¡ láº¡c á»Ÿ bang nÃ o (vd cali, Florida, Virginia, \u0026hellip;)), School Zip (mÃ£ bÆ°u chÃ­nh), School City, School County\nFile Resources.csv. Vá»›i má»—i dá»± Ã¡n, chÃºng ta cáº§n cÃ¡c loáº¡i tÃ i nguyÃªn khÃ¡c nhau. CÃ¡c cá»™t lÃ  Project ID (mÃ£ dá»± Ã¡n), Resource Item Name (tÃªn tÃ i nguyÃªn cáº§n cho dá»± Ã¡n Ä‘Ã³ vd project 000009891526c0ade7180f8423792063 cáº§n \u0026lsquo;chair move and store cart\u0026rsquo;), Resource Quantity (sá»‘ lÆ°á»£ng tÃ i nguyÃªn cáº§n, vd cáº§n 1 cÃ¡i gháº¿, 2 cÃ¡i báº£ng v.v), Resource Unit Price (Ä‘Æ¡n giÃ¡ cho 1 Ä‘Æ¡n vá»‹ tÃ i nguyÃªn, vd cÃ¡i gháº¿ giÃ¡ 7 ngÃ n, cÃ¡i báº£ng giÃ¡ 10 ngÃ n, náº¿u 1 unit lÃ  gháº¿ + báº£ng thÃ¬ lÃ  17 ngÃ n), Resource Vendor Name(nhÃ  cung cáº¥p, vd: Amazon Business, Woodwind and Brasswind).\nFile Projects.csv\nXÃ¢y dá»±ng chiáº¿n lÆ°á»£c tiáº¿p cáº­n bÃ i toÃ¡n HÃ£y xem Ä‘Ã¢y nhÆ° lÃ  bÃ i toÃ¡n gá»£i Ã½. VÃ  Donors chÃ­nh lÃ  há»‡ thá»‘ng cung cáº¥p cÃ¡c sáº£n pháº©m. VÃ­ dá»¥ Ä‘Æ¡n giáº£n lÃ  báº¡n cÃ³ website nghe nháº¡c mp3.zing.vn, alice vÃ o nghe má»™t hoáº·c má»™t vÃ i bÃ i nháº¡c. ChÃºng ta sáº½ xÃ¢y dá»±ng má»™t há»‡ gá»£i Ã½ nhá»¯ng bÃ i nháº¡c tiáº¿p theo alice nÃªn nghe dá»±a vÃ o nhá»¯ng bÃ i nháº¡c Ä‘Ã£ nghe trÆ°á»›c Ä‘Ã³ cá»§a alice. TÆ°Æ¡ng tá»± váº­y, há»‡ thá»‘ng Donor nhÆ° lÃ  website mp3.zing, bÃ i nháº¡c tÆ°Æ¡ng tá»± nhÆ° cÃ¡c project Ä‘ang cÃ³, ngÆ°á»i dÃ¹ng tÆ°Æ¡ng tá»± nhÆ° cÃ¡c nhÃ  tá»± thiá»‡n. Má»™t khi má»™t nhÃ  tá»« thiá»‡n Ä‘Ã£ quyÃªn gÃ³p cho 1 hoáº·c 1 nhÃ³n cÃ¡c dá»± Ã¡n, chÃºng ta sáº½ lÃªn káº¿ hoáº¡ch vÃ  gá»£i Ã½ cho khÃ¡c hÃ ng dá»± Ã¡n tiáº¿p theo khÃ¡ch hÃ ng nÃªn tÃ¬m hiá»ƒu ká»¹ Ä‘á»ƒ xÃ©t xem cÃ³ nÃªn donate hay khÃ´ng.\nDá»±a vÃ o cÃ¡c chiáº¿n lÆ°á»£c trÃªn, chÃºng ta cÃ³ 3 cÃ¡ch cÃ³ thá»ƒ tiáº¿p cáº­n váº¥n Ä‘á»:\nContent-based filltering. Collaborative Filtering Hybrid methods 1. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u TrÆ°á»›c khi báº¯t Ä‘áº§u xÃ¢y dá»±ng chÆ°Æ¡ng trÃ¬nh gá»£i Ã½, chÃºng ta cáº§n pháº£i load dá»¯ liá»‡u lÃªn bá»™ nhá»› chÃ­nh vÃ  lÃ m sáº¡ch dá»¯ liá»‡u.\nTrÆ°á»›c tiÃªn, chÃºng ta sáº½ import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t. Náº¿u thiáº¿u cÃ¡c thÆ° viá»‡n nÃ o, cÃ¡c báº¡n cá»© pip install tÃªn thÆ° viá»‡n trong cmd/terminal lÃ  Ä‘Æ°á»£c\n1 2import numpy as np 3import scipy 4import pandas as pd 5import math 6import random 7import sklearn 8from nltk.corpus import stopwords 9from sklearn.model_selection import train_test_split 10from sklearn.feature_extraction.text import TfidfVectorizer 11from sklearn.metrics.pairwise import cosine_similarity 12from scipy.sparse.linalg import svds 13import matplotlib.pyplot as plt 14import os Tiáº¿p theo, chÃºng ta sáº½ load 3 file Projects.csv, Donations.csv, Donors.csv lÃªn vÃ  merge donations vá»›i donors.\n1# Set up test mode to save some time 2test_mode = True 3 4# Read datasets 5projects = pd.read_csv(\u0026#39;../input/Projects.csv\u0026#39;) 6donations = pd.read_csv(\u0026#39;../input/Donations.csv\u0026#39;) 7donors = pd.read_csv(\u0026#39;../input/Donors.csv\u0026#39;) 8 9#this piece of code converts Project_ID which is a 32-bit Hex int digits 10-1010 10# create column \u0026#34;project_id\u0026#34; with sequential integers 11f=len(projects) 12projects[\u0026#39;project_id\u0026#39;] = np.nan 13g = list(range(10,f+10)) 14g = pd.Series(g) 15projects[\u0026#39;project_id\u0026#39;] = g.values 16 17# Merge datasets 18donations = donations.merge(donors, on=\u0026#34;Donor ID\u0026#34;, how=\u0026#34;left\u0026#34;) 19df = donations.merge(projects,on=\u0026#34;Project ID\u0026#34;, how=\u0026#34;left\u0026#34;) 20 21# only load a few lines in test mode 22if test_mode: 23 df = df.head(10000) 24 25donations_df = df á» giai Ä‘oáº¡n xÃ¢y dá»±ng code vÃ  debug, mÃ¬nh chá»‰ load 10000 dá»¯ liá»‡u lÃªn Ä‘á»ƒ test thá»­ (Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng mÃ¬nh code Ä‘Ãºng - báº±ng cÃ¡ch set test_mode = True). Khi cháº¡y tháº­t mÃ¬nh sáº½ set láº¡i test_mode = False.\nThá»±c hiá»‡n má»™t vÃ i bÆ°á»›c phÃ¢n tÃ­ch ká»¹ thuáº­t Ä‘Æ¡n giáº£n Ä‘á»ƒ náº¯m rÃµ hÆ¡n vá» dá»¯ liá»‡u.\nThá»­ Ä‘o má»‘i quan há»‡ giá»¯a cÃ¡c dá»± Ã¡n vÃ  cÃ¡c \u0026ldquo;máº¡nh thÆ°á»ng quÃ¢n\u0026rdquo;\n1# Deal with missing values 2donations[\u0026#34;Donation Amount\u0026#34;] = donations[\u0026#34;Donation Amount\u0026#34;].fillna(0) 3 4# Define event strength as the donated amount to a certain project 5donations_df[\u0026#39;eventStrength\u0026#39;] = donations_df[\u0026#39;Donation Amount\u0026#39;] 6 7def smooth_donor_preference(x): 8 return math.log(1+x, 2) 9 10donations_full_df = donations_df \\ 11 .groupby([\u0026#39;Donor ID\u0026#39;, \u0026#39;Project ID\u0026#39;])[\u0026#39;eventStrength\u0026#39;].sum() \\ 12 .apply(smooth_donor_preference).reset_index() 13 14# Update projects dataset 15project_cols = projects.columns 16projects = df[project_cols].drop_duplicates() 17 18print(\u0026#39;# of projects: %d\u0026#39; % len(projects)) 19print(\u0026#39;# of unique user/project donations: %d\u0026#39; % len(donations_full_df)) 1# of projects: 1889 2# of unique user/project donations: 8648 Dá»±a vÃ o káº¿t quáº£ trÃªn táº­p test, chÃºng ta cÃ³ thá»ƒ Ä‘Æ°a ra má»™t vÃ i nháº­n xÃ©t nhÆ° sau:\nHáº§u háº¿t cÃ¡c máº¡nh thÆ°á»ng quÃ¢n chá»‰ donate cho 1 project (tá»· lá»‡ 86,48%) Sáº½ cÃ³ trÆ°á»ng há»£p 1 máº¡nh thÆ°á»ng quÃ¢n sáº½ donate cho nhiá»u dá»± Ã¡n, vÃ  cÅ©ng cÃ³ trÆ°á»ng há»£p 1 máº¡nh thÆ°á»ng quÃ¢n donate nhiá»u láº§n cho 1 dá»± Ã¡n. TrÆ°á»ng há»£p nÃ y chiáº¿m pháº§n Ã­t. Äá»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh, chÃºng ta sáº½ chia táº­p dá»¯ liá»‡u thÃ nh 2 pháº§n lÃ  train vÃ  test. á» Ä‘Ã¢y, chÃºng ta sáº½ set tá»· lá»‡ train/test lÃ  20%.\n2. XÃ¢y dá»±ng mÃ´ hÃ¬nh Content-Based Filtering CÃ¡ch tiáº¿p cáº­n Ä‘áº§u tiÃªn, chÃºng ta sáº½ tÃ¬m nhá»¯ng project gáº§n giá»‘ng vá»›i nhá»¯ng project mÃ  donor Ä‘Ã£ donated. ÄÆ¡n giáº£n nháº¥t lÃ  vá»›i má»—i project, chÃºng ta sáº½ Ä‘á»‹nh nghÄ©a cÃ¡c vector Ä‘áº·c trÆ°ng cá»§a chÃºng vÃ  Ä‘o Ä‘á»™ giá»‘ng nhau giá»¯a hai vector Ä‘Ã³. Vector Ä‘áº·c trÆ°ng chÃºng ta cÃ³ thá»ƒ xÃ¢y dá»±ng trÃªn cÃ¡c thuá»™c tÃ­nh nhÆ° project type, project catefory, grade level, resource category, cost, school zip code, \u0026hellip; hoáº·c cÃ¡c báº¡n cÃ³ thá»ƒ tá»« cÃ¡c vector cÆ¡ báº£n do táº­p dá»¯ liá»‡u cung cáº¥p bá»• sung thÃªm cÃ¡c vector cáº¥p cao hÆ¡n, vÃ­ dá»¥ nhÆ° lÃ  rÃºt trÃ­ch cÃ¡c feature tá»« tÃªn project hoáº·c mÃ´ táº£ cá»§a project, loáº¡i bá» stopwords \u0026hellip;\ná» Ä‘Ã¢y, chÃºng ta sáº½ sá»­ dá»¥ng ká»¹ thuáº­t TF-IDF Ä‘á»ƒ rÃºt trÃ­ch thÃ´ng tin Ä‘áº·c trÆ°ng cá»§a dá»± Ã¡n dá»±a trÃªn project tittle vÃ  description. Vá» TF-IDF, cÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»c á»Ÿ má»™t bÃ i viáº¿t nÃ o Ä‘Ã³ cá»§a google, mÃ¬nh khÃ´ng tiá»‡n nháº¯c Ä‘áº¿n nÃ³ chi tiáº¿t á»Ÿ bÃ i viáº¿t nÃ y.\na. XÃ¢y dá»±ng táº­p Ä‘áº·c trÆ°ng 1 2# Preprocessing of text data 3textfeats = [\u0026#34;Project Title\u0026#34;,\u0026#34;Project Essay\u0026#34;] 4for cols in textfeats: 5 projects[cols] = projects[cols].astype(str) 6 projects[cols] = projects[cols].astype(str).fillna(\u0026#39;\u0026#39;) # FILL NA 7 projects[cols] = projects[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently 8 9text = projects[\u0026#34;Project Title\u0026#34;] + \u0026#39; \u0026#39; + projects[\u0026#34;Project Essay\u0026#34;] 10vectorizer = TfidfVectorizer(strip_accents=\u0026#39;unicode\u0026#39;, 11 analyzer=\u0026#39;word\u0026#39;, 12 lowercase=True, # Convert all uppercase to lowercase 13 stop_words=\u0026#39;english\u0026#39;, # Remove commonly found english words (\u0026#39;it\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;the\u0026#39;) which do not typically contain much signal 14 max_df = 0.9, # Only consider words that appear in fewer than max_df percent of all documents 15 # max_features=5000 # Maximum features to be extracted 16 ) 17project_ids = projects[\u0026#39;Project ID\u0026#39;].tolist() 18tfidf_matrix = vectorizer.fit_transform(text) 19tfidf_feature_names = vectorizer.get_feature_names() 20 21 22# build profile 23 24def get_project_profile(project_id): 25 idx = project_ids.index(project_id) 26 project_profile = tfidf_matrix[idx:idx+1] 27 return project_profile 28 29def get_project_profiles(ids): 30 project_profiles_list = [get_project_profile(x) for x in np.ravel([ids])] 31 project_profiles = scipy.sparse.vstack(project_profiles_list) 32 return project_profiles 33 34def build_donors_profile(donor_id, donations_indexed_df): 35 donations_donor_df = donations_indexed_df.loc[donor_id] 36 donor_project_profiles = get_project_profiles(donations_donor_df[\u0026#39;Project ID\u0026#39;]) 37 donor_project_strengths = np.array(donations_donor_df[\u0026#39;eventStrength\u0026#39;]).reshape(-1,1) 38 #Weighted average of project profiles by the donations strength 39 donor_project_strengths_weighted_avg = np.sum(donor_project_profiles.multiply(donor_project_strengths), axis=0) / (np.sum(donor_project_strengths)+1) 40 donor_profile_norm = sklearn.preprocessing.normalize(donor_project_strengths_weighted_avg) 41 return donor_profile_norm 42 43from tqdm import tqdm 44 45def build_donors_profiles(): 46 donations_indexed_df = donations_full_df[donations_full_df[\u0026#39;Project ID\u0026#39;].isin(projects[\u0026#39;Project ID\u0026#39;])].set_index(\u0026#39;Donor ID\u0026#39;) 47 donor_profiles = {} 48 for donor_id in tqdm(donations_indexed_df.index.unique()): 49 donor_profiles[donor_id] = build_donors_profile(donor_id, donations_indexed_df) 50 return donor_profiles 51 52donor_profiles = build_donors_profiles() 53print(\u0026#34;# of donors with profiles: %d\u0026#34; % len(donor_profiles)) 54 55mydonor1 = \u0026#34;6d5b22d39e68c656071a842732c63a0c\u0026#34; 56mydonor2 = \u0026#34;0016b23800f7ea46424b3254f016007a\u0026#34; 57mydonor1_profile = pd.DataFrame(sorted(zip(tfidf_feature_names, 58 donor_profiles[mydonor1].flatten().tolist()), 59 key=lambda x: -x[1])[:10], 60 columns=[\u0026#39;token\u0026#39;, \u0026#39;relevance\u0026#39;]) 61mydonor2_profile = pd.DataFrame(sorted(zip(tfidf_feature_names, 62 donor_profiles[mydonor2].flatten().tolist()), 63 key=lambda x: -x[1])[:10], 64 columns=[\u0026#39;token\u0026#39;, \u0026#39;relevance\u0026#39;]) 65 66print(\u0026#39;feature of user \u0026#39; + str(mydonor1)) 67print(mydonor1_profile) 68 69print(\u0026#39;feature of user \u0026#39; + str(mydonor2)) 70print(mydonor2_profile) MÃ£ nguá»“n á»Ÿ trÃªn cÅ©ng cÃ³ chÃº thÃ­ch Ä‘áº§y Ä‘á»§, vÃ  Ä‘á»c cÅ©ng dá»… hiá»ƒu, nÃªn mÃ¬nh khÃ´ng nÃ³i thÃªm gÃ¬ nhiá»u. MÃ¬nh tÃ³m gá»n má»™t chÃºt lÃ  chÃºng ta sáº½ convert toÃ n bá»™ project tittle vÃ  description vá» dáº¡ng chá»¯ thÆ°á»ng, tÃ¡ch tá»« dá»±a vÃ o khoáº£ng tráº¯ng, loáº¡i bá» nhá»¯ng english stopwords. Sau Ä‘Ã³ xÃ¢y dá»±ng profile cho tá»«ng donor.\nKáº¿t quáº£\n1feature of user 6d5b22d39e68c656071a842732c63a0c 2 token relevance 30 music 0.450057 41 auditorium 0.355256 52 cart 0.272809 63 chair 0.223861 74 equipment 0.211338 85 musicians 0.179244 96 time 0.172908 107 moving 0.137749 118 ohms 0.134065 129 prepare 0.131274 13feature of user 0016b23800f7ea46424b3254f016007a 14 token relevance 150 pollinators 0.670222 161 plants 0.305398 172 module 0.223407 183 pollination 0.211870 194 seeds 0.180609 205 writing 0.166816 216 books 0.137455 227 reading 0.115003 238 weaved 0.111704 249 bees 0.101842 NhÃ¬n káº¿t quáº£ trÃªn, ta tháº¥y ráº±ng donor 1 cÃ³ váº» thÃ­ch nhá»¯ng thá»© liÃªn quan Ä‘áº¿n Ã¢m nháº¡c (music, auditorim), trong khi Ä‘Ã³ donor 2 thÃ­ch nhá»¯ng thá»© liÃªn quan Ä‘áº¿n trá»“ng trá»t (pollinators - thá»¥ pháº¥n, plants - cÃ¢y cá»‘i)\nb. XÃ¢y dá»±ng mÃ´ hÃ¬nh Viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh Ä‘áº¿n Ä‘Ã¢y lÃ  khÃ¡ Ä‘Æ¡n giáº£n. ChÃºng ta chá»‰ viá»‡c tÃ­nh khoáº£ng cÃ¡ch cosin giá»¯a vector cáº§n dá»± Ä‘oÃ¡n vÃ  toÃ n bá»™ vector cÃ³ trong táº­p train rá»“i show top K prject cÃ³ liÃªn quan cao nháº¥t\n1 2 3class ContentBasedRecommender: 4 5 MODEL_NAME = \u0026#39;Content-Based\u0026#39; 6 7 def __init__(self, projects_df=None): 8 self.project_ids = project_ids 9 self.projects_df = projects_df 10 11 def get_model_name(self): 12 return self.MODEL_NAME 13 14 def _get_similar_projects_to_donor_profile(self, donor_id, topn=1000): 15 #Computes the cosine similarity between the donor profile and all project profiles 16 cosine_similarities = cosine_similarity(donor_profiles[donor_id], tfidf_matrix) 17 #Gets the top similar projects 18 similar_indices = cosine_similarities.argsort().flatten()[-topn:] 19 #Sort the similar projects by similarity 20 similar_projects = sorted([(project_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1]) 21 return similar_projects 22 23 def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10, verbose=False): 24 similar_projects = self._get_similar_projects_to_donor_profile(donor_id) 25 #Ignores projects the donor has already donated 26 similar_projects_filtered = list(filter(lambda x: x[0] not in projects_to_ignore, similar_projects)) 27 28 recommendations_df = pd.DataFrame(similar_projects_filtered, columns=[\u0026#39;Project ID\u0026#39;, \u0026#39;recStrength\u0026#39;]).head(topn) 29 30 recommendations_df = recommendations_df.merge(self.projects_df, how = \u0026#39;left\u0026#39;, 31 left_on = \u0026#39;Project ID\u0026#39;, 32 right_on = \u0026#39;Project ID\u0026#39;)[[\u0026#39;recStrength\u0026#39;, \u0026#39;Project ID\u0026#39;, \u0026#39;Project Title\u0026#39;, \u0026#39;Project Essay\u0026#39;]] 33 34 35 return recommendations_df 36 37 38cbr_model = ContentBasedRecommender(projects) 39 40 41print(\u0026#39;recommend for user \u0026#39; + str(mydonor1)) 42print(cbr_model.recommend_projects(mydonor1)) 43 44print(\u0026#39;recommend for user \u0026#39; + str(mydonor2)) 45print(cbr_model.recommend_projects(mydonor2)) Káº¿t quáº£\n1recommend for user 6d5b22d39e68c656071a842732c63a0c 2 recStrength ... Project Essay 30 1.000000 ... the music students in our classes perform freq... 41 0.390997 ... i have spent 12 years as an educator rebuildin... 52 0.338676 ... \u0026#34;music is what feelings sound like.\u0026#34; -g. cates... 63 0.331034 ... true music is created not by the teacher but b... 74 0.324355 ... every morning my first grade students come to ... 85 0.322923 ... in today\u0026#39;s fast paced environment, students ne... 96 0.315910 ... \u0026#34;music is a moral law. it gives soul to the u... 107 0.314845 ... i walk in the door so excited to get the stude... 118 0.310103 ... some students have never put their hands on a ... 129 0.297516 ... my students do not have money, but they do hav... 13 14[10 rows x 4 columns] 15recommend for user 0016b23800f7ea46424b3254f016007a 16 recStrength ... Project Essay 170 1.000000 ... my students are creative, curious, and excited... 181 0.211962 ... our school is a title 1 school. 100% of stude... 192 0.189111 ... my students are active and eager learners who ... 203 0.188095 ... being a small rural school we do a lot of trad... 214 0.173520 ... \u0026#34;science is a way of life...science is the pro... 225 0.159015 ... my second grade students love to come to schoo... 236 0.158071 ... i teach 28 fourth graders in a neighborhood sc... 247 0.150389 ... in my classroom we are working hard to become ... 258 0.144724 ... as a teacher in a diverse, low-income, high-po... 269 0.139937 ... have you ever been told you need to read, but ... 27 28[10 rows x 4 columns] MÃ¬nh dÃ¹ng cmd nÃªn bá»‹ giá»›i háº¡n káº¿t quáº£, cÃ¡c báº¡n cÃ³ thá»ƒ write log vÃ o file hoáº·c dÃ¹ng jupiter Ä‘á»ƒ show káº¿t quáº£ rÃµ hÆ¡n.\ná» Ä‘Ã¢y, chÃºng ta nháº­n tháº¥y ráº±ng cÃ¡c recommend cho donor 1 thÆ°á»ng lÃ  nhá»¯ng project liÃªn quan tá»›i Ã¢m nháº¡c (nhÃ¬n táº­p feature ta cÅ©ng cÃ³ thá»ƒ Ä‘oÃ¡n Ä‘Æ°á»£c). VÃ  recommend cho donor 2 lÃ  nhá»¯ng thá»© liÃªn quan Ä‘áº¿n chá»§ Ä‘á» lÃ m vÆ°á»n vÃ  reading.\n3. Collaborative Filtering Model LÃ½ thuyáº¿t vá» Collaborative Filtering Model cÃ¡c báº¡n cÃ³ thá»ƒ xem á»Ÿ cÃ¡c bÃ i viáº¿t khÃ¡c cá»§a mÃ¬nh hoáº·c tham kháº£o thÃªm trÃªn máº¡ng. á» Ä‘Ã¢y, mÃ¬nh sáº½ sá»­ dá»¥ng Singular Value Decomposition (SVD) Ä‘á»ƒ xÃ¢y dá»±ng ma tráº­n Ä‘áº·c trÆ°ng.\na. XÃ¢y dá»±ng ma tráº­n donor - project Äáº§u tiÃªn, chÃºng ta sáº½ xÃ¢y dá»±ng ma tráº­n má»‘i quan há»‡ giá»¯a donor vÃ  project. Náº¿u donor i cÃ³ donated cho 1 project j thÃ¬ dÃ²ng i cá»™t j cá»§a ma tráº­n sáº½ Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u lÃ  1, ngÆ°á»£c láº¡i lÃ  0.\n1## create matrix 2#Creating a sparse pivot table with donors in rows and projects in columns 3donors_projects_pivot_matrix_df = donations_full_df.pivot(index=\u0026#39;Donor ID\u0026#39;, 4 columns=\u0026#39;Project ID\u0026#39;, 5 values=\u0026#39;eventStrength\u0026#39;).fillna(0) 6 7# Transform the donor-project dataframe into a matrix 8donors_projects_pivot_matrix = donors_projects_pivot_matrix_df.as_matrix() 9 10# Get donor ids 11donors_ids = list(donors_projects_pivot_matrix_df.index) 12 13print(donors_projects_pivot_matrix[:5]) # print first 5 row 1 2array([[ 0., 0., 0., ..., 0., 0., 0.], 3 [ 0., 0., 0., ..., 0., 0., 0.], 4 [ 0., 0., 0., ..., 0., 0., 0.], 5 [ 0., 0., 0., ..., 0., 0., 0.], 6 [ 0., 0., 0., ..., 0., 0., 0.]]) b. Singular Value Decomposition Sau khi cÃ³ ma tráº­n trÃªn, ta cÃ³ má»™t nháº­n xÃ©t ráº±ng nÃ³ ráº¥t thÆ°a, sá»‘ lÆ°á»£ng 0 thÃ¬ nhiá»u mÃ  1 thÃ¬ Ã­t. Sau khi Ã¡p dá»¥ng SVD, ma tráº­n káº¿t quáº£ sáº½ Ã­t thÆ°a hÆ¡n (cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘áº¿n má»©c khÃ´ng cÃ²n thÆ°a ná»¯a).\n1# Performs matrix factorization of the original donor-project matrix 2# Here we set k = 20, which is the number of factors we are going to get 3# In the definition of SVD, an original matrix A is approxmated as a product A â‰ˆ UÎ£V 4# where U and V have orthonormal columns, and Î£ is non-negative diagonal. 5U, sigma, Vt = svds(donors_projects_pivot_matrix, k = 20) 6sigma = np.diag(sigma) 7 8# Reconstruct the matrix by multiplying its factors 9all_donor_predicted_ratings = np.dot(np.dot(U, sigma), Vt) 10 11#Converting the reconstructed matrix back to a Pandas dataframe 12cf_preds_df = pd.DataFrame(all_donor_predicted_ratings, 13 columns = donors_projects_pivot_matrix_df.columns, 14 index=donors_ids).transpose() 15 16print(cf_preds_df.head()) 1 0003aba06ccf49f8c44fc2dd3b582411 ... ffff088c35d3455779a30898d1327b76 2Project ID ... 3 4000009891526c0ade7180f8423792063 -3.423182e-34 ...-4.577244e-34 500000ce845c00cbf0686c992fc369df4 -3.061322e-36 ...-6.492305e-36 600002d44003ed46b066607c5455a999a 1.368936e-33 ...-2.239156e-32 700002eb25d60a09c318efbd0797bffb5 1.784576e-33 ...1.163684e-32 80000300773fe015f870914b42528541b 4.314216e-34 ...-4.666110e-34 9 10[5 rows x 8015 columns] c. XÃ¢y dá»±ng Collaborative Filtering Model 1 2 3class CFRecommender: 4 5 MODEL_NAME = \u0026#39;Collaborative Filtering\u0026#39; 6 7 def __init__(self, cf_predictions_df, projects_df=None): 8 self.cf_predictions_df = cf_predictions_df 9 self.projects_df = projects_df 10 11 def get_model_name(self): 12 return self.MODEL_NAME 13 14 def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10): 15 # Get and sort the donor\u0026#39;s predictions 16 sorted_donor_predictions = self.cf_predictions_df[donor_id].sort_values(ascending=False) \\ 17 .reset_index().rename(columns={donor_id: \u0026#39;recStrength\u0026#39;}) 18 19 # Recommend the highest predicted projects that the donor hasn\u0026#39;t donated to 20 recommendations_df = sorted_donor_predictions[~sorted_donor_predictions[\u0026#39;Project ID\u0026#39;].isin(projects_to_ignore)] \\ 21 .sort_values(\u0026#39;recStrength\u0026#39;, ascending = False) \\ 22 .head(topn) 23 24 25 recommendations_df = recommendations_df.merge(self.projects_df, how = \u0026#39;left\u0026#39;, 26 left_on = \u0026#39;Project ID\u0026#39;, 27 right_on = \u0026#39;Project ID\u0026#39;)[[\u0026#39;recStrength\u0026#39;, \u0026#39;Project ID\u0026#39;, \u0026#39;Project Title\u0026#39;, \u0026#39;Project Essay\u0026#39;]] 28 29 30 return recommendations_df 31 32cfr_model = CFRecommender(cf_preds_df, projects) 33print(cfr_model.recommend_projects(mydonor1)) 34 35print(cfr_model.recommend_projects(mydonor2)) 1[5 rows x 8015 columns] 2 recStrength ... Project Essay 30 3.015461e-17 ... Our students are some of the hardest working k... 41 2.237275e-17 ... As Service Learning Coordinators at our elemen... 52 2.188501e-17 ... We are trying to engage more students in scien... 63 1.768711e-17 ... We are a brand new charter school that has onl... 74 1.344489e-17 ... Sitting at a desk for a sustained period of ti... 85 9.957278e-18 ... Our students come from a Title I school in Jer... 96 6.932330e-18 ... In my school 50% of the students are socioecon... 107 8.589640e-19 ... Have you ever been told you need to read, but ... 118 6.698040e-19 ... \u0026#34;I cannot say good-bye to those whom I have gr... 129 5.733941e-19 ... I have students in class who are squinting and... 13 14[10 rows x 4 columns] 15 recStrength ... Project Essay 160 3.015461e-17 ... Our students are some of the hardest working k... 171 2.237275e-17 ... As Service Learning Coordinators at our elemen... 182 2.188501e-17 ... We are trying to engage more students in scien... 193 1.768711e-17 ... We are a brand new charter school that has onl... 204 1.344489e-17 ... Sitting at a desk for a sustained period of ti... 215 9.957278e-18 ... Our students come from a Title I school in Jer... 226 6.932330e-18 ... In my school 50% of the students are socioecon... 237 8.589640e-19 ... Have you ever been told you need to read, but ... 248 6.698040e-19 ... \u0026#34;I cannot say good-bye to those whom I have gr... 259 5.733941e-19 ... I have students in class who are squinting and... Káº¿t quáº£ tráº£ vá» cÃ³ váº» khÃ´ng Ä‘Æ°á»£c Ä‘áº¹p nhÆ° á»Ÿ phÆ°Æ¡ng phÃ¡p trÃªn. á» Ä‘Ã¢y, thuáº­t toÃ¡n dá»±a vÃ o hÃ nh vi donated cá»§a nhá»¯ng ngÆ°á»i khÃ¡c cÃ³ Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng vá»›i user donor 1 vÃ  2. Bá»Ÿi váº­y gá»£i Ã½ nhá»¯ng project sáº½ khÃ¡c nhá»¯ng gá»£i Ã½ á»Ÿ phÆ°Æ¡ng phÃ¡p 1.\n4. Hybrid Method PhÆ°Æ¡ng phÃ¡p lai nÃ y káº¿t há»£p cáº£ 2 hÆ°á»›ng tiáº¿p cáº­n cá»§a hai phÆ°Æ¡ng phÃ¡p á»Ÿ trÃªn. á» Ä‘Ã¢y, chÃºng ta sáº½ xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh nhá», nhÃ¢n Ä‘iá»ƒm cá»§a content based vÃ  collaborative filtering láº¡i vá»›i nhau, sau Ä‘Ã³ xáº¿p háº¡ng Ä‘á»ƒ Ä‘Æ°á»£c Ä‘iá»ƒm hybrid. ÄÃ¢y lÃ  1 cÃ¡ch Ä‘Æ¡n giáº£n, cÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m Ä‘á»c nhiá»u cÃ¡ch tiáº¿p cáº­n khÃ¡c vÃ  á»©ng dá»¥ng vÃ o bÃ i toÃ¡n.\n1class HybridRecommender: 2 3 MODEL_NAME = \u0026#39;Hybrid\u0026#39; 4 5 def __init__(self, cb_rec_model, cf_rec_model, projects_df): 6 self.cb_rec_model = cb_rec_model 7 self.cf_rec_model = cf_rec_model 8 self.projects_df = projects_df 9 10 def get_model_name(self): 11 return self.MODEL_NAME 12 13 def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10): 14 #Getting the top-1000 Content-based filtering recommendations 15 cb_recs_df = self.cb_rec_model.recommend_projects(donor_id, projects_to_ignore=projects_to_ignore, 16 topn=1000).rename(columns={\u0026#39;recStrength\u0026#39;: \u0026#39;recStrengthCB\u0026#39;}) 17 18 #Getting the top-1000 Collaborative filtering recommendations 19 cf_recs_df = self.cf_rec_model.recommend_projects(donor_id, projects_to_ignore=projects_to_ignore, 20 topn=1000).rename(columns={\u0026#39;recStrength\u0026#39;: \u0026#39;recStrengthCF\u0026#39;}) 21 22 #Combining the results by Project ID 23 recs_df = cb_recs_df.merge(cf_recs_df, 24 how = \u0026#39;inner\u0026#39;, 25 left_on = \u0026#39;Project ID\u0026#39;, 26 right_on = \u0026#39;Project ID\u0026#39;) 27 28 #Computing a hybrid recommendation score based on CF and CB scores 29 recs_df[\u0026#39;recStrengthHybrid\u0026#39;] = recs_df[\u0026#39;recStrengthCB\u0026#39;] * recs_df[\u0026#39;recStrengthCF\u0026#39;] 30 31 #Sorting recommendations by hybrid score 32 recommendations_df = recs_df.sort_values(\u0026#39;recStrengthHybrid\u0026#39;, ascending=False).head(topn) 33 34 recommendations_df = recommendations_df.merge(self.projects_df, how = \u0026#39;left\u0026#39;, 35 left_on = \u0026#39;Project ID\u0026#39;, 36 right_on = \u0026#39;Project ID\u0026#39;)[[\u0026#39;recStrengthHybrid\u0026#39;, 37 \u0026#39;Project ID\u0026#39;, \u0026#39;Project Title\u0026#39;, 38 \u0026#39;Project Essay\u0026#39;]] 39 40 41 return recommendations_df 42 43hybrid_model = HybridRecommender(cbr_model, cfr_model, projects) 44 45 46print(hybrid_model.recommend_projects(mydonor1)) 47 48print(hybrid_model.recommend_projects(mydonor2)) 1 recStrengthHybrid ... Project Essay 20 1.574375e-18 ... we are trying to engage more students in scien... 31 1.221807e-18 ... in my school 50% of the students are socioecon... 42 1.214293e-18 ... our students are some of the hardest working k... 53 4.037232e-19 ... sitting at a desk for a sustained period of ti... 64 6.661794e-20 ... â€œmusic expresses that which cannot be put into... 75 4.872264e-20 ... i walk in the door so excited to get the stude... 86 4.410098e-20 ... i have spent 12 years as an educator rebuildin... 97 2.907349e-20 ... \u0026#34;music is what feelings sound like.\u0026#34; -g. cates... 108 2.121616e-20 ... \u0026#34;i cannot say good-bye to those whom i have gr... 119 1.353927e-20 ... our band program is one of the largest in our ... 12 13[10 rows x 4 columns] 14 recStrengthHybrid ... Project Essay 150 2.811124e-18 ... in this modern, digital age, i would like to u... 161 1.249967e-18 ... we are a brand new charter school that has onl... 172 6.055628e-19 ... my students are african american and hispanic.... 183 5.912367e-19 ... the a. community and its students are a very s... 194 2.541749e-19 ... do you want to go on an adventure and learn ab... 205 2.494812e-19 ... the average day in my class involves students ... 216 2.323313e-19 ... i teach ela (reading component) to self-contai... 227 1.271629e-19 ... hi there! do you want to help to instill a lif... 238 1.044990e-19 ... having writing utensils is essential for stude... 249 1.004780e-19 ... there\u0026#39;s no such thing as a kid who hates readi... 25 26[10 rows x 4 columns] Káº¿t quáº£ tráº£ ra tá»‘t hÆ¡n nhiá»u so vá»›i cÃ¡ch 2, donor1 cÃ³ music, donor2 cÃ³ cÃ¢y trá»“ng vÃ  sÃ¡ch.\n5. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh CÃ³ ráº¥t nhiá»u cÃ¡ch khÃ¡c nhau Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh recommend system. Má»™t trong cÃ¡c cÃ¡ch mÃ¬nh sá»­ dá»¥ng á»Ÿ Ä‘Ã¢y lÃ  sá»­ dá»¥ng Ä‘á»™ Ä‘o top K accuracy. Äá»™ Ä‘o nÃ y Ä‘Æ°á»£c tÃ­nh nhÆ° sau:\nVá»›i má»—i user: Vá»›i má»—i item user Ä‘Ã£ pick trong test set Láº¥y máº«u 1000 item khÃ¡c mÃ  ngÆ°á»i dÃ¹ng chÆ°a bao giá» pick\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo. Cá»‘ lÃªn.\n","date":"Dec 11, 2018","img":"","permalink":"/blog/2019-01-03-donor-project-matching-with-recommender-systems/","series":null,"tags":["Machine learning","Deeplearning","recommender system"],"title":"Há»‡ Thá»‘ng Gá»£i Ã KhoÃ¡ Há»c Cho Website DonorChoose.org"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Kiá»ƒm tra dá»¯ liá»‡u Lá»i má»Ÿ Ä‘áº§u Viá»‡c huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh neural network khÃ¡ Ä‘Æ¡n giáº£n, chá»‰ viá»‡c download code máº«u vá», quÄƒng táº­p data cá»§a mÃ¬nh vÃ o, rá»“i cho cháº¡y, xong. NhÆ°ng khÃ³ khÄƒn á»Ÿ Ä‘Ã¢y lÃ  lÃ m cÃ¡ch nÃ o Ä‘á»ƒ nÃ¢ng Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh lÃªn. á» bÃ i viáº¿t nÃ y, chÃºng ta sáº½ tÃ¬m hiá»ƒu má»™t sá»‘ cÃ¡ch giÃºp tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh.\nKiá»ƒm tra dá»¯ liá»‡u Thá»±c cháº¥t, chÃºng ta pháº£i hiá»ƒu rÃµ ká»¹ chÃºng ta Ä‘ang cÃ³ nhá»¯ng gÃ¬ trong tay, thÃ¬ chÃºng ta má»›i dáº¡y cho mÃ¡y há»c Ä‘á»§ vÃ  Ä‘Ãºng Ä‘Æ°á»£c. CÃ¡c báº¡n hÃ£y kiá»ƒm tra tháº­t ká»¹ Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng táº­p nhÃ£n Ä‘Æ°á»£c gÃ¡n chÃ­nh xÃ¡c, bouding box cá»§a Ä‘á»‘i tÆ°á»£ng Ä‘Æ°á»£c váº½ khÃ´ng quÃ¡ dÆ° thá»«a, khÃ´ng cÃ³ missing value, v.v. Má»™t vÃ­ dá»¥ nhá» lÃ  táº­p MNIST, cÃ³ nhiá»u hÃ¬nh bá»‹ nháº­p nháº±ng giá»¯a nhá»¯ng con sá»‘, chÃºng ta khÃ´ng thá»ƒ phÃ¢n biá»‡t Ä‘Æ°á»£c chÃ­nh xÃ¡c hÃ¬nh Ä‘Ã³ lÃ  con sá»‘ nÃ o báº±ng máº¯t thÆ°á»ng.\nTiáº¿p theo, cÃ¡c báº¡n hÃ£y quyáº¿t Ä‘á»‹nh xem ráº±ng mÃ¬nh cÃ³ nÃªn sá»­ dá»¥ng cÃ¡c pre-train model hay khÃ´ng.\nNáº¿u táº­p dá»¯ liá»‡u cá»§a báº¡n gáº§n giá»‘ng vá»›i táº­p dá»¯ liá»‡u ImageNet, hÃ£y dÃ¹ng pre-train model. CÃ³ cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n sáºµn lÃ  VGG net, ResNet, DenseNet, Xception. Vá»›i cÃ¡c kiáº¿n trÃºc khÃ¡c nhau nhÆ° VGG(16 vÃ  19 layer), ResNet (50, 101, 152 layer), DenseNet(201,169,121 layer). Ban Ä‘áº§u, Ä‘á»«ng sá»­ dá»¥ng cÃ¡c kiáº¿n trÃºc cÃ³ sá»‘ lÆ°á»£ng nhiá»u (ResNet152, DenseNet201) bá»Ÿi vÃ¬ nÃ³ ráº¥t tá»‘n chi phÃ­ tÃ­nh toÃ¡n. ChÃºng ta nÃªn báº¯t Ä‘áº§u bá»Ÿi cÃ¡c mÃ´ hÃ¬nh nhá» nhÆ° VGG16, ResNet50. HÃ£y chá»n má»™t mÃ´ hÃ¬nh mÃ  báº¡n nghÄ© lÃ  sáº½ cÃ³ káº¿t quáº£ tá»‘t. Sau khi huáº¥n luyá»‡n, náº¿u káº¿t quáº£ khÃ´ng Ä‘Æ°á»£c nhÆ° Ã½ muá»‘n, hÃ£y tÄƒng sá»‘ lá»›p lÃªn (vÃ­ dá»¥ ban Ä‘áº§u chá»n Resnet50, sau Ä‘Ã³ nÃ¢ng lÃªn Resnet101, \u0026hellip;).\nNáº¿u báº¡n cÃ³ Ã­t dá»¯ liá»‡u, báº¡n nÃ£y \u0026ldquo;Ä‘Ã³ng bÄƒng\u0026rdquo; láº¡i trá»ng sá»‘ cá»§a pre-train model, chá»‰ huáº¥n luyá»‡n pháº§n phÃ¢n lá»›p. Báº¡n cÅ©ng cÃ³ thá»ƒ thÃªm pháº§n Dropout Ä‘á»ƒ trÃ¡nh overfit.\nNáº¿u táº­p dá»¯ liá»‡u cá»§a báº¡n khÃ´ng giá»‘ng má»™t tÃ­ nÃ o so vá»›i taapk ImageNet, khÃ´ng nÃªn dÃ¹ng pre-train model.\nLuÃ´n luÃ´n sá»­ dá»¥ng lá»›p chuáº©n hoÃ¡ trong mÃ´ hÃ¬nh. Náº¿u báº¡n huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i batch-size lá»›n ( vÃ­ dá»¥ lá»›n hÆ¡n 10), hÃ£y sá»­ dá»¥ng BatchNormalization Layer trong keras. Náº¿u báº¡n sá»­ dá»¥ng batch-size nhá» (vÃ­ dá»¥ 1), thÃ¬ hÃ£y sá»­ dá»¥ng InstanceNormalization. Hai layer nÃ y Ä‘Ã£ cÃ³ sáºµn trong Keras, trong cÃ¡c framework khÃ¡c thÃ¬ mÃ¬nh khÃ´ng rÃµ láº¯m. CÃ³ nhiá»u tÃ¡c giáº£ Ä‘Ã£ chá»‰ ra ráº±ng sá»­ dá»¥ng BatchNormalization sáº½ cho káº¿t quáº£ tá»‘t hÆ¡n náº¿u tÄƒng batch-size vÃ  hiá»‡u nÄƒng sáº½ giáº£m khi batch-size nhá», vÃ  trong trÆ°á»ng há»£p batch-size nhá» thÃ¬ káº¿t quáº£ sáº½ tá»‘t hÆ¡n má»™t tÃ­ khi sá»­ dá»¥ng InstanceNormalization thay cho BatchNormalization. NgoÃ i ra, cÃ¡c báº¡n cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng GroupNormalization (mÃ¬nh chÆ°a kiá»ƒm chá»©ng GroupNormalization cÃ³ lÃ m tÄƒng Ä‘á»™ chÃ­nh xÃ¡c hay khÃ´ng).\nNáº¿u báº¡n sá»­ dá»¥ng concatenation layer Ä‘á»ƒ káº¿t há»£p cÃ¡c feature tá»« nhiá»u convolution layers (Li), vÃ  nhá»¯ng Li trÃªn rÃºt trÃ­ch thÃ´ng tin tá»« cÃ¹ng má»™t input (F), thÃ¬ báº¡n jay sá»­ dá»¥ng SpatialDropout ngay sau concatenation layer trÃªn (Xem hÃ¬nh bÃªn dÆ°á»›i). Khi cÃ¡c convolution layer rÃºt trÃ­ch thÃ´ng tin tá»« cÃ¹ng má»™t nguá»“n, cÃ¡c Ä‘áº·c trÆ°ng cá»§a chÃºng thÆ°á»ng sáº½ cÃ³ má»©c tÆ°Æ¡ng quan vá»›i nhau ráº¥t lá»›n. SpatialDropout sáº½ loáº¡i bá» nhá»¯ng Ä‘áº·c trÆ°ng cÃ³ má»©c Ä‘á»™ liÃªn quan cao nÃ y vÃ  giÃºp báº¡n chá»‘ng láº¡i hiá»‡n tÆ°á»£ng overfiting. ThÃ´ng thÆ°á»ng ngÆ°á»i ta chá»‰ sá»­ dá»¥ng SpatialDropout á»Ÿ cÃ¡c lá»›p gáº§n input layer, vÃ  khÃ´ng sá»­ dá»¥ng chÃºng á»Ÿ cÃ¡c lá»›p cao bÃªn trÃªn.\nTheo andrej Karpathy, Ä‘á»ƒ xÃ¡c Ä‘á»‹nh kháº£ nÄƒng lÆ°u trá»¯ thÃ´ng tin cá»§a mÃ´ hÃ¬nh, hÃ£y rÃºt má»™t pháº§n nhá» dá»¯ liá»‡u trong táº­p train cá»§a báº¡n Ä‘em Ä‘i huáº¥n luyá»‡n. Náº¿u mÃ´ hÃ¬nh khÃ´ng overfit, chÃºng ta tÄƒng sá»‘ lÆ°á»£ng node/layer lÃªn. Náº¿u mÃ´ hÃ¬nh bá»‹ overfit, sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° L1, L2, Dropout hoÄƒc cÃ¡c ká»¹ thuáº­t khÃ¡c Ä‘á»ƒ chá»‘ng láº¡i viá»‡c overfit.\nCÃ¡c ká»¹ thuáº­t chuáº©n hoÃ¡ thÆ°á»ng sáº½ rÃ ng buá»™c hoáº·c tinh gá»n cÃ¡c trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh. NÃ³ cÅ©ng Ä‘á»“ng thá»i giÃºp chÃºng ta chá»‘ng láº¡i viá»‡c gradient explosion (gradient mang giÃ¡ trá»‹ lá»›n khi tÃ­nh backpropagation) (lÃ½ do lÃ  cÃ¡c trá»ng sá»‘ sáº½ bá»‹ giá»›i háº¡n trong Ä‘oáº¡n nÃ o Ä‘Ã³, vÃ­ dá»¥ L2 giá»›i háº¡n cÄƒn báº­c 2 tá»•ng bÃ¬nh phÆ°Æ¡ng cÃ¡c trá»ng sá»‘ =1 cháº³ng háº¡n). VÃ­ dá»¥ dÆ°á»›i sá»­ dá»¥ng kares vÃ  giá»›i háº¡n max cá»§a L2 lÃ  2.\n1from keras.constraints import max_norm 2# add to Dense layers 3model.add(Dense(64, kernel_constraint=max_norm(2.))) 4# or add to Conv layers 5model.add(Conv2D(64, kernel_constraint=max_norm(2.))) Viá»‡c sá»­ dá»¥ng mean subtraction Ä‘Ã´i khi cho káº¿t quáº£ khÃ¡ tá»‡, Ä‘áº·c biá»‡t lÃ  khi sá»­ dá»¥ng trong áº£nh xÃ¡m (grayscale image), hoáº·c cÃ¡c bÃ i toÃ¡n phÃ¢n Ä‘oáº¡n áº£nh.\nLuÃ´n nhá»› Ä‘áº¿n viá»‡c xÃ¡o trá»™n dá»¯ liá»‡u (náº¿u báº¡n cÃ³ thá»ƒ). Náº¿u Ä‘Æ°á»£c, hÃ£y thá»±c hiá»‡n xÃ¡o trá»™n dá»¯ liá»‡u trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Viá»‡c xÃ¡o trá»™n áº£nh sáº½ giÃºp báº¡n cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c.\nNáº¿u bÃ i toÃ¡n cá»§a báº¡n thuá»™c nhÃ³m dense prediction (vÃ­ dá»¥ phÃ¢n Ä‘oáº¡n ngá»¯ nghÄ©a - semantic segmentation). HÃ£y sá»­ dá»¥ng pre-train model lÃ  Dilated Residual Networks. MÃ´ hÃ¬nh trÃªn cá»±c ká»³ hiá»‡u quáº£ cho bÃ i toÃ¡n nÃ y.\nÄá»ƒ xÃ¡c Ä‘á»‹nh thÃ´ng tin ngá»¯ cáº£nh xung quanh cÃ¡c Ä‘á»‘i tÆ°á»£ng, hÃ£y sá»­ dá»¥ng module multi-scale feature pooling. Module nÃ y sáº½ giÃºp báº¡n tÄƒng Ä‘á»™ chÃ­nh xÃ¡c vÃ  thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong bÃ i toÃ¡n phÃ¢n Ä‘oáº¡n ngá»¯ nghÄ©a (semantic segmentation) hoáº·c bÃ i toÃ¡n phÃ¢n Ä‘oáº¡n ná»n (foreground segmentation).\nKhi báº¡n tÃ­nh Ä‘á»™ lá»—i hoáº·c Ä‘á»™ chÃ­nh xÃ¡c, náº¿u cÃ³ vÃ¹ng nÃ o khÃ´ng tráº£ vá» nhÃ£n, hoáº·c nhÃ£n tráº£ vá» khÃ´ng cháº¯c cháº¯n, hÃ£y bá» qua viá»‡c tÃ­nh toÃ¡n chÃºng Ä‘i. HÃ nh Ä‘á»™ng nÃ y sáº½ giÃºp mÃ´ hÃ¬nh cá»§a báº¡n cháº¯c cháº¯n hÆ¡n khi Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh.\nSá»­ dá»¥ng trá»ng sá»‘ cho tá»«ng class trong quÃ¡ trÃ¬nh training náº¿u dá»¯ liá»‡u cá»§a báº¡n cÃ³ tÃ­nh báº¥t cÃ¢n báº±ng cao. HÃ£y Ä‘áº·t trá»ng sá»‘ lá»›n cho nhá»¯ng lá»›p cÃ³ Ã­t dá»¯ liá»‡u, vÃ  trá»ng sá»‘ nhá» cho nhá»¯ng lá»›p cÃ³ nhiá»u dá»¯ liá»‡u. Trá»ng sá»‘ cá»§a cÃ¡c lá»›p cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­nh toÃ¡n má»™t cÃ¡ch dá»… dÃ ng báº±ng cÃ¡c sá»­ dá»¥ng thÆ° viá»‡n skearn trong python. NgoÃ i ra, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° OverSampling hoáº·c UnderSampling Ä‘á»‘i vá»›i táº­p dá»¯ liá»‡u nhá».\nChá»n Ä‘Ãºng hÃ m tá»‘i Æ°u. CÃ³ ráº¥t nhiá»u hÃ m tá»‘i Æ°u nhÆ° Adam, Adagrad, Adadellta, RMSprop, \u0026hellip; Trong cÃ¡c paper ngÆ°á»i ta thÆ°á»ng sá»­ dá»¥ng tá»• há»£p SGD + momentun. CÃ³ hai váº¥n Ä‘á» cáº§n Ä‘Æ°á»£c xem xÃ©t á»Ÿ Ä‘Ã¢y: Má»™t lÃ  náº¿u báº¡n muá»‘n mÃ´ hÃ¬nh cÃ³ Ä‘á»™ há»™i tá»¥ nhanh, hÃ£y dÃ¹ng Adam ( vÃ  cÃ³ kháº£ nÄƒng cao lÃ  mÃ´ hÃ¬nh sáº½ bá»‹ káº¹t á»Ÿ Ä‘iá»ƒm cá»±c tiá»ƒu cá»¥c bá»™ -\u0026gt; khÃ´ng cÃ³ tÃ­nh tá»•ng quÃ¡t hoÃ¡ cao). Hai lÃ  sá»­ dujg SGD + momentun Ä‘á»ƒ tÃ¬m cá»±c tiá»ƒu toÃ n cá»¥c, mÃ´ hÃ¬nh nÃ y phá»¥ thuá»™c ráº¥t nhiá»u vÃ o giÃ¡ trá»‹ khá»Ÿi táº¡o ban Ä‘áº§u vÃ  mÃ´ hÃ¬nh thÆ°á»ng sáº½ há»™i tá»¥ ráº¥t cháº­m. (Xem hÃ¬nh bÃªn dÆ°á»›i)\nThÃ´ng thÆ°á»ng, chÃºng ta sáº½ chá»n learning-rate lÃ  (1e-1, 1e-3, 1e-6). Náº¿u báº¡n sá»­ dá»¥ng pre-train model, hÃ£y sá»­ dá»¥ng learning rate nhá» hÆ¡n 1e-3 (vÃ­ dá»¥ 1e-4). Náº¿u báº¡n khÃ´ng sá»­ dá»¥ng pre-train model, hÃ£y sá»­ dá»¥ng learning-rate lá»›n hÆ¡n 1e-3. Báº¡n cÃ³ thá»ƒ grid search giÃ¡ trá»‹ learning-rate vÃ  chá»n ra mÃ´ hÃ¬nh cho káº¿t quáº£ tá»‘t nháº¥t. Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng Learing Rate Schedulers giáº£m giÃ¡ trá»‹n learning rate trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh.\nBÃªn cáº¡nh viá»‡c sá»­ dá»¥ng Learing Rate Schedulers Ä‘á»ƒ giáº£m giÃ¡ trá»‹ learning rate, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng má»™t ká»¹ thuáº­t khÃ¡c Ä‘á»ƒ giáº£m giÃ¡ trá»‹ learning-rate. VÃ­ dá»¥ sau 5 epochs, Ä‘á»™ lá»—i trÃªn táº­p validation khÃ´ng thay Ä‘á»•i, báº¡n giáº£m learning-rate Ä‘i 10 láº§n (vd tá»« 1e-3 thÃ nh 1e-4). Trong keras, báº¡n cÃ³ thá»ƒ dá»… dÃ ng implement cÃ´ng thá»©c trÃªn báº±ng viá»‡c sá»­ dá»¥ng callbacs ReduceLROnPlateau.\n1reduce = keras.callbacks.ReduceLROnPlateau(monitor=\u0026#39;val_loss\u0026#39;, factor=0.1, patience=5, mode=\u0026#39;auto\u0026#39;) 2early = keras.callbacks.EarlyStopping(monitor=\u0026#39;val_loss\u0026#39;, min_delta=1e-4, patience=10, mode=\u0026#39;auto\u0026#39;) 3model.fit(X, Y, callbacks=[reduce, early]) VÃ­ dá»¥ trÃªn, chÃºng ta sáº½ giáº£m learning-rate Ä‘i 10 láº§n khi Ä‘á»™ lá»—i trÃªn táº­p validation khÃ´ng thay Ä‘á»•i qua 5 láº§n láº·p liÃªn tiáº¿p, vÃ  sáº½ dá»«ng viá»‡c huáº¥n luyá»‡n khi Ä‘á»™ lá»—i khÃ´ng giáº£m qua 10 láº§n láº·p liÃªn tiáº¿p.\nNáº¿u bÃ i toÃ¡n cá»§a báº¡n thuá»™c nhÃ³m dense prediction nhÆ° phÃ¢n Ä‘oáº¡n áº£nh, phÃ¢n Ä‘oáº¡n ngá»¯ nghÄ©a, báº¡n nÃªn sá»­ dá»¥ng skip connection Ä‘á»ƒ chá»‘ng láº¡i viá»‡c cÃ¡c biÃªn cá»§a Ä‘á»‘i tÆ°á»£ng hoáº·c cÃ¡c thÃ´ng tin Ä‘áº·c trÆ°ng há»¯u Ã­ch cá»§a Ä‘á»‘i tÆ°á»£ng bá»‹ máº¥t trong max-pooling hoáº·c strided convolution. Skip connection cÅ©ng giÃºp mÃ´ hÃ¬nh há»c features map tá»« feature space vÃ  image space dá»… dÃ ng hÆ¡n, vÃ  nÃ³ cÅ©ng giÃºp cho báº¡n giáº£m bá»‹ vanish gradient ( giÃ¡ trá»‹ gradient nhá» dáº§n vÃ  gáº§n xáº¥p xá»‰ báº±ng 0, nÃªn trá»ng sá»‘ khÃ´ng thay Ä‘á»•i nhiá»u, dáº«n Ä‘áº¿n khÃ´ng há»™i tá»¥).\nNÃªn sá»­ dá»¥ng data augmentation, nhÆ° lÃ  horizontally flipping, rotating, zoom-croping\u0026hellip; Ä‘á»ƒ tÄƒng dá»¯ liá»‡u cá»§a báº¡n lÃªn. Viá»‡c cÃ³ nhiá»u dá»¯ liá»‡u sáº½ giÃºp mÃ´ hÃ¬nh cÃ³ má»©c tá»•ng quÃ¡t hoÃ¡ cao hÆ¡n.\nSá»­ dá»¥ng Max-pooling trÆ°á»›c Relu Ä‘á»ƒ giáº£m thiá»ƒu má»©c Ä‘á»™ tÃ­nh toÃ¡n thay vÃ¬ lÃ m ngÆ°á»£c láº¡i. chÃºng ta biáº¿t ráº±ng ReLU tráº£ ra giÃ¡ trá»‹ cÃ³ ngÆ°á»¡ng cá»±c tiá»ƒu lÃ  0 do f(x)=max(0,x), vÃ  max-pooling tÃ­nh max cho cÃ¡c Ä‘áº·c trÆ°ng f(x) = max(x1,x2,\u0026hellip;,xi). Náº¿u ta sá»­ dá»¥ng Conv \u0026gt; ReLU \u0026gt; Max-pooling, ta sáº½ tá»‘n i láº§n tÃ­nh ReLu, vÃ  1 láº§n tÃ­nh max. Náº¿u ta sá»­ dá»¥ng Conv -\u0026gt; max-pooling \u0026gt; ReLU, ta tá»‘n 1 láº§n tÃ­nh max, 1 láº§n tÃ­nh ReLU.\nNáº¿u cÃ³ thá»ƒ, hÃ£y thá»­ sá»­ dá»¥ng Depthwise Separable Convolution. NÃ³ giÃºp mÃ´ hÃ¬nh giáº£m sá»‘ lÆ°á»£ng tham sá»‘ so vá»›i cÃ¡c convolution khÃ¡c, ngoÃ i ra nÃ³ giÃºp mÃ´ hÃ¬nh cháº¡y nhanh hÆ¡n.\nÄiá»u cuá»‘i cÃ¹ng lÃ  Ä‘á»«ng bao giá» tá»« bá». HÃ£y tin tÆ°á»Ÿng ráº±ng báº¡n cÃ³ thá»ƒ lÃ m Ä‘Æ°á»£c. Náº¿u báº¡n váº«n khÃ´ng thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c nhÆ° mong Ä‘á»£i, hÃ£y Ä‘iá»u chá»‰nh láº¡i cÃ¡c tham sá»‘, kiáº¿n trÃºc mÃ´ hÃ¬nh, táº­p dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘áº¿n khi báº¡n Ä‘áº¡t Ä‘Æ°á»£c mÃ´ hÃ¬nh vá»›i Ä‘á»™ chÃ­nh xÃ¡c nhÆ° báº¡n Ä‘á» ra.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo. Cá»‘ lÃªn.\n","date":"Dec 11, 2018","img":"","permalink":"/blog/2018-12-11-a-bunch-of-tips-and-tricks-for-training-deep-neural-networks/","series":null,"tags":["Machine learning","Deeplearning","object detector","single shot"],"title":"Má»™t Sá»‘ Máº¹o Äá»ƒ Lá»±a Chá»n MÃ´ HÃ¬nh Object Detection"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Box encoding vÃ  loss function Feature extraction Feature extractor accuracy Non-max suppression (nms) Data augmentation Feature map strides Speed v.s. accuracy Object size Input image resolution Number of proposals Äiá»ƒm danh danh láº¡i cÃ¡c bÆ°á»›c phÃ¡t triá»ƒn cá»§a object detection Lesson learned Lá»i má»Ÿ Ä‘áº§u CÃ¡c thuáº­t toÃ¡n phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng, nhÆ° cÃ¡c thuáº­t toÃ¡n thuá»™c nhÃ³m region proposal hoáº·c single shot Ä‘áº§u báº¯t Ä‘áº§u bá»Ÿi nhá»¯ng Ã½ tÆ°á»Ÿng khÃ¡c nhau, nhÆ°ng sau qua má»™t vÃ i quÃ¡ trÃ¬nh cáº­p nháº­t vÃ  nÃ¢ng cáº¥p cho Ä‘áº¿n thá»i Ä‘iá»ƒm hiá»‡n táº¡i, mÃ´ hÃ¬nh chung cá»§a chÃºng Ä‘Ã£ gáº§n gáº§n giá»‘ng nhau hÆ¡n. VÃ  hai thuáº­t toÃ¡n trÃªn lÃ  hai thuáº­t toÃ¡n tiÃªu biá»ƒu cáº¡nh tranh nhau danh hiá»‡u thuáº­t toÃ¡n phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng nhanh nháº¥t vÃ  thuáº­t toÃ¡n nháº­n diá»‡n chÃ­nh xÃ¡c nháº¥t. Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ Ä‘á» cáº­p Ä‘áº¿n má»™t sá»‘ chiáº¿n lÆ°á»£c lá»±a chá»n mÃ´ hÃ¬nh cho bÃ i toÃ¡n object detector vÃ  má»™t sá»‘ benchmarks do team Google Research thá»±c hiá»‡n.\nBox encoding vÃ  loss function CÃ³ ráº¥t nhiá»u hÃ m lá»—i vÃ  box encoding Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c thuáº­t toÃ¡n phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng. VÃ­ dá»¥, SSD tráº£ ra cÄƒn báº­c hai cá»§a Width vÃ  height Ä‘á»ƒ giáº£m tá»· lá»‡ Ä‘á»™ lá»—i.\nCÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»ƒ Ã½ ká»¹ hÆ¡n SSD phiÃªn báº£n custom khÃ´ng sá»­ dá»¥ng cáº·p toáº¡ Ä‘á»™ trÃ¡i trÃªn - pháº£i dÆ°á»›i mÃ  lÃ  cáº·p tÃ¢m - cÄƒn báº­c hai cá»§a with, cÄƒn báº­c hai cá»§a height. Má»™t sá»‘ thuáº­t toÃ¡n láº¡i dÃ¹ng log width, log height, má»™t sá»‘ láº¡i dÃ¹ng tÃ¢m lÃ  Wc/Wa, Wy/ha, vá»›i Wc vÃ  Wy lÃ  toáº¡ Ä‘á»™ tÃ¢m cá»§a Ä‘á»‘i tÆ°á»£ng, wa vÃ  ha lÃ  chiá»u dÃ i vÃ  rá»™ng cá»§a anchor khá»›p nháº¥t (matching anchor). CÃ¡c báº¡n cÃ³ thá»ƒ tham kháº£o thÃªm á»Ÿ https://arxiv.org/pdf/1611.10012.pdf.\nÄá»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh tá»‘t hÆ¡n, CÃ¡c nhÃ  nghiÃªn cá»©u sá»­ dá»¥ng cÃ¡c trá»ng sá»‘ khÃ¡c nhau cho cÃ¡c hÃ m lá»—i, YOLO vÃ  má»™t vÃ­ dá»¥ minh hoáº¡.\nFeature extraction Trong thá»±c táº¿, Feature extraction áº£nh hÆ°á»Ÿng lá»›n trÃªn 2 pháº§n tradeoff lÃ  Ä‘á»™ chÃ­nh xÃ¡c vÃ  tá»‘c Ä‘á»™. NhÃ³m thuáº­t toÃ¡n ResNet vÃ  Inception Ä‘i theo tiÃªu chÃ­ lÃ  Ä‘á»™ chÃ­nh xÃ¡c quan trá»ng hÆ¡n tá»‘c Ä‘á»™ (vÃ  quáº£ tháº­t nhÃ³m thuáº­t toÃ¡n thuá»™c há» nÃ y cÃ³ Ä‘á»™ chÃ­nh xÃ¡c khÃ¡ cao). MobileNet cung cáº¥p cho chÃºng ta má»™t mÃ´ hÃ¬nh khÃ¡ nhá» gá»n, sá»­ dá»¥ng SSD, má»¥c tiÃªu cá»§a nhÃ³m nÃ y lÃ  cÃ³ thá»ƒ xá»­ lÃ½ Ä‘Æ°á»£c trÃªn cÃ¡c thiáº¿t bá»‹ di Ä‘á»™ng vÃ  thá»i gian xá»­ lÃ½ lÃ  realtime.\nFeature extractor accuracy NhÃ¬n vÃ o hÃ¬nh trÃªn, chÃºng ta cÃ³ thá»ƒ tháº¥y rÃµ rÃ ng ráº±ng Faster R-CNN vÃ  R-FCN Ä‘á»u cho Ä‘á»™ chÃ­nh xÃ¡c khÃ¡ tá»‘t trÃªn feature extraction. NgÆ°á»£c láº¡i SSD cÃ³ káº¿t quáº£ khÃ¡ tá»‡.\nNon-max suppression (nms) Sau khi thu Ä‘Æ°á»£c vá»‹ trÃ­ cá»§a cÃ¡c Ä‘á»‘i tÆ°á»£ng, chÃºng ta sáº½ merge láº¡i cÃ¡c vá»‹ trÃ­ bá»‹ phÃ¡t hiá»‡n trÃ¹ng láº¯p. CÃ¡c thuáº­t toÃ¡n thuá»™c nhÃ³m single shot thÆ°á»ng cho ra output overlap khÃ¡ nhiá»u.\nData augmentation NgÃ y nay, háº§u háº¿t cÃ¡c thuáº­t toÃ¡n Ä‘á»u sá»­ dá»¥ng Data augmentation. Viá»‡c augment data báº±ng cÃ¡ch cáº¯t xÃ©t áº£nh, quay áº£nh má»™t gÃ³c ngáº«u nhiÃªn nÃ o Ä‘Ã³, giÃºp cho trÃ¡nh Ä‘Æ°á»£c overfit trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, do Ä‘Ã³ giÃ¡n tiáº¿p tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh.\nFeature map strides Thuáº­t toÃ¡n thuá»™c nhÃ³m single shot thÆ°á»ng cÃ³ tuá»³ chá»n layter feature map nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng. Feature map cÃ³ stride lÃ  2 náº¿u chÃºng ta thá»±c hiá»‡n giáº£m 2 láº§n Ä‘á»™ phÃ¢n giáº£i. Feature map cÃ³ Ä‘á»™ phÃ¢n giáº£i tháº¥p thÆ°á»ng giá»¯ láº¡i nhá»¯ng thÃ´ng tin Ä‘áº·c trÆ°ng tá»‘t cá»§a Ä‘á»‘i tÆ°á»£ng vÃ  giÃºp cho detector thá»±c hiá»‡n tá»‘t hÆ¡n. Tuy nhiÃªn, nhá»¯ng Ä‘á»‘i tÆ°á»£ng cÃ³ kÃ­nh thÆ°á»›c nhá» sáº½ bá»‹ máº¥t thÃ´ng tin tráº§m trá»ng vÃ  khÃ³ Ä‘á»ƒ phÃ¡t hiá»‡n ra chÃºng.\nSpeed v.s. accuracy Tháº­t khÃ³ Ä‘á»ƒ tráº£ lá»i ráº±ng thuáº­t toÃ¡n nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng nÃ o tá»‘t hÆ¡n, mÃ  cÃ¢u tráº£ lá»i phá»¥ thuá»™c vÃ o bÃ i toÃ¡n cá»§a báº¡n Ä‘ang gáº·p. Náº¿u bÃ i toÃ¡n cáº§n Ä‘á»™ chÃ­nh xÃ¡c cao, hÃ£y sá»­ dá»¥ng ResNet hoáº·c Inception, náº¿u báº¡n cáº§n cháº¡y realtime vÃ  Ä‘á»™ chÃ­nh xÃ¡c táº¡m cháº¥p nháº­n, hÃ£y sá»­ dá»¥ng MobileNet hoáº·c YOLO. KhÃ´ng cÃ³ (chÆ°a cÃ³ - Ã­t nháº¥t Ä‘áº¿n thá»i Ä‘iá»ƒm hiá»‡n táº¡i) cÃ³ thuáº­t toÃ¡n nÃ o Ä‘Ã¡p á»©ng cáº£ 2 tiÃªu chÃ­ lÃ  vá»«a cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao, vá»«a cháº¡y nhanh cáº£. ÄÃ³ lÃ  má»™t tradeoff giá»¯a Speed vÃ  Accuracy.\nObject size Vá»›i nhá»¯ng hÃ¬nh áº£nh cÃ³ kÃ­ch thÆ°á»›c lá»›n, SSD thá»±c hiá»‡n rÃºt trÃ­ch Ä‘áº·c trÆ°ng ráº¥t tá»‘t (nÃªn nhá»› ráº±ng mÃ´ hÃ¬nh rÃºt trÃ­ch Ä‘áº·c trÆ°ng cá»§a SSD ráº¥t Ä‘Æ¡n giáº£n). Vá»›i nhá»¯ng hÃ¬nh áº£nh dáº¡ng nÃ y, SSD cÃ³ thá»ƒ so sÃ¡nh vá»›i cÃ¡c thuáº­t toÃ¡n khÃ¡c khÃ¡c vá» Ä‘á»™ chÃ­nh xÃ¡c.\nVá»›i nhÆ°ng hÃ¬nh áº£nh cÃ³ kÃ­ch thÆ°á»›c nhá», chÃºng ta khÃ´ng nÃªn/khÃ´ng bao giá» xÃ i SSD.\nNhÃ¬n hÃ¬nh á»Ÿ trÃªn, chÃºng ta tháº¥y rÃµ Ä‘á»™ chÃ­nh xÃ¡c cá»§a SSD vÃ  cÃ¡c thuáº­t oÃ¡n khÃ¡c trÃªn cÃ¡c táº­p dá»¯ liá»‡u cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau. VÃ  phá»¥ thuá»™c vÃ o kÃ­ch thÆ°á»›c dá»¯ liá»‡u cá»§a báº¡n Ä‘á»ƒ chá»n ra mÃ´ hÃ¬nh tá»‘i Æ°u nháº¥t.\nInput image resolution NhÃ¬n hÃ¬nh trÃªn cÃ¡c báº¡n cÅ©ng cÃ³ thá»ƒ nhÃ¬n tháº¥y rÃµ. áº¢nh cÃ³ Ä‘á»™ phÃ¢n giáº£i lá»›n giÃºp nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng tá»‘t hÆ¡n ráº¥t nhiá»u so vá»›i áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i nhá». Khi giáº£m 2 láº§n Ä‘á»™ phÃ¢n giáº£i trÃªn má»—i chiá»u (tá»« 600x600 xuá»‘ng cÃ²n 300x300), trung bÃ¬nh Ä‘á»™ chÃ­nh xÃ¡c giáº£m 15.88% trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, vÃ  trung bÃ¬nh giáº£m 27.4% trong inference.\nNumber of proposals Sá»‘ lÆ°á»£ng proposal Ä‘Æ°á»£c sinh ra áº£nh hÆ°á»Ÿng trá»±c tiáº¿p Ä‘áº¿n tá»‘c Ä‘á»™ cá»§a nhÃ³m R-CNN. VÃ­ dá»¥, Faster R-CNN cÃ³ thá»ƒ tÄƒng tá»‘c Ä‘á»™ nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng gáº¥p 3 láº§n náº¿u ta chá»‰ sá»­ dá»¥ng 50 proposal thay vÃ¬ 300 proposal. Äá»™ chÃ­nh xÃ¡c chá»‰ giáº£m 4%\nHÃ¬nh trÃªn, Ä‘Æ°á»ng nÃ©t liá»n mÃ´ táº£ Ä‘á»™ chÃ­nh xÃ¡c khi tÄƒng sá»‘ lÆ°á»£ng proposal. ÄÆ°á»ng nÃ©t Ä‘á»©t thá»ƒ hiá»‡n thá»i gian xá»­ lÃ¡y tÄƒng khi tÄƒng sá»‘ lÆ°á»£ng proposal.\nÄiá»ƒm danh danh láº¡i cÃ¡c bÆ°á»›c phÃ¡t triá»ƒn cá»§a object detection CÃ¡c thuáº­t toÃ¡n object detection Ä‘Ã£ phÃ¡t triá»ƒn trong má»™t khoáº£ng thá»i gian dÃ i. Ã tÆ°á»Ÿng Ä‘áº§u tiÃªn, Ä‘Æ¡n giáº£n nháº¥t lÃ  chÃºng ta sáº½ sá»­ dá»¥ng cá»­a sá»• trÆ°á»£t.\n1 2# Sliding windows 3for window in windows 4 patch = get_patch(image, window) 5 results = detector(patch) Äá»ƒ tÄƒng tá»‘c, chÃºng ta sáº½\nGiáº£m sá»‘ lÆ°á»£ng windows (R-CNN giáº£m cÃ²n khoáº£ng 2000) Giáº£m cÃ¡c phÃ©p tÃ­nh trong viá»‡c tÃ¬m ROI (Fast R-CNN sá»­ dá»¥ng feature map thay vÃ¬ toÃ n bá»™ image patchs). 1# Fast R-CNN 2feature_maps = process(image) 3ROIs = region_proposal(feature_maps) 4for ROI in ROIs 5 patch = roi_pooling(feature_maps, ROI) 6 results = detector2(patch) Viá»‡c tÃ¬m region_proposal cÅ©ng tá»‘n khÃ¡ nhiá»u thá»i gian. Faster R-CNN sá»­ dá»¥ng má»™t convolution network thay tháº¿ cho region proposal á»Ÿ bÆ°á»›c nÃ y (lÃ m giáº£m thá»i gian tá»« 2.3s xuá»‘ng cÃ²n 0.3 giÃ¢y). Faster R-CNN cÅ©ng giá»›i thiá»‡u 1 khÃ¡i nhiá»‡m lÃ  anchor giÃºp cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c vÃ  viá»‡c huáº¥n luyá»‡n trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n.\nR-FCN Ä‘Æ°a ra má»™t Ä‘iá»u chá»‰nh nhá», lÃ  tiáº¿n hÃ nh tÃ¬m position vÃ  sensitive score map trÃªn má»—i ROIS Ä‘á»™c láº­p. VÃ  tÃ­nh trung bÃ¬nh xÃ¡c suáº¥t xuáº¥t hiá»‡n Ä‘á»‘i tÆ°á»£ng\n1# R-FCN 2feature_maps = process(image) 3ROIs = region_proposal(feature_maps) 4score_maps = compute_score_map(feature_maps) 5for ROI in ROIs 6 V = pool(score_maps, ROI) 7 class_scores = average(V) 8 class_probabilities = softmax(class_scores) R-FCN cháº¡y khÃ¡ nhanh, nhÆ°ng Ä‘á»™ chÃ­nh xÃ¡c thÃ¬ tháº¥p hÆ¡n má»™t hÃºt so vá»›i Faster R-CNN. Äá»ƒ Ã½ ká»¹ Ä‘oáº¡n mÃ£ giáº£ á»Ÿ trÃªn, chÃºng ta pháº£i tráº£i qua 2 láº§n tÃ­nh toÃ¡n, má»™t láº§n lÃ  tÃ¬m cÃ¡c ROIs, má»™t láº§n lÃ  object detection. Thuáº­t toÃ¡n Single shot detector Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ sá»­ dá»¥ng 1 láº§n tÃ­nh toÃ¡n.\n1feature_maps = process(image) 2results = detector3(feature_maps) # No more separate step for ROIs Thuáº­t toÃ¡n SSD vÃ  YOLO Ä‘á»u thuá»™c nhÃ³m single shot detectors. Cáº£ hai Ä‘á»u sá»­ dá»¥ng convolution layer Ä‘á»ƒ rÃºt trÃ­ch Ä‘áº·c trÆ°ng vÃ  má»™t convolution filter Ä‘á»ƒ Ä‘Æ°a quyáº¿t Ä‘á»‹nh. Cáº£ hai Ä‘á»u dÃ¹ng feature map cÃ³ Ä‘á»™ phÃ¢n giáº£i tháº¥p (low resolution feature map) Ä‘á»ƒ dÃ² tÃ¬m Ä‘á»‘i tÆ°á»£ng =\u0026gt; chá»‰ phÃ¡t hiá»‡n Ä‘Æ°á»£c cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ³ kÃ­ch thÆ°á»›c lá»›n. Má»™t cÃ¡ch tiáº¿p cáº­n lÃ  sá»­ dá»¥ng cÃ¡c feature map cÃ³ Ä‘á»™ phÃ¢n giáº£i cao (higher resolution feature map). NhÆ°ng Ä‘á»™ chÃ­nh xÃ¡c sáº½ giáº£m do thÃ´ng tin Ä‘áº·c trÆ°ng cá»§a Ä‘á»‘i tÆ°á»£ng quÃ¡ há»—n loáº¡n. FPN Ä‘Æ°a ra Ã½ tÆ°á»Ÿng sá»­ dá»¥ng feature map trung gian merge giá»¯a feature map high resolution vÃ  low resolution. Viá»‡c nÃ y giÃºp cho chÃºng ta váº«n giá»¯ Ä‘Æ°á»£c thÃ´ng tin Ä‘áº·c trÆ°ng há»¯u Ã­ch cá»§a Ä‘á»‘i tÆ°á»£ng, Ä‘á»“ng thá»i cÅ©ng giá»¯ Ä‘Æ°á»£c thÃ´ng tin cá»§a cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ³ kÃ­ch thÆ°á»›c nhá». Do Ä‘Ã³, Ä‘á»™ chÃ­nh xÃ¡c cÅ©ng tÄƒng lÃªn vÃ  phÃ¡t hiá»‡n cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ³ cÃ¡c tá»· lá»‡ khÃ¡c nhau (different scale) tá»‘t hÆ¡n.\nTrong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, chÃºng ta sáº½ nháº­n ra 1 váº¥n Ä‘á» ráº±ng backgroup sáº½ chiáº¿m 1 pháº§n ráº¥t lá»›n trong bá»©c áº£nh. Hoáº·c má»™t Ä‘á»‘i tÆ°á»£ng nÃ o Ä‘Ã³ cÃ³ sá»‘ máº«u nhiá»u hÆ¡n so vá»›i cÃ¡c Ä‘á»‘i tÆ°á»£ng khÃ¡c. Thuáº­t toÃ¡n Focal loss Ä‘Æ°á»£c sinh ra Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y.\nLesson learned Feature Pyramid Networks sá»­ dá»¥ng cÃ¡c feature map nhiá»u thÃ´ng tin hÆ¡n Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c.\nSá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh nhÆ° ResNet hoáº·c Inception ResNet náº¿u mÃ´ hÃ¬nh báº¡n cáº§n Ä‘á»™ chÃ­nh xÃ¡c vÃ  khÃ´ng quan tÃ¢m láº¯m vá» tá»‘c Ä‘á»™.\nSá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n thuá»™c nhÃ³m Single shot detectors nhÆ° MobileNet náº¿u báº¡n cáº§n tá»‘c Ä‘á»™ tÃ­nh toÃ¡n vÃ  cÃ³ thá»ƒ cháº¡y Ä‘Æ°á»£c trÃªn mobilenet, yÃªu cáº§u vá» Ä‘á»™ chÃ­nh xÃ¡c táº¡m cháº¥p nháº­n Ä‘Æ°á»£c.\nSá»­ dá»¥ng batch normaliation, nÃ³i chung lÃ  Ä‘á»u pháº£i chuáº©n hoÃ¡ dá»¯ liá»‡u trÆ°á»›c khi sá»­ dá»¥ng.\nLá»±a chá»n anchors cáº©n tháº­n (CÃ¡i nÃ y khÃ¡ khÃ³, Ä‘Ã²i há»i báº¡n pháº£i am hiá»ƒu khÃ¡ ká»¹ vá» dá»¯ liá»‡u, vÃ  náº¿u set nháº§m thÃ¬ sáº½ Ä‘i tong).\nSá»­ dá»¥ng data augmentation.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\nBÃ i viáº¿t Ä‘Æ°á»£c lÆ°á»£c dá»‹ch vÃ  tham kháº£o tá»« nguá»“n https://medium.com/@jonathan_hui/design-choices-lessons-learned-and-trends-for-object-detections-4f48b59ec5ff\n","date":"Dec 10, 2018","img":"","permalink":"/blog/2018-12-10-design-choices-lessons-learned-and-trends-for-object-detections/","series":null,"tags":["Machine learning","Deeplearning","object detector","single shot"],"title":"Lá»±a Chá»n MÃ´ HÃ¬nh Object Detectors"},{"categories":null,"content":" Single Shot detectors SSD YOLO YOLOv3 Feature Pyramid Networks (FPN) So sÃ¡nh Feature Pyramid Networks vá»›i Region Proposal Network Sá»­ dá»¥ng Feature Pyramid Networks trong Fast R-CNN vÃ  Faster R-CNN Focal loss (RetinaNet) Single Shot detectors á» bÃ i trÆ°á»›c, chÃºng ta Ä‘Ã£ tÃ¬m hiá»ƒu vá» region proposal vÃ  á»©ng dá»¥ng cá»§a nÃ³ vÃ o Faster R-CNN. CÃ¡c thuáº­t toÃ¡n thuá»™c nhÃ³m region proposal tuy cho káº¿t quáº£ cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao, nhÆ°ng chÃºng cÃ³ má»™t nhÆ°á»£c Ä‘iá»ƒm ráº¥t lá»›n lÃ  thá»i gian huáº¥n luyá»‡n vÃ  Ä‘Æ°a quyáº¿t Ä‘á»‹nh ráº¥t cháº­m. Faster R-CNN xá»­ lÃ½ khoáº£ng 7 FPS trÃªn táº­p dá»¯ liá»‡u PASCAL VOC 2007. Má»™t cÃ¡ch Ä‘á»ƒ tÄƒng tá»‘c quÃ¡ trÃ¬nh tÃ­nh toÃ¡n lÃ  giáº£m sá»‘ lÆ°á»£ng tÃ­nh toÃ¡n trÃªn má»—i ROI.\n1feature_maps = process(image) 2ROIs = region_proposal(feature_maps) 3for ROI in ROIs 4 patch = roi_align(feature_maps, ROI) 5 results = detector2(patch) # Giáº£m khá»‘i lÆ°á»£ng tÃ­nh toÃ¡n á»Ÿ Ä‘Ã¢y Má»™t Ã½ tÆ°á»Ÿng khÃ¡c, lÃ  chÃºng ta sáº½ bá» qua bÆ°á»›c tÃ¬m region proposal, mÃ  trá»±c tiáº¿p rÃºt trÃ­ch boundary boxes vÃ  classes trá»±c tiáº¿p tá»« feature map.\n1feature_maps = process(image) 2results = detector3(feature_maps) # KhÃ´ng cáº§n tÃ¬m ROI Dá»±a trÃªn Ã½ tÆ°á»Ÿng sá»­ dá»¥ng cá»­a sá»• trÆ°á»£t. ChÃºng ta sáº½ trÆ°á»£t trÃªn feature mÃ¡p Ä‘á»ƒ nháº­n diá»‡n cÃ¡c Ä‘á»‘i tÆ°á»£ng. Vá»›i má»—i loáº¡i Ä‘á»‘i tÆ°á»£ng khÃ¡c nhau, chÃºng ta sá»­a dá»¥ng cÃ¡c cá»­a sá»• trÆ°á»£t cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau. CÃ¡ch nÃ y thoáº¡t Ä‘áº§u trÃ´ng cÃ³ váº» khÃ¡ tá»‘t, nhÆ°ng Ä‘iá»ƒm yáº¿u cá»§a nÃ³ lÃ  Ä‘Ã£ sá»­ dá»¥ng cá»­a sá»• trÆ°á»£t lÃ m final boundary box. Do Ä‘Ã³, giáº£ sá»­ chÃºng ta cÃ³ nhiá»u Ä‘á»‘i tÆ°á»£ng, vÃ  má»—i Ä‘á»‘i tÆ°á»£ng cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau, chÃºng ta sáº½ cÃ³ ráº¥t nhiá»u cá»­a sá»• trÆ°á»£t Ä‘á»ƒ bao phá»§ háº¿t toÃ n bá»™ Ä‘á»‘i tÆ°á»£ng.\nMá»™t Ã½ tÆ°á»Ÿng cáº£i tiáº¿n lÃ  chÃºng ta sáº½ Ä‘á»‹nh nghÄ©a trÆ°á»›c cÃ¡c cá»­a sá»• trÆ°á»£t, sau Ä‘Ã³ sáº½ tiáº¿n hÃ nh dá»± Ä‘oÃ¡n lá»›p vÃ  boundary box ( vÃ  Ã tÆ°á»Ÿng nÃ y, nhÃ³m nghiÃªn cá»©u phÃ¡t triá»ƒn thuáº­t toÃ¡n vÃ  Ä‘áº·t tÃªn thuáº­t toÃ¡n lÃ  single shot detectors). Ã tÆ°á»Ÿng nÃ y tÆ°Æ¡ng tá»± nhÆ° viá»‡c sá»­ dá»¥ng anchors trong Faster R-CNN, nhÆ°ng single shot detectors thá»±c hiá»‡n dá»± Ä‘oÃ¡n boundary box vÃ  class Ä‘á»“ng thá»i cÃ¹ng nhau.\nVÃ­ dá»¥, giáº£ sá»­ chÃºng ta cÃ³ má»™t feature map 8x8 vÃ  chÃºng ta Ä‘Æ°a ra k = 4 dá»± Ä‘oÃ¡n. Váº­y ta cÃ³ tá»•ng cá»™ng 8x8x4 = 256 dá»± Ä‘oÃ¡n.\nXÃ©t hÃ¬nh bÃªn trÃªn, ta cÃ³ 4 anchors Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trÆ°á»›c ( mÃ u xanh lÃ¡ cÃ¢y), vÃ  cÃ³ 4 prediction( mÃ u xanh nÆ°á»›c biá»ƒn) tÆ°Æ¡ng á»©ng vá»›i tá»«ng anchor trÃªn.\nVá»›i thuáº­t toÃ¡n Faster R-CNN, chÃºng ta sá»­ dá»¥ng má»™t convolution filter tráº£ ra 5 káº¿t quáº£ dá»± Ä‘oÃ¡n: 4 giÃ¡ trá»‹ lÃ  toáº¡ Ä‘á»™ cá»§a boundary box, vÃ  giÃ¡ trá»‹ cÃ²n láº¡i lÃ  xÃ¡c suáº¥t xuáº¥t hiá»‡n Ä‘á»‘i tÆ°á»£ng. Tá»•ng quÃ¡t hÆ¡n, ta cÃ³ input lÃ  D feature map 8x8, output lÃ  8x8x5, sá»‘ convolution filter trong Faster R-CNN lÃ  3x3xDx8.\nVá»›i single shot detector, input cá»§a ta cÅ©ng tÆ°Æ¡ng tá»± lÃ  8x8xD, output lÃ  8x8x (4 + C) ( vá»›i 4 tÆ°Æ¡ng á»©ng vá»›i 4 Ä‘iá»ƒm boundary box, vÃ  C lÃ  sá»‘ lÆ°á»£ng lá»›p Ä‘á»‘i tÆ°á»£ng), váº­y ta cáº§n má»™t convolution filter lÃ  3x3xDx(4+C)\nThuáº­t toÃ¡n Single shot detect cháº¡y khÃ¡ nhanh, nhÆ°ng Ä‘á»™ chÃ­nh xÃ¡c cá»§a nÃ³ khÃ´ng cao láº¯m (khÃ´ng báº±ng region proposal). Thuáº­t toÃ¡n cÃ³ váº¥n Ä‘á» vá» viá»‡c nháº­n dáº¡ng cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ³ kÃ­ch thÆ°á»›c nhá». VÃ­ dá»¥ nhÆ° hÃ¬nh bÃªn dÆ°á»›i, chÃºng ta cÃ³ tá»•ng cá»™ng 9 Ã´ng giÃ  noel, nhÆ°ng thuáº­t toÃ¡n chá»‰ nháº­n diá»‡n Ä‘Æ°á»£c cÃ³ 5 Ã´ng.\nSSD SSD lÃ  mÃ´ hÃ¬nh single shot detector sá»­ dá»¥ng máº¡ng VGG16 Ä‘á»ƒ rÃºt trÃ­ch Ä‘áº·c trÆ°ng. MÃ´ hÃ¬nh nhÆ° hÃ¬nh bÃªn dÆ°á»›i. Trong Ä‘Ã³, nhá»¯ng conv cÃ³ mÃ u xanh nÆ°á»›c biá»ƒn nháº¡t lÃ  nhá»¯ng custom convolution layter (ta cÃ³ thá»ƒ thÃªm bá»›t bao nhiÃªu tuá»³ thÃ­ch). Convolutional filter layter (lÃ  cá»¥c mÃ u xanh lÃ¡ cÃ¢y) cÃ³ nhiá»‡m vá»¥ tá»•ng há»£p cÃ¡c thÃ´ng tin láº¡i Ä‘á»ƒ Ä‘Æ°a quyáº¿t Ä‘á»‹nh.\nKhi sá»­ dá»¥ng mÃ´ hÃ¬nh nhÆ° hÃ¬nh á»Ÿ trÃªn, chÃºng ta tháº¥y ráº±ng cÃ¡c custom convolution layter cÃ³ nhiá»‡m vá»¥ lÃ m giáº£m chiá»u vÃ  giáº£m Ä‘á»™ phÃ¢n giáº£i cá»§a bá»©c áº£nh. Cho nÃªn, mÃ´ hÃ¬nh chá»‰ cÃ³ kháº£ nÄƒng nháº­n ra cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ³ kÃ­ch thÆ°á»›c lá»›n. Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y, chÃºng ta sáº½ sá»­ dá»¥ng cÃ¡c object detector khÃ¡c nhau trÃªn má»—i feature maps (xem output cá»§a má»—i custom convolution lÃ  má»™t feature map).\náº¢nh bÃªn dÆ°á»›i lÃ  sÆ¡ Ä‘á»“ sá»‘ chiá»u cá»§a cÃ¡c feature maps.\nSSD sá»­ dá»¥ng cÃ¡c layter cÃ³ kÃ­ch thÆ°á»›c giáº£m dáº§n theo Ä‘á»™ sÃ¢u Ä‘á»ƒ nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng. NhÃ¬n vÃ o hÃ¬nh váº½ sÆ¡ Ä‘á»“ bÃªn dÆ°á»›i cá»§a SSD, chÃºng ra dá»… dÃ ng nháº­n tháº¥y ráº±ng Ä‘á»™ phÃ¢n giáº£i giáº£m Ä‘Ã¡ng ká»ƒ qua má»—i layer vÃ  cÃ³ láº½ (cháº¯c cháº¯n) sáº½ bá» sÃ³t nhá»¯ng Ä‘á»‘i tÆ°á»£ng cÃ³ kÃ­ch thÆ°á»›c nhá» á»Ÿ nhá»¯ng lá»›p cÃ³ Ä‘á»™ phÃ¢n giáº£i tháº¥p. Náº¿u trong dá»± Ã¡n thá»±c táº¿ cá»§a báº¡n cÃ³ xáº£y ra váº¥n Ä‘á» nÃ y, báº¡n nÃªn tÄƒng Ä‘á»™ phÃ¢n giáº£i cá»§a áº£nh Ä‘áº§u vÃ o.\nYOLO YOLO cÅ©ng lÃ  má»™t thuáº­t toÃ¡n sá»­ dá»¥ng single shot detector Ä‘á»ƒ dÃ² tÃ¬m vá»‹ trÃ­ cá»§a cÃ¡c Ä‘á»‘i tÆ°á»£ng trong áº£nh. YOLO sá»­ dá»¥ng DarkNet Ä‘á»ƒ táº¡o cÃ¡c feature cho bá»©c áº£nh (SSD sá»­ dá»¥ng VGG16). MÃ´ hÃ¬nh cá»§a YOLLO nhÆ° áº£nh á»Ÿ bÃªn dÆ°á»›i.\nKhÃ¡c vá»›i kiáº¿n trÃºc máº¡ng SSD á»Ÿ trÃªn, YOLLO khÃ´ng sá»­ dá»¥ng multiple scale feature map (SSD sá»­ dá»¥ng cÃ¡c custom convolution layter, qua má»—i layter thÃ¬ feature maps sáº½ cÃ³ kÃ­ch thÆ°á»›c giáº£m xuá»‘ng - cÃ¡c output cá»§a custom convolution layer chÃ­nh lÃ  cÃ¡c feature map chÃºng ta thu Ä‘Æ°á»£c). Thay vÃ o Ä‘Ã³, YOLLO sáº½ lÃ m pháº³ng hoÃ¡ (flatten - vd ma tráº­n 3x3 sáº½ biáº¿n thÃ nh vector 1x9, ma tráº­n 4x5 sáº½ biáº¿n thÃ nh vector 1x20 \u0026hellip;, lÃ m pháº³ng nghÄ©a lÃ  chÃºng ta sáº½ khÃ´ng dÃ¹ng bá»™ lá»c nÃ o háº¿t, mÃ  sá»­ dá»¥ng cÃ¡c phÃ©p biáº¿n Ä‘á»•i, nÃªn khÃ´ng lÃ m thay Ä‘á»•i giÃ¡ trá»‹, chá»‰ lÃ m thay Ä‘á»•i hÃ¬nh dáº¡ng) má»™t pháº§n output cá»§a convolution layer vÃ  káº¿t há»£p vá»›i convolution layer á»Ÿ trong DarkNet táº¡o thÃ nh feature map (Xem hÃ¬nh á»Ÿ trÃªn sáº½ rÃµ hÆ¡n). VÃ­ dá»¥ á»Ÿ custom convolution layer chÃºng ta thu Ä‘Æ°á»£c output cÃ³ kÃ­ch thÆ°á»›c 28x28x512, chÃºng ta sáº½ flatten thÃ nh layter cÃ³ kÃ­ch thÆ°á»›c 14x14x2048, káº¿t há»£p vá»›i 1 layter cÃ³ kÃ­ch thÆ°á»›c 14x14x1024 á»Ÿ trong darknet, chÃºng ta thu Ä‘Æ°á»£c feature maps cÃ³ kÃ­ch thÆ°á»›c lÃ  14x14x3072. Äem feature maps nÃ y Ä‘i Ä‘á»± Ä‘oÃ¡n.\nYOLOv2 Ä‘Ã£ thÃªm vÃ o ráº¥t nhiá»u cÃ¡c cáº£i tiá»n Ä‘á»ƒ cáº£i tÄƒng mAP tá»« 63.4 trong mÃ´ hÃ¬nh Ä‘áº§u tiÃªn (YOLOv1) lÃªn 78.6. CÃ¡c cáº£i tiá»n bao gá»“m thÃªm batch norm, anchor boxes, hi-res classifier \u0026hellip; CÃ¡c báº¡n cÃ³ thá»ƒ xem á»Ÿ hÃ¬nh bÃªn dÆ°á»›i. YOLO9000 cÃ³ thá»ƒ nháº­n dáº¡ng 9000 Ä‘á»‘i tÆ°á»£ng khÃ¡c nhau.\nYOLOv2 cÃ³ thá»ƒ nháº­n diá»‡n cÃ¡c Ä‘á»‘i tÆ°á»£ng vá»›i áº£nh Ä‘áº§u vÃ o cÃ³ Ä‘á»™ phÃ¢n giáº£i báº¥t ká»³. Vá»›i áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i tháº¥p thÃ¬ mÃ´ hÃ¬nh cháº¡y khÃ¡ nhanh, cÃ³ FPS cao nhÆ°ng mAP láº¡i tháº¥p (tradeoff giá»¯a FPS vÃ  mAP).\nYOLOv3 YOLOv3 sá»­ dá»¥ng darknet vá»›i kiáº¿n trÃºc phá»©c hÆ¡n Ä‘á»ƒ rÃºt trÃ­ch Ä‘áº·c trÆ°ng cá»§a bá»©c áº£nh. YOLOv3 thÃªm vÃ o Ä‘áº·c trÆ°ng Pyramid Ä‘á»ƒ dÃ² tÃ¬m cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ³ kÃ­ch thÆ°á»›c nhá».\nHÃ¬nh bÃªn dÆ°á»›i so sÃ¡nh tradeoff giá»¯a thá»i gian thá»±c thi vÃ  Ä‘á»™ chÃ­nh xÃ¡c giá»¯a cÃ¡c mÃ´ hÃ¬nh. Ta tháº¥y ráº±ng thá»i gian thá»±c thi cá»§a YOLOv3 ráº¥t nhanh, cÃ¹ng phÃ¢n má»©c mAP 28.8, thá»i gian YOLOv3 thá»±c thi chá»‰ tá»‘n 22ms, trong khi Ä‘Ã³ SSD321 tá»‘n Ä‘áº¿n 61ms - gáº¥p 3 láº§n.\nFeature Pyramid Networks (FPN) DÃ² tÃ¬m cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ³ kÃ­ch thÆ°á»›c nhá» lÃ  má»™t váº¥n Ä‘á» Ä‘Ã¡ng Ä‘Æ°á»£c giáº£i quyáº¿t Ä‘á»ƒ nÃ¢ng cao Ä‘á»™ chÃ­nh xÃ¡c. VÃ  FPN lÃ  mÃ´ hÃ¬nh máº¡ng Ä‘Æ°á»£c thiáº¿t káº¿ ra dá»±a trÃªn khÃ¡i niá»‡m pyramid Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y.\nMÃ´ hÃ¬nh FPN káº¿t há»£p thÃ´ng tin cá»§a mÃ´ hÃ¬nh theo hÆ°á»›ng bottom-up káº¿t há»£p vá»›i top-down Ä‘á»ƒ dÃ² tÃ¬m Ä‘á»‘i tÆ°á»£ng (trong khi Ä‘Ã³, cÃ¡c thuáº­t toÃ¡n khÃ¡c chá»‰ thÆ°á»ng sá»­ dá»¥ng bottom-up). Khi chÃºng ta á»Ÿ bottom vÃ  Ä‘i lÃªn (up), Ä‘á»™ phÃ¢n giáº£i sáº½ giáº£m, nhÆ°ng giÃ¡ trá»‹ ngá»¯ nghÄ©a sáº½ tÄƒng lÃªn. Xem hÃ¬nh mÃ´ phá»ng bÃªn dÆ°á»›i.\nSSD Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh dá»±a vÃ o nhiá»u feature map. NhÆ°ng layer á»Ÿ bottom khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ nháº­n dáº¡ng Ä‘á»‘i tÆ°á»£ng. VÃ¬ nhá»¯ng layter nÃ y cÃ³ Ä‘á»™ phÃ¢n giáº£i cao nhÆ°ng giÃ¡ trá»‹ ngá»¯ nghÄ©a cá»§a chÃºng láº¡i khÃ´ng Ä‘á»§ cao (tháº¥p) nÃªn nhá»¯ng nhÃ  nghiÃªn cá»©u bá» chÃºng Ä‘i Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½. CÃ¡c nhÃ  nghiÃªng cá»©u biá»‡n minh ráº±ng cÃ¡c layer á»Ÿ bottom chÆ°a Ä‘á»§ má»©c Ã½ nghÄ©a cáº§n thiáº¿t Ä‘á»ƒ nÃ¢ng cao Ä‘á»™ chÃ­nh xÃ¡c, thÃªm cÃ¡c layer Ä‘Ã³ vÃ o sáº½ khÃ´ng nÃ¢ng Ä‘á»™ chÃ­nh xÃ¡c cao thÃªm bao nhiÃªu vÃ  há» bá» chÃºng Ä‘i Ä‘á»ƒ cÃ³ tá»‘c Ä‘á»™ tá»‘t hÆ¡n. Cho nÃªn, SSD chá»‰ sá»­ dá»¥ng cÃ¡c layer á»Ÿ lá»›p trÃªn , vÃ  do Ä‘Ã³ sáº½ khÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ³ kÃ­ch thÆ°á»›c nhá».\nTrong khi Ä‘Ã³, FPN xÃ¢y dá»±ng thÃªm mÃ´ hÃ¬nh top-down, nháº±m má»¥c Ä‘Ã­ch xÃ¢y dá»±ng cÃ¡c layer cÃ³ Ä‘á»™ phÃ¢n giáº£i cao tá»« cÃ¡c layer cÃ³ ngá»¯ nghÄ©a cao.\nTrong quÃ¡ trÃ¬nh xÃ¢y dá»±ng láº¡i cÃ¡c layer tá»« top xuá»‘ng bottom, chÃºng ta sáº½ gáº·p má»™t váº¥n Ä‘á» khÃ¡ nghiÃªm trá»ng lÃ  bá»‹ máº¥t mÃ¡t thÃ´ng tin cá»§a cÃ¡c Ä‘á»‘i tÆ°á»£ng. VÃ­ dá»¥ má»™t Ä‘á»‘i tÆ°á»£ng nhá» khi lÃªn top sáº½ khÃ´ng tháº¥y nÃ³, vÃ  tá»« top Ä‘i ngÆ°á»£c láº¡i sáº½ khÃ´ng thá»ƒ tÃ¡i táº¡o láº¡i Ä‘á»‘i tÆ°á»£ng nhá» Ä‘Ã³. Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y, chÃºng ta sáº½ táº¡o cÃ¡c káº¿t ná»‘i (skip connection) giá»¯a cÃ¡c reconstruction layter vÃ  cÃ¡c feature map Ä‘á»ƒ giÃºp quÃ¡ trÃ¬nh detector dá»± Ä‘oÃ¡n cÃ¡c vá»‹ trÃ­ cá»§a Ä‘á»‘i tÆ°á»£ng thá»±c hiá»‡n tá»‘t hÆ¡n (háº¡n cháº¿ tá»‘t nháº¥t viá»‡c máº¥t mÃ¡t thÃ´ng tin).\nThÃªm cÃ¡c skip connection giá»¯a feature map vÃ  reconstruction layer\nÄá»“ hÃ¬nh bÃªn dÆ°á»›i diá»…n ta chi tiáº¿t Ä‘Æ°á»ng Ä‘i theo bottom-up vÃ  top-down. P2, P3, P4, P5 lÃ  cÃ¡c pyramid cá»§a cÃ¡c feature map.\nSo sÃ¡nh Feature Pyramid Networks vá»›i Region Proposal Network FPN khÃ´ng pháº£i lÃ  mÃ´ hÃ¬nh phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng. NÃ³ lÃ  mÃ´ hÃ¬nh phÃ¡t hiá»‡n Ä‘áº·c trÆ°ng vÃ  Ä‘Æ°á»£c sá»­ dá»¥ng trong phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng. CÃ¡c feature map tá»« P2 Ä‘áº¿n P5 trong hÃ¬nh bÃªn dÆ°á»›i Ä‘á»™c láº­p vá»›i nhau vÃ  cÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng.\nSá»­ dá»¥ng Feature Pyramid Networks trong Fast R-CNN vÃ  Faster R-CNN ChÃºng ta hoÃ n toÃ n cÃ³ thá»ƒ sá»­ dá»¥ng FPN trong Fast vÃ  Faster R-CNN. ChÃºng ta sáº½ táº¡o ra cÃ¡c feature map sá»­ dá»¥ng FPN, káº¿t quáº£ lÃ  ta thu Ä‘Æ°á»£c cÃ¡c puramid (feature map). Sau Ä‘Ã³, chÃºng ta sáº½ rÃºt trÃ­ch cÃ¡c ROIs trÃªn cÃ¡c feature map Ä‘Ã³. Dá»±a trÃªn kÃ­ch thÆ°á»›c cá»§a cÃ¡c ROI, chÃºng ta sáº½ chá»n feature map nÃ o tá»‘t nháº¥t Ä‘á»ƒ táº¡o cÃ¡c feature patches (cÃ¡c hÃ¬nh chá»¯ nháº­t nhá»). CÃ¡c báº¡n cÃ³ thá»ƒ xem chi tiáº¿t á»Ÿ hÃ¬nh bÃªn dÆ°á»›i.\nFocal loss (RetinaNet) Trong thá»±c táº¿, chÃºng ta sáº½ gáº·p tÃ¬nh tráº¡ng tá»· lá»‡ diá»‡n tÃ­ch cá»§a cÃ¡c Ä‘á»‘i tÆ°á»£ng trong áº£nh nhá» hÆ¡n nhiá»u so vá»›i pháº§n background cÃ²n láº¡i, vÃ­ dá»¥ chÃºng ta cáº§n nháº­n dáº¡ng má»™t quáº£ cam cÃ³ kÃ­ch thÆ°á»›c 100x100 trong áº£nh 1920x1080. VÃ¬ pháº§n background quÃ¡ lá»›n nÃªn chÃºng sáº½ lÃ  thÃ nh pháº§n \u0026ldquo;thá»‘ng trá»‹\u0026rdquo; vÃ  lÃ m sai lá»‡ch káº¿t quáº£. SSD sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p láº¥y máº«u tá»· lá»‡ cá»§a object class vÃ  background class trong quÃ¡ trÃ¬nh train (nÃªn background sáº½ khÃ´ng cÃ²n thá»‘ng trá»‹ ná»¯a).\nNgoÃ i ra, chÃºng ta sáº½ cÃ²n gáº·p tÃ¬nh tráº¡ng lÃ  sá»‘ lÆ°á»£ng tá»· lá»‡ object trong áº£nh khÃ´ng Ä‘á»u nhau, vÃ­ dá»¥ trong táº­p huáº¥n luyá»‡t cÃ³ 1000 quáº£ cam vÃ  10 quáº£ tÃ¡o.\nFocal loss (FL) Ä‘Æ°á»£c sinh ra Ä‘á»ƒ giáº£i quyáº¿t tÃ¬nh tráº¡ng nÃ y. Äá»ƒ Ä‘i vÃ o chi tiáº¿t hÆ¡n, chÃºng ta nháº¯c láº¡i hÃ m lá»—i cross entropy.\n$$ \\begin{equation} CE(p,y) = \\begin{cases} -\\log(p) \u0026amp; \\text{if y=1} \\\\\\\\ -\\log(1-p) \u0026amp; \\text{otherwise} \\end{cases} \\end{equation} $$\nTrong hÃ m trÃªn thÃ¬ y nháº­n giÃ¡ trá»‹ 1 hoáº·c -1. GiÃ¡ trá»‹ xÃ¡c xuáº¥t náº±m trong khoáº£ng (0,1) lÃ  xÃ¡c suáº¥t dá»± Ä‘oÃ¡n cho lá»›p cÃ³ y=1.\nÄá»ƒ rÃµ rÃ ng hÆ¡n, ta cÃ³ thá»ƒ viáº¿t láº¡i hÃ m trÃªn nhÆ° sau:\n$$ \\begin{equation} p_t = \\begin{cases} p \u0026amp; \\text{if y=1} \\\\\\\\ 1-p \u0026amp; \\text{otherwise} \\end{cases} \\end{equation} $$\n$$ \\begin{equation} CE(p,y) = CE(p_t) = -\\log(p_t) \\end{equation} $$\nTa cÃ³ nháº­n xÃ©t ráº±ng Ä‘á»‘i vá»›i cÃ¡c trÆ°á»ng há»£p Ä‘Æ°á»£c phÃ¢n loáº¡i tá»‘t (cÃ³ xÃ¡c suáº¥t lá»›n hÆ¡n 0.6) thÃ¬ hÃ m loss nháº­n gÃ¡i trá»‹ vá»›i Ä‘á»™ lá»›n lá»›n hÆ¡n 0. VÃ  trong trÆ°á»ng há»£p dá»¯ liá»‡u cÃ³ tá»· lá»‡ lá»‡ch cao thÃ¬ tá»•ng cÃ¡c giÃ¡ trá»‹ nÃ y sáº½ cho ra káº¿t quáº£ loss vá»›i má»™t con sá»‘ ráº¥t lá»›n so vá»›i loss cá»§a cÃ¡c trÆ°á»ng há»£p khÃ³ phÃ¢m loáº¡i. VÃ  nÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n quÃ¡ trÃ¬nh huáº¥n luyá»‡n.\nÃ tÆ°á»Ÿng chÃ­nh cá»§a focal-lost lÃ  Ä‘á»‘i vá»›i cÃ¡c trÆ°á»ng há»£p Ä‘Æ°á»£c phÃ¢n loáº¡i tá»‘t ( xÃ¡c suáº¥t lá»›n hÆ¡n 0.5) thÃ¬ focal lost sáº½ lÃ m giáº£m giÃ¡ trá»‹ cross-entropy cá»§a nÃ³ xuá»‘ng nhá» hÆ¡n so vá»›i thÃ´ng thÆ°á»ng. Do Ä‘Ã³, ta sáº½ thÃªm trá»ng sá»‘ cho hÃ m cross-entropy Ä‘á»ƒ biáº¿n thÃ nh hÃ m focal lost.\n$$ FL(p_t) = -(1-p_t)^\\gamma\\log(p_t) $$\nVá»›i nhÃ¢n tá»­ Ä‘Æ°á»£c thÃªm vÃ o Ä‘Æ°á»£c gá»i lÃ  modulating factor, gamma lá»›n hÆ¡n hoáº·c báº±ng 0 Ä‘Æ°á»£c gá»i lÃ  tham sá»‘ focusing.\nNhÃ¬n hÃ¬nh á»Ÿ trÃªn, ta tháº¥y ráº±ng khi gamma = 0 thÃ¬ hÃ m focal lost chÃ­nh lÃ  cross-entropy.\nÄáº·c Ä‘iá»ƒm cá»§a hÃ m lost trÃªn nhÆ° sau:\nKhi máº«u bá»‹ phÃ¢n loáº¡i sai, pt nhá», nhÃ¢n tá»‘ modulating factor gáº§n vá»›i 1 vÃ  hÃ m lost Ã­t bá»‹ áº£nh hÆ°á»Ÿng. Khi pt tiáº¿n gáº§n tá»›i 1 (máº«u phÃ¢n loáº¡i tá»‘t), moduling factor sáº½ tiáº¿n gáº§n tá»›i 0 vÃ  hÃ m loss trong trÆ°á»ng há»£p nÃ y sáº½ bá»‹ giáº£m trá»ng sá»‘ xuá»‘ng.\nTham sá»‘ focusing sáº½ Ä‘iá»u chá»‰nh tá»· lá»‡ cÃ¡c trÆ°á»ng há»£p Ä‘Æ°á»£c phÃ¢n loáº¡i tá»‘t Ä‘Æ°á»£c giáº£m trá»ng sá»‘. Khi gamma cÃ ng tÄƒng thÃ¬ áº£nh hÆ°á»Ÿng cá»§a modulating factor cÅ©ng tÄƒng. Trong cÃ¡c thÃ­ nghiá»‡m cho tháº¥y vá»›i gamma = 2 hÃ¬ káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c sáº½ tá»‘t nháº¥t.\nHÃ¬nh bÃªn dÆ°á»›i lÃ  Ä‘á»“ hÃ¬nh cá»§a RetinaNet Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn FPN vÃ  ResNet sá»­ dung Focal loss.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\nBÃ i viáº¿t Ä‘Æ°á»£c lÆ°á»£c dá»‹ch vÃ  tham kháº£o tá»« nguá»“n https://medium.com/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d\n","date":"Dec 6, 2018","img":"","permalink":"/blog/2018-12-06-what-do-we-learn-from-single-shot-object-detection/","series":null,"tags":["Machine learning","Deeplearning","object detector","single shot"],"title":"TÃ¬m Hiá»ƒu Single Shot Object Detectors"},{"categories":null,"content":" Sliding-window detectors Selective Search Máº¡ng R-CNN Máº¡ng Fast R-CNN ROI Pooling Faster R-CNN Region proposal network Hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh R-CNN Region-based Fully Convolutional Networks Sliding-window detectors Báº¯t Ä‘áº§u tá»« nÄƒm 2012, sau khi máº¡ng AlexNet giÃ nh giáº£i nháº¥t cuá»™c thi 2012 ILSVRC, má»i nghiÃªn cá»©u vá» phÃ¢n lá»›p dá»¯ liá»‡u Ä‘á»u sá»­ dá»¥ng máº¡ng CNN. Ká»ƒ tá»« Ä‘Ã³ Ä‘áº¿n Ä‘Ã¢y, CNN Ä‘Æ°á»£c coi nhÆ° lÃ  thuáº­t toÃ¡n thá»‘ng trá»‹ trÃªn má»i publish paper vá» cÃ¡c bÃ i toÃ¡n phÃ¢n lá»›p Ä‘á»‘i tÆ°á»£ng. Trong khi Ä‘Ã³, Ä‘á»ƒ nháº­n dáº¡ng 1 Ä‘á»‘i tÆ°á»£ng trong áº£nh, cÃ¡c Ä‘Æ¡n giáº£n nháº¥t lÃ  thiáº¿t láº­p má»™t cá»­a sá»• trÆ°á»£t cÃ³ kÃ­ch thÆ°á»›c lÃ  window size trÆ°á»£t tá»« trÃ¡i qua pháº£i, tá»« trÃªn xuá»‘ng dÆ°á»›i, quÃ©t qua toÃ n bá»™ bá»©c áº£nh. Äá»ƒ phÃ¡t hiá»‡n cÃ¡c Ä‘á»‘i tÆ°á»£ng khÃ¡c nhau á»Ÿ cÃ¡c gÃ³c nhÃ¬n khÃ¡c nhau, chÃºng ta sáº½ sá»­ dá»¥ng cá»­a sá»• trÆ°á»£t cÃ³ kÃ­ch thÆ°á»›c thay Ä‘á»•i vÃ  áº£nh Ä‘áº§u vÃ o cÃ³ kÃ­ch thÆ°á»›c thay Ä‘á»•i.\nDá»±a vÃ o windowsize, chÃºng ta cÃ³ thá»ƒ cáº¯t táº¥m hÃ¬nh bá»± thÃ nh cÃ¡c táº¥m hÃ¬nh nhá», sau Ä‘Ã³ sáº½ rescale cÃ¡c pháº§n nhá» cá»§a bá»©c áº£nh thÃ nh cÃ¡c bá»©c áº£nh cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh.\nCÃ¡c pháº§n cá»§a bá»©c áº£nh sau Ä‘Ã³ sáº½ Ä‘Æ°á»£c Ä‘em qua bá»™ phÃ¢n lá»›p CNN Ä‘á»ƒ rÃºt trÃ­ch cÃ¡c Ä‘áº·c trÆ°ng, sau Ä‘Ã³ sá»­ dá»¥ng má»™t hÃ m phÃ¢n lá»›p (nhÆ° svm, logictic regression) Ä‘á»ƒ xÃ¡c Ä‘á»‹nh lá»›p cá»§a bá»©c hÃ¬nh vÃ  sá»­ dá»¥ng linear regressor Ä‘á»ƒ tÃ¬m bao Ä‘Ã³ng cá»§a Ä‘á»‘i tÆ°á»£ng.\nMÃ£ giáº£ cá»§a mÃ´ hÃ¬nh\n1for window in windows 2 patch = get_patch(image, window) 3 results = detector(patch) CÃ¡ch dá»… dÃ ng nháº¥t Ä‘á»ƒ cáº£i tiáº¿n hiá»‡u nÄƒng cá»§a phÆ°Æ¡ng phÃ¡p nÃ y lÃ  giáº£m sá»‘ lÆ°á»£ng táº¥m hÃ¬nh nhá» xuá»‘ng (vÃ­ dá»¥ tÄƒng kÃ­ch thÆ°á»›c window size). CÃ¡ch nÃ y cÃ²n Ä‘Æ°á»£c giang há»“ gá»i lÃ  brute force.\nSelective Search Thay vÃ¬ hÆ°á»›ng tiáº¿p cáº­n brute force á»Ÿ trÃªn, chÃºng ta sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p region proposal Ä‘á»ƒ táº¡o cÃ¡c region of interest (ROIs) Ä‘á»ƒ phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng. Selective search lÃ  má»™t phÆ°Æ¡ng phÃ¡p náº±m trong nhÃ³m region proposal. Trong phÆ°Æ¡ng phÃ¡p selective search(SS), chÃºng ta báº¯t Ä‘áº§u báº±ng cÃ¡ch xem cÃ¡c pixel lÃ  má»—i nhÃ³m, cÃ¡c láº§n láº·p tiáº¿p theo, chÃºng ta sáº½ tÃ­nh khoáº£ng cÃ¡ch ngá»¯ nghÄ©a (vÃ­ dá»¥ nhÆ° lÃ  mÃ u sáº¯c, cÆ°á»ng Ä‘á»™ Ã¡nh sÃ¡ng) giá»¯a cÃ¡c nhÃ³m vÃ  gom cÃ¡c nhÃ³m cÃ³ khoáº£ng cÃ¡ch gáº§n nhau vá» chung 1 nhÃ³m Ä‘á»ƒ tÃ¬m ra phÃ¢n vÃ¹ng cÃ³ kháº£ nÄƒng cao nháº¥t chá»©a Ä‘á»‘i tÆ°á»£ng (Æ°u tiÃªn gom nhá»¯ng nhÃ³m nhá» trÆ°á»›c).\nNhÆ° hÃ¬nh bÃªn dÆ°á»›i, dÃ²ng Ä‘áº§u tiÃªn, bá»©c áº£nh Ä‘Ã¢u tiÃªn lÃ  ta cÃ³ má»™t vÃ i nhÃ³m nhá» á»Ÿ thá»i Ä‘iá»ƒm X nÃ o Ä‘Ã³, á»Ÿ hÃ¬nh thá»© 2 lÃ  thá»±c hiá»‡n gom nhá»›m theo cÆ°á»ng Ä‘á»™ mÃ u sáº¯c cá»§a hÃ¬nh sá»‘ 1, vÃ  á»Ÿ bÆ°á»›c cuá»‘i cÃ¹ng, ta thu Ä‘Æ°á»£c hÃ¬nh sá»‘ 3. Nhá»¯ng hÃ¬nh chá»¯ nháº­t mÃ u xanh á»Ÿ dÃ²ng thá»© 2 lÃ  nhá»¯ng ROIS mÃ´ phá»ng quÃ¡ trÃ¬nh gom nhÃ³m Ä‘á»ƒ tÃ¬m phÃ¢n vÃ¹ng cÃ³ kháº£ nÄƒng chá»©a Ä‘á»‘i tÆ°á»£ng.\nselective search\nMáº¡ng R-CNN Máº¡ng R-CNN sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p region proposal Ä‘á»ƒ táº¡o ra khoáº£ng 2000 ROIs. CÃ¡c vÃ¹ng sau Ä‘Ã³ sáº½ Ä‘Æ°á»£c rescale theo má»™t kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh nÃ o Ä‘Ã³ vÃ  Ä‘Æ°á»£c Ä‘Æ°a vÃ o mÃ´ hÃ¬nh CNN cÃ³ lá»›p cuá»‘i cÃ¹ng kÃ  má»™t full conected layer Ä‘á»ƒ phÃ¢n lá»›p Ä‘á»‘i tÆ°á»£ng vÃ  Ä‘á»ƒ lá»c ra boundary box (bao Ä‘Ã³ng) cá»§a Ä‘á»‘i tÆ°á»£ng.\nMÃ´ phá»ng viá»‡c sá»­ dá»¥ng region proposal\nMÃ´ phá»ng viá»‡c sá»­ dá»¥ng region proposal cá»§a RCNN\nMÃ£ giáº£ cá»§a mÃ´ hÃ¬nh\n1ROIs = region_proposal(image) 2for ROI in ROIs 3 patch = get_patch(image, ROI) 4 results = detector(patch) Vá»›i viá»‡c sá»­ dá»¥ng Ã­t táº¥m áº£nh nhá» hÆ¡n, vÃ  cháº¥t lÆ°á»£ng cá»§a má»—i táº¥m áº£nh nhá» tá»‘t hÆ¡n, Máº¡ng R-CNN cháº¡y nhanh hÆ¡n vÃ  cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n so vá»›i mÃ´ hÃ¬nh sá»­ dá»¥ng cá»­a sá»• trÆ°á»£t.\nMáº¡ng Fast R-CNN Trong thá»±c táº¿, cÃ¡c phÃ¢n vÃ¹ng cá»§a máº¡ng R-CNN bá»‹ chá»“ng láº¥p má»™t pháº§n / toÃ n bá»™ vá»›i cÃ¡c phÃ¢n vÃ¹ng khÃ¡c. Do Ä‘Ã³, viá»‡c huáº¥n luyá»‡n vÃ  thá»±c thi ( inference ) máº¡ng R-CNN diá»…n ra khÃ¡ cháº­m. Náº¿u chÃºng ta cÃ³ 2000 proposal cá»§a máº¡ng R-CNN, chÃºng ta pháº£i thá»±c hiá»‡n 2000 láº§n viá»‡c rÃºt trÃ­ch Ä‘áº·c trÆ°ng, má»™t con sá»‘ khÃ¡c lá»›n.\nThay vÃ¬ pháº£i rÃºt trÃ­ch Ä‘áº·c trÆ°ng cá»§a má»—i proposal, chÃºng ta cÃ³ thá»ƒ dÃ¹ng CNN rÃºt trÃ­ch Ä‘áº·c trÆ°ng cá»§a toÃ n bá»™ bá»©c áº£nh trÆ°á»›c (Ä‘Æ°á»£c feature map), Ä‘á»“ng thá»i rÃºt trÃ­ch cÃ¡c proposal, láº¥y cÃ¡c proposal tÆ°Æ¡ng á»©ng trÃªn feature map, rescale vÃ  cuá»‘i cÃ¹ng lÃ  phÃ¢n lá»›p vÃ  tÃ¬m vá»‹ trÃ­ cá»§a object. Vá»›i viá»‡c khÃ´ng pháº£i láº·p láº¡i 2000 láº§n viá»‡c rÃºt trÃ­ch Ä‘áº·c trÆ°ng, Fast R-CNN giáº£m thá»i gian xá»­ lÃ½ má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ.\nMÃ´ phá»ngviá»‡c sá»­ dá»¥ng propoxal trÃªn feature map vÃ  cÃ¡c bÆ°á»›c tiáº¿p theo cá»§a Fast R-CNN\nÄá»“ hÃ¬nh cá»§a Fast R-CNN\nMÃ£ giáº£ cá»§a mÃ´ hÃ¬nh\n1feature_maps = process(image) 2ROIs = region_proposal(image) 3for ROI in ROIs 4 patch = roi_pooling(feature_maps, ROI) 5 results = detector2(patch) Vá»›i viá»‡c khÃ´ng pháº£i láº·p Ä‘i láº·p láº¡i quÃ¡ trÃ¬nh tÃ¬m ra cÃ¡c proposal, tá»‘c Ä‘á»™ cá»§a thuáº­t toÃ¡n tÄƒng lÃªn kha khÃ¡. Trong thá»±c nghiá»‡m, mÃ´ hÃ¬nh Fast R-CNN cháº¡y nhanh hÆ¡n gáº¥p 10 láº§n so vá»›i R-CNN trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. VÃ  nhanh hÆ¡n 150 láº§n trong inferencing.\nMá»™t khÃ¡c biá»‡t lá»›n nháº¥t cá»§a Fast R-CNN lÃ  toÃ n bá»™ network (feature extractior, classifier, boundary box regressor) cÃ³ thá»ƒ huáº¥n luyá»‡n end-to end (nghÄ©a lÃ  tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i) vá»›i 2 hÃ m Ä‘á»™ lá»—i (loss funtion) khÃ¡c nhau cÃ¹ng lÃºc (classification loss vÃ  localization loss). Äiá»u nÃ y lÃ m tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh.\nROI Pooling VÃ¬ Fast R-CNN sá»­ dá»¥ng full connected layter á»Ÿ lá»›p cuá»‘i, nÃªn Ä‘Ã²i há»i input cá»§a chÃºng pháº£i cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh, nÃªn ta pháº£i resize láº¡i feature vá» 1 kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh (do 2000 proposal cÃ³ kÃ­ch thÆ°á»›c khÃ´ng cá»‘ Ä‘á»‹nh). á» Ä‘Ã¢y, cÃ¡c tÃ¡c giáº£ sá»­ dá»¥ng ROI pooling Ä‘á»ƒ resize. Thuáº­t toÃ¡n á»Ÿ Ä‘Ã¢y Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° sau:\nGiáº£ sá»­ Ä‘Æ¡n giáº£n lÃ  chÃºng ta cÃ³ má»™t proposal cÃ³ kÃ­ch thÆ°á»›c 5x7, vÃ  chÃºng ta cáº§n resize vá» hÃ¬nh dáº¡ng 2x2. ChÃºng ta xem ká»¹ hÃ¬nh bÃªn dÆ°á»›i.\nHÃ¬nh áº£nh mÃ´ phá»ng ROI pooling\nHÃ¬nh á»Ÿ bÃªn trÃ¡i lÃ  feature map cá»§a chÃºng ta.\nHÃ¬nh sá»‘ 2, vÃ¹ng hÃ¬nh chá»¯ nháº­t xanh lÃ  vÃ¹ng proposal 5x7.\nVÃ¬ chÃºng ta cáº§n resize vá» vÃ¹ng cÃ³ kÃ­ch thÆ°á»›c 2x2 (4 pháº§n), nÃªn ta chia vÃ¹ng proposal 5x7 thÃ nh 4 pháº§n (5/2 =2 dÆ° 3, váº­y cÃ³ 1 pháº§n lÃ  2, 1 pháº§n lÃ  3. TÆ°Æ¡ng tá»± 7/2 = 3 dÆ° 4, váº­y cÃ³ 1 pháº§n 3, má»™t pháº§n 4. Cuá»‘i cÃ¹ng ta cÃ³ 4 hÃ¬nh chá»¯ nháº­t cÃ³ kÃ­ch thÆ°á»›c tÆ°Æ¡ng á»©ng lÃ  2x3, 2x4, 3x3, 3x4) (HÃ¬nh sá»‘ 3).\nHÃ¬nh sá»‘ 4, tá»« 4 pháº§n cá»§a vÃ¹ng sá»‘ 3, ta sáº½ láº¥y giÃ¡ trá»‹ lá»›n nháº¥t cá»§a má»—i vÃ¹ng.\nVáº­y lÃ  ta thu Ä‘Æ°á»£c feature proposal cÃ³ kÃ­ch thÆ°á»›c 2x2 rá»“i.\nFaster R-CNN NhÃ¬n ká»¹ láº¡i vÃ o thuáº­t toÃ¡n F-CNN, chÃºng ta cáº§n pháº£i rÃºt rÃ­ch 2000 ROIs, vÃ  nÃ³ lÃ  nguyÃªn nhÃ¢n lá»›n gÃ¢y nÃªn sá»± cháº­m trá»ƒ cá»§a mÃ´ hÃ¬nh\n1feature_maps = process(image) 2ROIs = region_proposal(image) # Expensive, slow 3for ROI in ROIs 4 patch = roi_pooling(feature_maps, ROI) 5 results = detector2(patch) Thuáº­t toÃ¡n Faster R-CNN sá»­ dá»¥ng mÃ´ hÃ¬nh gáº§n nhÆ° tÆ°Æ¡ng tá»± Fast R-CNN, ngoÃ i viá»‡c sá»­ dá»¥ng thuáº­t toÃ¡n interal deep network thay cho selective search Ä‘á»ƒ tÃ¬m region proposal. Thuáº­t toÃ¡n má»›i cháº¡y hiá»‡u quáº£ hÆ¡n khi tÃ¬m táº¥t cáº£ cÃ¡c ROIs trÃªn má»—i bá»©c áº£nh vá»›i tá»‘c Ä‘á»™ 10ms/\nMÃ´ hÃ¬nh cá»§a Faster R-CNN\nÄá»“ hÃ¬nh cá»§a Faster R-CNN\nRegion proposal network Máº¡ng region proposal sá»­ dá»¥ng feature map lÃ m input Ä‘áº§u vÃ o (nhÆ° hÃ¬nh trÃªn Ä‘Ã£ mÃ´ phá»ng). Máº¡ng sá»­ dá»¥ng 1 bá»™ lá»c 3x3, sau Ä‘Ã³ lÃ  má»™t mÃ´ hÃ¬nh CNN nhÆ° ZF hoáº·c VGG hoáº·c ResNet ( mÃ´ hÃ¬nh cÃ ng phá»©c táº¡p thÃ¬ Ä‘á»™ chÃ­nh xÃ¡c cao, nhÆ°ng bÃ¹ láº¡i thá»i gian tÃ¬m kiáº¿m sáº½ lÃ¢u hÆ¡n) Ä‘á»ƒ dá»± Ä‘oÃ¡n boundary box vÃ  object score (Ä‘á»ƒ xÃ©t xem trong bodary box trÃªn cÃ³ chá»©a Ä‘á»‘i tÆ°á»£ng hay khÃ´ng. Trong thá»±c táº¿, máº¡ng Faster R-CNN tráº£ vá» 2 lá»›p, lá»›p thá»© nháº¥t lÃ  cÃ³ chá»©a object, lá»›p thá»© 2 lÃ  khÃ´ng chá»©a object ( vÃ­ dá»¥ lá»›p mÃ u ná»n - background, lá»›p abc gÃ¬ gÃ¬ Ä‘Ã³)) .\nVÃ­ dá»¥ Region proposal network\nMÃ´ hÃ¬nh Region proposal network sá»­ dá»¥ng ZF network\nGiáº£ sá»­ táº¡i 1 Ä‘iá»ƒm nÃ o Ä‘Ã³ trÃªn feature map, RPN cÃ³ k dá»± Ä‘oÃ¡n, váº­y lÃ  chÃºng ta cÃ³ tá»•ng cá»™ng 4xk toáº¡ Ä‘á»™ Ä‘iá»ƒm vÃ  2xk Ä‘iá»ƒm cho Ä‘iá»ƒm Ä‘Ã³. NhÃ¬n vÃ­ dá»¥ á»Ÿ hÃ¬nh bÃªn dÆ°á»›i.\nHÃ¬nh 1: ta cÃ³ feature map vá»›i kÃ­ch thÆ°á»›c 8x8, vÃ¹ng hÃ¬nh vuÃ´ng Ä‘Æ°á»£c tÃ´ lÃ  filter Ä‘ang xÃ©t cÃ³ kÃ­ch thÆ°á»›c 3x3. HÃ¬nh 2: Giáº£ sá»­ xÃ©t Ä‘iá»ƒm cÃ³ cháº¥m xanh. Táº¡i Ä‘iá»ƒm Ä‘Ã³, ta cÃ³ k=3 sau khi cháº¡y RPN, vÃ  ta Ä‘Æ°á»£c 3 hÃ¬nh chá»¯ nháº­t nhÆ° hÃ¬nh.\nTuy nhiÃªn, táº¡i má»—i Ä‘iá»ƒm, ta chá»‰ cáº§n 1 boundary box tá»‘t nháº¥t. CÃ¡ch Ä‘Æ¡n giáº£n nháº¥t lÃ  chá»n ngáº«u nhiÃªn 1 cÃ¡i. NhÆ°ng nhÆ° váº­y thÃ¬ ngay tá»« Ä‘áº§u ta chá»n k=1 luÃ´n cho khoáº», máº¯c cÃ´ng gÃ¬ pháº£i chá»n k=3. Trong thá»±c táº¿, Faster R-CNN khÃ´ng sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p random select. Thay vÃ o Ä‘Ã³, thuáº­t toÃ¡n má»™t reference boxs hay cÃ²n Ä‘Æ°á»£c gá»i vá»›i tÃªn lÃ  anchors vÃ  tÃ¬m má»©c Ä‘á»™ liÃªn quan cá»§a k boundary box vá»›i k reference boxs vÃ  chá»n ra boundary box cÃ³ Ä‘á»™ liÃªn quan lá»›n nháº¥t.\nVÃ­ dá»¥ anchors box\nCÃ¡c anchors nÃ y Ä‘Æ°á»£c lá»±a chá»n trÆ°á»›c Ä‘Ã³ vÃ  Ä‘Æ°á»£c xem lÃ  config cá»§a mÃ´ hÃ¬nh. Faster R-CNN sá»­ dá»¥ng 9 anchor boxs (tÆ°Æ¡ng á»©ng vá»›i k =3) vá»›i 3 box Ä‘áº§u tiÃªn cÃ³ tá»· lá»‡ width, height khÃ¡c nhau (vÃ­ dá»¥ 2x3, 3x3, 3x2), tiáº¿p Ä‘Ã³ sáº½ scale cÃ¡c box trÃªn vá»›i cÃ¡c tá»· lá»‡ khÃ¡c khau (vÃ­ dá»¥ 1.5,3,7) Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c 9 anchor boxs.\nVÃ¬ má»—i Ä‘iá»ƒm sá»­ dá»¥ng 9 anchors, nÃªn ta cÃ³ tá»•ng cá»™ng 2x9 score vÃ  4x9 location (toáº¡ Ä‘á»™)\nAnchor box cÃ³ thá»ƒ Ä‘Æ°á»£c goijlaf priors hoáº·c default boundary boxes trong má»—i bÃ i bÃ¡o khÃ¡c nhau.\nHiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh R-CNN HÃ¬nh bÃªn dÆ°á»›i mÃ´ táº£ benchmark cá»§a cÃ¡c mÃ´ hÃ¬nh dáº«n xuáº¥t tá»« R-CNN, ta tháº¥y Faster R-CNN cÃ³ tá»‘c Ä‘á»™ tá»‘t nháº¥t.\nRegion-based Fully Convolutional Networks Giáº£ sá»­ chÃºng ta chá»‰ cÃ³ toáº¡ Ä‘á»™ cá»§a máº¯t pháº£i trong khuÃ´n máº·t, chÃºng ta cÃ³ thá»ƒ ná»™i suy ra Ä‘Æ°á»£c vá»‹ trÃ­ cá»§a khuÃ´n máº·t. VÃ¬ ta biáº¿t ráº±ng máº¯t pháº£i náº±m á»Ÿ vá»‹ trÃ­ trÃ¡i trÃ¡i trong bá»©c hÃ¬nh, vÃ  ta tá»« Ä‘Ã³ suy ra vá»‹ trÃ­ cá»§a cÃ¡c pháº§n cÃ²n láº¡i (xem hÃ¬nh).\nNáº¿u chÃºng ta cÃ³ thÃªm thÃ´ng tin khÃ¡c, vÃ­ nhÆ° toáº¡ Ä‘á»™ cá»§a máº¯t trÃ¡i, mÅ©i, miá»‡ng, \u0026hellip; thÃ¬ chÃºng ta cÃ³ thá»ƒ káº¿t há»£p chÃºng Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cá»§a phÃ¢n vÃ¹ng khuÃ´n máº·t.\nTrong Faster R-CNN, chÃºng ta pháº£i tÃ¬m proposal sá»­ dá»¥ng má»™t mÃ´ hÃ¬nh CNN, vá»›i khoáº£ng 2000 ROI, chÃºng ta sáº½ tiÃªu tá»‘n má»™t khoáº£ng thá»i gian khÃ¡ lá»›n Ä‘á»ƒ tÃ¬m chÃºng.\n1feature_maps = process(image) 2ROIs = region_proposal(feature_maps) 3for ROI in ROIs 4 patch = roi_pooling(feature_maps, ROI) 5 class_scores, box = detector(patch) # Expensive, slow 6 class_probabilities = softmax(class_scores) Trong khi Ä‘Ã³, vá»›i Fast R-CNN, chÃºng ta chá»‰ cáº§n pháº£i tÃ­nh max hoáº·c average, nÃªn Fast R-CNN nhanh hÆ¡n Faster R-CNN á»Ÿ Ä‘Ã¢y.\n1feature_maps = process(image) 2ROIs = region_proposal(feature_maps) 3score_maps = compute_score_map(feature_maps) 4for ROI in ROIs 5 V = region_roi_pool(score_maps, ROI) 6 class_scores, box = average(V) # Much simpler, faster. 7 class_probabilities = softmax(class_scores) XÃ©t feature map M cÃ³ kÃ­ch thÆ°á»›c 5x5, trong Ä‘Ã³ cÃ³ chá»©a má»™t hÃ¬nh vuÃ´ng mÃ u xanh, hÃ¬nh vuÃ´ng xanh lÃ  Ä‘á»‘i tÆ°á»£ng thá»±c táº¿ ta cáº§n tÃ¬m.\nTa chia hÃ¬nh vuÃ´ng thÃ nh phÃ¢n vÃ¹ng cÃ³ kÃ­ch thÆ°á»›c 3x3 (hÃ¬nh 2). Sau Ä‘Ã³, chÃºng ta táº¡o má»™t feature má»›i Ä‘á»ƒ tá»« M Ä‘á»ƒ tÃ¬m ra gÃ³c trÃ¡i trÃªn cá»§a hÃ¬nh vuÃ´ng (chá»‰ tÃ¬m gÃ³c trÃ¡i trÃªn) (hÃ¬nh 3). Feature map má»›i giá»‘ng hÃ¬nh thá»© 3, chá»‰ cÃ³ Ã´ Ä‘Æ°á»£c tÃ´ mÃ u vÃ ng á»Ÿ vá»‹ trÃ­ [2,2] Ä‘Æ°á»£c báº­t.\nVá»›i má»—i 9 pháº§n cá»§a hÃ¬nh vuÃ´ng, chÃºng ta cÃ³ 9 feature map cho má»—i pháº§n, nháº­n dáº¡ng 9 vÃ¹ng tÆ°Æ¡ng á»©ng cho má»™t Ä‘á»‘i tÆ°á»£ng. Nhá»¯ng feature map nÃ y Ä‘Æ°á»£c gá»i lÃ  position sensitive score map, bá»Ÿi vÃ¬ chÃºng detect ra Ä‘iá»ƒm (score) vÃ  sub region cá»§a má»™t Ä‘á»‘i tÆ°á»£ng (Xem hÃ¬nh bÃªn dÆ°á»›i).\nXÃ©t áº£nh bÃªn dÆ°á»›i, giáº£ sá»­ vÃ¹ng Ä‘Æ°á»£c tÃ´ gáº¡ch Ä‘á» lÃ  proposal (hÃ¬nh 1). ChÃºng ta cÅ©ng chia nÃ³ thÃ nh nhá»¯ng phÃ¢n vÃ¹ng con cÃ³ kÃ­ch thÆ°á»›c 3x3 (hÃ¬nh 2). VÃ  tÃ¬m xem má»©c Ä‘á»™ giá»‘ng nhau cá»§a má»—i vÃ¹ng con cá»§a proposal vÃ  vÃ¹ng con cá»§a feature map nhÆ° tháº¿ nÃ o. Káº¿t quáº£ sáº½ Ä‘Æ°á»£c lÆ°u vÃ o má»™t ma tráº­n 3x3 nhÆ° hÃ¬nh sá»‘ 3.\nQuÃ¡ trÃ¬nh Ã¡nh xáº¡ Ä‘iá»ƒm tá»« score maps vÃ  ROIS vÃ o máº£ng vote_array Ä‘Æ°á»£c gá»i lÃ  position sensitive ROI pool.\nSau khi tÃ­nh toÃ¡n háº¿t cÃ¡c giÃ¡ trá»‹ cá»§a position-sensitive ROI pool, chÃºng ta sáº½ tÃ­nh trung bÃ¬nh cá»§a vote_array Ä‘á»ƒ láº¥y Ä‘iá»ƒm cá»§a lá»›p (class score).\nGiáº£ sá»­ mÃ´ hÃ¬nh chÃºng ta pháº£i nháº­n dáº¡ng k lá»›p, do cÃ³ thÃªm lá»›p background nÃªn chÃºng ta cÃ³ tá»•ng cá»™ng k+1 lá»›p. Vá»›i má»—i lá»›p chÃºng ta cÃ³ 3x3 score map, suy ra chÃºng ta cÃ³ tá»•ng cá»™ng lÃ  (k+1)x3x3 score maps, (k+1) Ä‘iá»ƒm, vÃ  dÃ¹ng softmax ta sáº½ thu Ä‘Æ°á»£c xÃ¡c suáº¥t cá»§a má»—i lá»›p.\nLuá»“ng dá»¯ liá»‡u cá»§a mÃ´ hÃ¬nh\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\nBÃ i viáº¿t Ä‘Æ°á»£c lÆ°á»£c dá»‹ch vÃ  tham kháº£o tá»« nguá»“n https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9\n","date":"Dec 5, 2018","img":"","permalink":"/blog/2018-12-05-what-do-we-learn-from-object-detection-p1/","series":null,"tags":["Machine learning","Deeplearning","object detector","region base"],"title":"TÃ¬m Hiá»ƒu Region Based Object Detectors"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Dáº«n nháº­p PhÃ¢n tÃ­ch dá»¯ liá»‡u Thá»±c hÃ nh XÃ¢y dá»±ng táº­p Ä‘áº·c trÆ°ng Äáº·c trÆ°ng sáº£n pháº©m Äáº·c trÆ°ng ngÆ°á»i dÃ¹ng Äáº·c trÆ°ng má»‘i tÆ°Æ¡ng quan giá»¯a ngÆ°á»i dÃ¹ng vÃ  sáº£n pháº©m Bá»• sung thÃªm Ä‘áº·c trÆ°ng Huáº¥n luyá»‡n mÃ´ hÃ¬nh Lá»i má»Ÿ Ä‘áº§u Instacart lÃ  má»™t startup cung á»©ng Ä‘á»“ táº¡p hÃ³a qua website vÃ  á»©ng dá»¥ng di Ä‘á»™ng. NgÆ°á»i dÃ¹ng chá»‰ cáº§n chá»n Ä‘á»“ muá»‘n mua táº¡i cÃ¡c chuá»—i bÃ¡n láº» vÃ  Ä‘áº·t Ä‘á»“, Instacart sáº½ Ä‘i mua vÃ  giao Ä‘áº¿n táº­n tay há». Äáº¿n nay, Instacart hoáº¡t Ä‘á»™ng táº¡i 15.000 cá»­a hÃ ng táº¡p hoÃ¡ táº¡i 4.000 thÃ nh phá»‘ vá»›i khoáº£ng 50.000 â€œtrá»£ lÃ½ mua sáº¯mâ€. Team data science cá»§a instacart Ä‘Ã³ng vai trÃ² ráº¥t quan trá»ng trong viá»‡c cung cáº¥p tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng trong viá»‡c sá»­ dá»¥ng app Ä‘á»ƒ mua hÃ ng. Hiá»‡n táº¡i, há» Ä‘ang sá»­ dá»¥ng cÃ¡c dá»¯ liá»‡u cá»§a khÃ¡ch hÃ ng Ä‘á»ƒ táº¡o nÃªn mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n sáº£n pháº©m nÃ o ngÆ°á»i dÃ¹ng sáº½ mua láº¡i, sáº½ mua thá»­ láº§n Ä‘áº§u tiÃªn, hoáº·c sáº½ thÃªm vÃ o giá» hÃ ng. Hiá»‡n há» Ä‘Ã£ publish khoáº£ng 3 triá»‡u Ä‘Æ¡n hÃ ng cá»§a há» Ä‘á»ƒ cÃ¡c nhÃ  khoa há»c dá»¯ liá»‡u khÃ¡c sá»­ dá»¥ng vÃ  nghiÃªn cá»©u.\nDáº«n nháº­p PhÃ¢n tÃ­ch dá»¯ liá»‡u CÃ¡c báº¡n cÃ³ thá»ƒ download dá»¯ liá»‡u á»Ÿ https://www.instacart.com/datasets/grocery-shopping-2017.\nCÃ¡c file bao gá»“m:\nFile aisles.csv (134 dÃ²ng) cÃ³ 2 cá»™t lÃ  aisle_id,aisle\n1aisle_id,aisle 21,prepared soups salads 32,specialty cheeses 43,energy granola bars 5 ... File departments.csv (21 dÃ²ng) gá»“m 2 cá»™t lÃ  department_id,department\n1department_id,department 21,frozen 32,other 43,bakery 5 ... File order_products__(prior|train).csv (trÃªn 30 triá»‡u dÃ²ng)\nTáº­p nÃ y chá»©a danh sÃ¡ch sáº£n pháº©m Ä‘Æ°á»£c mua trong má»—i Ä‘Æ¡n hÃ ng. File order_products__prior.csv chá»©a sáº£n pháº©m cá»§a Ä‘Æ¡n hÃ ng trÆ°á»›c Ä‘Ã³ cá»§a khÃ¡ch hÃ ng. \u0026lsquo;reordered\u0026rsquo; nÃ³i ráº±ng sáº£n pháº©m nÃ y trong Ä‘Æ¡n hÃ ng hiá»‡n táº¡i Ä‘Ã£ Ä‘Æ°á»£c mua á»Ÿ Ä‘Æ¡n hÃ ng trÆ°á»›c Ä‘Ã³. VÃ¬ váº­y, sáº½ cÃ³ Ä‘Æ¡n hÃ ng khÃ´ng Ä‘Æ°á»£c gÃ¡n lÃ  \u0026lsquo;reordered\u0026rsquo; (chÃºng ta cÃ³ thá»ƒ gÃ¡n nhÃ£n lÃ  None hoáº·c cÃ¡i gÃ¬ Ä‘Ã³ cÅ©ng Ä‘Æ°á»£c Ä‘á»ƒ chá»‰ cÃ¡c sáº£n pháº©m nÃ y). \u0026lsquo;add_to_cart_order\u0026rsquo; lÃ  thá»© tá»± cá»§a sp Ä‘Æ°á»£c thÃªm vÃ o giá» hÃ ng.\n1order_id,product_id,add_to_cart_order,reordered 2 1,49302,1,1 3 1,11109,2,1 4 1,10246,3,0 5 ... File orders.csv (3.4 triá»‡u dÃ²ng, 206k users): chá»©a thÃ´ng tin cá»§a Ä‘Æ¡n hÃ ng, trong Ä‘Ã³, order_dow lÃ  ngÃ y trong tuáº§n, eval_set thuá»™c má»™t trong 3 loáº¡i lÃ  prior, train, test. order_number lÃ  thá»© tá»± cá»§a Ä‘Æ¡n hÃ ng cá»§a user nÃ y.\n1order_id,user_id,eval_set,order_number,order_dow,order_hour_of_day,days_since_prior_order 2 2539329,1,prior,1,2,08, 3 2398795,1,prior,2,3,07,15.0 4 473747,1,prior,3,3,12,21.0 5 ... File products.csv ((50k dÃ²ng) chá»©a thÃ´ng tin sáº£n pháº©m:\n1 product_id,product_name,aisle_id,department_id 2 1,Chocolate Sandwich Cookies,61,19 3 2,All-Seasons Salt,104,13 4 3,Robust Golden Unsweetened Oolong Tea,94,7 5 ... Vá»›i má»—i order_id trong táº­p test á»Ÿ file orders.csv, chÃºng ta pháº£i dá»± Ä‘oÃ¡n cÃ¡c sáº£n pháº©m nÃ o ngÆ°á»i dÃ¹ng sáº½ mua láº¡i (\u0026ldquo;reorder\u0026rdquo;) thuá»™c Ä‘Æ¡n hÃ ng Ä‘Ã³. Náº¿u báº¡n dá»± Ä‘oÃ¡n Ä‘Ã³ lÃ  Ä‘Æ¡n hÃ ng khÃ´ng cÃ³ sáº£n pháº©m nÃ o Ä‘Æ°á»£c mua láº¡i, thÃ¬ ta sáº½ Ä‘iá»n vÃ o giÃ¡ trá»‹ \u0026lsquo;None\u0026rsquo;\nVÃ­ dá»¥ vá» káº¿t quáº£ dá»± Ä‘oÃ¡n:\n1order_id,products 217,1 2 334,None 4137,1 2 3 Thá»±c hÃ nh Äáº§u tiÃªn, ta sáº½ import má»™t sá»‘ thÆ° viá»‡n cÆ¡ báº£n Ä‘á»ƒ sá»­ dá»¥ng, vÃ  load táº¥t cáº£ cÃ¡c file lÃªn. LÆ°u Ã½ má»™t chÃºt lÃ  á»Ÿ Ä‘Ã¢y, mÃ¬nh Ä‘á»ƒ táº¥t cáº£ cÃ¡c file trong thÆ° má»¥c data\n1import pandas as pd 2import numpy as np 3from collections import OrderedDict 4 5from sklearn.linear_model import LogisticRegression 6from sklearn.metrics import f1_score 7 8from sklearn import metrics, cross_validation 9from sklearn.metrics import f1_score 10from sklearn.preprocessing import MinMaxScaler 11 12#Import the files 13aisles_df = pd.read_csv(\u0026#39;data/aisles.csv\u0026#39;) 14products_df = pd.read_csv(\u0026#39;data/products.csv\u0026#39;) 15orders_df = pd.read_csv(\u0026#39;data/orders.csv\u0026#39;) 16order_products_prior_df = pd.read_csv(\u0026#39;data/order_products__prior.csv\u0026#39;) 17departments_df = pd.read_csv(\u0026#39;data/departments.csv\u0026#39;) 18order_products_train_df = pd.read_csv(\u0026#39;data/order_products__train.csv\u0026#39;) Sau Ä‘Ã³, mÃ¬nh sáº½ merge Ä‘Æ¡n hÃ ng vÃ o chi tiáº¿t Ä‘Æ¡n hÃ ng cá»§a táº­p train vÃ  táº­p prior\n1order_products_train_df = order_products_train_df.merge(orders_df.drop(\u0026#39;eval_set\u0026#39;, axis=1), on=\u0026#39;order_id\u0026#39;) 2order_products_prior_df = order_products_prior_df.merge(orders_df.drop(\u0026#39;eval_set\u0026#39;, axis=1), on=\u0026#39;order_id\u0026#39;) show ra 5 dÃ²ng Ä‘áº§u tiÃªn cá»§a order_products_train_df\n1print(order_products_train_df.head()) 1 order_id product_id add_to_cart_order reordered user_id order_number order_dow order_hour_of_day days_since_prior_order 20 1 49302 1 1 112108 4 4 10 9.0 31 1 11109 2 1 112108 4 4 10 9.0 42 1 10246 3 0 112108 4 4 10 9.0 53 1 49683 4 0 112108 4 4 10 9.0 64 1 43633 5 1 112108 4 4 10 9.0 7 8[5 rows x 9 columns] Tá»•ng cá»™ng mÃ¬nh cÃ³ 9 cá»™t, Ã½ nghÄ©a cÃ¡c cá»™t mÃ¬nh cÃ³ giáº£i thÃ­ch á»Ÿ trÃªn rá»“i nha.\nTiáº¿p theo, chÃºng ta táº¡o táº­p táº­p dá»¯ liá»‡u Ä‘áº¿m sá»‘ lÆ°á»£ng sáº£n pháº©m cá»§a tá»«ng ngÆ°á»i mua\n1user_product_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;],as_index=False) 2 .agg({\u0026#39;order_id\u0026#39;:\u0026#39;count\u0026#39;}) 3 .rename(columns={\u0026#39;order_id\u0026#39;:\u0026#39;user_product_total_orders\u0026#39;})) 4 5train_ids = order_products_train_df[\u0026#39;user_id\u0026#39;].unique() 6df_X = user_product_df[user_product_df[\u0026#39;user_id\u0026#39;].isin(train_ids)] 7print(df_X.head()) 1 product_id user_id user_product_total_orders 20 1 138 2 31 1 709 1 43 1 777 1 56 1 1052 2 69 1 1494 3 á» Ä‘Ã¢y, ngÆ°á»i 138 mua sáº£n pháº©m 1 2 láº§n, ngÆ°á»i 709 mua sáº£n pháº©m 1 1 láº§n, \u0026hellip; tÆ°Æ¡ng tá»± nhÆ° váº­y cho cÃ¡c user vÃ  product khÃ¡c.\nBÆ°á»›c tiáº¿p theo, chÃºng ta sáº½ liá»‡t kÃª cÃ¡c sáº£n pháº©m ngÆ°á»i dÃ¹ng Ä‘Ã£ mua:\n1train_carts = (order_products_train_df.groupby(\u0026#39;user_id\u0026#39;,as_index=False) 2 .agg({\u0026#39;product_id\u0026#39;:(lambda x: set(x))}) 3 .rename(columns={\u0026#39;product_id\u0026#39;:\u0026#39;latest_cart\u0026#39;})) print(train_carts.head())\n1 user_id latest_cart 20 1 {196, 26405, 27845, 46149, 13032, 39657, 26088... 31 2 {24838, 11913, 45066, 31883, 48523, 38547, 248... 42 5 {40706, 21413, 20843, 48204, 21616, 19057, 201... 53 7 {17638, 29894, 47272, 45066, 13198, 37999, 408... 64 8 {27104, 15937, 5539, 41540, 31717, 48230, 2224... Má»‘i tÆ°Æ¡ng quan giá»¯a sáº£n pháº©m Ä‘Æ°á»£c add to card vÃ  sáº£n pháº©m Ä‘Æ°á»£c mua\n1df_X = df_X.merge(train_carts, on=\u0026#39;user_id\u0026#39;) 2df_X[\u0026#39;in_cart\u0026#39;] = (df_X.apply(lambda row: row[\u0026#39;product_id\u0026#39;] in row[\u0026#39;latest_cart\u0026#39;], axis=1).astype(int)) 3 4print(df_X.head()) 5 6print(df_X[\u0026#39;in_cart\u0026#39;].value_counts()) 1# df_X.head() 2 product_id user_id user_product_total_orders latest_cart in_cart 30 1 138 2 {42475} 0 41 907 138 2 {42475} 0 52 1000 138 1 {42475} 0 63 3265 138 1 {42475} 0 74 4913 138 1 {42475} 0 8 9# df_X[\u0026#39;in_cart\u0026#39;].value_counts() 100 7645837 111 828824 12Name: in_cart, dtype: int64 Tá»· lá»‡ khoáº£ng 9.7%. Äiá»u nÃ y nÃ³i lÃªn ráº±ng, ngÆ°á»i dÃ¹ng trong 1 phiÃªn mua hÃ ng cÃ³ thá»ƒ add ráº¥t nhiá»u sáº£n pháº©m vÃ o giá», nhÆ°ng chá»‰ khoáº£ng 10% sáº£n pháº©m há» mua tháº­t sá»±, hÆ¡n 90% sáº£n pháº©m cÃ²n láº¡i sáº½ bá»‹ remove trÆ°á»›c khi ná» nháº¥n nÃºt thanh toÃ¡n.\nXÃ¢y dá»±ng táº­p Ä‘áº·c trÆ°ng Äáº·c trÆ°ng sáº£n pháº©m Vá»›i Ä‘áº·c trÆ°ng sáº£n pháº©m, chÃºng ta sáº½ rÃºt trÃ­ch 2 Ä‘áº·c trÆ°ng Ä‘Æ¡n giáº£n lÃ  tá»•ng sá»‘ lÆ°á»£ng Ä‘Æ¡n hÃ ng cá»§a má»™t sáº£n pháº©m vÃ  trung bÃ¬nh sá»‘ lÆ°á»£ng Ä‘Æ¡n hÃ ng cÃ³ chá»©a sáº£n pháº©m.\n1prod_features = [\u0026#39;product_total_orders\u0026#39;,\u0026#39;product_avg_add_to_cart_order\u0026#39;] 2 3prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;],as_index=False) 4 .agg(OrderedDict( 5 [(\u0026#39;order_id\u0026#39;,\u0026#39;nunique\u0026#39;), 6 (\u0026#39;add_to_cart_order\u0026#39;,\u0026#39;mean\u0026#39;)]))) 7prod_features_df.columns = [\u0026#39;product_id\u0026#39;] + prod_features 8print(prod_features_df.head()) 1 2 product_id product_total_orders product_avg_add_to_cart_order 30 1 1852 5.801836 41 2 90 9.888889 52 3 277 6.415162 63 4 329 9.507599 74 5 15 6.466667 Add thÃªm Ä‘áº·c trÆ°ng sáº£n pháº©m vÃ o trong táº­p huáº¥n luyá»‡n\n1 2df_X = df_X.merge(prod_features_df, on=\u0026#39;product_id\u0026#39;) 3 4#note that dropping rows with NA product_avg_days_since_prior_order is likely a naive choice 5df_X = df_X.dropna() 6print(df_X.head()) 1 product_id user_id ... product_total_orders product_avg_add_to_cart_order 20 1 138 ... 1852 5.801836 31 1 709 ... 1852 5.801836 42 1 777 ... 1852 5.801836 53 1 1052 ... 1852 5.801836 64 1 1494 ... 1852 5.801836 Äáº·c trÆ°ng ngÆ°á»i dÃ¹ng Vá»›i ngÆ°á»i dÃ¹ng, chÃºng sa sá»­ dá»¥ng cÃ¡c Ä‘áº·c trÆ°ng lÃ : Tá»•ng sá»‘ lÆ°á»£ng Ä‘Æ¡n hÃ ng, trung bÃ¬nh sá»‘ sáº£n pháº©m trong 1 Ä‘Æ¡n hÃ ng, tá»•ng sá»‘ lÆ°á»£ng sáº£n pháº©m ngÆ°á»i dÃ¹ng mua, Trung bÃ¬nh sá»‘ ngÃ y user sáº½ mua Ä‘Æ¡n hÃ ng tiáº¿p theo\n1user_features = [\u0026#39;user_total_orders\u0026#39;,\u0026#39;user_avg_cartsize\u0026#39;,\u0026#39;user_total_products\u0026#39;,\u0026#39;user_avg_days_since_prior_order\u0026#39;] 2 3user_features_df = (order_products_prior_df.groupby([\u0026#39;user_id\u0026#39;],as_index=False) 4 .agg(OrderedDict( 5 [(\u0026#39;order_id\u0026#39;,[\u0026#39;nunique\u0026#39;, (lambda x: x.shape[0] / x.nunique())]), 6 (\u0026#39;product_id\u0026#39;,\u0026#39;nunique\u0026#39;), 7 (\u0026#39;days_since_prior_order\u0026#39;,\u0026#39;mean\u0026#39;)]))) 8 9user_features_df.columns = [\u0026#39;user_id\u0026#39;] + user_features 10print(user_features_df.head()) VÃ  chÃºng ta merge tiáº¿p Ä‘áº·c trÆ°ng user vÃ o trong táº­p huáº¥n luyá»‡n.\n1 2df_X = df_X.merge(user_features_df, on=\u0026#39;product_id\u0026#39;) 3 4#note that dropping rows with NA product_avg_days_since_prior_order is likely a naive choice 5df_X = df_X.dropna() Äáº·c trÆ°ng má»‘i tÆ°Æ¡ng quan giá»¯a ngÆ°á»i dÃ¹ng vÃ  sáº£n pháº©m á» Ä‘Ã¢y, chÃºng ta sá»­ dá»¥ng Ä‘áº·c trÆ°ng trung bÃ¬nh sá»‘ sáº£n pháº©m cá»§a 1 ngÆ°á»i Ä‘Æ°á»£c thÃªm vÃ o Ä‘Æ¡n hÃ ng vÃ  táº§n suáº¥t 1 sáº£n pháº©m 1 user add vÃ o Ä‘Æ¡n hÃ ng.\n1user_prod_features = [\u0026#39;user_product_avg_add_to_cart_order\u0026#39;] 2 3user_prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;],as_index=False) \\ 4 .agg(OrderedDict( 5 [(\u0026#39;add_to_cart_order\u0026#39;,\u0026#39;mean\u0026#39;)]))) 6 7user_prod_features_df.columns = [\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;] + user_prod_features 8df_X = df_X.merge(user_prod_features_df,on=[\u0026#39;user_id\u0026#39;,\u0026#39;product_id\u0026#39;]) 9df_X[\u0026#39;user_product_order_freq\u0026#39;] = df_X[\u0026#39;user_product_total_orders\u0026#39;] / df_X[\u0026#39;user_total_orders\u0026#39;] Bá»• sung thÃªm Ä‘áº·c trÆ°ng NgoÃ i cÃ¡c Ä‘áº·c trÆ°ng cÆ¡ báº£n á»Ÿ trÃªn, ta sáº½ bá»• sung thÃªm má»™t sá»‘ Ä‘áº·c trÆ°ng khÃ¡c:\nÄáº·c trÆ°ng sáº£n pháº©m: bá»• sung thÃªm 3 Ä‘áº·c trÆ°ng trung bÃ¬nh ngÃ y trong tuáº§n Ä‘Æ°á»£c Ä‘áº·t hÃ ng (cá»™t order_down), trung bÃ¬nh giá» Ä‘áº·t hÃ ng (cá»™t order_hour_of_day), trung bÃ¬nh ngÃ y Ä‘áº·t hÃ ng ká»ƒ tá»« láº§n Ä‘áº·t trÆ°á»›c Ä‘Ã³ (cá»™t days_since_prior_order) theo sáº£n pháº©m.\n1prod_features = [\u0026#39;product_avg_order_dow\u0026#39;, \u0026#39;product_avg_order_hour_of_day\u0026#39;, \u0026#39;product_avg_days_since_prior_order\u0026#39;] 2 3prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;], as_index=False) 4 .agg(OrderedDict( 5 [(\u0026#39;order_dow\u0026#39;,\u0026#39;mean\u0026#39;), 6 (\u0026#39;order_hour_of_day\u0026#39;, \u0026#39;mean\u0026#39;), 7 (\u0026#39;days_since_prior_order\u0026#39;, \u0026#39;mean\u0026#39;)]))) 8 9prod_features_df.columns = [\u0026#39;product_id\u0026#39;] + prod_features 10 11df_X = df_X.merge(prod_features_df, on=\u0026#39;product_id\u0026#39;) 12df_X = df_X.dropna() Äáº·c trÆ°ng ngÆ°á»i dÃ¹ng: bá»• sung thÃªm 2 cá»™t Ä‘áº·c trung trung bÃ¬nh ngÃ y trong tuáº§n Ä‘Æ°á»£c Ä‘áº·t hÃ ng (cá»™t order_down) vÃ  trung bÃ¬nh giá» Ä‘áº·t hÃ ng (cá»™t order_hour_of_day) theo ngÆ°á»i dÃ¹ng\n1user_features = [\u0026#39;user_avg_order_dow\u0026#39;,\u0026#39;user_avg_order_hour_of_day\u0026#39;] 2 3user_features_df = (order_products_prior_df.groupby([\u0026#39;user_id\u0026#39;],as_index=False) 4 .agg(OrderedDict( 5 [(\u0026#39;order_dow\u0026#39;,\u0026#39;mean\u0026#39;), 6 (\u0026#39;order_hour_of_day\u0026#39;,\u0026#39;mean\u0026#39;)]))) 7 8user_features_df.columns = [\u0026#39;user_id\u0026#39;] + user_features 9df_X = df_X.merge(user_features_df, on=\u0026#39;user_id\u0026#39;) 10df_X = df_X.dropna() Äáº·c trung ngÆ°á»i dÃ¹ng - sáº£n pháº©m: Bá»• sung thÃªm Ä‘áº·c trÆ°ng tung bÃ¬nh trÃªn cá»™t order_down, order_hour_of_day, days_since_prior_order theo ngÆ°á»i dÃ¹ng vÃ  sáº£n pháº©m\n1 2user_prod_features = [\u0026#39;user_product_avg_days_since_prior_order\u0026#39;, 3 \u0026#39;user_product_avg_order_dow\u0026#39;, 4 \u0026#39;user_product_avg_order_hour_of_day\u0026#39;] 5 6user_prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;],as_index=False) \\ 7 .agg(OrderedDict( 8 [(\u0026#39;days_since_prior_order\u0026#39;,\u0026#39;mean\u0026#39;), 9 (\u0026#39;order_dow\u0026#39;,\u0026#39;mean\u0026#39;), 10 (\u0026#39;order_hour_of_day\u0026#39;,\u0026#39;mean\u0026#39;)]))) 11 12user_prod_features_df.columns = [\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;] + user_prod_features 13 14df_X = df_X.merge(user_prod_features_df, on=[\u0026#39;user_id\u0026#39;, \u0026#39;product_id\u0026#39;]) 15df_X = df_X.dropna() Äáº·c trÆ°ng Ä‘á»™ lá»‡ch: TÃ­nh Ä‘á»™ lá»‡ch cá»§a cá»§a má»™t sá»‘ Ä‘áº·c trÆ°ng so vá»›i trung bÃ¬nh cá»§a chÃºng\n1#Create delta columns to compare how users perform against averages 2df_X[\u0026#39;product_total_orders_delta_per_user\u0026#39;] = df_X[\u0026#39;product_total_orders\u0026#39;] - df_X[\u0026#39;user_product_total_orders\u0026#39;] 3 4df_X[\u0026#39;product_avg_add_to_cart_order_delta_per_user\u0026#39;] = df_X[\u0026#39;product_avg_add_to_cart_order\u0026#39;] - \\ 5 df_X[\u0026#39;user_product_avg_add_to_cart_order\u0026#39;] 6 7df_X[\u0026#39;product_avg_order_dow_per_user\u0026#39;] = df_X[\u0026#39;product_avg_order_dow\u0026#39;] - df_X[\u0026#39;user_product_avg_order_dow\u0026#39;] 8 9df_X[\u0026#39;product_avg_order_hour_of_day_per_user\u0026#39;] = df_X[\u0026#39;product_avg_order_hour_of_day\u0026#39;] - \\ 10 df_X[\u0026#39;user_product_avg_order_hour_of_day\u0026#39;] 11 12df_X[\u0026#39;product_avg_days_since_prior_order_per_user\u0026#39;] = df_X[\u0026#39;product_avg_days_since_prior_order\u0026#39;] - \\ 13 df_X[\u0026#39;user_product_avg_days_since_prior_order\u0026#39;] Bá»• sung thÃªm Ä‘áº·c trÆ°ng department name\n1f_departments_df = products_df.merge(departments_df, on = \u0026#39;department_id\u0026#39;) 2f_departments_df = f_departments_df[[\u0026#39;product_id\u0026#39;, \u0026#39;department\u0026#39;]] 3 4df_X = df_X.merge(f_departments_df, on = \u0026#39;product_id\u0026#39;) 5df_X = df_X.dropna() 6df_X = pd.concat([df_X, pd.get_dummies(df_X[\u0026#39;department\u0026#39;])], axis=1) 7del df_X[\u0026#39;department\u0026#39;] ChÃºng ta cÃ³ tá»•ng cá»™ng 21 department name, váº­y chÃºng ta thÃªm 21 cá»™t, má»™t cá»™t tÆ°Æ¡ng á»©ng vá»›i má»™t department name, vÃ­ dá»¥: alcohol,babies ,bakery, \u0026hellip; Sáº£n pháº©m thuá»™c department name thÃ¬ sáº½ Ä‘Æ°á»£c Ä‘Ã¡nh sá»‘ 1, khÃ´ng thuá»™c department name thÃ¬ Ä‘Ã¡nh sá»‘ 0.\nHuáº¥n luyá»‡n mÃ´ hÃ¬nh Chia táº­p dá»¯ liá»‡u thÃ nh 80/20 trong Ä‘Ã³ 80% lÃ  táº­p train, 20% lÃ  táº­p test. Sá»­ dá»¥ng k-fold-cross_validation vá»›i k=10\n1 2np.random.seed(99) 3total_users = df_X[\u0026#39;user_id\u0026#39;].unique() 4test_users = np.random.choice(total_users, size=int(total_users.shape[0] * .20), replace=False) 5 6 7 8test_user_sets = [] 9length = len(test_users) 10cv = 10 11 12 13for x in range (0, cv): 14 start = int(x/cv*length) 15 finish = int((x+1)/cv*length) 16 test_user_sets.append(test_users[start:finish]) 17 18cv_f1_scores = [] 19cv_f1_scores_balanced = [] 20cv_f1_scores_10fit = [] 21 22for test_user_set in test_user_sets: 23 df_X_tr, df_X_te = df_X[~df_X[\u0026#39;user_id\u0026#39;].isin(test_user_set)], df_X[df_X[\u0026#39;user_id\u0026#39;].isin(test_user_set)] 24 25 y_tr, y_te = df_X_tr[\u0026#39;in_cart\u0026#39;], df_X_te[\u0026#39;in_cart\u0026#39;] 26 X_tr, X_te = df_X_tr.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 27 df_X_te.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 28 29 scaler = MinMaxScaler() 30 X_tr = pd.DataFrame(scaler.fit_transform(X_tr), columns=X_tr.columns) 31 X_te = pd.DataFrame(scaler.fit_transform(X_te), columns=X_te.columns) 32 33 lr = LogisticRegression(C=10000000) 34 lr_balanced = LogisticRegression(class_weight=\u0026#39;balanced\u0026#39;, C=10000000) 35 lr_10x = LogisticRegression(class_weight={1 : 6, 0 : 1}, C=10000000) 36 37 lr.fit(X_tr, y_tr) 38 cv_f1_scores.append(f1_score(lr.predict(X_te), y_te)) 39 40 lr_balanced.fit(X_tr, y_tr) 41 cv_f1_scores_balanced.append(f1_score(lr_balanced.predict(X_te), y_te)) 42 43 lr_10x.fit(X_tr, y_tr) 44 cv_f1_scores_10fit.append(f1_score(lr_10x.predict(X_te), y_te)) 45 46print(\u0026#34;cv_f1_scores: \u0026#34; +str( np.mean(cv_f1_scores))) 47print(\u0026#34;cv_f1_scores_balanced: \u0026#34;+str(np.mean(cv_f1_scores_balanced))) 48print(\u0026#34;cv_f1_scores_10fit: \u0026#34;+str(np.mean(cv_f1_scores_10fit))) 49 50df_X_tr, df_X_te = df_X[~df_X[\u0026#39;user_id\u0026#39;].isin(test_users)], df_X[df_X[\u0026#39;user_id\u0026#39;].isin(test_users)] 51 52y_tr, y_te = df_X_tr[\u0026#39;in_cart\u0026#39;], df_X_te[\u0026#39;in_cart\u0026#39;] 53X_tr, X_te = df_X_tr.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 54 df_X_te.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 55 56lr_10x = LogisticRegression(class_weight={1 : 6, 0 : 1}, C=10000000) 57lr_10x.fit(X_tr, y_tr) 58print(\u0026#34;F1 store all: \u0026#34;+str(f1_score(lr_10x.predict(X_te), y_te))) 1cv_f1_scores: 0.2026889989037295 2cv_f1_scores_balanced: 0.3816810646496983 3cv_f1_scores_10fit: 0.3899595078917494 4 5F1 store all: 0.3808374055616213 Thá»­ in ra há»‡ sá»‘ cá»§a hÃ m há»“i quy\n1coefficients = pd.DataFrame(lr_10x.coef_, columns = X_tr.columns) 2coefficients = np.exp(coefficients) 3print(coefficients.T) 1user_product_total_orders 1.160475 2product_total_orders 1.077254 3product_avg_add_to_cart_order 0.915343 4user_total_orders 0.983272 5user_avg_cartsize 1.059655 6user_total_products 0.993839 7user_avg_days_since_prior_order 0.993513 8user_product_avg_add_to_cart_order 0.950418 9user_product_order_freq 1.051246 10product_avg_order_dow 0.994744 11product_avg_order_hour_of_day 1.010971 12product_avg_days_since_prior_order 0.994498 13user_avg_order_dow 0.997298 14user_avg_order_hour_of_day 1.012958 15user_product_avg_days_since_prior_order 1.003382 16user_product_avg_order_dow 0.994477 17user_product_avg_order_hour_of_day 1.003457 18product_total_orders_delta_per_user 0.928288 19product_avg_add_to_cart_order_delta_per_user 0.963095 20product_avg_order_dow_per_user 1.000268 21product_avg_order_hour_of_day_per_user 1.007489 22product_avg_days_since_prior_order_per_user 0.991147 23alcohol 0.998866 24babies 1.000313 25bakery 1.003098 26beverages 1.007733 27breakfast 1.000117 28bulk 0.999980 29canned goods 0.995017 30dairy eggs 1.018069 31deli 1.002720 32dry goods pasta 0.997379 33frozen 1.000752 34household 0.992164 35international 0.996822 36meat seafood 1.000340 37missing 1.001953 38other 0.999607 39pantry 0.972038 40personal care 0.992072 41pets 1.000466 42produce 1.017809 43snacks 1.004893 Thá»­ show confusion matrix cá»§a dá»¯ liá»‡u:\n1from sklearn.metrics import confusion_matrix 2import seaborn as sns 3import matplotlib.pyplot as plt 4%matplotlib inline 5plt.style.use(\u0026#39;fivethirtyeight\u0026#39;) 6 7def plot_confusion_matrix(cm,title=\u0026#39;Confusion matrix\u0026#39;, cmap=plt.cm.Reds): 8 plt.imshow(cm, interpolation=\u0026#39;nearest\u0026#39;,cmap=cmap) 9 plt.title(title) 10 plt.colorbar() 11 plt.tight_layout() 12 plt.ylabel(\u0026#39;True label\u0026#39;) 13 plt.xlabel(\u0026#39;Predicted label\u0026#39;) 14 15#y_tr=np.ravel(y_tr) 16 17train_acc=lr_10x.score(X_tr, y_tr) 18test_acc=lr_10x.score(X_te, y_te) 19print(\u0026#34;Training Data Accuracy: %0.2f\u0026#34; %(train_acc)) 20print(\u0026#34;Test Data Accuracy: %0.2f\u0026#34; %(test_acc)) 21 22y_true = y_te 23y_pred = lr_10x.predict(X_te) 24 25 26conf = confusion_matrix(y_true, y_pred) 27print(conf) 28 29print (\u0026#39;\\n\u0026#39;) 30print (\u0026#34;Precision: %0.2f\u0026#34; %(conf[1, 1] / (conf[1, 1] + conf[0, 1]))) 31print (\u0026#34;Recall: %0.2f\u0026#34;% (conf[1, 1] / (conf[1, 1] + conf[1, 0]))) 32 33cm=confusion_matrix(y_true, y_pred, labels=[0, 1]) 34 35plt.figure() 36plot_confusion_matrix(cm) Káº¿t quáº£\n1Training Data Accuracy: 0.83 2Test Data Accuracy: 0.83 3[[1236979 190126] 4 [ 78107 82493]] 5 6 7Precision: 0.30 8Recall: 0.51 Show Ä‘Æ°á»ng cong ROC cá»§a dá»¯ liá»‡u\n1 2from sklearn.metrics import roc_curve, auc 3 4y_score = lr_10x.predict_proba(X_te)[:,1] 5 6fpr, tpr,_ = roc_curve(y_te, y_score) 7roc_auc = auc(fpr, tpr) 8 9plt.figure() 10# Plotting our Baseline.. 11plt.plot([0,1],[0,1], linestyle=\u0026#39;--\u0026#39;, color = \u0026#39;black\u0026#39;) 12plt.plot(fpr, tpr, color = \u0026#39;green\u0026#39;) 13plt.xlabel(\u0026#39;False Positive Rate\u0026#39;) 14plt.ylabel(\u0026#39;True Positive Rate\u0026#39;) 15plt.gca().set_aspect(\u0026#39;equal\u0026#39;, adjustable=\u0026#39;box\u0026#39;) Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Nov 13, 2018","img":"","permalink":"/blog/2018-11-13-instacart-market-basket-analysis/","series":null,"tags":["Machine learning","Deeplearning","instacart","Giá» hÃ ng","ÄÆ¡n hÃ ng"],"title":"PhÃ¢n TÃ­ch Giá» HÃ ng Cá»§a Website Instacart"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Dáº«n nháº­p PhÃ¢n tÃ­ch dá»¯ liá»‡u Scale dá»¯ liá»‡u PhÃ¢n chia táº­p train vÃ  test. XÃ¢y dá»±ng mÃ´ hÃ¬nh sá»­ dá»¥ng keras Lá»i má»Ÿ Ä‘áº§u á» bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ xÃ¢y dá»±ng mÃ´ hÃ¬nh hÆ¡n giáº£n Ä‘á»ƒ Ã¡p dá»¥ng vÃ o táº­p dá»¯ liá»‡u giÃ¡ chá»©ng khoÃ¡ng. Má»¥c tiÃªu cá»§a bÃ i nÃ y lÃ  chÃºng ta sáº½ dá»± Ä‘oÃ¡n chá»‰ sá»‘ S\u0026amp;P 500 sá»­ dá»¥ng LSTM. CÃ¡c báº¡n cÃ³ nhu cáº§u tÃ¬m hiá»ƒu thÃªm vá» chá»‰ sá»‘ sp 500 cÃ³ thá»ƒ Ä‘á»c thÃªm á»Ÿ https://vi.wikipedia.org/wiki/S%26P_500. ÄÃ¢y lÃ  má»™t á»©ng dá»¥ng nhá», khÃ´ng cÃ³ Ã½ nghÄ©a nhiá»u á»Ÿ thá»±c táº¿ do khi phÃ¢n tÃ­ch chá»©ng khoÃ¡n, ta cÃ²n xÃ©t thÃªm ráº¥t nhiá»u yáº¿u tá»‘ phá»¥ ná»¯a. MÃ´ hÃ¬nh nÃ y thá»±c cháº¥t chá»‰ lÃ  má»™t trong nhá»¯ng mÃ´ hÃ¬nh chÆ¡i chÆ¡i.\nDáº«n nháº­p PhÃ¢n tÃ­ch dá»¯ liá»‡u CÃ¡c báº¡n cÃ³ thá»ƒ download dá»¯ liá»‡u á»Ÿ https://github.com/AlexBlack2202/alexmodel/blob/master/GSPC.csv\nÄáº§u tiÃªn, nhÆ° thÆ°á»ng lá»‡, chÃºng ta sáº½ import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t Ä‘á»ƒ sá»­ dá»¥ng.\n1import numpy as np # linear algebra 2import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) 3 4from subprocess import check_output 5from keras.layers.core import Dense, Activation, Dropout 6from keras.layers.recurrent import LSTM 7from keras.models import Sequential 8from sklearn.cross_validation import train_test_split 9import time #helper libraries 10from sklearn.preprocessing import MinMaxScaler 11import matplotlib.pyplot as plt 12from numpy import newaxis Äá»c dá»¯ liá»‡u lÃªn:\n1 2file_name =\u0026#39;GSPC.csv\u0026#39; 3 4prices_dataset = pd.read_csv(file_name, header=0) 5 6`` 7 8Xem kÃ­ch thÆ°á»›c cá»§a dá»¯ liá»‡u: 9 10```python 11print(prices_dataset.shape) 1(17114, 7) Káº¿t quáº£ lÃ  ta cÃ³ 17114 ngÃ n dÃ²ng vÃ  7 cá»™t. Thá»­ show 10 row Ä‘áº§u tiÃªn cá»§a dá»¯ liá»‡u lÃªn xem nhÆ° tháº¿ nÃ o.\n1print(prices_dataset.head()) 1 Date Open High Low Close Adj Close Volume 20 1950-11-09 19.790001 19.790001 19.790001 19.790001 19.790001 1760000 31 1950-11-10 19.940001 19.940001 19.940001 19.940001 19.940001 1640000 42 1950-11-13 20.010000 20.010000 20.010000 20.010000 20.010000 1630000 53 1950-11-14 19.860001 19.860001 19.860001 19.860001 19.860001 1780000 64 1950-11-15 19.820000 19.820000 19.820000 19.820000 19.820000 1620000 Cá»™t Ä‘áº§u tiÃªn lÃ  ngÃ y, sau Ä‘Ã³ lÃ  giÃ¡ má»Ÿ cá»­a, giÃ¡ giao dá»‹ch cao nháº¥t, giÃ¡ giao dá»‹ch tháº¥p nhÃ¢t, giÃ¡ Ä‘Ã³ng cá»­, giÃ¡ Ä‘Ã³ng cá»­a Ä‘Ã£ Ä‘iá»u chá»‰nh, khá»‘i lÆ°á»£ng giao dá»‹ch.\nPlot Ä‘á»“ thá»‹ cá»§a mÃ£ SP500 lÃªn:\n1import matplotlib.pyplot as plt 2 3plt.plot(prices_dataset.Open.values, color=\u0026#39;red\u0026#39;, label=\u0026#39;open\u0026#39;) 4plt.plot(prices_dataset.Close.values, color=\u0026#39;green\u0026#39;, label=\u0026#39;close\u0026#39;) 5plt.plot(prices_dataset.Low.values, color=\u0026#39;blue\u0026#39;, label=\u0026#39;low\u0026#39;) 6plt.plot(prices_dataset.High.values, color=\u0026#39;black\u0026#39;, label=\u0026#39;high\u0026#39;) 7plt.title(\u0026#39;stock price\u0026#39;) 8plt.xlabel(\u0026#39;time [days]\u0026#39;) 9plt.ylabel(\u0026#39;price\u0026#39;) 10plt.legend(loc=\u0026#39;best\u0026#39;) 11plt.show() HÃ¬nh vá»›i sá»‘ lÆ°á»£ng hÆ¡i nhiá»u nÃªn khÃ³ phÃ¢n biá»‡t Ä‘Æ°á»£c giÃ¡ trá»‹ cá»§a dá»¯ liá»‡u, chÃºng ta thá»­ show Ä‘á»“ thá»‹ cá»§a 50 ngÃ y cuá»‘i cÃ¹ng trong dá»¯ liá»‡u.\n1prices_dataset_tail_50 = prices_dataset.tail(50) 2 3plt.plot(prices_dataset_tail_50.Open.values, color=\u0026#39;red\u0026#39;, label=\u0026#39;open\u0026#39;) 4plt.plot(prices_dataset_tail_50.Close.values, color=\u0026#39;green\u0026#39;, label=\u0026#39;close\u0026#39;) 5plt.plot(prices_dataset_tail_50.Low.values, color=\u0026#39;blue\u0026#39;, label=\u0026#39;low\u0026#39;) 6plt.plot(prices_dataset_tail_50.High.values, color=\u0026#39;black\u0026#39;, label=\u0026#39;high\u0026#39;) 7plt.title(\u0026#39;stock price\u0026#39;) 8plt.xlabel(\u0026#39;time [days]\u0026#39;) 9plt.ylabel(\u0026#39;price\u0026#39;) 10plt.legend(loc=\u0026#39;best\u0026#39;) 11plt.show() HÃ¬nh áº£nh trÃ´ng khÃ¡ rÃµ rÃ ng vÃ  trá»±c quan hÆ¡n ráº¥t nhiá»u.\nChÃºng ta sáº½ bá» Ä‘i cá»™t DATE,Adj Close,Volume Ä‘i. CÃ¡c cá»™t Ä‘Ã³ khÃ´ng cáº§n thiáº¿t cho quÃ¡ trÃ¬nh dá»± Ä‘oÃ¡n.\n1 2prices_dataset_dropout = prices_dataset.drop([\u0026#39;Date\u0026#39;,\u0026#39;Adj Close\u0026#39;,\u0026#39;Volume\u0026#39;], 1) Scale dá»¯ liá»‡u Khi sá»­ dá»¥ng ANN, chÃºng ta thÃ´ng thÆ°á»ng sáº½ scale dá»¯ liá»‡u input vá» Ä‘oáº¡n [-1,1]. Trong python, thÆ° viá»‡n sklearn Ä‘Ã£ há»— trá»£ cho chÃºng ta sáºµn cÃ¡c hÃ m scale dá»¯ liá»‡u cáº§n thiáº¿t.\n1# Scale data 2def normalize_data(df): 3 min_max_scaler = MinMaxScaler() 4 df[\u0026#39;Open\u0026#39;] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1)) 5 df[\u0026#39;High\u0026#39;] = min_max_scaler.fit_transform(df.High.values.reshape(-1,1)) 6 df[\u0026#39;Low\u0026#39;] = min_max_scaler.fit_transform(df.Low.values.reshape(-1,1)) 7 df[\u0026#39;Close\u0026#39;] = min_max_scaler.fit_transform(df.Close.values.reshape(-1,1)) 8 return df 9 10prices_dataset_norm = normalize_data(prices_dataset_dropout) PhÃ¢n chia táº­p train vÃ  test. ChÃºng ta sáº½ chia dá»¯ liá»‡u thÃ nh 2 pháº§n vá»›i 80% lÃ  train vÃ  20% cÃ²n láº¡i lÃ  test. Chá»n seq_len=20, cÃ¡c báº¡n cÃ³ thá»ƒ test vá»›i cÃ¡c seq len khÃ¡c, vÃ  sau Ä‘Ã³ chuyá»ƒn dá»¯ liá»‡u vá» dáº¡ng numpy array Ä‘á»ƒ dá»… dÃ ng thá»±c hiá»‡n cÃ¡c phÃ©p chuyá»ƒn Ä‘á»•i.\n1 2def generate_data(stock_ds, seq_len): 3 data_raw = stock_ds.as_matrix() 4 data = [] 5 6 # create all possible sequences of length seq_len 7 for index in range(len(data_raw) - seq_len): 8 data.append(data_raw[index: index + seq_len]) 9 return data 10 11#data as numpy array 12def generate_train_test(data_ds,split_percent=0.8): 13 print(len(data_ds)) 14 data = np.asarray(data_ds) 15 16 data_size = len(data) 17 train_end = int(np.floor(split_percent*data_size)) 18 19 x_train = data[:train_end,:-1,:] 20 y_train = data[:train_end,-1,:] 21 22 23 24 x_test = data[train_end:,:-1,:] 25 y_test = data[train_end:,-1,:] 26 27 return [x_train, y_train, x_test, y_test] 28 29 30 31seq_len = 20 # choose sequence length 32 33seq_prices_dataset = generate_data(prices_dataset_norm,seq_len) 34 35x_train, y_train, x_test, y_test = generate_train_test(seq_prices_dataset, 0.8) 36 37print(\u0026#39;x_train.shape = \u0026#39;,x_train.shape) 38print(\u0026#39;y_train.shape = \u0026#39;, y_train.shape) 39print(\u0026#39;x_test.shape = \u0026#39;, x_test.shape) 40print(\u0026#39;y_test.shape = \u0026#39;,y_test.shape) Káº¿t quáº£:\n1x_train.shape = (13675, 19, 4) 2y_train.shape = (13675, 4) 3x_test.shape = (3419, 19, 4) 4y_test.shape = (3419, 4) XÃ¢y dá»±ng mÃ´ hÃ¬nh sá»­ dá»¥ng keras á» Ä‘Ã¢y mÃ¬nh sá»­ dá»¥ng keras xÃ¢y dá»±ng mÃ´ hÃ¬nh ANN. MÃ´ hÃ¬nh cá»§a mÃ¬nh xÃ¢y dá»±ng gá»“m:\n1model = Sequential() 2 3model.add(LSTM( 4 input_dim=4, 5 output_dim=50, 6 return_sequences=True)) 7model.add(Dropout(0.2)) 8 9model.add(LSTM( 10 100, 11 return_sequences=False)) 12model.add(Dropout(0.2)) 13 14model.add(Dense( 15 output_dim=4)) 16model.add(Activation(\u0026#39;linear\u0026#39;)) 17 18 19 20model.compile(loss=\u0026#39;mean_squared_error\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) 21checkpoint = ModelCheckpoint(filepath=\u0026#39;sp500_stockperdict.h5\u0026#39;, verbose=1, save_best_only=True) 22hist = model.fit(x_train, y_train, epochs=300, batch_size=128, verbose=1, callbacks=[checkpoint], validation_split=0.2) Sau má»™t thá»i gian cháº¡y, mÃ¬nh cÅ©ng thu Ä‘Æ°á»£c model. CÃ¡c báº¡n quan tÃ¢m cÃ³ thá»ƒ download model cá»§a mÃ¬nh huáº¥n luyá»‡n Ä‘Æ°á»£c táº¡i https://drive.google.com/open?id=1ImHQM9yWmOjpF5tjmSI9oqAi5BORa9Rs . Tiáº¿n hÃ nh plot dá»¯ liá»‡u táº­p test lÃªn xem káº¿t quáº£ nhÆ° tháº¿ nÃ o.\n1 2model =load_model(\u0026#39;sp500_stockperdict.h5\u0026#39;) 3 4 5y_hat = model.predict(x_test) 6 7ft = 3 # 0 = open, 1 = highest, 2 =lowest , 3 = close 8 9plt.plot( y_test[:,ft], color=\u0026#39;blue\u0026#39;, label=\u0026#39;target\u0026#39;) 10 11plt.plot( y_hat[:,ft], color=\u0026#39;red\u0026#39;, label=\u0026#39;prediction\u0026#39;) 12 13plt.title(\u0026#39;future stock prices\u0026#39;) 14plt.xlabel(\u0026#39;time [days]\u0026#39;) 15plt.ylabel(\u0026#39;normalized price\u0026#39;) 16plt.legend(loc=\u0026#39;best\u0026#39;) 17 18plt.show() 19 20from sklearn.metrics import mean_squared_error 21 22# 0 = open, 1 = highest, 2 =lowest , 3 = close 23print(\u0026#34;open error: \u0026#34;) 24print(mean_squared_error(y_test[:,0], y_hat[ :,0])) 25 26print(\u0026#34;highest error: \u0026#34;) 27print(mean_squared_error(y_test[:,1], y_hat[ :,1])) 28 29print(\u0026#34;lowest error: \u0026#34;) 30print(mean_squared_error(y_test[:,2], y_hat[ :,2])) 31 32print(\u0026#34;close error: \u0026#34;) 33print(mean_squared_error(y_test[:,3], y_hat[ :,3])) 1open error: 20.0009739211460315127 3highest error: 40.0010539412808401607 5lowest error: 60.0010066509540756113 7close error: 80.0010840500965408758 Hiá»‡n Ä‘Ã£ cÃ³ báº£n tensorflow 2 cÃ³ tÃ­ch há»£p keras, mÃ¬nh update láº¡i code\n1 2from re import T 3import numpy as np 4# linear algebra 5import pandas as pd 6from tensorflow.keras.models import Sequential 7from tensorflow.keras.layers import Dense 8from tensorflow.keras.layers import LSTM 9from sklearn.preprocessing import MinMaxScaler 10import tensorflow as tf 11import joblib 12 13import matplotlib 14matplotlib.use(\u0026#39;TkAgg\u0026#39;) 15import matplotlib.pyplot as plt 16 17 18file_name =\u0026#39;GSPC.csv\u0026#39; 19 20 21prices_dataset = pd.read_csv(file_name, header=0) 22 23 24# prices_dataset_dropout = prices_dataset.drop([\u0026#39;Date\u0026#39;,\u0026#39;Adj Close\u0026#39;,\u0026#39;Volume\u0026#39;], 1) 25prices_dataset_dropout=prices_dataset.reset_index()[\u0026#39;Close\u0026#39;] 26 27 28scaler=MinMaxScaler(feature_range=(0,1)) 29prices_dataset_norm=scaler.fit_transform(np.array(prices_dataset_dropout).reshape(-1,1)) 30joblib.dump(scaler, \u0026#39;scaler.alex\u0026#39;) 31 32 33print(prices_dataset_norm[:10]) 34 35 36def generate_data(stock_ds, seq_len,predict_next_t): 37 dataX, dataY = [], [] 38 for i in range(len(stock_ds)-seq_len-1): 39 dataX.append(stock_ds[i:(i+seq_len)]) 40 dataY.append(stock_ds[i + seq_len+predict_next_t]) 41 return np.array(dataX), np.array(dataY) 42 43#data as numpy array 44def generate_train_test(data_x,data_y,split_percent=0.8): 45 46 train_end = int(np.floor(split_percent*data_x.shape[0])) 47 48 x_train,x_test=data_x[:train_end,:],data_x[train_end:,:] 49 y_train,y_test = data_y[:train_end],data_y[train_end:] 50 return x_train,y_train,x_test,y_test 51 52 53 54seq_len = 100 # choose sequence length 55predict_next_t = 1 # 0 is next date, 1 is 2 next date 56 57data_x, data_y = generate_data(prices_dataset_norm,seq_len,predict_next_t) 58 59x_train,y_train,x_test,y_test = generate_train_test(data_x,data_y, 0.8) 60 61 62x_train =x_train.reshape(x_train.shape[0],x_train.shape[1] , 1) 63x_test = x_test.reshape(x_test.shape[0],x_test.shape[1] , 1) 64print(\u0026#39;x_train.shape = \u0026#39;,x_train.shape) 65print(\u0026#39;y_train.shape = \u0026#39;, y_train.shape) 66print(\u0026#39;x_test.shape = \u0026#39;, x_test.shape) 67print(\u0026#39;y_test.shape = \u0026#39;,y_test.shape) 68 69 70 71model = Sequential() 72 73 # input_dim=4, 74 # output_dim=50, 75model.add(LSTM(units=100,input_shape=x_train.shape[1:], 76 return_sequences=True)) 77 78model.add(LSTM( 79 100, 80 return_sequences=False)) 81model.add(Dense(1)) 82 83 84model.compile(loss=\u0026#39;mean_squared_error\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) 85checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=\u0026#39;my_model_stock.h5\u0026#39;, verbose=1, save_best_only=True) 86hist = model.fit(x_train, y_train, epochs=3, batch_size=64, verbose=1, callbacks=[checkpoint], validation_split=0.2) 87 88from tensorflow.keras.models import load_model 89print(\u0026#39;load model\u0026#39;) 90model =load_model(\u0026#39;my_model_stock.h5\u0026#39;) 91 92print(\u0026#39;predict\u0026#39;) 93y_test = y_test.reshape(y_test.shape[0]) 94# train_predict=model.predict(x_train) 95test_predict=model.predict(x_test) 96print(\u0026#39;invert\u0026#39;) 97print(y_test.shape) 98# train_predict=scaler.inverse_transform(train_predict) 99 100# scaler = joblib.load(\u0026#39;scaler.alex\u0026#39;) 101 102y_hat=scaler.inverse_transform(test_predict) 103y_test=scaler.inverse_transform(y_test.reshape(-1, 1)) 104print(y_hat.shape) 105# y_hat = model.predict(x_test) 106# import matplotlib 107# matplotlib.use(\u0026#39;GTKAgg\u0026#39;) 108# print(\u0026#39;plot\u0026#39;) 109 110plt.plot( y_test, color=\u0026#39;blue\u0026#39;, label=\u0026#39;target\u0026#39;) 111 112plt.plot( y_hat, color=\u0026#39;red\u0026#39;, label=\u0026#39;prediction\u0026#39;) 113print(\u0026#39;plot complete\u0026#39;) 114plt.title(\u0026#39;future stock prices\u0026#39;) 115plt.xlabel(\u0026#39;time [days]\u0026#39;) 116plt.ylabel(\u0026#39;normalized price\u0026#39;) 117plt.legend(loc=\u0026#39;best\u0026#39;) 118print(\u0026#39;plot show\u0026#39;) 119plt.savefig(\u0026#34;mygraph.png\u0026#34;) 120plt.show() Káº¿t quáº£ cá»§a mÃ´ hÃ¬nh trÃ´ng khÃ¡ tá»‘t, vá» hÃ¬nh dáº¡ng thÃ¬ khÃ¡ tÆ°Æ¡ng Ä‘á»“ng vá»›i káº¿t quáº£. ChÃºng ta cÃ³ thá»ƒ cáº£i tiáº¿n model báº±ng cÃ¡ch nÃ¢ng sá»‘ lÆ°á»£ng layer/ hidden node.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Nov 10, 2018","img":"","permalink":"/blog/2018-11-10-stock-prediction_lsmt/","series":null,"tags":["Machine learning","Deeplearning","stock prediction","chá»©ng khoÃ¡n"],"title":"Dá»± ÄoÃ¡n GiÃ¡ Chá»©ng KhoÃ¡n SP500 Sá»­ Dá»¥ng LSTM"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Dáº«n nháº­p PhÃ¢n tÃ­ch dá»¯ liá»‡u PhÃ¢n chia táº­p train vÃ  test. Scale dá»¯ liá»‡u XÃ¢y dá»±ng mÃ´ hÃ¬nh sá»­ dá»¥ng keras Lá»i má»Ÿ Ä‘áº§u á» bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ xÃ¢y dá»±ng mÃ´ hÃ¬nh hÆ¡n giáº£n Ä‘á»ƒ Ã¡p dá»¥ng vÃ o táº­p dá»¯ liá»‡u giÃ¡ chá»©ng khoÃ¡n. Má»¥c tiÃªu cá»§a bÃ i nÃ y lÃ  chÃºng ta sáº½ dá»± Ä‘oÃ¡n chá»‰ sá»‘ S\u0026amp;P 500 dá»±a trÃªn chá»‰ sá»‘ cá»§a 500 mÃ£ chá»©ng khoÃ¡n. CÃ¡c báº¡n cÃ³ nhu cáº§u tÃ¬m hiá»ƒu thÃªm vá» chá»‰ sá»‘ sp 500 cÃ³ thá»ƒ Ä‘á»c thÃªm á»Ÿ https://vi.wikipedia.org/wiki/S%26P_500. ÄÃ¢y lÃ  má»™t á»©ng dá»¥ng nhá», khÃ´ng cÃ³ Ã½ nghÄ©a nhiá»u á»Ÿ thá»±c táº¿ do khi phÃ¢n tÃ­ch chá»©ng khoÃ¡n, ta cÃ²n xÃ©t thÃªm ráº¥t nhiá»u yáº¿u tá»‘ phá»¥ ná»¯a. MÃ´ hÃ¬nh nÃ y thá»±c cháº¥t chá»‰ lÃ  má»™t trong nhá»¯ng mÃ´ hÃ¬nh chÆ¡i chÆ¡i.\nDáº«n nháº­p PhÃ¢n tÃ­ch dá»¯ liá»‡u CÃ¡c báº¡n cÃ³ thá»ƒ download dá»¯ liá»‡u á»Ÿ https://drive.google.com/open?id=1UTlj5Ced-yj6RBRVc6bBM6IWMjfQR3GR.\nÄáº§u tiÃªn, chÃºng ta sáº½ dÃ¹ng pandas Ä‘á»ƒ load mÃ´ hÃ¬nh lÃªn:\n1import pandas as pd 2 3# Import data 4data = pd.read_csv(\u0026#39;data_stocks.csv\u0026#39;) Xem kÃ­ch thÆ°á»›c cá»§a dá»¯ liá»‡u:\n1print(data.shape) 1(41266, 502) Káº¿t quáº£ lÃ  ta cÃ³ hÆ¡n 40 ngÃ n dÃ²ng vÃ  502 cá»™t. Thá»­ show 10 row Ä‘áº§u tiÃªn cá»§a dá»¯ liá»‡u lÃªn xem nhÆ° tháº¿ nÃ o.\n1print(data.head()) 1 DATE SP500 NASDAQ.AAL NASDAQ.AAPL NASDAQ.ADBE NASDAQ.ADI \\ 20 1491226200 2363.6101 42.3300 143.6800 129.6300 82.040 31 1491226260 2364.1001 42.3600 143.7000 130.3200 82.080 42 1491226320 2362.6799 42.3100 143.6901 130.2250 82.030 53 1491226380 2364.3101 42.3700 143.6400 130.0729 82.000 64 1491226440 2364.8501 42.5378 143.6600 129.8800 82.035 7 8 NASDAQ.ADP NASDAQ.ADSK NASDAQ.AKAM NASDAQ.ALXN ... NYSE.WYN \\ 90 102.2300 85.2200 59.760 121.52 ... 84.370 101 102.1400 85.6500 59.840 121.48 ... 84.370 112 102.2125 85.5100 59.795 121.93 ... 84.585 123 102.1400 85.4872 59.620 121.44 ... 84.460 134 102.0600 85.7001 59.620 121.60 ... 84.470 14 15 NYSE.XEC NYSE.XEL NYSE.XL NYSE.XOM NYSE.XRX NYSE.XYL NYSE.YUM \\ 160 119.035 44.40 39.88 82.03 7.36 50.22 63.86 171 119.035 44.11 39.88 82.03 7.38 50.22 63.74 182 119.260 44.09 39.98 82.02 7.36 50.12 63.75 193 119.260 44.25 39.99 82.02 7.35 50.16 63.88 204 119.610 44.11 39.96 82.03 7.36 50.20 63.91 21 22 NYSE.ZBH NYSE.ZTS 230 122.000 53.350 241 121.770 53.350 252 121.700 53.365 263 121.700 53.380 274 121.695 53.240 Cá»™t Ä‘áº§u tiÃªn lÃ  ngÃ y, sau Ä‘Ã³ lÃ  mÃ£ chá»©ng khoÃ¡n. ChÃºng ta cÃ³ tá»•ng cá»™ng 500 mÃ£ chá»©ng khoÃ¡n vÃ  1 chá»‰ sá»‘. Äá»ƒ Ã½ cá»™t Date, ta tháº¥y giÃ¡ trá»‹ Ä‘áº§u tiÃªn lÃ  1491226200, giÃ¡ trá»‹ thá»© 2 lÃ  1491226260, giÃ¡ trá»‹ thá»© 3 lÃ  1491226320, má»—i giÃ¡ trá»‹ cÃ¡ch nhau 60. Chuyá»ƒn Ä‘á»•i sá»‘ 1491226200 sang dáº¡ng datetime thÃ¬ ra giÃ¡ trá»‹ Monday, April 3, 2017 1:30:00 PM giá» GMT, tÆ°Æ¡ng tá»± sá»‘ 1491226260 ra Monday, April 3, 2017 1:31:00 PM giá» GMT. Ta cÃ³ thá»ƒ suy luáº­n ra lÃ  giÃ¡ trá»‹ giao dá»‹ch lÆ°u theo tá»«ng phÃºt má»™t (khoáº£ng interval lÃ  60 giÃ¢y), vÃ  dá»¯ liá»‡u chÃºng ta cÃ³ báº¯t Ä‘áº§u vÃ o 3 thÃ¡ng 4 nÄƒm 2017.\nPlot Ä‘á»“ thá»‹ cá»§a mÃ£ SP500 lÃªn:\n1import matplotlib.pyplot as plt 2 3plt.plot(data[\u0026#39;SP500\u0026#39;]) 4plt.show() 1Notes: á» Ä‘Ã¢y cÃ³ má»™t lÆ°u Ã½ nhá» nhÆ°ng ráº¥t quan trá»ng. ÄÃ³ lÃ  táº¡i thá»i Ä‘iá»ƒm phÃºt thá»© t lÆ°u trá»¯ giÃ¡ trá»‹ sp500 cá»§a thá»i Ä‘iá»ƒm phÃºt thá»© t+1. VÃ­ dá»¥ vá»›i chá»‰ sá»‘ sp500, dÃ²ng Ä‘áº§u tiÃªn ta tháº¥y lÃ  1491226200 2363.6101, nghÄ©a lÃ  giÃ¡ thá»±c táº¿ cá»§a thá»i Ä‘iá»ƒm 1491226260 lÃ  2363.6101. Do bÃ i toÃ¡n cá»§a chÃºng ta lÃ  dá»¯ Ä‘oÃ¡n giÃ¡ tÆ°Æ¡ng láº¡i, nÃªn táº¡i thá»i Ä‘iá»ƒm hiá»‡n táº¡i ta sáº½ dá»± Ä‘oÃ¡n giÃ¡ 1 phÃºt sau sáº½ báº±ng bao nhiÃªu. VÃ  táº­p dá»¯ liá»‡u Ä‘Ã£ tá»± Ä‘á»™ng dá»‹ch chuyá»ƒn giÃ¡ trá»‹ lÃªn 1 phÃºt cho chÃºng ta Ä‘á»¡ máº¥t cÃ´ng lÃ m. CÃ²n giÃ¡ cá»§a 500 cá»— phiáº¿u cÃ²n láº¡i váº«n lÃ  giÃ¡ táº¡i thá»i Ä‘iá»ƒm t PhÃ¢n chia táº­p train vÃ  test. ChÃºng ta sáº½ chia dá»¯ liá»‡u thÃ nh 2 pháº§n vá»›i 80% lÃ  train vÃ  20% cÃ²n láº¡i lÃ  test. Do tÃ­ch cháº¥t cá»§a dá»¯ liá»‡u lÃ  time serial nÃªn chÃºng ta khÃ´ng thá»ƒ lÃ m thay Ä‘á»•i thá»© tá»± dá»¯ liá»‡u.\nChÃºng ta sáº½ bá» Ä‘i cá»™t DATE Ä‘áº§u tiÃªn, vÃ  sau Ä‘Ã³ chuyá»ƒn dá»¯ liá»‡u vá» dáº¡ng numpy array Ä‘á»ƒ dá»… dÃ ng thá»±c hiá»‡n cÃ¡c phÃ©p chuyá»ƒn Ä‘á»•i.\n1data_ = data_raw.drop([\u0026#39;DATE\u0026#39;], 1) 2 3data = data_.values 4# Training and test data 5train_start = 0 6train_end = int(np.floor(0.8*n)) 7test_start = train_end 8test_end = n 9data_train = data[ :train_end] 10data_test = data[train_end:] Scale dá»¯ liá»‡u Khi sá»­ dá»¥ng ANN, chÃºng ta thÃ´ng thÆ°á»ng sáº½ scale dá»¯ liá»‡u input vá» Ä‘oáº¡n [-1,1]. Trong python, thÆ° viá»‡n sklearn Ä‘Ã£ há»— trá»£ cho chÃºng ta sáºµn cÃ¡c hÃ m scale dá»¯ liá»‡u cáº§n thiáº¿t.\n1# Scale data 2from sklearn.preprocessing import MinMaxScaler 3scaler = MinMaxScaler() 4data_train = scaler.fit_transform(data_train) 5data_test = scaler.transform(data_test) 6# Build X and y 7X_train = data_train[:, 1:] 8y_train = data_train[:, 0] 9X_test = data_test[:, 1:] 10y_test = data_test[:, 0] MÃ¬nh cáº§n dá»± Ä‘oÃ¡n giÃ¡ trá»‹ cá»§a chá»‰ sá»‘ sp 500, nÃªn giÃ¡ trá»‹ cá»§a sp500 sáº½ lÃ  cÃ¡i mÃ¬nh cáº§n dá»± Ä‘oÃ¡n, chÃ­nh lÃ  cá»™t Ä‘áº§u tiÃªn, cÃ²n 500 cÃ¡i cÃ²n láº¡i lÃ  input cá»§a mÃ¬nh.\nXÃ¢y dá»±ng mÃ´ hÃ¬nh sá»­ dá»¥ng keras á» Ä‘Ã¢y mÃ¬nh sá»­ dá»¥ng keras xÃ¢y dá»±ng mÃ´ hÃ¬nh ANN. MÃ´ hÃ¬nh cá»§a mÃ¬nh xÃ¢y dá»±ng gá»“m\n1from keras.models import Sequential 2from keras.layers.core import Dense, Dropout, Activation 3from keras.callbacks import ModelCheckpoint 4from keras.optimizers import SGD 5 6import os 7os.environ[\u0026#34;CUDA_DEVICE_ORDER\u0026#34;]=\u0026#34;PCI_BUS_ID\u0026#34; 8# The GPU id to use, usually either \u0026#34;0\u0026#34; or \u0026#34;1\u0026#34; 9os.environ[\u0026#34;CUDA_VISIBLE_DEVICES\u0026#34;]=\u0026#34;0\u0026#34; 10# create model 11model = Sequential() 12model.add(Dense(2048, input_dim=input_dim,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 13model.add(Dense(1024,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 14model.add(Dense(512,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 15model.add(Dense(256,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 16model.add(Dense(128,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 17model.add(Dense(1,kernel_initializer=\u0026#39;normal\u0026#39;)) 18 19 20 21model.compile(loss=\u0026#39;mse\u0026#39;, optimizer=\u0026#39;rmsprop\u0026#39;) 22checkpoint = ModelCheckpoint(filepath=\u0026#39;my_model3.h5\u0026#39;, verbose=1, save_best_only=True) 23model.fit(X_train, y_train, epochs=100, batch_size=256, verbose=1, callbacks=[checkpoint], validation_split=0.2) Sau má»™t thá»i gian cháº¡y, mÃ¬nh cÅ©ng thu Ä‘Æ°á»£c model. CÃ¡c báº¡n quan tÃ¢m cÃ³ thá»ƒ download model cá»§a mÃ¬nh huáº¥n luyá»‡n Ä‘Æ°á»£c táº¡i https://drive.google.com/open?id=1BLQZbcADfnLqzIHlkgpsqZBlhljBp1Eb . Tiáº¿n hÃ nh plot dá»¯ liá»‡u táº­p test lÃªn xem káº¿t quáº£ nhÆ° tháº¿ nÃ o.\n1 2yhat = model.predict(X_test) 3 4 5x = np.arange(len(yhat)) 6 7plt.plot(x, y_test) 8plt.plot(x, yhat) 9plt.legend([\u0026#39;real\u0026#39;, \u0026#39;test\u0026#39;], loc=\u0026#39;upper right\u0026#39;) 10plt.show() 11 12 13from sklearn.metrics import mean_squared_error 14 15print(\u0026#34;mse: \u0026#34;+ str(mean_squared_error(y_test, yhat))) 1mse: 0.0014582120695331884 Káº¿t quáº£ cá»§a mÃ´ hÃ¬nh táº¡m cháº¥p nháº­n Ä‘Æ°á»£c, vá» hÃ¬nh dáº¡ng thÃ¬ khÃ¡ tÆ°Æ¡ng Ä‘á»“ng vá»›i káº¿t quáº£. ChÃºng ta cÃ³ thá»ƒ cáº£i tiáº¿n model báº±ng cÃ¡ch nÃ¢ng sá»‘ lÆ°á»£ng layter/ hidden node, hoáº·c thÃªm dropout. Hoáº·c cÃ³ thá»ƒ thay tháº¿ mÃ´ hÃ¬nh báº±ng RNN. ChÃºng ta sáº½ Ä‘á» cáº­p Ä‘áº¿n mÃ´ hÃ¬nh RNN trong bÃ i viáº¿t sau.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Nov 3, 2018","img":"","permalink":"/blog/2018-11-03-stock-prediction/","series":null,"tags":["Machine learning","Deep learning","stock prediction"],"title":"Dá»± ÄoÃ¡n Chá»©ng KhoÃ¡n Sá»­ Dá»¥ng Tensorflow"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Dáº«n nháº­p Lá»i má»Ÿ Ä‘áº§u Sau khi thá»±c hiá»‡n bÃ i phÃ¢n loáº¡i chÃ³ mÃ¨o báº±ng keras, mÃ¬nh phÃ¡t hiá»‡n ráº±ng keras cÃ³ há»— trá»£ ráº¥t nhiá»u thuáº­t toÃ¡n tá»‘i Æ°u hoÃ¡ https://keras.io/optimizers/. NhÃ¢n dá»‹p rÃ£nh rá»—i, mÃ¬nh sáº½ tá»•ng há»£p láº¡i má»™t vÃ i thuáº­t toÃ¡n mÃ  keras há»— trá»£.\nDáº«n nháº­p Táº¡i thá»i Ä‘iá»ƒm hiá»‡n táº¡i, Gradient descent lÃ  má»™t trong nhá»¯ng thuáº­t toÃ¡n phá»• biáº¿n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tá»‘i Æ°u hoÃ¡ máº¡ng neural networks. CÃ¡c thÆ° viá»‡n DNN sáº½ implement kÃ¨m theo má»™t vÃ i biáº¿n thá»ƒ cá»§a gradient descent giÃºp ngÆ°á»i dÃ¹ng dá»… dÃ ng sá»­ dá»¥ng cÃ´ng cá»¥ hÆ¡n.\nBÃ i viáº¿t nÃ y mÃ¬nh sáº½ cáº­p nháº­t dáº§n Ä‘áº¿n khi hoÃ n thiá»‡n.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Oct 29, 2018","img":"","permalink":"/blog/2018-11-01-overview-of-gradient-descent-optimization-algorithm/","series":null,"tags":["Machine learning","Deeplearning"],"title":"Overview of Gradient Descent Optimization Algorithm"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Thá»±c hiá»‡n Quáº­y phÃ¡ mÃ´ hÃ¬nh Quáº­y phÃ¡ 1: Má»Ÿ Ä‘Ã³ng bÄƒng má»™t sá»‘ lá»›p cuá»‘i vÃ  train trÃªn chÃºng. Quáº­y phÃ¡ 2: Chá»‰ sá»­ dá»¥ng 72 lá»›p Ä‘áº§u tiÃªn cá»§a inception. Lá»i má»Ÿ Ä‘áº§u BÃ i toÃ¡n phÃ¢n loáº¡i chÃ³ mÃ¨o lÃ  bÃ i toÃ¡n khÃ¡ cÅ© táº¡i thá»i Ä‘iá»ƒm hiá»‡n táº¡i. Tuy nhiÃªn, Ä‘á»‘i vá»›i cÃ¡c báº¡n má»›i bÆ°á»›c chÃ¢n vÃ o con Ä‘Æ°á»ng machine learning thÃ¬ Ä‘Ã¢y lÃ  má»™t trong nhá»¯ng bÃ i toÃ¡n cÆ¡ báº£n Ä‘á»ƒ cÃ¡c báº¡n thá»±c hÃ nh sá»­ dá»¥ng vÃ  tÃ¬m hiá»ƒu thÆ° viá»‡n mÃ  mÃ¬nh Ä‘ang cÃ³. á» Ä‘Ã¢y, chÃºng ta sáº½ sá»­ dá»¥ng pretrain model cÃ³ sáºµn cá»§a kares Ã¡p dá»¥ng trÃªn táº­p dá»¯ liá»‡u. CÃ¡c báº¡n cÃ³ thá»ƒ download táº­p dá»¯ liá»‡u train vÃ  test á»Ÿ Ä‘á»‹a chá»‰ https://www.kaggle.com/c/dogs-vs-cats/download/train.zip vÃ  https://www.kaggle.com/c/dogs-vs-cats/download/test1.zip Ä‘á»ƒ báº¯t Ä‘áº§u thá»±c hiá»‡n.\nThá»±c hiá»‡n Sau khi giáº£i nÃ©n dá»¯ liá»‡u, ta tháº¥y ráº±ng thÆ° má»¥c train cÃ³ cáº¥u trÃºc Ä‘áº·t trÃªn sáº½ lÃ  label.sá»‘ thá»© tá»±.jpg. Trong Ä‘Ã³ label cÃ³ thá»ƒ lÃ  dog hoáº·c cat, sá»‘ thá»© tá»± tÄƒng dáº§n tá»« 0 Ä‘áº¿n \u0026hellip;. 12499. Äá»ƒ Ä‘áº£m báº£o Ä‘Ãºng vá»›i mÃ´ hÃ¬nh, ta pháº£i cáº¥u trÃºc láº¡i dá»¯ liá»‡u thÃ nh dáº¡ng.\n1data_dir/classname1/*.* 2data_dir/classname2/*.* 3... VÃ¬ váº­y, ta táº¡o ra thÆ° má»¥c cat vÃ  copy nhá»¯ng file báº¯t Ä‘áº§u báº±ng cat.* vÃ o thÆ° má»¥c cat. LÃ m tÆ°Æ¡ng tá»± vá»›i thÆ° má»¥c dog.\nÄáº§u tiÃªn, cÃ¡c báº¡n download file pretrain model, giáº£i nÃ©n ra vÃ  Ä‘á»ƒ á»Ÿ Ä‘Ã¢u Ä‘Ã³ trong á»• cá»©ng cá»§a mÃ¡y báº¡n. ÄÆ°á»ng dáº«n file pretrain model cÃ¡c báº¡n cÃ³ thá»ƒ download á»Ÿ http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz. CÃ¡c báº¡n cÃ³ thá»ƒ download cÃ¡c file pretrain khÃ¡c náº¿u cÃ³ há»©ng thÃº tÃ¬m hiá»ƒu.\nTiáº¿p theo, chÃºng ta sáº½ load dataset lÃªn vÃ  tranform nÃ³ Ä‘á»ƒ Ä‘Æ°a vÃ o huáº¥n luyá»‡n.\n1import sys 2import os 3from collections import defaultdict 4import numpy as np 5import scipy.misc 6 7 8def preprocess_input(x0): 9 x = x0 / 255. 10 x -= 0.5 11 x *= 2. 12 return x 13 14 15def reverse_preprocess_input(x0): 16 x = x0 / 2.0 17 x += 0.5 18 x *= 255. 19 return x 20 21 22def dataset(base_dir, n): 23 print(\u0026#34;base dir: \u0026#34;+base_dir) 24 print(\u0026#34;n: \u0026#34;+str(n)) 25 n = int(n) 26 d = defaultdict(list) 27 for root, subdirs, files in os.walk(base_dir): 28 for filename in files: 29 file_path = os.path.join(root, filename) 30 assert file_path.startswith(base_dir) 31 32 suffix = file_path[len(base_dir):] 33 34 suffix = suffix.lstrip(\u0026#34;/\u0026#34;) 35 suffix = suffix.lstrip(\u0026#34;\\\\\u0026#34;) 36 if(suffix.find(\u0026#39;/\u0026#39;)\u0026gt;-1): #linux 37 label = suffix.split(\u0026#34;/\u0026#34;)[0] 38 else: #window 39 label = suffix.split(\u0026#34;\\\\\u0026#34;)[0] 40 d[label].append(file_path) 41 print(\u0026#34;walk directory complete\u0026#34;) 42 tags = sorted(d.keys()) 43 44 processed_image_count = 0 45 useful_image_count = 0 46 47 X = [] 48 y = [] 49 50 for class_index, class_name in enumerate(tags): 51 filenames = d[class_name] 52 for filename in filenames: 53 processed_image_count += 1 54 if processed_image_count%100 ==0: 55 print(class_name+\u0026#34;\\tprocess: \u0026#34;+str(processed_image_count)+\u0026#34;\\t\u0026#34;+str(len(d[class_name]))) 56 img = scipy.misc.imread(filename) 57 height, width, chan = img.shape 58 assert chan == 3 59 aspect_ratio = float(max((height, width))) / min((height, width)) 60 if aspect_ratio \u0026gt; 2: 61 continue 62 # We pick the largest center square. 63 centery = height // 2 64 centerx = width // 2 65 radius = min((centerx, centery)) 66 img = img[centery-radius:centery+radius, centerx-radius:centerx+radius] 67 img = scipy.misc.imresize(img, size=(n, n), interp=\u0026#39;bilinear\u0026#39;) 68 X.append(img) 69 y.append(class_index) 70 useful_image_count += 1 71 print(\u0026#34;processed %d, used %d\u0026#34; % (processed_image_count, useful_image_count)) 72 73 X = np.array(X).astype(np.float32) 74 #X = X.transpose((0, 3, 1, 2)) 75 X = preprocess_input(X) 76 y = np.array(y) 77 78 perm = np.random.permutation(len(y)) 79 X = X[perm] 80 y = y[perm] 81 82 print(\u0026#34;classes:\u0026#34;,end=\u0026#34; \u0026#34;) 83 for class_index, class_name in enumerate(tags): 84 print(class_name, sum(y==class_index),end=\u0026#34; \u0026#34;) 85 print(\u0026#34;X shape: \u0026#34;,X.shape) 86 87 return X, y, tags Äoáº¡n code trÃªn khÃ¡ Ä‘Æ¡n giáº£n vÃ  dá»… hiá»ƒu. LÆ°u Ã½ á»Ÿ Ä‘Ã¢y lÃ  vá»›i nhá»¯ng bá»©c áº£nh cÃ³ tá»· lá»‡ width vÃ  height \u0026gt; 2 thÃ¬ mÃ¬nh sáº½ loáº¡i chÃºng ra khá»i táº­p dá»¯ liá»‡u.\nTiáº¿p theo, chÃºng ta sáº½ xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»±a trÃªn mÃ´ hÃ¬nh InceptionV3 cÃ³ sáºµn, thÃªm má»™t lá»›p softmax á»Ÿ cuá»‘i Ä‘á»ƒ phÃ¢n lá»›p dá»¯ liá»‡u, chÃºng ta sáº½ huáº¥n luyá»‡n lá»›p softmax nÃ y. CÃ¡c lá»›p trÆ°á»›c lá»›p softmax nÃ y sáº½ bá»‹ Ä‘Ã³ng bÄƒng (khÃ´ng cáº­p nháº­t trá»ng sá»‘ trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n ).\n1 2# create the base pre-trained model 3def build_model(nb_classes): 4 base_model = InceptionV3(weights=\u0026#39;imagenet\u0026#39;, include_top=False) 5 6 # add a global spatial average pooling layer 7 x = base_model.output 8 x = GlobalAveragePooling2D()(x) 9 # let\u0026#39;s add a fully-connected layer 10 x = Dense(1024, activation=\u0026#39;relu\u0026#39;)(x) 11 # and a logistic layer 12 predictions = Dense(nb_classes, activation=\u0026#39;softmax\u0026#39;)(x) 13 14 # this is the model we will train 15 model = Model(inputs=base_model.input, outputs=predictions) 16 17 # first: train only the top layers (which were randomly initialized) 18 # i.e. freeze all convolutional InceptionV3 layers 19 for layer in base_model.layers: 20 layer.trainable = False 21 22 # compile the model (should be done *after* setting layers to non-trainable) 23 print(\u0026#34;starting model compile\u0026#34;) 24 compile(model) 25 print(\u0026#34;model compile done\u0026#34;) 26 return model Visualize má»™t chÃºt xÃ­u vá» kiáº¿n trÃºc inceptionV3 mÃ¬nh Ä‘ang dÃ¹ng.\n1__________________________________________________________________________________________________ 2Layer (type) Output Shape Param # Connected to 3================================================================================================== 4input_1 (InputLayer) (None, None, None, 3 0 5__________________________________________________________________________________________________ 6conv2d_1 (Conv2D) (None, None, None, 3 864 input_1[0][0] 7__________________________________________________________________________________________________ 8batch_normalization_1 (BatchNor (None, None, None, 3 96 conv2d_1[0][0] 9__________________________________________________________________________________________________ 10activation_1 (Activation) (None, None, None, 3 0 batch_normalization_1[0][0] 11__________________________________________________________________________________________________ 12conv2d_2 (Conv2D) (None, None, None, 3 9216 activation_1[0][0] 13__________________________________________________________________________________________________ 14batch_normalization_2 (BatchNor (None, None, None, 3 96 conv2d_2[0][0] 15__________________________________________________________________________________________________ 16activation_2 (Activation) (None, None, None, 3 0 batch_normalization_2[0][0] 17__________________________________________________________________________________________________ 18conv2d_3 (Conv2D) (None, None, None, 6 18432 activation_2[0][0] 19__________________________________________________________________________________________________ 20batch_normalization_3 (BatchNor (None, None, None, 6 192 conv2d_3[0][0] 21__________________________________________________________________________________________________ 22activation_3 (Activation) (None, None, None, 6 0 batch_normalization_3[0][0] 23__________________________________________________________________________________________________ 24max_pooling2d_1 (MaxPooling2D) (None, None, None, 6 0 activation_3[0][0] 25__________________________________________________________________________________________________ 26conv2d_4 (Conv2D) (None, None, None, 8 5120 max_pooling2d_1[0][0] 27__________________________________________________________________________________________________ 28batch_normalization_4 (BatchNor (None, None, None, 8 240 conv2d_4[0][0] 29__________________________________________________________________________________________________ 30activation_4 (Activation) (None, None, None, 8 0 batch_normalization_4[0][0] 31__________________________________________________________________________________________________ 32conv2d_5 (Conv2D) (None, None, None, 1 138240 activation_4[0][0] 33__________________________________________________________________________________________________ 34batch_normalization_5 (BatchNor (None, None, None, 1 576 conv2d_5[0][0] 35__________________________________________________________________________________________________ 36activation_5 (Activation) (None, None, None, 1 0 batch_normalization_5[0][0] 37__________________________________________________________________________________________________ 38max_pooling2d_2 (MaxPooling2D) (None, None, None, 1 0 activation_5[0][0] 39__________________________________________________________________________________________________ 40conv2d_9 (Conv2D) (None, None, None, 6 12288 max_pooling2d_2[0][0] 41__________________________________________________________________________________________________ 42batch_normalization_9 (BatchNor (None, None, None, 6 192 conv2d_9[0][0] 43__________________________________________________________________________________________________ 44activation_9 (Activation) (None, None, None, 6 0 batch_normalization_9[0][0] 45__________________________________________________________________________________________________ 46conv2d_7 (Conv2D) (None, None, None, 4 9216 max_pooling2d_2[0][0] 47__________________________________________________________________________________________________ 48conv2d_10 (Conv2D) (None, None, None, 9 55296 activation_9[0][0] 49__________________________________________________________________________________________________ 50batch_normalization_7 (BatchNor (None, None, None, 4 144 conv2d_7[0][0] 51__________________________________________________________________________________________________ 52batch_normalization_10 (BatchNo (None, None, None, 9 288 conv2d_10[0][0] 53__________________________________________________________________________________________________ 54activation_7 (Activation) (None, None, None, 4 0 batch_normalization_7[0][0] 55__________________________________________________________________________________________________ 56activation_10 (Activation) (None, None, None, 9 0 batch_normalization_10[0][0] 57__________________________________________________________________________________________________ 58average_pooling2d_1 (AveragePoo (None, None, None, 1 0 max_pooling2d_2[0][0] 59__________________________________________________________________________________________________ 60conv2d_6 (Conv2D) (None, None, None, 6 12288 max_pooling2d_2[0][0] 61__________________________________________________________________________________________________ 62conv2d_8 (Conv2D) (None, None, None, 6 76800 activation_7[0][0] 63__________________________________________________________________________________________________ 64conv2d_11 (Conv2D) (None, None, None, 9 82944 activation_10[0][0] 65__________________________________________________________________________________________________ 66conv2d_12 (Conv2D) (None, None, None, 3 6144 average_pooling2d_1[0][0] 67__________________________________________________________________________________________________ 68batch_normalization_6 (BatchNor (None, None, None, 6 192 conv2d_6[0][0] 69__________________________________________________________________________________________________ 70batch_normalization_8 (BatchNor (None, None, None, 6 192 conv2d_8[0][0] 71__________________________________________________________________________________________________ 72batch_normalization_11 (BatchNo (None, None, None, 9 288 conv2d_11[0][0] 73__________________________________________________________________________________________________ 74batch_normalization_12 (BatchNo (None, None, None, 3 96 conv2d_12[0][0] 75__________________________________________________________________________________________________ 76activation_6 (Activation) (None, None, None, 6 0 batch_normalization_6[0][0] 77__________________________________________________________________________________________________ 78activation_8 (Activation) (None, None, None, 6 0 batch_normalization_8[0][0] 79__________________________________________________________________________________________________ 80activation_11 (Activation) (None, None, None, 9 0 batch_normalization_11[0][0] 81__________________________________________________________________________________________________ 82activation_12 (Activation) (None, None, None, 3 0 batch_normalization_12[0][0] 83__________________________________________________________________________________________________ 84mixed0 (Concatenate) (None, None, None, 2 0 activation_6[0][0] 85 activation_8[0][0] 86 activation_11[0][0] 87 activation_12[0][0] 88__________________________________________________________________________________________________ 89conv2d_16 (Conv2D) (None, None, None, 6 16384 mixed0[0][0] 90__________________________________________________________________________________________________ 91batch_normalization_16 (BatchNo (None, None, None, 6 192 conv2d_16[0][0] 92__________________________________________________________________________________________________ 93activation_16 (Activation) (None, None, None, 6 0 batch_normalization_16[0][0] 94__________________________________________________________________________________________________ 95conv2d_14 (Conv2D) (None, None, None, 4 12288 mixed0[0][0] 96__________________________________________________________________________________________________ 97conv2d_17 (Conv2D) (None, None, None, 9 55296 activation_16[0][0] 98__________________________________________________________________________________________________ 99batch_normalization_14 (BatchNo (None, None, None, 4 144 conv2d_14[0][0] 100__________________________________________________________________________________________________ 101batch_normalization_17 (BatchNo (None, None, None, 9 288 conv2d_17[0][0] 102__________________________________________________________________________________________________ 103activation_14 (Activation) (None, None, None, 4 0 batch_normalization_14[0][0] 104__________________________________________________________________________________________________ 105activation_17 (Activation) (None, None, None, 9 0 batch_normalization_17[0][0] 106__________________________________________________________________________________________________ 107average_pooling2d_2 (AveragePoo (None, None, None, 2 0 mixed0[0][0] 108__________________________________________________________________________________________________ 109conv2d_13 (Conv2D) (None, None, None, 6 16384 mixed0[0][0] 110__________________________________________________________________________________________________ 111conv2d_15 (Conv2D) (None, None, None, 6 76800 activation_14[0][0] 112__________________________________________________________________________________________________ 113conv2d_18 (Conv2D) (None, None, None, 9 82944 activation_17[0][0] 114__________________________________________________________________________________________________ 115conv2d_19 (Conv2D) (None, None, None, 6 16384 average_pooling2d_2[0][0] 116__________________________________________________________________________________________________ 117batch_normalization_13 (BatchNo (None, None, None, 6 192 conv2d_13[0][0] 118__________________________________________________________________________________________________ 119batch_normalization_15 (BatchNo (None, None, None, 6 192 conv2d_15[0][0] 120__________________________________________________________________________________________________ 121batch_normalization_18 (BatchNo (None, None, None, 9 288 conv2d_18[0][0] 122__________________________________________________________________________________________________ 123batch_normalization_19 (BatchNo (None, None, None, 6 192 conv2d_19[0][0] 124__________________________________________________________________________________________________ 125activation_13 (Activation) (None, None, None, 6 0 batch_normalization_13[0][0] 126__________________________________________________________________________________________________ 127activation_15 (Activation) (None, None, None, 6 0 batch_normalization_15[0][0] 128__________________________________________________________________________________________________ 129activation_18 (Activation) (None, None, None, 9 0 batch_normalization_18[0][0] 130__________________________________________________________________________________________________ 131activation_19 (Activation) (None, None, None, 6 0 batch_normalization_19[0][0] 132__________________________________________________________________________________________________ 133mixed1 (Concatenate) (None, None, None, 2 0 activation_13[0][0] 134 activation_15[0][0] 135 activation_18[0][0] 136 activation_19[0][0] 137__________________________________________________________________________________________________ 138conv2d_23 (Conv2D) (None, None, None, 6 18432 mixed1[0][0] 139__________________________________________________________________________________________________ 140batch_normalization_23 (BatchNo (None, None, None, 6 192 conv2d_23[0][0] 141__________________________________________________________________________________________________ 142activation_23 (Activation) (None, None, None, 6 0 batch_normalization_23[0][0] 143__________________________________________________________________________________________________ 144conv2d_21 (Conv2D) (None, None, None, 4 13824 mixed1[0][0] 145__________________________________________________________________________________________________ 146conv2d_24 (Conv2D) (None, None, None, 9 55296 activation_23[0][0] 147__________________________________________________________________________________________________ 148batch_normalization_21 (BatchNo (None, None, None, 4 144 conv2d_21[0][0] 149__________________________________________________________________________________________________ 150batch_normalization_24 (BatchNo (None, None, None, 9 288 conv2d_24[0][0] 151__________________________________________________________________________________________________ 152activation_21 (Activation) (None, None, None, 4 0 batch_normalization_21[0][0] 153__________________________________________________________________________________________________ 154activation_24 (Activation) (None, None, None, 9 0 batch_normalization_24[0][0] 155__________________________________________________________________________________________________ 156average_pooling2d_3 (AveragePoo (None, None, None, 2 0 mixed1[0][0] 157__________________________________________________________________________________________________ 158conv2d_20 (Conv2D) (None, None, None, 6 18432 mixed1[0][0] 159__________________________________________________________________________________________________ 160conv2d_22 (Conv2D) (None, None, None, 6 76800 activation_21[0][0] 161__________________________________________________________________________________________________ 162conv2d_25 (Conv2D) (None, None, None, 9 82944 activation_24[0][0] 163__________________________________________________________________________________________________ 164conv2d_26 (Conv2D) (None, None, None, 6 18432 average_pooling2d_3[0][0] 165__________________________________________________________________________________________________ 166batch_normalization_20 (BatchNo (None, None, None, 6 192 conv2d_20[0][0] 167__________________________________________________________________________________________________ 168batch_normalization_22 (BatchNo (None, None, None, 6 192 conv2d_22[0][0] 169__________________________________________________________________________________________________ 170batch_normalization_25 (BatchNo (None, None, None, 9 288 conv2d_25[0][0] 171__________________________________________________________________________________________________ 172batch_normalization_26 (BatchNo (None, None, None, 6 192 conv2d_26[0][0] 173__________________________________________________________________________________________________ 174activation_20 (Activation) (None, None, None, 6 0 batch_normalization_20[0][0] 175__________________________________________________________________________________________________ 176activation_22 (Activation) (None, None, None, 6 0 batch_normalization_22[0][0] 177__________________________________________________________________________________________________ 178activation_25 (Activation) (None, None, None, 9 0 batch_normalization_25[0][0] 179__________________________________________________________________________________________________ 180activation_26 (Activation) (None, None, None, 6 0 batch_normalization_26[0][0] 181__________________________________________________________________________________________________ 182mixed2 (Concatenate) (None, None, None, 2 0 activation_20[0][0] 183 activation_22[0][0] 184 activation_25[0][0] 185 activation_26[0][0] 186__________________________________________________________________________________________________ 187conv2d_28 (Conv2D) (None, None, None, 6 18432 mixed2[0][0] 188__________________________________________________________________________________________________ 189batch_normalization_28 (BatchNo (None, None, None, 6 192 conv2d_28[0][0] 190__________________________________________________________________________________________________ 191activation_28 (Activation) (None, None, None, 6 0 batch_normalization_28[0][0] 192__________________________________________________________________________________________________ 193conv2d_29 (Conv2D) (None, None, None, 9 55296 activation_28[0][0] 194__________________________________________________________________________________________________ 195batch_normalization_29 (BatchNo (None, None, None, 9 288 conv2d_29[0][0] 196__________________________________________________________________________________________________ 197activation_29 (Activation) (None, None, None, 9 0 batch_normalization_29[0][0] 198__________________________________________________________________________________________________ 199conv2d_27 (Conv2D) (None, None, None, 3 995328 mixed2[0][0] 200__________________________________________________________________________________________________ 201conv2d_30 (Conv2D) (None, None, None, 9 82944 activation_29[0][0] 202__________________________________________________________________________________________________ 203batch_normalization_27 (BatchNo (None, None, None, 3 1152 conv2d_27[0][0] 204__________________________________________________________________________________________________ 205batch_normalization_30 (BatchNo (None, None, None, 9 288 conv2d_30[0][0] 206__________________________________________________________________________________________________ 207activation_27 (Activation) (None, None, None, 3 0 batch_normalization_27[0][0] 208__________________________________________________________________________________________________ 209activation_30 (Activation) (None, None, None, 9 0 batch_normalization_30[0][0] 210__________________________________________________________________________________________________ 211max_pooling2d_3 (MaxPooling2D) (None, None, None, 2 0 mixed2[0][0] 212__________________________________________________________________________________________________ 213mixed3 (Concatenate) (None, None, None, 7 0 activation_27[0][0] 214 activation_30[0][0] 215 max_pooling2d_3[0][0] 216__________________________________________________________________________________________________ 217conv2d_35 (Conv2D) (None, None, None, 1 98304 mixed3[0][0] 218__________________________________________________________________________________________________ 219batch_normalization_35 (BatchNo (None, None, None, 1 384 conv2d_35[0][0] 220__________________________________________________________________________________________________ 221activation_35 (Activation) (None, None, None, 1 0 batch_normalization_35[0][0] 222__________________________________________________________________________________________________ 223conv2d_36 (Conv2D) (None, None, None, 1 114688 activation_35[0][0] 224__________________________________________________________________________________________________ 225batch_normalization_36 (BatchNo (None, None, None, 1 384 conv2d_36[0][0] 226__________________________________________________________________________________________________ 227activation_36 (Activation) (None, None, None, 1 0 batch_normalization_36[0][0] 228__________________________________________________________________________________________________ 229conv2d_32 (Conv2D) (None, None, None, 1 98304 mixed3[0][0] 230__________________________________________________________________________________________________ 231conv2d_37 (Conv2D) (None, None, None, 1 114688 activation_36[0][0] 232__________________________________________________________________________________________________ 233batch_normalization_32 (BatchNo (None, None, None, 1 384 conv2d_32[0][0] 234__________________________________________________________________________________________________ 235batch_normalization_37 (BatchNo (None, None, None, 1 384 conv2d_37[0][0] 236__________________________________________________________________________________________________ 237activation_32 (Activation) (None, None, None, 1 0 batch_normalization_32[0][0] 238__________________________________________________________________________________________________ 239activation_37 (Activation) (None, None, None, 1 0 batch_normalization_37[0][0] 240__________________________________________________________________________________________________ 241conv2d_33 (Conv2D) (None, None, None, 1 114688 activation_32[0][0] 242__________________________________________________________________________________________________ 243conv2d_38 (Conv2D) (None, None, None, 1 114688 activation_37[0][0] 244__________________________________________________________________________________________________ 245batch_normalization_33 (BatchNo (None, None, None, 1 384 conv2d_33[0][0] 246__________________________________________________________________________________________________ 247batch_normalization_38 (BatchNo (None, None, None, 1 384 conv2d_38[0][0] 248__________________________________________________________________________________________________ 249activation_33 (Activation) (None, None, None, 1 0 batch_normalization_33[0][0] 250__________________________________________________________________________________________________ 251activation_38 (Activation) (None, None, None, 1 0 batch_normalization_38[0][0] 252__________________________________________________________________________________________________ 253average_pooling2d_4 (AveragePoo (None, None, None, 7 0 mixed3[0][0] 254__________________________________________________________________________________________________ 255conv2d_31 (Conv2D) (None, None, None, 1 147456 mixed3[0][0] 256__________________________________________________________________________________________________ 257conv2d_34 (Conv2D) (None, None, None, 1 172032 activation_33[0][0] 258__________________________________________________________________________________________________ 259conv2d_39 (Conv2D) (None, None, None, 1 172032 activation_38[0][0] 260__________________________________________________________________________________________________ 261conv2d_40 (Conv2D) (None, None, None, 1 147456 average_pooling2d_4[0][0] 262__________________________________________________________________________________________________ 263batch_normalization_31 (BatchNo (None, None, None, 1 576 conv2d_31[0][0] 264__________________________________________________________________________________________________ 265batch_normalization_34 (BatchNo (None, None, None, 1 576 conv2d_34[0][0] 266__________________________________________________________________________________________________ 267batch_normalization_39 (BatchNo (None, None, None, 1 576 conv2d_39[0][0] 268__________________________________________________________________________________________________ 269batch_normalization_40 (BatchNo (None, None, None, 1 576 conv2d_40[0][0] 270__________________________________________________________________________________________________ 271activation_31 (Activation) (None, None, None, 1 0 batch_normalization_31[0][0] 272__________________________________________________________________________________________________ 273activation_34 (Activation) (None, None, None, 1 0 batch_normalization_34[0][0] 274__________________________________________________________________________________________________ 275activation_39 (Activation) (None, None, None, 1 0 batch_normalization_39[0][0] 276__________________________________________________________________________________________________ 277activation_40 (Activation) (None, None, None, 1 0 batch_normalization_40[0][0] 278__________________________________________________________________________________________________ 279mixed4 (Concatenate) (None, None, None, 7 0 activation_31[0][0] 280 activation_34[0][0] 281 activation_39[0][0] 282 activation_40[0][0] 283__________________________________________________________________________________________________ 284conv2d_45 (Conv2D) (None, None, None, 1 122880 mixed4[0][0] 285__________________________________________________________________________________________________ 286batch_normalization_45 (BatchNo (None, None, None, 1 480 conv2d_45[0][0] 287__________________________________________________________________________________________________ 288activation_45 (Activation) (None, None, None, 1 0 batch_normalization_45[0][0] 289__________________________________________________________________________________________________ 290conv2d_46 (Conv2D) (None, None, None, 1 179200 activation_45[0][0] 291__________________________________________________________________________________________________ 292batch_normalization_46 (BatchNo (None, None, None, 1 480 conv2d_46[0][0] 293__________________________________________________________________________________________________ 294activation_46 (Activation) (None, None, None, 1 0 batch_normalization_46[0][0] 295__________________________________________________________________________________________________ 296conv2d_42 (Conv2D) (None, None, None, 1 122880 mixed4[0][0] 297__________________________________________________________________________________________________ 298conv2d_47 (Conv2D) (None, None, None, 1 179200 activation_46[0][0] 299__________________________________________________________________________________________________ 300batch_normalization_42 (BatchNo (None, None, None, 1 480 conv2d_42[0][0] 301__________________________________________________________________________________________________ 302batch_normalization_47 (BatchNo (None, None, None, 1 480 conv2d_47[0][0] 303__________________________________________________________________________________________________ 304activation_42 (Activation) (None, None, None, 1 0 batch_normalization_42[0][0] 305__________________________________________________________________________________________________ 306activation_47 (Activation) (None, None, None, 1 0 batch_normalization_47[0][0] 307__________________________________________________________________________________________________ 308conv2d_43 (Conv2D) (None, None, None, 1 179200 activation_42[0][0] 309__________________________________________________________________________________________________ 310conv2d_48 (Conv2D) (None, None, None, 1 179200 activation_47[0][0] 311__________________________________________________________________________________________________ 312batch_normalization_43 (BatchNo (None, None, None, 1 480 conv2d_43[0][0] 313__________________________________________________________________________________________________ 314batch_normalization_48 (BatchNo (None, None, None, 1 480 conv2d_48[0][0] 315__________________________________________________________________________________________________ 316activation_43 (Activation) (None, None, None, 1 0 batch_normalization_43[0][0] 317__________________________________________________________________________________________________ 318activation_48 (Activation) (None, None, None, 1 0 batch_normalization_48[0][0] 319__________________________________________________________________________________________________ 320average_pooling2d_5 (AveragePoo (None, None, None, 7 0 mixed4[0][0] 321__________________________________________________________________________________________________ 322conv2d_41 (Conv2D) (None, None, None, 1 147456 mixed4[0][0] 323__________________________________________________________________________________________________ 324conv2d_44 (Conv2D) (None, None, None, 1 215040 activation_43[0][0] 325__________________________________________________________________________________________________ 326conv2d_49 (Conv2D) (None, None, None, 1 215040 activation_48[0][0] 327__________________________________________________________________________________________________ 328conv2d_50 (Conv2D) (None, None, None, 1 147456 average_pooling2d_5[0][0] 329__________________________________________________________________________________________________ 330batch_normalization_41 (BatchNo (None, None, None, 1 576 conv2d_41[0][0] 331__________________________________________________________________________________________________ 332batch_normalization_44 (BatchNo (None, None, None, 1 576 conv2d_44[0][0] 333__________________________________________________________________________________________________ 334batch_normalization_49 (BatchNo (None, None, None, 1 576 conv2d_49[0][0] 335__________________________________________________________________________________________________ 336batch_normalization_50 (BatchNo (None, None, None, 1 576 conv2d_50[0][0] 337__________________________________________________________________________________________________ 338activation_41 (Activation) (None, None, None, 1 0 batch_normalization_41[0][0] 339__________________________________________________________________________________________________ 340activation_44 (Activation) (None, None, None, 1 0 batch_normalization_44[0][0] 341__________________________________________________________________________________________________ 342activation_49 (Activation) (None, None, None, 1 0 batch_normalization_49[0][0] 343__________________________________________________________________________________________________ 344activation_50 (Activation) (None, None, None, 1 0 batch_normalization_50[0][0] 345__________________________________________________________________________________________________ 346mixed5 (Concatenate) (None, None, None, 7 0 activation_41[0][0] 347 activation_44[0][0] 348 activation_49[0][0] 349 activation_50[0][0] 350__________________________________________________________________________________________________ 351conv2d_55 (Conv2D) (None, None, None, 1 122880 mixed5[0][0] 352__________________________________________________________________________________________________ 353batch_normalization_55 (BatchNo (None, None, None, 1 480 conv2d_55[0][0] 354__________________________________________________________________________________________________ 355activation_55 (Activation) (None, None, None, 1 0 batch_normalization_55[0][0] 356__________________________________________________________________________________________________ 357conv2d_56 (Conv2D) (None, None, None, 1 179200 activation_55[0][0] 358__________________________________________________________________________________________________ 359batch_normalization_56 (BatchNo (None, None, None, 1 480 conv2d_56[0][0] 360__________________________________________________________________________________________________ 361activation_56 (Activation) (None, None, None, 1 0 batch_normalization_56[0][0] 362__________________________________________________________________________________________________ 363conv2d_52 (Conv2D) (None, None, None, 1 122880 mixed5[0][0] 364__________________________________________________________________________________________________ 365conv2d_57 (Conv2D) (None, None, None, 1 179200 activation_56[0][0] 366__________________________________________________________________________________________________ 367batch_normalization_52 (BatchNo (None, None, None, 1 480 conv2d_52[0][0] 368__________________________________________________________________________________________________ 369batch_normalization_57 (BatchNo (None, None, None, 1 480 conv2d_57[0][0] 370__________________________________________________________________________________________________ 371activation_52 (Activation) (None, None, None, 1 0 batch_normalization_52[0][0] 372__________________________________________________________________________________________________ 373activation_57 (Activation) (None, None, None, 1 0 batch_normalization_57[0][0] 374__________________________________________________________________________________________________ 375conv2d_53 (Conv2D) (None, None, None, 1 179200 activation_52[0][0] 376__________________________________________________________________________________________________ 377conv2d_58 (Conv2D) (None, None, None, 1 179200 activation_57[0][0] 378__________________________________________________________________________________________________ 379batch_normalization_53 (BatchNo (None, None, None, 1 480 conv2d_53[0][0] 380__________________________________________________________________________________________________ 381batch_normalization_58 (BatchNo (None, None, None, 1 480 conv2d_58[0][0] 382__________________________________________________________________________________________________ 383activation_53 (Activation) (None, None, None, 1 0 batch_normalization_53[0][0] 384__________________________________________________________________________________________________ 385activation_58 (Activation) (None, None, None, 1 0 batch_normalization_58[0][0] 386__________________________________________________________________________________________________ 387average_pooling2d_6 (AveragePoo (None, None, None, 7 0 mixed5[0][0] 388__________________________________________________________________________________________________ 389conv2d_51 (Conv2D) (None, None, None, 1 147456 mixed5[0][0] 390__________________________________________________________________________________________________ 391conv2d_54 (Conv2D) (None, None, None, 1 215040 activation_53[0][0] 392__________________________________________________________________________________________________ 393conv2d_59 (Conv2D) (None, None, None, 1 215040 activation_58[0][0] 394__________________________________________________________________________________________________ 395conv2d_60 (Conv2D) (None, None, None, 1 147456 average_pooling2d_6[0][0] 396__________________________________________________________________________________________________ 397batch_normalization_51 (BatchNo (None, None, None, 1 576 conv2d_51[0][0] 398__________________________________________________________________________________________________ 399batch_normalization_54 (BatchNo (None, None, None, 1 576 conv2d_54[0][0] 400__________________________________________________________________________________________________ 401batch_normalization_59 (BatchNo (None, None, None, 1 576 conv2d_59[0][0] 402__________________________________________________________________________________________________ 403batch_normalization_60 (BatchNo (None, None, None, 1 576 conv2d_60[0][0] 404__________________________________________________________________________________________________ 405activation_51 (Activation) (None, None, None, 1 0 batch_normalization_51[0][0] 406__________________________________________________________________________________________________ 407activation_54 (Activation) (None, None, None, 1 0 batch_normalization_54[0][0] 408__________________________________________________________________________________________________ 409activation_59 (Activation) (None, None, None, 1 0 batch_normalization_59[0][0] 410__________________________________________________________________________________________________ 411activation_60 (Activation) (None, None, None, 1 0 batch_normalization_60[0][0] 412__________________________________________________________________________________________________ 413mixed6 (Concatenate) (None, None, None, 7 0 activation_51[0][0] 414 activation_54[0][0] 415 activation_59[0][0] 416 activation_60[0][0] 417__________________________________________________________________________________________________ 418conv2d_65 (Conv2D) (None, None, None, 1 147456 mixed6[0][0] 419__________________________________________________________________________________________________ 420batch_normalization_65 (BatchNo (None, None, None, 1 576 conv2d_65[0][0] 421__________________________________________________________________________________________________ 422activation_65 (Activation) (None, None, None, 1 0 batch_normalization_65[0][0] 423__________________________________________________________________________________________________ 424conv2d_66 (Conv2D) (None, None, None, 1 258048 activation_65[0][0] 425__________________________________________________________________________________________________ 426batch_normalization_66 (BatchNo (None, None, None, 1 576 conv2d_66[0][0] 427__________________________________________________________________________________________________ 428activation_66 (Activation) (None, None, None, 1 0 batch_normalization_66[0][0] 429__________________________________________________________________________________________________ 430conv2d_62 (Conv2D) (None, None, None, 1 147456 mixed6[0][0] 431__________________________________________________________________________________________________ 432conv2d_67 (Conv2D) (None, None, None, 1 258048 activation_66[0][0] 433__________________________________________________________________________________________________ 434batch_normalization_62 (BatchNo (None, None, None, 1 576 conv2d_62[0][0] 435__________________________________________________________________________________________________ 436batch_normalization_67 (BatchNo (None, None, None, 1 576 conv2d_67[0][0] 437__________________________________________________________________________________________________ 438activation_62 (Activation) (None, None, None, 1 0 batch_normalization_62[0][0] 439__________________________________________________________________________________________________ 440activation_67 (Activation) (None, None, None, 1 0 batch_normalization_67[0][0] 441__________________________________________________________________________________________________ 442conv2d_63 (Conv2D) (None, None, None, 1 258048 activation_62[0][0] 443__________________________________________________________________________________________________ 444conv2d_68 (Conv2D) (None, None, None, 1 258048 activation_67[0][0] 445__________________________________________________________________________________________________ 446batch_normalization_63 (BatchNo (None, None, None, 1 576 conv2d_63[0][0] 447__________________________________________________________________________________________________ 448batch_normalization_68 (BatchNo (None, None, None, 1 576 conv2d_68[0][0] 449__________________________________________________________________________________________________ 450activation_63 (Activation) (None, None, None, 1 0 batch_normalization_63[0][0] 451__________________________________________________________________________________________________ 452activation_68 (Activation) (None, None, None, 1 0 batch_normalization_68[0][0] 453__________________________________________________________________________________________________ 454average_pooling2d_7 (AveragePoo (None, None, None, 7 0 mixed6[0][0] 455__________________________________________________________________________________________________ 456conv2d_61 (Conv2D) (None, None, None, 1 147456 mixed6[0][0] 457__________________________________________________________________________________________________ 458conv2d_64 (Conv2D) (None, None, None, 1 258048 activation_63[0][0] 459__________________________________________________________________________________________________ 460conv2d_69 (Conv2D) (None, None, None, 1 258048 activation_68[0][0] 461__________________________________________________________________________________________________ 462conv2d_70 (Conv2D) (None, None, None, 1 147456 average_pooling2d_7[0][0] 463__________________________________________________________________________________________________ 464batch_normalization_61 (BatchNo (None, None, None, 1 576 conv2d_61[0][0] 465__________________________________________________________________________________________________ 466batch_normalization_64 (BatchNo (None, None, None, 1 576 conv2d_64[0][0] 467__________________________________________________________________________________________________ 468batch_normalization_69 (BatchNo (None, None, None, 1 576 conv2d_69[0][0] 469__________________________________________________________________________________________________ 470batch_normalization_70 (BatchNo (None, None, None, 1 576 conv2d_70[0][0] 471__________________________________________________________________________________________________ 472activation_61 (Activation) (None, None, None, 1 0 batch_normalization_61[0][0] 473__________________________________________________________________________________________________ 474activation_64 (Activation) (None, None, None, 1 0 batch_normalization_64[0][0] 475__________________________________________________________________________________________________ 476activation_69 (Activation) (None, None, None, 1 0 batch_normalization_69[0][0] 477__________________________________________________________________________________________________ 478activation_70 (Activation) (None, None, None, 1 0 batch_normalization_70[0][0] 479__________________________________________________________________________________________________ 480mixed7 (Concatenate) (None, None, None, 7 0 activation_61[0][0] 481 activation_64[0][0] 482 activation_69[0][0] 483 activation_70[0][0] 484__________________________________________________________________________________________________ 485conv2d_73 (Conv2D) (None, None, None, 1 147456 mixed7[0][0] 486__________________________________________________________________________________________________ 487batch_normalization_73 (BatchNo (None, None, None, 1 576 conv2d_73[0][0] 488__________________________________________________________________________________________________ 489activation_73 (Activation) (None, None, None, 1 0 batch_normalization_73[0][0] 490__________________________________________________________________________________________________ 491conv2d_74 (Conv2D) (None, None, None, 1 258048 activation_73[0][0] 492__________________________________________________________________________________________________ 493batch_normalization_74 (BatchNo (None, None, None, 1 576 conv2d_74[0][0] 494__________________________________________________________________________________________________ 495activation_74 (Activation) (None, None, None, 1 0 batch_normalization_74[0][0] 496__________________________________________________________________________________________________ 497conv2d_71 (Conv2D) (None, None, None, 1 147456 mixed7[0][0] 498__________________________________________________________________________________________________ 499conv2d_75 (Conv2D) (None, None, None, 1 258048 activation_74[0][0] 500__________________________________________________________________________________________________ 501batch_normalization_71 (BatchNo (None, None, None, 1 576 conv2d_71[0][0] 502__________________________________________________________________________________________________ 503batch_normalization_75 (BatchNo (None, None, None, 1 576 conv2d_75[0][0] 504__________________________________________________________________________________________________ 505activation_71 (Activation) (None, None, None, 1 0 batch_normalization_71[0][0] 506__________________________________________________________________________________________________ 507activation_75 (Activation) (None, None, None, 1 0 batch_normalization_75[0][0] 508__________________________________________________________________________________________________ 509conv2d_72 (Conv2D) (None, None, None, 3 552960 activation_71[0][0] 510__________________________________________________________________________________________________ 511conv2d_76 (Conv2D) (None, None, None, 1 331776 activation_75[0][0] 512__________________________________________________________________________________________________ 513batch_normalization_72 (BatchNo (None, None, None, 3 960 conv2d_72[0][0] 514__________________________________________________________________________________________________ 515batch_normalization_76 (BatchNo (None, None, None, 1 576 conv2d_76[0][0] 516__________________________________________________________________________________________________ 517activation_72 (Activation) (None, None, None, 3 0 batch_normalization_72[0][0] 518__________________________________________________________________________________________________ 519activation_76 (Activation) (None, None, None, 1 0 batch_normalization_76[0][0] 520__________________________________________________________________________________________________ 521max_pooling2d_4 (MaxPooling2D) (None, None, None, 7 0 mixed7[0][0] 522__________________________________________________________________________________________________ 523mixed8 (Concatenate) (None, None, None, 1 0 activation_72[0][0] 524 activation_76[0][0] 525 max_pooling2d_4[0][0] 526__________________________________________________________________________________________________ 527conv2d_81 (Conv2D) (None, None, None, 4 573440 mixed8[0][0] 528__________________________________________________________________________________________________ 529batch_normalization_81 (BatchNo (None, None, None, 4 1344 conv2d_81[0][0] 530__________________________________________________________________________________________________ 531activation_81 (Activation) (None, None, None, 4 0 batch_normalization_81[0][0] 532__________________________________________________________________________________________________ 533conv2d_78 (Conv2D) (None, None, None, 3 491520 mixed8[0][0] 534__________________________________________________________________________________________________ 535conv2d_82 (Conv2D) (None, None, None, 3 1548288 activation_81[0][0] 536__________________________________________________________________________________________________ 537batch_normalization_78 (BatchNo (None, None, None, 3 1152 conv2d_78[0][0] 538__________________________________________________________________________________________________ 539batch_normalization_82 (BatchNo (None, None, None, 3 1152 conv2d_82[0][0] 540__________________________________________________________________________________________________ 541activation_78 (Activation) (None, None, None, 3 0 batch_normalization_78[0][0] 542__________________________________________________________________________________________________ 543activation_82 (Activation) (None, None, None, 3 0 batch_normalization_82[0][0] 544__________________________________________________________________________________________________ 545conv2d_79 (Conv2D) (None, None, None, 3 442368 activation_78[0][0] 546__________________________________________________________________________________________________ 547conv2d_80 (Conv2D) (None, None, None, 3 442368 activation_78[0][0] 548__________________________________________________________________________________________________ 549conv2d_83 (Conv2D) (None, None, None, 3 442368 activation_82[0][0] 550__________________________________________________________________________________________________ 551conv2d_84 (Conv2D) (None, None, None, 3 442368 activation_82[0][0] 552__________________________________________________________________________________________________ 553average_pooling2d_8 (AveragePoo (None, None, None, 1 0 mixed8[0][0] 554__________________________________________________________________________________________________ 555conv2d_77 (Conv2D) (None, None, None, 3 409600 mixed8[0][0] 556__________________________________________________________________________________________________ 557batch_normalization_79 (BatchNo (None, None, None, 3 1152 conv2d_79[0][0] 558__________________________________________________________________________________________________ 559batch_normalization_80 (BatchNo (None, None, None, 3 1152 conv2d_80[0][0] 560__________________________________________________________________________________________________ 561batch_normalization_83 (BatchNo (None, None, None, 3 1152 conv2d_83[0][0] 562__________________________________________________________________________________________________ 563batch_normalization_84 (BatchNo (None, None, None, 3 1152 conv2d_84[0][0] 564__________________________________________________________________________________________________ 565conv2d_85 (Conv2D) (None, None, None, 1 245760 average_pooling2d_8[0][0] 566__________________________________________________________________________________________________ 567batch_normalization_77 (BatchNo (None, None, None, 3 960 conv2d_77[0][0] 568__________________________________________________________________________________________________ 569activation_79 (Activation) (None, None, None, 3 0 batch_normalization_79[0][0] 570__________________________________________________________________________________________________ 571activation_80 (Activation) (None, None, None, 3 0 batch_normalization_80[0][0] 572__________________________________________________________________________________________________ 573activation_83 (Activation) (None, None, None, 3 0 batch_normalization_83[0][0] 574__________________________________________________________________________________________________ 575activation_84 (Activation) (None, None, None, 3 0 batch_normalization_84[0][0] 576__________________________________________________________________________________________________ 577batch_normalization_85 (BatchNo (None, None, None, 1 576 conv2d_85[0][0] 578__________________________________________________________________________________________________ 579activation_77 (Activation) (None, None, None, 3 0 batch_normalization_77[0][0] 580__________________________________________________________________________________________________ 581mixed9_0 (Concatenate) (None, None, None, 7 0 activation_79[0][0] 582 activation_80[0][0] 583__________________________________________________________________________________________________ 584concatenate_1 (Concatenate) (None, None, None, 7 0 activation_83[0][0] 585 activation_84[0][0] 586__________________________________________________________________________________________________ 587activation_85 (Activation) (None, None, None, 1 0 batch_normalization_85[0][0] 588__________________________________________________________________________________________________ 589mixed9 (Concatenate) (None, None, None, 2 0 activation_77[0][0] 590 mixed9_0[0][0] 591 concatenate_1[0][0] 592 activation_85[0][0] 593__________________________________________________________________________________________________ 594conv2d_90 (Conv2D) (None, None, None, 4 917504 mixed9[0][0] 595__________________________________________________________________________________________________ 596batch_normalization_90 (BatchNo (None, None, None, 4 1344 conv2d_90[0][0] 597__________________________________________________________________________________________________ 598activation_90 (Activation) (None, None, None, 4 0 batch_normalization_90[0][0] 599__________________________________________________________________________________________________ 600conv2d_87 (Conv2D) (None, None, None, 3 786432 mixed9[0][0] 601__________________________________________________________________________________________________ 602conv2d_91 (Conv2D) (None, None, None, 3 1548288 activation_90[0][0] 603__________________________________________________________________________________________________ 604batch_normalization_87 (BatchNo (None, None, None, 3 1152 conv2d_87[0][0] 605__________________________________________________________________________________________________ 606batch_normalization_91 (BatchNo (None, None, None, 3 1152 conv2d_91[0][0] 607__________________________________________________________________________________________________ 608activation_87 (Activation) (None, None, None, 3 0 batch_normalization_87[0][0] 609__________________________________________________________________________________________________ 610activation_91 (Activation) (None, None, None, 3 0 batch_normalization_91[0][0] 611__________________________________________________________________________________________________ 612conv2d_88 (Conv2D) (None, None, None, 3 442368 activation_87[0][0] 613__________________________________________________________________________________________________ 614conv2d_89 (Conv2D) (None, None, None, 3 442368 activation_87[0][0] 615__________________________________________________________________________________________________ 616conv2d_92 (Conv2D) (None, None, None, 3 442368 activation_91[0][0] 617__________________________________________________________________________________________________ 618conv2d_93 (Conv2D) (None, None, None, 3 442368 activation_91[0][0] 619__________________________________________________________________________________________________ 620average_pooling2d_9 (AveragePoo (None, None, None, 2 0 mixed9[0][0] 621__________________________________________________________________________________________________ 622conv2d_86 (Conv2D) (None, None, None, 3 655360 mixed9[0][0] 623__________________________________________________________________________________________________ 624batch_normalization_88 (BatchNo (None, None, None, 3 1152 conv2d_88[0][0] 625__________________________________________________________________________________________________ 626batch_normalization_89 (BatchNo (None, None, None, 3 1152 conv2d_89[0][0] 627__________________________________________________________________________________________________ 628batch_normalization_92 (BatchNo (None, None, None, 3 1152 conv2d_92[0][0] 629__________________________________________________________________________________________________ 630batch_normalization_93 (BatchNo (None, None, None, 3 1152 conv2d_93[0][0] 631__________________________________________________________________________________________________ 632conv2d_94 (Conv2D) (None, None, None, 1 393216 average_pooling2d_9[0][0] 633__________________________________________________________________________________________________ 634batch_normalization_86 (BatchNo (None, None, None, 3 960 conv2d_86[0][0] 635__________________________________________________________________________________________________ 636activation_88 (Activation) (None, None, None, 3 0 batch_normalization_88[0][0] 637__________________________________________________________________________________________________ 638activation_89 (Activation) (None, None, None, 3 0 batch_normalization_89[0][0] 639__________________________________________________________________________________________________ 640activation_92 (Activation) (None, None, None, 3 0 batch_normalization_92[0][0] 641__________________________________________________________________________________________________ 642activation_93 (Activation) (None, None, None, 3 0 batch_normalization_93[0][0] 643__________________________________________________________________________________________________ 644batch_normalization_94 (BatchNo (None, None, None, 1 576 conv2d_94[0][0] 645__________________________________________________________________________________________________ 646activation_86 (Activation) (None, None, None, 3 0 batch_normalization_86[0][0] 647__________________________________________________________________________________________________ 648mixed9_1 (Concatenate) (None, None, None, 7 0 activation_88[0][0] 649 activation_89[0][0] 650__________________________________________________________________________________________________ 651concatenate_2 (Concatenate) (None, None, None, 7 0 activation_92[0][0] 652 activation_93[0][0] 653__________________________________________________________________________________________________ 654activation_94 (Activation) (None, None, None, 1 0 batch_normalization_94[0][0] 655__________________________________________________________________________________________________ 656mixed10 (Concatenate) (None, None, None, 2 0 activation_86[0][0] 657 mixed9_1[0][0] 658 concatenate_2[0][0] 659 activation_94[0][0] 660__________________________________________________________________________________________________ 661global_average_pooling2d_1 (Glo (None, 2048) 0 mixed10[0][0] 662__________________________________________________________________________________________________ 663dense_1 (Dense) (None, 1024) 2098176 global_average_pooling2d_1[0][0] 664__________________________________________________________________________________________________ 665dense_2 (Dense) (None, 2) 2050 dense_1[0][0] 666================================================================================================== 667Total params: 23,903,010 668Trainable params: 2,100,226 669Non-trainable params: 21,802,784 670__________________________________________________________________________________________________ Pháº§n train láº¡i sáº½ cÃ³ khoáº£ng hÆ¡n 2 triá»‡u tham sá»‘, pháº§n layter á»Ÿ trÆ°á»›c Ä‘Ã³ khÃ´ng train lÃ  khoáº£ng 21 triá»‡u tham sá»‘.\nÄá»“ hÃ¬nh cá»§a model (cÃ¡c báº¡n cÃ³ thá»ƒ download vá» rá»“i zoom bá»± lÃªn Ä‘á»ƒ xem rÃµ hÆ¡n).\nChia táº­p dá»¯ liá»‡u ra thÃ nh 5 pháº§n, 4 pháº§n lÃ m táº­p train, 1 pháº§n lÃ m táº­p validation.\n1X, y, tags = dataset.dataset(data_directory, n) 2nb_classes = len(tags) 3 4 5sample_count = len(y) 6train_size = sample_count * 4 // 5 7X_train = X[:train_size] 8y_train = y[:train_size] 9Y_train = np_utils.to_categorical(y_train, nb_classes) 10X_test = X[train_size:] 11y_test = y[train_size:] 12Y_test = np_utils.to_categorical(y_test, nb_classes) Äá»ƒ chá»‘ng overfit, chÃºng ta sáº½ thÃªm má»™t sá»‘ yáº¿u tá»‘ nhÆ° thá»±c hiá»‡n cÃ¡c phÃ©p biáº¿n Ä‘á»•i affine trÃªn áº£nh gá»‘c.\n1datagen = ImageDataGenerator( 2 featurewise_center=False, 3 samplewise_center=False, 4 featurewise_std_normalization=False, 5 samplewise_std_normalization=False, 6 zca_whitening=False, 7 rotation_range=45, 8 width_shift_range=0.25, 9 height_shift_range=0.25, 10 horizontal_flip=True, 11 vertical_flip=False, 12 zoom_range=0.5, 13 channel_shift_range=0.5, 14 fill_mode=\u0026#39;nearest\u0026#39;) 15 16datagen.fit(X_train) Cuá»‘i cÃ¹ng, chÃºng ta sáº½ xÃ¢y dá»±ng mÃ´ hÃ¬nh vÃ  tiáº¿n hÃ nh huáº¥n luyá»‡n, lÆ°u mÃ´ hÃ¬nh. QuÃ¡ trÃ¬nh nÃ y tá»‘n hÆ¡i nhiá»u thá»i gian.\n1 2model = net.build_model(nb_classes) 3model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#34;accuracy\u0026#34;]) 4 5# train the model on the new data for a few epochs 6 7print(\u0026#34;training the newly added dense layers\u0026#34;) 8 9samples_per_epoch = X_train.shape[0]//batch_size*batch_size 10steps_per_epoch = samples_per_epoch//batch_size 11validation_steps = X_test.shape[0]//batch_size*batch_size 12 13model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True), 14 samples_per_epoch=samples_per_epoch, 15 epochs=nb_epoch, 16 steps_per_epoch = steps_per_epoch, 17 validation_data=datagen.flow(X_test, Y_test, batch_size=batch_size), 18 validation_steps=validation_steps, 19 ) 20 21 22net.save(model, tags, model_file_prefix) Äá»™ chÃ­nh xÃ¡c trÃªn táº­p train.\n1Y_pred = model.predict(X_test, batch_size=batch_size) 2y_pred = np.argmax(Y_pred, axis=1) 3 4accuracy = float(np.sum(y_test==y_pred)) / len(y_test) 5print(\u0026#34;accuracy: \u0026#34;, accuracy) 6 7confusion = np.zeros((nb_classes, nb_classes), dtype=np.int32) 8for (predicted_index, actual_index, image) in zip(y_pred, y_test, X_test): 9 confusion[predicted_index, actual_index] += 1 10 11print(\u0026#34;rows are predicted classes, columns are actual classes\u0026#34;) 12for predicted_index, predicted_tag in enumerate(tags): 13 print(predicted_tag[:7], end=\u0026#39;\u0026#39;, flush=True) 14 for actual_index, actual_tag in enumerate(tags): 15 print(\u0026#34;\\t%d\u0026#34; % confusion[predicted_index, actual_index], end=\u0026#39;\u0026#39;) 16 print(\u0026#34;\u0026#34;, flush=True) 1accuracy: 0.9907213167661771 2rows are predicted classes, columns are actual classes 3cat 12238 106 4dog 124 12320 Káº¿t quáº£ Ä‘áº¡t 0.99 trÃªn táº­p train, khÃ¡ tá»‘t pháº£i khÃ´ng cÃ¡c báº¡n.\nCÃ¡c báº¡n cÃ³ thá»ƒ download mÃ´ hÃ¬nh mÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n á»Ÿ https://drive.google.com/open?id=1qQo8gj3KA6c1rPmJMVS_FZkVDcDmRgSf.\nThá»­ show ra káº¿t quáº£ trÃªn táº­p test xem nhÆ° tháº¿ nÃ o.\n1Y_pred = model.predict(X_test, batch_size=batch_size) 2y_pred = np.argmax(Y_pred, axis=1) 3 4lst_img = [] 5 6columns = 5 7rows = 5 8# fig,= plt.figure(rows) 9for idx, val in enumerate(X_test): 10 pred =y_pred[idx] 11 label = \u0026#34;{}: {:.2f}%\u0026#34;.format(tags[pred], Y_pred[idx][pred] * 100) 12 image = dataset.reverse_preprocess_input(val) 13 image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) 14 cv2.putText(image,label , (10, 25), cv2.FONT_HERSHEY_SIMPLEX,0.7, (255, 000, 0), 2) 15 16 plt.subplot(rows,rows,idx+1) 17 plt.imshow(image) 18 plt.title(label) 19 plt.axis(\u0026#39;off\u0026#39;) 20 21plt.show() Káº¿t quáº£ cÃ³ má»™t sá»‘ hÃ¬nh mÃ¨o bá»‹ nháº­n nháº§m lÃ  chÃ³, vÃ  má»™t sá»‘ hÃ¬nh khÃ´ng pháº£i mÃ¨o, khÃ´ng pháº£i chÃ³. NhÃ¬n chung káº¿t quáº£ cÅ©ng khÃ´ng Ä‘áº¿n ná»—i nÃ o quÃ¡ tá»‡.\nQuáº­y phÃ¡ mÃ´ hÃ¬nh MÃ´ hÃ¬nh InceptionV3 chÃºng ta Ä‘ang xÃ i cÃ³ tá»•ng cá»™ng 311 lá»›p, chÃºng ta sáº½ tiáº¿n hÃ nh má»™t sá»‘ pha quáº­y phÃ¡ mÃ´ hÃ¬nh xem káº¿t quáº£ nhÆ° tráº£ ra nhÆ° tháº¿ nÃ o\nQuáº­y phÃ¡ 1: Má»Ÿ Ä‘Ã³ng bÄƒng má»™t sá»‘ lá»›p cuá»‘i vÃ  train trÃªn chÃºng. Náº¿u cÃ¡c báº¡n Ä‘á»ƒ Ã½ ká»¹, trong Ä‘oáº¡n mÃ£ nguá»“n cá»§a mÃ¬nh cÃ³ Ä‘oáº¡n\n1# first: train only the top layers (which were randomly initialized) 2 # i.e. freeze all convolutional InceptionV3 layers 3 for layer in base_model.layers: 4 layer.trainable = False NghÄ©a lÃ  mÃ¬nh Ä‘Ã³ng bÄƒng toÃ n bá»™ 311 lá»›p, khÃ´ng cho nÃ³ train mÃ  chá»‰ láº¥y káº¿t quáº£ cá»§a nÃ³ train lá»›p softmax cuá»‘i cÃ¹ng. BÃ¢y giá» mÃ¬nh sáº½ thá»­ nghiá»‡m vá»›i viá»‡c lÃ  Ä‘á»ƒ 299 lá»›p ban Ä‘áº§u váº«n Ä‘Ã³ng bÄƒng, vÃ  train láº¡i toÃ n bá»™ cÃ¡c lá»›p cÃ²n láº¡i (CÃ¡c báº¡n Ä‘á»«ng tháº¯c máº¯c vÃ¬ sao láº¡i lÃ  299 nha, do mÃ¬nh thÃ­ch thÃ´i).\n1for layer in model.layers[:299]: 2 layer.trainable = False 3for layer in model.layers[299:]: 4 layer.trainable = True Äá»“ hÃ¬nh cá»§a mÃ´ Ä‘á»“ khÃ¡ giá»‘ng á»Ÿ trÃªn, mÃ¬nh chá»‰ post láº¡i káº¿t quáº£ cá»§a sá»‘ param.\n1================================================================================================== 2Total params: 23,903,010 3Trainable params: 2,493,954 4Non-trainable params: 21,409,056 5__________________________________________________________________________________________________ NhÆ° váº­y lÃ  cÃ³ khoáº£ng 2 triá»‡u 5 tham sá»‘ Ä‘Æ°á»£c huáº¥n luyá»‡n láº¡i\nModel cá»§a mÃ¬nh huáº¥n luyá»‡n Ä‘Æ°á»£c cÃ¡c báº¡n cÃ³ thá»ƒ download á»Ÿ https://drive.google.com/open?id=1Ts18LICUAh6gcOnXcmuVr7PUG5IxpCdt.\nKáº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c:\n1accuracy: 0.9834610730133119 2rows are predicted classes, columns are actual classes 3cat 2429 69 4dog 13 2447 Káº¿t quáº£ 25 hÃ¬nh ngáº«u nhiÃªn cÅ©ng khÃ¡ giá»‘ng káº¿t quáº£ á»Ÿ trÆ°á»›c Ä‘Ã³. Má»™t sá»‘ hÃ¬nh khÃ´ng cÃ³ con váº­t bá»‹ nháº­n nháº§m nhÆ° hÃ¬nh cÃ²n mÃ¨o á»Ÿ gÃ³c pháº£i trÃªn bá»‹ nháº­n nháº§m lÃ  chÃ³. Tuy nhiÃªn, vá»›i cháº¥t lÆ°á»£ng hÃ¬nh áº£nh nhÆ° tháº¿ nÃ y thÃ¬ mÃ¬nh tháº¥y káº¿t quáº£ nhÆ° váº­y lÃ  khÃ¡ tuyá»‡t vá»i.\nQuáº­y phÃ¡ 2: Chá»‰ sá»­ dá»¥ng 72 lá»›p Ä‘áº§u tiÃªn cá»§a inception. á» láº§n thÃ­ nghiá»‡m nÃ y, mÃ¬nh sáº½ chá»‰ sá»­ dá»¥ng 72 lá»›p Ä‘áº§u tiÃªn cá»§a inception Ä‘á»ƒ huáº¥n luyá»‡n. MÃ¬nh sáº½ sá»­a láº¡i má»™t xÃ­u á»Ÿ hÃ m build model nhÆ° sau:\n1x = base_model.layers[72].output Má»™t lÆ°u Ã½ nhá» lÃ  do inception khÃ´ng cÃ³ tÃ­nh tuáº§n tá»± giá»¯a cÃ¡c lá»›p (cÃ¡c báº¡n cÃ³ thá»ƒ nhÃ¬n hÃ¬nh á»Ÿ trÃªn sáº½ tháº¥y rÃµ), nÃªn index sáº½ khÃ´ng pháº£i lÃ  72 nhÆ° thÃ´ng thÆ°á»ng.\nTiáº¿p theo, chÃºng ta sáº½ thá»±c hiá»‡n viá»‡c huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh vÃ  káº¿t quáº£ lÃ :\n1accuracy: 0.5494150867285196 2rows are predicted classes, columns are actual classes 3cat 339 131 4dog 2103 2385 Káº¿t quáº£ khÃ¡ tá»‡, lÃ½ do lÃ  mÃ´ hÃ¬nh cÃ¡c layer khÃ´ng theo sequence, mÃ¬nh láº¥y ngáº«u nhiÃªu 72 lá»›p lÃ m thÃ´ng tin feature cá»§a cÃ¡c hÃ¬nh bá»‹ máº¥t mÃ¡t nhiá»u (vÃ­ dá»¥ trÆ°á»ng há»£p layey 80 lÃ  tá»•ng há»£p thÃ´ng tin cá»§a layter 79 + layter 4 + layer 48, mÃ  mÃ¬nh chá»‰ láº¥y 72 layter Ä‘áº§u, nÃªn sáº½ máº¥t Ä‘i pháº§n Ä‘Ã³ng gÃ³p cá»±c ká»³ quan trá»ng cá»§a layter 4 vÃ  48 á»Ÿ lá»›p cao hÆ¡n).\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Oct 29, 2018","img":"","permalink":"/blog/2018-10-29-phan-loai-cho-meo/","series":null,"tags":["Machine learning","Deeplearning","dog cat"],"title":"PhÃ¢n Loáº¡i ChÃ³ MÃ¨o Sá»­ Dá»¥ng Pretrain Model"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Sá»­ dá»¥ng pretrain model Lá»i má»Ÿ Ä‘áº§u PhÃ¢n vÃ¹ng Ä‘á»‘i tÆ°á»£ng lÃ  má»™t bÃ i toÃ¡n khÃ¡ phá»• biáº¿n trong lÄ©nh vá»±c computer vision. Trong open cv cÃ³ há»— trá»£ cho chÃºng ta má»™t sá»‘ hÃ m Ä‘á»ƒ phÃ¢n vÃ¹ng Ä‘á»‘i tÆ°á»£ng ráº¥t dá»… sá»­ dá»¥ng. Äáº·c Ä‘iá»ƒm chung cá»§a cÃ¡c hÃ m nÃ y lÃ  Ä‘á»™ chÃ­nh xÃ¡c khÃ´ng Ä‘Æ°á»£c cao cho láº¯m. á» bÃ i viáº¿t nÃ y, chÃºng ta sáº½ tÃ¬m hiá»ƒu cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh pretrain cá»§a DNN Ä‘á»ƒ phÃ¢n vÃ¹ng cÃ¡c Ä‘á»‘i tÆ°á»£ng trong áº£nh.\nSá»­ dá»¥ng pretrain model Äáº§u tiÃªn, cÃ¡c báº¡n download file pretrain model, giáº£i nÃ©n ra vÃ  Ä‘á»ƒ á»Ÿ Ä‘Ã¢u Ä‘Ã³ trong á»• cá»©ng cá»§a mÃ¡y báº¡n. ÄÆ°á»ng dáº«n file pretrain model cÃ¡c báº¡n cÃ³ thá»ƒ download á»Ÿ http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz. CÃ¡c báº¡n cÃ³ thá»ƒ download cÃ¡c file pretrain khÃ¡c náº¿u cÃ³ há»©ng thÃº tÃ¬m hiá»ƒu.\nTiáº¿p theo, chÃºng ta sáº½ load mÃ´ hÃ¬nh lÃªn:\n1import numpy as np 2import os 3import sys 4import tarfile 5import tensorflow as tf 6 7from collections import defaultdict 8from io import StringIO 9from matplotlib import pyplot as plt 10from PIL import Image 11import PIL.ImageDraw as ImageDraw 12import PIL.ImageFont as ImageFont 13import cv2 14 15import pprint 16 17import PIL.Image as Image 18import PIL.ImageColor as ImageColor 19 20# Model preparation 21 22 23# Path to frozen detection graph. This is the actual model that is used for the object detection. 24PATH_TO_CKPT = \u0026#39;mask_rcnn_inception_v2_coco_2018_01_28\u0026#39; + \u0026#39;/frozen_inference_graph.pb\u0026#39; 25 26# List of the strings that is used to add correct label for each box. 27#PATH_TO_LABELS = \u0026#39;mscoco_label_map.pbtxt\u0026#39; 28 29NUM_CLASSES = 1 30 31 32# categories 33 34category_index = {1: {\u0026#39;id\u0026#39;: 1, \u0026#39;name\u0026#39;: \u0026#39;person\u0026#39;}, 35# 3: {\u0026#39;id\u0026#39;: 3, \u0026#39;name\u0026#39;: \u0026#39;car\u0026#39;}, 36 } 37 38detection_graph = tf.Graph() 39with detection_graph.as_default(): 40 od_graph_def = tf.GraphDef() 41 with tf.gfile.GFile(PATH_TO_CKPT, \u0026#39;rb\u0026#39;) as fid: 42 serialized_graph = fid.read() 43 od_graph_def.ParseFromString(serialized_graph) 44 tf.import_graph_def(od_graph_def, name=\u0026#39;\u0026#39;) á» Ä‘Ã¢y, mÃ¬nh chá»‰ demo detect ngÆ°á»i trong hÃ¬nh, nÃªn mÃ¬nh chá»‰ Ä‘á»ƒ category_index chá»‰ lÃ  \u0026ldquo;person\u0026rdquo;. Thá»±c táº¿, mÃ´ hÃ¬nh COCO há»— trá»£ cho chÃºng ta nháº­n dáº¡ng 90 loáº¡i Ä‘á»‘i tÆ°á»£ng khÃ¡c nhau, cÃ¡c báº¡n cÃ³ nhu cáº§u tÃ¬m hiá»ƒu thÃ¬ thay báº±ng Ä‘oáº¡n mÃ£ sau:\n1category_index = {1: {\u0026#39;id\u0026#39;: 1, \u0026#39;name\u0026#39;: \u0026#39;person\u0026#39;}, 2 2: {\u0026#39;id\u0026#39;: 2, \u0026#39;name\u0026#39;: \u0026#39;bicycle\u0026#39;}, 3 3: {\u0026#39;id\u0026#39;: 3, \u0026#39;name\u0026#39;: \u0026#39;car\u0026#39;}, 4 4: {\u0026#39;id\u0026#39;: 4, \u0026#39;name\u0026#39;: \u0026#39;motorcycle\u0026#39;}, 5 5: {\u0026#39;id\u0026#39;: 5, \u0026#39;name\u0026#39;: \u0026#39;airplane\u0026#39;}, 6 6: {\u0026#39;id\u0026#39;: 6, \u0026#39;name\u0026#39;: \u0026#39;bus\u0026#39;}, 7 7: {\u0026#39;id\u0026#39;: 7, \u0026#39;name\u0026#39;: \u0026#39;train\u0026#39;}, 8 8: {\u0026#39;id\u0026#39;: 8, \u0026#39;name\u0026#39;: \u0026#39;truck\u0026#39;}, 9 9: {\u0026#39;id\u0026#39;: 9, \u0026#39;name\u0026#39;: \u0026#39;boat\u0026#39;}, 10 10: {\u0026#39;id\u0026#39;: 10, \u0026#39;name\u0026#39;: \u0026#39;traffic light\u0026#39;}, 11 11: {\u0026#39;id\u0026#39;: 11, \u0026#39;name\u0026#39;: \u0026#39;fire hydrant\u0026#39;}, 12 13: {\u0026#39;id\u0026#39;: 13, \u0026#39;name\u0026#39;: \u0026#39;stop sign\u0026#39;}, 13 14: {\u0026#39;id\u0026#39;: 14, \u0026#39;name\u0026#39;: \u0026#39;parking meter\u0026#39;}, 14 15: {\u0026#39;id\u0026#39;: 15, \u0026#39;name\u0026#39;: \u0026#39;bench\u0026#39;}, 15 16: {\u0026#39;id\u0026#39;: 16, \u0026#39;name\u0026#39;: \u0026#39;bird\u0026#39;}, 16 17: {\u0026#39;id\u0026#39;: 17, \u0026#39;name\u0026#39;: \u0026#39;cat\u0026#39;}, 17 18: {\u0026#39;id\u0026#39;: 18, \u0026#39;name\u0026#39;: \u0026#39;dog\u0026#39;}, 18 19: {\u0026#39;id\u0026#39;: 19, \u0026#39;name\u0026#39;: \u0026#39;horse\u0026#39;}, 19 20: {\u0026#39;id\u0026#39;: 20, \u0026#39;name\u0026#39;: \u0026#39;sheep\u0026#39;}, 20 21: {\u0026#39;id\u0026#39;: 21, \u0026#39;name\u0026#39;: \u0026#39;cow\u0026#39;}, 21 22: {\u0026#39;id\u0026#39;: 22, \u0026#39;name\u0026#39;: \u0026#39;elephant\u0026#39;}, 22 23: {\u0026#39;id\u0026#39;: 23, \u0026#39;name\u0026#39;: \u0026#39;bear\u0026#39;}, 23 24: {\u0026#39;id\u0026#39;: 24, \u0026#39;name\u0026#39;: \u0026#39;zebra\u0026#39;}, 24 25: {\u0026#39;id\u0026#39;: 25, \u0026#39;name\u0026#39;: \u0026#39;giraffe\u0026#39;}, 25 27: {\u0026#39;id\u0026#39;: 27, \u0026#39;name\u0026#39;: \u0026#39;backpack\u0026#39;}, 26 28: {\u0026#39;id\u0026#39;: 28, \u0026#39;name\u0026#39;: \u0026#39;umbrella\u0026#39;}, 27 31: {\u0026#39;id\u0026#39;: 31, \u0026#39;name\u0026#39;: \u0026#39;handbag\u0026#39;}, 28 32: {\u0026#39;id\u0026#39;: 32, \u0026#39;name\u0026#39;: \u0026#39;tie\u0026#39;}, 29 33: {\u0026#39;id\u0026#39;: 33, \u0026#39;name\u0026#39;: \u0026#39;suitcase\u0026#39;}, 30 34: {\u0026#39;id\u0026#39;: 34, \u0026#39;name\u0026#39;: \u0026#39;frisbee\u0026#39;}, 31 35: {\u0026#39;id\u0026#39;: 35, \u0026#39;name\u0026#39;: \u0026#39;skis\u0026#39;}, 32 36: {\u0026#39;id\u0026#39;: 36, \u0026#39;name\u0026#39;: \u0026#39;snowboard\u0026#39;}, 33 37: {\u0026#39;id\u0026#39;: 37, \u0026#39;name\u0026#39;: \u0026#39;sports ball\u0026#39;}, 34 38: {\u0026#39;id\u0026#39;: 38, \u0026#39;name\u0026#39;: \u0026#39;kite\u0026#39;}, 35 39: {\u0026#39;id\u0026#39;: 39, \u0026#39;name\u0026#39;: \u0026#39;baseball bat\u0026#39;}, 36 40: {\u0026#39;id\u0026#39;: 40, \u0026#39;name\u0026#39;: \u0026#39;baseball glove\u0026#39;}, 37 41: {\u0026#39;id\u0026#39;: 41, \u0026#39;name\u0026#39;: \u0026#39;skateboard\u0026#39;}, 38 42: {\u0026#39;id\u0026#39;: 42, \u0026#39;name\u0026#39;: \u0026#39;surfboard\u0026#39;}, 39 43: {\u0026#39;id\u0026#39;: 43, \u0026#39;name\u0026#39;: \u0026#39;tennis racket\u0026#39;}, 40 44: {\u0026#39;id\u0026#39;: 44, \u0026#39;name\u0026#39;: \u0026#39;bottle\u0026#39;}, 41 46: {\u0026#39;id\u0026#39;: 46, \u0026#39;name\u0026#39;: \u0026#39;wine glass\u0026#39;}, 42 47: {\u0026#39;id\u0026#39;: 47, \u0026#39;name\u0026#39;: \u0026#39;cup\u0026#39;}, 43 48: {\u0026#39;id\u0026#39;: 48, \u0026#39;name\u0026#39;: \u0026#39;fork\u0026#39;}, 44 49: {\u0026#39;id\u0026#39;: 49, \u0026#39;name\u0026#39;: \u0026#39;knife\u0026#39;}, 45 50: {\u0026#39;id\u0026#39;: 50, \u0026#39;name\u0026#39;: \u0026#39;spoon\u0026#39;}, 46 51: {\u0026#39;id\u0026#39;: 51, \u0026#39;name\u0026#39;: \u0026#39;bowl\u0026#39;}, 47 52: {\u0026#39;id\u0026#39;: 52, \u0026#39;name\u0026#39;: \u0026#39;banana\u0026#39;}, 48 53: {\u0026#39;id\u0026#39;: 53, \u0026#39;name\u0026#39;: \u0026#39;apple\u0026#39;}, 49 54: {\u0026#39;id\u0026#39;: 54, \u0026#39;name\u0026#39;: \u0026#39;sandwich\u0026#39;}, 50 55: {\u0026#39;id\u0026#39;: 55, \u0026#39;name\u0026#39;: \u0026#39;orange\u0026#39;}, 51 56: {\u0026#39;id\u0026#39;: 56, \u0026#39;name\u0026#39;: \u0026#39;broccoli\u0026#39;}, 52 57: {\u0026#39;id\u0026#39;: 57, \u0026#39;name\u0026#39;: \u0026#39;carrot\u0026#39;}, 53 58: {\u0026#39;id\u0026#39;: 58, \u0026#39;name\u0026#39;: \u0026#39;hot dog\u0026#39;}, 54 59: {\u0026#39;id\u0026#39;: 59, \u0026#39;name\u0026#39;: \u0026#39;pizza\u0026#39;}, 55 60: {\u0026#39;id\u0026#39;: 60, \u0026#39;name\u0026#39;: \u0026#39;donut\u0026#39;}, 56 61: {\u0026#39;id\u0026#39;: 61, \u0026#39;name\u0026#39;: \u0026#39;cake\u0026#39;}, 57 62: {\u0026#39;id\u0026#39;: 62, \u0026#39;name\u0026#39;: \u0026#39;chair\u0026#39;}, 58 63: {\u0026#39;id\u0026#39;: 63, \u0026#39;name\u0026#39;: \u0026#39;couch\u0026#39;}, 59 64: {\u0026#39;id\u0026#39;: 64, \u0026#39;name\u0026#39;: \u0026#39;potted plant\u0026#39;}, 60 65: {\u0026#39;id\u0026#39;: 65, \u0026#39;name\u0026#39;: \u0026#39;bed\u0026#39;}, 61 67: {\u0026#39;id\u0026#39;: 67, \u0026#39;name\u0026#39;: \u0026#39;dining table\u0026#39;}, 62 70: {\u0026#39;id\u0026#39;: 70, \u0026#39;name\u0026#39;: \u0026#39;toilet\u0026#39;}, 63 72: {\u0026#39;id\u0026#39;: 72, \u0026#39;name\u0026#39;: \u0026#39;tv\u0026#39;}, 64 73: {\u0026#39;id\u0026#39;: 73, \u0026#39;name\u0026#39;: \u0026#39;laptop\u0026#39;}, 65 74: {\u0026#39;id\u0026#39;: 74, \u0026#39;name\u0026#39;: \u0026#39;mouse\u0026#39;}, 66 75: {\u0026#39;id\u0026#39;: 75, \u0026#39;name\u0026#39;: \u0026#39;remote\u0026#39;}, 67 76: {\u0026#39;id\u0026#39;: 76, \u0026#39;name\u0026#39;: \u0026#39;keyboard\u0026#39;}, 68 77: {\u0026#39;id\u0026#39;: 77, \u0026#39;name\u0026#39;: \u0026#39;cell phone\u0026#39;}, 69 78: {\u0026#39;id\u0026#39;: 78, \u0026#39;name\u0026#39;: \u0026#39;microwave\u0026#39;}, 70 79: {\u0026#39;id\u0026#39;: 79, \u0026#39;name\u0026#39;: \u0026#39;oven\u0026#39;}, 71 80: {\u0026#39;id\u0026#39;: 80, \u0026#39;name\u0026#39;: \u0026#39;toaster\u0026#39;}, 72 81: {\u0026#39;id\u0026#39;: 81, \u0026#39;name\u0026#39;: \u0026#39;sink\u0026#39;}, 73 82: {\u0026#39;id\u0026#39;: 82, \u0026#39;name\u0026#39;: \u0026#39;refrigerator\u0026#39;}, 74 84: {\u0026#39;id\u0026#39;: 84, \u0026#39;name\u0026#39;: \u0026#39;book\u0026#39;}, 75 85: {\u0026#39;id\u0026#39;: 85, \u0026#39;name\u0026#39;: \u0026#39;clock\u0026#39;}, 76 86: {\u0026#39;id\u0026#39;: 86, \u0026#39;name\u0026#39;: \u0026#39;vase\u0026#39;}, 77 87: {\u0026#39;id\u0026#39;: 87, \u0026#39;name\u0026#39;: \u0026#39;scissors\u0026#39;}, 78 88: {\u0026#39;id\u0026#39;: 88, \u0026#39;name\u0026#39;: \u0026#39;teddy bear\u0026#39;}, 79 89: {\u0026#39;id\u0026#39;: 89, \u0026#39;name\u0026#39;: \u0026#39;hair drier\u0026#39;}, 80 90: {\u0026#39;id\u0026#39;: 90, \u0026#39;name\u0026#39;: \u0026#39;toothbrush\u0026#39;}} Tiáº¿p theo, chÃºng ta sáº½ load má»™t sá»‘ hÃ m giÃºp há»— trá»£ viá»‡c háº­u xá»­ lÃ½ áº£nh Ä‘á»ƒ váº½ cÃ¡c mask cho chÃºng ta xem trá»±c quan hÆ¡n.\n1 2 draw = ImageDraw.Draw(image) 3 im_width, im_height = image.size 4 if use_normalized_coordinates: 5 (left, right, top, bottom) = (xmin * im_width, xmax * im_width, 6 ymin * im_height, ymax * im_height) 7 else: 8 (left, right, top, bottom) = (xmin, xmax, ymin, ymax) 9 draw.line([(left, top), (left, bottom), (right, bottom), 10 (right, top), (left, top)], width=thickness, fill=color) 11 try: 12 font = ImageFont.truetype(\u0026#39;arial.ttf\u0026#39;, 24) 13 except IOError: 14 font = ImageFont.load_default() 15 16 # If the total height of the display strings added to the top of the bounding 17 # box exceeds the top of the image, stack the strings below the bounding box 18 # instead of above. 19 display_str_heights = [font.getsize(ds)[1] for ds in display_str_list] 20 # Each display_str has a top and bottom margin of 0.05x. 21 total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights) 22 23 if top \u0026gt; total_display_str_height: 24 text_bottom = top 25 else: 26 text_bottom = bottom + total_display_str_height 27 # Reverse list and print from bottom to top. 28 for display_str in display_str_list[::-1]: 29 text_width, text_height = font.getsize(display_str) 30 margin = np.ceil(0.05 * text_height) 31 draw.rectangle( 32 [(left, text_bottom - text_height - 2 * margin), (left + text_width, 33 text_bottom)], 34 fill=color) 35 draw.text( 36 (left + margin, text_bottom - text_height - margin), 37 display_str, 38 fill=\u0026#39;black\u0026#39;, 39 font=font) 40 text_bottom -= text_height - 2 * margin 41 42 43 44def visualize_boxes_and_labels_on_image_array( 45 image, 46 boxes, 47 classes, 48 scores, 49 category_index, 50 instance_masks=None, 51 instance_boundaries=None, 52 keypoints=None, 53 use_normalized_coordinates=False, 54 max_boxes_to_draw=20, 55 min_score_thresh=.5, 56 agnostic_mode=False, 57 line_thickness=4, 58 groundtruth_box_visualization_color=\u0026#39;black\u0026#39;, 59 skip_scores=False, 60 skip_labels=False): 61 62 box_to_display_str_map = collections.defaultdict(list) 63 box_to_color_map = collections.defaultdict(str) 64 box_to_instance_masks_map = {} 65 box_to_instance_boundaries_map = {} 66 box_to_keypoints_map = collections.defaultdict(list) 67 if not max_boxes_to_draw: 68 max_boxes_to_draw = boxes.shape[0] 69 #print(boxes) 70 for i in range(min(max_boxes_to_draw, boxes.shape[0])): 71 if scores is None or scores[i] \u0026gt; min_score_thresh: 72 box = tuple(boxes[i].tolist()) 73 if instance_masks is not None: 74 box_to_instance_masks_map[box] = instance_masks[i] 75 if instance_boundaries is not None: 76 box_to_instance_boundaries_map[box] = instance_boundaries[i] 77 if keypoints is not None: 78 box_to_keypoints_map[box].extend(keypoints[i]) 79 if scores is None: 80 box_to_color_map[box] = groundtruth_box_visualization_color 81 else: 82 display_str = \u0026#39;\u0026#39; 83 if not skip_labels: 84 if not agnostic_mode: 85 if classes[i] in category_index.keys(): 86 class_name = category_index[classes[i]][\u0026#39;name\u0026#39;] 87 else: 88 class_name = \u0026#39;N/A\u0026#39; 89 display_str = str(class_name) 90 if not skip_scores: 91 if not display_str: 92 display_str = \u0026#39;{}%\u0026#39;.format(int(100 * scores[i])) 93 else: 94 display_str = \u0026#39;{}: {}%\u0026#39;.format( 95 display_str, int(100 * scores[i])) 96 box_to_display_str_map[box].append(display_str) 97 if agnostic_mode: 98 box_to_color_map[box] = \u0026#39;DarkOrange\u0026#39; 99 else: 100 box_to_color_map[box] = STANDARD_COLORS[classes[i] % 101 len(STANDARD_COLORS)] 102 103 # Draw all boxes onto image. 104 for box, color in box_to_color_map.items(): 105 ymin, xmin, ymax, xmax = box 106 if instance_masks is not None: 107 draw_mask_on_image_array(image, box_to_instance_masks_map[box], color=color) 108 109 draw_bounding_box_on_image_array( 110 image, 111 ymin, 112 xmin, 113 ymax, 114 xmax, 115 color=color, 116 thickness=line_thickness, 117 display_str_list=box_to_display_str_map[box], 118 use_normalized_coordinates=use_normalized_coordinates) 119 120 return image 121 122 123def reframe_box_masks_to_image_masks(box_masks, boxes, image_height, 124 image_width): 125 \u0026#34;\u0026#34;\u0026#34;Transforms the box masks back to full image masks. 126 127 Embeds masks in bounding boxes of larger masks whose shapes correspond to 128 image shape. 129 130 Args: 131 box_masks: A tf.float32 tensor of size [num_masks, mask_height, mask_width]. 132 boxes: A tf.float32 tensor of size [num_masks, 4] containing the box 133 corners. Row i contains [ymin, xmin, ymax, xmax] of the box 134 corresponding to mask i. Note that the box corners are in 135 normalized coordinates. 136 image_height: Image height. The output mask will have the same height as 137 the image height. 138 image_width: Image width. The output mask will have the same width as the 139 image width. 140 141 Returns: 142 A tf.float32 tensor of size [num_masks, image_height, image_width]. 143 \u0026#34;\u0026#34;\u0026#34; 144 # TODO(rathodv): Make this a public function. 145 def reframe_box_masks_to_image_masks_default(): 146 \u0026#34;\u0026#34;\u0026#34;The default function when there are more than 0 box masks.\u0026#34;\u0026#34;\u0026#34; 147 def transform_boxes_relative_to_boxes(boxes, reference_boxes): 148 boxes = tf.reshape(boxes, [-1, 2, 2]) 149 min_corner = tf.expand_dims(reference_boxes[:, 0:2], 1) 150 max_corner = tf.expand_dims(reference_boxes[:, 2:4], 1) 151 transformed_boxes = (boxes - min_corner) / \\ 152 (max_corner - min_corner) 153 return tf.reshape(transformed_boxes, [-1, 4]) 154 155 box_masks_expanded = tf.expand_dims(box_masks, axis=3) 156 num_boxes = tf.shape(box_masks_expanded)[0] 157 unit_boxes = tf.concat( 158 [tf.zeros([num_boxes, 2]), tf.ones([num_boxes, 2])], axis=1) 159 reverse_boxes = transform_boxes_relative_to_boxes(unit_boxes, boxes) 160 return tf.image.crop_and_resize( 161 image=box_masks_expanded, 162 boxes=reverse_boxes, 163 box_ind=tf.range(num_boxes), 164 crop_size=[image_height, image_width], 165 extrapolation_value=0.0) 166 image_masks = tf.cond( 167 tf.shape(box_masks)[0] \u0026gt; 0, 168 reframe_box_masks_to_image_masks_default, 169 lambda: tf.zeros([0, image_height, image_width, 1], dtype=tf.float32)) 170 return tf.squeeze(image_masks, axis=3) Cho hÃ¬nh áº£nh vÃ o vÃ  rÃºt ra káº¿t quáº£.\n1 2def detect_frame(image_np, sess, detection_graph): 3 4 with detection_graph.as_default(): 5 6 ops = tf.get_default_graph().get_operations() 7 all_tensor_names = {output.name for op in ops for output in op.outputs} 8 tensor_dict = {} 9 for key in [ 10 \u0026#39;num_detections\u0026#39;, \u0026#39;detection_boxes\u0026#39;, \u0026#39;detection_scores\u0026#39;, 11 \u0026#39;detection_classes\u0026#39;, \u0026#39;detection_masks\u0026#39; 12 ]: 13 tensor_name = key + \u0026#39;:0\u0026#39; 14 if tensor_name in all_tensor_names: 15 tensor_dict[key] = tf.get_default_graph( 16 ).get_tensor_by_name(tensor_name) 17 if \u0026#39;detection_masks\u0026#39; in tensor_dict: 18 # The following processing is only for single image 19 detection_boxes = tf.squeeze(tensor_dict[\u0026#39;detection_boxes\u0026#39;], [0]) 20 detection_masks = tf.squeeze(tensor_dict[\u0026#39;detection_masks\u0026#39;], [0]) 21 # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size. 22 real_num_detection = tf.cast( 23 tensor_dict[\u0026#39;num_detections\u0026#39;][0], tf.int32) 24 25 detection_boxes = tf.slice(detection_boxes, [0, 0], [ 26 real_num_detection, -1]) 27 detection_masks = tf.slice(detection_masks, [0, 0, 0], [ 28 real_num_detection, -1, -1]) 29 detection_masks_reframed = reframe_box_masks_to_image_masks( 30 detection_masks, detection_boxes, image_np.shape[0], image_np.shape[1]) 31 detection_masks_reframed = tf.cast( 32 tf.greater(detection_masks_reframed, 0.5), tf.uint8) 33 # Follow the convention by adding back the batch dimension 34 tensor_dict[\u0026#39;detection_masks\u0026#39;] = tf.expand_dims( 35 detection_masks_reframed, 0) 36 image_tensor = tf.get_default_graph().get_tensor_by_name(\u0026#39;image_tensor:0\u0026#39;) 37 38 # Run inference 39 output_dict = sess.run(tensor_dict, 40 feed_dict={image_tensor: np.expand_dims(image_np, 0)}) 41 42 # all outputs are float32 numpy arrays, so convert types as appropriate 43 output_dict[\u0026#39;num_detections\u0026#39;] = int(output_dict[\u0026#39;num_detections\u0026#39;][0]) 44 #print(\u0026#34;num detect \u0026#34;+str(output_dict[\u0026#39;num_detections\u0026#39;])) 45 output_dict[\u0026#39;detection_classes\u0026#39;] = output_dict[\u0026#39;detection_classes\u0026#39;][0].astype( 46 np.uint8) 47 output_dict[\u0026#39;detection_boxes\u0026#39;] = output_dict[\u0026#39;detection_boxes\u0026#39;][0] 48 output_dict[\u0026#39;detection_scores\u0026#39;] = output_dict[\u0026#39;detection_scores\u0026#39;][0] 49 if \u0026#39;detection_masks\u0026#39; in output_dict: 50 output_dict[\u0026#39;detection_masks\u0026#39;] = output_dict[\u0026#39;detection_masks\u0026#39;][0] 51 52 visualize_boxes_and_labels_on_image_array( 53 image_np, 54 output_dict[\u0026#39;detection_boxes\u0026#39;], 55 output_dict[\u0026#39;detection_classes\u0026#39;], 56 output_dict[\u0026#39;detection_scores\u0026#39;], 57 category_index, 58 instance_masks=output_dict.get(\u0026#39;detection_masks\u0026#39;), 59 use_normalized_coordinates=True, 60 line_thickness=1, 61 max_boxes_to_draw=min(output_dict[\u0026#39;num_detections\u0026#39;],20) 62 ) 63 64 return image_np 1image = cv2.imread(\u0026#39;img2.jpg\u0026#39;) 2with detection_graph.as_default(): 3 with tf.Session(graph=detection_graph) as sess: 4 image_np = detect_frame(image, sess, detection_graph) 5 6cv2.imwrite(\u0026#39;output.jpg\u0026#39;, image) Káº¿t quáº£ file output.jpg cá»§a chÃºng ta lÃ :\nThá»­ vá»›i bá»©c áº£nh ngÆ°á»i vÃ  xe hÆ¡i.\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi. Háº¹n gáº·p báº¡n á»Ÿ cÃ¡c bÃ i viáº¿t tiáº¿p theo.\n","date":"Oct 8, 2018","img":"","permalink":"/blog/2018-10-08-mask-rnn/","series":null,"tags":["Machine learning","Deeplearning","Spark"],"title":"Mask R-CNN Trong BÃ i ToÃ¡n Nháº­n Dáº¡ng VÃ  PhÃ¢n VÃ¹ng Äá»‘i TÆ°á»£ng"},{"categories":null,"content":"Lá»i má»Ÿ Ä‘áº§u LÆ°u Ã½: Äá»ƒ sá»­ dá»¥ng Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh trong bÃ i viáº¿t nÃ y, báº¡n pháº£i sá»­ dá»¥ng phiÃªn báº£n opencv \u0026gt; 3.4.1.\ná» bÃ i viáº¿t trÆ°á»›c, chÃºng ta Ä‘Ã£ tÃ¬m hiá»ƒu cÃ¡ch thá»©c rÃºt trÃ­ch khung xÆ°Æ¡ng sá»­ dá»¥ng DNN vÃ  Ä‘Ã£ Ã¡p dá»¥ng thÃ nh cÃ´ng trÃªn áº£nh cÃ³ chá»©a 1 Ä‘á»‘i tÆ°á»£ng ngÆ°á»i. Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ thá»±c hiá»‡n Ã¡p dá»¥ng mÃ´ hÃ¬nh cho bÃ i toÃ¡n cÃ³ nhiá»u ngÆ°á»i trong cÃ¹ng 1 bá»©c áº£nh.\nSá»­ dá»¥ng pretrain model trong bÃ i toÃ¡n multiple Pose Estimation Trong bÃ i viáº¿t nÃ y, chÃºng ta tiáº¿p tá»¥c sá»­ dá»¥ng mÃ´ hÃ¬nh MPI Ä‘á»ƒ dÃ² tÃ¬m cÃ¡c Ä‘iá»ƒm Ä‘áº·c trÆ°ng cá»§a con ngÆ°á»i vÃ  rÃºt ra mÃ´ hÃ¬nh khung xÆ°Æ¡ng. Káº¿t quáº£ tráº£ vá» cá»§a thuáº­t toÃ¡n gá»“m 15 Ä‘áº·c trÆ°ng nhÆ° bÃªn dÆ°á»›i.\n1Head â€“ 0, Neck â€“ 1, Right Shoulder â€“ 2, Right Elbow â€“ 3, Right Wrist â€“ 4, 2Left Shoulder â€“ 5, Left Elbow â€“ 6, Left Wrist â€“ 7, Right Hip â€“ 8, 3Right Knee â€“ 9, Right Ankle â€“ 10, Left Hip â€“ 11, Left Knee â€“ 12, 4Left Ankle â€“ 13, Chest â€“ 14, Background â€“ 15 Ãp dá»¥ng mÃ´ hÃ¬nh vá»›i áº£nh cá»§a nhÃ³m T-ARA.\n1import cv2 2 3nPoints = 15 4POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ] 5 6protoFile = \u0026#34;pose/mpi/pose_deploy_linevec.prototxt\u0026#34; 7weightsFile = \u0026#34;pose/mpi/pose_iter_160000.caffemodel\u0026#34; 8 9net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile) 10 11frame = cv2.imread(\u0026#34;tara1.jpg\u0026#34;) 12 13inWidth = 368 14inHeight = 368 15 16# Prepare the frame to be fed to the network 17inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False) 18 19# Set the prepared object as the input blob of the network 20net.setInput(inpBlob) 21 22output = net.forward() Thá»­ show lÃªn vá»‹ trÃ­ vÃ¹ng cá»• trong hÃ¬nh.\n1 2i = 0 3probMap = output[0, i, :, :] 4probMap = cv2.resize(probMap, (frameWidth, frameHeight)) 5 6import matplotlib.pyplot as plt 7 8plt.imshow(cv2.cvtColor(frameCopy, cv2.COLOR_BGR2RGB)) 9plt.imshow(probMap, alpha=0.5) 10plt.show() Thá»­ show lÃªn hÃ¬nh Ä‘iá»ƒm Ä‘áº·c trÆ°ng vÃ¹ng cá»•\n1i = 1 2probMap = output[0, i, :, :] 3probMap = cv2.resize(probMap, (frameWidth, frameHeight)) 4 5import matplotlib.pyplot as plt 6 7plt.imshow(cv2.cvtColor(frameCopy, cv2.COLOR_BGR2RGB)) 8plt.imshow(probMap, alpha=0.5) 9plt.show() Báº±ng má»™t sá»‘ phÃ©p biáº¿n Ä‘á»•i quen thuá»™c cÃ³ sáºµn trong opencv, chÃºng ta hoÃ n toÃ n cÃ³ thá»ƒ láº¥y Ä‘Æ°á»£c toáº¡ Ä‘á»™ cá»§a cÃ¡c Ä‘iá»ƒm keypoint má»™t cÃ¡ch dá»… dÃ ng.\n1 2# Find the Keypoints using Non Maximum Suppression on the Confidence Map 3def getKeypoints(probMap, threshold=0.1): 4 5 mapSmooth = cv2.GaussianBlur(probMap,(3,3),0,0) 6 7 mapMask = np.uint8(mapSmooth\u0026gt;threshold) 8 keypoints = [] 9 10 #find the blobs 11 _, contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) 12 13 #for each blob find the maxima 14 for cnt in contours: 15 blobMask = np.zeros(mapMask.shape) 16 blobMask = cv2.fillConvexPoly(blobMask, cnt, 1) 17 maskedProbMap = mapSmooth * blobMask 18 _, maxVal, _, maxLoc = cv2.minMaxLoc(maskedProbMap) 19 keypoints.append(maxLoc + (probMap[maxLoc[1], maxLoc[0]],)) 20 21 return keypoints 22 23 24detected_keypoints = [] 25keypoints_list = np.zeros((0,3)) 26keypoint_id = 0 27threshold = 0.1 28for i in range(nPoints): 29 probMap = output[0, i, :, :] 30 probMap = cv2.resize(probMap, (frameWidth, frameHeight)) 31 32 keypoints = getKeypoints(probMap, threshold) 33 keypoints_with_id = [] 34 for j in range(len(keypoints)): 35 keypoints_with_id.append(keypoints[j] + (keypoint_id,)) 36 keypoints_list = np.vstack([keypoints_list, keypoints[j]]) 37 keypoint_id += 1 38 39 detected_keypoints.append(keypoints_with_id) 40 41 42 43frameClone = cv2.cvtColor(frameCopy,cv2.COLOR_BGR2RGB) 44for i in range(nPoints): 45 for j in range(len(detected_keypoints[i])): 46 cv2.circle(frameClone, detected_keypoints[i][j][0:2], 3, [0,0,255], -1, cv2.LINE_AA) 47 48plt.imshow(frameClone) 49plt.show() Cuá»‘i cÃ¹ng, chÃºng ta sáº½ ná»‘i cÃ¡c Ä‘iá»ƒm Ä‘áº·c trÆ°ng cá»§a cÃ¡c nhÃ¢n váº­t thÃ´ng qua thuáº­t toÃ¡n Part Affinity Heatmaps. Thuáº­t toÃ¡n nÃ y Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi nhÃ³m tÃ¡c giáº£ Zhe Cao, Tomas Simon,Shih-En Wei, Yaser Sheikh thuá»™c phÃ²ng thÃ­ nghiá»‡m The Robotics Institute trÆ°á»ng Ä‘áº¡i há»c Carnegie Mellon. CÃ¡c báº¡n cÃ³ nhu cáº§u cÃ³ thá»ƒ tÃ¬m hiá»ƒu á»Ÿ https://arxiv.org/pdf/1611.08050.pdf.\n1 2mapIdx = [[16,17], [18,19], [20,21], [22,23], [24,25], [26,27], [28,29], [30,31], [32,33], [34,35], [36,37], [38,39], [40,41], [42,43]] 3 4 5 6colors = [ [0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255], 7 [0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255], 8 [0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]] 9# Find valid connections between the different joints of a all persons present 10def getValidPairs(output): 11 valid_pairs = [] 12 invalid_pairs = [] 13 n_interp_samples = 10 14 paf_score_th = 0.1 15 conf_th = 0.5 16 # loop for every POSE_PAIR 17 for k in range(len(mapIdx)): 18 # A-\u0026gt;B constitute a limb 19 pafA = output[0, mapIdx[k][0], :, :] 20 pafB = output[0, mapIdx[k][1], :, :] 21 pafA = cv2.resize(pafA, (frameWidth, frameHeight)) 22 pafB = cv2.resize(pafB, (frameWidth, frameHeight)) 23 24 25 # Find the keypoints for the first and second limb 26 candA = detected_keypoints[POSE_PAIRS[k][0]] 27 candB = detected_keypoints[POSE_PAIRS[k][1]] 28 nA = len(candA) 29 nB = len(candB) 30 31 # fig=plt.figure(figsize=(8, 8)) 32 33 # interp_coord = list(zip(np.linspace(candA[0][0], candB[0][0], num=n_interp_samples), 34 # np.linspace(candA[0][1], candB[0][1], num=n_interp_samples))) 35 36 # frameClone1 = frameClone.copy() 37 # fig.add_subplot(1, 2, 1) 38 39 # for xx in interp_coord: 40 # cv2.circle(frameClone1,(int(xx[0]),int(xx[1])), 3, [0,0,255], -1, cv2.LINE_AA) 41 42 43 # plt.imshow(cv2.cvtColor(frameClone1, cv2.COLOR_BGR2RGB)) 44 # plt.imshow(pafA, alpha=0.5) 45 46 # frameClone1 = frameClone.copy() 47 # fig.add_subplot(1, 2, 2) 48 49 50 51 52 # for xx in interp_coord: 53 # cv2.circle(frameClone1,(int(xx[0]),int(xx[1])), 3, [0,0,255], -1, cv2.LINE_AA) 54 55 # plt.imshow(cv2.cvtColor(frameClone1, cv2.COLOR_BGR2RGB)) 56 # plt.imshow(pafB, alpha=0.5) 57 # plt.show() 58 59 60 61 62 63 # If keypoints for the joint-pair is detected 64 # check every joint in candA with every joint in candB 65 # Calculate the distance vector between the two joints 66 # Find the PAF values at a set of interpolated points between the joints 67 # Use the above formula to compute a score to mark the connection valid 68 69 if( nA != 0 and nB != 0): 70 valid_pair = np.zeros((0,3)) 71 for i in range(nA): 72 max_j=-1 73 maxScore = -1 74 found = 0 75 for j in range(nB): 76 # Find d_ij 77 d_ij = np.subtract(candB[j][:2], candA[i][:2]) 78 norm = np.linalg.norm(d_ij) 79 if norm: 80 d_ij = d_ij / norm 81 else: 82 continue 83 # Find p(u) 84 interp_coord = list(zip(np.linspace(candA[i][0], candB[j][0], num=n_interp_samples), 85 np.linspace(candA[i][1], candB[j][1], num=n_interp_samples))) 86 # Find L(p(u)) 87 paf_interp = [] 88 for k in range(len(interp_coord)): 89 paf_interp.append([pafA[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))], 90 pafB[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))] ]) 91 # Find E 92 paf_scores = np.dot(paf_interp, d_ij) 93 avg_paf_score = sum(paf_scores)/len(paf_scores) 94 95 # Check if the connection is valid 96 # If the fraction of interpolated vectors aligned with PAF is higher then threshold -\u0026gt; Valid Pair 97 if ( len(np.where(paf_scores \u0026gt; paf_score_th)[0]) / n_interp_samples ) \u0026gt; conf_th : 98 if avg_paf_score \u0026gt; maxScore: 99 max_j = j 100 maxScore = avg_paf_score 101 found = 1 102 # Append the connection to the list 103 if found: 104 valid_pair = np.append(valid_pair, [[candA[i][3], candB[max_j][3], maxScore]], axis=0) 105 106 # Append the detected connections to the global list 107 valid_pairs.append(valid_pair) 108 109 pprint(valid_pair) 110 else: # If no keypoints are detected 111 print(\u0026#34;No Connection : k = {}\u0026#34;.format(k)) 112 invalid_pairs.append(k) 113 valid_pairs.append([]) 114 pprint(valid_pairs) 115 return valid_pairs, invalid_pairs 116 117# This function creates a list of keypoints belonging to each person 118# For each detected valid pair, it assigns the joint(s) to a person 119# It finds the person and index at which the joint should be added. This can be done since we have an id for each joint 120def getPersonwiseKeypoints(valid_pairs, invalid_pairs): 121 # the last number in each row is the overall score 122 personwiseKeypoints = -1 * np.ones((0, 19)) 123 124 for k in range(len(mapIdx)): 125 if k not in invalid_pairs: 126 partAs = valid_pairs[k][:,0] 127 partBs = valid_pairs[k][:,1] 128 indexA, indexB = np.array(POSE_PAIRS[k]) 129 130 for i in range(len(valid_pairs[k])): 131 found = 0 132 person_idx = -1 133 for j in range(len(personwiseKeypoints)): 134 if personwiseKeypoints[j][indexA] == partAs[i]: 135 person_idx = j 136 found = 1 137 break 138 139 if found: 140 personwiseKeypoints[person_idx][indexB] = partBs[i] 141 personwiseKeypoints[person_idx][-1] += keypoints_list[partBs[i].astype(int), 2] + valid_pairs[k][i][2] 142 143 # if find no partA in the subset, create a new subset 144 elif not found and k \u0026lt; 17: 145 row = -1 * np.ones(19) 146 row[indexA] = partAs[i] 147 row[indexB] = partBs[i] 148 # add the keypoint_scores for the two keypoints and the paf_score 149 row[-1] = sum(keypoints_list[valid_pairs[k][i,:2].astype(int), 2]) + valid_pairs[k][i][2] 150 personwiseKeypoints = np.vstack([personwiseKeypoints, row]) 151 return personwiseKeypoints 152 153valid_pairs, invalid_pairs = getValidPairs(output) 154 155personwiseKeypoints = getPersonwiseKeypoints(valid_pairs, invalid_pairs) 156 157 158for i in range(nPoints-1): 159 for n in range(len(personwiseKeypoints)): 160 161 index = personwiseKeypoints[n][np.array(POSE_PAIRS[i])] 162 if -1 in index: 163 continue 164 B = np.int32(keypoints_list[index.astype(int), 0]) 165 A = np.int32(keypoints_list[index.astype(int), 1]) 166 cv2.line(frameClone, (B[0], A[0]), (B[1], A[1]), colors[i], 3, cv2.LINE_AA) 167 168 169 170plt.imshow(frameClone) 171 # plt.imshow(mapMask, alpha=0.5) 172plt.show() Háº¹n gáº·p láº¡i cÃ¡c báº¡n á»Ÿ nhá»¯ng bÃ i viáº¿t tiáº¿p theo.\nBÃ i viáº¿t nÃ y Ä‘Æ°á»£c viáº¿t dá»±a vÃ o nguá»“n https://www.learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/ cá»§a tÃ¡c giáº£ VIKAS GUPTA. TÃ´i sá»­ dá»¥ng táº­p model vÃ  hÃ¬nh áº£nh khÃ¡c vá»›i bÃ i viáº¿t nguyÃªn gá»‘c cá»§a tÃ¡c giáº£.\n","date":"Oct 5, 2018","img":"","permalink":"/blog/2018-10-05-deep-learning-base-multiple-human-pose-estimation/","series":null,"tags":["Machine learning","Deeplearning","multiple pose estimation"],"title":"Deep Learning Based Multiple Human Pose Estimation Using OpenCV"},{"categories":null,"content":"Lá»i má»Ÿ Ä‘áº§u Äá»ƒ sá»­ dá»¥ng Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh trong bÃ i viáº¿t nÃ y, báº¡n pháº£i sá»­ dá»¥ng phiÃªn báº£n opencv \u0026gt; 3.4.1.\nPose Estimation lÃ  gÃ¬? Post Estimation ( Ä‘Ã´i khi Ä‘Æ°á»£c dÃ¹ng vá»›i thuáº­t ngá»¯ Keypoint Detection) lÃ  má»™t váº¥n Ä‘á» khÃ¡ phá»• biáº¿n trong lÄ©nh vá»±c xá»­ lÃ½ áº£nh khi chÃºng ta cáº§n xÃ¡c Ä‘á»‹nh vá»‹ trÃ­ vÃ  hÆ°á»›ng cá»§a má»™t Ä‘á»‘i tÆ°á»£ng. Má»©c Ã½ nghÄ©a á»Ÿ Ä‘Ã¢y lÃ  chÃºng ta pháº£i rÃºt ra Ä‘Æ°á»£c nhá»¯ng Ä‘áº·c Ä‘iá»ƒm chÃ­nh, nhá»¯ng Ä‘áº·c Ä‘iá»ƒm Ä‘Ã³ lÃ  nhá»¯ng Ä‘áº·c trÆ°ng cá»§a Ä‘á»‘i tÆ°á»£ng ( cÃ³ thá»ƒ mÃ´ táº£ Ä‘Æ°á»£c Ä‘á»‘i tÆ°á»£ng).\nVÃ­ dá»¥, trong bÃ i toÃ¡n face pose estimation ( cÃ³ tÃªn khÃ¡c lÃ  facial landmark detection), chÃºng ta cáº§n xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c Ä‘Ã¢u lÃ  vá»‹ trÃ­ cá»§a nhá»¯ng Ä‘iá»ƒm landmark trÃªn khuÃ´n máº·t ngÆ°á»i.\nMá»™t bÃ i toÃ¡n cÃ³ liÃªn quan Ä‘áº¿n bÃ i toÃ¡n trÃªn lÃ  head pose estimation. ChÃºng ta cáº§n xÃ¡c Ä‘á»‹nh nhá»¯ng Ä‘iá»ƒm landmark Ä‘á»ƒ mÃ´ hÃ¬nh hoÃ¡ láº¡i Ä‘Æ°á»£c mÃ´ hÃ¬nh 3D cá»§a Ä‘áº§u ngÆ°á»i.\ná» trong bÃ i viáº¿t nÃ y, chÃºng ta Ä‘á» cáº­p Ä‘áº¿n bÃ i toÃ¡n human pose estimation, cÃ´ng viá»‡c chÃ­nh lÃ  xÃ¡c Ä‘á»‹nh vÃ  chá»‰ ra Ä‘Æ°á»£c má»™t pháº§n/ toÃ n bá»™ cÃ¡c pháº§n chÃ­nh cá»§a cÆ¡ thá»ƒ con ngÆ°á»i (vd vai, khuá»·u tay, cá»• tay, Ä‘áº§u gá»‘i v.v).\nTrong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n sáºµn Ä‘á»ƒ chá»‰ ra cÃ¡c pháº§n chÃ­nh cá»§a cÆ¡ thá»ƒ con ngÆ°á»i. Káº¿t quáº£ cÆ¡ báº£n cá»§a pháº§n nháº­n diá»‡n nÃ y sáº½ gáº§n giá»‘ng nhÆ° hÃ¬nh bÃªn dÆ°á»›i.\nSá»­ dá»¥ng pretrain model trong bÃ i toÃ¡n Pose Estimation VÃ o náº±m 2016, 2017, PhÃ²ng thÃ­ nghiá»‡m Perceptual Computing cá»§a trÆ°á»ng Ä‘áº¡i há»c Carnegie Mellon University Ä‘Ã£ cÃ´ng bá»‘ má»™t bÃ i bÃ¡o cÃ³ liÃªn quan Ä‘áº¿n chá»§ Ä‘á» Multi-Person Pose Estimation. VÃ  Ä‘áº¿n nay, há» Ä‘Ã£ cÃ´ng bá»‘ mÃ´ hÃ¬nh huáº¥n luyá»‡n cho chÃºng ta sá»­ dá»¥ng. CÃ¡c báº¡n cÃ³ nhu cáº§u tÃ¬m hiá»ƒu sÃ¢u hÆ¡n cÃ³ thá»ƒ Ä‘á»c ká»¹ nguá»“n dá»¯ liá»‡u cá»§a há» cÃ´ng bá»‘ á»Ÿ link https://github.com/CMU-Perceptual-Computing-Lab/openpose.\nTrong bÃ i post nÃ y, mÃ¬nh sáº½ khÃ´ng Ä‘á» cáº­p ká»¹ Ä‘áº¿n pháº§n kiáº¿n trÃºc máº¡ng neural net há» sá»­ dá»¥ng bÃªn dÆ°á»›i, thay vÃ o Ä‘Ã³, mÃ¬nh sáº½ táº­p trung hÆ¡n vÃ o cÃ¡ch thá»©c sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘á»ƒ thu Ä‘Æ°á»£c káº¿t quáº£ cáº§n thiáº¿t.\nTrÆ°á»›c khi báº¯t Ä‘áº§u vÃ o thá»±c hÃ nh, mÃ¬nh sáº½ mÃ´ táº£ má»™t chÃºt vá» mÃ´ hÃ¬nh pretrain cÃ³ sáºµn. á» Ä‘Ã¢y, há» cung cáº¥p cho chÃºng ta 2 mÃ´ hÃ¬nh lÃ  MPII model vÃ  COCO model. ÄÃ³ chÃ­nh lÃ  tÃªn cá»§a hai bá»™ database mÃ  há» sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã o táº¡o mÃ´ hÃ¬nh. Káº¿t quáº£ tráº£ vá» cá»§a má»— bá»™ database lÃ  khÃ¡c nhau hoÃ n toÃ n.\nVá»›i bá»™ COCO dataset, káº¿t quáº£ tráº£ vá» lÃ  18 Ä‘áº·c trÆ°ng gá»“m cÃ¡c thÃ´ng tin:\n1Nose â€“ 0, Neck â€“ 1, Right Shoulder â€“ 2, Right Elbow â€“ 3, Right Wrist â€“ 4, 2Left Shoulder â€“ 5, Left Elbow â€“ 6, Left Wrist â€“ 7, Right Hip â€“ 8, 3Right Knee â€“ 9, Right Ankle â€“ 10, Left Hip â€“ 11, Left Knee â€“ 12, 4LAnkle â€“ 13, Right Eye â€“ 14, Left Eye â€“ 15, Right Ear â€“ 16, 5Left Ear â€“ 17, Background â€“ 18 Vá»›i bá»™ MPII, káº¿t quáº£ tráº£ vá» lÃ  15 Ä‘áº·c trÆ°ng gá»“m cÃ¡c thÃ´ng tin:\n1Head â€“ 0, Neck â€“ 1, Right Shoulder â€“ 2, Right Elbow â€“ 3, Right Wrist â€“ 4, 2Left Shoulder â€“ 5, Left Elbow â€“ 6, Left Wrist â€“ 7, Right Hip â€“ 8, 3Right Knee â€“ 9, Right Ankle â€“ 10, Left Hip â€“ 11, Left Knee â€“ 12, 4Left Ankle â€“ 13, Chest â€“ 14, Background â€“ 15 Trong pháº§n nÃ y, chÃºng ta sáº½ táº­p trung vÃ o mÃ´ hÃ¬nh MPII, mÃ´ hÃ¬nh COCO sá»­ dá»¥ng tÆ°Æ¡ng tá»±, chá»‰ viá»‡c thay láº¡i Ä‘Æ°á»ng dáº«n file mÃ´ hÃ¬nh lÃ  Ä‘Æ°á»£c.\nBáº¯t Ä‘áº§u code. BÆ°á»›c 1: Download mÃ´ hÃ¬nh.\nNhÃ³m tÃ¡c giáº£ sá»­ dá»¥ng caffe Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh, do Ä‘Ã³, Ä‘á»ƒ sá»­ dá»¥ng Ä‘Æ°á»£c, chÃºng ta cáº§n download file mÃ´ hÃ¬nh á»Ÿ Ä‘Æ°á»ng dáº«n http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_iter_160000.caffemodel vÃ  file cáº¥u hÃ¬nh á»Ÿ Ä‘Æ°á»ng dáº«n http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_deploy_linevec.prototxt. CÃ¡c báº¡n cÃ³ thá»ƒ Ä‘á»ƒ Ä‘Ã¢u Ä‘Ã³ tuá»³ thÃ­ch, á»Ÿ Ä‘Ã¢y tÃ´i Ä‘á»ƒ trong thÆ° má»¥c pose/mpi Ä‘á»ƒ dá»… dÃ ng nháº­n biáº¿t vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c.\nBÆ°á»›c 2: Load mÃ´ hÃ¬nh.\nÄá»ƒ load mÃ´ hÃ¬nh lÃªn bá»™ nhá»› chÃ­nh, Ä‘Æ¡n giáº£n lÃ  chÃºng ta thá»±c hiá»‡n cÃ¢u lá»‡nh sau trong python\n1import cv2 2# Specify the paths for the 2 files 3protoFile = \u0026#34;pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\u0026#34; 4weightsFile = \u0026#34;pose/mpi/pose_iter_160000.caffemodel\u0026#34; 5 6# Read the network into Memory 7net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile) ÄÆ¡n giáº£n quÃ¡ pháº£i khÃ´ng cÃ¡c báº¡n :).\nBÆ°á»›c 3: Äá»c áº£nh vÃ  Ä‘Æ°a áº£nh vÃ o trong mÃ´ hÃ¬nh.\n1 2# Read image 3frame = cv2.imread(\u0026#34;img2.jpg\u0026#34;) 4 5frameCopy = np.copy(frame) 6frameWidth = frame.shape[1] 7frameHeight = frame.shape[0] 8t = time.time() 9# Specify the input image dimensions 10inWidth = 368 11inHeight = 368 12 13# Prepare the frame to be fed to the network 14inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False) 15 16# Set the prepared object as the input blob of the network 17net.setInput(inpBlob) Cháº¯c khÃ´ng cáº§n pháº£i nÃ³i gÃ¬ thÃªm, pháº§n comment chÃº thÃ­ch Ä‘Ã£ mÃ´ táº£ khÃ¡ Ä‘áº§y Ä‘á»§ chá»©c nÄƒng cá»§a tá»«ng pháº§n trong nÃ y rá»“i.\nBÆ°á»›c 4: Thu tháº­p káº¿t quáº£ vÃ  trÃ­ch xuáº¥t Ä‘iá»ƒm Ä‘áº·c trÆ°ng\n1 2frameCopy = frame.copy() 3 4output = net.forward() 5print(\u0026#34;time taken by network : {:.3f}\u0026#34;.format(time.time() - t)) 6H = output.shape[2] 7W = output.shape[3] 8 9nPoints = 15 10POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ] 11 12 13threshold = 0.01 14# Empty list to store the detected keypoints 15points = [] 16for i in range(nPoints): 17 # confidence map of corresponding body\u0026#39;s part. 18 probMap = output[0, i, :, :] 19 20 # Find global maxima of the probMap. 21 minVal, prob, minLoc, point = cv2.minMaxLoc(probMap) 22 23 # Scale the point to fit on the original image 24 x = (frameWidth * point[0]) / W 25 y = (frameHeight * point[1]) / H 26 27 print(prob) 28 29 if prob \u0026gt; threshold : 30 cv2.circle(frame, (int(x), int(y)), 15, (0, 255, 255), thickness=-1, lineType=cv2.FILLED) 31 cv2.putText(frame, \u0026#34;{}\u0026#34;.format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 2, lineType=cv2.LINE_AA) 32 33 # Add the point to the list if the probability is greater than the threshold 34 points.append((int(x), int(y))) 35 else : 36 points.append(None) 37 38# cv2.imshow(\u0026#34;Output-Keypoints\u0026#34;,frame) 39# cv2.waitKey(0) 40# cv2.destroyAllWindows() 41 42cv2.imwrite(\u0026#34;dot_keypoint.png\u0026#34;,frame) 43 44# Draw Skeleton 45for pair in POSE_PAIRS: 46 partA = pair[0] 47 partB = pair[1] 48 49 if points[partA] and points[partB]: 50 cv2.line(frameCopy, points[partA], points[partB], (0, 255, 255), 2) 51 cv2.circle(frameCopy, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED) 52 cv2.circle(frameCopy, points[partB], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED) 53 54 55cv2.imwrite(\u0026#34;line_keypoint.png\u0026#34;,frameCopy) Káº¿t quáº£ cá»§a giÃ¡ trá»‹ output lÃ  má»™t ma tráº­n 4D, vá»›i Ã½ nghÄ©a cá»§a má»—i chiá»u nhÆ° sau:\nChiá»u Ä‘áº§u tiÃªn lÃ  image ID (Ä‘á»‹nh danh áº£nh trong trÆ°á»ng há»£p báº¡n truyá»n nhiá»u áº£nh vÃ o máº¡ng) Chiá»u thá»© 2 lÃ  chá»‰ sá»‘ cá»§a cÃ¡c Ä‘iá»ƒm Ä‘áº·c trÆ°ng. Táº­p MPI tráº£ vá» táº­p gá»“m 44 Ä‘iá»ƒm dá»¯ liá»‡u, ta chá»‰ sá»­ dá»¥ng má»™t vÃ i Ä‘iá»ƒm dá»¯ liá»‡u tÆ°Æ¡ng á»©ng vá»›i vá»‹ trÃ­ cÃ¡c Ä‘iá»ƒm Ä‘áº·c trÆ°ng mÃ  chÃºng ta quan tÃ¢m. Chiá»u thá»© 3 lÃ  height cá»§a output map. Chiá»u thá»© 4 lÃ  width cá»§a output map. Má»™t lÆ°u Ã½ á»Ÿ Ä‘Ã¢y lÃ  tÃ´i cÃ³ sá»­ dá»¥ng Ä‘áº·t giÃ¡ trá»‹ cháº·n dÆ°á»›i threshold Ä‘á»ƒ giáº£m thiá»ƒu sá»± sai sÃ³t do nháº­n diá»‡n sai. VÃ  káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c lÃ  hai hÃ¬nh bÃªn dÆ°á»›i: Háº¹n gáº·p láº¡i cÃ¡c báº¡n á»Ÿ nhá»¯ng bÃ i viáº¿t tiáº¿p theo.\n","date":"Oct 4, 2018","img":"","permalink":"/blog/2018-10-04-deep-learning-base-human-pose-estimation/","series":null,"tags":["Machine learning","Deeplearning","pose estimation"],"title":"Deep Learning Based Human Pose Estimation Using OpenCV"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u KhÃ¡i niá»‡n Epoch Batch Size Iterations Táº¡i sao pháº£i dÃ¹ng hÆ¡n 1 Epoch. Sá»‘ láº§n láº·p tá»‘i Æ°u lÃ  bao nhiÃªu? Repeat Regularization Images Lá»i má»Ÿ Ä‘áº§u Khi má»›i báº¯t Ä‘áº§u bÆ°á»›c vÃ o tháº¿ giá»›i cá»§a ML/DL chÃºng ta sáº½ báº¯t gáº·p cÃ¡c thuáº­t ngá»¯ Epoch - Batch size vÃ  Iterations. VÃ  sáº½ cáº£m tháº¥y bá»‘i rá»‘i vÃ¬ chÃºng khÃ¡ giá»‘ng nhau, nhÆ°ng thá»±c táº¿ lÃ  chÃºng khÃ¡c xa nhau.\nÄá»ƒ cho dá»… hÃ¬nh dung, mÃ¬nh láº¥y vÃ­ dá»¥ vá» viá»‡c Äƒn cÆ¡m. ChÃºng ta khÃ´ng thá»ƒ Äƒn má»™t láº§n háº¿t má»™t chÃ©n cÆ¡m Ä‘Æ°á»£c, mÃ  pháº£i má»—i láº§n Äƒn pháº£i xÃºc tá»«ng muá»—n Äƒn. XÃºc láº§n lÆ°á»£t khi háº¿t bÃ¡t thá»© nháº¥t, chÃºng ta láº¡i Äƒn tiáº¿p bÃ¡t thá»© 2, bÃ¡t thá»© 3 \u0026hellip; Ä‘áº¿n khi no, káº¿t thÃºc bá»¯a Äƒn.\nLiÃªn tÆ°á»Ÿng giá»¯a viá»‡t Äƒn cÆ¡m vÃ  cÃ¡c thuáº­t ngá»¯ epoch, batch size, iteration nhÆ° sau:\nbatch size: Sá»‘ háº¡t cÆ¡m trong 1 láº§n xÃºc.\nIteration : Sá»‘ láº§n xÃºc cÆ¡m háº¿t 1 bÃ¡t.\nepoch : Sá»‘ bÃ¡t cÆ¡m báº¡n Äƒn trong 1 bá»¯a Äƒn.\nHáº¿t pháº§n diá»…n giáº£i báº±ng vÃ­ dá»¥. Äáº¿n pháº§n viáº¿t hÃ n lÃ¢m bÃªn dÆ°á»›i, náº¿u báº¡n nÃ o Ä‘Ã£ hiá»ƒu rá»“i thÃ¬ cÃ³ thá»ƒ bá» qua, báº¡n nÃ o muá»‘n Ä‘Ã o sÃ¢u thÃªm lÃ½ do thÃ¬ xem mÃ¬nh diá»…n giáº£i bÃªn dÆ°á»›i.\nÄá»ƒ hiá»ƒu rÃµ sá»± khÃ¡c biá»‡t giá»¯a chÃºng, cÃ¡c báº¡n cáº§n tÃ¬m hiá»ƒu má»™t khÃ¡i niá»‡m vÃ´ cÃ¹ng quan trá»ng trong machine learning - Gradient Descent.\nÄá»‹nh nghÄ©a ngáº¯n gá»n cá»§a Gradient Descent:\nGradient Descent lÃ  thuáº­t toÃ¡n láº·p tá»‘i Æ°u (iteractive optimization algorithm) Ä‘Æ°á»£c sá»­ dá»¥ng trong machine learning Ä‘á»ƒ tÃ¬m káº¿t quáº£ tá»‘t nháº¥t (minima of a curve).\nTrong Ä‘Ã³:\n..* Gradient cÃ³ nghÄ©a lÃ  tá»· lá»‡ cá»§a Ä‘á»™ nghiÃªng cá»§a Ä‘Æ°á»ng dá»‘c.\n..* Descent lÃ  tá»« viáº¿t táº¯t cá»§a decending - nghÄ©a lÃ  giáº£m.\nThuáº­t toÃ¡n sáº½ láº·p Ä‘i láº·p láº¡i nhiá»u láº§n Ä‘á»ƒ tÃ¬m ra Ä‘Æ°á»£c cá»±c tiá»ƒu.\nhttps://medium.com/onfido-tech/machine-learning-101-be2e0a86c96a Nguá»“n áº£nh\nCÃ¡c báº¡n quan sÃ¡t hÃ¬nh phÃ­a trÃªn bÃªn trÃ¡i, ban Ä‘áº§u, bÆ°á»›c nháº£y khÃ¡ lá»›n, nghÄ©a lÃ  giÃ¡ trá»‹ cost lá»›n, vÃ  sau má»™t vÃ i láº§n láº·p, Ä‘iá»ƒm cháº¥m Ä‘en Ä‘i xuá»‘ng dáº§n, vÃ  giÃ¡ trá»‹ cost nhá» dáº§n theo. MÃ´ hÃ¬nh há»™i tá»¥ dáº§n dáº§n Ä‘áº¿n khi cost \u0026lt;= epselon\nChÃºng ta sá»­ dá»¥ng thuáº­t ngá»¯ epochs, batch size, iterations khi chÃºng ta cáº§n pháº£i trainning mÃ´ hÃ¬nh machine learning, mÃ  táº­p trainset cá»§a chÃºng ta quÃ¡ (ráº¥t) lá»›n (vd 10 triá»‡u máº«u, vÃ­ dá»¥ train mÃ´ hÃ¬nh nháº­n dáº¡ng khuÃ´n máº·t vá»›i táº­p ms-celeb-1m). LÃºc nÃ y cÃ¡c khÃ¡i niá»‡m trÃªn má»›i trá»Ÿ nÃªn rÃµ rÃ ng, cÃ²n vá»›i trÆ°á»ng há»£p dá»¯ liá»‡u nhá» thÃ¬ chÃºng khÃ¡ tÆ°Æ¡ng tá»± nhau.\nKhÃ¡i niá»‡n Epoch Má»™t Epoch Ä‘Æ°á»£c tÃ­nh lÃ  khi chÃºng ta Ä‘Æ°a táº¥t cáº£ dá»¯ liá»‡u trong táº­p train vÃ o máº¡ng neural network 1 láº§n. VÃ­ dá»¥, báº¡n cÃ³ 10 bá»©c hÃ¬nh trong táº­p train, báº¡n Ä‘em háº¿t toÃ n bá»™ 10 bá»©c hÃ¬nh Ä‘Ã³ cho mÃ´ hÃ¬nh há»c á»Ÿ láº§n thá»© nháº¥t, báº¡n Ä‘Ã£ train Ä‘Æ°á»£c má»™t epoch. Sau Ä‘Ã³, báº¡n láº¡i quay láº¡i vá»‹ trÃ­ hÃ¬nh ban Ä‘áº§u rá»“i cho toÃ n bá»™ 10 bá»©c hÃ¬nh Ä‘Ã³ há»c, báº¡n cÃ³ thÃªm 1 epoch ná»¯a, váº­y lÃ  báº¡n Ä‘Ã£ train 2 epoch, báº¡n láº·p láº¡i viá»‡c nÃ y 100 láº§n , suy ra báº¡n Ä‘Ã£ train 100 epoch.\nKhi dá»¯ liá»‡u quÃ¡ lá»›n, chÃºng ta khÃ´ng thá»ƒ Ä‘Æ°a háº¿t táº¥t cáº£ táº­p dá»¯ liá»‡u vÃ o Ä‘á»ƒ huáº¥n luyá»‡n trong 1 láº§n train Ä‘Æ°á»£c, vÃ¬ báº¡n cáº§n má»™t siÃªu mÃ¡y tÃ­nh cÃ³ lÆ°á»£ng RAM vÃ  GPU RAM cá»±c lá»›n Ä‘á»ƒ lÆ°u trá»¯ toÃ n bá»™ hÃ¬nh áº£nh trÃªn, Ä‘iá»u nÃ y lÃ  báº¥t kháº£ thi Ä‘á»‘i vá»›i ngÆ°á»i dÃ¹ng bÃ¬nh thÆ°á»ng, phÃ²ng lab nhá», hoáº·c cÃ¡c há»‡ thá»‘ng mÃ¡y tÃ­nh hiá»‡n táº¡i. Buá»™c lÃ²ng chÃºng ta pháº£i chia nhá» táº­p dá»¯ liá»‡u ra, vÃ  khÃ¡i niá»‡m batch hÃ¬nh thÃ nh.\nBatch Size Batch size lÃ  sá»‘ lÆ°á»£ng máº«u dá»¯ liá»‡u trong má»™t láº§n train. VÃ­ dá»¥, trong bÃ i toÃ¡n phÃ¢n loáº¡i chÃ³ mÃ¨o, chá»n batch size =32, nghÄ©a lÃ  1 láº§n train ta sáº½ cho ngáº«u nhiÃªn 32 bá»©c nhÃ¬n chÃ³ hoáº·c mÃ¨o cháº¡y lan truyá»n tiáº¿n trong máº¡ng neural network. Tiáº¿p theo báº¡n quÄƒng tiáº¿p 32 hÃ¬nh ngáº«u nhiÃªn, khÃ´ng láº·p vá»›i cÃ¡c hÃ¬nh trÆ°á»›c Ä‘Ã³, vÃ o máº¡ng, quÄƒng Ä‘áº¿n khi nÃ o khÃ´ng cÃ²n hÃ¬nh nÃ o cÃ³ thá»ƒ quÄƒng vÃ o ná»¯a -\u0026gt; báº¡n hoÃ n thÃ nh 1 epoch.\nIterations Iterations lÃ  sá»‘ lÆ°á»£ng batchs cáº§n Ä‘á»ƒ hoÃ n thÃ nh 1 epoch.\n$$Iterations = data size / batch size$$\nVÃ­ dá»¥ chÃºng ta cÃ³ táº­p dá»¯ liá»‡u cÃ³ 20,000 máº«u, batch size lÃ  500, váº­y chÃºng ta cáº§n 40 láº§n láº·p (iteration) Ä‘á»ƒ hoÃ n thÃ nh 1 epoch.\nTáº¡i sao pháº£i dÃ¹ng hÆ¡n 1 Epoch. CÃ¢u tráº£ lá»i á»Ÿ Ä‘Ã¢y lÃ  táº¡i vÃ¬ chÃºng ta Ä‘ang dÃ¹ng thuáº­t toÃ¡n tá»‘i Æ°u lÃ  Gradient Descent. Thuáº­t toÃ¡n nÃ y Ä‘Ã²i há»i chÃºng ta pháº£i Ä‘em toÃ n bá»™ dá»¯ liá»‡u qua máº¡ng má»™t vÃ i láº§n Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c káº¿t quáº£ tá»‘i Æ°u. VÃ¬ váº­y, dÃ¹ng 1 epoch tháº­t sá»± khÃ´ng Ä‘á»§ Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c káº¿t quáº£ tá»‘t nháº¥t.\nVá»›i viá»‡c chá»‰ sá»­ dá»¥ng 1 láº§n láº·p, xÃ¡c suáº¥t ráº¥t cao lÃ  dá»¯ liá»‡u sáº½ bá»‹ underfitting(nhÆ° hÃ¬nh mÃ´ táº£ bÃªn dÆ°á»›i).\nKhi sá»‘ láº§n láº·p tÄƒng dáº§n, tráº¡ng thÃ¡i cá»§a mÃ´ hÃ¬nh sáº½ chuyá»ƒn dáº§n tá»« underfitting sang optimal vÃ  sau Ä‘Ã³ lÃ  overfitting (thÃ´ng thÆ°á»ng lÃ  váº­y, trá»« khi mÃ´ hÃ¬nh huáº¥n luyá»‡n cá»§a báº¡n Ä‘ang sá»­ dá»¥ng quÃ¡ Ä‘Æ¡n giáº£n, quÃ¡ Ã­t trá»ng sá»‘ thÃ¬ chÃºng khÃ´ng thá»ƒ nÃ o overfitting ná»•i).\nChÃºng ta cÃ³ thá»ƒ dÃ¹ng 1 epoch Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh, vá»›i Ä‘iá»u kiá»‡n lÃ  ta sá»­ dá»¥ng thuáº­t toÃ¡n tá»‘i Æ°u khÃ´ng pháº£i lÃ  gradient descent.\nSá»‘ láº§n láº·p tá»‘i Æ°u lÃ  bao nhiÃªu? Tiáº¿c ráº±ng khÃ´ng cÃ³ cÃ¢u tráº£ lá»i cho cÃ¢u há»i nÃ y. Phá»¥ thuá»™c hoÃ n toÃ n vÃ o nhiá»u yáº¿u tá»‘. Má»¥c tiÃªu chung lÃ  ta sáº½ láº·p Ä‘áº¿n khi nÃ o há»™i tá»¥. CÃ³ má»™t sá»‘ phÆ°Æ¡ng phÃ¡p giÃºp chÃºng ta xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh Ä‘Ã£ Ä‘á»©ng á»Ÿ ngÆ°á»¡ng cá»±c tiá»ƒu cá»¥c bá»™ rá»“i, khÃ´ng thá»ƒ xuá»‘ng hÆ¡n Ä‘Æ°á»£c ná»¯a.\nCÃ¡c báº¡n cÃ³ thá»ƒ tÃ¬m hiá»ƒu vá»›i tá»« khÃ³a early stopping.\nRepeat update 13/01/2025\nGáº§n Ä‘Ã¢y, vá»›i sá»± phÃ¡t triá»ƒn cá»§a stable diffusion vÃ  flux, chÃºng ta cÃ³ thÃªm tham sá»‘ Repeat, Ä‘Æ°á»£c hiá»ƒu lÃ  sá»‘ láº§n 1 hÃ¬nh sáº½ Ä‘Æ°á»£c láº·p láº¡i trong quÃ¡ trÃ¬nh train.\nHiá»ƒu Ä‘Æ¡n giáº£n lÃ  khi train lora, trong 1 batch, 1 hÃ¬nh trong batch Ä‘Ã³ sáº½ Repeat x láº§n\nMá»¥c tiÃªu cá»§a Repeat trong stable diffusion\nBalance the number of training images to the regularization images. The number of regularization images is larger than the training, so it is required to repeat training images for using all regularization images in the epoch.\nControl \u0026lsquo;weight\u0026rsquo; over folders. If you have high quality images and low quality images, you can set higher number of repeats for high quality images, and lower for low quality.\nRegularization Images HÃ¬nh áº£nh Ä‘iá»u chá»‰nh (Regularization images) lÃ  cÃ¡c hÃ¬nh áº£nh Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° má»™t pháº§n cá»§a quÃ¡ trÃ¬nh Ä‘iá»u chá»‰nh nháº±m cáº£i thiá»‡n sá»± á»•n Ä‘á»‹nh vÃ  hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u (deep learning).\nQuÃ¡ trÃ¬nh nÃ y giÃºp ngÄƒn mÃ´ hÃ¬nh há»c quÃ¡ má»©c tá»« dá»¯ liá»‡u huáº¥n luyá»‡n, duy trÃ¬ sá»± cÃ¢n báº±ng giá»¯a cÃ¡c lá»›p, vÃ  báº£o toÃ n tÃ­nh linh hoáº¡t trong viá»‡c táº¡o ra hÃ¬nh áº£nh má»›i.\nRegularization giÃºp giáº£i quyáº¿t hai váº¥n Ä‘á» chÃ­nh: quÃ¡ khá»›p (overfitting) vÃ  báº£o toÃ n lá»›p (class preservation).\nBáº£o ToÃ n Lá»›p (Class Preservation):\nKhi táº¡o ra cÃ¡c hÃ¬nh áº£nh Ä‘iá»u chá»‰nh, báº¡n Ä‘ang Ä‘á»‹nh nghÄ©a má»™t \u0026ldquo;lá»›p\u0026rdquo; cá»§a nhá»¯ng gÃ¬ báº¡n muá»‘n nghá»‹ch Ä‘áº£o. VÃ­ dá»¥, náº¿u báº¡n Ä‘ang cá»‘ nghá»‹ch Ä‘áº£o má»™t chiáº¿c mÃ¡y bay má»›i, báº¡n cÃ³ thá»ƒ táº¡o má»™t loáº¡t hÃ¬nh áº£nh vá» mÃ¡y bay Ä‘á»ƒ lÃ m hÃ¬nh áº£nh Ä‘iá»u chá»‰nh. Äiá»u nÃ y giÃºp Ä‘áº£m báº£o ráº±ng quÃ¡ trÃ¬nh huáº¥n luyá»‡n khÃ´ng bá»‹ lá»‡ch sang má»™t lá»›p khÃ¡c, cháº³ng háº¡n nhÆ° \u0026ldquo;Ã´ tÃ´\u0026rdquo; hoáº·c \u0026ldquo;xe Ä‘áº¡p\u0026rdquo;. Tháº­m chÃ­, nÃ³ cÃ²n giÃºp ngÄƒn viá»‡c mÃ´ hÃ¬nh bá»‹ nghiÃªng vá» hÆ°á»›ng \u0026ldquo;mÃ¡y bay Ä‘á»“ chÆ¡i\u0026rdquo; náº¿u báº¡n sá»­ dá»¥ng cÃ¡c tham chiáº¿u thá»±c táº¿ thay vÃ¬ cÃ¡c diá»…n giáº£i trá»«u tÆ°á»£ng. Chá»‘ng QuÃ¡ Khá»›p (Overfitting):\nNhá»¯ng hÃ¬nh áº£nh Ä‘iá»u chá»‰nh nÃ y cÅ©ng Ä‘Æ°á»£c sá»­ dá»¥ng trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng cÃ¡c hÃ¬nh áº£nh báº¡n Ä‘ang cá»‘ nghá»‹ch Ä‘áº£o khÃ´ng bá»‹ quÃ¡ khá»›p. Náº¿u quÃ¡ khá»›p xáº£y ra, cÃ¡c hÃ¬nh áº£nh Ä‘Æ°á»£c táº¡o ra cÃ³ thá»ƒ giá»‘ng há»‡t vá»›i táº­p huáº¥n luyá»‡n, lÃ m máº¥t kháº£ nÄƒng chá»‰nh sá»­a cá»§a chÃºng. Má»™t trong nhá»¯ng váº¥n Ä‘á» cá»§a nghá»‹ch Ä‘áº£o vÄƒn báº£n (textual inversion) lÃ  báº¡n cÃ³ thá»ƒ máº¥t kháº£ nÄƒng chá»‰nh sá»­a hÃ¬nh áº£nh trong quÃ¡ trÃ¬nh nghá»‹ch Ä‘áº£o, Ä‘áº·c biá»‡t khi huáº¥n luyá»‡n quÃ¡ lÃ¢u. Viá»‡c thÃªm hÃ¬nh áº£nh Ä‘iá»u chá»‰nh vÃ o quÃ¡ trÃ¬nh huáº¥n luyá»‡n giÃºp ngÄƒn cháº·n váº¥n Ä‘á» nÃ y. Hiá»‡n Tráº¡ng Cá»§a Dreambooth:\nVá»›i cÃ¡ch triá»ƒn khai hiá»‡n táº¡i cá»§a Dreambooth, má»™t sá»‘ hiá»‡n tÆ°á»£ng lá»‡ch hÆ°á»›ng (drifting) váº«n cÃ³ thá»ƒ xáº£y ra. VÃ­ dá»¥: náº¿u báº¡n nghá»‹ch Ä‘áº£o hÃ¬nh áº£nh má»™t con áº¿ch, cÃ¡c tháº¿ há»‡ má»›i cÃ³ thá»ƒ cÃ³ Ä‘áº·c Ä‘iá»ƒm giá»‘ng áº¿ch. Tuy nhiÃªn, mÃ´ hÃ¬nh váº«n hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t miá»…n lÃ  báº¡n giá»¯ má»i thá»© há»£p lÃ½ vá»›i dá»¯ liá»‡u Ä‘Ã£ huáº¥n luyá»‡n. TÃ³m láº¡i, hÃ¬nh áº£nh Ä‘iá»u chá»‰nh khÃ´ng chá»‰ giÃºp duy trÃ¬ tÃ­nh nguyÃªn báº£n cá»§a lá»›p mÃ  báº¡n Ä‘ang lÃ m viá»‡c, mÃ  cÃ²n giáº£m nguy cÆ¡ quÃ¡ khá»›p, cáº£i thiá»‡n kháº£ nÄƒng chá»‰nh sá»­a vÃ  tÃ­nh linh hoáº¡t cá»§a cÃ¡c hÃ¬nh áº£nh Ä‘Æ°á»£c táº¡o ra.\nNguá»“n cá»§a pháº§n Regularization Images https://www.reddit.com/r/StableDiffusion/comments/xu1ill/comment/iqu81m7/\nCáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi bÃ i viáº¿t.\nNguá»“n: https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9\n","date":"Oct 2, 2018","img":"https://unsplash.it/1920/1080?image=99","permalink":"/blog/2018-10-02-understanding-epoch-batchsize-iterations/","series":null,"tags":["Machine learning","Deeplearning","Epoch","Batch Size","Iteration"],"title":"PhÃ¢n Biá»‡t Epoch - Batch Size VÃ  Iterations"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Chuáº©n bá»‹ dá»¯ liá»‡u Loading vÃ  parsing dá»¯ liá»‡u. Collaborative Filtering Chá»n cÃ¡c tham sá»‘ cho ALS XÃ¢y dá»±ng mÃ´ hÃ¬nh vá»›i táº­p dá»¯ liá»‡u large XÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n phim Dá»± Ä‘oÃ¡n rating cá»§a 1 cÃ¡ nhÃ¢n LÆ°u trá»¯ mÃ´ hÃ¬nh Lá»i má»Ÿ Ä‘áº§u MovieLens lÃ  má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i cÃ¡ch Ä‘Ã¢y nhiá»u nÄƒm. HÃ´m nay, mÃ¬nh sáº½ sá»­ dá»¥ng táº­p dá»¯ liá»‡u nÃ y vÃ  mÃ´ hÃ¬nh ALS cá»§a spark Ä‘á»ƒ xÃ¢y dá»±ng chÆ°Æ¡ng trÃ¬nh dá»± Ä‘oÃ¡n phim cho ngÆ°á»i dÃ¹ng.\nChuáº©n bá»‹ dá»¯ liá»‡u CÃ¡c báº¡n cÃ³ thá»ƒ download táº­p dá»¯ liá»‡u MovieLens á»Ÿ link https://grouplens.org/datasets/movielens/. CÃ¡c báº¡n cÃ³ thá»ƒ download trá»±c tiáº¿p 2 file nÃ©n á»Ÿ link http://files.grouplens.org/datasets/movielens/ml-latest-small.zip vÃ  link http://files.grouplens.org/datasets/movielens/ml-latest.zip.\ná» trÃªn bao gá»“m 2 táº­p dá»¯ liá»‡u. chÃºng ta táº¡o thÆ° má»¥c datasets vÃ  download rá»“i bá» chÃºng vÃ o trong thÆ° má»¥c Ä‘áº¥y.\n1complete_dataset_url = \u0026#39;http://files.grouplens.org/datasets/movielens/ml-latest.zip\u0026#39; 2small_dataset_url = \u0026#39;http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\u0026#39; 3 4import os 5 6datasets_path = \u0026#39;datasets\u0026#39; 7if not os.path.exists(datasets_path): 8 os.makedirs(datasets_path)) 9 10complete_dataset_path = os.path.join(datasets_path, \u0026#39;ml-latest.zip\u0026#39;) 11small_dataset_path = os.path.join(datasets_path, \u0026#39;ml-latest-small.zip\u0026#39;) 12 13import urllib 14import zipfile 15 16if not os.path.exists(small_dataset_url): 17\tsmall_f = urllib.urlretrieve (small_dataset_url, small_dataset_path)#Download 18\twith zipfile.ZipFile(small_dataset_path, \u0026#34;r\u0026#34;) as z:#Giáº£i nÃ©n 19\tz.extractall(datasets_path) 20if not os.path.exists(small_dataset_url): 21\tcomplete_f = urllib.urlretrieve (complete_dataset_url, complete_dataset_path)#Download 22\twith zipfile.ZipFile(complete_dataset_path, \u0026#34;r\u0026#34;) as z:#Giáº£i nÃ©n 23\tz.extractall(datasets_path) Trong thÆ° má»¥c giáº£i nÃ©n, chÃºng ta sáº½ cÃ³ cÃ¡c file ratings.csv, movies.csv, tags.csv, links.csv, README.txt.\nLoading vÃ  parsing dá»¯ liá»‡u. Má»—i dÃ²ng trong táº­p ratings.csv cÃ³ Ä‘á»‹nh dáº¡ng \u0026quot;userId,movieId,rating,timestamp\u0026quot;.\nMá»—i dÃ²ng trong táº­p movies.csv cÃ³ Ä‘á»‹nh dáº¡ng \u0026quot;movieId,title,genres\u0026quot;.\nMá»—i dÃ²ng trong táº­p tags.csv cÃ³ Ä‘á»‹nh dáº¡ng \u0026quot;userId,movieId,tag,timestamp\u0026quot;.\nMá»—i dÃ²ng trong táº­p links.csv cÃ³ Ä‘á»‹nh dáº¡ng \u0026quot;movieId,imdbId,tmdbId\u0026quot;.\nTÃ³m láº¡i, cÃ¡c trÆ°á»ng dá»¯ liá»‡u trong cÃ¡c file csv Ä‘á»u ngÄƒn cÃ¡ch nhau bá»Ÿi dáº¥u pháº©y (,). Trong python, ta cÃ³ thá»ƒ dÃ¹ng hÃ m split Ä‘á»ƒ cáº¯t chÃºng ra. Sau Ä‘Ã³ sáº½ load toÃ n bá»™ dá»¯ liá»‡u lÃªn RDDs.\nLÆ°u Ã½ nhá»:\ná» táº­p dá»¯ liá»‡u ratings, chÃºng ta chá»‰ giá»¯ láº¡i cÃ¡c trÆ°á»ng (UserID, MovieID, Rating) bá» Ä‘i trÆ°á»ng timestamp vÃ¬ khÃ´ng cáº§n thiáº¿t. á» táº­p dá»¯ liá»‡u movies chÃºng ta giá»¯ láº¡i trÆ°á»ng (MovieID, Title) vÃ  bá» Ä‘i trÆ°á»ng genres vÃ¬ lÃ½ do tÆ°Æ¡ng tá»±. 1small_ratings_file = os.path.join(datasets_path, \u0026#39;ml-latest-small\u0026#39;, \u0026#39;ratings.csv\u0026#39;) 2small_ratings_raw_data = sc.textFile(small_ratings_file) 3small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0] 4small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header).map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache() 5print(small_ratings_data.take(3)) #Hiá»‡n thá»‹ top 3 ratting Ä‘áº§u tiÃªn 6 7small_movies_file = os.path.join(datasets_path, \u0026#39;ml-latest-small\u0026#39;, \u0026#39;movies.csv\u0026#39;) 8 9small_movies_raw_data = sc.textFile(small_movies_file) 10small_movies_raw_data_header = small_movies_raw_data.take(1)[0] 11 12small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\ 13 .map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (tokens[0],tokens[1])).cache() 14 15small_movies_data.take(3) #Hiá»‡n thá»‹ top 3 movie Ä‘áº§u tiÃªn Pháº§n tiáº¿p theo, chÃºng ta sáº½ tÃ¬m hiá»ƒu lá»c cá»™ng tÃ¡c (Collaborative Filtering) vÃ  cÃ¡ch sá»­ dá»¥ng Spark MLlib Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± bÃ¡o.\nCollaborative Filtering á» Ä‘Ã¢y, tÃ´i sáº½ khÃ´ng Ä‘á» cáº­p Ä‘áº¿n lá»c cá»™ng tÃ¡c lÃ  gÃ¬, cÃ¡c báº¡n cÃ³ nhu cáº§u tÃ¬m hiá»ƒu cÃ³ thá»ƒ xem á»Ÿ bÃ i post khÃ¡c hoáº·c tham kháº£o trÃªn wiki. ChÃºng ta sáº½ táº­p trung vÃ o tÃ¬m hiá»ƒu cÃ¡ch sá»­ dá»¥ng ALS trong thÆ° viá»‡n MLlib cá»§a Spark. CÃ¡c tham sá»‘ cá»§a thuáº­t toÃ¡n nÃ y bao gá»“m:\nnumBlocks: sá»‘ lÆ°á»£ng block Ä‘Æ°á»£c sá»­ dá»¥ng trong tÃ­nh toÃ¡n song song (-1 vá»›i Ã½ nghÄ©a lÃ  auto configure).\nrank: sá»‘ lÆ°á»£ng nhÃ¢n tá»‘ áº©n (latent factor) trong mÃ´ hÃ¬nh.\niterations: sá»‘ láº§n láº·p.\nlambda: tham sá»‘ cá»§a chuáº©n hoÃ¡(regularization ) trong ALS.\nimplicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\nalpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations.\nChá»n cÃ¡c tham sá»‘ cho ALS Äá»ƒ chá»n Ä‘Æ°á»£c cÃ¡c tham sá»‘ tá»‘t nháº¥t cho mÃ´ hÃ¬nh ALS, chÃºng ta sáº½ sá»­ dá»¥ng táº­p small Ä‘á»ƒ grid search. Äáº§u tiÃªn, chÃºng ta chia táº­p dá»¯ liá»‡u thÃ nh 3 pháº§n lÃ  táº­p train, táº­p vali vÃ  táº­p test. Sau Ä‘Ã³ tiáº¿n hÃ nh huáº¥n luyá»‡n trÃªn táº­p train vÃ  predict trÃªn táº­p valid Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c tham sá»‘ tá»‘t nháº¥t. Cuá»‘i cÃ¹ng Ä‘Ã¡nh giÃ¡ káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c trÃªn táº­p test.\n1training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0) 2validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1])) 3test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1])) 4 5from pyspark.mllib.recommendation import ALS 6import math 7 8seed = 5L 9iterations = 10 10regularization_parameter = 0.1 11ranks = [4, 8, 12] 12errors = [0, 0, 0] 13err = 0 14tolerance = 0.02 15 16min_error = float(\u0026#39;inf\u0026#39;) 17best_rank = -1 18best_iteration = -1 19for rank in ranks: 20 model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations, 21 lambda_=regularization_parameter) 22 predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2])) 23 rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions) 24 error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) 25 errors[err] = error 26 err += 1 27 print(\u0026#39;For rank %s the RMSE is %s\u0026#39; % (rank, error)) 28 if error \u0026lt; min_error: 29 min_error = error 30 best_rank = rank 31 32print(\u0026#39;The best model was trained with rank %s\u0026#39; % best_rank) Káº¿t quáº£ sau khi thá»±c hiá»‡n Ä‘oáº¡n code trÃªn lÃ :\n1For rank 4 the RMSE is 0.963681878574 2For rank 8 the RMSE is 0.96250475933 3For rank 12 the RMSE is 0.971647563632 4The best model was trained with rank 8 Tiáº¿n hÃ nh thá»±c hiá»‡n test.\n1model_test = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations, 2 lambda_=regularization_parameter) 3predictions = model_test.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2])) 4rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions) 5error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) 6 7print(\u0026#39;For testing data the RMSE is %s\u0026#39; % (error)) 1For testing data the RMSE is 0.972342381898 Xem ká»¹ hÆ¡n má»™t chÃºt vá» dá»¯ liá»‡u mÃ  spark tráº£ vá» cho chÃºng ta. Vá»›i predictions vÃ  rates_and_preds, ta cÃ³:\n1print(predictions.take(3)) 1[((32, 4018), 3.280114696166238), 2 ((375, 4018), 2.7365714977314086), 3 ((674, 4018), 2.510684514310653)] Táº­p dá»¯ liá»‡u tráº£ vá» bao gá»“m cáº·p (UserID, MovieID) vÃ  Rating (tÆ°Æ¡ng á»©ng vá»›i colum 0, column 1 vÃ  column 2 á»Ÿ trÃªn),Ä‘Æ°á»£c hiá»ƒu á»Ÿ Ä‘Ã¢y lÃ  vá»›i ngÆ°á»i dÃ¹ng UserID vÃ  phim MovieID thÃ¬ mÃ´ hÃ¬nh sáº½ dá»± Ä‘oÃ¡n ngÆ°á»i dÃ¹ng sáº½ rating káº¿t quáº£ Rating.\nSau Ä‘Ã³ chÃºng ta sáº½ ná»‘i(join) chÃºng vá»›i táº­p valid tÆ°Æ¡ng á»©ng theo cáº·p (UserID, MovieID), káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c lÃ :\n1rates_and_preds.take(3) 1[((558, 788), (3.0, 3.0419325487471403)), 2 ((176, 3550), (4.5, 3.3214065001580986)), 3 ((302, 3908), (1.0, 2.4728711204440765))] Viá»‡c cÃ²n láº¡i lÃ  chÃºng ta sáº½ tÃ­nh trung bÃ¬nh Ä‘á»™ lá»—i báº±ng hÃ m mean() vÃ  sqlt().\nXÃ¢y dá»±ng mÃ´ hÃ¬nh vá»›i táº­p dá»¯ liá»‡u large Tiáº¿p theo, chÃºng ta sáº½ sá»­ dá»¥ng táº­p dá»± liá»‡u bá»± hÆ¡n Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh. CÃ¡ch thá»±c hiá»‡n y chang nhÆ° táº­p dá»¯ liá»‡u nhá» Ä‘Ã£ Ä‘Æ°á»£c trÃ¬nh bÃ y á»Ÿ trÃªn, nÃªn tÃ´i sáº½ bá» qua má»™t sá»‘ giáº£i thÃ­ch khÃ´ng cáº§n thiáº¿t Ä‘á»ƒ trÃ¡nh láº·p láº¡i.\n1# Load the complete dataset file 2complete_ratings_file = os.path.join(datasets_path, \u0026#39;ml-latest\u0026#39;, \u0026#39;ratings.csv\u0026#39;) 3complete_ratings_raw_data = sc.textFile(complete_ratings_file) 4complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0] 5 6# Parse 7complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\ 8 .map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache() 9 10print(\u0026#34;There are %s recommendations in the complete dataset\u0026#34; % (complete_ratings_data.count())) 1There are 21063128 recommendations in the complete dataset Tiáº¿n hÃ nh train vÃ  test.\n1training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0) 2 3complete_model = ALS.train(training_RDD, best_rank, seed=seed,iterations=iterations, lambda_=regularization_parameter) 4 5test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1])) 6 7predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2])) 8rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions) 9error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) 10 11print(\u0026#39;For testing data the RMSE is %s\u0026#39; % (error)) 1For testing data the RMSE is 0.82183583368 XÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n phim 1complete_movies_file = os.path.join(datasets_path, \u0026#39;ml-latest\u0026#39;, \u0026#39;movies.csv\u0026#39;) 2complete_movies_raw_data = sc.textFile(complete_movies_file) 3complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0] 4 5# Parse 6complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\ 7 .map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache() 8 9complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1])) 10 11print(\u0026#34;There are %s movies in the complete dataset\u0026#34; % (complete_movies_titles.count())) 1There are 27303 movies in the complete dataset 1def get_counts_and_averages(ID_and_ratings_tuple): 2 nratings = len(ID_and_ratings_tuple[1]) 3 return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings) 4 5movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey()) 6movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages) 7movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0])) Giáº£ sá»­ chÃºng ta cÃ³ 1 ngÆ°á»i dÃ¹ng má»›i, vá»›i cÃ¡c ratting nhÆ° sau:\n1new_user_ID = 0 2 3# The format of each line is (userID, movieID, rating) 4new_user_ratings = [ 5 (0,260,4), # Star Wars (1977) 6 (0,1,3), # Toy Story (1995) 7 (0,16,3), # Casino (1995) 8 (0,25,4), # Leaving Las Vegas (1995) 9 (0,32,4), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995) 10 (0,335,1), # Flintstones, The (1994) 11 (0,379,1), # Timecop (1994) 12 (0,296,3), # Pulp Fiction (1994) 13 (0,858,5) , # Godfather, The (1972) 14 (0,50,4) # Usual Suspects, The (1995) 15 ] 16new_user_ratings_RDD = sc.parallelize(new_user_ratings) 17print(\u0026#39;New user ratings: %s\u0026#39; % new_user_ratings_RDD.take(10)) 1New user ratings: [(0, 260, 9), (0, 1, 8), (0, 16, 7), (0, 25, 8), (0, 32, 9), (0, 335, 4), (0, 379, 3), (0, 296, 7), (0, 858, 10), (0, 50, 8)] ChÃºng ta tiáº¿n hÃ nh huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh khi cÃ³ thÃªm ngÆ°á»i má»›i:\n1complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD) 2 3from time import time 4 5t0 = time() 6new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, 7 iterations=iterations, lambda_=regularization_parameter) 8tt = time() - t0 9 10print(\u0026#34;New model trained in %s seconds\u0026#34; % round(tt,3)) 1New model trained in 56.61 seconds Tiáº¿n hÃ nh dá»± Ä‘oÃ¡n ratting cá»§a ngÆ°á»i dÃ¹ng má»›i cho toÃ n bá»™ cÃ¡c phim ngÆ°á»i dÃ¹ng Ä‘Ã³ chÆ°a xem.\n1new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs 2# keep just those not on the ID list (thanks Lei Li for spotting the error!) 3new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0]))) 4 5# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies 6new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD) VÃ  show ra top 3 káº¿t quáº£ :\n1# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating) 2new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating)) 3new_user_recommendations_rating_title_and_count_RDD = \\ 4 new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD) 5new_user_recommendations_rating_title_and_count_RDD.take(3) Hiá»ƒn thá»‹ top recommend (á» Ä‘Ã¢y sáº½ flat dá»¯ liá»‡u hiá»ƒn thá»‹ thÃ nh dÃ ng ((Title, Rating, Ratings Count)) ra cho dá»… nhÃ¬n).\n1new_user_recommendations_rating_title_and_count_RDD = new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1])) 2 3top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]\u0026gt;=25).takeOrdered(25, key=lambda x: -x[1]) 4 5print (\u0026#39;TOP recommended movies (with more than 25 reviews):\\n%s\u0026#39; % 6 \u0026#39;\\n\u0026#39;.join(map(str, top_movies))) 1TOP recommended movies (with more than 25 reviews): 2 (u\u0026#39;\u0026#34;Godfather: Part II\u0026#39;, 8.503749129186701, 29198) 3 (u\u0026#39;\u0026#34;Civil War\u0026#39;, 8.386497469089297, 257) 4 (u\u0026#39;Frozen Planet (2011)\u0026#39;, 8.372705479107108, 31) 5 (u\u0026#39;\u0026#34;Shawshank Redemption\u0026#39;, 8.258510064442426, 67741) 6 (u\u0026#39;Cosmos (1980)\u0026#39;, 8.252254825768972, 948) 7 (u\u0026#39;Band of Brothers (2001)\u0026#39;, 8.225114960311624, 4450) 8 (u\u0026#39;Generation Kill (2008)\u0026#39;, 8.206487040524653, 52) 9 (u\u0026#34;Schindler\u0026#39;s List (1993)\u0026#34;, 8.172761674773625, 53609) 10 (u\u0026#39;Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\u0026#39;, 8.166229786764168, 23915) 11 (u\u0026#34;One Flew Over the Cuckoo\u0026#39;s Nest (1975)\u0026#34;, 8.15617022970577, 32948) 12 (u\u0026#39;Casablanca (1942)\u0026#39;, 8.141303207981174, 26114) 13 (u\u0026#39;Seven Samurai (Shichinin no samurai) (1954)\u0026#39;, 8.139633165142612, 11796) 14 (u\u0026#39;Goodfellas (1990)\u0026#39;, 8.12931139039048, 27123) 15 (u\u0026#39;Star Wars: Episode V - The Empire Strikes Back (1980)\u0026#39;, 8.124225700242096, 47710) 16 (u\u0026#39;Jazz (2001)\u0026#39;, 8.078538221315313, 25) 17 (u\u0026#34;Long Night\u0026#39;s Journey Into Day (2000)\u0026#34;, 8.050176820606127, 34) 18 (u\u0026#39;Lawrence of Arabia (1962)\u0026#39;, 8.041331489948814, 13452) 19 (u\u0026#39;Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\u0026#39;, 8.0399424815528, 45908) 20 (u\u0026#39;12 Angry Men (1957)\u0026#39;, 8.011389274280754, 13235) 21 (u\u0026#34;It\u0026#39;s Such a Beautiful Day (2012)\u0026#34;, 8.007734839026181, 35) 22 (u\u0026#39;Apocalypse Now (1979)\u0026#39;, 8.005094327199552, 23905) 23 (u\u0026#39;Paths of Glory (1957)\u0026#39;, 7.999379786394267, 3598) 24 (u\u0026#39;Rear Window (1954)\u0026#39;, 7.9860865203540214, 17996) 25 (u\u0026#39;State of Play (2003)\u0026#39;, 7.981582126801772, 27) 26 (u\u0026#39;Chinatown (1974)\u0026#39;, 7.978673289692703, 16195) Dá»± Ä‘oÃ¡n rating cá»§a 1 cÃ¡ nhÃ¢n Má»™t trÆ°á»ng há»£p khÃ¡c lÃ  chÃºng ta cáº§n dá»± Ä‘oÃ¡n giÃ¡ trá»‹ ratting cá»§a 1 ngÆ°á»i dÃ¹ng vá»›i 1 bá»™ phim cá»¥ thá»ƒ nÃ o Ä‘Ã³.\n1my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994) 2individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD) 3individual_movie_rating_RDD.take(1) 1[Rating(user=0, product=122880, rating=4.955831875971526)] LÆ°u trá»¯ mÃ´ hÃ¬nh Sau khi cÃ³ Ä‘Æ°á»£c mÃ´ hÃ¬nh. ChÃºng ta cáº§n pháº£i lÆ°u trá»¯ chÃºng láº¡i Ä‘á»ƒ sau nÃ y dÃ¹ng.\n1from pyspark.mllib.recommendation import MatrixFactorizationModel 2 3model_path = os.path.join(\u0026#39;models\u0026#39;, \u0026#39;movie_lens_als\u0026#39;) 4 5# Save and load model 6model.save(sc, model_path) 7same_model = MatrixFactorizationModel.load(sc, model_path) ","date":"Oct 1, 2018","img":"https://unsplash.it/1920/1080?image=100","permalink":"/blog/2018-10-01-buiding-a-movie-model/","series":null,"tags":["Machine learning","Deeplearning","Spark"],"title":"XÃ¢y Dá»±ng ChÆ°Æ¡ng TrÃ¬nh Gá»£i Ã Phim Dá»±a VÃ o Táº­p Dá»¯ Liá»‡u Movie Len"},{"categories":null,"content":" Lá»i má»Ÿ Ä‘áº§u Äáº§u vÃ o Kiáº¿n trÃºc AlexNet Overlapping Max Pooling ReLu Nonlinearity Reducing overfitting Overfitting lÃ  gÃ¬? Data Augmentation Dropout Lá»i má»Ÿ Ä‘áº§u Tá»· phÃº Peter Thiel Ä‘Ã£ tá»«ng Ä‘Æ°a ra cÃ¢u há»i trÃ©o ngoe nhÆ° tháº¿ nÃ y: \u0026ldquo;What important truth do very few people agree with you on?\u0026rdquo;\nNáº¿u báº¡n Ä‘em cÃ¢u nÃ y há»i giÃ¡o sÆ° Geoffrey Hinton vÃ o nÄƒm 2010, Ã´ng áº¥y sáº½ tráº£ lá»i ráº±ng máº¡ng Convolutional Neural Networks (CNN) sáº½ cÃ³ bÆ°á»›c Ä‘á»™t phÃ¡ lá»›n vÃ  giÃºp chÃºng ta giáº£i quyáº¿t hoÃ n toÃ n bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh. Táº¡i thá»i Ä‘iá»ƒm nÄƒm 2010, cÃ¡c nhÃ  nghiÃªn cá»©u trong lÄ©nh vá»±c phÃ¢n loáº¡i áº£nh Ä‘á»u khÃ´ng nghÄ© nhÆ° giÃ¡o sÆ° Geoffrey Hinton. VÃ  Deep Learning táº¡i thá»i Ä‘iá»ƒm Ä‘Ã³ chÆ°a tháº­t sá»± giáº£i quyáº¿t Ä‘Æ°á»£c bÃ i toÃ¡n nÃ y.\nNÄƒm 2010 cÅ©ng lÃ  nÄƒm ra Ä‘á»i cá»§a cuá»™c thi ImageNet Large Scale Visual Recognition Challenge. Táº­p dá»¯ liá»‡u áº£nh trong cuá»™c thi bao gá»“m khoáº£ng 1.2 triá»‡u áº£nh thuá»™c 1000 lá»›p khÃ¡c nhau, ngÆ°á»i tháº¯ng cuá»™c lÃ  ngÆ°á»i táº¡o ra mÃ´ hÃ¬nh lÃ m cho Ä‘á»™ lá»—i trÃªn táº­p dá»¯ liá»‡u trÃªn lÃ  nhá» nháº¥t.\nHai nÄƒm sau, trong bÃ i bÃ¡o \u0026ldquo;ImageNet Classification with Deep Convolutional Neural Networks\u0026rdquo; cá»§a nhÃ³m tÃ¡c giáº£ Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton, Geoffrey vÃ  cÃ¡c cá»™ng sá»± cá»§a mÃ¬nh Ä‘Ã£ chá»©ng minh Ä‘iá»u Ã´ng áº¥y nÃ³i hai nÄƒm trÆ°á»›c lÃ  hoÃ n toÃ n chÃ­nh xÃ¡c. á» bÃ i bÃ¡o nÃ y, nhÃ³m tÃ¡c giáº£ Ä‘Ã£ huáº¥n luyá»‡n máº¡ng CNN vÃ  vÃ  Ä‘áº¡t Ä‘á»™ lá»—i top-5 error rate lÃ  15.3% (nhÃ³m tÃ¡c giáº£ Ä‘Ã£ giÃ nh háº¡ng nháº¥t), cÃ¡ch biá»‡t khÃ¡ xa so vá»›i káº¿t quáº£ cá»§a nhÃ³m Ä‘á»©ng thá»© hai(Ä‘á»™ lá»—i 26.2%). Trong cÃ¡c nÄƒm tiáº¿p theo, ráº¥t nhiá»u nhÃ³m Ä‘Ã£ nghiÃªn cá»©u, cáº£i tiáº¿n kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh CNN Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tá»‘t hÆ¡n, tháº­m chÃ­ hÆ¡n luÃ´n kháº£ nÄƒng nháº­n biáº¿t cá»§a con ngÆ°á»i.\nKiáº¿n trÃºc máº¡ng CNN Ä‘Æ°á»£c sá»­ dá»¥ng vÃ o nÄƒm 2012 Ä‘Æ°á»£c cá»™ng Ä‘á»“ng nghiÃªn cá»©u gá»i vá»›i tÃªn gá»i thÃ¢n thÆ°Æ¡ng lÃ  AlexNet do tÃ¡c giáº£ chÃ­nh cá»§a nhÃ³m nghiÃªn cá»©u lÃ  Alex Krizhevsky. á» trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ Ä‘i sÃ¢u vÃ o tÃ¬m hiá»ƒu kiáº¿n trÃºc AlexNet vÃ  Ä‘Ã³ng gÃ³p chÃ­nh cá»§a nÃ³ trong CNN.\nÄáº§u vÃ o NhÆ° Ä‘Ã£ Ä‘á» cáº­p á»Ÿ pháº§n trÃªn, máº¡ng AlexNet Ä‘Ã£ tháº¯ng háº¡ng nháº¥t trong cuá»™c thi ILSVRC nÄƒm 2012. MÃ´ hÃ¬nh giáº£i quyáº¿t bÃ i toÃ¡n phÃ¢n lá»›p má»™t bá»©c áº£nh vÃ o 1 lá»›p trong 1000 lá»›p khÃ¡c nhau (vd gÃ , chÃ³, mÃ¨o \u0026hellip; ). Äáº§u ra cá»§a mÃ´ hÃ¬nh lÃ  má»™t vector cÃ³ 1000 pháº§n tá»­. Pháº§n tá»­ thá»© i cá»§a vector Ä‘áº¡i diá»‡n cho xÃ¡c suáº¥t bá»©c áº£nh thuá»™c vá» lá»›p thá»© i. Do Ä‘Ã³, tá»•ng cá»§a cÃ¡c pháº§n tá»­ trong vector lÃ  1.\nÄáº§u vÃ o cá»§a máº¡ng AlexNet lÃ  má»™t bá»©c áº£nh RGB cÃ³ kÃ­ch thÆ°á»›c 256x256 pixel. ToÃ n bá»™ cÃ¡c bá»©c áº£nh cá»§a táº­p train vÃ  táº­p test Ä‘á»u cÃ³ cÃ¹ng kÃ­ch thÆ°á»›c lÃ  256x256. Náº¿u má»™t bá»©c áº£nh nÃ o Ä‘Ã³ khÃ´ng cÃ³ kÃ­ch thÆ°á»›c 256x256, bá»©c áº£nh Ä‘Ã³ sáº½ Ä‘Æ°á»£c chuyá»ƒn vá» kÃ­ch thÆ°á»›c Ä‘Ãºng 256x256. Nhá»¯ng bá»©c hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c nhá» hÆ¡n 256 thÃ¬ sáº½ Ä‘Æ°á»£c phÃ³ng bá»± lÃªn Ä‘áº¿n kÃ­ch thÆ°á»›c 256, nhá»¯ng bá»©c hÃ¬nh nÃ o cÃ³ kÃ­ch thÆ°á»›c lá»›n hÆ¡n 256 thÃ¬ sáº½ Ä‘Æ°á»£c cáº¯t loáº¡i pháº§n thá»«a Ä‘á»ƒ nháº­n Ä‘Æ°á»£c bá»©c hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c 256x256. HÃ¬nh áº£nh á»Ÿ dÆ°á»›i lÃ  má»™t vÃ­ dá»¥ vá» viá»‡c Ä‘iá»u chá»‰nh bá»©c áº£nh vá» kÃ­ch thÆ°á»›c 256x256.\nNáº¿u áº£nh Ä‘áº§u vÃ o lÃ  áº£nh xÃ¡m (grayscale), bá»©c áº£nh trÃªn sáº½ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh Ä‘á»‹nh dáº¡ng RGB báº±ng cÃ¡ch táº¡o ra 3 layer kÃªnh mÃ u giá»‘ng nhau tá»« áº£nh xÃ¡m.\nSau khi chuáº©n hoÃ¡ háº¿t táº¥t cáº£ cÃ¡c áº£nh vá» dáº¡ng 256x256x3, nhÃ³m tÃ¡c giáº£ chá»‰ sá»­ dá»¥ng má»™t pháº§n cá»§a bá»©c áº£nh cÃ³ kÃ­ch thÆ°á»›c 227x227x3 cá»§a má»™t bá»©c áº£nh lÃ m Ä‘áº§u vÃ o cho máº¡ng neural network. Trong bÃ i bÃ¡o nhÃ³m tÃ¡c giáº£ ghi lÃ  224x224, nhÆ°ng Ä‘Ã¢y lÃ  má»™t lá»—i nhá» cá»§a nhÃ³m tÃ¡c giáº£, vÃ  kÃ­ch thÆ°á»›c thá»±c táº¿ Ä‘áº§u vÃ o cá»§a bá»©c áº£nh lÃ  227x227.\nKiáº¿n trÃºc AlexNet Kiáº¿n trÃºc AlexNet lá»›n hÆ¡n nhiá»u so vá»›i cÃ¡c kiáº¿n trÃºc CNNs Ä‘Æ°á»£c sá»­ dá»¥ng trong thá»‹ giÃ¡c mÃ¡y tÃ­nh trÆ°á»›c kia (trÆ°á»›c nÄƒm 2010), vd kiáº¿n trÃºc LeNet cá»§a Yann LeCun nÄƒm 1998. NÃ³ cÃ³ 60 triá»‡u tham sá»‘ vÃ  650000 neural vÃ  tá»‘n khoáº£ng tá»« nÄƒm Ä‘áº¿n sÃ¡u ngÃ y huáº¥n luyá»‡n trÃªn hai GPU GTX 580 3GB. NgÃ y nay, vá»›i sá»± tiáº¿n bá»™ vÆ°á»£t báº­t cá»§a GPU, chÃºng ta cÃ³ nhiá»u kiáº¿n trÃºc CNN cÃ³ cáº¥u trÃºc phá»©c táº¡p hÆ¡n, vÃ  hoáº¡t Ä‘á»™ng ráº¥t hiá»‡u quáº£ trÃªn nhá»¯ng táº­p dá»¯ liá»‡u phá»©c táº¡p. NhÆ°ng táº¡i thá»i Ä‘iá»ƒm nÄƒm 2012 thÃ¬ viá»‡c huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i lÆ°á»£ng tham sá»‘ vÃ  neural lá»›n nhÆ° váº­y lÃ  má»™t váº¥n Ä‘á» cá»±c ká»³ khÃ³ khÄƒn. NhÃ¬n ká»¹ vÃ o hÃ¬nh bÃªn dÆ°á»›i Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n vá» kiáº¿n trÃºc AlexNet. AlexNet bao gá»“m 5 convolution Layer vÃ  3 Fully connected Layers.\nNhá»¯ng convolution layer ( hay cÃ²n gá»i vá»›i tÃªn khÃ¡c lÃ  cÃ¡c filter) rÃºt trÃ­ch cÃ¡c thÃ´ng tin há»¯u Ã­ch trong cÃ¡c bá»©c áº£nh. Trong má»™t convolution layer báº¥t ká»³ thÆ°á»ng bao gá»“m nhiá»u kernel cÃ³ cÃ¹ng kÃ­ch thÆ°á»›c. VÃ­ dá»¥ nhÆ° convolution layer Ä‘áº§u tiÃªn cá»§a AlexNet chá»©a 96 kernel cÃ³ kÃ­ch thÆ°á»›c 11x11x3. ThÃ´ng thÆ°á»ng thÃ¬ width vÃ  height cá»§a má»™t kernel báº±ng nhau, vÃ  Ä‘á»™ sÃ¢u (depth) thÆ°á»ng báº±ng sá»‘ lÆ°á»£ng kÃªnh mÃ u.\nConvolutional 1 vÃ  convolution 2 káº¿t ná»‘i vá»›i nhau qua má»™t Overlapping Max Pooling á»Ÿ giá»¯a. TÆ°Æ¡ng tá»± nhÆ° váº­y giá»¯a convolution 2 vÃ  convolution 3. Convolutional 3, convolution 4, convolution 5 káº¿t ná»‘i trá»±c tiáº¿p vá»›i nhau, khÃ´ng thÃ´ng qua trung gian. Convolutional 5 káº¿t ná»‘i fully connected layter 1 thÃ´ng qua má»™t Overlapping Max pooling, tiáº¿p theo mÃ  má»™t fully connected layter ná»¯a. VÃ  cuá»‘i cÃ¹ng lÃ  má»™t bá»™ phÃ¢n lá»›p softmax vá»›i 1000 lá»›p nhÃ£n (cÃ¡c báº¡n cÃ³ thá»ƒ xem hÃ¬nh kiáº¿n trÃºc máº¡ng AlexNet á»Ÿ trÃªn Ä‘á»ƒ cÃ³ cÃ¡i nhÃ¬n tá»•ng quÃ¡t hÆ¡n).\nReLU nonlinerity Ä‘Æ°á»£c sá»­ dá»¥ng sau táº¥t cÃ¡c cÃ¡c convolution vÃ  fully connected layer. TrÆ°á»›c Ä‘Ã¢y, ReLU nonlinerity cá»§a lá»›p convolution 1 vÃ  2 thÆ°á»ng theo sau bá»Ÿi má»™t bÆ°á»›c chuáº©n hoÃ¡ cá»¥c bá»™ (local normalization) rá»“i má»›i thá»±c hiá»‡n pooling. Tuy nhiÃªn, cÃ¡c nghiÃªn cá»©u sau Ä‘Ã³ nháº­n tháº¥y ráº±ng viá»‡c sá»­ dá»¥ng normalization khÃ´ng tháº­t sá»± há»¯u Ã­ch. Do váº­y chÃºng ta sáº½ khÃ´ng Ä‘i chi tiáº¿t vá» váº¥n Ä‘á» Ä‘Ã³.\nOverlapping Max Pooling Max Pooling layer thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giáº£m chiá»u rá»™ng vÃ  chiá»u dÃ i cá»§a má»™t tensor nhÆ°ng váº«n giá»¯ nguyÃªn chiá»u sÃ¢u. Overlapping Max Pool layter cÅ©ng tÆ°Æ¡ng tá»± nhÆ° Max Pool layter, ngoáº¡i trá»« viá»‡c lÃ  má»™t window cá»§a bÆ°á»›c nÃ y sáº½ cÃ³ má»™t pháº§n chá»“ng lÃªn window cá»§a bÆ°á»›c tiáº¿p theo. TÃ¡c giáº£ sá»­ dá»¥ng pooling cÃ³ kÃ­ch thÆ°á»›c 3x3 vÃ  bÆ°á»›c nháº£y lÃ  2 giá»¯a cÃ¡c pooling. NghÄ©a lÃ  giá»¯a pooling nÃ y vÃ  pooling khÃ¡c sáº½ overlapping vá»›i nhau 1 pixel. CÃ¡c thÃ­ nghiá»‡m thá»±c táº¿ Ä‘Ã£ chá»©ng minh ráº±ng viá»‡c sá»­ dá»¥ng overlapping giá»¯a cÃ¡c pooling giÃºp giáº£m Ä‘á»™ lá»—i top-1 error 0.4% vÃ  top-5 error lÃ  0.3% khi so vá»›i viá»‡c sá»­ dá»¥ng pooling cÃ³ kÃ­ch thÆ°á»›c 2x2 vÃ  bÆ°á»›c nháº£y 2 (vector output cá»§a cáº£ hai Ä‘á»u cÃ³ sá»‘ chiá»u báº±ng nhau).\nReLu Nonlinearity Má»™t cáº£i tiáº¿n quan trá»ng khÃ¡c cá»§a AlexNet lÃ  viá»‡c sá»­ dá»¥ng hÃ m phi tuyáº¿n ReLU. TrÆ°á»›c Ä‘Ã¢y, cÃ¡c nhÃ³m nghiÃªn cá»©u khÃ¡c thÆ°á»ng sá»­ dá»¥ng hÃ m kÃ­ch hoáº¡t lÃ  hÃ m Tanh hoáº·c hÃ m Sigmoid Ä‘á»ƒ huáº¥n luyÃªn mÃ´ hÃ¬nh neural network. AlexNet chá»‰ ra ráº±ng, khi sá»­ dá»¥ng ReLU, mÃ´ hÃ¬nh deep CNN sáº½ huáº¥n luyá»‡n nhanh hÆ¡n so vá»›i viÃªc sá»­ dá»¥ng tanh hoáº·c sigmoid. HÃ¬nh bÃªn dÆ°á»›i Ä‘Æ°á»£c rÃºt ra tá»« bÃ i bÃ¡o chá»‰ ra ráº±ng vá»›i viá»‡c sá»­ dá»¥ng ReLU (Ä‘Æ°á»ng nÃ©t liá»n trong hÃ¬nh), AlexNet Ä‘áº¡t Ä‘á»™ lá»—i 25% trÃªn táº­p huáº¥n luyá»‡n vÃ  nhanh hÆ¡n gáº¥p 6 láº§n so vá»›i mÃ´ hÃ¬nh tÆ°Æ¡ng tá»± nhÆ°ng sá»­ dá»¥ng Tanh (Ä‘Æ°á»ng nÃ©t Ä‘á»©t trong hÃ¬nh). ThÃ­ nghiá»‡m trÃªn sá»­ dá»¥ng táº­p dá»¯ liá»‡u CIFAR-10 Ä‘á»ƒ huáº¥n luyá»‡n.\nÄá»ƒ hiá»ƒu rÃµ hÆ¡n lÃ½ do vÃ¬ sao ReLU láº¡i nhanh hÆ¡n so vá»›i cÃ¡c hÃ m khÃ¡c, chÃºng ta hÃ£y Ä‘á»‘i sÃ¡nh hÃ¬nh dáº¡ng giÃ¡ trá»‹ output cá»§a cÃ¡c hÃ m trÃªn.\nCÃ´ng thá»©c cá»§a ReLU lÃ : f(X) = max(0,x)\nNhÃ¬n ká»¹ vÃ o hÃ¬nh trÃªn, ta cÃ³ nháº­n xÃ©t ráº±ng: hÃ m tanh Ä‘áº¡t giÃ¡ trá»‹ bÃ£o hoÃ  khi giÃ¡ trá»‹ z \u0026gt;2.5 vÃ  z \u0026lt; -2.5 (sá»‘ 2.5 lÃ  sá»‘ cáº£m tÃ­nh cá»§a mÃ¬nh). VÃ  táº¡i vÃ¹ng |z|\u0026gt;2.5, thÃ¬ Ä‘á»™ dá»‘c cá»§a hÃ m háº§u nhÆ° gáº§n nhÆ° báº±ng 0, |z| cÃ ng lá»›n thÃ¬ Ä‘á»™ dá»‘c cÃ ng gáº§n 0 hÆ¡n. VÃ¬ lÃ½ do nÃ y nÃªn gradient descent sáº½ há»™i tá»¥ cháº­m. CÃ²n Ä‘á»‘i vá»›i hÃ m ReLU, vá»›i giÃ¡ trá»‹ z dÆ°Æ¡ng thÃ¬ Ä‘á»™ dá»‘c cá»§a hÃ m khÃ´ng gáº§n báº±ng 0 nhÆ° hÃ m tanh. Äiá»u nÃ y giÃºp cho viá»‡c há»™i tá»¥ xáº£y ra nhanh hÆ¡n. Vá»›i giÃ¡ trá»‹ z Ã¢m, Ä‘á»™ dá»‘c báº±ng 0, tuy nhiÃªn, háº§u háº¿t cÃ¡c giÃ¡ trá»‹ cá»§a cÃ¡c neural trong máº¡ng thÆ°á»ng cÃ³ giÃ¡ trá»‹ dÆ°Æ¡ng, nÃªn trÆ°á»ng há»£p Ã¢m Ã­t (hiáº¿m) khi xáº£y ra. ReLU huáº¥n luyá»‡n nhanh hÆ¡n so vá»›i sigmoid cÅ©ng bá»Ÿi lÃ½ do tÆ°Æ¡ng tá»±.\nReducing overfitting Overfitting lÃ  gÃ¬? Khi báº¡n dáº¡y má»™t Ä‘á»©a tráº» tá»« 2-5 tuá»•i vá» viá»‡c cá»™ng hai sá»‘, chÃºng sáº½ há»c ráº¥t nhanh vÃ  tráº£ lá»i Ä‘Ãºng háº§u háº¿t cÃ¡c cÃ¢u há»i mÃ  chÃºng ta Ä‘Ã£ dáº¡y chÃºng. Tuy nhiÃªn, chÃºng sáº½ tráº£ lá»i sai Ä‘á»‘i vá»›i nhá»¯ng cÃ¢u há»i hÆ¡i láº¯c lÃ©o má»™t chÃºt (cÃ¢u há»i tÆ°Æ¡ng tá»± cÃ¢u chÃºng ta Ä‘Ã£ dáº¡y, nhÆ°ng thÃªm má»™t xÃ­u thÃ´ng tin Ä‘Ã²i há»i tráº» pháº£i suy nghÄ©), hoáº·c cÃ¡c cÃ¢u há»i chÆ°a Ä‘Æ°á»£c dáº¡y. LÃ½ do chÃºng tráº£ lá»i sai nhá»¯ng cÃ¢u há»i Ä‘Ã³ lÃ  khi tráº£ lá»i nhá»¯ng cÃ¢u há»i Ä‘Æ°á»£c dáº¡y, chÃºng thÆ°á»ng nhá»› láº¡i cÃ¢u tráº£ lá»i, chá»© khÃ´ng thá»±c sá»± hiá»ƒu cÃ¢u há»i. CÃ¡i nÃ y á»Ÿ Viá»‡t Nam ta gá»i lÃ  há»c váº¹t.\nTÆ°Æ¡ng tá»± váº­y, Neural network chÃ­nh báº£n thÃ¢n nÃ³ cÃ³ kháº£ nÄƒng há»c Ä‘Æ°á»£c nhá»¯ng gÃ¬ Ä‘Æ°á»£c dáº¡y, tuy nhiÃªn, náº¿u quÃ¡ trÃ¬nh huáº¥n luyá»‡n cá»§a báº¡n khÃ´ng tá»‘t, mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng sáº½ giá»‘ng nhÆ° nhá»¯ng Ä‘á»©a tráº» trÃªn kia, há»“i tÆ°á»Ÿng láº¡i nhá»¯ng gÃ¬ Ä‘Ã£ dáº¡y cho chÃºng mÃ  khÃ´ng hiá»ƒu báº£n cháº¥t. VÃ  káº¿t quáº£ Neural Network sáº½ hoáº¡t Ä‘á»™ng tá»‘t trÃªn táº­p huáº¥n luyá»‡n ( nhÆ°ng chÃºng khÃ´ng rÃºt ra Ä‘Æ°á»£c báº£n cháº¥t chÃ­nh cá»§a váº¥n Ä‘á»), vÃ  káº¿t quáº£ trÃªn táº­p test tá»‡. NgÆ°á»i ta gá»i trÆ°á»ng há»£p trÃªn lÃ  overfitting.\nNhÃ³m nghiÃªn cá»©u AlexNet sá»­ dá»¥ng nhiá»u phÆ°Æ¡ng phÃ¡p khÃ¡c nhau Ä‘á»ƒ giáº£m overfitting.\nData Augmentation Viá»‡c sá»­ dá»¥ng nhiá»u biáº¿n thá»ƒ khÃ¡c nhau cá»§a má»™t bá»©c hÃ¬nh cÃ³ thá»ƒ giÃºp ngÄƒn mÃ´ hÃ¬nh khÃ´ng bá»‹ overfitting. Vá»›i viá»‡c sá»­ dá»¥ng nhiá»u biáº¿n thá»ƒ cá»§a 1 bá»©c hÃ¬nh, báº¡n báº¯t Ã©p mÃ´ hÃ¬nh khÃ´ng há»c váº¹t dá»¯ liá»‡u. CÃ³ nhiá»u cÃ¡ch khÃ¡c nhau Ä‘á»ƒ sinh ra dá»¯ liá»‡u má»›i dá»±a vÃ o dá»¯ liá»‡u cÃ³ sáºµn. Má»™t vÃ i cÃ¡c mÃ  nhÃ³m AlexNet Ä‘Ã£ sá»­ dá»¥ng lÃ .\nData Augmentation by Mirroring Ã tÆ°á»Ÿng cá»§a viá»‡c nÃ y lÃ  láº¥y áº£nh trong gÆ°Æ¡ng cá»§a má»™t bá»©c hÃ¬nh (áº£nh áº£o). NhÃ¬n vÃ o áº£nh bÃªn dÆ°á»›i, bÃªn trÃ¡i lÃ  hÃ¬nh gá»‘c cá»§a con mÃ¨o trong táº­p huáº¥n luyá»‡n, bÃªn pháº£i lÃ  áº£nh cá»§a con mÃ¨o khi thÃªm hiá»‡u á»©ng hÃ¬nh qua gÆ°Æ¡ng (Ä‘Æ¡n giáº£n lÃ  xoay qua trá»¥c y lÃ  Ä‘Æ°á»£c ) Data Augmentation by Random Crops Viá»‡c lá»±a chá»n vá»‹ trÃ­ áº£nh gá»‘c má»™t cÃ¡ch ngáº«u nhiÃªn cÅ©ng giÃºp chÃºng ta cÃ³ thÃªm má»™t áº£nh khÃ¡c so vá»›i áº£nh gá»‘c ban Ä‘áº§u.\nNhÃ³m tÃ¡c giáº£ cá»§a AlexNet rÃºt trÃ­ch ngáº«u nhiÃªn bá»©c áº£nh cÃ³ kÃ­ch thÆ°á»›c 227x227 tá»« bá»©c áº£nh 256x256 ban Ä‘áº§u lÃ m input dáº§u vÃ o cho mÃ´ hÃ¬nh. Báº±ng cÃ¡ch nÃ y, chÃºng ta cÃ³ thá»ƒ tÄƒng sá»‘ lÆ°á»£ng dá»¯ liá»‡u lÃªn gáº¥p 2048 láº§n báº±ng viá»‡c sá»­ dá»¥ng cÃ¡ch nÃ y.\nBá»‘n bá»©c áº£nh Ä‘Æ°á»£c crop ngáº«u nhiÃªn á»Ÿ trÃªn thoáº¡t nhÃ¬n cÃ³ váº» giá»‘ng nhau, nhÆ°ng thá»±c cháº¥t khÃ´ng pháº£i nhÆ° váº­y.\nVá»›i viá»‡c sá»­ dá»¥ng Data Augmentation, chÃºng ta Ä‘ang bá»‘ gáº¯ng dáº¡y cho mÃ´ hÃ¬nh ráº±ng vá»›i viá»‡c nhÃ¬n hÃ¬nh con mÃ¨o qua gÆ°Æ¡ng, nÃ³ váº«n lÃ  con mÃ¨o, hoáº·c hÃ¬nh hÃ¬nh con mÃ¨o á»Ÿ báº¥t ká»³ gÃ³c Ä‘á»™ nÃ o thÃ¬ nÃ³ váº«n lÃ  nÃ³.\nDropout Vá»›i gáº§n 60 triá»‡u tham sá»‘ trong táº­p huáº¥n luyá»‡n, viá»‡c overfitting xáº£y ra lÃ  Ä‘iá»u dá»… hiá»ƒu. CÃ¡c tÃ¡c giáº£ cá»§a AlexNet Ä‘Ã£ thá»±c nghiá»‡m nhiá»u cÃ¡ch ná»¯a Ä‘á»ƒ giáº£m overfitting. Há» sá»­ dá»¥ng má»™t ká»¹ thuáº­t gá»i lÃ  dropout - ká»¹ thuáº­t nÃ y Ä‘Æ°á»£c giá»›i thiá»‡u á»Ÿ bÃ i bÃ¡o khÃ¡c cá»§a G.E. Hintol vÃ o nÄƒm 2012. Ká»¹ thuáº­t nÃ y khÃ¡ Ä‘Æ¡n giáº£n, má»™t neural sáº½ cÃ³ xÃ¡c suáº¥t bá»‹ loáº¡i khá»i mÃ´ hÃ¬nh lÃ  0.5. Khi má»™t neural bá»‹ loáº¡i khá»i mÃ´ hÃ¬nh, nÃ³ sáº½ khÃ´ng Ä‘Æ°á»£c tham qia vÃ o quÃ¡ trÃ¬nh lan truyá»n tiáº¿n hoáº·c lan truyá»n ngÆ°á»£c. Cho nÃªn, má»—i giÃ¡ trá»‹ input sáº½ Ä‘i qua má»™t kiáº¿n trÃºc máº¡ng khÃ¡c nhau. NhÆ° mÃ´ táº£ á»Ÿ hÃ¬nh Ä‘á»™ng á»Ÿ dÆ°á»›i, káº¿t quáº£ lÃ  giÃ¡ trá»‹ cá»§a tham sá»‘ trá»ng sá»‘ sáº½ tá»‘t hÆ¡n vÃ  khÃ³ bá»‹ overfitting hÆ¡n. Trong quÃ¡ trÃ¬nh test, toÃ n bá»™ network Ä‘Æ°á»£c sá»­ dá»¥ng, khÃ´ng cÃ³ dropout, tuy nhiÃªn, giÃ¡ trá»‹ output sáº½ scaled bá»Ÿi tham sá»‘ 0.5 tÆ°Æ¡ng á»©ng vá»›i nhá»¯ng neural khÃ´ng sá»­ dá»¥ng trong quÃ¡ trÃ¬nh trainning. Vá»›i viá»‡c sá»­ dá»¥ng dropout, chÃºng ta sáº½ tÄƒng gáº¥p Ä‘Ã´i láº§n láº·p cáº§n thiáº¿t Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ há»™i tá»¥, nhÆ°ng khi khÃ´ng sá»­ dá»¥ng dropout, máº¡ng AlexNet ráº¥t dá»… bá»‹ overfitting.\nNgÃ y nay, chuáº©n hoÃ¡ dropout lÃ  má»™t yáº¿u tá»‘ khÃ´ng thá»ƒ thiáº¿u vÃ  cÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng nÃ³ thÆ°á»ng cÃ³ káº¿t quáº£ tá»‘t hÆ¡n so vá»›i mÃ´ hÃ¬nh tÆ°Æ¡ng tá»± khÃ´ng sá»­ dá»¥ng dropout. ChÃºng ta sáº½ bÃ n sÃ¢u hÆ¡n vá» dropout á»Ÿ má»™t bÃ i khÃ¡c trong tÆ°Æ¡ng lai.\nTham kháº£o\nImageNet Classification with Deep Convolutional Neural Networks by Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton, 2012\nhttps://www.learnopencv.com/understanding-alexnet/\n","date":"Jun 15, 2018","img":"https://unsplash.it/1920/1080?image=35","permalink":"/blog/2018-06-15-understanding-alexnet/","series":null,"tags":["Machine learning","Deeplearning","AlexNet"],"title":"TÃ¬m Hiá»ƒu Vá» Máº¡ng Neural Network AlexNet"},{"categories":null,"content":"Chapter 9: References Introduction to References Declaring and using references Comparing pointers and references References and const\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/10_references/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 10: Character Manipulation and Strings Introduction to Strings Character Manipulation C-string manipulation C-String concatenation and copy Introducing std::string Declaring and using std::string\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/11_string/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 11: Functions The One Definition Rule First Hand on C++ Functions Function Declaration and Function Definitions Multiple Files - Compilation Model Revisited Pass by value Pass by pointer Pass by reference\nChapter 12: Getting Things out of functions Introduction to getting things out of functions Input and output parameters Returning from functions by value\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/12_function/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 13: Function Overloading Function Overloading Introduction Overloading with different parameters\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/13_function_overloading/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 14: Lambda functions Introduction to Lambda Functions Declaring and using lambda functions Capture lists Capture all in context Summary\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/14_lambda_function/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 15: Function Templates Introduction to function templates Trying out function templates Template type deduction and explicit arguments Template parameters by reference Template specialization\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/15_function_template/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 16: C++20 Concepts Crash course Introduction to C++20 Concepts Using C++20 Concepts Building your own C++20 Concepts Zooming in on the requires clause Combining C++20 Concepts C++20 Concepts and auto\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/16_concept/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 17: Classes Introduction to classes Your First Class C++ Constructors Defaulted constructors Setters and Getters Class Across Multiple Files Arrow pointer call notation Destructors Order of Constructor Destructor Calls The this Pointer struct Size of objects\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/17_class/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 18: Inheritance Introduction to Inheritance First try on Inheritance Protected members Base class access specifiers : Zooming in Base class access specifiers - A demo Closing in on Private Inheritance Resurrecting Members Back in Context Default Constructors with Inheritance Custom Constructors With Inheritance Copy Constructors with Inheritance Inheriting Base Constructors Inheritance and Destructors Reused Symbols in Inheritance\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/18_inheritance/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 19: Polymorphism Introduction to Polymorphism Static Binding with Inheritance Dynamic binding with virtual functions Size of polymorphic objects and slicing Polymorphic objects stored in collections (array) Override Overloading, overriding and function hiding Inheritance and Polymorphism at different levels Inheritance and polymorphism with static members Final Virtual functions with default arguments Virtual Destructors Dynamic casts Polymorphic Functions and Destructors Pure virtual functions and abstract classes Abstract Classes as Interfaces\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/19_polymorphism/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 3: Variables and data types Variables and data types Introduction Number Systems Integer types : Decimals and Integers Integer Modifiers Fractional Numbers Booleans Characters And Text Auto Assignments Variables and data types summary\nBÃ i 3: XÃ¢y dá»±ng chÆ°Æ¡ng trÃ¬nh C++ Ä‘áº§u tiÃªn vá»›i Visual Studio 2015\nMá»™t sá»‘ kiáº¿n thá»©c cáº§n lÆ°u Ã½ CÃ¡ch táº¡o vÃ  biÃªn dá»‹ch chÆ°Æ¡ng trÃ¬nh C++ Ä‘áº§u tiÃªn trÃªn Visual Studio Má»™t sá»‘ váº¥n Ä‘á» thÆ°á»ng gáº·p Ä‘á»‘i vá»›i láº­p trÃ¬nh viÃªn má»›i BÃ i 4: Cáº¥u trÃºc má»™t chÆ°Æ¡ng trÃ¬nh C++ (Structure of a program)\nCáº¥u trÃºc cá»§a má»™t chÆ°Æ¡ng trÃ¬nh C++ CÃº phÃ¡p vÃ  lá»—i cÃº phÃ¡p trong C++ (Syntax and syntax errors) BÃ i 5: Ghi chÃº trong C++ (Comments in C++)\nCÃº phÃ¡p comment trong C++ Má»™t sá»‘ kinh nghiá»‡m khi comment trong láº­p trÃ¬nh BÃ i 6: Biáº¿n trong C++ (Variables in C++)\nBiáº¿n trong C++ Khá»Ÿi táº¡o biáº¿n trong C++ (Defining a variable) Äá»‹nh nghÄ©a biáº¿n á»Ÿ Ä‘Ã¢u (Where to define variables) BÃ i 7: Sá»‘ tá»± nhiÃªn vÃ  Sá»‘ cháº¥m Ä‘á»™ng trong C++ (Integer, Floating point)\nTá»•ng quan vá» kiá»ƒu dá»¯ liá»‡u cÆ¡ báº£n trong C++ Kiá»ƒu sá»‘ nguyÃªn (Integer) Sá»‘ cháº¥m Ä‘á»™ng (Floating point numbers) BÃ i 8: Kiá»ƒu kÃ½ tá»± trong C++ (Character)\nTá»•ng quan vá» kiá»ƒu kÃ½ tá»± (Character) Khai bÃ¡o, khá»Ÿi táº¡o vÃ  gÃ¡n giÃ¡ trá»‹ má»™t biáº¿n kÃ½ tá»± In kÃ½ tá»± ra mÃ n hÃ¬nh In kÃ½ tá»± tá»« sá»‘ nguyÃªn vÃ  ngÆ°á»£c láº¡i (Casting) Escape sequences Newline â€˜\\nâ€™ vÃ  std::endl Dáº¥u nhÃ¡y Ä‘Æ¡n â€˜Kâ€™ vÃ  dáº¥u nhÃ¡y kÃ©p â€œKteamâ€ BÃ i 9: Kiá»ƒu luáº­n lÃ½ vÃ  cÆ¡ báº£n vá» CÃ¢u Ä‘iá»u kiá»‡n If (Boolean and If statements)\nTá»•ng quan vá» kiá»ƒu luáº­n lÃ½ (Boolean) CÆ¡ báº£n vá» cÃ¢u Ä‘iá»u kiá»‡n If vÃ  Boolean BÃ i 10: Nháº­p, Xuáº¥t vÃ  Äá»‹nh dáº¡ng dá»¯ liá»‡u trong C++ (Input and Output)\nXuáº¥t dá»¯ liá»‡u vá»›i std::cout trong C++ Nháº­p dá»¯ liá»‡u vá»›i std::cin trong C++ Äá»‹nh dáº¡ng dá»¯ liá»‡u nháº­p xuáº¥t trong C++ BÃ i 11: Háº±ng sá»‘ trong C++ (Constants)\nTá»•ng quan háº±ng sá»‘ (Constants) Háº±ng sá»‘ vá»›i tá»« khÃ³a const Háº±ng sá»‘ vá»›i chá»‰ thá»‹ tiá»n xá»­ lÃ½ #define NÃªn Ä‘á»‹nh nghÄ©a háº±ng sá»‘ á»Ÿ Ä‘Ã¢u BÃ i 12: ToÃ¡n tá»­ sá»‘ há»c, toÃ¡n tá»­ tÄƒng giáº£m, toÃ¡n tá»­ gÃ¡n sá»‘ há»c trong C++ (Operators)\nTá»•ng quan vá» toÃ¡n tá»­ ToÃ¡n tá»­ sá»‘ há»c trong C++ (Arithmetic operators) ToÃ¡n tá»­ gÃ¡n sá»‘ há»c trong C++ (Arithmetic assignment operators) BÃ i 13: ToÃ¡n tá»­ quan há»‡, logic, bitwise, misc vÃ  Ä‘á»™ Æ°u tiÃªn toÃ¡n tá»­ trong C++\nToÃ¡n tá»­ quan há»‡ trong C++ (Relational operators) ToÃ¡n tá»­ logic trong C++ (Logical operators) ToÃ¡n tá»­ trÃªn bit trong C++ (Bitwise operators) CÃ¡c toÃ¡n tá»­ há»—n há»£p trong C++ (Misc Operators) Äá»™ Æ°u tiÃªn vÃ  quy táº¯c káº¿t há»£p toÃ¡n tá»­ trong C++ BÃ i 14: CÆ¡ báº£n vá» chuá»—i kÃ½ tá»± trong C++ (An introduction to std::string)\nTá»•ng quan vá» chuá»—i kÃ½ tá»± (std::string) Khai bÃ¡o, khá»Ÿi táº¡o vÃ  gÃ¡n giÃ¡ trá»‹ má»™t chuá»—i kÃ½ tá»± Xuáº¥t má»™t chuá»—i kÃ½ tá»± (string output): Nháº­p má»™t chuá»—i kÃ½ tá»± (string input) Má»™t sá»‘ thao tÃ¡c cÆ¡ báº£n vá»›i chuá»—i kÃ½ tá»± BÃ i 15: Biáº¿n cá»¥c bá»™ trong C++ (Local variables in C++)\nTá»•ng quan vá» táº§m vá»±c cá»§a biáº¿n Biáº¿n cá»¥c bá»™ (Local variables) BÃ i 16: Biáº¿n toÃ n cá»¥c trong C++ (Global variables in C++)\nTá»•ng quan vá» táº§m vá»±c cá»§a biáº¿n Biáº¿n toÃ n cá»¥c (Global variables) Sá»­ dá»¥ng biáº¿n toÃ n cá»¥c lÃ  nguy hiá»ƒm Khi nÃ o cáº§n sá»­ dá»¥ng biáº¿n toÃ n cá»¥c (non-const) BÃ i 17: Biáº¿n tÄ©nh trong C++ (Static variables in C++)\nTá»•ng quan vá» biáº¿n tÄ©nh (static variables) Khi nÃ o nÃªn sá»­ dá»¥ng biáº¿n tÄ©nh BÃ i 18: Ã‰p kiá»ƒu ngáº§m Ä‘á»‹nh trong C++ (Implicit type conversion in C++)\nTá»•ng quan vá» Ã©p kiá»ƒu dá»¯ liá»‡u Ã‰p kiá»ƒu ngáº§m Ä‘á»‹nh trong C++ (Implicit type conversion) BÃ i 19: Ã‰p kiá»ƒu tÆ°á»ng minh trong C++ (Explicit type conversion in C++)\nÃ‰p kiá»ƒu tÆ°á»ng minh trong C++ (Explicit type conversion) BÃ i 20: CÆ¡ báº£n vá» HÃ m vÃ  GiÃ¡ trá»‹ tráº£ vá» (Basic of functions and return values)\nTá»•ng quan vá» hÃ m (functions overview) GiÃ¡ trá»‹ tráº£ vá» (return values) GiÃ¡ trá»‹ tráº£ vá» cá»§a kiá»ƒu void (return values of type void) BÃ i 21: Truyá»n GiÃ¡ Trá»‹ cho HÃ m (Passing Arguments by Value)\nTham sá»‘ vÃ  Ä‘á»‘i sá»‘ cá»§a hÃ m (Function parameters and arguments) Truyá»n giÃ¡ trá»‹ cho hÃ m (Passing arguments by value) Tá»•ng káº¿t vá» phÆ°Æ¡ng phÃ¡p truyá»n giÃ¡ trá»‹ cho hÃ m (Passing argument by value) BÃ i 22: Truyá»n Tham Chiáº¿u cho HÃ m (Passing Arguments by Reference)\nTruyá»n tham chiáº¿u cho hÃ m (Passing arguments by reference) Truyá»n tham chiáº¿u háº±ng (Pass by const reference) Tá»•ng káº¿t vá» phÆ°Æ¡ng phÃ¡p truyá»n tham chiáº¿u cho hÃ m (Passing arguments by reference) BÃ i 23: Tiá»n khai bÃ¡o vÃ  Äá»‹nh nghÄ©a HÃ m (Forward declarations and Definitions of Functions)\nLá»—i â€œidentifier not foundâ€ Tiá»n khai bÃ¡o vÃ  nguyÃªn máº«u hÃ m (Forward declaration and function prototypes) Khai bÃ¡o vÃ  Ä‘á»‹nh nghÄ©a trong C++ (Declarations and definitions in C++) BÃ i 24: Giá»›i thiá»‡u vá» cáº¥u trÃºc Ä‘iá»u khiá»ƒn (Control flow introduction)\nTá»•ng quan vá» cáº¥u trÃºc Ä‘iá»u khiá»ƒn trong C++ CÃ¢u lá»‡nh dá»«ng (halt) CÃ¢u lá»‡nh nháº£y (Jumps) Cáº¥u trÃºc ráº½ nhÃ¡nh cÃ³ Ä‘iá»u kiá»‡n (Conditional branches) Cáº¥u trÃºc vÃ²ng láº·p (Loops) Xá»­ lÃ½ ngoáº¡i lá»‡ (Exceptions handling) BÃ i 25: CÃ¢u Ä‘iá»u kiá»‡n If vÃ  ToÃ¡n tá»­ Ä‘iá»u kiá»‡n (If statements and Conditional operator)\nCÃ¢u Ä‘iá»u kiá»‡n If ToÃ¡n tá»­ Ä‘iá»u kiá»‡n (Conditional operator) BÃ i 26: CÃ¢u Ä‘iá»u kiá»‡n Switch trong C++ (Switch statements)\nCÃ¢u Ä‘iá»u kiá»‡n Switch (Switch statements) Khai bÃ¡o vÃ  khá»Ÿi táº¡o biáº¿n bÃªn trong case statement BÃ i 27: CÃ¢u lá»‡nh Goto trong C++ (Goto statements)\nTá»•ng quan vá» cÃ¢u lá»‡nh Goto trong C++ Má»™t sá»‘ váº¥n Ä‘á» cá»§a cÃ¢u lá»‡nh Goto BÃ i 28: VÃ²ng láº·p While trong C++ (While statements)\nTá»•ng quan vá» cáº¥u trÃºc vÃ²ng láº·p VÃ²ng láº·p while (while statements) BÃ i 29: VÃ²ng láº·p Do while trong C++ (Do while statements)\nVÃ²ng láº·p do while (do while statements) BÃ i 30: VÃ²ng láº·p For trong C++ (For statements)\nVÃ²ng láº·p for (for statements) BÃ i 31: Tá»« khÃ³a Break and continue trong C++\nTá»« khÃ³a break Tá»« khÃ³a continue BÃ i 32: PhÃ¡t sinh sá»‘ ngáº«u nhiÃªn trong C++ (Random number generation)\nTá»•ng quan vá» phÃ¡t sinh sá»‘ ngáº«u nhiÃªn PhÃ¡t sinh sá»‘ ngáº«u nhiÃªn trong C++ PhÃ¡t sinh sá»‘ ngáº«u nhiÃªn trong C++ 11 BÃ i 33: Máº£ng 1 chiá»u trong C++ (Arrays)\nTáº¡i sao láº¡i sá»­ dá»¥ng máº£ng? Tá»•ng quan vá» máº£ng 1 chiá»u Khai bÃ¡o vÃ  khá»Ÿi táº¡o máº£ng 1 chiá»u Xuáº¥t cÃ¡c pháº§n tá»­ máº£ng 1 chiá»u Nháº­p dá»¯ liá»‡u cho máº£ng 1 chiá»u PhÃ¡t sinh dá»¯ liá»‡u ngáº«u nhiÃªn cho máº£ng 1 chiá»u BÃ i 34: CÃ¡c thao tÃ¡c trÃªn Máº£ng má»™t chiá»u\nTruyá»n máº£ng vÃ o hÃ m (passing arrays to functions) Nháº­p vÃ  xuáº¥t máº£ng 1 chiá»u Sao chÃ©p máº£ng 1 chiá»u TÃ¬m kiáº¿m pháº§n tá»­ trong máº£ng Sáº¯p xáº¿p máº£ng 1 chiá»u ThÃªm vÃ  xÃ³a má»™t pháº§n tá»­ trong máº£ng BÃ i 35: Máº£ng 2 chiá»u trong C++ (Two-dimensional arrays)\nMáº£ng 2 chiá»u lÃ  gÃ¬? Khai bÃ¡o vÃ  khá»Ÿi táº¡o máº£ng 2 chiá»u Xuáº¥t cÃ¡c pháº§n tá»­ máº£ng 2 chiá»u Nháº­p cÃ¡c pháº§n tá»­ máº£ng 2 chiá»u BÃ i 36: CÃ¡c thao tÃ¡c trÃªn Máº£ng 2 chiá»u\nTruyá»n máº£ng vÃ o hÃ m (passing arrays to functions) Nháº­p vÃ  xuáº¥t máº£ng 2 chiá»u TÃ­nh tá»•ng cÃ¡c pháº§n tá»­ trong máº£ng TÃ¬m giÃ¡ trá»‹ lá»›n nháº¥t cá»§a máº£ng 2 chiá»u BÃ i 37: Máº£ng kÃ½ tá»± trong C++ (C-style strings)\nMáº£ng kÃ½ tá»± (C-style strings) lÃ  gÃ¬? Khai bÃ¡o vÃ  khá»Ÿi táº¡o máº£ng kÃ½ tá»± (C-style strings) Xuáº¥t máº£ng kÃ½ tá»± (C-style strings) vá»›i std::cout Nháº­p máº£ng kÃ½ tá»± (C-style strings) vá»›i std::cin BÃ i 38: CÃ¡c thao tÃ¡c trÃªn Máº£ng kÃ½ tá»± (C-style strings)\nMá»™t sá»‘ thao tÃ¡c vá»›i máº£ng kÃ½ tá»± (C-style strings)\nhttps://www.freecodecamp.org/news/learn-c-with-free-31-hour-course/\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/4_variable_and_datatype/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 4: Operations on Data Introduction on Data operations Basic Operations Precedence and Associativity Prefix/Postfix Increment \u0026amp; Decrement Compound Assignment Operators Relational Operators Logical Operators Output formatting Numeric Limits Math Functions Weird Integral Types Data Operations Summary\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/5_operator_on_data/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 5: Flow Control Flow Control Introduction If Statements Else If Switch Ternary Operators Flow Control Summary\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/6_flow_control/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 6: Loops Loops Introduction For Loop While Loop Do While Loop\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/7_loop/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 7: Arrays Introduction to Arrays Declaring and using arrays Size of an array Arrays of characters Array Bounds\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/8_array/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 8: Pointers Introduction to Pointers Declaring and using pointers Pointer to char Program Memory Map Revisited Dynamic Memory Allocation Dangling Pointers When new Fails Null Pointer Safety Memory Leaks Dynamically allocated arrays\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/9_array/","series":null,"tags":null,"title":""},{"categories":null,"content":"âŒ¨ï¸ (0:00:00) Introduction to data structures âŒ¨ï¸ (0:06:33) Data Structures: List as abstract data type âŒ¨ï¸ (0:19:40) Introduction to linked list âŒ¨ï¸ (0:36:50) Arrays vs Linked Lists âŒ¨ï¸ (0:49:05) Linked List - Implementation in C/C++ âŒ¨ï¸ (1:03:02) Linked List in C/C++ - Inserting a node at beginning âŒ¨ï¸ (1:15:50) Linked List in C/C++ - Insert a node at nth position âŒ¨ï¸ (1:31:04) Linked List in C/C++ - Delete a node at nth position âŒ¨ï¸ (1:43:32) Reverse a linked list - Iterative method âŒ¨ï¸ (1:57:21) Print elements of a linked list in forward and reverse order using recursion âŒ¨ï¸ (2:11:43) Reverse a linked list using recursion âŒ¨ï¸ (2:20:38) Introduction to Doubly Linked List âŒ¨ï¸ (2:27:50) Doubly Linked List - Implementation in C/C++ âŒ¨ï¸ (2:43:09) Introduction to stack âŒ¨ï¸ (2:51:34) Array implementation of stacks âŒ¨ï¸ (3:04:42) Linked List implementation of stacks âŒ¨ï¸ (3:15:39) Reverse a string or linked list using stack. âŒ¨ï¸ (3:32:03) Check for balanced parentheses using stack âŒ¨ï¸ (3:46:14) Infix, Prefix and Postfix âŒ¨ï¸ (3:59:14) Evaluation of Prefix and Postfix expressions using stack âŒ¨ï¸ (4:14:00) Infix to Postfix using stack âŒ¨ï¸ (4:32:17) Introduction to Queues âŒ¨ï¸ (4:41:35) Array implementation of Queue âŒ¨ï¸ (4:56:33) Linked List implementation of Queue âŒ¨ï¸ (5:10:48) Introduction to Trees âŒ¨ï¸ (5:26:37) Binary Tree âŒ¨ï¸ (5:42:51) Binary Search Tree âŒ¨ï¸ (6:02:17) Binary search tree - Implementation in C/C++ âŒ¨ï¸ (6:20:52) BST implementation - memory allocation in stack and heap âŒ¨ï¸ (6:33:55) Find min and max element in a binary search tree âŒ¨ï¸ (6:39:41) Find height of a binary tree âŒ¨ï¸ (6:46:50) Binary tree traversal - breadth-first and depth-first strategies âŒ¨ï¸ (6:58:43) Binary tree: Level Order Traversal âŒ¨ï¸ (7:10:05) Binary tree traversal: Preorder, Inorder, Postorder âŒ¨ï¸ (7:24:33) Check if a binary tree is binary search tree or not âŒ¨ï¸ (7:41:01) Delete a node from Binary Search Tree âŒ¨ï¸ (7:59:27) Inorder Successor in a binary search tree âŒ¨ï¸ (8:17:23) Introduction to graphs âŒ¨ï¸ (8:34:05) Properties of Graphs âŒ¨ï¸ (8:49:19) Graph Representation part 01 - Edge List âŒ¨ï¸ (9:03:03) Graph Representation part 02 - Adjacency Matrix âŒ¨ï¸ (9:17:46) Graph Representation part 03 - Adjacency List\n","date":"Jan 1, 0001","img":"","permalink":"/courses/data_structures/","series":null,"tags":null,"title":""},{"categories":null,"content":"ThÃ´ng thÆ°á»ng, chÃºng ta Ä‘á»c ná»™i dung cá»§a file sau khi má»Ÿ file.\nGiáº£ sá»­ chÃºng ta cÃ³ file \u0026ldquo;test.txt\u0026rdquo; cÃ³ ná»™i dung nhÆ° bÃªn dÆ°á»›i:\n1This file is testing. 2Good Luck! HÃ m má»Ÿ file ra Ä‘Æ°á»£c viáº¿t nhÆ° tháº¿ nÃ y:\nf = open(\u0026ldquo;test.txt\u0026rdquo;,\u0026lsquo;r\u0026rsquo;,encoding = \u0026lsquo;utf-8\u0026rsquo;)\nÄá»ƒ Ä‘á»c ná»™i dung file, python há»— trá»£ cÃ¡c hÃ m lÃ  read, readline, readlines, má»—i hÃ m sáº½ cÃ³ tÃ¡c dá»¥ng khÃ¡c nhau\nhÃ m read sáº½ tráº£ vá» toÃ n bá»™ ná»™i dung cá»§a file f.read()\n'This file is testing.\\nGood Luck!\\n'\nhÃ m readline, má»—i láº§n Ä‘á»c sáº½ tráº£ vá» 1 dÃ²ng trong file f.readline()\n\u0026lsquo;This file is testing.\\n\u0026rsquo;\nKhi gá»i readline má»™t láº§n ná»¯a, chÆ°Æ¡ng trÃ¬nh sáº½ tráº£ vá» dÃ²ng tiáº¿p theo\nf.readline()\n\u0026lsquo;Good Luck!\\n\u0026rsquo;\nhÃ m readlines sáº½ tráº£ vá» má»™t máº£ng cÃ¡c chuá»—i, má»—i chuá»—i tÆ°Æ¡ng á»©ng má»™t dÃ²ng trong file f.readlines()\n[\u0026lsquo;This file is testing.\\n\u0026rsquo;, \u0026lsquo;Good Luck!\\n\u0026rsquo;]\n","date":"Jan 1, 0001","img":"","permalink":"/courses/python/io/","series":null,"tags":null,"title":""},{"categories":null,"content":"","date":"Jan 1, 0001","img":"","permalink":"/contact/","series":null,"tags":null,"title":"Contact Us"},{"categories":null,"content":"","date":"Jan 1, 0001","img":"","permalink":"/faq/","series":null,"tags":null,"title":"FAQs"},{"categories":null,"content":"","date":"Jan 1, 0001","img":"","permalink":"/offline/","series":null,"tags":null,"title":"Offline"},{"categories":null,"content":"Tools sinh password\nTools sinh sá»‘ ngáº«u nhiÃªn\n","date":"Jan 1, 0001","img":"","permalink":"/tools/","series":null,"tags":null,"title":"Tools"}]