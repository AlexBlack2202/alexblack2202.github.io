[{"categories":null,"content":" I. Structured Prompt Outputs l√† g√¨ ? C√°ch t·∫°o Structured Prompt Outputs V√≠ d·ª•: T·∫°o m·ªôt danh s√°ch c√¥ng vi·ªác h√†ng ng√†y C√°c l·ª£i √≠ch c·ªßa Structured Prompt Outputs C√°c chi·∫øn l∆∞·ª£c t·∫°o Structured Prompts hi·ªáu qu·∫£ II. ·ª®ng d·ª•ng Structured Prompt Outputs trong c√°c d·ª± √°n AI. 1. X√¢y d·ª±ng h·ªá th·ªëng qu·∫£n l√Ω c√¥ng vi·ªác (Task Management System) 2. T·∫°o API gi·∫£ l·∫≠p cho d·ªØ li·ªáu s·∫£n ph·∫©m 3. Ph√¢n t√≠ch d·ªØ li·ªáu b√°n h√†ng 4. T·∫°o n·ªôi dung b√†i vi·∫øt c√≥ c·∫•u tr√∫c 5. T·∫°o c√¥ng th·ª©c n·∫•u ƒÉn c√≥ c·∫•u tr√∫c 6. T·∫°o c√¢u h·ªèi kh·∫£o s√°t c√≥ c·∫•u tr√∫c III. S·ª≠ d·ª•ng Structured Prompt Outputs trong chatbot C·∫•u h√¨nh bot B∆∞·ªõc 1: ƒê·ªãnh nghƒ©a c·∫•u tr√∫c ƒë·∫ßu ra B∆∞·ªõc 2: T·∫°o prompt c√≥ c·∫•u tr√∫c B∆∞·ªõc 3: X·ª≠ l√Ω ƒë·∫ßu ra B∆∞·ªõc 4: T√≠ch h·ª£p v√†o chatbot 2. V√≠ d·ª• th·ª±c t·∫ø V√≠ d·ª• 1: Chatbot h·ªó tr·ª£ ƒë·∫∑t h√†ng V√≠ d·ª• 2: Chatbot ph√¢n lo·∫°i √Ω ki·∫øn kh√°ch h√†ng M·ªôt s·ªë kh√≥ khƒÉn khi tri·ªÉn khai chatbot v√† c√°ch gi·∫£i quy·∫øt 1. Thi·∫øu hi·ªÉu bi·∫øt v·ªÅ ng√¥n ng·ªØ t·ª± nhi√™n (NLP) 2. Kh√≥ khƒÉn trong vi·ªác thi·∫øt k·∫ø prompt 3. Chi ph√≠ ƒë·∫ßu t∆∞ ban ƒë·∫ßu cao 4. Thi·∫øu d·ªØ li·ªáu ch·∫•t l∆∞·ª£ng 5. Lo ng·∫°i v·ªÅ quy·ªÅn ri√™ng t∆∞ v√† b·∫£o m·∫≠t 6. Kh√°ch h√†ng kh√¥ng c√≥ ni·ªÅm tin v√†o AI 7. X√°c ƒë·ªãnh tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng ch∆∞a ph√π h·ª£p 8. Kh√¥ng x√¢y d·ª±ng k·ªãch b·∫£n ri√™ng cho doanh nghi·ªáp IV. ƒêo l∆∞·ªùng hi·ªáu su·∫•t c·ªßa Structured Prompt Outputs 1. X√°c ƒë·ªãnh c√°c ch·ªâ s·ªë ƒëo l∆∞·ªùng hi·ªáu su·∫•t (KPI) 2. Ph√¢n t√≠ch ngu·ªìn t∆∞∆°ng t√°c 3. S·ª≠ d·ª•ng ph√¢n t√≠ch n√¢ng cao (Advanced Analytics) 4. Ki·ªÉm tra t√≠nh nh·∫•t qu√°n c·ªßa ƒë·∫ßu ra 5. Thu th·∫≠p ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng 6. Th·ª±c hi·ªán A/B Testing 7. Theo d√µi v√† c·∫£i ti·∫øn li√™n t·ª•c I. Structured Prompt Outputs l√† g√¨ ? Tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu, h√£y c√πng l√†m r√µ kh√°i ni·ªám Structured Prompt Outputs. ƒê√¢y l√† c√°ch m√† ch√∫ng ta h∆∞·ªõng d·∫´n c√°c m√¥ h√¨nh ng√¥n ng·ªØ nh∆∞ GPT-4 ho·∫∑c PaLM t·∫°o ra k·∫øt qu·∫£ theo m·ªôt ƒë·ªãnh d·∫°ng c·ª• th·ªÉ, ch·∫≥ng h·∫°n nh∆∞ JSON, XML, ho·∫∑c th·∫≠m ch√≠ l√† danh s√°ch c√≥ c·∫•u tr√∫c. ƒêi·ªÅu n√†y ƒë·∫∑c bi·ªát h·ªØu √≠ch trong c√°c ·ª©ng d·ª•ng th·ª±c t·∫ø, v√¨ n√≥ gi√∫p d·ªØ li·ªáu ƒë·∫ßu ra tr·ªü n√™n d·ªÖ ƒë·ªçc, d·ªÖ x·ª≠ l√Ω, v√† c√≥ t·ªï ch·ª©c h∆°n .\nV√≠ d·ª•, n·∫øu b·∫°n mu·ªën y√™u c·∫ßu m·ªôt LLM t·∫°o ra m·ªôt danh s√°ch c√°c s·∫£n ph·∫©m k√®m theo gi√° c·∫£, thay v√¨ nh·∫≠n ƒë∆∞·ª£c m·ªôt ƒëo·∫°n vƒÉn d√†i d√≤ng kh√¥ng r√µ r√†ng, b·∫°n c√≥ th·ªÉ ch·ªâ ƒë·ªãnh r·∫±ng k·∫øt qu·∫£ ph·∫£i ·ªü d·∫°ng JSON:\n1{ 2 \u0026#34;products\u0026#34;: [ 3 { 4 \u0026#34;name\u0026#34;: \u0026#34;Laptop Dell XPS 13\u0026#34;, 5 \u0026#34;price\u0026#34;: \u0026#34;$999\u0026#34; 6 }, 7 { 8 \u0026#34;name\u0026#34;: \u0026#34;Smartphone Samsung Galaxy S23\u0026#34;, 9 \u0026#34;price\u0026#34;: \u0026#34;$799\u0026#34; 10 } 11 ] 12} K·∫øt qu·∫£ n√†y kh√¥ng ch·ªâ d·ªÖ ƒë·ªçc m√† c√≤n r·∫•t thu·∫≠n ti·ªán ƒë·ªÉ t√≠ch h·ª£p v√†o c√°c h·ªá th·ªëng ph·∫ßn m·ªÅm kh√°c.\nC√°ch t·∫°o Structured Prompt Outputs ƒê·ªÉ t·∫°o ra c√°c ƒë·∫ßu ra c√≥ c·∫•u tr√∫c, ƒëi·ªÅu quan tr·ªçng nh·∫•t l√† b·∫°n c·∫ßn h∆∞·ªõng d·∫´n r√µ r√†ng cho LLM. ƒêi·ªÅu n√†y bao g·ªìm vi·ªác s·ª≠ d·ª•ng c√°c prompts ƒë∆∞·ª£c thi·∫øt k·∫ø c·∫©n th·∫≠n, ƒë·∫£m b·∫£o r·∫±ng m√¥ h√¨nh hi·ªÉu ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng mong mu·ªën c·ªßa b·∫°n. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë b∆∞·ªõc c∆° b·∫£n ƒë·ªÉ b·∫Øt ƒë·∫ßu:\nX√°c ƒë·ªãnh m·ª•c ti√™u: B·∫°n mu·ªën g√¨ t·ª´ LLM? M·ªôt danh s√°ch, m·ªôt ƒë·ªëi t∆∞·ª£ng JSON, hay m·ªôt c√¢u tr·∫£ l·ªùi c√≥ c·∫•u tr√∫c? S·ª≠ d·ª•ng v√≠ d·ª•: Cung c·∫•p m·ªôt v√†i v√≠ d·ª• v·ªÅ ƒë·ªãnh d·∫°ng ƒë·∫ßu ra m√† b·∫°n mong ƒë·ª£i. ƒê·∫∑t y√™u c·∫ßu c·ª• th·ªÉ: S·ª≠ d·ª•ng c√°c t·ª´ kh√≥a nh∆∞ \u0026ldquo;H√£y tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng JSON\u0026rdquo; ho·∫∑c \u0026ldquo;Danh s√°ch ph·∫£i c√≥ √≠t nh·∫•t 5 m·ª•c\u0026rdquo;. V√≠ d·ª•: T·∫°o m·ªôt danh s√°ch c√¥ng vi·ªác h√†ng ng√†y Gi·∫£ s·ª≠ b·∫°n mu·ªën LLM t·∫°o ra m·ªôt danh s√°ch c√°c c√¥ng vi·ªác h√†ng ng√†y. B·∫°n c√≥ th·ªÉ vi·∫øt prompt nh∆∞ sau:\nPrompt:\n1H√£y t·∫°o m·ªôt danh s√°ch c√°c c√¥ng vi·ªác c·∫ßn l√†m h√†ng ng√†y cho m·ªôt l·∫≠p tr√¨nh vi√™n. Tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng JSON v·ªõi c√°c tr∆∞·ªùng \u0026#34;task\u0026#34; (t√™n c√¥ng vi·ªác) v√† \u0026#34;priority\u0026#34; (m·ª©c ƒë·ªô ∆∞u ti√™n t·ª´ 1 ƒë·∫øn 5). K·∫øt qu·∫£ d·ª± ki·∫øn:\n1{ 2 \u0026#34;tasks\u0026#34;: [ 3 { 4 \u0026#34;task\u0026#34;: \u0026#34;Ki·ªÉm tra email\u0026#34;, 5 \u0026#34;priority\u0026#34;: 3 6 }, 7 { 8 \u0026#34;task\u0026#34;: \u0026#34;Code review\u0026#34;, 9 \u0026#34;priority\u0026#34;: 4 10 }, 11 { 12 \u0026#34;task\u0026#34;: \u0026#34;Vi·∫øt t√†i li·ªáu\u0026#34;, 13 \u0026#34;priority\u0026#34;: 2 14 } 15 ] 16} Nh∆∞ b·∫°n th·∫•y, b·∫±ng c√°ch y√™u c·∫ßu c·ª• th·ªÉ ƒë·ªãnh d·∫°ng JSON, LLM ƒë√£ t·∫°o ra m·ªôt k·∫øt qu·∫£ c√≥ t·ªï ch·ª©c v√† d·ªÖ s·ª≠ d·ª•ng.\nC√°c l·ª£i √≠ch c·ªßa Structured Prompt Outputs Structured Prompt Outputs kh√¥ng ch·ªâ gi√∫p c·∫£i thi·ªán t√≠nh ƒë·ªçc hi·ªÉu m√† c√≤n mang l·∫°i nhi·ªÅu l·ª£i √≠ch kh√°c:\nTƒÉng t√≠nh nh·∫•t qu√°n: Khi s·ª≠ d·ª•ng structured prompts, b·∫°n c√≥ th·ªÉ ƒë·∫£m b·∫£o r·∫±ng m·ªçi l·∫ßn g·ªçi API ƒë·ªÅu tr·∫£ v·ªÅ k·∫øt qu·∫£ theo c√πng m·ªôt ƒë·ªãnh d·∫°ng . ƒêi·ªÅu n√†y r·∫•t quan tr·ªçng trong c√°c ·ª©ng d·ª•ng s·∫£n xu·∫•t, n∆°i t√≠nh nh·∫•t qu√°n l√† y·∫øu t·ªë then ch·ªët.\nC·∫£i thi·ªán kh·∫£ nƒÉng t√≠ch h·ª£p: D·ªØ li·ªáu c√≥ c·∫•u tr√∫c d·ªÖ d√†ng t√≠ch h·ª£p v√†o c√°c h·ªá th·ªëng kh√°c, ch·∫≥ng h·∫°n nh∆∞ c∆° s·ªü d·ªØ li·ªáu, API, ho·∫∑c giao di·ªán ng∆∞·ªùi d√πng .\nGi·∫£m thi·ªÉu l·ªói: ƒê·ªãnh d·∫°ng c√≥ c·∫•u tr√∫c gi√∫p gi·∫£m thi·ªÉu nguy c∆° x·∫£y ra l·ªói do hi·ªÉu sai √Ω nghƒ©a c·ªßa d·ªØ li·ªáu .\nT·ªëi ∆∞u h√≥a SEO: C√°c b√†i vi·∫øt ho·∫∑c n·ªôi dung ƒë∆∞·ª£c t·∫°o ra theo ƒë·ªãnh d·∫°ng c√≥ c·∫•u tr√∫c th∆∞·ªùng d·ªÖ d√†ng h∆°n ƒë·ªÉ t·ªëi ∆∞u h√≥a cho c√¥ng c·ª• t√¨m ki·∫øm .\nC√°c chi·∫øn l∆∞·ª£c t·∫°o Structured Prompts hi·ªáu qu·∫£ ƒê·ªÉ t·∫°o ra c√°c structured prompts hi·ªáu qu·∫£, b·∫°n c·∫ßn √°p d·ª•ng m·ªôt s·ªë chi·∫øn l∆∞·ª£c sau:\nS·ª≠ d·ª•ng v√≠ d·ª•: ƒê∆∞a ra m·ªôt v√†i v√≠ d·ª• v·ªÅ ƒë·ªãnh d·∫°ng ƒë·∫ßu ra m√† b·∫°n mong ƒë·ª£i. ƒêi·ªÅu n√†y gi√∫p LLM hi·ªÉu r√µ h∆°n v·ªÅ y√™u c·∫ßu c·ªßa b·∫°n .\nV√≠ d·ª•:\n1H√£y t·∫°o m·ªôt danh s√°ch c√°c m√≥n ƒÉn Vi·ªát Nam n·ªïi ti·∫øng. K·∫øt qu·∫£ ph·∫£i ·ªü d·∫°ng JSON v·ªõi c√°c tr∆∞·ªùng \u0026#34;dish\u0026#34; (t√™n m√≥n ƒÉn) v√† \u0026#34;region\u0026#34; (v√πng mi·ªÅn). 2 3V√≠ d·ª•: 4{ 5 \u0026#34;dishes\u0026#34;: [ 6 { 7 \u0026#34;dish\u0026#34;: \u0026#34;Ph·ªü\u0026#34;, 8 \u0026#34;region\u0026#34;: \u0026#34;B·∫Øc\u0026#34; 9 }, 10 { 11 \u0026#34;dish\u0026#34;: \u0026#34;B√°nh x√®o\u0026#34;, 12 \u0026#34;region\u0026#34;: \u0026#34;Trung\u0026#34; 13 } 14 ] 15} S·ª≠ d·ª•ng d·∫•u ph√¢n c√°ch r√µ r√†ng: N·∫øu b·∫°n mu·ªën LLM t·∫°o ra nhi·ªÅu ƒëo·∫°n th√¥ng tin kh√°c nhau, h√£y s·ª≠ d·ª•ng c√°c d·∫•u ph√¢n c√°ch nh∆∞ ti√™u ƒë·ªÅ ho·∫∑c s·ªë th·ª© t·ª± .\nV√≠ d·ª•:\n1H√£y t·∫°o m·ªôt b√†i b√°o ng·∫Øn v·ªÅ l·ª£i √≠ch c·ªßa vi·ªác t·∫≠p th·ªÉ d·ª•c. B√†i b√°o ph·∫£i c√≥ ba ph·∫ßn: Gi·ªõi thi·ªáu, L·ª£i √≠ch, v√† K·∫øt lu·∫≠n. M·ªói ph·∫ßn ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng m·ªôt ti√™u ƒë·ªÅ in ƒë·∫≠m. Y√™u c·∫ßu ki·ªÉm tra ch·∫•t l∆∞·ª£ng: B·∫°n c√≥ th·ªÉ y√™u c·∫ßu LLM ki·ªÉm tra l·∫°i k·∫øt qu·∫£ tr∆∞·ªõc khi tr·∫£ v·ªÅ. ƒêi·ªÅu n√†y gi√∫p ƒë·∫£m b·∫£o r·∫±ng d·ªØ li·ªáu ƒë·∫ßu ra ƒë√°p ·ª©ng ƒë√∫ng y√™u c·∫ßu .\nV√≠ d·ª•:\n1H√£y t·∫°o m·ªôt danh s√°ch c√°c qu·ªëc gia ƒê√¥ng Nam √Å k√®m theo d√¢n s·ªë. Ki·ªÉm tra l·∫°i ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng t·∫•t c·∫£ c√°c qu·ªëc gia ƒë·ªÅu n·∫±m trong khu v·ª±c ƒê√¥ng Nam √Å. II. ·ª®ng d·ª•ng Structured Prompt Outputs trong c√°c d·ª± √°n AI. 1. X√¢y d·ª±ng h·ªá th·ªëng qu·∫£n l√Ω c√¥ng vi·ªác (Task Management System) Gi·∫£ s·ª≠ b·∫°n ƒëang ph√°t tri·ªÉn m·ªôt ·ª©ng d·ª•ng qu·∫£n l√Ω c√¥ng vi·ªác, n∆°i ng∆∞·ªùi d√πng c√≥ th·ªÉ y√™u c·∫ßu AI t·∫°o ra danh s√°ch c√°c nhi·ªám v·ª• c·∫ßn l√†m cho m·ªôt ng√†y c·ª• th·ªÉ. B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng Structured Prompt Outputs ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng d·ªØ li·ªáu ƒë·∫ßu ra lu√¥n ·ªü ƒë·ªãnh d·∫°ng JSON, d·ªÖ d√†ng t√≠ch h·ª£p v√†o c∆° s·ªü d·ªØ li·ªáu ho·∫∑c giao di·ªán ng∆∞·ªùi d√πng.\nPrompt:\n1H√£y t·∫°o m·ªôt danh s√°ch c√°c c√¥ng vi·ªác c·∫ßn l√†m cho m·ªôt l·∫≠p tr√¨nh vi√™n v√†o th·ª© Hai. M·ªói c√¥ng vi·ªác ph·∫£i bao g·ªìm t√™n c√¥ng vi·ªác, th·ªùi gian b·∫Øt ƒë·∫ßu, v√† m·ª©c ƒë·ªô ∆∞u ti√™n (t·ª´ 1 ƒë·∫øn 5). Tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng JSON. K·∫øt qu·∫£ d·ª± ki·∫øn:\n1{ 2 \u0026#34;tasks\u0026#34;: [ 3 { 4 \u0026#34;name\u0026#34;: \u0026#34;Ki·ªÉm tra email\u0026#34;, 5 \u0026#34;start_time\u0026#34;: \u0026#34;09:00 AM\u0026#34;, 6 \u0026#34;priority\u0026#34;: 3 7 }, 8 { 9 \u0026#34;name\u0026#34;: \u0026#34;Code review\u0026#34;, 10 \u0026#34;start_time\u0026#34;: \u0026#34;10:00 AM\u0026#34;, 11 \u0026#34;priority\u0026#34;: 4 12 }, 13 { 14 \u0026#34;name\u0026#34;: \u0026#34;Vi·∫øt t√†i li·ªáu\u0026#34;, 15 \u0026#34;start_time\u0026#34;: \u0026#34;02:00 PM\u0026#34;, 16 \u0026#34;priority\u0026#34;: 2 17 } 18 ] 19} D·ªØ li·ªáu n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng tr·ª±c ti·∫øp trong ·ª©ng d·ª•ng c·ªßa b·∫°n ƒë·ªÉ hi·ªÉn th·ªã l·ªãch l√†m vi·ªác h√†ng ng√†y .\n2. T·∫°o API gi·∫£ l·∫≠p cho d·ªØ li·ªáu s·∫£n ph·∫©m N·∫øu b·∫°n ƒëang x√¢y d·ª±ng m·ªôt trang th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ v√† mu·ªën th·ª≠ nghi·ªám v·ªõi d·ªØ li·ªáu s·∫£n ph·∫©m m√† kh√¥ng c·∫ßn k·∫øt n·ªëi t·ªõi c∆° s·ªü d·ªØ li·ªáu th·∫≠t, b·∫°n c√≥ th·ªÉ y√™u c·∫ßu LLM t·∫°o ra m·ªôt b·ªô d·ªØ li·ªáu gi·∫£ l·∫≠p d∆∞·ªõi d·∫°ng JSON.\nPrompt:\n1H√£y t·∫°o m·ªôt danh s√°ch c√°c s·∫£n ph·∫©m ƒëi·ªán t·ª≠ v·ªõi c√°c tr∆∞·ªùng: t√™n s·∫£n ph·∫©m, gi√° c·∫£, v√† ƒë√°nh gi√° t·ª´ kh√°ch h√†ng (t·ª´ 1 ƒë·∫øn 5 sao). K·∫øt qu·∫£ ph·∫£i ·ªü d·∫°ng JSON. K·∫øt qu·∫£ d·ª± ki·∫øn:\n1{ 2 \u0026#34;products\u0026#34;: [ 3 { 4 \u0026#34;name\u0026#34;: \u0026#34;Laptop Dell XPS 13\u0026#34;, 5 \u0026#34;price\u0026#34;: \u0026#34;$999\u0026#34;, 6 \u0026#34;rating\u0026#34;: 4.8 7 }, 8 { 9 \u0026#34;name\u0026#34;: \u0026#34;Smartphone Samsung Galaxy S23\u0026#34;, 10 \u0026#34;price\u0026#34;: \u0026#34;$799\u0026#34;, 11 \u0026#34;rating\u0026#34;: 4.6 12 }, 13 { 14 \u0026#34;name\u0026#34;: \u0026#34;Tai nghe AirPods Pro\u0026#34;, 15 \u0026#34;price\u0026#34;: \u0026#34;$249\u0026#34;, 16 \u0026#34;rating\u0026#34;: 4.9 17 } 18 ] 19} B·ªô d·ªØ li·ªáu n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ki·ªÉm tra giao di·ªán ng∆∞·ªùi d√πng ho·∫∑c c√°c t√≠nh nƒÉng t√¨m ki·∫øm/s·∫Øp x·∫øp s·∫£n ph·∫©m .\n3. Ph√¢n t√≠ch d·ªØ li·ªáu b√°n h√†ng Trong m·ªôt d·ª± √°n ph√¢n t√≠ch d·ªØ li·ªáu, b·∫°n c√≥ th·ªÉ y√™u c·∫ßu AI x·ª≠ l√Ω d·ªØ li·ªáu b√°n h√†ng v√† t·∫°o ra b√°o c√°o d∆∞·ªõi d·∫°ng JSON. ƒêi·ªÅu n√†y gi√∫p b·∫°n d·ªÖ d√†ng t√≠ch h·ª£p k·∫øt qu·∫£ v√†o c√°c c√¥ng c·ª• ph√¢n t√≠ch nh∆∞ Tableau ho·∫∑c Power BI.\nPrompt:\n1H√£y ph√¢n t√≠ch d·ªØ li·ªáu b√°n h√†ng sau v√† t·∫°o ra m·ªôt b√°o c√°o t·ªïng quan. D·ªØ li·ªáu bao g·ªìm c√°c s·∫£n ph·∫©m: Laptop ($1000, b√°n ƒë∆∞·ª£c 10 c√°i), Smartphone ($800, b√°n ƒë∆∞·ª£c 20 c√°i), v√† Tablet ($600, b√°n ƒë∆∞·ª£c 15 c√°i). B√°o c√°o ph·∫£i bao g·ªìm t·ªïng doanh thu v√† s·ªë l∆∞·ª£ng s·∫£n ph·∫©m b√°n ƒë∆∞·ª£c. Tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng JSON. K·∫øt qu·∫£ d·ª± ki·∫øn:\n1{ 2 \u0026#34;sales_report\u0026#34;: { 3 \u0026#34;total_revenue\u0026#34;: \u0026#34;$29,000\u0026#34;, 4 \u0026#34;total_products_sold\u0026#34;: 45, 5 \u0026#34;details\u0026#34;: [ 6 { 7 \u0026#34;product\u0026#34;: \u0026#34;Laptop\u0026#34;, 8 \u0026#34;revenue\u0026#34;: \u0026#34;$10,000\u0026#34;, 9 \u0026#34;quantity_sold\u0026#34;: 10 10 }, 11 { 12 \u0026#34;product\u0026#34;: \u0026#34;Smartphone\u0026#34;, 13 \u0026#34;revenue\u0026#34;: \u0026#34;$16,000\u0026#34;, 14 \u0026#34;quantity_sold\u0026#34;: 20 15 }, 16 { 17 \u0026#34;product\u0026#34;: \u0026#34;Tablet\u0026#34;, 18 \u0026#34;revenue\u0026#34;: \u0026#34;$9,000\u0026#34;, 19 \u0026#34;quantity_sold\u0026#34;: 15 20 } 21 ] 22 } 23} D·ªØ li·ªáu n√†y r·∫•t h·ªØu √≠ch khi b·∫°n mu·ªën t·∫°o dashboard ho·∫∑c bi·ªÉu ƒë·ªì ph√¢n t√≠ch .\n4. T·∫°o n·ªôi dung b√†i vi·∫øt c√≥ c·∫•u tr√∫c N·∫øu b·∫°n ƒëang s·ª≠ d·ª•ng AI ƒë·ªÉ h·ªó tr·ª£ vi·∫øt b√†i, b·∫°n c√≥ th·ªÉ y√™u c·∫ßu n√≥ t·∫°o ra n·ªôi dung theo m·ªôt c·∫•u tr√∫c nh·∫•t ƒë·ªãnh. V√≠ d·ª•, b·∫°n c√≥ th·ªÉ y√™u c·∫ßu AI vi·∫øt m·ªôt b√†i b√°o ng·∫Øn v·ªÅ l·ª£i √≠ch c·ªßa vi·ªác ƒë·ªçc s√°ch.\nPrompt:\n1H√£y vi·∫øt m·ªôt b√†i b√°o ng·∫Øn v·ªÅ l·ª£i √≠ch c·ªßa vi·ªác ƒë·ªçc s√°ch. B√†i b√°o ph·∫£i c√≥ ba ph·∫ßn: Gi·ªõi thi·ªáu, L·ª£i √≠ch, v√† K·∫øt lu·∫≠n. M·ªói ph·∫ßn ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng m·ªôt ti√™u ƒë·ªÅ in ƒë·∫≠m. Tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng JSON. K·∫øt qu·∫£ d·ª± ki·∫øn:\n1{ 2 \u0026#34;article\u0026#34;: { 3 \u0026#34;introduction\u0026#34;: \u0026#34;**Gi·ªõi thi·ªáu**: ƒê·ªçc s√°ch l√† m·ªôt th√≥i quen mang l·∫°i nhi·ªÅu l·ª£i √≠ch cho s·ª©c kh·ªèe tinh th·∫ßn v√† tr√≠ tu·ªá.\u0026#34;, 4 \u0026#34;benefits\u0026#34;: \u0026#34;**L·ª£i √≠ch**: ƒê·ªçc s√°ch gi√∫p c·∫£i thi·ªán v·ªën t·ª´ v·ª±ng, tƒÉng kh·∫£ nƒÉng t·∫≠p trung, v√† gi·∫£m cƒÉng th·∫≥ng.\u0026#34;, 5 \u0026#34;conclusion\u0026#34;: \u0026#34;**K·∫øt lu·∫≠n**: H√£y d√†nh √≠t nh·∫•t 30 ph√∫t m·ªói ng√†y ƒë·ªÉ ƒë·ªçc s√°ch v√† t·∫≠n h∆∞·ªüng nh·ªØng l·ª£i √≠ch tuy·ªát v·ªùi m√† n√≥ mang l·∫°i.\u0026#34; 6 } 7} ƒê·ªãnh d·∫°ng n√†y gi√∫p b·∫°n d·ªÖ d√†ng chuy·ªÉn ƒë·ªïi n·ªôi dung th√†nh c√°c ƒë·ªãnh d·∫°ng kh√°c, ch·∫≥ng h·∫°n nh∆∞ HTML ho·∫∑c Markdown .\n5. T·∫°o c√¥ng th·ª©c n·∫•u ƒÉn c√≥ c·∫•u tr√∫c N·∫øu b·∫°n ƒëang x√¢y d·ª±ng m·ªôt ·ª©ng d·ª•ng chia s·∫ª c√¥ng th·ª©c n·∫•u ƒÉn, b·∫°n c√≥ th·ªÉ y√™u c·∫ßu AI t·∫°o ra c√°c c√¥ng th·ª©c c√≥ c·∫•u tr√∫c, bao g·ªìm t√™n m√≥n ƒÉn, danh s√°ch nguy√™n li·ªáu, v√† c√°c b∆∞·ªõc th·ª±c hi·ªán.\nPrompt:\n1H√£y t·∫°o m·ªôt c√¥ng th·ª©c n·∫•u ƒÉn cho m√≥n \u0026#34;B√°nh x√®o\u0026#34;. C√¥ng th·ª©c ph·∫£i bao g·ªìm c√°c tr∆∞·ªùng: t√™n m√≥n ƒÉn, danh s√°ch nguy√™n li·ªáu, v√† c√°c b∆∞·ªõc th·ª±c hi·ªán. Tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng JSON. K·∫øt qu·∫£ d·ª± ki·∫øn:\n1{ 2 \u0026#34;recipe\u0026#34;: { 3 \u0026#34;name\u0026#34;: \u0026#34;B√°nh x√®o\u0026#34;, 4 \u0026#34;ingredients\u0026#34;: [ 5 \u0026#34;200g b·ªôt g·∫°o\u0026#34;, 6 \u0026#34;100g t√¥m\u0026#34;, 7 \u0026#34;50g gi√° ƒë·ªó\u0026#34;, 8 \u0026#34;1 c·ªß h√†nh t√≠m\u0026#34; 9 ], 10 \u0026#34;steps\u0026#34;: [ 11 \u0026#34;Tr·ªôn b·ªôt g·∫°o v·ªõi n∆∞·ªõc ƒë·ªÉ t·∫°o h·ªón h·ª£p l·ªèng.\u0026#34;, 12 \u0026#34;Phi th∆°m h√†nh t√≠m v√† cho t√¥m v√†o x√†o s∆°.\u0026#34;, 13 \u0026#34;ƒê·ªï h·ªón h·ª£p b·ªôt l√™n ch·∫£o n√≥ng v√† th√™m gi√° ƒë·ªó.\u0026#34;, 14 \u0026#34;G·∫≠p ƒë√¥i b√°nh v√† chi√™n v√†ng ƒë·ªÅu hai m·∫∑t.\u0026#34; 15 ] 16 } 17} C√¥ng th·ª©c n√†y c√≥ th·ªÉ ƒë∆∞·ª£c t√≠ch h·ª£p tr·ª±c ti·∫øp v√†o ·ª©ng d·ª•ng c·ªßa b·∫°n ƒë·ªÉ hi·ªÉn th·ªã cho ng∆∞·ªùi d√πng .\n6. T·∫°o c√¢u h·ªèi kh·∫£o s√°t c√≥ c·∫•u tr√∫c N·∫øu b·∫°n ƒëang thi·∫øt k·∫ø m·ªôt cu·ªôc kh·∫£o s√°t, b·∫°n c√≥ th·ªÉ y√™u c·∫ßu AI t·∫°o ra m·ªôt b·ªô c√¢u h·ªèi c√≥ c·∫•u tr√∫c, bao g·ªìm lo·∫°i c√¢u h·ªèi (tr·∫Øc nghi·ªám, m·ªü, thang ƒëo) v√† c√°c t√πy ch·ªçn tr·∫£ l·ªùi.\nPrompt:\n1H√£y t·∫°o m·ªôt b·ªô c√¢u h·ªèi kh·∫£o s√°t v·ªÅ th√≥i quen ƒë·ªçc s√°ch. M·ªói c√¢u h·ªèi ph·∫£i bao g·ªìm c√°c tr∆∞·ªùng: n·ªôi dung c√¢u h·ªèi, lo·∫°i c√¢u h·ªèi, v√† c√°c t√πy ch·ªçn tr·∫£ l·ªùi (n·∫øu c√≥). Tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng JSON. K·∫øt qu·∫£ d·ª± ki·∫øn:\n1{ 2 \u0026#34;survey_questions\u0026#34;: [ 3 { 4 \u0026#34;question\u0026#34;: \u0026#34;B·∫°n ƒë·ªçc s√°ch bao nhi√™u l·∫ßn m·ªói tu·∫ßn?\u0026#34;, 5 \u0026#34;type\u0026#34;: \u0026#34;multiple_choice\u0026#34;, 6 \u0026#34;options\u0026#34;: [\u0026#34;Kh√¥ng bao gi·ªù\u0026#34;, \u0026#34;1-2 l·∫ßn\u0026#34;, \u0026#34;3-4 l·∫ßn\u0026#34;, \u0026#34;H√†ng ng√†y\u0026#34;] 7 }, 8 { 9 \u0026#34;question\u0026#34;: \u0026#34;Th·ªÉ lo·∫°i s√°ch y√™u th√≠ch c·ªßa b·∫°n l√† g√¨?\u0026#34;, 10 \u0026#34;type\u0026#34;: \u0026#34;open_ended\u0026#34; 11 }, 12 { 13 \u0026#34;question\u0026#34;: \u0026#34;B·∫°n ƒë√°nh gi√° m·ª©c ƒë·ªô h√†i l√≤ng v·ªõi th√≥i quen ƒë·ªçc s√°ch hi·ªán t·∫°i nh∆∞ th·∫ø n√†o?\u0026#34;, 14 \u0026#34;type\u0026#34;: \u0026#34;scale\u0026#34;, 15 \u0026#34;options\u0026#34;: [\u0026#34;1 - R·∫•t kh√¥ng h√†i l√≤ng\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;4\u0026#34;, \u0026#34;5 - R·∫•t h√†i l√≤ng\u0026#34;] 16 } 17 ] 18} B·ªô c√¢u h·ªèi n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o form kh·∫£o s√°t tr√™n c√°c n·ªÅn t·∫£ng nh∆∞ Google Forms ho·∫∑c Typeform .\nIII. S·ª≠ d·ª•ng Structured Prompt Outputs trong chatbot Chatbot l√† m·ªôt nh√¢n vi√™n ·∫£o, c·∫ßn m·∫´n, chƒÉm ch·ªâ, kh√¥ng c·∫ßn tr·∫£ l∆∞∆°ng, kh√¥ng c·∫ßn tr·∫£ BHXH, c√≥ th·ªÉ online 24/24 gi·∫£i quy·∫øt nhu c·∫ßu c·ªßa kh√°c h√†ng. Ng√†y nay, c√≥ nhi·ªÅu c√¥ng ty / t·∫≠p ƒëo√†n ƒë√£ t√≠ch h·ª£p chatbot v√†o c√°c ·ª©ng d·ª•ng t·ª± ƒë·ªông c·ªßa m√¨nh , gi√∫p tƒÉng c∆∞·ªùng tr·∫£i nghi·ªám kh√°ch h√†ng.\n·ªû ph·∫ßn n√†y, m√¨nh show m·ªôt usecase nh·ªè v·ªÅ c√°ch s·ª≠ d·ª•ng Structured Prompt Outputs trong chatbot\nC·∫•u h√¨nh bot B∆∞·ªõc 1: ƒê·ªãnh nghƒ©a c·∫•u tr√∫c ƒë·∫ßu ra Tr∆∞·ªõc ti√™n, b·∫°n c·∫ßn x√°c ƒë·ªãnh c·∫•u tr√∫c ƒë·∫ßu ra m√† b·∫°n mong ƒë·ª£i t·ª´ LLM. V√≠ d·ª•, n·∫øu b·∫°n mu·ªën chatbot cung c·∫•p th√¥ng tin v·ªÅ s·∫£n ph·∫©m, b·∫°n c√≥ th·ªÉ ƒë·ªãnh nghƒ©a m·ªôt l∆∞·ª£c ƒë·ªì JSON nh∆∞ sau:\n1{ 2 \u0026#34;product_name\u0026#34;: \u0026#34;T√™n s·∫£n ph·∫©m\u0026#34;, 3 \u0026#34;price\u0026#34;: \u0026#34;Gi√° s·∫£n ph·∫©m\u0026#34;, 4 \u0026#34;availability\u0026#34;: \u0026#34;C√≥ s·∫µn hay kh√¥ng\u0026#34; 5} B∆∞·ªõc 2: T·∫°o prompt c√≥ c·∫•u tr√∫c S·ª≠ d·ª•ng prompt controls, m·ªôt th√†nh ph·∫ßn giao di·ªán ng∆∞·ªùi d√πng (UI) bao quanh tr∆∞·ªùng nh·∫≠p li·ªáu trong chatbot, ƒë·ªÉ h∆∞·ªõng d·∫´n ng∆∞·ªùi d√πng ho·∫∑c h·ªá th·ªëng cung c·∫•p ƒë·∫ßu v√†o ph√π h·ª£p . B·∫°n c√≥ th·ªÉ vi·∫øt m·ªôt prompt nh∆∞ sau:\n1H√£y cung c·∫•p th√¥ng tin v·ªÅ s·∫£n ph·∫©m d∆∞·ªõi d·∫°ng JSON v·ªõi c√°c tr∆∞·ªùng: product_name, price, v√† availability. B∆∞·ªõc 3: X·ª≠ l√Ω ƒë·∫ßu ra Khi LLM tr·∫£ v·ªÅ k·∫øt qu·∫£, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c c√¥ng c·ª• nh∆∞ Structured Outputs API c·ªßa OpenAI ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng ƒë·∫ßu ra lu√¥n tu√¢n th·ªß l∆∞·ª£c ƒë·ªì JSON m√† b·∫°n ƒë√£ ƒë·ªãnh nghƒ©a . V√≠ d·ª•:\n1{ 2 \u0026#34;product_name\u0026#34;: \u0026#34;Laptop Dell XPS 13\u0026#34;, 3 \u0026#34;price\u0026#34;: \u0026#34;$999\u0026#34;, 4 \u0026#34;availability\u0026#34;: \u0026#34;C√≥ s·∫µn\u0026#34; 5} B∆∞·ªõc 4: T√≠ch h·ª£p v√†o chatbot Sau khi nh·∫≠n ƒë∆∞·ª£c ƒë·∫ßu ra c√≥ c·∫•u tr√∫c, b·∫°n c√≥ th·ªÉ t√≠ch h·ª£p n√≥ v√†o ·ª©ng d·ª•ng chatbot b·∫±ng c√°ch:\nHi·ªÉn th·ªã th√¥ng tin tr·ª±c ti·∫øp cho ng∆∞·ªùi d√πng. L∆∞u tr·ªØ d·ªØ li·ªáu v√†o c∆° s·ªü d·ªØ li·ªáu. G·ªçi c√°c API kh√°c ƒë·ªÉ th·ª±c hi·ªán c√°c h√†nh ƒë·ªông ti·∫øp theo. 2. V√≠ d·ª• th·ª±c t·∫ø V√≠ d·ª• 1: Chatbot h·ªó tr·ª£ ƒë·∫∑t h√†ng Gi·∫£ s·ª≠ b·∫°n ƒëang x√¢y d·ª±ng m·ªôt chatbot h·ªó tr·ª£ kh√°ch h√†ng ƒë·∫∑t h√†ng s·∫£n ph·∫©m. B·∫°n c√≥ th·ªÉ y√™u c·∫ßu LLM t·∫°o ra m·ªôt ph·∫£n h·ªìi c√≥ c·∫•u tr√∫c nh∆∞ sau:\nPrompt:\n1Kh√°ch h√†ng mu·ªën ƒë·∫∑t mua m·ªôt chi·∫øc laptop Dell XPS 13. H√£y t·∫°o m·ªôt ph·∫£n h·ªìi c√≥ c·∫•u tr√∫c v·ªõi c√°c tr∆∞·ªùng: product_name, quantity, v√† total_price. Tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng JSON. K·∫øt qu·∫£ d·ª± ki·∫øn:\n1{ 2 \u0026#34;product_name\u0026#34;: \u0026#34;Laptop Dell XPS 13\u0026#34;, 3 \u0026#34;quantity\u0026#34;: 1, 4 \u0026#34;total_price\u0026#34;: \u0026#34;$999\u0026#34; 5} D·ªØ li·ªáu n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ hi·ªÉn th·ªã th√¥ng tin ƒë∆°n h√†ng cho kh√°ch h√†ng ho·∫∑c g·ª≠i y√™u c·∫ßu ƒë·∫øn h·ªá th·ªëng qu·∫£n l√Ω ƒë∆°n h√†ng .\nV√≠ d·ª• 2: Chatbot ph√¢n lo·∫°i √Ω ki·∫øn kh√°ch h√†ng N·∫øu b·∫°n ƒëang x√¢y d·ª±ng m·ªôt chatbot ƒë·ªÉ ph√¢n lo·∫°i √Ω ki·∫øn kh√°ch h√†ng, b·∫°n c√≥ th·ªÉ y√™u c·∫ßu LLM t·∫°o ra m·ªôt ph·∫£n h·ªìi c√≥ c·∫•u tr√∫c bao g·ªìm lo·∫°i √Ω ki·∫øn (positive, negative, neutral) v√† n·ªôi dung chi ti·∫øt.\nPrompt:\n1Ph√¢n lo·∫°i √Ω ki·∫øn sau: \u0026#34;T√¥i r·∫•t h√†i l√≤ng v·ªõi d·ªãch v·ª• c·ªßa c√¥ng ty.\u0026#34; Tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng JSON v·ªõi c√°c tr∆∞·ªùng: sentiment v√† content. K·∫øt qu·∫£ d·ª± ki·∫øn:\n1{ 2 \u0026#34;sentiment\u0026#34;: \u0026#34;positive\u0026#34;, 3 \u0026#34;content\u0026#34;: \u0026#34;T√¥i r·∫•t h√†i l√≤ng v·ªõi d·ªãch v·ª• c·ªßa c√¥ng ty.\u0026#34; 4} M·ªôt s·ªë kh√≥ khƒÉn khi tri·ªÉn khai chatbot v√† c√°ch gi·∫£i quy·∫øt 1. Thi·∫øu hi·ªÉu bi·∫øt v·ªÅ ng√¥n ng·ªØ t·ª± nhi√™n (NLP) M·ªôt trong nh·ªØng th√°ch th·ª©c l·ªõn nh·∫•t khi tri·ªÉn khai AI cho chatbot n√≥i chung v√† Structured Prompt Outputs n√≥i ri√™ng l√† kh·∫£ nƒÉng x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP). Chatbots c·∫ßn hi·ªÉu ƒë∆∞·ª£c √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng v√† t·∫°o ra ph·∫£n h·ªìi ph√π h·ª£p theo ƒë·ªãnh d·∫°ng ƒë√£ ch·ªâ ƒë·ªãnh. N·∫øu kh√¥ng c√≥ s·ª± hi·ªÉu bi·∫øt s√¢u s·∫Øc v·ªÅ NLP, vi·ªác y√™u c·∫ßu LLM t·∫°o ra ƒë·∫ßu ra c√≥ c·∫•u tr√∫c c√≥ th·ªÉ d·∫´n ƒë·∫øn k·∫øt qu·∫£ kh√¥ng mong mu·ªën ho·∫∑c thi·∫øu ch√≠nh x√°c .\nC√°ch gi·∫£i quy·∫øt:\nS·ª≠ d·ª•ng c√°c c√¥ng c·ª• nh∆∞ Prompt Engineering ƒë·ªÉ t·ªëi ∆∞u h√≥a c√¢u l·ªánh (prompt) sao cho r√µ r√†ng v√† c·ª• th·ªÉ. √Åp d·ª•ng c√°c k·ªπ thu·∫≠t nh∆∞ meta prompting ƒë·ªÉ tinh ch·ªânh y√™u c·∫ßu ban ƒë·∫ßu . 2. Kh√≥ khƒÉn trong vi·ªác thi·∫øt k·∫ø prompt ƒê·ªÉ nh·∫≠n ƒë∆∞·ª£c ƒë·∫ßu ra c√≥ c·∫•u tr√∫c, b·∫°n c·∫ßn thi·∫øt k·∫ø c√°c c√¢u l·ªánh (prompts) m·ªôt c√°ch c·∫©n th·∫≠n. N·∫øu c√¢u l·ªánh kh√¥ng ƒë·ªß r√µ r√†ng ho·∫∑c kh√¥ng bao g·ªìm v√≠ d·ª• minh h·ªça, LLM c√≥ th·ªÉ tr·∫£ v·ªÅ k·∫øt qu·∫£ kh√¥ng tu√¢n th·ªß ƒë·ªãnh d·∫°ng mong mu·ªën .\nV√≠ d·ª•:\nM·ªôt prompt kh√¥ng r√µ r√†ng: \u0026ldquo;H√£y li·ªát k√™ c√°c s·∫£n ph·∫©m.\u0026rdquo; M·ªôt prompt r√µ r√†ng: \u0026ldquo;H√£y li·ªát k√™ c√°c s·∫£n ph·∫©m d∆∞·ªõi d·∫°ng JSON v·ªõi c√°c tr∆∞·ªùng \u0026lsquo;product_name\u0026rsquo;, \u0026lsquo;price\u0026rsquo;, v√† \u0026lsquo;availability\u0026rsquo;.\u0026rdquo; C√°ch gi·∫£i quy·∫øt:\nCung c·∫•p v√≠ d·ª• c·ª• th·ªÉ v·ªÅ ƒë·ªãnh d·∫°ng ƒë·∫ßu ra mong ƒë·ª£i. S·ª≠ d·ª•ng XML tags ho·∫∑c Markdown ƒë·ªÉ ƒë·ªãnh d·∫°ng v√† c·∫•u tr√∫c prompt, tƒÉng t√≠nh r√µ r√†ng . 3. Chi ph√≠ ƒë·∫ßu t∆∞ ban ƒë·∫ßu cao Vi·ªác tri·ªÉn khai Structured Prompt Outputs ƒë√≤i h·ªèi ƒë·∫ßu t∆∞ v√†o c√°c c√¥ng c·ª• v√† n·ªÅn t·∫£ng AI, ch·∫≥ng h·∫°n nh∆∞ OpenAI Structured Outputs API ho·∫∑c Google AI Studio. ƒêi·ªÅu n√†y c√≥ th·ªÉ g√¢y kh√≥ khƒÉn cho c√°c doanh nghi·ªáp nh·ªè ho·∫∑c v·ª´a .\nC√°ch gi·∫£i quy·∫øt:\nB·∫Øt ƒë·∫ßu v·ªõi c√°c c√¥ng c·ª• mi·ªÖn ph√≠ ho·∫∑c th·ª≠ nghi·ªám tr∆∞·ªõc khi chuy·ªÉn sang c√°c gi·∫£i ph√°p th∆∞∆°ng m·∫°i. S·ª≠ d·ª•ng c√°c n·ªÅn t·∫£ng nh∆∞ Google AI Studio, n∆°i b·∫°n c√≥ th·ªÉ t·∫°o v√† th·ª≠ nghi·ªám c√°c c√¢u l·ªánh c√≥ c·∫•u tr√∫c m·ªôt c√°ch d·ªÖ d√†ng . 4. Thi·∫øu d·ªØ li·ªáu ch·∫•t l∆∞·ª£ng ƒê·ªÉ hu·∫•n luy·ªán chatbot t·∫°o ra ƒë·∫ßu ra c√≥ c·∫•u tr√∫c ch√≠nh x√°c, b·∫°n c·∫ßn c√≥ d·ªØ li·ªáu ƒë·∫ßu v√†o ch·∫•t l∆∞·ª£ng cao. N·∫øu d·ªØ li·ªáu kh√¥ng ƒë·∫ßy ƒë·ªß ho·∫∑c kh√¥ng ch√≠nh x√°c, chatbot c√≥ th·ªÉ g·∫∑p kh√≥ khƒÉn trong vi·ªác hi·ªÉu y√™u c·∫ßu v√† t·∫°o ra k·∫øt qu·∫£ ph√π h·ª£p .\nC√°ch gi·∫£i quy·∫øt:\nX√¢y d·ª±ng c∆° s·ªü d·ªØ li·ªáu ch·∫•t l∆∞·ª£ng cao t·ª´ c√°c t∆∞∆°ng t√°c th·ª±c t·∫ø v·ªõi kh√°ch h√†ng. S·ª≠ d·ª•ng c√°c c√¥ng c·ª• ph√¢n t√≠ch d·ªØ li·ªáu ƒë·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu ƒë·∫ßu v√†o. 5. Lo ng·∫°i v·ªÅ quy·ªÅn ri√™ng t∆∞ v√† b·∫£o m·∫≠t Khi tri·ªÉn khai chatbot s·ª≠ d·ª•ng Structured Prompt Outputs, ƒë·∫∑c bi·ªát l√† trong c√°c lƒ©nh v·ª±c nh·∫°y c·∫£m nh∆∞ chƒÉm s√≥c s·ª©c kh·ªèe ho·∫∑c t√†i ch√≠nh, v·∫•n ƒë·ªÅ quy·ªÅn ri√™ng t∆∞ v√† b·∫£o m·∫≠t lu√¥n l√† m·ªëi quan t√¢m l·ªõn . Ng∆∞·ªùi d√πng c√≥ th·ªÉ lo ng·∫°i r·∫±ng d·ªØ li·ªáu c·ªßa h·ªç s·∫Ω b·ªã l∆∞u tr·ªØ ho·∫∑c s·ª≠ d·ª•ng kh√¥ng ƒë√∫ng c√°ch.\nC√°ch gi·∫£i quy·∫øt:\nƒê·∫£m b·∫£o r·∫±ng d·ªØ li·ªáu ƒë∆∞·ª£c m√£ h√≥a v√† l∆∞u tr·ªØ an to√†n. Tu√¢n th·ªß c√°c quy ƒë·ªãnh v·ªÅ quy·ªÅn ri√™ng t∆∞, ch·∫≥ng h·∫°n nh∆∞ GDPR ho·∫∑c CCPA. 6. Kh√°ch h√†ng kh√¥ng c√≥ ni·ªÅm tin v√†o AI Kh√¥ng ph·∫£i kh√°ch h√†ng n√†o c≈©ng tho·∫£i m√°i v·ªõi vi·ªác t∆∞∆°ng t√°c c√πng chatbot thay v√¨ con ng∆∞·ªùi. S·ª± e d√® n√†y th∆∞·ªùng xu·∫•t ph√°t t·ª´ tr·∫£i nghi·ªám k√©m v·ªõi c√°c chatbot tr∆∞·ªõc ƒë√¢y ho·∫∑c lo ng·∫°i v·ªÅ kh·∫£ nƒÉng hi·ªÉu sai √Ω c·ªßa AI .\nC√°ch gi·∫£i quy·∫øt:\nThi·∫øt k·∫ø giao di·ªán th√¢n thi·ªán v√† cung c·∫•p t√πy ch·ªçn chuy·ªÉn sang h·ªó tr·ª£ con ng∆∞·ªùi n·∫øu c·∫ßn. T·∫°o ra c√°c t√¨nh hu·ªëng th·ª≠ nghi·ªám ƒë·ªÉ ch·ª©ng minh hi·ªáu qu·∫£ c·ªßa chatbot. 7. X√°c ƒë·ªãnh tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng ch∆∞a ph√π h·ª£p M·ªôt th√°ch th·ª©c kh√°c l√† vi·ªác x√°c ƒë·ªãnh tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng chatbot ch∆∞a ph√π h·ª£p. N·∫øu chatbot ƒë∆∞·ª£c tri·ªÉn khai trong c√°c t√¨nh hu·ªëng kh√¥ng c·∫ßn thi·∫øt ho·∫∑c kh√¥ng ph√π h·ª£p, n√≥ c√≥ th·ªÉ g√¢y ra s·ª± th·∫•t v·ªçng cho ng∆∞·ªùi d√πng .\nV√≠ d·ª•:\nS·ª≠ d·ª•ng chatbot ƒë·ªÉ x·ª≠ l√Ω c√°c v·∫•n ƒë·ªÅ ph·ª©c t·∫°p y√™u c·∫ßu t∆∞ duy s√°ng t·∫°o. S·ª≠ d·ª•ng chatbot ƒë·ªÉ thay th·∫ø ho√†n to√†n nh√¢n vi√™n h·ªó tr·ª£ kh√°ch h√†ng. C√°ch gi·∫£i quy·∫øt:\nPh√¢n t√≠ch k·ªπ l∆∞·ª°ng c√°c k·ªãch b·∫£n s·ª≠ d·ª•ng tr∆∞·ªõc khi tri·ªÉn khai chatbot. K·∫øt h·ª£p chatbot v·ªõi s·ª± h·ªó tr·ª£ c·ªßa con ng∆∞·ªùi trong c√°c t√¨nh hu·ªëng ph·ª©c t·∫°p. 8. Kh√¥ng x√¢y d·ª±ng k·ªãch b·∫£n ri√™ng cho doanh nghi·ªáp M·ªói doanh nghi·ªáp c√≥ nhu c·∫ßu v√† quy tr√¨nh ri√™ng. N·∫øu chatbot kh√¥ng ƒë∆∞·ª£c thi·∫øt k·∫ø v√† hu·∫•n luy·ªán theo k·ªãch b·∫£n ri√™ng c·ªßa doanh nghi·ªáp, n√≥ c√≥ th·ªÉ kh√¥ng ƒë√°p ·ª©ng ƒë∆∞·ª£c k·ª≥ v·ªçng c·ªßa ng∆∞·ªùi d√πng .\nC√°ch gi·∫£i quy·∫øt:\nX√¢y d·ª±ng k·ªãch b·∫£n s·ª≠ d·ª•ng d·ª±a tr√™n nhu c·∫ßu c·ª• th·ªÉ c·ªßa doanh nghi·ªáp. Hu·∫•n luy·ªán chatbot b·∫±ng d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ ho·∫°t ƒë·ªông kinh doanh. IV. ƒêo l∆∞·ªùng hi·ªáu su·∫•t c·ªßa Structured Prompt Outputs 1. X√°c ƒë·ªãnh c√°c ch·ªâ s·ªë ƒëo l∆∞·ªùng hi·ªáu su·∫•t (KPI) C√°c ch·ªâ s·ªë ƒëo l∆∞·ªùng hi·ªáu su·∫•t (KPI) l√† c√¥ng c·ª• quan tr·ªçng ƒë·ªÉ ƒë√°nh gi√° m·ª©c ƒë·ªô th√†nh c√¥ng c·ªßa chatbot khi s·ª≠ d·ª•ng Structured Prompt Outputs. M·ªôt s·ªë KPI ph·ªï bi·∫øn bao g·ªìm:\nT·ª∑ l·ªá ph·∫£n h·ªìi ch√≠nh x√°c: ƒê√¢y l√† t·ª∑ l·ªá m√† chatbot cung c·∫•p ƒë·∫ßu ra c√≥ c·∫•u tr√∫c ch√≠nh x√°c theo y√™u c·∫ßu . V√≠ d·ª•, n·∫øu b·∫°n y√™u c·∫ßu JSON nh∆∞ng chatbot tr·∫£ v·ªÅ vƒÉn b·∫£n thu·∫ßn t√∫y, ƒë√≥ ƒë∆∞·ª£c coi l√† l·ªói.\nT·ªëc ƒë·ªô x·ª≠ l√Ω y√™u c·∫ßu: ƒêo l∆∞·ªùng th·ªùi gian m√† chatbot m·∫•t ƒë·ªÉ t·∫°o ra ƒë·∫ßu ra c√≥ c·∫•u tr√∫c t·ª´ khi nh·∫≠n ƒë∆∞·ª£c c√¢u l·ªánh . T·ªëc ƒë·ªô nhanh gi√∫p c·∫£i thi·ªán tr·∫£i nghi·ªám ng∆∞·ªùi d√πng.\nT·ª∑ l·ªá t·ª± ph·ª•c v·ª• (Self-service Rate): ƒê√¢y l√† t·ª∑ l·ªá t∆∞∆°ng t√°c m√† chatbot x·ª≠ l√Ω th√†nh c√¥ng m√† kh√¥ng c·∫ßn s·ª± can thi·ªáp c·ªßa con ng∆∞·ªùi . ƒê·ªëi v·ªõi Structured Prompt Outputs, t·ª∑ l·ªá n√†y c√†ng cao th√¨ hi·ªáu qu·∫£ c√†ng l·ªõn.\nT·ª∑ l·ªá ngƒÉn ch·∫∑n chatbot (Deflection Rate): Ch·ªâ s·ªë n√†y ƒëo l∆∞·ªùng kh·∫£ nƒÉng chatbot gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ m√† kh√¥ng c·∫ßn chuy·ªÉn ti·∫øp ƒë·∫øn nh√¢n vi√™n h·ªó tr·ª£ . M·ªôt chatbot hi·ªáu qu·∫£ s·∫Ω gi·∫£m thi·ªÉu nhu c·∫ßu chuy·ªÉn ti·∫øp.\n2. Ph√¢n t√≠ch ngu·ªìn t∆∞∆°ng t√°c Hi·ªÉu r√µ ngu·ªìn t∆∞∆°ng t√°c c·ªßa ng∆∞·ªùi d√πng l√† b∆∞·ªõc quan tr·ªçng ƒë·ªÉ t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t chatbot. B·∫°n c·∫ßn x√°c ƒë·ªãnh ng∆∞·ªùi d√πng ƒë·∫øn t·ª´ ƒë√¢u‚Äîv√≠ d·ª•, t·ª´ website, ·ª©ng d·ª•ng di ƒë·ªông, hay n·ªÅn t·∫£ng m·∫°ng x√£ h·ªôi nh∆∞ YouTube . ƒêi·ªÅu n√†y gi√∫p b·∫°n ƒëi·ªÅu ch·ªânh prompt v√† c·∫•u tr√∫c ƒë·∫ßu ra ph√π h·ª£p v·ªõi t·ª´ng k√™nh.\n3. S·ª≠ d·ª•ng ph√¢n t√≠ch n√¢ng cao (Advanced Analytics) C√¥ng c·ª• ph√¢n t√≠ch n√¢ng cao c√≥ th·ªÉ gi√∫p b·∫°n ƒëo l∆∞·ªùng hi·ªáu su·∫•t c·ªßa chatbot m·ªôt c√°ch chi ti·∫øt h∆°n. V√≠ d·ª•, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng Chatbot Analytics ƒë·ªÉ ph√¢n t√≠ch:\nKh·ªëi l∆∞·ª£ng c√¥ng vi·ªác c·ªßa chatbot: S·ªë l∆∞·ª£ng y√™u c·∫ßu m√† chatbot x·ª≠ l√Ω m·ªói ng√†y . Ch·∫•t l∆∞·ª£ng ƒë·∫ßu ra: ƒê√°nh gi√° xem d·ªØ li·ªáu ƒë·∫ßu ra c√≥ tu√¢n th·ªß ƒë√∫ng ƒë·ªãnh d·∫°ng JSON ho·∫∑c XML hay kh√¥ng . T·ª∑ l·ªá l·ªói: X√°c ƒë·ªãnh t·ª∑ l·ªá m√† chatbot kh√¥ng th·ªÉ t·∫°o ra ƒë·∫ßu ra c√≥ c·∫•u tr√∫c ch√≠nh x√°c. Ngo√†i ra, c√°c c√¥ng c·ª• nh∆∞ Botpress cung c·∫•p h∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc ƒë·ªÉ tri·ªÉn khai ph√¢n t√≠ch n√¢ng cao cho chatbot .\n4. Ki·ªÉm tra t√≠nh nh·∫•t qu√°n c·ªßa ƒë·∫ßu ra M·ªôt trong nh·ªØng th√°ch th·ª©c l·ªõn nh·∫•t c·ªßa Structured Prompt Outputs l√† ƒë·∫£m b·∫£o r·∫±ng ƒë·∫ßu ra lu√¥n nh·∫•t qu√°n. ƒê·ªÉ ki·ªÉm tra ƒëi·ªÅu n√†y, b·∫°n c√≥ th·ªÉ:\nSo s√°nh ƒë·∫ßu ra c·ªßa chatbot v·ªõi l∆∞·ª£c ƒë·ªì JSON ho·∫∑c XML ƒë√£ ƒë·ªãnh nghƒ©a tr∆∞·ªõc. S·ª≠ d·ª•ng c√°c c√¥ng c·ª• ki·ªÉm tra c√∫ ph√°p ƒë·ªÉ ph√°t hi·ªán l·ªói trong ƒë·∫ßu ra. V√≠ d·ª•, n·∫øu b·∫°n y√™u c·∫ßu chatbot t·∫°o ra m·ªôt danh s√°ch s·∫£n ph·∫©m d∆∞·ªõi d·∫°ng JSON, h√£y ƒë·∫£m b·∫£o r·∫±ng t·∫•t c·∫£ c√°c tr∆∞·ªùng nh∆∞ \u0026ldquo;product_name\u0026rdquo;, \u0026ldquo;price\u0026rdquo;, v√† \u0026ldquo;availability\u0026rdquo; ƒë·ªÅu ƒë∆∞·ª£c ƒëi·ªÅn ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c.\n5. Thu th·∫≠p ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng Ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng l√† ngu·ªìn th√¥ng tin qu√Ω gi√° ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t c·ªßa chatbot. B·∫°n c√≥ th·ªÉ thu th·∫≠p ph·∫£n h·ªìi th√¥ng qua:\nB·∫£ng kh·∫£o s√°t ng·∫Øn g·ªçn: Sau m·ªói t∆∞∆°ng t√°c, h·ªèi ng∆∞·ªùi d√πng v·ªÅ m·ª©c ƒë·ªô h√†i l√≤ng v·ªõi c√¢u tr·∫£ l·ªùi c·ªßa chatbot. Ph√¢n t√≠ch c·∫£m x√∫c (Sentiment Analysis): S·ª≠ d·ª•ng AI ƒë·ªÉ ph√¢n t√≠ch c·∫£m x√∫c trong ph·∫£n h·ªìi c·ªßa ng∆∞·ªùi d√πng, gi√∫p x√°c ƒë·ªãnh xem h·ªç c√≥ h√†i l√≤ng v·ªõi ƒë·∫ßu ra c√≥ c·∫•u tr√∫c hay kh√¥ng . 6. Th·ª±c hi·ªán A/B Testing A/B Testing l√† ph∆∞∆°ng ph√°p th·ª≠ nghi·ªám hai phi√™n b·∫£n kh√°c nhau c·ªßa c√πng m·ªôt prompt ƒë·ªÉ x√°c ƒë·ªãnh phi√™n b·∫£n n√†o hi·ªáu qu·∫£ h∆°n. V√≠ d·ª•:\nPhi√™n b·∫£n A: Y√™u c·∫ßu chatbot t·∫°o ra ƒë·∫ßu ra JSON v·ªõi √≠t v√≠ d·ª• minh h·ªça. Phi√™n b·∫£n B: Y√™u c·∫ßu chatbot t·∫°o ra ƒë·∫ßu ra JSON v·ªõi nhi·ªÅu v√≠ d·ª• minh h·ªça. So s√°nh k·∫øt qu·∫£ t·ª´ hai phi√™n b·∫£n ƒë·ªÉ t√¨m ra c√°ch t·ªëi ∆∞u h√≥a prompt.\n7. Theo d√µi v√† c·∫£i ti·∫øn li√™n t·ª•c Hi·ªáu su·∫•t c·ªßa chatbot kh√¥ng ph·∫£i l√† m·ªôt y·∫øu t·ªë c·ªë ƒë·ªãnh m√† c·∫ßn ƒë∆∞·ª£c theo d√µi v√† c·∫£i ti·∫øn li√™n t·ª•c. H√£y th·ª±c hi·ªán c√°c b∆∞·ªõc sau:\nL∆∞u tr·ªØ d·ªØ li·ªáu t∆∞∆°ng t√°c: L∆∞u l·∫°i t·∫•t c·∫£ c√°c t∆∞∆°ng t√°c gi·ªØa chatbot v√† ng∆∞·ªùi d√πng ƒë·ªÉ ph√¢n t√≠ch sau n√†y . C·∫≠p nh·∫≠t prompt: D·ª±a tr√™n d·ªØ li·ªáu thu th·∫≠p ƒë∆∞·ª£c, ƒëi·ªÅu ch·ªânh v√† c·∫£i ti·∫øn prompt ƒë·ªÉ tƒÉng hi·ªáu su·∫•t. Hu·∫•n luy·ªán m√¥ h√¨nh: N·∫øu c√≥ th·ªÉ, hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLM) b·∫±ng c√°ch s·ª≠ d·ª•ng d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ c√°c t∆∞∆°ng t√°c. √ü√ü C·∫£m ∆°n b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\n","date":"Apr 28, 2025","img":"https://unsplash.it/1920/1080?image=232","permalink":"/blog/2025-04-28-structured-prompt-outputs/","series":null,"tags":["llm"],"title":"Machine Learning - S·ª≠ D·ª•ng Structured Prompt Outputs ƒê·ªÉ T·ªëi ∆Øu H√≥a K·∫øt Qu·∫£ T·ª´ LLMs"},{"categories":null,"content":" Phi√™n b·∫£n basic Train v·ªõi ultimate pro B√†i t·∫≠p h√¥m nay l√† train m√¥ h√¨nh ƒë·ªÉ nh·∫≠n d·∫°ng email l·ª´a ƒë·∫£o Phishing Email. ƒê√¢y ƒë∆∞·ª£c xem nh∆∞ l√† b√†i t·∫≠p nh·∫≠p m√¥n machine learning.\nTrong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω train m√¥ h√¨nh v√† vi·∫øt m·ªôt web api nho nh·ªè b·∫±ng fastapi ƒë·ªÉ hosting model l√™n. C√°c b∆∞·ªõc th·ª±c hi·ªán nh∆∞ sau:\nNguy√™n li·ªáu ch√≠nh: data phishing email ƒë∆∞·ª£c download ·ªü https://www.kaggle.com/datasets/subhajournal/phishingemails/data\nC√†i c√°c th∆∞ vi·ªán c∆° b·∫£n\n1python3 -m venv venv 2 3source venv/bin/activate 4pip install fastapi uvicorn redis joblib scikit-learn fastapi: Framework ƒë·ªÉ x√¢y d·ª±ng API. uvicorn: Server ASGI ƒë·ªÉ ch·∫°y ·ª©ng d·ª•ng FastAPI. redis: Th∆∞ vi·ªán ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi Redis. joblib: Th∆∞ vi·ªán ƒë·ªÉ l∆∞u v√† t·∫£i m√¥ h√¨nh h·ªçc m√°y. scikit-learn: Th∆∞ vi·ªán ƒë·ªÉ hu·∫•n luy·ªán v√† tri·ªÉn khai m√¥ h√¨nh. Phi√™n b·∫£n basic Train m√¥ h√¨nh\n1# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt 2import os 3import joblib 4import pandas as pd 5from sklearn.feature_extraction.text import TfidfVectorizer 6from sklearn.linear_model import LogisticRegression 7from sklearn.model_selection import train_test_split 8from sklearn.pipeline import Pipeline 9from sklearn.metrics import accuracy_score 10 11def trainPhishingEmailModel(): 12 \u0026#34;\u0026#34;\u0026#34; 13 H√†m th·ª±c hi·ªán: 14 - ƒê·ªçc d·ªØ li·ªáu email t·ª´ file CSV 15 - Ti·ªÅn x·ª≠ l√Ω, chia d·ªØ li·ªáu train/test 16 - X√¢y d·ª±ng pipeline (TF-IDF + Logistic Regression) 17 - Hu·∫•n luy·ªán m√¥ h√¨nh 18 - ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p test 19 - L∆∞u m√¥ h√¨nh ƒë√£ train v√†o th∆∞ m·ª•c model/ 20 \u0026#34;\u0026#34;\u0026#34; 21 22 # B∆∞·ªõc 1: ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV 23 dataFrame = pd.read_csv(\u0026#34;data/Phishing_Email.csv\u0026#34;) # C·∫ßn ƒë·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n file ch√≠nh x√°c 24 25 # B∆∞·ªõc 2: Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o (features) v√† nh√£n (labels) 26 emailTexts = dataFrame[\u0026#34;Email Text\u0026#34;].fillna(\u0026#34;\u0026#34;) # Thay th·∫ø gi√° tr·ªã null b·∫±ng chu·ªói r·ªóng 27 emailLabels = dataFrame[\u0026#34;Email Type\u0026#34;] # Label: lo·∫°i email (v√≠ d·ª•: phishing ho·∫∑c legit) 28 29 # B∆∞·ªõc 3: Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra 30 emailTextsTrain, emailTextsTest, emailLabelsTrain, emailLabelsTest = train_test_split( 31 emailTexts, 32 emailLabels, 33 test_size=0.2, # 20% d·ªØ li·ªáu d√πng ƒë·ªÉ ki·ªÉm tra 34 random_state=42 # ƒê·∫£m b·∫£o chia d·ªØ li·ªáu ng·∫´u nhi√™n nh∆∞ng c√≥ th·ªÉ t√°i l·∫≠p 35 ) 36 37 # B∆∞·ªõc 4: X√¢y d·ª±ng pipeline: 38 # - TfidfVectorizer: chuy·ªÉn vƒÉn b·∫£n th√†nh vector ƒë·∫∑c tr∆∞ng 39 # - LogisticRegression: m√¥ h√¨nh ph√¢n lo·∫°i tuy·∫øn t√≠nh 40 phishingDetectionPipeline = Pipeline([ 41 (\u0026#34;tfidfVectorizer\u0026#34;, TfidfVectorizer(stop_words=\u0026#34;english\u0026#34;)), # Lo·∫°i b·ªè t·ª´ d·ª´ng ti·∫øng Anh 42 (\u0026#34;logisticClassifier\u0026#34;, LogisticRegression(solver=\u0026#34;liblinear\u0026#34;)) # S·ª≠ d·ª•ng solver ph√π h·ª£p v·ªõi t·∫≠p nh·ªè 43 ]) 44 45 # B∆∞·ªõc 5: Hu·∫•n luy·ªán pipeline tr√™n t·∫≠p hu·∫•n luy·ªán 46 phishingDetectionPipeline.fit(emailTextsTrain, emailLabelsTrain) 47 48 # B∆∞·ªõc 6: ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra 49 emailLabelsPredicted = phishingDetectionPipeline.predict(emailTextsTest) 50 accuracy = accuracy_score(emailLabelsTest, emailLabelsPredicted) 51 print(f\u0026#34;üéØ ƒê·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra: {accuracy * 100:.2f}%\u0026#34;) 52 53 # B∆∞·ªõc 7: T·∫°o th∆∞ m·ª•c l∆∞u m√¥ h√¨nh n·∫øu ch∆∞a t·ªìn t·∫°i 54 modelDirectory = \u0026#34;model\u0026#34; 55 if not os.path.exists(modelDirectory): 56 os.makedirs(modelDirectory) 57 58 # B∆∞·ªõc 8: L∆∞u m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán v√†o th∆∞ m·ª•c model/ 59 modelPath = os.path.join(modelDirectory, \u0026#34;phishingModel.pkl\u0026#34;) 60 joblib.dump(phishingDetectionPipeline, modelPath) 61 print(f\u0026#34;‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v√† l∆∞u th√†nh c√¥ng t·∫°i \u0026#39;{modelPath}\u0026#39;.\u0026#34;) 62 63# ƒêi·ªÉm b·∫Øt ƒë·∫ßu ch∆∞∆°ng tr√¨nh 64if __name__ == \u0026#34;__main__\u0026#34;: 65 trainPhishingEmailModel() K·∫øt qu·∫£\n1 2üéØ ƒê·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra: 97.24% 3‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v√† l∆∞u th√†nh c√¥ng t·∫°i \u0026#39;model/phishingModel.pkl\u0026#39;. Ph·∫ßn code tri·ªÉn khai fast api kh√° ƒë∆°n gi·∫£n\n1# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt 2import asyncio 3import json 4import joblib 5from fastapi import FastAPI 6from pydantic import BaseModel 7 8# B∆∞·ªõc 1: Load m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán (ƒë·ªìng b·ªô) 9model = joblib.load(\u0026#34;model/phishingModel.pkl\u0026#34;) # ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n ƒë√∫ng 10 11# B∆∞·ªõc 2: Kh·ªüi t·∫°o FastAPI app 12app = FastAPI() 13 14# B∆∞·ªõc 3: ƒê·ªãnh nghƒ©a l·ªõp d·ªØ li·ªáu v√†o (request) v√† d·ªØ li·ªáu ra (response) 15class PredictionRequest(BaseModel): 16 text: str # VƒÉn b·∫£n email c·∫ßn ph√¢n lo·∫°i 17 18class PredictionResponse(BaseModel): 19 prediction: str # K·∫øt qu·∫£ ph√¢n lo·∫°i (v√≠ d·ª•: \u0026#34;Phishing\u0026#34; ho·∫∑c \u0026#34;Legit\u0026#34;) 20 probability: float # X√°c su·∫•t d·ª± ƒëo√°n cao nh·∫•t 21 22# B∆∞·ªõc 4: ƒê·ªãnh nghƒ©a API endpoint cho vi·ªác d·ª± ƒëo√°n 23@app.post(\u0026#34;/predict\u0026#34;, response_model=PredictionResponse) 24async def predictEmail(data: PredictionRequest): 25 \u0026#34;\u0026#34;\u0026#34; 26 Nh·∫≠n vƒÉn b·∫£n email t·ª´ client, ch·∫°y m√¥ h√¨nh d·ª± ƒëo√°n, 27 v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ c√πng x√°c su·∫•t d·ª± ƒëo√°n. 28 \u0026#34;\u0026#34;\u0026#34; 29 30 # Ch·∫°y d·ª± ƒëo√°n m√¥ h√¨nh trong thread ri√™ng ƒë·ªÉ kh√¥ng block event loop 31 prediction = await asyncio.to_thread(model.predict, [data.text]) 32 probability = await asyncio.to_thread(lambda: model.predict_proba([data.text])[0].max()) 33 34 # ƒê√≥ng g√≥i k·∫øt qu·∫£ tr·∫£ v·ªÅ 35 result = { 36 \u0026#34;prediction\u0026#34;: str(prediction[0]), 37 \u0026#34;probability\u0026#34;: float(probability) 38 } 39 40 return result 41 42# B∆∞·ªõc 5: Ch·∫°y server FastAPI v·ªõi uvicorn khi file ƒë∆∞·ª£c th·ª±c thi tr·ª±c ti·∫øp 43if __name__ == \u0026#34;__main__\u0026#34;: 44 import uvicorn 45 uvicorn.run(app, host=\u0026#34;0.0.0.0\u0026#34;, port=8000) M√¨nh th·ª≠ l·∫°i v·ªõi c√°c test case sau nha\n1 2curl \u0026#39;http://localhost:8000/predict\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;text\u0026#34;:\u0026#34;Hi There, Watch your customer engagement soar with custom, branded messaging experience powered by artificial intelligence. Improve customer retention, conversion and satisfaction with Sendbird‚Äôs award winning communications platform. Schedule a Custom Demo at your convenience. Cheers, Natalie\u0026#34;}\u0026#39; 3 4curl \u0026#39;http://localhost:8000/predict\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{ 5 \u0026#34;text\u0026#34;: \u0026#34;Hi, We noticed a login from a device you don\u0026#39;\\\u0026#39;\u0026#39;t usually use: android device Lagos, Nigeria If this was you, you can safely disregard this email.\u0026#34; 6}\u0026#39; 7 8curl \u0026#39;http://localhost:8000/predict\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;text\u0026#34;:\u0026#34;STARTING AT $40 ($80) (50% OFF APPLIED FOR LIMITED TIME) If you are looking to learn in-demand skills and apply them directly at your workplace then Premium Courses by Great Learning Academy are a great way to get started! Learn industry-relevant skills in Data Science and AI through a combination of expert-led hands-on projects, interactive exercises, and advanced AI support tools. These courses empower you to apply your skills effectively at work and grow in your current role or take on new projects with confidence.\u0026#34;}\u0026#39; 9 10 11curl \u0026#39;http://localhost:8000/predict\u0026#39; -H \u0026#39;accept: application/json\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;text\u0026#34;:\u0026#34;I spend most of my time building and improving Retrieval Augmented Generation (RAG) apps. I trust RAGs are perhaps the most popular application of AI. It‚Äôs everywhere, from chatbots to document summaries. I also believe that most of these apps ultimately go undeployed for various reasons, many of which are not technical. However, I wish I had known a few technical aspects to create more effective RAGs.\u0026#34;}\u0026#39; K·∫øt qu·∫£ nh∆∞ sau\n1{\u0026#34;prediction\u0026#34;:\u0026#34;Phishing Email\u0026#34;,\u0026#34;probability\u0026#34;:0.6649311587527311} 2{\u0026#34;prediction\u0026#34;:\u0026#34;Phishing Email\u0026#34;,\u0026#34;probability\u0026#34;:0.5568319143944104} 3{\u0026#34;prediction\u0026#34;:\u0026#34;Phishing Email\u0026#34;,\u0026#34;probability\u0026#34;:0.5126072633692877} 4{\u0026#34;prediction\u0026#34;:\u0026#34;Safe Email\u0026#34;,\u0026#34;probability\u0026#34;:0.5550190678745507} ƒê√¢y l√† c√°c email th·∫≠t m√¨nh l·∫•y ra t·ª´ gmail c√° nh√¢n c·ªßa m√¨nh, ƒë√£ ƒë∆∞·ª£c google ph√¢n lo·∫°i. K·∫øt qu·∫£ c·ªßa m√¨nh ra kh·ªõp 100% v·ªõi google nh·ªâ. hi hi.\nTrain v·ªõi ultimate pro Model ch·ªâ ƒë√∫ng v·ªõi 97% ·ªü t·∫≠p train, kh√° c√πi nh·ªâ. Ch√∫ng ta s·∫Ω b·ªï sung auto grid search ƒë·ªÉ turning tham s·ªë, ch·ªçn ra best_params, th√™m EarlyStopping, th√™m Auto Save Checkpoint, ƒë·ªïi m√¥ h√¨nh sang random forest \u0026hellip; C√°c ch·ª©c nƒÉng x·ªãn s√≤ h∆°n nh·ªâ\nC√°c b·∫°n th·ª≠ coding th·ª≠, xem nh∆∞ l√† b√†i t·∫≠p.\nC·∫£m ∆°n b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\n","date":"Apr 26, 2025","img":"https://unsplash.it/1920/1080?image=232","permalink":"/blog/2025-04-26-phishing-email/","series":null,"tags":["email_phishing"],"title":"Machine Learning - Train M√¥ H√¨nh Nh·∫≠n D·∫°ng Email L·ª´a ƒê·∫£o"},{"categories":null,"content":" I. Kh√°i ni·ªám Heavy Buyer v√† Light Buyer 1. Heavy Buyer l√† g√¨? 2. Light Buyer l√† g√¨? II. C√°c ƒëi·ªÉm ch√≠nh c·ªët l√µi khi ph√°t tri·ªÉn m√¥ h√¨nh marketing, ph√¢n t√≠ch h√†ng vi mua s·∫Øm c·ªßa ng∆∞·ªùi d√πng 1. S·ª± TƒÉng Tr∆∞·ªüng ƒê·∫øn T·ª´ Kh√°ch H√†ng M·ªõi 2. Nh·ªØng Ni·ªÅm Tin Sai L·∫ßm V·ªÅ S·ª± Trung Th√†nh C·ªßa Kh√°ch H√†ng 3. Nh√≥m Light Buyers R·∫•t, R·∫•t Quan Tr·ªçng 4. Thay ƒê·ªïi C√°c Quan ƒêi·ªÉm Marketing Truy·ªÅn Th·ªëng 5. Nh·ªØng B√†i H·ªçc Th·ª±c Ti·ªÖn: L√†m Th·∫ø N√†o ƒê·ªÉ √Åp D·ª•ng Nh·ªØng Ph√°t Hi·ªán T·ª´ Cu·ªën S√°ch? III. Chi·∫øn l·ª±c t·∫≠n d·ª•ng Light Buyers cho nh√≥m doanh nghi·ªáp Chi·∫øn l∆∞·ª£c cho doanh nghi·ªáp nh·ªè Chi·∫øn l∆∞·ª£c cho doanh nghi·ªáp l·ªõn L·ªùi ng∆∞·ªùi vi·∫øt: trong qu√° tr√¨nh l∆∞·ªõt l∆∞·ªõt web, t√¥i v√¥ t√¨nh b·∫Øt g·∫∑p 2 t·ª´ kho√° Heavy Buyer v√† Light Buyer. C√°ch ph√¢n nh√≥m kh√°ch h√†ng d·ª±a v√†o h√†nh vi mua s·∫Øm, ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i ƒë·ªÉ x√¢y d·ª±ng chi·∫øn l∆∞·ª£c marketing v√† tƒÉng tr∆∞·ªüng doanh thu. T√¨m hi·ªÉu s√¢u h∆°n, t·ª± nhi√™n l·∫°i l√≤i ra quy·ªÉn s√°ch How Brands Grow v·ªõi nhi·ªÅu th·ªëng k√™ nghi√™n c·ª©u , ƒë·ªÅ c·∫≠p tr√™n d·ªØ li·ªáu FMCG ( nh√≥m h√†ng m√† t√¥i ƒë√£ ph√¢n t√≠ch , v√† hi·ªán t·∫°i v·∫´n ƒëang ph√¢n t√≠ch). T·ª´ ƒë√≥, c√≥ b√†i vi·∫øt n√†y.\nI. Kh√°i ni·ªám Heavy Buyer v√† Light Buyer 1. Heavy Buyer l√† g√¨? Heavy Buyers l√† nh·ªØng ng∆∞·ªùi mua h√†ng th∆∞·ªùng xuy√™n, chi·∫øm m·ªôt t·ª∑ l·ªá nh·ªè (kho·∫£ng 20%) nh∆∞ng l·∫°i ƒë√≥ng g√≥p ph·∫ßn l·ªõn v√†o doanh thu c·ªßa doanh nghi·ªáp (l√™n t·ªõi 80% doanh thu) . H·ªç c√≥ xu h∆∞·ªõng trung th√†nh v·ªõi m·ªôt th∆∞∆°ng hi·ªáu ho·∫∑c s·∫£n ph·∫©m c·ª• th·ªÉ v√† c√≥ gu ti√™u d√πng ri√™ng. V√≠ d·ª•, nh·ªØng ng∆∞·ªùi ƒëi cafe 2-3 l·∫ßn/tu·∫ßn ƒë∆∞·ª£c coi l√† Heavy Buyers .\n2. Light Buyer l√† g√¨? Light Buyers l√† nh·ªØng ng∆∞·ªùi mua h√†ng √≠t th∆∞·ªùng xuy√™n h∆°n, chi·∫øm ƒëa s·ªë trong t·ªïng s·ªë kh√°ch h√†ng (kho·∫£ng 80%), nh∆∞ng ch·ªâ ƒë√≥ng g√≥p m·ªôt ph·∫ßn nh·ªè v√†o doanh thu (v√≠ d·ª•: 20%). H·ªç th∆∞·ªùng mua khi c√≥ nhu c·∫ßu ƒë·∫∑c bi·ªát ho·∫∑c d·ªãp ƒë·∫∑c bi·ªát nh∆∞ g·∫∑p b·∫°n b√® hay ƒë·ªëi t√°c . Nh√≥m n√†y kh√¥ng trung th√†nh v·ªõi m·ªôt th∆∞∆°ng hi·ªáu c·ª• th·ªÉ v√† d·ªÖ b·ªã ·∫£nh h∆∞·ªüng b·ªüi c√°c y·∫øu t·ªë b√™n ngo√†i nh∆∞ khuy·∫øn m√£i ho·∫∑c qu·∫£ng c√°o .\nII. C√°c ƒëi·ªÉm ch√≠nh c·ªët l√µi khi ph√°t tri·ªÉn m√¥ h√¨nh marketing, ph√¢n t√≠ch h√†ng vi mua s·∫Øm c·ªßa ng∆∞·ªùi d√πng 1. S·ª± TƒÉng Tr∆∞·ªüng ƒê·∫øn T·ª´ Kh√°ch H√†ng M·ªõi M·ªôt trong nh·ªØng ph√°t hi·ªán g√¢y tranh c√£i nh∆∞ng c≈©ng ƒë·∫ßy thuy·∫øt ph·ª•c, ƒë√≥ l√†: th∆∞∆°ng hi·ªáu tƒÉng tr∆∞·ªüng ch·ªß y·∫øu b·∫±ng c√°ch thu h√∫t kh√°ch h√†ng m·ªõi, thay v√¨ ch·ªâ t·∫≠p trung v√†o vi·ªác gi·ªØ ch√¢n kh√°ch h√†ng hi·ªán t·∫°i . ƒêi·ªÅu n√†y c√≥ th·ªÉ tr√°i ng∆∞·ª£c v·ªõi suy nghƒ© c·ªßa nhi·ªÅu ng∆∞·ªùi l√†m marketing, khi h·ªç th∆∞·ªùng cho r·∫±ng vi·ªác duy tr√¨ l√≤ng trung th√†nh c·ªßa kh√°ch h√†ng hi·ªán t·∫°i l√† ch√¨a kh√≥a cho s·ª± th√†nh c√¥ng. Tuy nhi√™n, nghi√™n c·ª©u c·ªßa Byron Sharp ƒë√£ ch·ª©ng minh r·∫±ng h·∫ßu h·∫øt s·ª± tƒÉng tr∆∞·ªüng c·ªßa th∆∞∆°ng hi·ªáu ƒë·∫øn t·ª´ vi·ªác m·ªü r·ªông t·ªáp kh√°ch h√†ng, ƒë·∫∑c bi·ªát l√† nh√≥m kh√°ch h√†ng mua s·∫Øm kh√¥ng th∆∞·ªùng xuy√™n (light buyers).\nƒê·ªÉ hi·ªÉu r√µ h∆°n, h√£y l·∫•y v√≠ d·ª• v·ªÅ Coca-Cola. H·ªç kh√¥ng ch·ªâ h∆∞·ªõng ƒë·∫øn nh·ªØng ng∆∞·ªùi u·ªëng Coca-Cola m·ªói ng√†y m√† c√≤n t√¨m c√°ch thu h√∫t c·∫£ nh·ªØng ng∆∞·ªùi ch·ªâ th·ªânh tho·∫£ng u·ªëng n∆∞·ªõc ng·ªçt. Theo nghi√™n c·ª©u trong s√°ch, nh√≥m kh√°ch h√†ng kh√¥ng mua th∆∞·ªùng xuy√™n (light buyers) chi·∫øm ph·∫ßn l·ªõn doanh s·ªë b√°n h√†ng c·ªßa b·∫•t k·ª≥ th∆∞∆°ng hi·ªáu n√†o. ƒê√¢y m·ªõi th·ª±c s·ª± l√† ƒë·ªông l·ª±c ch√≠nh th√∫c ƒë·∫©y s·ª± ph√°t tri·ªÉn c·ªßa th∆∞∆°ng hi·ªáu .\nTuy nhi√™n, ƒëi·ªÅu ƒë√°ng ch√∫ √Ω ·ªü ƒë√¢y l√† vi·ªác thu h√∫t kh√°ch h√†ng m·ªõi kh√¥ng ƒë·ªìng nghƒ©a v·ªõi vi·ªác b·ªè qua kh√°ch h√†ng hi·ªán t·∫°i. Thay v√†o ƒë√≥, n√≥ nh·∫•n m·∫°nh t·∫ßm quan tr·ªçng c·ªßa vi·ªác c√¢n b·∫±ng gi·ªØa hai m·ª•c ti√™u: v·ª´a duy tr√¨ m·ªëi quan h·ªá v·ªõi kh√°ch h√†ng hi·ªán t·∫°i, v·ª´a m·ªü r·ªông ph·∫°m vi ti·∫øp c·∫≠n. V√≠ d·ª•, m·ªôt th∆∞∆°ng hi·ªáu nh∆∞ Apple kh√¥ng ng·ª´ng c·∫£i ti·∫øn s·∫£n ph·∫©m ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu c·ªßa ng∆∞·ªùi d√πng trung th√†nh, nh∆∞ng h·ªç c≈©ng li√™n t·ª•c qu·∫£ng b√° s·∫£n ph·∫©m ƒë·∫øn nh·ªØng ng∆∞·ªùi ch∆∞a t·ª´ng s·ª≠ d·ª•ng iPhone ho·∫∑c iPad. Chi·∫øn l∆∞·ª£c n√†y gi√∫p h·ªç v·ª´a duy tr√¨ ƒë∆∞·ª£c l√≤ng trung th√†nh c·ªßa kh√°ch h√†ng c≈©, v·ª´a m·ªü r·ªông ƒë∆∞·ª£c th·ªã tr∆∞·ªùng m·ªõi .\nTh√™m v√†o ƒë√≥, c√°c th∆∞∆°ng hi·ªáu c·∫ßn nh·ªõ r·∫±ng kh√°ch h√†ng m·ªõi kh√¥ng ph·∫£i l√∫c n√†o c≈©ng d·ªÖ d√†ng tr·ªü th√†nh kh√°ch h√†ng trung th√†nh ngay l·∫≠p t·ª©c. V√¨ v·∫≠y, vi·ªác x√¢y d·ª±ng m·ªëi quan h·ªá l√¢u d√†i v·ªõi h·ªç ƒë√≤i h·ªèi s·ª± ki√™n nh·∫´n v√† chi·∫øn l∆∞·ª£c ph√π h·ª£p. M·ªôt v√≠ d·ª• ƒëi·ªÉn h√¨nh l√† Netflix. Ban ƒë·∫ßu, h·ªç thu h√∫t ng∆∞·ªùi d√πng b·∫±ng c√°c ch∆∞∆°ng tr√¨nh khuy·∫øn m√£i mi·ªÖn ph√≠ trong m·ªôt th√°ng. Sau ƒë√≥, h·ªç d·∫ßn d·∫ßn bi·∫øn nh·ªØng ng∆∞·ªùi d√πng th·ª≠ th√†nh kh√°ch h√†ng tr·∫£ ph√≠ th√¥ng qua vi·ªác cung c·∫•p n·ªôi dung ƒë·ªôc quy·ªÅn v√† tr·∫£i nghi·ªám ng∆∞·ªùi d√πng t·ªët nh·∫•t .\n2. Nh·ªØng Ni·ªÅm Tin Sai L·∫ßm V·ªÅ S·ª± Trung Th√†nh C·ªßa Kh√°ch H√†ng Nhi·ªÅu doanh nghi·ªáp th∆∞·ªùng tin r·∫±ng kh√°ch h√†ng trung th√†nh l√† y·∫øu t·ªë quy·∫øt ƒë·ªãnh s·ª± th√†nh c√¥ng c·ªßa th∆∞∆°ng hi·ªáu. Tuy nhi√™n, cu·ªën s√°ch ƒë√£ ƒë∆∞a ra m·ªôt g√≥c nh√¨n kh√°c: s·ª± trung th√†nh c·ªßa kh√°ch h√†ng th∆∞·ªùng b·ªã th·ªïi ph·ªìng qu√° m·ª©c. Th·ª±c t·∫ø, ngay c·∫£ nh·ªØng kh√°ch h√†ng ƒë∆∞·ª£c coi l√† ‚Äútrung th√†nh‚Äù c≈©ng th∆∞·ªùng xuy√™n th·ª≠ nghi·ªám c√°c th∆∞∆°ng hi·ªáu kh√°c n·∫øu c√≥ c∆° h·ªôi .\nV√≠ d·ª•, m·ªôt ng∆∞·ªùi lu√¥n mua s·ªØa c·ªßa Vinamilk c√≥ th·ªÉ d·ªÖ d√†ng chuy·ªÉn sang TH True Milk n·∫øu s·∫£n ph·∫©m n√†y xu·∫•t hi·ªán ·ªü m·ªçi c·ª≠a h√†ng ho·∫∑c c√≥ ch∆∞∆°ng tr√¨nh khuy·∫øn m√£i h·∫•p d·∫´n. ƒêi·ªÅu n√†y cho th·∫•y r·∫±ng kh√¥ng c√≥ g√¨ ƒë·∫£m b·∫£o r·∫±ng kh√°ch h√†ng s·∫Ω lu√¥n g·∫Øn b√≥ v·ªõi m·ªôt th∆∞∆°ng hi·ªáu duy nh·∫•t. Do ƒë√≥, thay v√¨ c·ªë g·∫Øng bi·∫øn kh√°ch h√†ng th√†nh ‚Äút√≠n ƒë·ªì‚Äù c·ªßa th∆∞∆°ng hi·ªáu, c√°c doanh nghi·ªáp n√™n t·∫≠p trung v√†o hai y·∫øu t·ªë quan tr·ªçng: ƒë·ªô nh·∫≠n bi·∫øt (mental availability) v√† kh·∫£ nƒÉng ti·∫øp c·∫≠n (physical availability).\nƒê·ªô nh·∫≠n bi·∫øt (mental availability): ƒê√¢y l√† kh·∫£ nƒÉng th∆∞∆°ng hi·ªáu xu·∫•t hi·ªán trong t√¢m tr√≠ kh√°ch h√†ng khi h·ªç c·∫ßn m·ªôt s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª• c·ª• th·ªÉ. V√≠ d·ª•, n·∫øu ai ƒë√≥ mu·ªën mua kem ƒë√°nh rƒÉng, Colgate th∆∞·ªùng l√† c√°i t√™n ƒë·∫ßu ti√™n xu·∫•t hi·ªán trong t√¢m tr√≠ nh·ªù chi·∫øn l∆∞·ª£c qu·∫£ng c√°o m·∫°nh m·∫Ω v√† nh·∫•t qu√°n. ƒêi·ªÅu n√†y kh√¥ng ch·ªâ d·ª±a v√†o vi·ªác qu·∫£ng c√°o r·∫ßm r·ªô m√† c√≤n ph·ª• thu·ªôc v√†o c√°ch th∆∞∆°ng hi·ªáu x√¢y d·ª±ng h√¨nh ·∫£nh v√† gi√° tr·ªã c·ªßa m√¨nh trong m·∫Øt kh√°ch h√†ng . M·ªôt th∆∞∆°ng hi·ªáu nh∆∞ Nike ƒë√£ th√†nh c√¥ng trong vi·ªác t·∫°o ra s·ª± li√™n t∆∞·ªüng m·∫°nh m·∫Ω gi·ªØa s·∫£n ph·∫©m c·ªßa h·ªç v√† l·ªëi s·ªëng nƒÉng ƒë·ªông, kh·ªèe kho·∫Øn. Khi nh·∫Øc ƒë·∫øn gi√†y th·ªÉ thao, ng∆∞·ªùi ta th∆∞·ªùng nghƒ© ngay ƒë·∫øn Nike, d√π h·ªç kh√¥ng ph·∫£i l√† th∆∞∆°ng hi·ªáu duy nh·∫•t tr√™n th·ªã tr∆∞·ªùng.\nKh·∫£ nƒÉng ti·∫øp c·∫≠n (physical availability): ƒê√¢y l√† kh·∫£ nƒÉng kh√°ch h√†ng c√≥ th·ªÉ d·ªÖ d√†ng mua ƒë∆∞·ª£c s·∫£n ph·∫©m ·ªü b·∫•t k·ª≥ ƒë√¢u. M·ªôt th∆∞∆°ng hi·ªáu nh∆∞ Coca-Cola th√†nh c√¥ng nh·ªù vi·ªác ph√¢n ph·ªëi s·∫£n ph·∫©m r·ªông kh·∫Øp, t·ª´ si√™u th·ªã l·ªõn ƒë·∫øn c√°c c·ª≠a h√†ng t·∫°p h√≥a nh·ªè . Tuy nhi√™n, ƒëi·ªÅu n√†y kh√¥ng ch·ªâ ƒë∆°n gi·∫£n l√† vi·ªác ƒë·∫∑t s·∫£n ph·∫©m ·ªü m·ªçi n∆°i. N√≥ c√≤n ƒë√≤i h·ªèi th∆∞∆°ng hi·ªáu ph·∫£i ƒë·∫£m b·∫£o r·∫±ng s·∫£n ph·∫©m lu√¥n s·∫µn c√≥ khi kh√°ch h√†ng c·∫ßn. V√≠ d·ª•, trong m√πa h√®, c√°c th∆∞∆°ng hi·ªáu n∆∞·ªõc gi·∫£i kh√°t th∆∞·ªùng tƒÉng c∆∞·ªùng ph√¢n ph·ªëi s·∫£n ph·∫©m ·ªü c√°c khu v·ª±c b√£i bi·ªÉn, c√¥ng vi√™n, ho·∫∑c c√°c ƒëi·ªÉm du l·ªãch. ƒêi·ªÅu n√†y gi√∫p h·ªç t·∫≠n d·ª•ng t·ªëi ƒëa nhu c·∫ßu tƒÉng cao trong m√πa n√≥ng.\n3. Nh√≥m Light Buyers R·∫•t, R·∫•t Quan Tr·ªçng C·∫ßn nh·∫•n m·∫°nh r·∫±ng nh√≥m kh√°ch h√†ng kh√¥ng mua th∆∞·ªùng xuy√™n (light buyers) ƒë√≥ng vai tr√≤ quan tr·ªçng h∆°n nhi·ªÅu so v·ªõi nh√≥m kh√°ch h√†ng trung th√†nh. L√Ω do r·∫•t ƒë∆°n gi·∫£n: nh√≥m light buyers chi·∫øm s·ªë l∆∞·ª£ng l·ªõn h∆°n ƒë√°ng k·ªÉ. H·ªç c√≥ th·ªÉ kh√¥ng mua s·∫£n ph·∫©m th∆∞·ªùng xuy√™n, nh∆∞ng t·ªïng s·ªë l∆∞·ª£ng giao d·ªãch c·ªßa h·ªç v·∫´n v∆∞·ª£t xa nh√≥m kh√°ch h√†ng trung th√†nh .\nH√£y t∆∞·ªüng t∆∞·ª£ng b·∫°n ƒëang ƒëi·ªÅu h√†nh m·ªôt th∆∞∆°ng hi·ªáu c√† ph√™. Thay v√¨ ch·ªâ chƒÉm chƒÉm v√†o nh·ªØng ng∆∞·ªùi u·ªëng c√† ph√™ m·ªói s√°ng, b·∫°n n√™n ƒë·∫ßu t∆∞ v√†o vi·ªác thu h√∫t nh·ªØng ng∆∞·ªùi ch·ªâ th·ªânh tho·∫£ng u·ªëng c√† ph√™ ‚Äì v√≠ d·ª• nh∆∞ khi ƒëi g·∫∑p g·ª° b·∫°n b√® ho·∫∑c trong nh·ªØng d·ªãp ƒë·∫∑c bi·ªát. Khi nh√≥m kh√°ch h√†ng n√†y c·∫£m th·∫•y h√†i l√≤ng, h·ªç s·∫Ω d·∫ßn tr·ªü th√†nh kh√°ch h√†ng th∆∞·ªùng xuy√™n h∆°n .\nƒê·ªÉ l√†m ƒë∆∞·ª£c ƒëi·ªÅu n√†y, c√°c th∆∞∆°ng hi·ªáu c·∫ßn √°p d·ª•ng chi·∫øn l∆∞·ª£c marketing ƒë·∫°i tr√† (mass marketing) thay v√¨ ch·ªâ t·∫≠p trung v√†o m·ªôt nh√≥m nh·ªè kh√°ch h√†ng trung th√†nh. V√≠ d·ª•, m·ªôt th∆∞∆°ng hi·ªáu nh∆∞ Starbucks kh√¥ng ch·ªâ qu·∫£ng c√°o s·∫£n ph·∫©m c·ªßa m√¨nh ƒë·∫øn nh·ªØng ng∆∞·ªùi y√™u th√≠ch c√† ph√™ m√† c√≤n h∆∞·ªõng ƒë·∫øn nh·ªØng ng∆∞·ªùi ch·ªâ th·ªânh tho·∫£ng u·ªëng ƒë·ªì u·ªëng c√≥ h∆∞∆°ng v·ªã ƒë·∫∑c bi·ªát. H·ªç th∆∞·ªùng xuy√™n tung ra c√°c d√≤ng s·∫£n ph·∫©m m·ªõi, ch·∫≥ng h·∫°n nh∆∞ ƒë·ªì u·ªëng theo m√πa (Pumpkin Spice Latte), ƒë·ªÉ thu h√∫t s·ª± ch√∫ √Ω c·ªßa nh√≥m kh√°ch h√†ng n√†y .\n4. Thay ƒê·ªïi C√°c Quan ƒêi·ªÉm Marketing Truy·ªÅn Th·ªëng Marketing C·ªï ƒêi·ªÉn C√≥ Th·ªÉ Sai L·∫ßm :) hi hi. T√¥i kh√¥ng bi·∫øt, nh∆∞ng. Theo Byron Sharp, r·∫•t nhi·ªÅu chi·∫øn l∆∞·ª£c marketing hi·ªán ƒë·∫°i d·ª±a tr√™n ni·ªÅm tin sai l·∫ßm r·∫±ng c√°c th∆∞∆°ng hi·ªáu c·∫ßn t·∫°o ra s·ª± kh√°c bi·ªát r√µ r·ªát so v·ªõi ƒë·ªëi th·ªß c·∫°nh tranh ƒë·ªÉ thu h√∫t kh√°ch h√†ng . Tuy nhi√™n, nghi√™n c·ª©u th·ª±c t·∫ø ƒë√£ ch·ªâ ra r·∫±ng ƒëi·ªÅu n√†y kh√¥ng ho√†n to√†n ch√≠nh x√°c.\nTrong th·ª±c t·∫ø, kh√°ch h√†ng th∆∞·ªùng kh√¥ng nh·∫≠n ra s·ª± kh√°c bi·ªát ƒë√°ng k·ªÉ gi·ªØa c√°c th∆∞∆°ng hi·ªáu trong c√πng m·ªôt ng√†nh h√†ng. H√£y l·∫•y v√≠ d·ª• v·ªÅ ng√†nh h√†ng n∆∞·ªõc gi·∫£i kh√°t. N·∫øu h·ªèi m·ªôt ng∆∞·ªùi ti√™u d√πng b√¨nh th∆∞·ªùng, h·ªç c√≥ th·ªÉ kh√≥ n√≥i ƒë∆∞·ª£c s·ª± kh√°c bi·ªát c·ª• th·ªÉ gi·ªØa Coca-Cola v√† Pepsi, ho·∫∑c gi·ªØa Red Bull v√† Monster Energy. ƒêi·ªÅu n√†y cho th·∫•y r·∫±ng ni·ªÅm tin v√†o vi·ªác x√¢y d·ª±ng s·ª± kh√°c bi·ªát ƒë·ªôc ƒë√°o gi·ªØa c√°c th∆∞∆°ng hi·ªáu th∆∞·ªùng b·ªã ph√≥ng ƒë·∫°i. Kh√°ch h√†ng kh√¥ng d√†nh qu√° nhi·ªÅu th·ªùi gian ƒë·ªÉ ph√¢n t√≠ch k·ªπ l∆∞·ª°ng t·ª´ng ƒë·∫∑c ƒëi·ªÉm s·∫£n ph·∫©m; thay v√†o ƒë√≥, h·ªç th∆∞·ªùng quy·∫øt ƒë·ªãnh mua s·∫Øm d·ª±a tr√™n y·∫øu t·ªë quen thu·ªôc (brand familiarity) v√† t√≠nh s·∫µn c√≥ (availability) .\nC·∫ßn nh·∫•n m·∫°nh r·∫±ng vi·ªác c·ªë g·∫Øng l√†m n·ªïi b·∫≠t t√≠nh ƒë·ªôc ƒë√°o c·ªßa s·∫£n ph·∫©m ƒë√¥i khi kh√¥ng hi·ªáu qu·∫£ nh∆∞ mong ƒë·ª£i, ƒë·∫∑c bi·ªát khi ng√¢n s√°ch marketing b·ªã h·∫°n ch·∫ø. V√≠ d·ª•, m·ªôt th∆∞∆°ng hi·ªáu nh·ªè trong ng√†nh m·ªπ ph·∫©m c√≥ th·ªÉ t·∫≠p trung v√†o vi·ªác qu·∫£ng c√°o r·∫±ng s·∫£n ph·∫©m c·ªßa h·ªç \u0026ldquo;100% t·ª± nhi√™n\u0026rdquo; ho·∫∑c \u0026ldquo;kh√¥ng ch·ª©a h√≥a ch·∫•t ƒë·ªôc h·∫°i\u0026rdquo;. Tuy nhi√™n, n·∫øu th∆∞∆°ng hi·ªáu n√†y kh√¥ng ƒë·∫ßu t∆∞ v√†o vi·ªác tƒÉng ƒë·ªô nh·∫≠n bi·∫øt v√† kh·∫£ nƒÉng ti·∫øp c·∫≠n, th√¨ nh·ªØng th√¥ng ƒëi·ªáp v·ªÅ s·ª± kh√°c bi·ªát n√†y s·∫Ω kh√≥ c√≥ th·ªÉ ch·∫°m t·ªõi kh√°ch h√†ng ti·ªÅm nƒÉng. Thay v√¨ c·ªë g·∫Øng tr·ªü n√™n \u0026ldquo;ƒë·ªôc nh·∫•t v√¥ nh·ªã\u0026rdquo;, c√°c th∆∞∆°ng hi·ªáu n√™n t·∫≠p trung v√†o vi·ªác x√¢y d·ª±ng s·ª± hi·ªán di·ªán m·∫°nh m·∫Ω trong t√¢m tr√≠ kh√°ch h√†ng th√¥ng qua vi·ªác l·∫∑p l·∫°i li√™n t·ª•c v√† nh·∫•t qu√°n . Qu·∫£ng c√°o TVC c·ªßa m·ªôt th∆∞∆°ng hi·ªáu b√°n l·∫ª s·ªë 1 Vi·ªát Nam c√°ch ƒë√¢y v√†i nƒÉm m√† t√¥i kh√¥ng ti·ªán n√™u t√™n l√† m·ªôt v√≠ d·ª•.\nH√£y nghƒ© ƒë·∫øn c√°c th∆∞∆°ng hi·ªáu l·ªõn nh∆∞ McDonald‚Äôs hay Nike ‚Äì h·ªç kh√¥ng c·∫ßn ph·∫£i thay ƒë·ªïi th√¥ng ƒëi·ªáp qu√° nhi·ªÅu, m√† ch·ªâ c·∫ßn duy tr√¨ s·ª± nh·∫•t qu√°n trong c√°ch truy·ªÅn t·∫£i gi√° tr·ªã th∆∞∆°ng hi·ªáu. McDonald‚Äôs lu√¥n g·∫Øn li·ªÅn v·ªõi h√¨nh ·∫£nh c·ªßa nh·ªØng b·ªØa ƒÉn nhanh, ti·ªán l·ª£i v√† vui v·∫ª. D√π menu c·ªßa h·ªç c√≥ thay ƒë·ªïi theo t·ª´ng qu·ªëc gia, th√¥ng ƒëi·ªáp c·ªët l√µi v·∫´n lu√¥n ƒë∆∞·ª£c gi·ªØ nguy√™n. T∆∞∆°ng t·ª±, Nike kh√¥ng ng·ª´ng nh·∫Øc nh·ªü kh√°ch h√†ng v·ªÅ kh·∫©u hi·ªáu \u0026ldquo;Just Do It\u0026rdquo; v√† h√¨nh ·∫£nh g·∫Øn li·ªÅn v·ªõi l·ªëi s·ªëng nƒÉng ƒë·ªông, kh·ªèe kho·∫Øn. ƒêi·ªÅu n√†y gi√∫p h·ªç duy tr√¨ v·ªã th·∫ø d·∫´n ƒë·∫ßu trong t√¢m tr√≠ kh√°ch h√†ng m√† kh√¥ng c·∫ßn ph·∫£i li√™n t·ª•c ƒë·ªïi m·ªõi th√¥ng ƒëi·ªáp .\nDo ƒë√≥, thay v√¨ c·ªë g·∫Øng t·∫°o ra s·ª± kh√°c bi·ªát qu√° m·ª©c, c√°c th∆∞∆°ng hi·ªáu n√™n t·∫≠p trung v√†o vi·ªác tƒÉng c∆∞·ªùng ƒë·ªô nh·∫≠n bi·∫øt (mental availability) v√† kh·∫£ nƒÉng ti·∫øp c·∫≠n (physical availability). ƒê√¢y l√† hai y·∫øu t·ªë quan tr·ªçng gi√∫p th∆∞∆°ng hi·ªáu xu·∫•t hi·ªán ƒë√∫ng l√∫c, ƒë√∫ng n∆°i v√† d·ªÖ d√†ng ti·∫øp c·∫≠n kh√°ch h√†ng ti·ªÅm nƒÉng .\n5. Nh·ªØng B√†i H·ªçc Th·ª±c Ti·ªÖn: L√†m Th·∫ø N√†o ƒê·ªÉ √Åp D·ª•ng Nh·ªØng Ph√°t Hi·ªán T·ª´ Cu·ªën S√°ch? L·ªùi khuy√™n quan tr·ªçng nh·∫•t l√† ƒë·ª´ng l√£ng ph√≠ ngu·ªìn l·ª±c v√†o vi·ªác c·ªë g·∫Øng gi·ªØ ch√¢n kh√°ch h√†ng trung th√†nh. Thay v√†o ƒë√≥, h√£y ƒë·∫ßu t∆∞ v√†o vi·ªác m·ªü r·ªông ƒë·ªô ph·ªß s√≥ng c·ªßa th∆∞∆°ng hi·ªáu v√† c·∫£i thi·ªán kh·∫£ nƒÉng ti·∫øp c·∫≠n s·∫£n ph·∫©m. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë chi·∫øn l∆∞·ª£c c·ª• th·ªÉ m√† c√°c doanh nghi·ªáp c√≥ th·ªÉ √°p d·ª•ng:\na. Qu·∫£ng c√°o r·ªông r√£i h∆°n: ƒê·∫£m b·∫£o th∆∞∆°ng hi·ªáu xu·∫•t hi·ªán ·ªü m·ªçi n∆°i ƒê·ªÉ tƒÉng ƒë·ªô nh·∫≠n bi·∫øt (mental availability), c√°c th∆∞∆°ng hi·ªáu c·∫ßn ƒë·∫£m b·∫£o r·∫±ng h·ªç xu·∫•t hi·ªán ·ªü m·ªçi n∆°i m√† kh√°ch h√†ng ti·ªÅm nƒÉng c√≥ th·ªÉ nh√¨n th·∫•y. ƒêi·ªÅu n√†y kh√¥ng ch·ªâ gi·ªõi h·∫°n ·ªü c√°c k√™nh qu·∫£ng c√°o truy·ªÅn th·ªëng nh∆∞ TV, b√°o ch√≠, m√† c√≤n bao g·ªìm c·∫£ c√°c n·ªÅn t·∫£ng k·ªπ thu·∫≠t s·ªë nh∆∞ m·∫°ng x√£ h·ªôi, YouTube, v√† c√°c ·ª©ng d·ª•ng di ƒë·ªông. V√≠ d·ª•, m·ªôt th∆∞∆°ng hi·ªáu nh∆∞ Coca-Cola kh√¥ng ng·ª´ng qu·∫£ng b√° s·∫£n ph·∫©m c·ªßa m√¨nh th√¥ng qua c√°c chi·∫øn d·ªãch qu·∫£ng c√°o to√†n c·∫ßu, t·ª´ Super Bowl ƒë·∫øn c√°c s·ª± ki·ªán th·ªÉ thao l·ªõn nh∆∞ World Cup. Nh·ªù ƒë√≥, h·ªç duy tr√¨ ƒë∆∞·ª£c s·ª± hi·ªán di·ªán m·∫°nh m·∫Ω trong t√¢m tr√≠ kh√°ch h√†ng .\nTuy nhi√™n, qu·∫£ng c√°o r·ªông r√£i kh√¥ng ƒë·ªìng nghƒ©a v·ªõi vi·ªác \u0026ldquo;l√†m ·ªìn √†o\u0026rdquo; m√† kh√¥ng c√≥ chi·∫øn l∆∞·ª£c. C√°c th∆∞∆°ng hi·ªáu c·∫ßn ƒë·∫£m b·∫£o r·∫±ng th√¥ng ƒëi·ªáp qu·∫£ng c√°o c·ªßa h·ªç nh·∫•t qu√°n v√† ph√π h·ª£p v·ªõi gi√° tr·ªã c·ªët l√µi c·ªßa th∆∞∆°ng hi·ªáu. V√≠ d·ª•, Apple lu√¥n g·∫Øn li·ªÅn v·ªõi h√¨nh ·∫£nh c·ªßa s·ª± s√°ng t·∫°o, ƒë·∫≥ng c·∫•p v√† c√¥ng ngh·ªá ti√™n ti·∫øn. D√π qu·∫£ng c√°o tr√™n b·∫•t k·ª≥ n·ªÅn t·∫£ng n√†o, th√¥ng ƒëi·ªáp c·ªßa h·ªç v·∫´n lu√¥n xoay quanh nh·ªØng gi√° tr·ªã n√†y .\nb. M·ªü r·ªông m·∫°ng l∆∞·ªõi ph√¢n ph·ªëi: ƒê·∫£m b·∫£o s·∫£n ph·∫©m c√≥ m·∫∑t ·ªü t·∫•t c·∫£ c√°c k√™nh b√°n h√†ng Kh·∫£ nƒÉng ti·∫øp c·∫≠n (physical availability) l√† y·∫øu t·ªë quan tr·ªçng th·ª© hai m√† c√°c th∆∞∆°ng hi·ªáu c·∫ßn ch√∫ tr·ªçng. M·ªôt s·∫£n ph·∫©m d√π t·ªët ƒë·∫øn ƒë√¢u c≈©ng s·∫Ω kh√¥ng th·ªÉ th√†nh c√¥ng n·∫øu kh√°ch h√†ng kh√¥ng th·ªÉ d·ªÖ d√†ng mua ƒë∆∞·ª£c n√≥. Do ƒë√≥, c√°c th∆∞∆°ng hi·ªáu c·∫ßn m·ªü r·ªông m·∫°ng l∆∞·ªõi ph√¢n ph·ªëi ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng s·∫£n ph·∫©m c·ªßa h·ªç c√≥ m·∫∑t ·ªü t·∫•t c·∫£ c√°c k√™nh b√°n h√†ng, t·ª´ c·ª≠a h√†ng truy·ªÅn th·ªëng ƒë·∫øn c√°c n·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ .\nV√≠ d·ª•, m·ªôt th∆∞∆°ng hi·ªáu nh∆∞ Unilever ƒë√£ x√¢y d·ª±ng m·∫°ng l∆∞·ªõi ph√¢n ph·ªëi r·ªông kh·∫Øp, t·ª´ si√™u th·ªã l·ªõn nh∆∞ Big C, Lotte Mart ƒë·∫øn c√°c c·ª≠a h√†ng t·∫°p h√≥a nh·ªè ·ªü v√πng n√¥ng th√¥n. ƒêi·ªÅu n√†y gi√∫p h·ªç ti·∫øp c·∫≠n ƒë∆∞·ª£c c·∫£ nh√≥m kh√°ch h√†ng th√†nh th·ªã v√† n√¥ng th√¥n, t·ª´ ƒë√≥ tƒÉng doanh s·ªë b√°n h√†ng m·ªôt c√°ch ƒë√°ng k·ªÉ. T∆∞∆°ng t·ª±, c√°c th∆∞∆°ng hi·ªáu ƒë·ªì u·ªëng nh∆∞ Coca-Cola ho·∫∑c Pepsi lu√¥n ƒë·∫£m b·∫£o r·∫±ng s·∫£n ph·∫©m c·ªßa h·ªç c√≥ m·∫∑t ·ªü m·ªçi n∆°i, t·ª´ m√°y b√°n h√†ng t·ª± ƒë·ªông t·∫°i s√¢n bay ƒë·∫øn c√°c qu√°n c√† ph√™ nh·ªè .\nc. T·ªëi ∆∞u h√≥a tr·∫£i nghi·ªám mua s·∫Øm c·ªßa kh√°ch h√†ng: ƒê∆°n gi·∫£n h√≥a quy tr√¨nh mua h√†ng B√™n c·∫°nh vi·ªác qu·∫£ng c√°o r·ªông r√£i v√† m·ªü r·ªông m·∫°ng l∆∞·ªõi ph√¢n ph·ªëi, c√°c th∆∞∆°ng hi·ªáu c≈©ng c·∫ßn ch√∫ tr·ªçng ƒë·∫øn vi·ªác t·ªëi ∆∞u h√≥a tr·∫£i nghi·ªám mua s·∫Øm c·ªßa kh√°ch h√†ng. ƒêi·ªÅu n√†y bao g·ªìm vi·ªác ƒë∆°n gi·∫£n h√≥a quy tr√¨nh mua h√†ng, cung c·∫•p d·ªãch v·ª• kh√°ch h√†ng t·ªët nh·∫•t c√≥ th·ªÉ, v√† ƒë·∫£m b·∫£o r·∫±ng s·∫£n ph·∫©m lu√¥n ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu c·ªßa kh√°ch h√†ng. V√≠ d·ª•, Amazon ƒë√£ th√†nh c√¥ng nh·ªù vi·ªác t·ªëi ∆∞u h√≥a tr·∫£i nghi·ªám mua s·∫Øm tr·ª±c tuy·∫øn, t·ª´ vi·ªác cung c·∫•p giao di·ªán d·ªÖ s·ª≠ d·ª•ng ƒë·∫øn d·ªãch v·ª• giao h√†ng nhanh ch√≥ng v√† ch√≠nh x√°c. ƒêi·ªÅu n√†y gi√∫p h·ªç thu h√∫t v√† gi·ªØ ch√¢n ƒë∆∞·ª£c l∆∞·ª£ng l·ªõn kh√°ch h√†ng .\nNgo√†i ra, c√°c th∆∞∆°ng hi·ªáu c≈©ng c·∫ßn ch√∫ √Ω ƒë·∫øn ph·∫£n h·ªìi c·ªßa kh√°ch h√†ng ƒë·ªÉ kh√¥ng ng·ª´ng c·∫£i thi·ªán s·∫£n ph·∫©m v√† d·ªãch v·ª•. V√≠ d·ª•, Netflix th∆∞·ªùng xuy√™n thu th·∫≠p ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng ƒë·ªÉ c·∫£i thi·ªán n·ªôi dung v√† tr·∫£i nghi·ªám xem phim. H·ªç c≈©ng li√™n t·ª•c tung ra c√°c d√≤ng s·∫£n ph·∫©m m·ªõi, ch·∫≥ng h·∫°n nh∆∞ ch∆∞∆°ng tr√¨nh g·ªëc (original series), ƒë·ªÉ thu h√∫t s·ª± ch√∫ √Ω c·ªßa kh√°ch h√†ng .\nd. X√¢y d·ª±ng th∆∞∆°ng hi·ªáu d·ª±a tr√™n d·ªØ li·ªáu th·ª±c t·∫ø V√≠ d·ª•, m·ªôt th∆∞∆°ng hi·ªáu nh∆∞ Google th∆∞·ªùng xuy√™n s·ª≠ d·ª•ng d·ªØ li·ªáu ng∆∞·ªùi d√πng ƒë·ªÉ c·∫£i thi·ªán s·∫£n ph·∫©m v√† d·ªãch v·ª• c·ªßa m√¨nh. H·ªç ph√¢n t√≠ch h√†nh vi t√¨m ki·∫øm c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ ƒë∆∞a ra c√°c ƒë·ªÅ xu·∫•t ph√π h·ª£p v√† c√° nh√¢n h√≥a tr·∫£i nghi·ªám ng∆∞·ªùi d√πng .\nIII. Chi·∫øn l·ª±c t·∫≠n d·ª•ng Light Buyers cho nh√≥m doanh nghi·ªáp Chi·∫øn l∆∞·ª£c cho doanh nghi·ªáp nh·ªè Doanh nghi·ªáp nh·ªè th∆∞·ªùng c√≥ ngu·ªìn l·ª±c h·∫°n ch·∫ø, v√¨ v·∫≠y c·∫ßn t·∫≠p trung v√†o Light Buyers ƒë·ªÉ t·ªëi ∆∞u h√≥a chi ph√≠ v√† m·ªü r·ªông t·ªáp kh√°ch h√†ng ti·ªÅm nƒÉng. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë g·ª£i √Ω:\nTƒÉng s·ª± nh·∫≠n di·ªán th∆∞∆°ng hi·ªáu: Doanh nghi·ªáp nh·ªè n√™n t·∫≠p trung v√†o vi·ªác ti·∫øp c·∫≠n nhi·ªÅu kh√°ch h√†ng m·ªõi, bao g·ªìm c·∫£ Light Buyers, th√¥ng qua c√°c chi·∫øn d·ªãch qu·∫£ng c√°o s√°ng t·∫°o v√† n·ªôi dung ph√π h·ª£p. ƒêi·ªÅu n√†y gi√∫p gia tƒÉng c∆° h·ªôi b√°n h√†ng t·ª´ nh·ªØng ng∆∞·ªùi ch∆∞a t·ª´ng mua s·∫£n ph·∫©m .\nKhuy·∫øn m√£i v√† tr·∫£i nghi·ªám th·ª≠: S·ª≠ d·ª•ng c√°c ch∆∞∆°ng tr√¨nh khuy·∫øn m√£i, gi·∫£m gi√° ho·∫∑c d√πng th·ª≠ mi·ªÖn ph√≠ ƒë·ªÉ thu h√∫t Light Buyers. Nh√≥m n√†y th∆∞·ªùng nh·∫°y c·∫£m v·ªõi gi√° c·∫£ v√† d·ªÖ b·ªã thu h√∫t b·ªüi c√°c ∆∞u ƒë√£i h·∫•p d·∫´n .\nX√¢y d·ª±ng l√≤ng tin: Th√¥ng qua d·ªãch v·ª• chƒÉm s√≥c kh√°ch h√†ng t·ªët v√† s·∫£n ph·∫©m ch·∫•t l∆∞·ª£ng, doanh nghi·ªáp nh·ªè c√≥ th·ªÉ chuy·ªÉn ƒë·ªïi m·ªôt s·ªë Light Buyers th√†nh Heavy Buyers, t·ª´ ƒë√≥ tƒÉng doanh thu l√¢u d√†i .\nChi·∫øn l∆∞·ª£c cho doanh nghi·ªáp l·ªõn Doanh nghi·ªáp l·ªõn c√≥ ngu·ªìn l·ª±c d·ªìi d√†o h∆°n, v√¨ v·∫≠y c√≥ th·ªÉ √°p d·ª•ng chi·∫øn l∆∞·ª£c song song gi·ªØa Heavy Buyers v√† Light Buyers:\nDuy tr√¨ m·ªëi quan h·ªá v·ªõi Heavy Buyers: T·∫≠p trung v√†o vi·ªác gi·ªØ ch√¢n nh√≥m kh√°ch h√†ng trung th√†nh b·∫±ng c√°ch cung c·∫•p c√°c ch∆∞∆°ng tr√¨nh ∆∞u ƒë√£i ƒë·∫∑c bi·ªát, qu√† t·∫∑ng VIP ho·∫∑c d·ªãch v·ª• c√° nh√¢n h√≥a. Nh·ªØng n·ªó l·ª±c n√†y gi√∫p ƒë·∫£m b·∫£o r·∫±ng Heavy Buyers ti·∫øp t·ª•c ƒë√≥ng g√≥p ƒë√°ng k·ªÉ v√†o doanh thu .\nM·ªü r·ªông th·ªã tr∆∞·ªùng v·ªõi Light Buyers: T∆∞∆°ng t·ª± nh∆∞ doanh nghi·ªáp nh·ªè, doanh nghi·ªáp l·ªõn c≈©ng c·∫ßn ch√∫ tr·ªçng ƒë·∫øn vi·ªác thu h√∫t th√™m Light Buyers. Tuy nhi√™n, ·ªü quy m√¥ l·ªõn, h·ªç c√≥ th·ªÉ ƒë·∫ßu t∆∞ v√†o c√°c chi·∫øn d·ªãch qu·∫£ng c√°o to√†n di·ªán, v√≠ d·ª• nh∆∞ truy·ªÅn th√¥ng ƒë·∫°i ch√∫ng (TV, b√°o ch√≠) ho·∫∑c digital marketing tr√™n nhi·ªÅu n·ªÅn t·∫£ng kh√°c nhau .\nƒêa d·∫°ng h√≥a s·∫£n ph·∫©m v√† d·ªãch v·ª•: ƒê∆∞a ra c√°c d√≤ng s·∫£n ph·∫©m m·ªõi nh·∫±m ƒë√°p ·ª©ng nhu c·∫ßu c·ªßa c·∫£ hai nh√≥m kh√°ch h√†ng. V√≠ d·ª•, n·∫øu kinh doanh qu√°n cafe, c√≥ th·ªÉ ph√°t tri·ªÉn c√°c lo·∫°i ƒë·ªì u·ªëng d√†nh ri√™ng cho d·ªãp ƒë·∫∑c bi·ªát (thu h√∫t Light Buyers) ho·∫∑c g√≥i ∆∞u ƒë√£i cho kh√°ch h√†ng th∆∞·ªùng xuy√™n (ph·ª•c v·ª• Heavy Buyers) .\nB√†i vi·∫øt d∆∞·ªõi g√≥c nh√¨n c·ªßa m·ªôt con IT qu√®n, th·∫±ng IT l·ªè, vi·∫øt v·ªÅ m·ªôt v·∫•n ƒë·ªÅ kinh t·∫ø, b√† con chuy√™n ng√†nh th·∫•y sai th√¨ hoan h·ªâ c√≤m m√™n nh·∫π nh√†ng, ƒë·ª´ng bu√¥n l·ªùi cay ƒë·∫Øng.\nC·∫£m ∆°n b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\nNgu·ªìn tham kh·∫£o\ncu·ªën s√°ch How Brands Grow c·ªßa t√°c gi·∫£ Byron Sharp v√† Jenni Romaniuk\nB·∫£n d·ªãch ti·∫øng vi·ªát Con ƒë∆∞·ªùng tƒÉng tr∆∞·ªüng th∆∞∆°ng hi·ªáu\n","date":"Apr 26, 2025","img":"https://unsplash.it/1920/1080?image=231","permalink":"/blog/2025-04-26-how-brands-grow/","series":null,"tags":["marketing"],"title":"Kh√°m Ph√° B√≠ M·∫≠t ƒê·∫±ng Sau S·ª± Th√†nh C√¥ng C·ªßa C√°c Th∆∞∆°ng Hi·ªáu"},{"categories":null,"content":" C√°c b∆∞·ªõc th·ª±c hi·ªán Ch∆∞∆°ng 1 ‚Äì Tuy·∫øt Gi√°c Tr√∫c L√¢m Ch∆∞∆°ng 2 ‚Äì T√¢m Ma K√Ω ·ª®c Ch∆∞∆°ng 3 ‚Äì Huy·∫øt T√¢m Li√™n Hoa Ch∆∞∆°ng 4 ‚Äì Tuy·∫øt Giao Chi·∫øn Ch∆∞∆°ng 5 ‚Äì Th·∫ø L·ª±c B·ªã X√© R√°ch Ch∆∞∆°ng 6 ‚Äì Ma T√¥n ƒê·∫°i Th·∫Øng Ch∆∞∆°ng 7 ‚Äì L·ªó H·ªïng Kh√¥ng Gian L√† m·ªôt fan c·ªßa ti·ªÉu thuy·∫øt tu ti√™n, tu ti√™n gi·∫£ ƒë·ªùi ƒë·∫ßu, b·ªô truy·ªán ƒë·∫ßu ti√™n m√¨nh ƒë·ªçc l√† Tru ti√™n c·ªßa Ti√™u ƒê·ªânh. H√¥m nay, m√¨nh ch·ª£t n·∫£y ra √Ω t∆∞·ªüng, d√πng AI, k·∫øt h·ª£p h√¨nh t∆∞·ª£ng bƒÉng thanh ng·ªçc khi·∫øt c·ªßa L·ª•c Tuy·∫øt K·ª≥, k·∫øt h·ª£p v·ªõi m·ªôt nh√¢n v·∫≠t n·ªØ ƒë·ªôc ƒëo√°n v·∫°n c·ªó Li·ªÖu Nh∆∞ Y√™n, v√† ƒë·∫°i s∆∞ huynh di·ªáp thi√™n ƒë·∫ø Di·ªáp Th·∫ßn, th√†nh m·ªôt c√¢u truy·ªán m·ªõi Tuy·∫øt Gi√°c Tr√∫c L√¢m\nC√°c b∆∞·ªõc th·ª±c hi·ªán ƒê·ªÉ c√≥ th·ªÉ t·∫°o ƒë∆∞·ª£c m·ªôt b·ªô truy·ªán, ch√∫ng ta c·∫ßn nguy√™n li·ªáu l√† b·ªë c·ª•c c√¢u truy·ªán v√† x√¢y d·ª±ng t√≠nh c√°ch nh√¢n v·∫≠t. Nh√¢n v·∫≠t ch√≠nh m√¨nh c√≥ r·ªìi, gi·ªù ch·ªâ c·∫ßn nh·ªù AI x√¢y d·ª±ng b·ªë c·ª•c d·ª±a v√†o v√†i g·ª£i √Ω, v√≠ d·ª• 2 c√¥ g√°i c√πng y√™u ƒë·∫°i s∆∞ huynh ( d·∫°ng c·∫©u huy·∫øt) , ho·∫∑c l√† Di·ªáp Th·∫ßn k·∫øt h·ª£p v·ªõi L·ª•c Tuy·∫øt K·ª≥ v√† Li·ªÖu Nh∆∞ Y√™n ph√° ƒë√°m \u0026hellip; Ch·ªâ c·∫ßn b·∫°n c√≥ √Ω t∆∞·ªüng, AI s·∫Ω ho√†n th√†nh n√≥ cho b·∫°n.\nv√≠ d·ª•, ti·ªÉu thy·∫øt ng·∫Øn m√¨nh y√™u c·∫ßu AI vi·∫øt nh∆∞ sau:\nTh·ªÉ lo·∫°i: Ti√™n hi·ªáp ‚Äì Huy·ªÅn huy·ªÖn ‚Äì C·ªï trang ‚Äì T√¨nh c·∫£m ‚Äì Ch√≠nh t√† l∆∞·ª°ng l·ªô\nTuy·∫øn nh√¢n v·∫≠t trung t√¢m:\nL·ª•c Tuy·∫øt K·ª≥ ‚Äì n·ªØ tu Thanh V√¢n M√¥n, l·∫°nh l√πng, ki√™n ƒë·ªãnh, nghƒ©a kh√≠\nLi·ªÖu Nh∆∞ Y√™n ‚Äì truy·ªÅn nh√¢n C·∫ßm M·ªông C·ªëc, √¥n nhu, n·ªôi t√¢m s√¢u s·∫Øc\nDi·ªáp Th·∫ßn ‚Äì t·ª´ng l√† thi√™n t√†i tu ƒë·∫°o, sau b·ªã k·∫øt t·ªôi ma tu, nh√¢n v·∫≠t trung gian gi·ªØa ch√≠nh v√† t√†\nTh·∫ø gi·ªõi: 9 ƒë·∫°i ti√™n m√¥n ‚Äì 3 v·ª±c Ma gi·ªõi ‚Äì 1 gi·ªõi ‚ÄúNgo·∫°i v·ª±c‚Äù c·ªï x∆∞a b·ªã phong ·∫•n\nC·ªët truy·ªán ch√≠nh: H√†nh tr√¨nh truy t√¨m b√≠ ·∫©n v·ªÅ B√≠ch L·∫°c c·ªï t√¥ng, ‚ÄúHuy·∫øt T√¢m H√†n Li√™n‚Äù ch·ªâ l√† kh·ªüi ƒë·∫ßu. B√≠ m·∫≠t v·ªÅ qu√° kh·ª© Di·ªáp Th·∫ßn, m·ªëi li√™n h·ªá gi·ªØa Tuy·∫øt K·ª≥ ‚Äì Nh∆∞ Y√™n, v√† th·∫ø l·ª±c c·ªï x∆∞a ƒëang d·∫ßn th·ª©c t·ªânh.\nSau ƒë√≥ , ch√∫ng ta s·∫Ω y√™u c·∫ßu AI l√™n k·ªãch b·∫£n s·ªë ch∆∞∆°ng, ti√™u ƒë·ªÅ m·ªói ch∆∞∆°ng, v√† vi·∫øt th√¥i\nTruy·ªán n√†y m√¨nh y√™u c·∫ßu AI vi·∫øt h∆°n 100 ch∆∞∆°ng, m√¨nh post 7 ch∆∞∆°ng, c√≥ ai h·ª©ng th√∫ xem th√¨ m√¨nh c√≤m men ƒë·ªÉ m√¨nh post th√™m, c√≤n kh√¥ng c√≥ ai h·ª©ng th√∫ th√¨ coi nh∆∞ AI vi·∫øt d·ªü , he he.\nCh∆∞∆°ng 1 ‚Äì Tuy·∫øt Gi√°c Tr√∫c L√¢m Tuy·∫øt r∆°i tr·∫Øng x√≥a tr·ªùi.\nTr√™n ƒë·ªânh Tuy·∫øt Gi√°c, gi·ªØa r·ª´ng tr√∫c ng√∫t ng√†n bƒÉng gi√°, t·ª´ng c∆°n gi√≥ th√©t g√†o r√≠t qua t·ª´ng k·∫Ω l√°. Tr√∫c xanh ph·ªß tuy·∫øt b·∫°c, ƒë·∫•t tr·ªùi nh∆∞ h√≥a th√†nh b·ª©c tranh m·ª±c t√†u l·∫°nh l·∫Ωo v√† t·ªãch m·ªãch.\nGi·ªØa bi·ªÉn tr·∫Øng m√™nh m√¥ng ·∫•y, hai b√≥ng ng∆∞·ªùi c√πng l√∫c ƒë√°p xu·ªëng ƒë·∫•t.\nM·ªôt ng∆∞·ªùi kho√°c tr∆∞·ªùng sam m√†u lam nh·∫°t, th√¢n h√¨nh thanh m·∫£nh, c·∫ßm trong tay m·ªôt thanh ki·∫øm b·∫°c d√†i g·∫ßn ba th∆∞·ªõc. M√°i t√≥c n√†ng d√†i ƒë·∫øn eo, ƒë∆∞·ª£c c·ªôt b·∫±ng d√¢y l·ª•a tr·∫Øng. D∆∞·ªõi l·ªõp khƒÉn che m·ªèng, √°nh m·∫Øt n√†ng nh∆∞ s∆∞∆°ng tuy·∫øt ngh√¨n nƒÉm, l·∫∑ng l·∫Ω v√† s·∫Øc b√©n nh∆∞ ki·∫øm ƒë√£ r√∫t kh·ªèi v·ªè.\nL·ª•c Tuy·∫øt K·ª≥ ‚Äì ƒë·ªá t·ª≠ ch√¢n truy·ªÅn Thanh V√¢n M√¥n, Ki·∫øm T√¢m kh√¥ng dao ƒë·ªông, l√† m·ªôt trong b·ªën ng∆∞·ªùi ƒë∆∞·ª£c truy·ªÅn th·ª• ki·∫øm ƒë·∫°o t·ªëi cao c·ªßa t√¥ng m√¥n.\nƒê·ªëi di·ªán n√†ng l√† m·ªôt thi·∫øu n·ªØ trong b·ªô c·∫ßm y t√≠m nh·∫°t, b√™n h√¥ng mang m·ªôt ·ªëng tr√∫c xanh. M·ªói b∆∞·ªõc ƒëi c·ªßa n√†ng nh·∫π nh∆∞ ti·∫øng gi√≥ l∆∞·ªõt qua l√° tr√∫c, m∆° h·ªì nh∆∞ m·ªông. ƒê√¥i m·∫Øt n√†ng nh∆∞ ƒëang c∆∞·ªùi, nh∆∞ng trong n·ª• c∆∞·ªùi ·∫•y l·∫°i ch·ª©a ch√∫t bu·ªìn ch·∫≥ng th·ªÉ n√≥i th√†nh l·ªùi.\nLi·ªÖu Nh∆∞ Y√™n ‚Äì truy·ªÅn nh√¢n duy nh·∫•t c·ªßa C·∫ßm M·ªông C·ªëc, n·ªïi danh v·ªõi c·∫ßm ƒë·∫°o c√≥ th·ªÉ h√≥a t√¢m, th·ª©c t·ªânh linh tr√≠, ch·∫ø ng·ª± t√† ni·ªám.\nHai ng∆∞·ªùi ƒë·ªÅu ƒë·∫øn n∆°i n√†y ‚Äì v√¨ m·ªôt l√Ω do.\nM·ªôt ng∆∞·ªùi ƒë·ªÉ t√¨m linh v·∫≠t Huy·∫øt T√¢m H√†n Li√™n, mong c·ª©u m·ªôt sinh m·ªánh ƒëang h·∫•p h·ªëi. M·ªôt ng∆∞·ªùi v√¨ linh tr·∫≠n c·ªï t√¥ng, c≈©ng l√† ƒë·ªÉ tr·∫£ l·∫°i m·ªôt m·ªëi nghi ho·∫∑c ƒë√£ ƒë√® n·∫∑ng trong l√≤ng nhi·ªÅu nƒÉm.\nV√† c·∫£ hai\u0026hellip; ƒë·ªÅu v√¨ m·ªôt c√°i t√™n.\nDi·ªáp Th·∫ßn.\nCh√†ng t·ª´ng l√† s∆∞ huynh c·ªßa Tuy·∫øt K·ª≥, l√† ng∆∞·ªùi n√†ng ng∆∞·ª°ng m·ªô, c≈©ng l√† k·∫ª ph·∫£n b·ªôi m√¥n quy nƒÉm nƒÉm tr∆∞·ªõc, b·ªã Thanh V√¢n M√¥n truy s√°t. Ch√†ng c≈©ng l√† ng∆∞·ªùi t·ª´ng c·ª©u m·∫°ng Nh∆∞ Y√™n trong chuy·∫øn chu du nƒÉm ·∫•y, ƒë·ªÉ l·∫°i kh√∫c ‚ÄúPhong Tuy·∫øt H√†nh‚Äù khi·∫øn n√†ng kh·∫Øc c·ªët ghi t√¢m.\nM√† gi·ªù ƒë√¢y, ch√†ng ƒëang c·∫≠n k·ªÅ sinh t·ª≠ ‚Äì b·ªüi Ma H·ªèa T√¢m Ch√∫ ph·∫£n ph·ªá, n·∫øu kh√¥ng c√≥ Huy·∫øt T√¢m H√†n Li√™n, ch·∫Øc ch·∫Øn h·ªìn phi ph√°ch t√°n.\nTr·∫≠n ph√°p gi·ªØa r·ª´ng tr√∫c b·∫Øt ƒë·∫ßu kh·ªüi ƒë·ªông. D∆∞·ªõi ƒë·∫•t, c√°c ph√π vƒÉn ph√°t s√°ng ƒë·ªè nh∆∞ m√°u, t·ª´ng c·ªôt s√°ng b·∫Øn th·∫≥ng l√™n kh√¥ng trung, h√¨nh th√†nh m·ªôt v√≤ng linh tr·∫≠n bao ph·ªß kh·∫Øp ng·ªçn ƒë·ªìi.\n‚ÄúNg∆∞∆°i c≈©ng v√¨ h·∫Øn m√† ƒë·∫øn?‚Äù ‚Äì Li·ªÖu Nh∆∞ Y√™n l√™n ti·∫øng tr∆∞·ªõc, gi·ªçng nh·∫π nh∆∞ gi√≥ tuy·∫øt.\nL·ª•c Tuy·∫øt K·ª≥ kh√¥ng ƒë√°p. √Ånh m·∫Øt n√†ng nh√¨n v√†o t√¢m tr·∫≠n, n∆°i hoa sen m√°u v·∫´n ch∆∞a hi·ªán h√¨nh, nh∆∞ ƒëang c·ªë che gi·∫•u ƒëi·ªÅu g√¨ trong √°nh nh√¨n b√¨nh tƒ©nh ·∫•y.\n‚ÄúTa kh√¥ng tr√°ch ng∆∞∆°i.‚Äù ‚Äì Nh∆∞ Y√™n l·∫°i n√≥i, ‚ÄúNƒÉm ƒë√≥‚Ä¶ ai trong ch√∫ng ta c≈©ng kh√¥ng ƒë·ªß d≈©ng kh√≠.‚Äù\nTuy·∫øt K·ª≥ kh·∫Ω si·∫øt tay c·∫ßm ki·∫øm.\nNƒÉm nƒÉm tr∆∞·ªõc, khi Di·ªáp Th·∫ßn b·ªã nghi ng·ªù tu luy·ªán ma ph√°p, n√†ng l√† ng∆∞·ªùi ƒë∆∞·ª£c ph√°i ƒë·∫øn ƒë·ªÉ tra x√©t. Nh∆∞ng l√∫c ƒë·ªëi m·∫∑t, n√†ng kh√¥ng gi·∫øt ch√†ng ‚Äì c≈©ng kh√¥ng b·∫£o v·ªá ch√†ng. N√†ng ch·ªâ ƒë·ª©ng nh√¨n, ƒë·ªÉ m·∫∑c s∆∞ huynh kh√°c ra tay, ƒë·ªÉ m·∫∑c ch√†ng r∆°i xu·ªëng v·ª±c s√¢u.\nNg√†y ƒë√≥, n√†ng t∆∞·ªüng m√¨nh ƒë√£ ch·∫∑t ƒë·ª©t ƒë∆∞·ª£c m·ªçi t∆° v∆∞∆°ng.\nNh∆∞ng ƒë√™m qua, khi Nh∆∞ Y√™n t√¨m ƒë·∫øn, n√≥i r·∫±ng ch√†ng v·∫´n s·ªëng, v√† ƒëang h·∫•p h·ªëi‚Ä¶ l√≤ng n√†ng l·∫°i rung l√™n m·ªôt nh·ªãp ‚Äì nh∆∞ ti·∫øng ki·∫øm ch·∫•n ƒë·ªông trong v·ªè ki·∫øm l·∫°nh.\n·∫¶m!\nLinh tr·∫≠n ph√°t ra √¢m thanh tr·∫ßm ƒë·ª•c. D∆∞·ªõi m·∫∑t ƒë·∫•t, m·ªôt ƒëo√° sen ƒë·ªè r·ª±c t·ª´ t·ª´ tr·ªìi l√™n gi·ªØa t√¢m tr·∫≠n ‚Äì Huy·∫øt T√¢m H√†n Li√™n.\nN√≥ ƒë·∫πp ƒë·∫øn m√™ h·ªìn, m·ªói c√°nh hoa nh∆∞ ƒë∆∞·ª£c ƒëi√™u kh·∫Øc t·ª´ m√°u ng·ªçc, t·ªèa ra h√†n kh√≠ l·∫° l√πng.\nNh∆∞ng v·ª´a khi hai ng∆∞·ªùi ƒë·ªãnh b∆∞·ªõc v√†o, m·ªôt ·∫£o ·∫£nh ƒë·ªôt nhi√™n hi·ªán ra ‚Äì T√¢m Ma Gi·ªõi kh·ªüi ƒë·ªông!\nKhung c·∫£nh thay ƒë·ªïi ngay l·∫≠p t·ª©c.\nTuy·∫øt K·ª≥ th·∫•y m√¨nh ƒë·ª©ng gi·ªØa s√¢n luy·ªán ki·∫øm Thanh V√¢n. Di·ªáp Th·∫ßn quay ƒë·∫ßu l·∫°i nh√¨n n√†ng, √°nh m·∫Øt ƒë·∫ßy th·∫•t v·ªçng.\n‚ÄúN·∫øu nƒÉm ƒë√≥ ng∆∞∆°i tin ta m·ªôt c√¢u, ta ƒë√£ kh√¥ng r∆°i v√†o ma ƒë·∫°o.‚Äù\nN√†ng ƒë∆∞a tay ra, nh∆∞ng ch·ªâ ch·∫°m v√†o h∆∞ kh√¥ng.\nC√≤n Li·ªÖu Nh∆∞ Y√™n, trong ·∫£o ·∫£nh, th·∫•y Di·ªáp Th·∫ßn m·ªâm c∆∞·ªùi, r·ªìi xoay ng∆∞·ªùi r·ªùi ƒëi.\n‚ÄúN√†ng l√† ng∆∞·ªùi duy nh·∫•t khi·∫øn ta mu·ªën s·ªëng ti·∫øp. Nh∆∞ng\u0026hellip; ta kh√¥ng x·ª©ng.‚Äù\nM·ªôt kh√∫c nh·∫°c c·∫ßm vang l√™n gi·ªØa h∆∞ kh√¥ng, n√†ng b·∫≠t kh√≥c trong c·∫£nh gi·ªõi m·ªông ·∫£o.\nKhi hai ng∆∞·ªùi c√πng ph√° v·ª° ƒë∆∞·ª£c t√¢m ma, ·∫£o c·∫£nh tan bi·∫øn, c≈©ng l√† l√∫c Huy·∫øt T√¢m H√†n Li√™n n·ªü r·ªô.\n‚ÄúLinh v·∫≠t ch·ªâ c√≥ m·ªôt,‚Äù ‚Äì Nh∆∞ Y√™n n√≥i kh·∫Ω, ‚ÄúCh√∫ng ta\u0026hellip; kh√¥ng th·ªÉ chia.‚Äù\nTuy·∫øt K·ª≥ c√∫i ƒë·∫ßu nh√¨n ƒëo√° hoa trong tay, h·ªìi l√¢u m·ªõi ƒë√°p:\n‚ÄúTa kh√¥ng th·ªÉ c·ª©u h·∫Øn m·ªôt m√¨nh.‚Äù\nNh∆∞ Y√™n m·ªâm c∆∞·ªùi, nghi√™ng ƒë·∫ßu nh√¨n n√†ng:\n‚ÄúV·∫≠y th√¨\u0026hellip; c√πng nhau ƒëi.‚Äù\nTuy·∫øt K·ª≥ kh·∫Ω g·∫≠t ƒë·∫ßu.\nTuy·∫øt v·∫´n r∆°i, nh∆∞ng gi·ªØa r·ª´ng tr√∫c, ƒë√£ c√≥ hai b√≥ng ng∆∞·ªùi c√πng s√≥ng vai.\nV√¨ m·ªôt ng∆∞·ªùi. V√¨ m·ªôt t√≠n ni·ªám x∆∞a c≈©. V√† v√¨ m·ªôt con ƒë∆∞·ªùng ‚Äì m√† t·ª´ h√¥m nay, c·∫£ hai ƒë·ªÅu kh√¥ng th·ªÉ quay ƒë·∫ßu.\nCh∆∞∆°ng 2 ‚Äì T√¢m Ma K√Ω ·ª®c B√™n d∆∞·ªõi Tuy·∫øt Gi√°c s∆°n, m·ªôt hang ƒë·ªông nh·ªè ch√¨m trong √°nh lam nh·∫°t c·ªßa bƒÉng tinh, t·ª´ng gi·ªçt n∆∞·ªõc nh·ªè xu·ªëng, vang v·ªçng nh∆∞ ti·∫øng ƒë√†n ƒë√° l·∫∑ng l·∫Ω ng√¢n vang.\nDi·ªáp Th·∫ßn n·∫±m b·∫•t ƒë·ªông tr√™n m·ªôt b·ªá ng·ªçc h√†n th·∫°ch, s·∫Øc m·∫∑t t√°i nh·ª£t, mi t√¢m ·∫©n hi·ªán h·∫Øc ph√π l·∫•p l√°nh. H∆°i th·ªü y·∫øu ·ªõt nh∆∞ s·∫Øp t·∫Øt.\nLi·ªÖu Nh∆∞ Y√™n ng·ªìi b√™n c·∫°nh, tay ƒë·∫∑t l√™n ƒë√†n ng·ªçc xanh l·ª•c. M·ªôt b·∫£n c·∫ßm kh√∫c d·ªãu d√†ng vang l√™n, d·∫´n d·∫Øt linh kh√≠ nh·∫≠p th·ªÉ cho Di·ªáp Th·∫ßn. M·ªói n·ªët ƒë√†n l√† m·ªôt ƒë·∫°o c·∫ßm √Ω, h√≤a v√†o h∆∞ kh√¥ng, gi·ªØ l·∫•y h·ªìn ph√°ch Di·ªáp Th·∫ßn kh·ªèi tan bi·∫øn.\nL·ª•c Tuy·∫øt K·ª≥ ƒë·ª©ng xa h∆°n, tay v·∫´n gi·ªØ l·∫•y Huy·∫øt T√¢m H√†n Li√™n ch∆∞a giao ra.\nN√†ng ƒëang do d·ª±.\nN·∫øu d√πng linh v·∫≠t n√†y‚Ä¶ ch√≠nh l√† k·∫øt n·ªëi sinh m·ªánh b·∫£n th√¢n v·ªõi Di·ªáp Th·∫ßn. M·ªôt ph·∫ßn h·ªìn l·ª±c s·∫Ω vƒ©nh vi·ªÖn b·ªã phong ·∫•n ƒë·ªÉ gi·ªØ m·∫°ng cho ng∆∞·ªùi kia.\nKh√¥ng ch·ªâ l√† m·ªôt l·∫ßn c·ª©u ‚Äì m√† l√† r√†ng bu·ªôc gi·ªØa hai sinh m·ªánh.\nN√†ng xi·∫øt ch·∫∑t b√†n tay.\nH√¨nh ·∫£nh trong T√¢m Ma Gi·ªõi v·∫´n c√≤n ƒë√≥. Gi·ªçng n√≥i Di·ªáp Th·∫ßn nh∆∞ dao c·ª©a trong tim n√†ng.\n‚ÄúN·∫øu nƒÉm ƒë√≥ ng∆∞∆°i tin ta m·ªôt c√¢u, ta ƒë√£ kh√¥ng r∆°i v√†o ma ƒë·∫°o.‚Äù\nN√†ng mu·ªën n√≥i r·∫±ng\u0026hellip; n√†ng ƒë√£ tin. Nh∆∞ng n√†ng kh√¥ng ƒë·ªß can ƒë·∫£m. Thanh V√¢n M√¥n l√† t√≠n ng∆∞·ª°ng c·∫£ ƒë·ªùi n√†ng, l√†m sao n√†ng d√°m nghi√™ng l√≤ng v·ªÅ m·ªôt k·∫ª b·ªã xem l√† ph·∫£n ƒë·ªì?\nNh∆∞ Y√™n nh·∫π nh√†ng n√≥i:\n‚ÄúTa s·∫Ω d√πng ƒë√†n gi·ªØ h·ªìn. Nh∆∞ng n·∫øu mu·ªën c·ª©u th·∫≠t, c·∫ßn c√≥ linh v·∫≠t h·ª£p m·ªánh.‚Äù\nTuy·∫øt K·ª≥ kh√¥ng ƒë√°p, ch·∫≠m r√£i b∆∞·ªõc t·ªõi. Tay n√†ng ƒë·∫∑t l√™n mi t√¢m Di·ªáp Th·∫ßn. Trong ph√∫t ch·ªëc, hai lu·ªìng kh√≠ t·ª©c va ch·∫°m ‚Äì m·ªôt l·∫°nh nh∆∞ bƒÉng tuy·∫øt, m·ªôt h·ªón lo·∫°n √¢m d∆∞∆°ng.\n‚ÄúTa kh√¥ng tin‚Ä¶ huynh l√† ng∆∞·ªùi h·∫°i s∆∞ huynh Tr√°c D∆∞∆°ng.‚Äù ‚Äì n√†ng th√¨ th·∫ßm, ‚ÄúNh∆∞ng huynh kh√¥ng gi·∫£i th√≠ch.‚Äù\n√Ånh s√°ng t·ª´ Huy·∫øt T√¢m H√†n Li√™n t·ª´ t·ª´ nh·∫≠p th·ªÉ v√†o Di·ªáp Th·∫ßn. C√°nh hoa r·∫°n n·ª©t t·ª´ng ch√∫t, t·ª´ng c√°nh r∆°i xu·ªëng, h√≥a th√†nh tinh linh r·ª±c ƒë·ªè nh·∫≠p v√†o m·∫°ch kh√≠.\nGi√≥ th·ªïi qua. Kh√¥ng c√≤n l√† gi√≥ l·∫°nh Tuy·∫øt Gi√°c ‚Äì m√† l√† ti·∫øng th√¨ th·∫ßm nh∆∞ v·ªçng t·ª´ nƒÉm x∆∞a.\nNƒÉm nƒÉm tr∆∞·ªõc.\nT·∫°i Thanh V√¢n S∆°n, ng√†y Di·ªáp Th·∫ßn b·ªã truy s√°t, tr·ªùi c≈©ng ƒë·ªï tuy·∫øt.\nTuy·∫øt K·ª≥ khi ·∫•y ch·ªâ ƒë·ª©ng b√™n v√°ch n√∫i, nh√¨n ng∆∞·ªùi s∆∞ huynh t·ª´ng d·∫°y n√†ng ki·∫øm ph√°p qu·ª≥ g·ªëi, m·ªôt th√¢n m√°u t∆∞∆°i, tr∆∞·ªõc m·∫∑t c√°c tr∆∞·ªüng l√£o.\nTr√°c D∆∞∆°ng ‚Äì s∆∞ huynh c·ªßa h·ªç ‚Äì ƒë√£ ch·∫øt, ph√°p b·∫£o b·ªã h·ªßy. M·ªçi ch·ª©ng c·ª© ƒë·ªÅu ch·ªâ v·ªÅ Di·ªáp Th·∫ßn.\n‚ÄúTa kh√¥ng gi·∫øt h·∫Øn.‚Äù ‚Äì Di·ªáp Th·∫ßn ch·ªâ n√≥i m·ªôt c√¢u.\nNh∆∞ng kh√¥ng ai tin.\nTuy·∫øt K·ª≥ kh√¥ng b∆∞·ªõc ra. N√†ng ch·ªâ n·∫Øm ch·∫∑t thanh ki·∫øm b√™n h√¥ng, nh√¨n theo b√≥ng ng∆∞·ªùi r∆°i xu·ªëng v·ª±c s√¢u gi·ªØa tr·ªùi tuy·∫øt tr·∫Øng.\nN·ªói s·ª£ khi ƒë√≥ kh√¥ng ph·∫£i v√¨ Di·ªáp Th·∫ßn ‚Äì m√† v√¨ b·∫£n th√¢n n√†ng. S·ª£ r·∫±ng n·∫øu n√†ng l√™n ti·∫øng, n√†ng s·∫Ω b·ªã t√¥ng m√¥n xem l√† ph·∫£n b·ªôi.\nSau n√†y, n√†ng kh√¥ng d√°m c·∫ßm l·∫°i thanh ki·∫øm ng√†y ·∫•y.\nLinh l·ª±c trong c∆° th·ªÉ Di·ªáp Th·∫ßn d·∫ßn ·ªïn ƒë·ªãnh. H·∫Øc ph√π tr√™n tr√°n tan ƒëi, thay v√†o ƒë√≥ l√† m·ªôt v·∫ßng s√°ng ƒë·ªè nh·∫°t ƒëang ƒë·∫≠p nh∆∞ nh·ªãp tim.\n‚Äúƒê√£ k·∫øt n·ªëi linh m·∫°ch.‚Äù ‚Äì Nh∆∞ Y√™n th·ªü nh·∫π. ‚ÄúGi·ªù\u0026hellip; ch·ªâ c√≤n ch·ªù h·∫Øn t·ªânh l·∫°i.‚Äù\nTuy·∫øt K·ª≥ quay ƒëi, ƒë·ª©ng nh√¨n ra tuy·∫øt tr·∫Øng.\nGi√≥ th·ªïi tung d·∫£i l·ª•a tr√™n t√≥c n√†ng. Trong l√≤ng, m·ªôt tia √°y n√°y kh√¥ng t√™n d·∫ßn k·∫øt th√†nh h·∫°t bƒÉng nh·ªè ‚Äì nh∆∞ng c≈©ng l·∫∑ng l·∫Ω tan ch·∫£y.\n·ªû ph√≠a sau, Nh∆∞ Y√™n ch·ª£t c·∫•t ti·∫øng:\n‚ÄúC√¥ ƒë√£ t·ª´ng th√≠ch h·∫Øn, ƒë√∫ng kh√¥ng?‚Äù\nTuy·∫øt K·ª≥ kh·ª±ng l·∫°i.\n‚ÄúTa kh√¥ng r√µ ƒë√≥ c√≥ g·ªçi l√† ‚Äòth√≠ch‚Äô kh√¥ng.‚Äù ‚Äì n√†ng ƒë√°p, ‚ÄúNh∆∞ng ta n·ª£ h·∫Øn m·ªôt l·ªùi xin l·ªói.‚Äù\n‚ÄúV·∫≠y‚Ä¶ n·∫øu l·∫ßn n√†y h·∫Øn t·ªânh l·∫°i, c√¥ c√≥ ƒë·ªãnh b√π ƒë·∫Øp kh√¥ng?‚Äù ‚Äì Nh∆∞ Y√™n c∆∞·ªùi nh·∫π, nh∆∞ng trong m·∫Øt n√†ng l√† th·ª© √°nh s√°ng r·∫•t kh√≥ ph√¢n ƒë·ªãnh gi·ªØa d·ªãu d√†ng v√† ki√™n quy·∫øt.\nTuy·∫øt K·ª≥ kh√¥ng ƒë√°p.\nN√†ng ch·ªâ nh√¨n tuy·∫øt r∆°i, l√≤ng th·∫ßm nghƒ©:\nN·∫øu Di·ªáp Th·∫ßn t·ªânh l·∫°i‚Ä¶ ta s·∫Ω kh√¥ng im l·∫∑ng nh∆∞ nƒÉm x∆∞a n·ªØa.\n·ªû b·ªá ng·ªçc, mi m·∫Øt Di·ªáp Th·∫ßn kh·∫Ω ƒë·ªông.\nM·ªôt l√†n kh√≠ ƒë·ªè nh·∫°t t·ªèa ra t·ª´ tim ch√†ng, dung h·ª£p gi·ªØa bƒÉng h√†n c·ªßa Tuy·∫øt K·ª≥ v√† t·ªãnh √¢m c·ªßa c·∫ßm ƒë·∫°o Nh∆∞ Y√™n.\nCh√†ng s·∫Øp t·ªânh.\nNh∆∞ng\u0026hellip; c≈©ng ƒë√∫ng l√∫c ·∫•y, trong s√¢u th·∫≥m linh h·ªìn Di·ªáp Th·∫ßn, m·ªôt gi·ªçng n√≥i vang l√™n:\n‚ÄúNg∆∞∆°i t∆∞·ªüng tho√°t r·ªìi sao? Ngo·∫°i V·ª±c v·∫´n ƒëang nh√¨n ng∆∞∆°i. V√† khi ng∆∞∆°i m·ªü m·∫Øt\u0026hellip; m·ªçi th·ª© m·ªõi ch·ªâ b·∫Øt ƒë·∫ßu.‚Äù\nCh∆∞∆°ng 3 ‚Äì Huy·∫øt T√¢m Li√™n Hoa √Ånh l·ª≠a h·ªìng nh√†n nh·∫°t l·∫•p l√≥e trong h√†n ƒë·ªông nh∆∞ m·∫°ch m√°u ƒëang ƒë·∫≠p gi·ªØa l√≤ng bƒÉng tuy·∫øt.\nDi·ªáp Th·∫ßn m·ªü m·∫Øt.\nM·∫Øt ch√†ng v·ªën ƒëen tuy·ªÅn, nh∆∞ng gi·ªù ƒë√¢y b√™n trong ·∫©n hi·ªán m·ªôt v·ªát ƒë·ªè m∆° h·ªì ‚Äì t√†n d∆∞ c·ªßa Ma H·ªèa T√¢m Ch√∫, nh∆∞ng l·∫°i tr·∫ßm ·ªïn ƒë·∫øn k·ª≥ l·∫°, kh√¥ng c√≤n cu·ªìng lo·∫°n nh∆∞ tr∆∞·ªõc.\nC·∫£m gi√°c ƒë·∫ßu ti√™n l√†\u0026hellip; l·∫°nh. L·∫°nh t·ª´ x∆∞∆°ng t·ªßy.\nSau ƒë√≥ l√†\u0026hellip; √¢m thanh.\nM·ªôt kh√∫c c·∫ßm nh·∫π nh√†ng v·ªó v·ªÅ t√¢m tr√≠, t·ª´ng n·ªët nh∆∞ xoa d·ªãu linh h·ªìn r√°ch n√°t c·ªßa ch√†ng, d·∫´n l·ªëi ch√†ng t·ª´ b√≥ng t·ªëi quay l·∫°i th·ª±c t·∫°i.\nDi·ªáp Th·∫ßn nh√¨n quanh, kh·∫Ω c·ª±a m√¨nh. √Ånh m·∫Øt m∆° h·ªì d·∫ßn r√µ r√†ng ‚Äì v√† r·ªìi\u0026hellip; √°nh m·∫Øt ·∫•y d·ª´ng l·∫°i.\nL√† n√†ng.\nLi·ªÖu Nh∆∞ Y√™n.\nT√≥c n√†ng r·ªëi nh·∫π v√¨ gi√≥ trong ƒë·ªông, ng√≥n tay v·∫´n ƒë·∫∑t tr√™n d√¢y ƒë√†n. Khi √°nh m·∫Øt h·ªç ch·∫°m nhau, n√†ng kh·∫Ω c∆∞·ªùi.\n‚ÄúCh√†ng t·ªânh r·ªìi.‚Äù\nCh√†ng ch∆∞a k·ªãp ƒë√°p l·ªùi, th√¨ m·ªôt gi·ªçng kh√°c vang l√™n ‚Äì l·∫°nh v√† s·∫Øc nh∆∞ ki·∫øm:\n‚ÄúNg∆∞∆°i\u0026hellip; c√≤n nh·ªõ ta kh√¥ng?‚Äù\nDi·ªáp Th·∫ßn quay sang, nh√¨n th·∫•y L·ª•c Tuy·∫øt K·ª≥. N√†ng ƒë·ª©ng ƒë√≥, √°nh m·∫Øt l·∫°nh l√πng, nh∆∞ng b√™n trong gi·∫•u m·ªôt tia ch·∫•n ƒë·ªông kh√¥ng th·ªÉ che gi·∫•u.\nC·∫£ hai ƒë·ªÅu im l·∫∑ng m·ªôt l√∫c.\nR·ªìi Di·ªáp Th·∫ßn c·∫•t gi·ªçng, kh√†n kh√†n:\n‚ÄúKh√¥ng nghƒ©\u0026hellip; c√≤n c√≥ th·ªÉ th·∫•y c√°c ng∆∞∆°i.‚Äù\nGi·ªçng n√≥i kh√¥ng o√°n h·∫≠n, c≈©ng kh√¥ng d·ªãu d√†ng. Ch·ªâ nh∆∞ m·ªôt k·∫ª t·ª´ng ch·∫øt ƒëi m·ªôt l·∫ßn, gi·ªù quay v·ªÅ, ch·∫≥ng c√≤n tha thi·∫øt truy c·ª©u qu√° kh·ª©.\nTuy·∫øt K·ª≥ nh√≠u m√†y.\nNh∆∞ Y√™n nh·∫π nh√†ng ti·∫øp l·ªùi:\n‚ÄúCh√∫ng ta t√¨m th·∫•y Huy·∫øt T√¢m H√†n Li√™n, c·ª©u ƒë∆∞·ª£c ch√†ng\u0026hellip; nh∆∞ng ch·ªâ l√† t·∫°m th·ªùi. H·ªèa ch√∫ trong t√¢m m·∫°ch c·ªßa ch√†ng v·∫´n ch∆∞a ho√†n to√†n b·ªã √©p lui.‚Äù\nDi·ªáp Th·∫ßn tr·∫ßm m·∫∑c, r·ªìi ng·ªìi d·∫≠y, d·ª±a l∆∞ng v√†o b·ªá ng·ªçc. M√°i t√≥c ƒëen d√†i r≈© xu·ªëng, ch√†ng nh√¨n v√†o l√≤ng b√†n tay m√¨nh ‚Äì n∆°i c√≥ m·ªôt v·∫øt ƒë·ªè nh·∫°t v·∫´n c√≤n ƒëang ch·ªõp ƒë·ªông.\n‚ÄúV·∫≠y l√†\u0026hellip; ta v·∫´n ch∆∞a tr·ªën kh·ªèi ƒë∆∞·ª£c n√≥.‚Äù\nTuy·∫øt K·ª≥ h·ªèi, ‚ÄúN√≥ l√† g√¨?‚Äù\nDi·ªáp Th·∫ßn ch·∫≠m r√£i ƒë√°p:\n‚ÄúKh√¥ng ph·∫£i ma ph√°p. C≈©ng kh√¥ng ph·∫£i t√† thu·∫≠t. ƒê√≥ l√† k·∫øt ·∫•n t·ª´ Ngo·∫°i V·ª±c.‚Äù\nC√¢u n√≥i nh∆∞ s√©t ƒë√°nh ngang tai.\nLi·ªÖu Nh∆∞ Y√™n bi·∫øn s·∫Øc.\n‚ÄúNgo·∫°i V·ª±c?\u0026hellip; L·∫Ω n√†o l√†\u0026hellip; v·ª±c ngo·∫°i ch√¢n ma trong truy·ªÅn thuy·∫øt?‚Äù ‚Äì n√†ng h·ªèi.\nDi·ªáp Th·∫ßn g·∫≠t ƒë·∫ßu.\n‚ÄúNƒÉm ƒë√≥ ta kh√¥ng ph·∫£n b·ªôi Tr√°c D∆∞∆°ng. L√† h·∫Øn, v√¨ t√¨m ki·∫øm b√≠ thu·∫≠t ƒë·ªÉ tƒÉng tu vi, ƒë√£ m·ªü ra m·ªôt khe n·ª©t linh h·ªìn, d·∫´n linh th·ª©c c·ªßa Ngo·∫°i V·ª±c x√¢m nh·∫≠p. Ta ngƒÉn kh√¥ng k·ªãp. Tr∆∞·ªõc khi ch·∫øt, h·∫Øn ƒë√£ c·∫•y m·∫ßm h·ªèa ·∫•n v√†o ta, mu·ªën k√©o ta c√πng xu·ªëng ƒë·ªãa ng·ª•c.‚Äù\n√Ånh m·∫Øt Tuy·∫øt K·ª≥ run l√™n. M√¥i n√†ng kh·∫Ω m√≠m l·∫°i.\n‚ÄúV√¨ sao\u0026hellip; l√∫c ƒë√≥ kh√¥ng n√≥i?‚Äù\nDi·ªáp Th·∫ßn c∆∞·ªùi nh·∫°t.\n‚ÄúN√≥i? C√°c ng∆∞∆°i c√≥ ai tin? Ngay c·∫£ n√†ng\u0026hellip; c≈©ng kh√¥ng b∆∞·ªõc ra.‚Äù\nC√¢u n√≥i ·∫•y kh√¥ng n·∫∑ng gi·ªçng, nh∆∞ng m·ªói ch·ªØ nh∆∞ ch√¢m l·ª≠a trong tim Tuy·∫øt K·ª≥. N√†ng quay m·∫∑t ƒëi, kh√¥ng ƒë√°p.\nNh∆∞ Y√™n d·ªãu gi·ªçng h·ªèi:\n‚ÄúV·∫≠y b√¢y gi·ªù th√¨ sao? K·∫øt ·∫•n ·∫•y‚Ä¶ c√≤n t·ªìn t·∫°i trong t√¢m m·∫°ch, li·ªáu c√≥ b·ªôc ph√°t l·∫ßn n·ªØa?‚Äù\nDi·ªáp Th·∫ßn tr·∫ßm ng√¢m.\n‚ÄúN·∫øu ƒë·ªÉ m·∫∑c, sau ba nƒÉm\u0026hellip; ta s·∫Ω tr·ªü th√†nh v·∫≠t d·∫´n cho √Ω ch√≠ Ngo·∫°i V·ª±c. Kh√¥ng c√≤n l√† ta n·ªØa.‚Äù\nL·∫∑ng im bao tr√πm.\nBa ng∆∞·ªùi, m·ªói ng∆∞·ªùi mang theo m·ªôt t√¢m s·ª±, gi·ªù ph·∫£i c√πng ƒë·ªëi di·ªán v·ªõi tai h·ªça l·ªõn h∆°n h·ªç t·ª´ng t∆∞·ªüng t∆∞·ª£ng.\nR·ªìi b·∫•t ng·ªù ‚Äì ·∫¶m!\nC·∫£ s∆°n ƒë·ªông rung chuy·ªÉn.\nM·ªôt ƒë·∫°o kh√≠ t·ª©c kh·ªïng l·ªì t·ª´ b√™n ngo√†i √°p xu·ªëng. Tuy·∫øt r∆°i d·ªìn d·∫≠p nh∆∞ b·ªã th·ª© g√¨ qu√©t qua. T·ª´ s√¢u trong r·ª´ng tr√∫c, m·ªôt b√≥ng ƒëen kh·ªïng l·ªì ƒëang t·ª´ t·ª´ ti·∫øn ƒë·∫øn ‚Äì Kim ƒêan y√™u th√∫ ‚Äì Tuy·∫øt Giao!\n‚ÄúL√† do linh kh√≠ Huy·∫øt T√¢m H√†n Li√™n h·∫•p d·∫´n!‚Äù ‚Äì Di·ªáp Th·∫ßn kh·∫Ω r√≠t.\nTuy·∫øt K·ª≥ r√∫t ki·∫øm, √°nh s√°ng b·∫°c r·ª±c l√™n nh∆∞ s·∫•m ch·ªõp gi·ªØa ƒë√™m tuy·∫øt. Nh∆∞ Y√™n v·ªôi ƒë·∫∑t ƒë√†n tr∆∞·ªõc m·∫∑t, chu·∫©n b·ªã th·ªß c·∫ßm tr·∫≠n.\nDi·ªáp Th·∫ßn nh·∫Øm m·∫Øt, th√∫c ƒë·∫©y linh l·ª±c c√≤n l·∫°i ‚Äì nh∆∞ng kh√≠ m·∫°ch ch∆∞a th√¥ng ho√†n to√†n, h·ªèa ·∫•n l·∫°i b·∫Øt ƒë·∫ßu r·ª•c r·ªãch.\nBa ng∆∞·ªùi ‚Äì gi·ªù ƒë√¢y ph·∫£i c√πng chi·∫øn ƒë·∫•u.\nKh√¥ng ph·∫£i v√¨ th√π, kh√¥ng v√¨ qu√° kh·ª©. M√† v√¨\u0026hellip; t·∫•t c·∫£ ƒë·ªÅu ƒë·ª©ng tr∆∞·ªõc m·ªôt hi·ªÉm h·ªça chung.\nV√† ƒë√≥\u0026hellip; l√† b∆∞·ªõc ƒë·∫ßu ti√™n, ƒë√°nh d·∫•u s·ª± tr·ªü l·∫°i c·ªßa Di·ªáp Th·∫ßn, k·∫ª mang trong m√¨nh m·ªôt ph·∫ßn √Ω ch√≠ c·ªßa Ngo·∫°i V·ª±c ‚Äì nh∆∞ng l·∫°i ƒë·ª©ng ·ªü l·∫±n ranh gi·ªØa th√°nh nh√¢n v√† ma ch·ªß t∆∞∆°ng lai.\nCh∆∞∆°ng 4 ‚Äì Tuy·∫øt Giao Chi·∫øn Tuy·∫øt v·∫´n kh√¥ng ng·ª´ng r∆°i, nh∆∞ng kh√¥ng gian trong s∆°n ƒë·ªông l√∫c n√†y l·∫°i tr·ªü n√™n ng·ªôt ng·∫°t. Linh kh√≠ xung quanh ƒëang b·ªã x√© r√°ch b·ªüi m·ªôt lu·ªìng s·ª©c m·∫°nh kh·ªßng khi·∫øp, kh√¥ng ph·∫£i t·ª´ ƒë·∫•t tr·ªùi, m√† t·ª´ ch√≠nh trong Tuy·∫øt Giao ‚Äì m·ªôt y√™u th√∫ ƒë√£ ƒë·∫°t ƒë·∫øn c·∫£nh gi·ªõi Kim ƒêan, kh√≠ t·ª©c m·∫°nh m·∫Ω nh∆∞ cu·ªìng phong.\nT·ª´ng b∆∞·ªõc ch√¢n c·ªßa n√≥ vang v·ªçng, m·∫°nh m·∫Ω v√† cu·ªìng lo·∫°n. ƒê√¥i m·∫Øt ƒë·ªè nh∆∞ m√°u ph√°t ra nh·ªØng tia s√°ng s·∫Øc l·∫°nh, c·∫∑p s·ª´ng cong ƒëen nh√°nh v∆∞∆°n cao nh∆∞ m≈©i ki·∫øm.\n‚ÄúC·∫©n th·∫≠n.‚Äù ‚Äì Tuy·∫øt K·ª≥ n√≥i, m·∫Øt √°nh l√™n v·∫ª nghi√™m t√∫c.\nNh∆∞ Y√™n g·∫≠t ƒë·∫ßu, tay n√†ng k√©o nh·∫π d√¢y ƒë√†n. M·ªôt l√†n s√≥ng nh·∫°c c·∫ßm d·ªãu d√†ng nh∆∞ng ·∫©n ch·ª©a s·ª©c m·∫°nh m√£nh li·ªát lan t·ªèa. N√≥ t·∫°o ra m·ªôt l·ªõp v·ªè b·∫£o v·ªá linh h·ªìn, ngƒÉn ch·∫∑n nh·ªØng s√≥ng √¢m c√≥ th·ªÉ x√¢m nh·∫≠p v√†o t√¢m tr√≠ ba ng∆∞·ªùi.\nDi·ªáp Th·∫ßn, ƒë·ª©ng gi·ªØa, m·∫Øt ch√†ng v·∫´n ch∆∞a ho√†n to√†n t·ªânh t√°o. M·∫∑c d√π linh kh√≠ ƒëang ·ªïn ƒë·ªãnh h∆°n sau khi d√πng Huy·∫øt T√¢m H√†n Li√™n, nh∆∞ng h·ªèa ch√∫ Ngo·∫°i V·ª±c trong c∆° th·ªÉ v·∫´n khi·∫øn linh m·∫°ch c·ªßa ch√†ng kh√¥ng ho√†n to√†n th√¥ng su·ªët. C·∫£m gi√°c nh∆∞ c√≥ ng·ªçn l·ª≠a √¢m ·ªâ trong c∆° th·ªÉ, c·ª© ch√°y m√£i, kh√¥ng d·ª©t.\nTuy·∫øt Giao ti·∫øn l·∫°i g·∫ßn, m·ªói b∆∞·ªõc ƒëi gi·ªëng nh∆∞ m·ªôt c∆°n s√≥ng m·∫°nh x√¥ v√†o b·ªù. Gi√≥ m·∫°nh m·∫Ω xo√°y v√†o kh√¥ng kh√≠, khi·∫øn tuy·∫øt bay cu·ªìn cu·ªôn.\nDi·ªáp Th·∫ßn l·∫∑ng l·∫Ω ƒë·ª©ng ƒë√≥, ƒë√¥i m·∫Øt ƒë·ªè nh·∫°t nh√¨n chƒÉm ch√∫ v√†o y√™u th√∫. M·∫∑c d√π ch∆∞a ho√†n to√†n c√≥ ƒë·ªß s·ª©c m·∫°nh, nh∆∞ng m·ªôt linh c·∫£m k·ª≥ l·∫° d√¢ng l√™n trong l√≤ng h·∫Øn. Ch√†ng kh√¥ng th·ªÉ l√πi b∆∞·ªõc. ƒê√¢y ch√≠nh l√† cu·ªôc chi·∫øn ƒë·ªÉ kh·∫≥ng ƒë·ªãnh l·∫°i b·∫£n th√¢n, ƒë·ªÉ kh√¥ng b·ªã chi ph·ªëi b·ªüi ngo·∫°i l·ª±c.\nTuy·∫øt K·ª≥ r√∫t ki·∫øm, thanh ki·∫øm b·∫°c s√°ng l√™n nh∆∞ √°nh s√°ng c·ªßa trƒÉng r·∫±m. N√†ng lao v·ªÅ ph√≠a Tuy·∫øt Giao v·ªõi t·ªëc ƒë·ªô c·ª±c nhanh, ki·∫øm ph√°p m·∫°nh m·∫Ω v√† s·∫Øc b√©n, m·ªói ƒë√≤n ƒë·ªÅu nh·∫±m v√†o ƒëi·ªÉm y·∫øu c·ªßa y√™u th√∫.\nNh∆∞ Y√™n ƒë·ª©ng ph√≠a sau, tay c·∫ßm ƒë√†n, n√†ng v·∫©y nh·∫π t·ª´ng ng√≥n tay, ph√≥ng ra t·ª´ng ƒë·ª£t s√≥ng √¢m c·ª±c k·ª≥ uy l·ª±c, c·ªë g·∫Øng ngƒÉn c·∫£n b∆∞·ªõc ƒëi c·ªßa y√™u th√∫, khi·∫øn n√≥ lo·∫°ng cho·∫°ng. Tuy nhi√™n, Tuy·∫øt Giao l√† m·ªôt sinh v·∫≠t c·ª±c k·ª≥ c∆∞·ªùng ƒë·∫°i. Nh·ªØng ƒë·ª£t s√≥ng √¢m c·ªßa Nh∆∞ Y√™n ch·ªâ khi·∫øn n√≥ dao ƒë·ªông m·ªôt ch√∫t, nh∆∞ng kh√¥ng h·ªÅ l√†m ch·∫≠m b∆∞·ªõc ti·∫øn c·ªßa n√≥.\nTuy·∫øt K·ª≥ t·∫≠n d·ª•ng c∆° h·ªôi, lao v√†o g·∫ßn h∆°n, thanh ki·∫øm ch√©m th·∫≥ng v√†o th√¢n th·ªÉ c·ªßa y√™u th√∫. Nh∆∞ng Tuy·∫øt Giao ph·∫£n ·ª©ng nhanh ch√≥ng, vung c·∫∑p vu·ªët s·∫Øc nh·ªçn v·ªÅ ph√≠a n√†ng.\nCh·ªâ trong kho·∫£nh kh·∫Øc, m·ªôt tia s√°ng b·∫°c ch·ªõp l√™n. Tuy·∫øt K·ª≥ ƒë√£ n√© tr√°nh k·ªãp th·ªùi, nh∆∞ng c·∫∑p vu·ªët c·ªßa Tuy·∫øt Giao ƒë√£ x√© r√°ch m·ªôt m·∫£ng √°o c·ªßa n√†ng, ƒë·ªÉ l·ªô ra m·ªôt v·∫øt th∆∞∆°ng nh·∫π tr√™n c√°nh tay.\n‚ÄúC·∫©n th·∫≠n!‚Äù ‚Äì Nh∆∞ Y√™n k√™u l√™n, nh∆∞ng Tuy·∫øt K·ª≥ ch·ªâ nh·∫øch m√¥i, ti·∫øp t·ª•c lao v√†o.\nDi·ªáp Th·∫ßn nh√¨n th·∫•y t·∫•t c·∫£. Trong ph√∫t ch·ªëc, linh l·ª±c trong ng∆∞·ªùi ch√†ng nh∆∞ b·ª´ng t·ªânh, nh∆∞ng l·∫°i b·ªã h·ªèa ch√∫ ƒë√® n√©n. Ch√†ng kh√¥ng th·ªÉ s·ª≠ d·ª•ng to√†n b·ªô s·ª©c m·∫°nh.\nNh∆∞ng c√≥ m·ªôt ƒëi·ªÅu k·ª≥ l·∫°.\nNgay khi √°nh m·∫Øt c·ªßa Di·ªáp Th·∫ßn ch·∫°m v√†o Tuy·∫øt Giao, ch√†ng c·∫£m nh·∫≠n ƒë∆∞·ª£c m·ªôt lu·ªìng kh√≠ √¢m h√†n k√¨ l·∫° t·ª´ con y√™u th√∫. ƒê√≥ l√† th·ª© m√† ch√†ng ch∆∞a t·ª´ng g·∫∑p ph·∫£i trong su·ªët qu√° tr√¨nh tu luy·ªán.\nNgo·∫°i V·ª±c ‚Äì kh√¥ng ph·∫£i l√† m·ªôt th·∫ø gi·ªõi tƒ©nh l·∫∑ng, m√† l√† m·ªôt c∆°n b√£o h·ªón lo·∫°n, ƒë·∫ßy m∆° h·ªì v√† tr√†n ƒë·∫ßy t√† kh√≠. Tuy·∫øt Giao\u0026hellip; c√≥ m·ªôt s·ª± li√™n k·∫øt k·ª≥ l·∫° v·ªõi ngu·ªìn nƒÉng l∆∞·ª£ng ·∫•y.\nDi·ªáp Th·∫ßn r·ªët cu·ªôc c≈©ng kh√¥ng th·ªÉ ƒë·ª©ng y√™n. Ch√†ng v·∫≠n d·ª•ng linh kh√≠ c√≤n l·∫°i, quy·∫øt ƒë·ªãnh l√†m m·ªôt vi·ªác m√† tr∆∞·ªõc gi·ªù ch∆∞a t·ª´ng l√†m.\nH·∫Øn kh√¥ng tr·ª±c ti·∫øp t·∫•n c√¥ng. Thay v√†o ƒë√≥, h·∫Øn k·∫øt n·ªëi v·ªõi linh kh√≠ c·ªßa Tuy·∫øt Giao, x√¢m nh·∫≠p v√†o ti·ªÅm th·ª©c c·ªßa n√≥, d√πng m·ªôt ph·∫ßn √Ω ch√≠ c·ªßa m√¨nh ƒë·ªÉ khu·∫•t ph·ª•c con th√∫ hoang d√£ n√†y.\n‚ÄúTuy·∫øt Giao!‚Äù ‚Äì Di·ªáp Th·∫ßn h√©t l√™n. ‚ÄúNg∆∞∆°i kh√¥ng ph·∫£i l√† k·∫ª th√π c·ªßa ch√∫ng ta. ƒê·ª´ng ƒë·ªÉ nh·ªØng k√Ω ·ª©c c·ªßa Ngo·∫°i V·ª±c l√†m ng∆∞∆°i m·∫•t ƒëi b·∫£n t√≠nh!‚Äù\nM·ªôt c∆°n s√≥ng √¢m t·ª´ Di·ªáp Th·∫ßn v·ª° ra, h√≤a v√†o kh√¥ng kh√≠, truy·ªÅn th·∫≥ng v√†o t√¢m tr√≠ Tuy·∫øt Giao. Nh∆∞ng ngay l·∫≠p t·ª©c, m·ªôt lu·ªìng ph·∫£n kh√°ng m·∫°nh m·∫Ω b√πng l√™n t·ª´ con y√™u th√∫, l√†m cho kh√¥ng kh√≠ trong ƒë·ªông n·∫∑ng n·ªÅ ƒë·∫øn m·ª©c g·∫ßn nh∆∞ ngh·∫πt th·ªü.\nTuy·∫øt Giao g·∫ßm l√™n, l∆∞ng n√≥ cong l·∫°i nh∆∞ m·ªôt cung t√™n, s·ª´ng ƒëen qu√©t qua kh√¥ng gian.\nNh∆∞ng r·ªìi, m·ªôt ti·∫øng c·∫ßm kh√∫c vang l√™n. Nh∆∞ Y√™n ph√°t ra m·ªôt ƒë·ª£t √¢m thanh m·∫°nh m·∫Ω, khi·∫øn linh h·ªìn Tuy·∫øt Giao dao ƒë·ªông. B·∫±ng √¢m thanh, n√†ng ƒë√£ k·∫øt n·ªëi ƒë∆∞·ª£c v·ªõi t√¢m h·ªìn c·ªßa y√™u th√∫, khi·∫øn n√≥ t·∫°m th·ªùi ch·ªØng l·∫°i.\nL√∫c n√†y, Tuy·∫øt K·ª≥ nhanh ch√≥ng lao ƒë·∫øn, ki·∫øm ph√°p chu·∫©n x√°c, ch√©m m·ªôt ƒë√≤n ch√≠ m·∫°ng v√†o y·∫øu huy·ªát c·ªßa y√™u th√∫.\nTuy·∫øt Giao g·∫ßm l√™n m·ªôt ti·∫øng ƒëau ƒë·ªõn, th√¢n h√¨nh to l·ªõn ng√£ g·ª•c xu·ªëng, tuy·∫øt quanh ng∆∞·ªùi tan ch·∫£y, t·∫°o th√†nh nh·ªØng v≈©ng n∆∞·ªõc l·∫°nh gi√°.\nL√∫c n√†y, ba ng∆∞·ªùi m·ªõi th·ªü ph√†o nh·∫π nh√µm, nh∆∞ng ch∆∞a k·ªãp vui m·ª´ng, m·ªôt ti·∫øng g·∫ßm th√©t vang l√™n t·ª´ xa.\nDi·ªáp Th·∫ßn nh√¨n l√™n, √°nh m·∫Øt h·∫Øn s·∫ßm l·∫°i. M·ªôt th·∫ø l·ª±c kh·ªßng khi·∫øp kh√°c ƒëang ƒë·∫øn g·∫ßn.\nƒê√¢y m·ªõi ch·ªâ l√† kh·ªüi ƒë·∫ßu.\nCh∆∞∆°ng 5 ‚Äì Th·∫ø L·ª±c B·ªã X√© R√°ch Gi√≥ b√£o cu·ªën ƒë·∫øn t·ª´ ph∆∞∆°ng xa, nh·ªØng ƒë√°m m√¢y ƒëen k·ªãt nh∆∞ b·ªëc ch√°y tr√™n b·∫ßu tr·ªùi cao, h√≤a l·∫´n v·ªõi l·ªõp tuy·∫øt tr·∫Øng, t·∫°o n√™n m·ªôt c·∫£nh t∆∞·ª£ng h√£i h√πng nh∆∞ m·ªôt th·∫ø gi·ªõi b·ªã x√© n√°t.\nDi·ªáp Th·∫ßn, Tuy·∫øt K·ª≥ v√† Nh∆∞ Y√™n ƒëang ƒë·ª©ng t·∫°i trung t√¢m c·ªßa tr·∫≠n chi·∫øn v·ª´a qua. Tuy·∫øt Giao, y√™u th√∫ Kim ƒêan, gi·ªù ƒë√£ g·ª•c xu·ªëng, nh∆∞ng kh√¥ng ph·∫£i v√¨ ho√†n to√†n b·ªã ti√™u di·ªát. N√≥ v·∫´n c√≤n h∆°i th·ªü y·∫øu ·ªõt, th·ªânh tho·∫£ng ph√°t ra nh·ªØng ti·∫øng g·∫ßm th·∫•p t·ª´ trong c·ªï h·ªçng.\nDi·ªáp Th·∫ßn c·∫£m nh·∫≠n r√µ s·ª± thay ƒë·ªïi trong kh√¥ng kh√≠. M·ªôt lu·ªìng kh√≠ u √°m ƒëen t·ªëi ƒëang ng√†y c√†ng ti·∫øn l·∫°i g·∫ßn, nh∆∞ c√≥ th·ª© g√¨ ƒë√≥ ƒëang x√© to·∫°c kh√¥ng gian.\n‚ÄúC√≥ c·∫£m gi√°c g√¨ kh√¥ng?‚Äù ‚Äì Tuy·∫øt K·ª≥ nh√¨n Di·ªáp Th·∫ßn, h·ªèi.\nCh√†ng nh√≠u m√†y, ƒë√¥i m·∫Øt ƒë·ªè nh·∫°t d·∫ßn √°nh l√™n s·ª± ch√∫ √Ω.\n‚ÄúLinh kh√≠ xung quanh‚Ä¶ c√≥ g√¨ ƒë√≥ kh√¥ng ·ªïn,‚Äù ‚Äì Di·ªáp Th·∫ßn n√≥i, gi·ªçng nghi√™m tr·ªçng. ‚ÄúC·∫£m gi√°c nh∆∞ c√≥ ai ƒë√≥ ƒëang √©p kh√¥ng gian n√†y v·∫∑n v·∫πo.‚Äù\nNh∆∞ Y√™n, ƒëang ng·ªìi b√™n c·∫°nh, ƒë∆∞a tay l√™n c·∫£m nh·∫≠n kh√¥ng kh√≠. ‚Äúƒê√∫ng v·∫≠y. Linh kh√≠ lo·∫°n ƒë·ªông, nh∆∞ c√≥ m·ªôt khe h·ªü v√¥ h√¨nh trong kh√¥ng gian.‚Äù\nTuy·∫øt K·ª≥ kh√¥ng n√≥i g√¨, ch·ªâ l·∫≥ng l·∫∑ng nh√¨n v·ªÅ ph√≠a ch√¢n tr·ªùi, n∆°i m√†n tuy·∫øt d√†y ƒë·∫∑c ƒëang kh√¥ng ng·ª´ng cu·ªìn cu·ªôn.\nƒê·ªôt nhi√™n, m·ªôt ti·∫øng g·∫ßm vang l√™n, x√© tan s·ª± tƒ©nh l·∫∑ng.\nDi·ªáp Th·∫ßn gi·∫≠t m√¨nh quay l·∫°i. T·ª´ trong m√†n tuy·∫øt m·ªù m·ªãt, m·ªôt b√≥ng ƒëen kh·ªïng l·ªì ƒëang lao t·ªõi, ph√°t ra nh·ªØng ti·∫øng th√©t r√πng r·ª£n. ƒê√≥ l√† m·ªôt con Th√∫ C·ªï Th·∫ßn, ƒë√£ l√¢u kh√¥ng xu·∫•t hi·ªán trong s·ª≠ s√°ch c·ªßa tu ti√™n gi·ªõi.\nN√≥ c√≥ th√¢n h√¨nh kh·ªïng l·ªì, bao ph·ªß l·ªõp l√¥ng ƒëen d√†y, hai c·∫∑p m·∫Øt ƒë·ªè r·ª±c nh∆∞ l·ª≠a. ƒê√¥i s·ª´ng v∆∞∆°n d√†i nh∆∞ m≈©i ki·∫øm, v√† m·ªói b∆∞·ªõc ƒëi c·ªßa n√≥ khi·∫øn m·∫∑t ƒë·∫•t rung chuy·ªÉn.\n‚ÄúL√† Th√∫ C·ªï Th·∫ßn ‚Äì sinh v·∫≠t ƒë√£ b·ªã phong ·∫•n trong nh·ªØng ng·ªçn n√∫i cao h√†ng ngh√¨n nƒÉm!‚Äù ‚Äì Nh∆∞ Y√™n th·ªët l√™n.\nTuy·∫øt K·ª≥ r√∫t thanh ki·∫øm b·∫°c ra, √°nh m·∫Øt l·∫°nh l√πng. ‚ÄúN·∫øu n√≥ ƒë√£ ƒë·∫øn ƒë√¢y‚Ä¶ th√¨ c√≥ th·ªÉ l√† d·∫•u hi·ªáu cho s·ª± tr·ªói d·∫≠y c·ªßa m·ªôt th·∫ø l·ª±c kh√°c.‚Äù\nDi·ªáp Th·∫ßn ƒë·ª©ng v·ªØng, tay n·∫Øm ch·∫∑t, c·∫£m nh·∫≠n s·ª©c m·∫°nh √¢m ·ªâ trong c∆° th·ªÉ m√¨nh. D√π h·ªèa ch√∫ Ngo·∫°i V·ª±c v·∫´n ƒë√® n√©n linh l·ª±c c·ªßa h·∫Øn, nh∆∞ng ch√†ng bi·∫øt, n·∫øu ƒë·ªÉ con Th√∫ C·ªï Th·∫ßn n√†y ho√†nh h√†nh, c·∫£ Tuy·∫øt Gi√°c S∆°n s·∫Ω b·ªã t√†n ph√°.\n‚ÄúCh√∫ng ta kh√¥ng th·ªÉ ƒë·ªÉ n√≥ ƒë·∫øn g·∫ßn khu v·ª±c d√¢n c∆∞.‚Äù ‚Äì Tuy·∫øt K·ª≥ n√≥i. ‚ÄúDi·ªáp Th·∫ßn, d√π th·∫ø n√†o, ng∆∞∆°i ph·∫£i gi√∫p ch√∫ng ta ngƒÉn ch·∫∑n n√≥!‚Äù\nDi·ªáp Th·∫ßn g·∫≠t ƒë·∫ßu, m·∫Øt s√°ng l√™n m·ªôt tia s·∫Øc b√©n.\n‚ÄúTa bi·∫øt. Ch√∫ng ta ph·∫£i ƒë√°nh b·∫°i n√≥ tr∆∞·ªõc khi n√≥ k√™u g·ªçi th√™m ƒë·ªìng b·ªçn.‚Äù\nTh√∫ C·ªï Th·∫ßn vung m·ªôt c√°nh tay kh·ªïng l·ªì, t·∫•n c√¥ng v·ªÅ ph√≠a ba ng∆∞·ªùi, v√† khi n√≥ vung tay, m·ªôt c∆°n s√≥ng √¢m nh∆∞ v·ª° n√°t kh√¥ng gian lao t·ªõi, cu·ªën theo m·ªôt ƒë·ª£t kh√≠ l·∫°nh t√™ bu·ªët.\nNh∆∞ Y√™n l·∫≠p t·ª©c ph√≥ng ra m·ªôt ƒë·ª£t s√≥ng √¢m t·ª´ ƒë√†n ng·ªçc, nh∆∞ng ƒë·ªëi v·ªõi m·ªôt sinh v·∫≠t m·∫°nh m·∫Ω nh∆∞ Th√∫ C·ªï Th·∫ßn, s√≥ng √¢m ·∫•y ch·ªâ nh∆∞ c∆°n gi√≥ nh·∫π. N√≥ kh√¥ng h·ªÅ b·ªã ·∫£nh h∆∞·ªüng.\n‚ÄúKi·∫øm ph√°p c·ªßa ta!‚Äù ‚Äì Tuy·∫øt K·ª≥ h√©t l√™n, lao v·ªÅ ph√≠a Th√∫ C·ªï Th·∫ßn, nh∆∞ng thanh ki·∫øm c·ªßa n√†ng ch·ªâ c·∫Øt m·ªôt v·ªát s√°ng lo√°ng tr∆∞·ªõc m·∫∑t y√™u th√∫, kh√¥ng th·ªÉ l√†m t·ªïn th∆∞∆°ng n√≥.\nDi·ªáp Th·∫ßn, c·∫£m nh·∫≠n th·∫•y s·ª± nguy hi·ªÉm ng√†y c√†ng tƒÉng, quy·∫øt ƒë·ªãnh k√≠ch ho·∫°t m·ªôt m·∫£nh linh l·ª±c m·∫°nh m·∫Ω nh·∫•t m√† ch√†ng c√≥ th·ªÉ s·ª≠ d·ª•ng trong l√∫c n√†y.\nH·∫Øn kh√¥ng tr·ª±c ti·∫øp t·∫•n c√¥ng Th√∫ C·ªï Th·∫ßn, m√† thay v√†o ƒë√≥, h·∫Øn k·∫øt n·ªëi linh h·ªìn c·ªßa m√¨nh v·ªõi Ng·ªçc T√¢m Ph√°p T∆∞·ªùng ‚Äì m·ªôt ph√°p thu·∫≠t c·ªï x∆∞a c√≥ kh·∫£ nƒÉng ƒëi·ªÅu khi·ªÉn l·ª±c l∆∞·ª£ng h·ªßy di·ªát.\nM·ªôt d√≤ng ch·∫£y nƒÉng l∆∞·ª£ng kh·ªïng l·ªì b·∫Øt ƒë·∫ßu t·ª´ c∆° th·ªÉ Di·ªáp Th·∫ßn, t·ªèa ra nh∆∞ m·ªôt c∆°n l·ªëc. Tuy nhi√™n, linh l·ª±c c·ªßa ch√†ng kh√¥ng ƒë·ªß m·∫°nh m·∫Ω ƒë·ªÉ ƒë√°nh b·∫°i Th√∫ C·ªï Th·∫ßn ngay l·∫≠p t·ª©c, ch·ªâ c√≥ th·ªÉ t·∫°o ra m·ªôt t·∫•m khi√™n b·∫£o v·ªá t·∫°m th·ªùi.\n‚ÄúNg∆∞∆°i v·∫´n ch∆∞a ƒë·ªß s·ª©c!‚Äù ‚Äì m·ªôt gi·ªçng n√≥i l·∫°nh l√πng vang l√™n t·ª´ ph√≠a xa.\nƒê√≥ l√† gi·ªçng c·ªßa m·ªôt ng∆∞·ªùi m√† Di·ªáp Th·∫ßn kh√¥ng bao gi·ªù qu√™n: Ma T√¥n.\nM·ªôt b√≥ng ƒëen xu·∫•t hi·ªán t·ª´ trong m√†n tuy·∫øt, m·ªôt l√£o nh√¢n m·∫∑c √°o b√†o ƒëen v·ªõi ƒë√¥i m·∫Øt ƒë·ªè ng·∫ßu. L√£o ta bay ƒë·∫øn g·∫ßn, vung tay l√™n, t·∫°o ra m·ªôt c∆°n cu·ªìng phong m·∫°nh m·∫Ω.\n‚Äúƒê√¢y m·ªõi l√† s·ª©c m·∫°nh th·∫≠t s·ª±!‚Äù ‚Äì Ma T√¥n qu√°t l·ªõn.\nL√£o v∆∞∆°n tay, khi·∫øn Th√∫ C·ªï Th·∫ßn d·ª´ng l·∫°i. M·ªôt lu·ªìng kh√≠ t√† ma kh·ªïng l·ªì t·ª´ tay l√£o b·∫Øn ra, cu·ªën theo m·ªôt c∆°n s√≥ng ƒëen t·ªëi ph·ªß l√™n m·ªçi th·ª©.\nDi·ªáp Th·∫ßn c·∫£m nh·∫≠n ƒë∆∞·ª£c m·ªôt s·ª©c m·∫°nh kh·ªßng khi·∫øp. Ch√≠nh l√† Ma T√¥n ‚Äì ng∆∞·ªùi ƒë·ª©ng sau m·ªçi th·∫ø l·ª±c t√† √°c trong th·∫ø gi·ªõi tu ti√™n. H·∫Øn ƒë√£ quay l·∫°i.\n‚ÄúL·∫Ω n√†o ng∆∞∆°i ƒë√£ kh√¥ng ch·∫øt?‚Äù ‚Äì Di·ªáp Th·∫ßn r√≠t l√™n, c·∫£m nh·∫≠n s·ª± l·∫°nh l·∫Ωo trong l√≤ng.\n‚ÄúCh·∫øt? Ta ƒë√£ tr·ªën tho√°t kh·ªèi c√°i ch·∫øt, v√† gi·ªù ƒë√¢y, ng∆∞∆°i s·∫Ω l√† c√¥ng c·ª• cho s·ª± ph·ª•c sinh c·ªßa ta!‚Äù ‚Äì Ma T√¥n c∆∞·ªùi l·∫°nh, ƒë√¥i m·∫Øt ƒë·ªè ng·∫ßu nh√¨n v√†o Di·ªáp Th·∫ßn.\nTrong kho·∫£nh kh·∫Øc, linh m·∫°ch c·ªßa Di·ªáp Th·∫ßn b·∫Øt ƒë·∫ßu b·ªã r√∫t ki·ªát, nh∆∞ c√≥ m·ªôt s·ª£i d√¢y v√¥ h√¨nh si·∫øt ch·∫∑t l·∫•y tr√°i tim v√† linh h·ªìn c·ªßa h·∫Øn.\nTuy·∫øt K·ª≥ v√† Nh∆∞ Y√™n ƒë·ª©ng ng√¢y ng∆∞·ªùi, kh√¥ng k·ªãp ph·∫£n ·ª©ng.\nL√£o ta s·∫Ω kh√¥ng bao gi·ªù bu√¥ng tha Di·ªáp Th·∫ßn.\nNh∆∞ng Di·ªáp Th·∫ßn, v·ªõi m·ªôt tia quy·∫øt t√¢m trong √°nh m·∫Øt, th·∫ßm nghƒ©:\nKh√¥ng th·ªÉ thua.\nCh∆∞∆°ng 6 ‚Äì Ma T√¥n ƒê·∫°i Th·∫Øng Kh√¥ng kh√≠ nh∆∞ ƒë·∫∑c l·∫°i, tƒ©nh m·ªãch nh∆∞ng l·∫°i ƒë·∫ßy cƒÉng th·∫≥ng. M·ªôt lu·ªìng t√† kh√≠ ƒëen k·ªãt t·ª´ Ma T√¥n ph√≥ng ra, bao tr√πm l√™n t·∫•t c·∫£. S·ª©c m·∫°nh t√† √°c nh∆∞ ƒëang √©p ch·∫∑t m·ªçi linh kh√≠ trong kh√¥ng gian, khi·∫øn ba ng∆∞·ªùi c·∫£m th·∫•y ngh·∫πt th·ªü, kh√≥ khƒÉn trong vi·ªác duy tr√¨ linh l·ª±c.\nDi·ªáp Th·∫ßn c·∫£m nh·∫≠n r√µ s·ª± √°p b·ª©c t·ª´ Ma T√¥n. C√°i c·∫£m gi√°c n√†y, ch√≠nh l√† th·ª© m√† h·∫Øn ƒë√£ ch·∫°y tr·ªën su·ªët bao nƒÉm qua. Ma T√¥n kh√¥ng ch·ªâ l√† m·ªôt ƒë·ªëi th·ªß m·∫°nh m·∫Ω v·ªÅ tu vi, m√† c√≤n l√† m·ªôt k·∫ª ƒëi·ªÅu khi·ªÉn b√≥ng t·ªëi, thao t√∫ng linh h·ªìn v√† t√¢m tr√≠ ng∆∞·ªùi kh√°c.\n‚ÄúNg∆∞∆°i kh√¥ng th·ªÉ th·∫Øng ƒë∆∞·ª£c ta.‚Äù ‚Äì Ma T√¥n c∆∞·ªùi l·∫°nh, b∆∞·ªõc t·ª´ng b∆∞·ªõc v·ªÅ ph√≠a Di·ªáp Th·∫ßn. ‚ÄúLinh l·ª±c c·ªßa ng∆∞∆°i ƒë√£ b·ªã ta phong ·∫•n. Ng∆∞∆°i ch·ªâ l√† m·ªôt con r·ªëi m√† ta ƒëi·ªÅu khi·ªÉn.‚Äù\nDi·ªáp Th·∫ßn kh√¥ng tr·∫£ l·ªùi, ch·ªâ n·∫Øm ch·∫∑t tay, c·∫£m nh·∫≠n s·ª± ƒëau ƒë·ªõn t·ª´ h·ªèa ch√∫ Ngo·∫°i V·ª±c v·∫´n ƒëang x√¢m chi·∫øm th√¢n th·ªÉ. Nh∆∞ng trong l√∫c tuy·ªát v·ªçng nh·∫•t, h·∫Øn c≈©ng c·∫£m nh·∫≠n ƒë∆∞·ª£c m·ªôt ƒëi·ªÅu.\nS·ª©c m·∫°nh trong b·∫£n th√¢n m√¨nh v·∫´n ch∆∞a ho√†n to√†n m·∫•t ƒëi.\nCh√†ng t·∫≠p trung v√†o nh·ªØng g√¨ c√≤n s√≥t l·∫°i trong c∆° th·ªÉ, √©p linh l·ª±c t·ªânh d·∫≠y. T·ª´ng tia s√°ng, t·ª´ng s·ª£i linh kh√≠ b·∫Øt ƒë·∫ßu cu·ªôn tr√†o trong c∆° th·ªÉ, m·∫∑c cho Ma T√¥n ƒëang c·ªë g·∫Øng ki·ªÅm h√£m.\nNh∆∞ng, kh√¥ng ph·∫£i t·∫•t c·∫£ s·ª©c m·∫°nh ƒë·ªÅu n·∫±m trong c∆° th·ªÉ Di·ªáp Th·∫ßn. Ch√†ng bi·∫øt, s·ª± thay ƒë·ªïi n√†y l√† t·ª´ Ngo·∫°i V·ª±c ‚Äì ch√≠nh l√† s·ª± k·∫øt n·ªëi m√† Ma T√¥n ƒë√£ kh∆°i d·∫≠y, v√† gi·ªù ƒë√¢y, Di·ªáp Th·∫ßn ph·∫£i t√¨m c√°ch t·∫≠n d·ª•ng ch√≠nh s·ª©c m·∫°nh ƒë√≥ ƒë·ªÉ chi·∫øn th·∫Øng.\n‚ÄúNg∆∞∆°i s·∫Ω kh√¥ng bao gi·ªù th·∫Øng!‚Äù ‚Äì Ma T√¥n l·∫°i qu√°t l·ªõn, tay vung l√™n, m·ªôt lu·ªìng ma kh√≠ ƒëen ƒë·∫∑c ph√≥ng th·∫≥ng v√†o Di·ªáp Th·∫ßn.\nC·∫£ ba ng∆∞·ªùi ‚Äì Tuy·∫øt K·ª≥, Nh∆∞ Y√™n v√† Di·ªáp Th·∫ßn ‚Äì ƒë·ªÅu l·∫≠p t·ª©c b·ªã bao ph·ªß trong m·ªôt c∆°n s√≥ng ƒëen t·ªëi. Linh h·ªìn c·ªßa h·ªç d∆∞·ªùng nh∆∞ b·ªã x√© n√°t d∆∞·ªõi √°p l·ª±c kh·ªßng khi·∫øp.\nNh∆∞ng Di·ªáp Th·∫ßn, m·∫∑c cho s·ª± ƒëau ƒë·ªõn th·∫•u x∆∞∆°ng, v·∫´n kh√¥ng khu·∫•t ph·ª•c. H·∫Øn ƒë∆∞a tay ra, kh√¥ng ph·∫£i ƒë·ªÉ ch·∫∑n l·∫°i, m√† ƒë·ªÉ h√∫t v√†o trong m√¨nh t·∫•t c·∫£ nh·ªØng g√¨ Ma T√¥n ƒëang ph√≥ng ra.\n‚ÄúNg∆∞∆°i kh√¥ng th·ªÉ l√†m ƒë∆∞·ª£c ƒë√¢u!‚Äù ‚Äì Ma T√¥n nghi·∫øn rƒÉng, m·∫Øt ƒë·ªè ng·∫ßu nh∆∞ m√°u, tr·ª´ng m·∫Øt nh√¨n Di·ªáp Th·∫ßn. ‚ÄúKh√¥ng th·ªÉ ch·ªëng l·∫°i ƒë∆∞·ª£c s·ª©c m·∫°nh c·ªßa ta!‚Äù\nNh∆∞ng Di·ªáp Th·∫ßn kh√¥ng ƒë√°p l·∫°i. H·∫Øn c·∫£m nh·∫≠n th·∫•y m·ªôt tia s√°ng m·ªèng manh t·ª´ trong b√≥ng t·ªëi. C√°i b√≥ng t·ªëi ·∫•y, ch√≠nh l√† m·ªôt ph·∫ßn trong m√¨nh.\nH·∫Øn b·∫Øt ƒë·∫ßu x√© r√°ch s·ª©c m·∫°nh t√† ma c·ªßa Ma T√¥n, ƒëi·ªÅu khi·ªÉn linh l·ª±c ƒë·ªÉ quay l·∫°i v√† ph·∫£n c√¥ng. M·ªôt tia s√°ng ƒë·ªè b√πng l√™n t·ª´ trong c∆° th·ªÉ Di·ªáp Th·∫ßn, nh∆∞ m·ªôt ng·ªçn l·ª≠a di·ªÖm l·ªá trong ƒë√™m t·ªëi.\nCh·ªâ trong kho·∫£nh kh·∫Øc, Ma T√¥n c·∫£m th·∫•y s·ª± ch·∫•n ƒë·ªông m·∫°nh m·∫Ω t·ª´ Di·ªáp Th·∫ßn, nh∆∞ c√≥ m·ªôt c∆°n s√≥ng th·∫ßn t·ª´ trong ng∆∞·ªùi h·∫Øn tr√†o ra, cu·ªën phƒÉng t·∫•t c·∫£ nh·ªØng g√¨ Ma T√¥n v·ª´a tung ra.\n‚ÄúC√°i g√¨?‚Äù ‚Äì Ma T√¥n k√™u l√™n ƒë·∫ßy b·∫•t ng·ªù, nh√¨n th·∫•y m·ªôt l∆∞·ª£ng nƒÉng l∆∞·ª£ng m√† h·∫Øn kh√¥ng ng·ªù t·ªõi. ƒê√¥i m·∫Øt l√£o ta m·ªü to, kinh ng·∫°c tr∆∞·ªõc s·ª± thay ƒë·ªïi trong Di·ªáp Th·∫ßn.\nNh∆∞ng r·ªìi, Di·ªáp Th·∫ßn kh√¥ng d·ª´ng l·∫°i. H·∫Øn ch·∫•n ƒë·ªông l·ª±c l∆∞·ª£ng c·ªßa Ngo·∫°i V·ª±c trong c∆° th·ªÉ m√¨nh, v·∫≠n d·ª•ng n√≥ ƒë·ªÉ t·∫°o th√†nh m·ªôt th·∫ø tr·∫≠n linh h·ªìn m·∫°nh m·∫Ω, khi·∫øn cho Ma T√¥n ph·∫£i l√πi l·∫°i m·ªôt b∆∞·ªõc.\nTuy·∫øt K·ª≥ v√† Nh∆∞ Y√™n, ch·ª©ng ki·∫øn s·ª©c m·∫°nh n√†y, kh√¥ng d√°m tin v√†o m·∫Øt m√¨nh.\n‚ÄúDi·ªáp Th·∫ßn\u0026hellip; l√†m sao c√≥ th·ªÉ?‚Äù ‚Äì Tuy·∫øt K·ª≥ th√¨ th·∫ßm.\n‚Äúƒê√≥ l√†\u0026hellip; s·ª©c m·∫°nh t·ª´ Ngo·∫°i V·ª±c,‚Äù ‚Äì Nh∆∞ Y√™n m√≠m m√¥i, r·ªìi quay sang Tuy·∫øt K·ª≥. ‚ÄúDi·ªáp Th·∫ßn ƒë√£ t√¨m c√°ch ƒëi·ªÅu khi·ªÉn n√≥!‚Äù\nNh∆∞ng Ma T√¥n kh√¥ng ph·∫£i k·∫ª d·ªÖ d√†ng b·ªã ƒë√°nh b·∫°i. L√£o ta th√©t l√™n, ƒë√¥i m·∫Øt ƒë·∫ßy th√π h·∫≠n, b√†n tay vung l√™n, v√† m·ªôt h√†o quang ƒëen xu·∫•t hi·ªán, bao ph·ªß l·∫•y t·∫•t c·∫£.\n‚ÄúKh√¥ng th·ªÉ n√†o\u0026hellip;‚Äù ‚Äì Ma T√¥n c∆∞·ªùi kh·∫©y. ‚ÄúNg∆∞∆°i ch·ªâ l√† m·ªôt con c·ªù. Kh√¥ng th·ªÉ v∆∞·ª£t qua ƒë∆∞·ª£c s·ª©c m·∫°nh c·ªßa ta!‚Äù\nC∆°n cu·ªìng phong ƒëen t·ªëi t·ª´ b√†n tay Ma T√¥n b·∫Øt ƒë·∫ßu bao tr√πm, nh∆∞ng Di·ªáp Th·∫ßn kh√¥ng l√πi b∆∞·ªõc. H·∫Øn n·∫Øm ch·∫∑t tay, m·ªôt l·∫ßn n·ªØa v·∫≠n s·ª©c m·∫°nh Ngo·∫°i V·ª±c.\n\u0026ldquo;Th·∫ßn H·ªèa!\u0026rdquo;\nL·ª≠a ƒë·ªè b√πng l√™n, bao tr√πm l·∫•y th√¢n th·ªÉ Ma T√¥n. S·ª©c m·∫°nh h·ªßy di·ªát c·ªßa Ngo·∫°i V·ª±c b√πng ph√°t m·∫°nh m·∫Ω, nh∆∞ m·ªôt tr·∫≠n cu·ªìng phong th·ªïi bay m·ªçi th·ª©. Ma T√¥n ch·ªâ k·ªãp h√©t l√™n m·ªôt ti·∫øng th·∫£m thi·∫øt, nh∆∞ng r·ªìi h√¨nh b√≥ng l√£o ta b·ªã ng·ªçn l·ª≠a ·∫•y nu·ªët ch·ª≠ng.\nM·ªôt ti·∫øng n·ªï l·ªõn vang l√™n.\nC·∫£ kh√¥ng gian s·ª•p ƒë·ªï, nh∆∞ v·ª° n√°t d∆∞·ªõi s·ª©c m·∫°nh c·ªßa Di·ªáp Th·∫ßn. Ma T√¥n, ng∆∞·ªùi ƒë√£ gieo r·∫Øc bao nhi√™u t·ªôi √°c, gi·ªù ƒë√£ b·ªã h·ªßy di·ªát ho√†n to√†n.\nNh∆∞ng kh√¥ng ph·∫£i t·∫•t c·∫£ ƒë·ªÅu y√™n ·ªïn. Nh·ªØng tia s√°ng t·ª´ v·ª• n·ªï b·∫Øt ƒë·∫ßu n·ªü ra th√†nh nh·ªØng l·ªó h·ªïng kh√¥ng gian, l√†m cho linh kh√≠ c√†ng th√™m r·ªëi lo·∫°n.\n‚Äúƒê√¢y kh√¥ng ph·∫£i l√† k·∫øt th√∫c.‚Äù ‚Äì Di·ªáp Th·∫ßn th·ªü d√†i, m·ªát m·ªèi, nh∆∞ng √°nh m·∫Øt v·∫´n s√°ng r·ª±c l√™n. ‚ÄúCh√∫ng ta m·ªõi ch·ªâ ƒë·ªëi m·∫∑t v·ªõi nh·ªØng g√¨ c√≤n s√≥t l·∫°i c·ªßa Ma T√¥n.‚Äù\nNh∆∞ Y√™n v√† Tuy·∫øt K·ª≥ nh√¨n nhau, c·∫£ hai ƒë·ªÅu bi·∫øt r·∫±ng cu·ªôc chi·∫øn m·ªõi ch·ªâ b·∫Øt ƒë·∫ßu.\nCh∆∞∆°ng 7 ‚Äì L·ªó H·ªïng Kh√¥ng Gian V·∫øt n·ª©t kh√¥ng gian kh√¥ng ng·ª´ng lan r·ªông ra t·ª´ trung t√¢m tr·∫≠n chi·∫øn, n∆°i Di·ªáp Th·∫ßn v·ª´a ƒë√°nh b·∫°i Ma T√¥n. C·∫£ ba ng∆∞·ªùi ƒë·ª©ng b·∫•t ƒë·ªông, nh√¨n nh·ªØng v·∫øt n·ª©t m·ªèng manh nh∆∞ t∆° v√†ng lan t·ªèa trong kh√¥ng kh√≠, t·∫°o th√†nh m·ªôt m·∫°ng l∆∞·ªõi k·ª≥ l·∫°, u √°m.\nM·∫∑t ƒë·∫•t d∆∞·ªõi ch√¢n h·ªç r·∫°n n·ª©t, v√† t·ª´ng ƒë·ª£t s√≥ng nƒÉng l∆∞·ª£ng t·ª´ nh·ªØng v·∫øt n·ª©t ·∫•y x√¥ng v√†o kh√¥ng gian, nh∆∞ mu·ªën x√© to·∫°c linh kh√≠ ƒëang duy tr√¨ s·ª± c√¢n b·∫±ng trong th·∫ø gi·ªõi n√†y.\nDi·ªáp Th·∫ßn n·∫Øm ch·∫∑t tay, c·∫£m nh·∫≠n ƒë∆∞·ª£c s·ª± chuy·ªÉn ƒë·ªông b·∫•t th∆∞·ªùng trong kh√¥ng gian. ‚ÄúKh√¥ng ·ªïn. Nh·ªØng l·ªó h·ªïng n√†y c√≥ th·ªÉ ph√° v·ª° kh√¥ng ch·ªâ c∆° th·ªÉ ch√∫ng ta m√† c√≤n l√†m v·ª° ƒëi c·∫£ linh m·∫°ch c·ªßa th·∫ø gi·ªõi n√†y.‚Äù\nTuy·∫øt K·ª≥ ƒë·ª©ng g·∫ßn b√™n, √°nh m·∫Øt nghi√™m ngh·ªã. ‚Äúƒê√¢y l√† h·∫≠u qu·∫£ c·ªßa s·ª± can thi·ªáp c·ªßa Ma T√¥n v√†o kh√¥ng gian. Nh·ªØng l·ªó h·ªïng n√†y kh√¥ng th·ªÉ c·ª© ƒë·ªÉ t·ªìn t·∫°i. Ch√∫ng s·∫Ω k√©o theo nh·ªØng c∆°n cu·ªìng phong, th·∫≠m ch√≠ l√† nh·ªØng th·∫ø l·ª±c t·ª´ Ngo·∫°i V·ª±c.‚Äù\nNh∆∞ Y√™n c√∫i ƒë·∫ßu, nh·∫π nh√†ng l·∫©m b·∫©m: ‚ÄúNgo·∫°i V·ª±c‚Ä¶ nh·ªØng g√¨ ta ƒë√£ nghe t·ª´ t·ªï ti√™n. Nh·ªØng v·∫øt n·ª©t n√†y ch√≠nh l√† d·∫•u hi·ªáu c·ªßa s·ª± x√¢m l∆∞·ª£c t·ª´ n∆°i ƒë√≥.‚Äù\nDi·ªáp Th·∫ßn nh√¨n v·ªÅ ph√≠a nh·ªØng v·∫øt n·ª©t, r·ªìi quay l·∫°i nh√¨n hai ng∆∞·ªùi b·∫°n. ‚ÄúCh√∫ng ta kh√¥ng th·ªÉ ƒë·ªÉ nh·ªØng l·ªó h·ªïng n√†y t·ªìn t·∫°i. Kh√¥ng gian n√†y ƒëang b·ªã r·∫°n n·ª©t, v√† ch·ªâ c√≥ ch√∫ng ta m·ªõi c√≥ th·ªÉ ngƒÉn ch·∫∑n n√≥.‚Äù\nTuy·∫øt K·ª≥ r√∫t thanh ki·∫øm b·∫°c t·ª´ b√™n h√¥ng, √°nh s√°ng t·ª´ thanh ki·∫øm ph·∫£n chi·∫øu l√™n g∆∞∆°ng m·∫∑t n√†ng, tr√¥ng ki√™n ƒë·ªãnh v√† l·∫°nh l√πng. ‚ÄúCh√∫ng ta s·∫Ω ph·∫£i ƒë√≥ng c√°c l·ªó h·ªïng l·∫°i, b·∫±ng c√°ch n√†o ƒë√≥. Nh∆∞ng l√†m th·∫ø n√†o, ch√∫ng ta kh√¥ng th·ªÉ bi·∫øt ch√≠nh x√°c.‚Äù\nNh∆∞ Y√™n nh√¨n v·ªÅ nh·ªØng v·∫øt n·ª©t kh√¥ng gian, ƒë√¥i m·∫Øt n√†ng to√°t l√™n v·∫ª lo √¢u. ‚ÄúT·ªï ti√™n ta ƒë√£ t·ª´ng n√≥i v·ªÅ m·ªôt c√°nh c·ª≠a v√¥ h√¨nh, n∆°i m√† linh kh√≠ t·ª´ th·∫ø gi·ªõi n√†y c√≥ th·ªÉ kh√©p l·∫°i c√°c v·∫øt n·ª©t. Nh∆∞ng c√°nh c·ª≠a ·∫•y‚Ä¶ ƒë√£ b·ªã phong ·∫•n t·ª´ l√¢u.‚Äù\nDi·ªáp Th·∫ßn n·∫Øm ch·∫∑t tay, m·∫Øt s√°ng r·ª±c. ‚ÄúPhong ·∫•n c√≥ th·ªÉ b·ªã ph√° v·ª°. M·ªói v·∫øt n·ª©t n√†y ƒë·ªÅu mang m·ªôt ngu·ªìn s·ª©c m·∫°nh t·ª´ Ngo·∫°i V·ª±c, v√† c√≥ th·ªÉ, ch·ªâ c√≥ c√°ch s·ª≠ d·ª•ng linh l·ª±c t·ª´ c·∫£ ba ch√∫ng ta m·ªõi c√≥ th·ªÉ l√†m ƒë∆∞·ª£c ƒëi·ªÅu ƒë√≥.‚Äù\nTuy·∫øt K·ª≥ v√† Nh∆∞ Y√™n ƒë·ªÅu g·∫≠t ƒë·∫ßu. C·∫£ ba ng∆∞·ªùi ƒë·ªÅu nh·∫≠n ra r·∫±ng ƒë√¢y kh√¥ng ph·∫£i l√† m·ªôt nhi·ªám v·ª• d·ªÖ d√†ng. M·ªói l·ªó h·ªïng trong kh√¥ng gian n√†y kh√¥ng ch·ªâ ƒëe d·ªça s·ª± ·ªïn ƒë·ªãnh c·ªßa th·∫ø gi·ªõi m√† c√≤n c√≥ th·ªÉ l√† d·∫•u hi·ªáu cho s·ª± tr·ªói d·∫≠y c·ªßa m·ªôt th·∫ø l·ª±c h√πng m·∫°nh, t·ª´ng b·ªã phong ·∫•n t·ª´ r·∫•t l√¢u.\n‚ÄúCh√∫ng ta kh√¥ng th·ªÉ ch·∫ßn ch·ª´. M·ªói ph√∫t gi√¢y tr√¥i qua ƒë·ªÅu c√≥ th·ªÉ l√† l√∫c th·∫ø gi·ªõi n√†y b·ªã x√© n√°t.‚Äù ‚Äì Di·ªáp Th·∫ßn n√≥i, gi·ªçng quy·∫øt ƒëo√°n.\nBa ng∆∞·ªùi b·∫Øt ƒë·∫ßu t·∫≠p trung, m·ªói ng∆∞·ªùi m·ªôt h∆∞·ªõng, c·ªë g·∫Øng c·∫£m nh·∫≠n v√† thu th·∫≠p nƒÉng l∆∞·ª£ng t·ª´ nh·ªØng l·ªó h·ªïng ƒëang lan ra.\nTuy·∫øt K·ª≥, v·ªõi thanh ki·∫øm b·∫°c, b·∫Øt ƒë·∫ßu v·∫Ω l√™n nh·ªØng k√Ω t·ª± tu ti√™n trong kh√¥ng gian, c·ªë g·∫Øng t·∫°o ra m·ªôt l√° ch·∫Øn linh l·ª±c b·∫£o v·ªá. Tuy nhi√™n, m·ªói k√Ω t·ª± n√†ng v·∫Ω ra l·∫°i b·ªã t√†n ph√° b·ªüi s·ª± khu·∫•y ƒë·ªông c·ªßa nh·ªØng v·∫øt n·ª©t kh√¥ng gian, khi·∫øn n√†ng ph·∫£i t·∫≠p trung cao ƒë·ªô.\nNh∆∞ Y√™n, ƒë·ª©ng b√™n c·∫°nh, s·ª≠ d·ª•ng ƒë√†n ng·ªçc c·ªßa m√¨nh ƒë·ªÉ ph√≥ng ra nh·ªØng √¢m thanh thanh tho√°t, nh·ªØng giai ƒëi·ªáu d·ªãu d√†ng nh∆∞ng ƒë·∫ßy m·∫°nh m·∫Ω, t·∫°o ra s√≥ng √¢m ch·ªëng l·∫°i s·ª± r·ªëi lo·∫°n c·ªßa linh kh√≠. M·ªói ti·∫øng ƒë√†n n√†ng ph√°t ra l√† m·ªôt n·ªó l·ª±c ƒë·ªÉ l√†m d·ªãu s·ª± xung ƒë·ªôt trong kh√¥ng gian, nh∆∞ng n√≥ ch·ªâ c√≥ th·ªÉ ng·ª´ng ƒë∆∞·ª£c m·ªôt ph·∫ßn nh·ªè trong d√≤ng ch·∫£y nƒÉng l∆∞·ª£ng h·ªßy di·ªát.\nDi·ªáp Th·∫ßn ƒë·ª©ng gi·ªØa, c·∫£m nh·∫≠n v√† truy·ªÅn linh l·ª±c c·ªßa m√¨nh v√†o nh·ªØng v·∫øt n·ª©t, ƒë·ªìng th·ªùi k√≠ch ho·∫°t Ngo·∫°i V·ª±c ƒë·ªÉ ƒë·ªëi kh√°ng l·∫°i s·ª± can thi·ªáp c·ªßa c√°c th·∫ø l·ª±c t·ª´ b√™n ngo√†i. Nh∆∞ng s·ª©c m·∫°nh c·ªßa Ngo·∫°i V·ª±c ƒëang √©p ch·∫∑t linh h·ªìn c·ªßa h·∫Øn, khi·∫øn c∆° th·ªÉ Di·ªáp Th·∫ßn c·∫£m th·∫•y ƒëau ƒë·ªõn v√¥ c√πng.\nM·ªói l·ªó h·ªïng kh√¥ng gian m·ªü r·ªông th√™m m·ªôt ch√∫t, v√† t·ª´ trong ƒë√≥, nh·ªØng sinh v·∫≠t k·ª≥ l·∫° b·∫Øt ƒë·∫ßu xu·∫•t hi·ªán. Nh·ªØng b√≥ng ma v·∫∑n v·∫πo, nh·ªØng tinh linh qu√°i d·ªã t·ª´ Ngo·∫°i V·ª±c b·∫Øt ƒë·∫ßu tr√†n v√†o, mang theo nh·ªØng c∆°n s√≥ng ƒëen c·ªßa nƒÉng l∆∞·ª£ng t√† √°c.\n‚ÄúCh√∫ng ta kh√¥ng th·ªÉ k√©o d√†i l√¢u h∆°n!‚Äù ‚Äì Di·ªáp Th·∫ßn g·∫ßm l√™n, m·∫Øt ƒë·ªè ng·∫ßu v√¨ s·ª± ƒëau ƒë·ªõn t·ª´ linh l·ª±c c·ªßa h·∫Øn.\nB√™n c·∫°nh ƒë√≥, Tuy·∫øt K·ª≥ v√† Nh∆∞ Y√™n c≈©ng kh√¥ng th·ªÉ gi·ªØ n·ªïi s·ª©c m·∫°nh c·ªßa m√¨nh l√¢u. H·ªç nh√¨n nhau, bi·∫øt r·∫±ng n·∫øu kh√¥ng l√†m g√¨ ƒë√≥ ngay l·∫≠p t·ª©c, c·∫£ th·∫ø gi·ªõi s·∫Ω b·ªã x√© r√°ch.\n‚Äúƒêi·ªÅu g√¨ ƒë√£ x·∫£y ra v·ªõi c√°nh c·ª≠a phong ·∫•n?‚Äù ‚Äì Tuy·∫øt K·ª≥ h·ªèi, gi·ªçng ƒë·∫ßy lo l·∫Øng.\nNh∆∞ Y√™n nh√¨n v·ªÅ ph√≠a Di·ªáp Th·∫ßn, r·ªìi nh·∫π nh√†ng n√≥i: ‚ÄúTa bi·∫øt n∆°i c√°nh c·ª≠a phong ·∫•n n·∫±m. Nh∆∞ng ch·ªâ c√≥ m·ªôt trong ch√∫ng ta c√≥ th·ªÉ b∆∞·ªõc v√†o. N·∫øu kh√¥ng, ch√∫ng ta s·∫Ω b·ªã k√©o v√†o Ngo·∫°i V·ª±c.‚Äù\nDi·ªáp Th·∫ßn quay sang Nh∆∞ Y√™n, √°nh m·∫Øt ƒë·∫ßy ki√™n quy·∫øt. ‚ÄúV·∫≠y ta s·∫Ω ƒëi. ƒê√¢y l√† tr√°ch nhi·ªám c·ªßa ta.‚Äù\nNh∆∞ng Nh∆∞ Y√™n l·∫Øc ƒë·∫ßu. ‚ÄúKh√¥ng. Ng∆∞∆°i ƒë√£ ch·ªãu qu√° nhi·ªÅu ƒëau ƒë·ªõn t·ª´ Ngo·∫°i V·ª±c. Ta s·∫Ω ƒëi, v√† ng∆∞∆°i ph·∫£i ·ªü l·∫°i ƒë·ªÉ b·∫£o v·ªá th·∫ø gi·ªõi n√†y.‚Äù\nDi·ªáp Th·∫ßn nh√¨n v√†o m·∫Øt Nh∆∞ Y√™n, √°nh m·∫Øt ƒë·∫ßy c·∫£m k√≠ch. C·∫£ ba ng∆∞·ªùi ƒë·ªÅu hi·ªÉu r·∫±ng ƒë√¢y l√† m·ªôt quy·∫øt ƒë·ªãnh quan tr·ªçng, kh√¥ng th·ªÉ quay l·∫°i. Nh∆∞ng n·∫øu h·ªç kh√¥ng h√†nh ƒë·ªông ngay l√∫c n√†y, th·∫ø gi·ªõi n√†y s·∫Ω ph·∫£i ƒë·ªëi m·∫∑t v·ªõi m·ªôt th·∫£m h·ªça kh·ªßng khi·∫øp.\nüí† H·∫øt ch∆∞∆°ng 7\nCh∆∞∆°ng 8: C√°nh C·ª≠a Phong ·∫§n khi Nh∆∞ Y√™n b∆∞·ªõc v√†o c√°nh c·ª≠a v√† ph·∫£i ƒë·ªëi m·∫∑t v·ªõi th·ª≠ th√°ch, hay b·∫°n mu·ªën Di·ªáp Th·∫ßn v√† Tuy·∫øt K·ª≥ s·∫Ω ph·∫£i t√¨m c√°ch ngƒÉn ch·∫∑n nh·ªØng sinh v·∫≠t Ngo·∫°i V·ª±c?\nH·∫øt r·ªìi, c√°c b·∫°n c√≥ h·ª©ng ƒë·ªçc th√¨ comment ho·∫∑c g·ª≠i email ƒë·ªÉ m√¨nh post th√™m nh√©.\nC·∫£m ∆°n b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\n","date":"Apr 20, 2025","img":"https://unsplash.it/1920/1080?image=231","permalink":"/blog/2025-04-20-ai-viet-truyen-tuyet-giac-truc-lam/","series":null,"tags":["story"],"title":"Tuy·∫øt Gi√°c Tr√∫c L√¢m - Truy·ªán AI"},{"categories":null,"content":" C√¢n b·∫±ng Nash: Kh√°i ni·ªám v√† ·ª©ng d·ª•ng ·ª®ng d·ª•ng chia th∆∞·ªüng cho nh√¢n vi√™n C√¢n b·∫±ng Nash: Kh√°i ni·ªám v√† ·ª©ng d·ª•ng 1. C√¢n b·∫±ng Nash l√† g√¨? C√¢n b·∫±ng Nash (Nash Equilibrium) l√† m·ªôt kh√°i ni·ªám trong l√Ω thuy·∫øt tr√≤ ch∆°i (game theory), ƒë∆∞·ª£c ƒë·∫∑t theo t√™n c·ªßa nh√† to√°n h·ªçc John Nash, ng∆∞·ªùi ƒë√£ ch·ª©ng minh s·ª± t·ªìn t·∫°i c·ªßa c√¢n b·∫±ng n√†y trong c√°c tr√≤ ch∆°i kh√¥ng h·ª£p t√°c (non-cooperative games). C√¢n b·∫±ng Nash m√¥ t·∫£ m·ªôt tr·∫°ng th√°i m√† m·ªói ng∆∞·ªùi ch∆°i trong tr√≤ ch∆°i ƒë·ªÅu ch·ªçn chi·∫øn l∆∞·ª£c t·ªëi ∆∞u nh·∫•t cho m√¨nh, d·ª±a tr√™n gi·∫£ ƒë·ªãnh r·∫±ng c√°c ƒë·ªëi th·ªß s·∫Ω kh√¥ng thay ƒë·ªïi chi·∫øn l∆∞·ª£c c·ªßa h·ªç.\nƒê·ªãnh nghƒ©a ch√≠nh x√°c: M·ªôt t·∫≠p h·ª£p c√°c chi·∫øn l∆∞·ª£c c·ªßa t·∫•t c·∫£ ng∆∞·ªùi ch∆°i ƒë∆∞·ª£c g·ªçi l√† c√¢n b·∫±ng Nash n·∫øu kh√¥ng c√≥ b·∫•t k·ª≥ ng∆∞·ªùi ch∆°i n√†o c√≥ th·ªÉ c·∫£i thi·ªán k·∫øt qu·∫£ c·ªßa m√¨nh b·∫±ng c√°ch ƒë∆°n ph∆∞∆°ng thay ƒë·ªïi chi·∫øn l∆∞·ª£c c·ªßa ri√™ng m√¨nh. 2. ƒê·∫∑c ƒëi·ªÉm c·ªßa c√¢n b·∫±ng Nash T√≠nh ·ªïn ƒë·ªãnh: Trong tr·∫°ng th√°i c√¢n b·∫±ng Nash, kh√¥ng ai c√≥ ƒë·ªông l·ª±c ƒë·ªÉ thay ƒë·ªïi h√†nh vi c·ªßa m√¨nh v√¨ h·ªç ƒë√£ ƒë·∫°t ƒë∆∞·ª£c l·ª£i √≠ch t·ªët nh·∫•t c√≥ th·ªÉ. Kh√¥ng ph·∫£i lu√¥n t·ªëi ∆∞u Pareto: C√¢n b·∫±ng Nash kh√¥ng nh·∫•t thi·∫øt ph·∫£i l√† gi·∫£i ph√°p t·ªët nh·∫•t cho t·∫•t c·∫£ m·ªçi ng∆∞·ªùi. ƒê√¥i khi, n√≥ c√≥ th·ªÉ d·∫´n ƒë·∫øn \u0026ldquo;k·∫øt c·ª•c bi k·ªãch\u0026rdquo; (tragedy of the commons) ho·∫∑c \u0026ldquo;hi·ªáu ·ª©ng t√π nh√¢n\u0026rdquo; (Prisoner\u0026rsquo;s Dilemma). S·ª± t·ªìn t·∫°i: Theo ƒë·ªãnh l√Ω c·ªßa Nash, m·ªçi tr√≤ ch∆°i h·ªØu h·∫°n v·ªõi s·ªë l∆∞·ª£ng ng∆∞·ªùi ch∆°i v√† chi·∫øn l∆∞·ª£c h·ªØu h·∫°n ƒë·ªÅu c√≥ √≠t nh·∫•t m·ªôt c√¢n b·∫±ng Nash (c√≥ th·ªÉ ·ªü d·∫°ng h·ªón h·ª£p, t·ª©c l√† s·ª≠ d·ª•ng chi·∫øn l∆∞·ª£c ng·∫´u nhi√™n). 3. V√≠ d·ª• v·ªÅ c√¢n b·∫±ng Nash V√≠ d·ª• 1: Tr√≤ ch∆°i \u0026ldquo;Chicken Game\u0026rdquo; (Tr√≤ ch∆°i G√† con)\nHai t√†i x·∫ø l√°i xe lao th·∫≥ng v√†o nhau. N·∫øu c·∫£ hai t·ª´ ch·ªëi nh∆∞·ªùng ƒë∆∞·ªùng, h·ªç s·∫Ω ƒë√¢m nhau v√† thi·ªát h·∫°i n·∫∑ng n·ªÅ. N·∫øu m·ªôt ng∆∞·ªùi nh∆∞·ªùng ƒë∆∞·ªùng (ch·∫°y tho√°t), ng∆∞·ªùi kia s·∫Ω th·∫Øng cu·ªôc.\nB·∫£ng tr·∫£ th∆∞·ªüng:\nNg∆∞·ªùi B nh∆∞·ªùng Ng∆∞·ªùi B kh√¥ng nh∆∞·ªùng Ng∆∞·ªùi A nh∆∞·ªùng (0, 0) (-1, +1) Ng∆∞·ªùi A kh√¥ng nh∆∞·ªùng (+1, -1) (-10, -10) N·∫øu c·∫£ hai ch·ªçn \u0026ldquo;kh√¥ng nh∆∞·ªùng\u0026rdquo;, h·ªç r∆°i v√†o t√¨nh hu·ªëng t·ªá nh·∫•t (-10, -10). ƒê√¢y kh√¥ng ph·∫£i l√† c√¢n b·∫±ng Nash. N·∫øu m·ªôt ng∆∞·ªùi ch·ªçn \u0026ldquo;nh∆∞·ªùng\u0026rdquo; v√† ng∆∞·ªùi kia ch·ªçn \u0026ldquo;kh√¥ng nh∆∞·ªùng\u0026rdquo;, th√¨ ng∆∞·ªùi kh√¥ng nh∆∞·ªùng s·∫Ω c√≥ l·ª£i (+1). Tuy nhi√™n, ƒë√¢y c≈©ng kh√¥ng ph·∫£i l√† c√¢n b·∫±ng Nash v√¨ ng∆∞·ªùi nh∆∞·ªùng c√≥ th·ªÉ thay ƒë·ªïi chi·∫øn l∆∞·ª£c ƒë·ªÉ tr√°nh thi·ªát h·∫°i. C√¢n b·∫±ng Nash x·∫£y ra khi m·ªôt ng∆∞·ªùi nh∆∞·ªùng v√† ng∆∞·ªùi kia kh√¥ng nh∆∞·ªùng, v√≠ d·ª•: (Ng∆∞·ªùi A nh∆∞·ªùng, Ng∆∞·ªùi B kh√¥ng nh∆∞·ªùng) ho·∫∑c ng∆∞·ª£c l·∫°i. V√≠ d·ª• 2: Tr√≤ ch∆°i \u0026ldquo;Prisoner‚Äôs Dilemma\u0026rdquo; (Dilemma c·ªßa T√π nh√¢n)\nHai t√π nh√¢n b·ªã b·∫Øt gi·ªØ v√† b·ªã th·∫©m v·∫•n ri√™ng bi·ªát. H·ªç c√≥ hai l·ª±a ch·ªçn: \u0026ldquo;h·ª£p t√°c\u0026rdquo; (gi·ªØ im l·∫∑ng) ho·∫∑c \u0026ldquo;ph·∫£n b·ªôi\u0026rdquo; (t·ªë c√°o ng∆∞·ªùi kia).\nB·∫£ng tr·∫£ th∆∞·ªüng:\nNg∆∞·ªùi B h·ª£p t√°c Ng∆∞·ªùi B ph·∫£n b·ªôi Ng∆∞·ªùi A h·ª£p t√°c (-1, -1) (-10, 0) Ng∆∞·ªùi A ph·∫£n b·ªôi (0, -10) (-5, -5) N·∫øu c·∫£ hai h·ª£p t√°c, h·ªç nh·∫≠n √°n nh·∫π (-1, -1). N·∫øu m·ªôt ng∆∞·ªùi ph·∫£n b·ªôi v√† ng∆∞·ªùi kia h·ª£p t√°c, ng∆∞·ªùi ph·∫£n b·ªôi ƒë∆∞·ª£c t·ª± do (0) c√≤n ng∆∞·ªùi h·ª£p t√°c ch·ªãu √°n n·∫∑ng (-10). C√¢n b·∫±ng Nash x·∫£y ra khi c·∫£ hai ph·∫£n b·ªôi (-5, -5), v√¨ d√π b√™n kia l√†m g√¨, ph·∫£n b·ªôi v·∫´n l√† chi·∫øn l∆∞·ª£c t·ªëi ∆∞u c√° nh√¢n. 4. ·ª®ng d·ª•ng c·ªßa c√¢n b·∫±ng Nash C√¢n b·∫±ng Nash c√≥ nhi·ªÅu ·ª©ng d·ª•ng trong c√°c lƒ©nh v·ª±c kh√°c nhau, bao g·ªìm:\n4.1. Kinh t·∫ø h·ªçc ƒê·∫•u gi√° v√† c·∫°nh tranh th·ªã tr∆∞·ªùng: C√°c c√¥ng ty trong th·ªã tr∆∞·ªùng c·∫°nh tranh th∆∞·ªùng t√¨m c√°ch ƒë·∫°t ƒë∆∞·ª£c c√¢n b·∫±ng Nash b·∫±ng c√°ch ƒë∆∞a ra m·ª©c gi√° v√† s·∫£n l∆∞·ª£ng t·ªëi ∆∞u ƒë·ªÉ t·ªëi ƒëa h√≥a l·ª£i nhu·∫≠n. Chi·∫øn l∆∞·ª£c ƒë·ªãnh gi√°: C√°c c√¥ng ty l·ªõn nh∆∞ Amazon, Walmart, hay c√°c h√£ng h√†ng kh√¥ng th∆∞·ªùng s·ª≠ d·ª•ng c√¢n b·∫±ng Nash ƒë·ªÉ d·ª± ƒëo√°n h√†nh vi c·ªßa ƒë·ªëi th·ªß v√† ƒëi·ªÅu ch·ªânh chi·∫øn l∆∞·ª£c c·ªßa m√¨nh. 4.2. Ch√≠nh tr·ªã v√† quan h·ªá qu·ªëc t·∫ø ƒê√†m ph√°n v√† xung ƒë·ªôt: C√¢n b·∫±ng Nash gi√∫p ph√¢n t√≠ch c√°c t√¨nh hu·ªëng ƒë√†m ph√°n gi·ªØa c√°c qu·ªëc gia ho·∫∑c c√°c b√™n trong xung ƒë·ªôt, v√≠ d·ª• nh∆∞ th·ªèa thu·∫≠n c·∫Øt gi·∫£m v≈© kh√≠ h·∫°t nh√¢n. Chi·∫øn tranh l·∫°nh: C√¢n b·∫±ng Nash gi·∫£i th√≠ch t·∫°i sao c√°c si√™u c∆∞·ªùng nh∆∞ M·ªπ v√† Li√™n X√¥ duy tr√¨ tr·∫°ng th√°i \u0026ldquo;c√¢n b·∫±ng kh·ªßng b·ªë\u0026rdquo; (Mutually Assured Destruction - MAD), n∆°i kh√¥ng b√™n n√†o d√°m t·∫•n c√¥ng tr∆∞·ªõc. 4.3. Sinh h·ªçc ti·∫øn h√≥a H√†nh vi c·ªßa ƒë·ªông v·∫≠t: C√¢n b·∫±ng Nash ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ gi·∫£i th√≠ch c√°c h√†nh vi ti·∫øn h√≥a c·ªßa ƒë·ªông v·∫≠t, ch·∫≥ng h·∫°n nh∆∞ vi·ªác ch·ªçn b·∫°n ƒë·ªùi ho·∫∑c ph√¢n b·ªï ngu·ªìn l·ª±c trong m√¥i tr∆∞·ªùng s·ªëng. 4.4. C√¥ng ngh·ªá v√† m·∫°ng m√°y t√≠nh Giao th√¥ng m·∫°ng: C√¢n b·∫±ng Nash gi√∫p t·ªëi ∆∞u h√≥a l∆∞u l∆∞·ª£ng m·∫°ng, ƒë·∫£m b·∫£o r·∫±ng c√°c lu·ªìng d·ªØ li·ªáu ƒë∆∞·ª£c ph√¢n ph·ªëi hi·ªáu qu·∫£ v√† tr√°nh t·∫Øc ngh·∫Ωn. Blockchain: Trong c√°c giao d·ªãch ti·ªÅn ƒëi·ªán t·ª≠, c√¢n b·∫±ng Nash ƒë∆∞·ª£c √°p d·ª•ng ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng c√°c n√∫t m·∫°ng ho·∫°t ƒë·ªông trung th·ª±c v√† kh√¥ng ph√° v·ª° h·ªá th·ªëng. 4.5. T√¢m l√Ω h·ªçc v√† x√£ h·ªôi h·ªçc Quy·∫øt ƒë·ªãnh c√° nh√¢n: C√¢n b·∫±ng Nash cung c·∫•p m·ªôt khung l√Ω thuy·∫øt ƒë·ªÉ hi·ªÉu c√°ch con ng∆∞·ªùi ƒë∆∞a ra quy·∫øt ƒë·ªãnh trong c√°c t√¨nh hu·ªëng t∆∞∆°ng t√°c x√£ h·ªôi ph·ª©c t·∫°p. 5. H·∫°n ch·∫ø c·ªßa c√¢n b·∫±ng Nash Kh√¥ng duy nh·∫•t: M·ªôt tr√≤ ch∆°i c√≥ th·ªÉ c√≥ nhi·ªÅu c√¢n b·∫±ng Nash, khi·∫øn vi·ªác d·ª± ƒëo√°n k·∫øt qu·∫£ tr·ªü n√™n kh√≥ khƒÉn. Kh√¥ng ph·∫£i lu√¥n c√¥ng b·∫±ng: C√¢n b·∫±ng Nash ƒë√¥i khi d·∫´n ƒë·∫øn k·∫øt qu·∫£ kh√¥ng mong mu·ªën ho·∫∑c kh√¥ng hi·ªáu qu·∫£ v·ªÅ m·∫∑t x√£ h·ªôi (v√≠ d·ª•: Prisoner\u0026rsquo;s Dilemma). Gi·∫£ ƒë·ªãnh l√Ω t√≠nh: C√¢n b·∫±ng Nash gi·∫£ ƒë·ªãnh r·∫±ng t·∫•t c·∫£ ng∆∞·ªùi ch∆°i ƒë·ªÅu h√†nh ƒë·ªông h·ª£p l√Ω v√† bi·∫øt r√µ chi·∫øn l∆∞·ª£c c·ªßa ƒë·ªëi th·ªß, ƒëi·ªÅu n√†y kh√¥ng ph·∫£i l√∫c n√†o c≈©ng ƒë√∫ng trong th·ª±c t·∫ø. ·ª®ng d·ª•ng chia th∆∞·ªüng cho nh√¢n vi√™n Ch√∫ng ta s·∫Ω ph√¢n t√≠ch m·ªôt t√¨nh hu·ªëng c·ª• th·ªÉ trong doanh nghi·ªáp, n∆°i tr∆∞·ªüng ph√≤ng c·∫ßn quy·∫øt ƒë·ªãnh c√°ch chia th∆∞·ªüng gi·ªØa c√°c nh√¢n vi√™n d·ª±a tr√™n hi·ªáu su·∫•t l√†m vi·ªác. ƒêi·ªÅu n√†y li√™n quan ƒë·∫øn l√Ω thuy·∫øt tr√≤ ch∆°i v√† c√¢n b·∫±ng Nash khi c√°c nh√¢n vi√™n c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh h√†nh vi c·ªßa m√¨nh ƒë·ªÉ t·ªëi ƒëa h√≥a l·ª£i √≠ch c√° nh√¢n.\nT√¨nh hu·ªëng M·ªôt tr∆∞·ªüng ph√≤ng qu·∫£n l√Ω hai nh√¢n vi√™n (A v√† B). Tr∆∞·ªüng ph√≤ng c√≥ m·ªôt kho·∫£n ti·ªÅn th∆∞·ªüng c·ªë ƒë·ªãnh l√† 10 tri·ªáu ƒë·ªìng ƒë·ªÉ chia cho hai nh√¢n vi√™n d·ª±a tr√™n m·ª©c ƒë·ªô ƒë√≥ng g√≥p c·ªßa h·ªç v√†o d·ª± √°n. Tuy nhi√™n, tr∆∞·ªüng ph√≤ng kh√¥ng th·ªÉ gi√°m s√°t ho√†n to√†n nƒÉng su·∫•t th·ª±c t·∫ø c·ªßa t·ª´ng ng∆∞·ªùi, m√† ch·ªâ c√≥ th·ªÉ ƒë√°nh gi√° qua k·∫øt qu·∫£ b√°o c√°o c·ªßa h·ªç.\nChi·∫øn l∆∞·ª£c c·ªßa nh√¢n vi√™n:\nL√†m vi·ªác chƒÉm ch·ªâ (C): ƒê√≤i h·ªèi n·ªó l·ª±c cao nh∆∞ng c√≥ kh·∫£ nƒÉng ƒë·∫°t k·∫øt qu·∫£ t·ªët. L√†m vi·ªác l∆∞·ªùi bi·∫øng (L): Ti·∫øt ki·ªám c√¥ng s·ª©c nh∆∞ng k·∫øt qu·∫£ k√©m h∆°n. Quy t·∫Øc chia th∆∞·ªüng:\nN·∫øu c·∫£ hai c√πng l√†m vi·ªác chƒÉm ch·ªâ (C, C), m·ªói ng∆∞·ªùi nh·∫≠n ƒë∆∞·ª£c 5 tri·ªáu ƒë·ªìng. N·∫øu m·ªôt ng∆∞·ªùi l√†m vi·ªác chƒÉm ch·ªâ v√† ng∆∞·ªùi kia l∆∞·ªùi bi·∫øng (C, L ho·∫∑c L, C), ng∆∞·ªùi l√†m vi·ªác chƒÉm ch·ªâ nh·∫≠n 3 tri·ªáu ƒë·ªìng, ng∆∞·ªùi l∆∞·ªùi bi·∫øng nh·∫≠n 7 tri·ªáu ƒë·ªìng (do ng∆∞·ªùi l∆∞·ªùi bi·∫øng \u0026ldquo;l·ª£i d·ª•ng\u0026rdquo; k·∫øt qu·∫£ c·ªßa ng∆∞·ªùi kh√°c). N·∫øu c·∫£ hai ƒë·ªÅu l∆∞·ªùi bi·∫øng (L, L), m·ªói ng∆∞·ªùi ch·ªâ nh·∫≠n ƒë∆∞·ª£c 2 tri·ªáu ƒë·ªìng (do k·∫øt qu·∫£ d·ª± √°n k√©m). Ma tr·∫≠n tr·∫£ th∆∞·ªüng B·∫£ng tr·∫£ th∆∞·ªüng (ƒë∆°n v·ªã: tri·ªáu ƒë·ªìng):\nNh√¢n vi√™n B: ChƒÉm ch·ªâ (C) Nh√¢n vi√™n B: L∆∞·ªùi bi·∫øng (L) Nh√¢n vi√™n A: ChƒÉm ch·ªâ (C) (5, 5) (3, 7) Nh√¢n vi√™n A: L∆∞·ªùi bi·∫øng (L) (7, 3) (2, 2) Ph√¢n t√≠ch c√¢n b·∫±ng Nash Ch√∫ng ta s·∫Ω x√°c ƒë·ªãnh chi·∫øn l∆∞·ª£c t·ªëi ∆∞u cho t·ª´ng nh√¢n vi√™n:\nN·∫øu nh√¢n vi√™n B ch·ªçn \u0026ldquo;ChƒÉm ch·ªâ (C)\u0026rdquo;:\nN·∫øu A ch·ªçn \u0026ldquo;ChƒÉm ch·ªâ (C)\u0026rdquo;, A nh·∫≠n 5 tri·ªáu. N·∫øu A ch·ªçn \u0026ldquo;L∆∞·ªùi bi·∫øng (L)\u0026rdquo;, A nh·∫≠n 7 tri·ªáu. =\u0026gt; A s·∫Ω ch·ªçn \u0026ldquo;L∆∞·ªùi bi·∫øng (L)\u0026rdquo; v√¨ 7 \u0026gt; 5. N·∫øu nh√¢n vi√™n B ch·ªçn \u0026ldquo;L∆∞·ªùi bi·∫øng (L)\u0026rdquo;:\nN·∫øu A ch·ªçn \u0026ldquo;ChƒÉm ch·ªâ (C)\u0026rdquo;, A nh·∫≠n 3 tri·ªáu. N·∫øu A ch·ªçn \u0026ldquo;L∆∞·ªùi bi·∫øng (L)\u0026rdquo;, A nh·∫≠n 2 tri·ªáu. =\u0026gt; A s·∫Ω ch·ªçn \u0026ldquo;L∆∞·ªùi bi·∫øng (L)\u0026rdquo; v√¨ 2 \u0026lt; 3. K·∫øt lu·∫≠n: D√π B ch·ªçn g√¨, A lu√¥n c√≥ ƒë·ªông l·ª±c ch·ªçn \u0026ldquo;L∆∞·ªùi bi·∫øng (L)\u0026rdquo;. T∆∞∆°ng t·ª±, n·∫øu ph√¢n t√≠ch ng∆∞·ª£c l·∫°i t·ª´ g√≥c ƒë·ªô c·ªßa B, B c≈©ng s·∫Ω ch·ªçn \u0026ldquo;L∆∞·ªùi bi·∫øng (L)\u0026rdquo;.\n=\u0026gt; C√¢n b·∫±ng Nash x·∫£y ra khi c·∫£ A v√† B ƒë·ªÅu ch·ªçn \u0026ldquo;L∆∞·ªùi bi·∫øng (L)\u0026rdquo;, d·∫´n ƒë·∫øn m·ªói ng∆∞·ªùi nh·∫≠n 2 tri·ªáu ƒë·ªìng.\n√ù nghƒ©a trong doanh nghi·ªáp Hi·ªáu qu·∫£ th·∫•p: M·∫∑c d√π c·∫£ hai nh√¢n vi√™n ƒë·ªÅu c√≥ th·ªÉ nh·∫≠n ƒë∆∞·ª£c 5 tri·ªáu ƒë·ªìng n·∫øu c√πng l√†m vi·ªác chƒÉm ch·ªâ, h·ªç l·∫°i r∆°i v√†o tr·∫°ng th√°i c√¢n b·∫±ng Nash v·ªõi k·∫øt qu·∫£ t·ªá h∆°n (2 tri·ªáu ƒë·ªìng m·ªói ng∆∞·ªùi). ƒê√¢y l√† m·ªôt v√≠ d·ª• ƒëi·ªÉn h√¨nh c·ªßa \u0026ldquo;Dilemma c·ªßa T√π nh√¢n\u0026rdquo; (Prisoner\u0026rsquo;s Dilemma). Nguy√™n nh√¢n: Do thi·∫øu s·ª± ph·ªëi h·ª£p v√† l√≤ng tin gi·ªØa c√°c nh√¢n vi√™n, m·ªói ng∆∞·ªùi ch·ªâ nghƒ© ƒë·∫øn l·ª£i √≠ch c√° nh√¢n thay v√¨ l·ª£i √≠ch t·∫≠p th·ªÉ. Gi·∫£i ph√°p: Tr∆∞·ªüng ph√≤ng c√≥ th·ªÉ √°p d·ª•ng c√°c bi·ªán ph√°p nh∆∞: X√¢y d·ª±ng h·ªá th·ªëng gi√°m s√°t: ƒê·∫£m b·∫£o r·∫±ng nƒÉng su·∫•t th·ª±c t·∫ø c·ªßa nh√¢n vi√™n ƒë∆∞·ª£c ƒëo l∆∞·ªùng ch√≠nh x√°c. Khuy·∫øn kh√≠ch tinh th·∫ßn ƒë·ªìng ƒë·ªôi: T·∫°o m√¥i tr∆∞·ªùng l√†m vi·ªác khuy·∫øn kh√≠ch h·ª£p t√°c v√† chia s·∫ª l·ª£i √≠ch. Th∆∞·ªüng theo nh√≥m: Thay v√¨ chia th∆∞·ªüng c√° nh√¢n, tr∆∞·ªüng ph√≤ng c√≥ th·ªÉ th∆∞·ªüng d·ª±a tr√™n k·∫øt qu·∫£ chung c·ªßa c·∫£ nh√≥m, gi·∫£m ƒë·ªông c∆° l∆∞·ªùi bi·∫øng c√° nh√¢n. B√†i vi·∫øt d∆∞·ªõi g√≥c nh√¨n c·ªßa m·ªôt con IT qu√®n, th·∫±ng IT l·ªè, vi·∫øt v·ªÅ m·ªôt v·∫•n ƒë·ªÅ kinh t·∫ø, b√† con chuy√™n ng√†nh th·∫•y sai th√¨ hoan h·ªâ c√≤m m√™n nh·∫π nh√†ng, ƒë·ª´ng bu√¥n l·ªùi cay ƒë·∫Øng.\nC·∫£m ∆°n b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\nNgu·ªìn tham kh·∫£o\ng√µ t·ª´ kho√° Nash Equilibrium\nNash, John F. (1950). \u0026ldquo;Equilibrium Points in N-Person Games.\u0026rdquo; Proceedings of the National Academy of Sciences . -\u0026gt; B√†i b√°o c·ªßa John Nash, gi·ªõi thi·ªáu kh√°i ni·ªám c√¢n b·∫±ng Nash.\nMyerson, Roger B. (1997). Game Theory: Analysis of Conflict. Harvard University Press. S√°ch gi√°o khoa\nOsborne, Martin J., \u0026amp; Rubinstein, Ariel. (1994). A Course in Game Theory. MIT Press. S√°ch gi√°o khoa\nGibbons, Robert. (1992). A Primer in Game Theory. Pearson Education. - S√°ch v·ªÅ l√Ω thuy·∫øt tr√≤ ch∆°i, v·ªõi nhi·ªÅu v√≠ d·ª• th·ª±c t·∫ø, th√≠ch h·ª£p cho ng∆∞·ªùi m·ªõi t√¨m hi·ªÉu .\n","date":"Apr 11, 2025","img":"https://unsplash.it/1920/1080?image=230","permalink":"/blog/2025-04-11-hash-equilibrium/","series":null,"tags":["Game Theory"],"title":"C√¢n B·∫±ng Nash - Nash Equilibrium"},{"categories":null,"content":" Gi·ªõi thi·ªáu v·ªÅ Prisoner‚Äôs Dilemma (Song ƒë·ªÅ t√π nh√¢n) ·ª®ng d·ª•ng c·ªßa Prisoner‚Äôs Dilemma ·ª®ng d·ª•ng Chia th∆∞·ªüng gi·ªØa c√°c nh√¢n vi√™n* ·ª®ng d·ª•ng th·ª±c t·∫ø trong doanh nghi·ªáp: √ù nghƒ©a t·ªïng qu√°t Gi·ªõi thi·ªáu v·ªÅ Prisoner‚Äôs Dilemma (Song ƒë·ªÅ t√π nh√¢n) Prisoner‚Äôs Dilemma l√† m·ªôt trong nh·ªØng kh√°i ni·ªám quan tr·ªçng nh·∫•t trong l√Ω thuy·∫øt tr√≤ ch∆°i (Game Theory), ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi hai nh√† to√°n h·ªçc Merrill Flood v√† Melvin Dresher v√†o nƒÉm 1950, v√† sau ƒë√≥ ƒë∆∞·ª£c Albert W. Tucker ƒë·∫∑t t√™n v√† minh h·ªça b·∫±ng c√¢u chuy·ªán v·ªÅ hai t√π nh√¢n.\nC√¢u chuy·ªán ƒëi·ªÉn h√¨nh c·ªßa Prisoner‚Äôs Dilemma Hai nghi ph·∫°m (A v√† B) b·ªã b·∫Øt v√¨ li√™n quan ƒë·∫øn m·ªôt v·ª• √°n. C·∫£nh s√°t kh√¥ng c√≥ ƒë·ªß b·∫±ng ch·ª©ng ƒë·ªÉ k·∫øt t·ªôi c·∫£ hai n·∫øu h·ªç kh√¥ng khai b√°o g√¨. Do ƒë√≥, c·∫£nh s√°t t√°ch h·ªç ra v√† ƒë∆∞a ra c√°c l·ª±a ch·ªçn nh∆∞ sau:\nN·∫øu c·∫£ hai im l·∫∑ng (h·ª£p t√°c v·ªõi nhau), m·ªói ng∆∞·ªùi s·∫Ω ch·ªâ ph·∫£i ng·ªìi t√π 1 nƒÉm v√¨ m·ªôt t·ªôi nh·∫π. N·∫øu m·ªôt ng∆∞·ªùi khai b√°o (ph·∫£n b·ªôi) v√† ng∆∞·ªùi kia im l·∫∑ng, ng∆∞·ªùi khai b√°o s·∫Ω ƒë∆∞·ª£c mi·ªÖn √°n t√π (0 nƒÉm) trong khi ng∆∞·ªùi im l·∫∑ng s·∫Ω ch·ªãu √°n 3 nƒÉm. N·∫øu c·∫£ hai c√πng khai b√°o (c·∫£ hai ph·∫£n b·ªôi nhau), m·ªói ng∆∞·ªùi s·∫Ω ph·∫£i ch·ªãu √°n 2 nƒÉm. K·∫øt qu·∫£ n√†y ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ma tr·∫≠n th∆∞·ªüng ph·∫°t:\nB Im L·∫∑ng B Khai B√°o A Im L·∫∑ng (-1, -1) (-3, 0) A Khai B√°o (0, -3) (-2, -2) Trong ƒë√≥, s·ªë ƒë·∫ßu ti√™n l√† s·ªë nƒÉm t√π c·ªßa A, s·ªë th·ª© hai l√† s·ªë nƒÉm t√π c·ªßa B.\nPh√¢n t√≠ch chi·∫øn l∆∞·ª£c Chi·∫øn l∆∞·ª£c h·ª£p t√°c (Im l·∫∑ng): C·∫£ hai ƒë·ªÅu im l·∫∑ng v√† nh·∫≠n 1 nƒÉm t√π. Chi·∫øn l∆∞·ª£c ph·∫£n b·ªôi (Khai b√°o): M·ªôt ng∆∞·ªùi ph·∫£n b·ªôi v√† ng∆∞·ªùi kia h·ª£p t√°c ‚Üí ng∆∞·ªùi ph·∫£n b·ªôi ƒë∆∞·ª£c t·ª± do, ng∆∞·ªùi h·ª£p t√°c ch·ªãu √°n n·∫∑ng. C·∫£ hai ph·∫£n b·ªôi: C·∫£ hai ƒë·ªÅu nh·∫≠n √°n 2 nƒÉm t√π. N·∫øu x√©t t·ª´ g√≥c ƒë·ªô c√° nh√¢n:\nM·ªói ng∆∞·ªùi ƒë·ªÅu c√≥ ƒë·ªông l·ª±c ƒë·ªÉ khai b√°o (ph·∫£n b·ªôi) v√¨ ƒëi·ªÅu n√†y mang l·∫°i l·ª£i √≠ch c√° nh√¢n t·ªët h∆°n (mi·ªÖn √°n ho·∫∑c √≠t nh·∫•t l√† 2 nƒÉm t√π thay v√¨ 3 nƒÉm). Tuy nhi√™n, n·∫øu c·∫£ hai c√πng ph·∫£n b·ªôi, k·∫øt qu·∫£ cu·ªëi c√πng (2 nƒÉm t√π cho m·ªói ng∆∞·ªùi) l·∫°i t·ªìi t·ªá h∆°n so v·ªõi tr∆∞·ªùng h·ª£p c·∫£ hai c√πng h·ª£p t√°c (1 nƒÉm t√π). ƒê√¢y ch√≠nh l√† \u0026ldquo;dilemma\u0026rdquo; (song ƒë·ªÅ): l·ª£i √≠ch c√° nh√¢n d·∫´n ƒë·∫øn k·∫øt qu·∫£ t·∫≠p th·ªÉ k√©m hi·ªáu qu·∫£.\n·ª®ng d·ª•ng c·ªßa Prisoner‚Äôs Dilemma Prisoner‚Äôs Dilemma kh√¥ng ch·ªâ l√† m·ªôt b√†i to√°n l√Ω thuy·∫øt m√† c√≤n c√≥ nhi·ªÅu ·ª©ng d·ª•ng th·ª±c t·∫ø trong c√°c lƒ©nh v·ª±c kh√°c nhau:\n1. Kinh t·∫ø v√† Kinh doanh C·∫°nh tranh gi√° c·∫£: Hai c√¥ng ty c·∫°nh tranh c√≥ th·ªÉ ch·ªçn gi·ªØa vi·ªác gi·ªØ gi√° cao (h·ª£p t√°c) ho·∫∑c gi·∫£m gi√° ƒë·ªÉ gi√†nh th·ªã ph·∫ßn (ph·∫£n b·ªôi). N·∫øu c·∫£ hai gi·∫£m gi√°, l·ª£i nhu·∫≠n c·ªßa c·∫£ hai s·∫Ω gi·∫£m s√∫t. Qu·∫£ng c√°o: Hai c√¥ng ty c√≥ th·ªÉ ch·ªçn chi nhi·ªÅu ti·ªÅn cho qu·∫£ng c√°o (ph·∫£n b·ªôi) ho·∫∑c c√πng h·∫°n ch·∫ø ng√¢n s√°ch qu·∫£ng c√°o (h·ª£p t√°c). N·∫øu c·∫£ hai c√πng tƒÉng chi ti√™u, l·ª£i nhu·∫≠n r√≤ng c√≥ th·ªÉ gi·∫£m. OPEC v√† s·∫£n l∆∞·ª£ng d·∫ßu m·ªè: C√°c qu·ªëc gia th√†nh vi√™n OPEC c√≥ th·ªÉ ch·ªçn tu√¢n th·ªß th·ªèa thu·∫≠n c·∫Øt gi·∫£m s·∫£n l∆∞·ª£ng (h·ª£p t√°c) ho·∫∑c tƒÉng s·∫£n l∆∞·ª£ng ƒë·ªÉ ki·∫øm l·ª£i nhu·∫≠n c√° nh√¢n (ph·∫£n b·ªôi). N·∫øu t·∫•t c·∫£ tƒÉng s·∫£n l∆∞·ª£ng, gi√° d·∫ßu s·∫Ω gi·∫£m, g√¢y thi·ªát h·∫°i chung. 2. Ch√≠nh tr·ªã v√† Ngo·∫°i giao Gi·∫£i tr·ª´ v≈© kh√≠ h·∫°t nh√¢n: C√°c qu·ªëc gia c√≥ th·ªÉ ch·ªçn gi·ªØa gi·∫£i tr·ª´ v≈© kh√≠ (h·ª£p t√°c) ho·∫∑c ti·∫øp t·ª•c ph√°t tri·ªÉn v≈© kh√≠ (ph·∫£n b·ªôi). N·∫øu m·ªôt n∆∞·ªõc ph·∫£n b·ªôi, h·ªç c√≥ l·ª£i th·∫ø qu√¢n s·ª±; n·∫øu c·∫£ hai c√πng ph√°t tri·ªÉn, nguy c∆° chi·∫øn tranh tƒÉng l√™n. Hi·ªáp ƒë·ªãnh m√¥i tr∆∞·ªùng: C√°c qu·ªëc gia c√≥ th·ªÉ h·ª£p t√°c ƒë·ªÉ gi·∫£m ph√°t th·∫£i kh√≠ nh√† k√≠nh ho·∫∑c ti·∫øp t·ª•c ph√°t tri·ªÉn c√¥ng nghi·ªáp m√† kh√¥ng quan t√¢m ƒë·∫øn m√¥i tr∆∞·ªùng. N·∫øu t·∫•t c·∫£ ph·∫£n b·ªôi, bi·∫øn ƒë·ªïi kh√≠ h·∫≠u s·∫Ω tr·ªü n√™n nghi√™m tr·ªçng h∆°n. 3. X√£ h·ªôi v√† T√¢m l√Ω h·ªçc H√†nh vi x√£ h·ªôi: Trong c√°c m·ªëi quan h·ªá c√° nh√¢n, ng∆∞·ªùi ta th∆∞·ªùng ƒë·ªëi m·∫∑t v·ªõi l·ª±a ch·ªçn gi·ªØa h·ª£p t√°c (gi√∫p ƒë·ª° ng∆∞·ªùi kh√°c) ho·∫∑c ph·∫£n b·ªôi (t·ª± b·∫£o v·ªá l·ª£i √≠ch c√° nh√¢n). V√≠ d·ª•: ƒë√≥ng g√≥p v√†o qu·ªπ c·ªông ƒë·ªìng hay gi·ªØ ti·ªÅn cho b·∫£n th√¢n. Tin t∆∞·ªüng v√† l√≤ng trung th√†nh: Song ƒë·ªÅ t√π nh√¢n gi√∫p gi·∫£i th√≠ch t·∫°i sao con ng∆∞·ªùi ƒë√¥i khi ch·ªçn h·ª£p t√°c d√π c√≥ nguy c∆° b·ªã ph·∫£n b·ªôi ‚Äì ƒëi·ªÅu n√†y li√™n quan ƒë·∫øn x√¢y d·ª±ng ni·ªÅm tin l√¢u d√†i. 4. Sinh h·ªçc v√† Ti·∫øn h√≥a H·ª£p t√°c trong t·ª± nhi√™n: Trong sinh h·ªçc ti·∫øn h√≥a, c√°c lo√†i ƒë·ªông v·∫≠t c√≥ th·ªÉ h·ª£p t√°c ƒë·ªÉ sƒÉn m·ªìi ho·∫∑c b·∫£o v·ªá l√£nh th·ªï. Tuy nhi√™n, h√†nh vi ph·∫£n b·ªôi (ƒÉn tr·ªôm th·ª©c ƒÉn c·ªßa ƒë·ªìng lo·∫°i) c≈©ng t·ªìn t·∫°i. L·ª±a ch·ªçn di truy·ªÅn: C√°c c√° th·ªÉ trong m·ªôt qu·∫ßn th·ªÉ c√≥ th·ªÉ ch·ªçn h·ª£p t√°c ƒë·ªÉ ƒë·∫£m b·∫£o s·ª± s·ªëng c√≤n c·ªßa c·∫£ nh√≥m ho·∫∑c c·∫°nh tranh ƒë·ªÉ t·ªëi ƒëa h√≥a kh·∫£ nƒÉng sinh s·∫£n c√° nh√¢n. 5. C√¥ng ngh·ªá v√† An ninh m·∫°ng Ph√≤ng ch·ªëng t·∫•n c√¥ng m·∫°ng: Hai t·ªï ch·ª©c c√≥ th·ªÉ h·ª£p t√°c ƒë·ªÉ b·∫£o v·ªá h·ªá th·ªëng m·∫°ng ho·∫∑c c·ªë g·∫Øng ti·∫øt ki·ªám chi ph√≠ b·∫±ng c√°ch b·ªè qua c√°c bi·ªán ph√°p an ninh. N·∫øu c·∫£ hai ƒë·ªÅu b·ªè qua, c·∫£ hai ƒë·ªÅu d·ªÖ b·ªã t·∫•n c√¥ng. Chia s·∫ª th√¥ng tin: C√°c c√¥ng ty c√¥ng ngh·ªá c√≥ th·ªÉ ch·ªçn chia s·∫ª d·ªØ li·ªáu ƒë·ªÉ c·∫£i thi·ªán s·∫£n ph·∫©m ho·∫∑c gi·ªØ b√≠ m·∫≠t ƒë·ªÉ duy tr√¨ l·ª£i th·∫ø c·∫°nh tranh. 6. Tr√≤ ch∆°i l·∫∑p ƒëi l·∫∑p l·∫°i (Iterated Prisoner‚Äôs Dilemma) Trong phi√™n b·∫£n l·∫∑p ƒëi l·∫∑p l·∫°i c·ªßa song ƒë·ªÅ t√π nh√¢n, c√°c b√™n t∆∞∆°ng t√°c nhi·ªÅu l·∫ßn. ƒêi·ªÅu n√†y m·ªü ra c∆° h·ªôi ƒë·ªÉ x√¢y d·ª±ng ni·ªÅm tin v√† √°p d·ª•ng chi·∫øn l∆∞·ª£c h·ª£p t√°c l√¢u d√†i. M·ªôt chi·∫øn l∆∞·ª£c n·ªïi ti·∫øng l√† \u0026ldquo;Tit-for-Tat\u0026rdquo; (ƒÉn mi·∫øng tr·∫£ mi·∫øng):\nB·∫Øt ƒë·∫ßu b·∫±ng vi·ªác h·ª£p t√°c. Sau ƒë√≥, l√†m theo h√†nh ƒë·ªông c·ªßa ƒë·ªëi ph∆∞∆°ng ·ªü v√≤ng tr∆∞·ªõc. Chi·∫øn l∆∞·ª£c n√†y ƒë√£ ƒë∆∞·ª£c ch·ª©ng minh l√† r·∫•t hi·ªáu qu·∫£ trong vi·ªác khuy·∫øn kh√≠ch h·ª£p t√°c. ·ª®ng d·ª•ng Chia th∆∞·ªüng gi·ªØa c√°c nh√¢n vi√™n* H√£y t∆∞·ªüng t∆∞·ª£ng m·ªôt t√¨nh hu·ªëng trong m·ªôt c√¥ng ty, n∆°i √¥ng tr∆∞·ªüng ph√≤ng c·∫ßn chia th∆∞·ªüng d·ª±a tr√™n hi·ªáu su·∫•t l√†m vi·ªác c·ªßa hai nh√¢n vi√™n (A v√† B). Ti·ªÅn th∆∞·ªüng c√≥ th·ªÉ ƒë∆∞·ª£c ph√¢n b·ªï theo c√°ch h·ª£p t√°c ho·∫∑c c·∫°nh tranh, t√πy thu·ªôc v√†o h√†nh vi c·ªßa hai nh√¢n vi√™n. ƒêi·ªÅu n√†y t·∫°o ra m·ªôt t√¨nh hu·ªëng t∆∞∆°ng t·ª± nh∆∞ Prisoner‚Äôs Dilemma.\nT√¨nh hu·ªëng c·ª• th·ªÉ: √îng tr∆∞·ªüng ph√≤ng th√¥ng b√°o r·∫±ng s·∫Ω c√≥ m·ªôt kho·∫£n ti·ªÅn th∆∞·ªüng l·ªõn cho nh√≥m n·∫øu c·∫£ hai nh√¢n vi√™n c√πng h·ª£p t√°c ƒë·ªÉ ho√†n th√†nh m·ªôt d·ª± √°n quan tr·ªçng. Tuy nhi√™n, n·∫øu m·ªôt ng∆∞·ªùi c·ªë g·∫Øng \u0026ldquo;ph·∫£n b·ªôi\u0026rdquo; b·∫±ng c√°ch ch·ªâ t·∫≠p trung v√†o l·ª£i √≠ch c√° nh√¢n (ch·∫≥ng h·∫°n, l√†m vi·ªác √≠t h∆°n nh∆∞ng v·∫´n c·ªë g·∫Øng nh·∫≠n ph·∫ßn th∆∞·ªüng l·ªõn), th√¨ ng∆∞·ªùi kia s·∫Ω ch·ªãu thi·ªát th√≤i. N·∫øu c·∫£ hai c√πng ph·∫£n b·ªôi (c·∫£ hai ƒë·ªÅu l∆∞·ªùi bi·∫øng ho·∫∑c kh√¥ng h·ª£p t√°c), d·ª± √°n s·∫Ω th·∫•t b·∫°i v√† c·∫£ hai ƒë·ªÅu kh√¥ng nh·∫≠n ƒë∆∞·ª£c th∆∞·ªüng. Ma tr·∫≠n th∆∞·ªüng ph·∫°t: Ch√∫ng ta c√≥ th·ªÉ bi·ªÉu di·ªÖn t√¨nh hu·ªëng n√†y d∆∞·ªõi d·∫°ng ma tr·∫≠n th∆∞·ªüng ph·∫°t:\nB H·ª£p T√°c B Kh√¥ng H·ª£p T√°c A H·ª£p T√°c (5 tri·ªáu, 5 tri·ªáu) (1 tri·ªáu, 8 tri·ªáu) A Kh√¥ng H·ª£p T√°c (8 tri·ªáu, 1 tri·ªáu) (2 tri·ªáu, 2 tri·ªáu) Trong ƒë√≥:\nS·ªë ƒë·∫ßu ti√™n l√† s·ªë ti·ªÅn th∆∞·ªüng c·ªßa A. S·ªë th·ª© hai l√† s·ªë ti·ªÅn th∆∞·ªüng c·ªßa B. Ph√¢n t√≠ch chi·∫øn l∆∞·ª£c: C·∫£ hai h·ª£p t√°c:\nC·∫£ A v√† B ƒë·ªÅu l√†m vi·ªác chƒÉm ch·ªâ v√† ho√†n th√†nh d·ª± √°n t·ªët. M·ªói ng∆∞·ªùi nh·∫≠n ƒë∆∞·ª£c 5 tri·ªáu ƒë·ªìng. ƒê√¢y l√† k·∫øt qu·∫£ t·ªëi ∆∞u cho c·∫£ hai. M·ªôt ng∆∞·ªùi h·ª£p t√°c, ng∆∞·ªùi kia kh√¥ng h·ª£p t√°c:\nN·∫øu A h·ª£p t√°c v√† B kh√¥ng h·ª£p t√°c: A nh·∫≠n 1 tri·ªáu (do ph·∫£i g√°nh v√°c ph·∫ßn vi·ªác c·ªßa B), trong khi B nh·∫≠n 8 tri·ªáu (v√¨ kh√¥ng l√†m g√¨ nh∆∞ng v·∫´n ƒë∆∞·ª£c th∆∞·ªüng). Ng∆∞·ª£c l·∫°i, n·∫øu B h·ª£p t√°c v√† A kh√¥ng h·ª£p t√°c: B nh·∫≠n 1 tri·ªáu, A nh·∫≠n 8 tri·ªáu. C·∫£ hai kh√¥ng h·ª£p t√°c:\nD·ª± √°n th·∫•t b·∫°i v√¨ c·∫£ hai ƒë·ªÅu l∆∞·ªùi bi·∫øng. M·ªói ng∆∞·ªùi ch·ªâ nh·∫≠n ƒë∆∞·ª£c 2 tri·ªáu ƒë·ªìng. Song ƒë·ªÅ trong t√¨nh hu·ªëng n√†y: N·∫øu x√©t t·ª´ g√≥c ƒë·ªô c√° nh√¢n:\nM·ªói nh√¢n vi√™n ƒë·ªÅu c√≥ ƒë·ªông l·ª±c ƒë·ªÉ kh√¥ng h·ª£p t√°c (ph·∫£n b·ªôi) v√¨ ƒëi·ªÅu n√†y mang l·∫°i l·ª£i √≠ch c√° nh√¢n cao h∆°n trong ng·∫Øn h·∫°n (8 tri·ªáu so v·ªõi 5 tri·ªáu n·∫øu h·ª£p t√°c). Tuy nhi√™n, n·∫øu c·∫£ hai c√πng kh√¥ng h·ª£p t√°c, k·∫øt qu·∫£ cu·ªëi c√πng (2 tri·ªáu cho m·ªói ng∆∞·ªùi) l·∫°i k√©m h∆°n nhi·ªÅu so v·ªõi tr∆∞·ªùng h·ª£p c·∫£ hai c√πng h·ª£p t√°c (5 tri·ªáu cho m·ªói ng∆∞·ªùi). T·ª´ g√≥c ƒë·ªô t·∫≠p th·ªÉ:\nK·∫øt qu·∫£ t·ªët nh·∫•t cho c·∫£ nh√≥m l√† c·∫£ hai c√πng h·ª£p t√°c, nh∆∞ng ƒë·ªông c∆° c√° nh√¢n khi·∫øn h·ªç d·ªÖ d√†ng r∆°i v√†o t√¨nh tr·∫°ng kh√¥ng h·ª£p t√°c. ·ª®ng d·ª•ng th·ª±c t·∫ø trong doanh nghi·ªáp: Khuy·∫øn kh√≠ch h·ª£p t√°c:\n√îng tr∆∞·ªüng ph√≤ng c√≥ th·ªÉ thi·∫øt k·∫ø h·ªá th·ªëng th∆∞·ªüng sao cho vi·ªác h·ª£p t√°c tr·ªü n√™n h·∫•p d·∫´n h∆°n. V√≠ d·ª•: Th∆∞·ªüng th√™m n·∫øu c·∫£ nh√≥m ho√†n th√†nh m·ª•c ti√™u chung. √Åp d·ª•ng h√¨nh ph·∫°t n·∫øu m·ªôt ng∆∞·ªùi kh√¥ng ƒë√≥ng g√≥p ƒë·ªß (v√≠ d·ª•: gi·∫£m l∆∞∆°ng ho·∫∑c c·∫Øt th∆∞·ªüng c√° nh√¢n). X√¢y d·ª±ng l√≤ng tin:\nN·∫øu hai nh√¢n vi√™n ƒë√£ t·ª´ng h·ª£p t√°c th√†nh c√¥ng trong qu√° kh·ª©, h·ªç s·∫Ω c√≥ xu h∆∞·ªõng tin t∆∞·ªüng nhau h∆°n v√† ti·∫øp t·ª•c h·ª£p t√°c trong t∆∞∆°ng lai. Minh b·∫°ch h√≥a quy tr√¨nh:\nC√¥ng khai m·ª©c ƒë·ªô ƒë√≥ng g√≥p c·ªßa t·ª´ng ng∆∞·ªùi ƒë·ªÉ tr√°nh t√¨nh tr·∫°ng \u0026ldquo;ƒÉn b√°m\u0026rdquo; ho·∫∑c l·ª£i d·ª•ng ng∆∞·ªùi kh√°c. √Åp d·ª•ng chi·∫øn l∆∞·ª£c d√†i h·∫°n (Iterated Prisoner‚Äôs Dilemma):\nN·∫øu hai nh√¢n vi√™n ph·∫£i l√†m vi·ªác c√πng nhau nhi·ªÅu l·∫ßn, h·ªç s·∫Ω nh·∫≠n ra r·∫±ng h·ª£p t√°c l√¢u d√†i mang l·∫°i l·ª£i √≠ch l·ªõn h∆°n. ƒêi·ªÅu n√†y khuy·∫øn kh√≠ch h·ªç ch·ªçn h·ª£p t√°c thay v√¨ ph·∫£n b·ªôi. √ù nghƒ©a t·ªïng qu√°t Prisoner‚Äôs Dilemma l√† m·ªôt m√¥ h√¨nh ƒë∆°n gi·∫£n nh∆∞ng s√¢u s·∫Øc, gi√∫p ch√∫ng ta hi·ªÉu r√µ s·ª± xung ƒë·ªôt gi·ªØa l·ª£i √≠ch c√° nh√¢n v√† l·ª£i √≠ch t·∫≠p th·ªÉ. N√≥ gi·∫£i th√≠ch t·∫°i sao con ng∆∞·ªùi v√† t·ªï ch·ª©c th∆∞·ªùng kh√≥ ƒë·∫°t ƒë∆∞·ª£c h·ª£p t√°c ho√†n h·∫£o, ngay c·∫£ khi ƒëi·ªÅu ƒë√≥ c√≥ l·ª£i cho t·∫•t c·∫£. ƒê·ªìng th·ªùi, n√≥ c≈©ng g·ª£i √Ω r·∫±ng c√°c c∆° ch·∫ø khuy·∫øn kh√≠ch h·ª£p t√°c (nh∆∞ th·ªèa thu·∫≠n, lu·∫≠t ph√°p, ho·∫∑c l√≤ng tin) l√† c·∫ßn thi·∫øt ƒë·ªÉ v∆∞·ª£t qua nh·ªØng t√¨nh hu·ªëng t∆∞∆°ng t·ª± trong cu·ªôc s·ªëng.\nB√†i vi·∫øt d∆∞·ªõi g√≥c nh√¨n c·ªßa m·ªôt con IT qu√®n, th·∫±ng IT l·ªè, vi·∫øt v·ªÅ m·ªôt v·∫•n ƒë·ªÅ kinh t·∫ø, b√† con chuy√™n ng√†nh th·∫•y sai th√¨ hoan h·ªâ c√≤m m√™n nh·∫π nh√†ng, ƒë·ª´ng bu√¥n l·ªùi cay ƒë·∫Øng.\nC·∫£m ∆°n b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\nNgu·ªìn tham kh·∫£o\ng√µ t·ª´ kho√° Prisoner‚Äôs Dilemma\nAxelrod, Robert. (1984). The Evolution of Cooperation . Basic Books. - S√°ch kinh ƒëi·ªÉn, n√™n ƒë·ªçc\nDixit, Avinash K., \u0026amp; Nalebuff, Barry J. (2008). The Art of Strategy: A Game Theorist\u0026rsquo;s Guide to Success in Business and Life . W.W. Norton \u0026amp; Company. - S√°ch ch·ª©a nhi·ªÅu v√≠ d·ª• th·ª±c t·∫ø , c√≥ th·ªÉ √°p d·ª•ng v√†o kinh doanh v√† cu·ªôc s·ªëng.\nOsborne, Martin J. (2003). An Introduction to Game Theory . Oxford University Press. - Gi√°o tr√¨nh l√Ω thuy·∫øt to√†n di·ªán, ph√¢n t√≠ch chi ti·∫øt, v√† c√°c m√¥ h√¨nh M·ªôt gi√°o tr√¨nh to√†n di·ªán v·ªÅ l√Ω thuy·∫øt tr√≤ ch∆°i, bao g·ªìm ph√¢n t√≠ch chi ti·∫øt v·ªÅ Prisoner‚Äôs Dilemma v√† c√°c m√¥ h√¨nh li√™n quan.\nPoundstone, William. (1992). Prisoner‚Äôs Dilemma: John von Neumann, Game Theory, and the Puzzle of the Bomb . Anchor Books. - l·ªãch s·ª≠ v√† √Ω nghƒ©a c·ªßa Prisoner‚Äôs Dilemma,k·∫øt n·ªëi v·ªõi c√°c v·∫•n ƒë·ªÅ ch√≠nh tr·ªã v√† x√£ h·ªôi.\n","date":"Apr 10, 2025","img":"https://unsplash.it/1920/1080?image=230","permalink":"/blog/2025-04-10-prisoner-dilemma/","series":null,"tags":["Game Theory"],"title":"Prisoner‚Äôs Dilemma - Song ƒê·ªÅ T√π Nh√¢n"},{"categories":null,"content":" 1. ƒê·ªÅ b√†i 2. K·∫øt qu·∫£ 2.1. V·ªÅ hi·ªáu su·∫•t 2.2. V·ªÅ chuy√™n m√¥n 2.3. V·ªÅ t√≠nh c·ªông ƒë·ªìng 2.4. K·∫øt qu·∫£ n·ªïi b·∫≠t kh√°c: 1. ƒê·ªÅ b√†i C√¥ng ty Procter \u0026amp; Gamble (P\u0026amp;G), m·ªôt c√¥ng ty h√†ng ti√™u d√πng ƒë√≥ng g√≥i to√†n c·∫ßu. C√¥ng ty c√≥ kho·∫£ng 7,000 chuy√™n gia R\u0026amp;D tr√™n to√†n th·∫ø gi·ªõi, ho·∫°t ƒë·ªông c·ªßa c√¥ng ty bao g·ªìm ph√°t tri·ªÉn s·∫£n ph·∫©m t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi (R\u0026amp;D to product), c√≥ quy tr√¨nh R\u0026amp;D c√≥ c·∫•u tr√∫c t·ªët v√† l·ª±c l∆∞·ª£ng lao ƒë·ªông c√≥ k·ªπ nƒÉng cao\nƒê·ªÅ t√†i c√¥ng ty ƒë·∫∑t ra: \u0026ldquo;ƒê√°nh gi√° t√°c ƒë·ªông c·ªßa Tr√≠ tu·ªá nh√¢n t·∫°o th·∫ø h·ªá m·ªõi (GenAI) ƒë·∫øn hi·ªáu qu·∫£ h·ª£p t√°c nh√≥m trong m√¥i tr∆∞·ªùng l√†m vi·ªác tri th·ª©c, t·∫≠p trung v√†o ba kh√≠a c·∫°nh ch√≠nh: hi·ªáu su·∫•t l√†m vi·ªác, chia s·∫ª chuy√™n m√¥n v√† t∆∞∆°ng t√°c c·ªông ƒë·ªìng .\u0026rdquo; hay n√≥i c√°ch kh√°c, Th√≠ nghi·ªám n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ki·ªÉm tra t√°c ƒë·ªông c·ªßa AI ƒë·∫øn ba kh√≠a c·∫°nh ch√≠nh c·ªßa teamwork: hi·ªáu su·∫•t, chia s·∫ª chuy√™n m√¥n v√† t∆∞∆°ng t√°c c·ªông ƒë·ªìng trong b·ªëi c·∫£nh l√†m vi·ªác th·ª±c t·∫ø\nC·ª• th·ªÉ, nghi√™n c·ª©u n√†y nh·∫±m tr·∫£ l·ªùi c√°c c√¢u h·ªèi ch√≠nh sau:\nLi·ªáu GenAI c√≥ th·ªÉ cung c·∫•p nh·ªØng l·ª£i √≠ch v·ªÅ hi·ªáu su·∫•t so v·ªõi c√°ch l√†m truy·ªÅn th·ªëng c·ªßa teamwork hay kh√¥ng?\nGenAI c√≥ gi√∫p m·ªü r·ªông ph·∫°m vi chuy√™n m√¥n c·ªßa nh√¢n vi√™n ngay c·∫£ khi h·ªç thi·∫øu m·ªôt s·ªë ki·∫øn th·ª©c v√† k·ªπ nƒÉng chuy√™n m√¥n nh·∫•t ƒë·ªãnh kh√¥ng?\nGenAI c√≥ th·ªÉ cung c·∫•p lo·∫°i h√¨nh t∆∞∆°ng t√°c c·ªông ƒë·ªìng n√†o m√† ch√∫ng ta th∆∞·ªùng li√™n t∆∞·ªüng ƒë·∫øn s·ª± h·ª£p t√°c gi·ªØa con ng∆∞·ªùi kh√¥ng?\nQuy m√¥ c√¥ng ty th·ª±c hi·ªán th√≠ nghi·ªám ƒë∆∞·ª£c m√¥ t·∫£ nh∆∞ sau:\nS·ªë l∆∞·ª£ng ng∆∞·ªùi tham gia: 811 nh√¢n vi√™n P\u0026amp;G\nNg∆∞·ªùi tham gia l√† c√°c chuy√™n gia t·ª´ hai lƒ©nh v·ª±c: R\u0026amp;D v√† Commercial\nƒê∆∞·ª£c ph√¢n ng·∫´u nhi√™n v√†o c√°c ƒëi·ªÅu ki·ªán th√≠ nghi·ªám\nPh√¢n b·ªï:\n776 ng∆∞·ªùi ƒë∆∞·ª£c ph√¢n ng·∫´u nhi√™n v√†o 4 ƒëi·ªÅu ki·ªán th√≠ nghi·ªám\n35 ng∆∞·ªùi kh√¥ng ƒë∆∞·ª£c ph√¢n ng·∫´u nhi√™n do v√†o mu·ªôn ho·∫∑c c·∫•p b·∫≠c cao h∆°n band 3\nC√°c nh√≥m l√†m vi·ªác t·ª´ xa qua Microsoft Teams\nChia l√†m 4 nh√≥m:\nC√° nh√¢n kh√¥ng s·ª≠ d·ª•ng AI\nNh√≥m 2 ng∆∞·ªùi kh√¥ng s·ª≠ d·ª•ng AI\nC√° nh√¢n s·ª≠ d·ª•ng AI\nNh√≥m 2 ng∆∞·ªùi s·ª≠ d·ª•ng AI\nC√¥ng c·ª• AI ƒë∆∞·ª£c s·ª≠ d·ª•ng:\nD·ª±a tr√™n GPT-4 v√† truy c·∫≠p th√¥ng qua Microsoft Azure\nNg∆∞·ªùi tham gia ·ªü ƒëi·ªÅu ki·ªán c√≥ AI ƒë∆∞·ª£c ƒë√†o t·∫°o 1 gi·ªù v·ªÅ c√°ch t∆∞∆°ng t√°c v·ªõi c√¥ng c·ª• GenAI\nPh·∫°m vi t·ªï ch·ª©c:\nƒê∆∞·ª£c th·ª±c hi·ªán ·ªü 4 ƒë∆°n v·ªã kinh doanh: ChƒÉm s√≥c tr·∫ª em, ChƒÉm s√≥c ph·ª• n·ªØ, ChƒÉm s√≥c c√° nh√¢n v√† ChƒÉm s√≥c rƒÉng mi·ªáng T·∫°i 2 khu v·ª±c ƒë·ªãa l√Ω: Ch√¢u √Çu v√† Ch√¢u M·ªπ Vi·ªác ch·ªçn P\u0026amp;G v·ªõi quy m√¥ l·ªõn v√† ph·∫°m vi to√†n c·∫ßu nh∆∞ v·∫≠y gi√∫p tƒÉng t√≠nh ƒë·∫°i di·ªán v√† ƒë·ªô tin c·∫≠y c·ªßa k·∫øt qu·∫£ nghi√™n c·ª©u. Th·ªùi gian:\nTh√≠ nghi·ªám ƒë∆∞·ª£c th·ª±c hi·ªán trong kho·∫£ng th·ªùi gian t·ª´ th√°ng 5 ƒë·∫øn th√°ng 7 nƒÉm 2024 D∆∞·ªõi h√¨nh th·ª©c h·ªôi th·∫£o ph√°t tri·ªÉn s·∫£n ph·∫©m ·∫£o k√©o d√†i m·ªôt ng√†y C√°ch th·ª©c thu th·∫≠p d·ªØ li·ªáu:\nThu th·∫≠p tr∆∞·ªõc th√≠ nghi·ªám: th√¥ng tin c√° nh√¢n ng∆∞·ªùi tham gia Trong qu√° tr√¨nh: ghi l·∫°i t·∫•t c·∫£ c√°c l·ªánh v√† ph·∫£n h·ªìi c·ªßa GenAI, b·∫£n ghi t∆∞∆°ng t√°c nh√≥m Sau th√≠ nghi·ªám: kh·∫£o s√°t v√† ph·ªèng v·∫•n m·ªôt s·ªë ng∆∞·ªùi tham gia Bi·∫øn s·ªë ƒëo l∆∞·ªùng:\nHi·ªáu su·∫•t: Ch·∫•t l∆∞·ª£ng gi·∫£i ph√°p (thang ƒëi·ªÉm 1-10) Chuy√™n m√¥n: T√≠nh k·ªπ thu·∫≠t c·ªßa gi·∫£i ph√°p (thang ƒëi·ªÉm 1-7) T√≠nh c·ªông ƒë·ªìng : C·∫£m x√∫c t√≠ch c·ª±c v√† ti√™u c·ª±c (thang ƒëi·ªÉm 1-7) 2. K·∫øt qu·∫£ M·ªôt v√†i k·∫øt qu·∫£ m√¨nh r√∫t ra khi ƒë·ªçc b√†i vi·∫øt\n2.1. V·ªÅ hi·ªáu su·∫•t Nh√≥m kh√¥ng AI c·∫£i thi·ªán 0.24 ƒë·ªô l·ªách chu·∫©n so v·ªõi c√° nh√¢n kh√¥ng AI (p \u0026lt; 0.05) C√° nh√¢n c√≥ AI c·∫£i thi·ªán 0.37 ƒë·ªô l·ªách chu·∫©n so v·ªõi c√° nh√¢n kh√¥ng AI (p \u0026lt; 0.01) Nh√≥m c√≥ AI c·∫£i thi·ªán 0.39 ƒë·ªô l·ªách chu·∫©n so v·ªõi c√° nh√¢n kh√¥ng AI (p \u0026lt; 0.01) C√° nh√¢n c√≥ AI v√† nh√≥m c√≥ AI c√≥ ch·∫•t l∆∞·ª£ng gi·∫£i ph√°p t∆∞∆°ng ƒë∆∞∆°ng C√° nh√¢n c√≥ AI gi·∫£m 16.4% th·ªùi gian ho√†n th√†nh nhi·ªám v·ª• Nh√≥m c√≥ AI gi·∫£m 12.7% th·ªùi gian ho√†n th√†nh nhi·ªám v·ª• Nh√≥m c√≥ AI t·∫°o ra gi·∫£i ph√°p d√†i h∆°n ƒë√°ng k·ªÉ 2.2. V·ªÅ chuy√™n m√¥n Nh√¢n vi√™n l√†m vi·ªác m·ªôt m√¨nh v·ªõi AI ƒë·∫°t hi·ªáu su·∫•t t∆∞∆°ng ƒë∆∞∆°ng nh√≥m c√≥ √≠t nh·∫•t m·ªôt nh√¢n vi√™n core-job ( 1 k·ªπ thu·∫≠t + 1 chuy√™n m√¥n) AI gi√∫p x√≥a nh√≤a ranh gi·ªõi gi·ªØa √Ω t∆∞·ªüng k·ªπ thu·∫≠t v√† th∆∞∆°ng m·∫°i S·ª± kh√°c bi·ªát v·ªÅ t√≠nh k·ªπ thu·∫≠t/th∆∞∆°ng m·∫°i gi·ªØa nh√¢n vi√™n R\u0026amp;D v√† Commercial bi·∫øn m·∫•t khi s·ª≠ d·ª•ng AI Kh√¥ng c√≥ s·ª± kh√°c bi·ªát v·ªÅ ƒëi·ªÉm ch·∫•t l∆∞·ª£ng d·ª±a tr√™n ƒë·ªãnh h∆∞·ªõng k·ªπ thu·∫≠t c·ªßa gi·∫£i ph√°p 2.3. V·ªÅ t√≠nh c·ªông ƒë·ªìng C√° nh√¢n s·ª≠ d·ª•ng AI tƒÉng 0.457 ƒë·ªô l·ªách chu·∫©n c·∫£m x√∫c t√≠ch c·ª±c (p \u0026lt; 0.01) Nh√≥m s·ª≠ d·ª•ng AI tƒÉng 0.635 ƒë·ªô l·ªách chu·∫©n c·∫£m x√∫c t√≠ch c·ª±c (p \u0026lt; 0.01) C√° nh√¢n s·ª≠ d·ª•ng AI gi·∫£m 0.233 ƒë·ªô l·ªách chu·∫©n c·∫£m x√∫c ti√™u c·ª±c (p \u0026lt; 0.05) Nh√≥m s·ª≠ d·ª•ng AI gi·∫£m 0.235 ƒë·ªô l·ªách chu·∫©n c·∫£m x√∫c ti√™u c·ª±c (p \u0026lt; 0.05) 2.4. K·∫øt qu·∫£ n·ªïi b·∫≠t kh√°c: Nh√≥m c√≥ AI c√≥ kh·∫£ nƒÉng t·∫°o ra gi·∫£i ph√°p trong top 10% cao h∆°n 9.2 ƒëi·ªÉm ph·∫ßn trƒÉm so v·ªõi nh√≥m ki·ªÉm so√°t Ph√¢n ph·ªëi √Ω t∆∞·ªüng c·ªßa nh√≥m c√≥ AI c√¢n b·∫±ng h∆°n, gi·∫£m ·∫£nh h∆∞·ªüng th·ªëng tr·ªã Nhi·ªÅu ng∆∞·ªùi tham gia gi·ªØ l·∫°i h∆°n 75% n·ªôi dung do AI t·∫°o ra trong gi·∫£i ph√°p cu·ªëi c√πng M·ªôt v√†i th√¥ng s·ªë trong b√†i b√°o\nC√≤n nhi·ªÅu th√¥ng s·ªë quan tr·ªçng kh√°c, c√°c b·∫°n c√≥ th·ªÉ ƒë·ªçc b√†i b√°o ƒë·ªÉ c√≥ th√¥ng tin chi ti·∫øt.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ ƒë·ªçc b√†i, h·∫πn g·∫∑p l·∫°i c√°c b·∫°n ·ªü b√†i vi·∫øt ti·∫øp theo\nNgu·ªìn tham kh·∫£o\nhttps://www.hbs.edu/faculty/Pages/item.aspx?num=67197\nhttps://www.nber.org/papers/w33641\n","date":"Apr 7, 2025","img":"https://unsplash.it/1920/1080?image=228","permalink":"/blog/2025-04-07-generative-ai-expertise-teamwork/","series":null,"tags":["Artificial intelligence","Teamwork","Human-machine interaction","Productivity","Skills","Innovation","Field experiment"],"title":"Song Ki·∫øm H·ª£p B√≠ch Gi·ªØa Generative Ai V√† Chuy√™n Vi√™n. N·∫•c Thang L√™n Thi√™n ƒê∆∞·ªùng"},{"categories":null,"content":" L√Ω thuy·∫øt v√† b·ªëi c·∫£nh ra ƒë·ªùi c·ªßa The Dictator Game 7. V√≠ d·ª• trong doanh nghi·ªáp B·ªëi c·∫£nh C√°c k·ªãch b·∫£n ph√¢n b·ªï ti·ªÅn th∆∞·ªüng Ph√¢n t√≠ch h√†nh vi c·ªßa √¥ng tr∆∞·ªüng ph√≤ng ·ª®ng d·ª•ng c·ªßa v√≠ d·ª• n√†y trong doanh nghi·ªáp 8. So s√°nh v·ªõi c√°c m√¥ h√¨nh kh√°c L√Ω thuy·∫øt v√† b·ªëi c·∫£nh ra ƒë·ªùi c·ªßa The Dictator Game 1. L√Ω thuy·∫øt n·ªÅn t·∫£ng The Dictator Game l√† m·ªôt bi·∫øn th·ªÉ ƒë∆°n gi·∫£n c·ªßa c√°c m√¥ h√¨nh th·ª≠ nghi·ªám trong l√Ω thuy·∫øt tr√≤ ch∆°i (Game Theory), m·ªôt lƒ©nh v·ª±c nghi√™n c·ª©u v·ªÅ c√°ch con ng∆∞·ªùi ƒë∆∞a ra quy·∫øt ƒë·ªãnh trong c√°c t√¨nh hu·ªëng t∆∞∆°ng t√°c chi·∫øn l∆∞·ª£c. L√Ω thuy·∫øt tr√≤ ch∆°i t·∫≠p trung v√†o vi·ªác ph√¢n t√≠ch c√°c l·ª±a ch·ªçn m√† con ng∆∞·ªùi th·ª±c hi·ªán khi k·∫øt qu·∫£ kh√¥ng ch·ªâ ph·ª• thu·ªôc v√†o h√†nh ƒë·ªông c·ªßa h·ªç m√† c√≤n ph·ª• thu·ªôc v√†o h√†nh ƒë·ªông c·ªßa nh·ªØng ng∆∞·ªùi kh√°c.\nTrong The Dictator Game, tr·ªçng t√¢m l√† nghi√™n c·ª©u h√†nh vi v·ªã tha (altruism) v√† s·ª± c√¥ng b·∫±ng (fairness) ‚Äì hai y·∫øu t·ªë quan tr·ªçng trong kinh t·∫ø h·ªçc h√†nh vi (Behavioral Economics). M·∫∑c d√π l√Ω thuy·∫øt kinh t·∫ø truy·ªÅn th·ªëng gi·∫£ ƒë·ªãnh r·∫±ng con ng∆∞·ªùi lu√¥n h√†nh ƒë·ªông v√¨ l·ª£i √≠ch c√° nh√¢n t·ªëi ƒëa (rational self-interest), c√°c th√≠ nghi·ªám nh∆∞ The Dictator Game ƒë√£ ch·ª©ng minh r·∫±ng con ng∆∞·ªùi th∆∞·ªùng c√≥ xu h∆∞·ªõng quan t√¢m ƒë·∫øn l·ª£i √≠ch c·ªßa ng∆∞·ªùi kh√°c ho·∫∑c tu√¢n theo c√°c chu·∫©n m·ª±c x√£ h·ªôi.\n2. B·ªëi c·∫£nh ra ƒë·ªùi The Dictator Game ƒë∆∞·ª£c ph√°t tri·ªÉn t·ª´ Ultimatum Game, m·ªôt m√¥ h√¨nh th·ª≠ nghi·ªám n·ªïi ti·∫øng trong l√Ω thuy·∫øt tr√≤ ch∆°i. Ultimatum Game y√™u c·∫ßu hai ng∆∞·ªùi ch∆°i tham gia: m·ªôt ng∆∞·ªùi ƒë·ªÅ xu·∫•t c√°ch chia s·∫ª m·ªôt kho·∫£n ti·ªÅn (Proposer) v√† ng∆∞·ªùi kia c√≥ quy·ªÅn ch·∫•p nh·∫≠n ho·∫∑c t·ª´ ch·ªëi ƒë·ªÅ xu·∫•t ƒë√≥ (Responder). N·∫øu Responder t·ª´ ch·ªëi, c·∫£ hai s·∫Ω kh√¥ng nh·∫≠n ƒë∆∞·ª£c g√¨.\nTuy nhi√™n, Ultimatum Game c√≥ m·ªôt nh∆∞·ª£c ƒëi·ªÉm l·ªõn: ph·∫£n ·ª©ng c·ªßa Responder c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn quy·∫øt ƒë·ªãnh c·ªßa Proposer, d·∫´n ƒë·∫øn vi·ªác Proposer ƒë∆∞a ra c√°c ƒë·ªÅ xu·∫•t \u0026ldquo;c√¥ng b·∫±ng\u0026rdquo; h∆°n ƒë·ªÉ tr√°nh b·ªã t·ª´ ch·ªëi. ƒêi·ªÅu n√†y l√†m ph·ª©c t·∫°p vi·ªác ƒë√°nh gi√° li·ªáu h√†nh vi c·ªßa Proposer c√≥ xu·∫•t ph√°t t·ª´ l√≤ng v·ªã tha th·∫≠t s·ª± hay ch·ªâ l√† m·ªôt chi·∫øn l∆∞·ª£c ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u c√° nh√¢n.\nƒê·ªÉ kh·∫Øc ph·ª•c v·∫•n ƒë·ªÅ n√†y, Daniel Kahneman, Jack Knetsch v√† Richard Thaler ƒë√£ gi·ªõi thi·ªáu The Dictator Game v√†o ƒë·∫ßu nh·ªØng nƒÉm 1980. Tr√≤ ch∆°i n√†y lo·∫°i b·ªè vai tr√≤ c·ªßa Responder, khi·∫øn quy·∫øt ƒë·ªãnh c·ªßa ng∆∞·ªùi cho (Dictator) tr·ªü n√™n ho√†n to√†n t·ª± do v√† kh√¥ng b·ªã ·∫£nh h∆∞·ªüng b·ªüi √°p l·ª±c x√£ h·ªôi ho·∫∑c kh·∫£ nƒÉng b·ªã t·ª´ ch·ªëi.\n3. C√°ch th·ª©c ho·∫°t ƒë·ªông: Hai ng∆∞·ªùi ch∆°i ƒë∆∞·ª£c ch·ªçn: Ng∆∞·ªùi cho (Dictator) v√† Ng∆∞·ªùi nh·∫≠n (Recipient). Ng∆∞·ªùi cho ƒë∆∞·ª£c trao m·ªôt s·ªë ti·ªÅn c·ªë ƒë·ªãnh (v√≠ d·ª•: 100 USD). Ng∆∞·ªùi cho c√≥ quy·ªÅn quy·∫øt ƒë·ªãnh c√°ch ph√¢n chia s·ªë ti·ªÅn n√†y gi·ªØa m√¨nh v√† ng∆∞·ªùi nh·∫≠n. Ng∆∞·ªùi nh·∫≠n kh√¥ng c√≥ quy·ªÅn ph·∫£n h·ªìi, th∆∞∆°ng l∆∞·ª£ng hay t·ª´ ch·ªëi. K·∫øt qu·∫£ cu·ªëi c√πng ph·ª• thu·ªôc ho√†n to√†n v√†o quy·∫øt ƒë·ªãnh c·ªßa ng∆∞·ªùi cho. V√≠ d·ª•:\nN·∫øu ng∆∞·ªùi cho quy·∫øt ƒë·ªãnh gi·ªØ 80 USD v√† t·∫∑ng 20 USD cho ng∆∞·ªùi nh·∫≠n, th√¨ k·∫øt qu·∫£ l√† ng∆∞·ªùi cho gi·ªØ 80% t√†i s·∫£n, ng∆∞·ªùi nh·∫≠n gi·ªØ 20%. N·∫øu ng∆∞·ªùi cho quy·∫øt ƒë·ªãnh gi·ªØ to√†n b·ªô s·ªë ti·ªÅn, ng∆∞·ªùi nh·∫≠n s·∫Ω kh√¥ng nh·∫≠n ƒë∆∞·ª£c g√¨. 4. M·ª•c ti√™u nghi√™n c·ª©u ban ƒë·∫ßu M·ª•c ti√™u ch√≠nh c·ªßa The Dictator Game l√† ki·ªÉm tra:\nL√≤ng v·ªã tha th·∫≠t s·ª±: Li·ªáu con ng∆∞·ªùi c√≥ s·∫µn s√†ng chia s·∫ª t√†i s·∫£n v·ªõi ng∆∞·ªùi kh√°c ngay c·∫£ khi kh√¥ng c√≥ b·∫•t k·ª≥ √°p l·ª±c n√†o? ·∫¢nh h∆∞·ªüng c·ªßa chu·∫©n m·ª±c x√£ h·ªôi: H√†nh vi c·ªßa con ng∆∞·ªùi c√≥ b·ªã chi ph·ªëi b·ªüi c√°c quy t·∫Øc vƒÉn h√≥a, ƒë·∫°o ƒë·ª©c ho·∫∑c x√£ h·ªôi kh√¥ng? S·ª± c√¥ng b·∫±ng trong ph√¢n ph·ªëi t√†i s·∫£n: Con ng∆∞·ªùi c√≥ xu h∆∞·ªõng ∆∞u ti√™n s·ª± c√¥ng b·∫±ng hay l·ª£i √≠ch c√° nh√¢n? K·∫øt qu·∫£ ban ƒë·∫ßu t·ª´ c√°c th√≠ nghi·ªám cho th·∫•y r·∫±ng:\nPh·∫ßn l·ªõn ng∆∞·ªùi ch∆°i v·∫´n chia s·∫ª m·ªôt ph·∫ßn t√†i s·∫£n v·ªõi ng∆∞·ªùi nh·∫≠n, m·∫∑c d√π h·ªç kh√¥ng b·∫Øt bu·ªôc ph·∫£i l√†m v·∫≠y. Tuy nhi√™n, m·ª©c ƒë·ªô chia s·∫ª th∆∞·ªùng √≠t h∆°n so v·ªõi Ultimatum Game, ƒëi·ªÅu n√†y cho th·∫•y r·∫±ng m·ªôt ph·∫ßn h√†nh vi v·ªã tha trong Ultimatum Game c√≥ th·ªÉ xu·∫•t ph√°t t·ª´ √°p l·ª±c x√£ h·ªôi. 5. Th√≠ nghi·ªám Th√≠ nghi·ªám The Dictator Game ban ƒë·∫ßu ƒë∆∞·ª£c th·ª±c hi·ªán t·∫°i Hoa K·ª≥ v√† Canada l√† nh·ªØng qu·ªëc gia ph√°t tri·ªÉn v·ªõi n·ªÅn vƒÉn h√≥a c√° nh√¢n ch·ªß nghƒ©a (individualistic culture), ph√π h·ª£p ƒë·ªÉ ki·ªÉm tra gi·∫£ thuy·∫øt v·ªÅ l·ª£i √≠ch c√° nh√¢n t·ªëi ƒëa. V ·ªõi t·∫≠p m·∫´u ch·ªß y·∫øu l√† sinh vi√™n ƒë·∫°i h·ªçc Princeton v√† University of British Columbia.\nSau ƒë√≥, th√≠ nghi·ªám ƒë∆∞·ª£c m·ªü r·ªông sang nhi·ªÅu qu·ªëc gia tr√™n th·∫ø gi·ªõi, bao g·ªìm c√°c n∆∞·ªõc ph√°t tri·ªÉn v√† ƒëang ph√°t tri·ªÉn, ƒë·ªÉ nghi√™n c·ª©u r·ªông h∆°n v·ªÅ s·ª± ·∫£nh h∆∞·ªüng c·ªßa vƒÉn h√≥a, kinh t·∫ø v√† t√¥n gi√°o.\nM·ªü r·ªông sang c√°c khu v·ª±c kh√°c Nghi√™n c·ª©u to√†n c·∫ßu: Sau khi th√≠ nghi·ªám tr·ªü n√™n ph·ªï bi·∫øn, c√°c nh√† nghi√™n c·ª©u ƒë√£ ti·∫øn h√†nh n√≥ ·ªü nhi·ªÅu qu·ªëc gia kh√°c nhau, bao g·ªìm c·∫£ c√°c n∆∞·ªõc ƒëang ph√°t tri·ªÉn. M·ªôt s·ªë v√≠ d·ª• n·ªïi b·∫≠t:\nCh√¢u √Çu: C√°c nghi√™n c·ª©u t·∫°i Anh, ƒê·ª©c, H√† Lan nh·∫±m so s√°nh h√†nh vi v·ªã tha gi·ªØa c√°c n·ªÅn vƒÉn h√≥a T√¢y √Çu. Ch√¢u √Å: Nh·∫≠t B·∫£n, Trung Qu·ªëc, ·∫§n ƒê·ªô ƒë∆∞·ª£c nghi√™n c·ª©u ƒë·ªÉ xem x√©t t√°c ƒë·ªông c·ªßa vƒÉn h√≥a t·∫≠p th·ªÉ (collectivist culture). Ch√¢u Phi v√† M·ªπ Latinh: C√°c nghi√™n c·ª©u t·∫°i Kenya, Uganda, Brazil nh·∫±m t√¨m hi·ªÉu h√†nh vi chia s·∫ª trong c√°c c·ªông ƒë·ªìng c√≥ thu nh·∫≠p th·∫•p. Ph√°t hi·ªán v·ªÅ s·ª± kh√°c bi·ªát vƒÉn h√≥a:\nT·∫°i c√°c n∆∞·ªõc c√° nh√¢n ch·ªß nghƒ©a (nh∆∞ Hoa K·ª≥, Canada), t·ª∑ l·ªá chia s·∫ª th∆∞·ªùng th·∫•p h∆°n, ph·∫£n √°nh xu h∆∞·ªõng ∆∞u ti√™n l·ª£i √≠ch c√° nh√¢n. T·∫°i c√°c n∆∞·ªõc t·∫≠p th·ªÉ ch·ªß nghƒ©a (nh∆∞ Nh·∫≠t B·∫£n, Trung Qu·ªëc), t·ª∑ l·ªá chia s·∫ª th∆∞·ªùng cao h∆°n, do ·∫£nh h∆∞·ªüng c·ªßa chu·∫©n m·ª±c x√£ h·ªôi v√† gi√° tr·ªã c·ªông ƒë·ªìng. Nghi√™n c·ª©u trong c√°c c·ªông ƒë·ªìng ƒë·∫∑c th√π C·ªông ƒë·ªìng n√¥ng th√¥n v√† ƒë√¥ th·ªã:\nC√°c nghi√™n c·ª©u so s√°nh h√†nh vi c·ªßa ng∆∞·ªùi d√¢n s·ªëng ·ªü n√¥ng th√¥n v√† ƒë√¥ th·ªã, nh·∫±m ƒë√°nh gi√° t√°c ƒë·ªông c·ªßa m√¥i tr∆∞·ªùng s·ªëng. K·∫øt qu·∫£ cho th·∫•y r·∫±ng ng∆∞·ªùi d√¢n n√¥ng th√¥n th∆∞·ªùng chia s·∫ª nhi·ªÅu h∆°n, do m·ª©c ƒë·ªô g·∫Øn k·∫øt c·ªông ƒë·ªìng cao h∆°n. C·ªông ƒë·ªìng thu nh·∫≠p th·∫•p:\nC√°c th√≠ nghi·ªám t·∫°i c√°c qu·ªëc gia ƒëang ph√°t tri·ªÉn ho·∫∑c khu v·ª±c ngh√®o kh√≥ th∆∞·ªùng cho th·∫•y t·ª∑ l·ªá chia s·∫ª cao h∆°n, d√π s·ªë ti·ªÅn ban ƒë·∫ßu r·∫•t nh·ªè. ƒêi·ªÅu n√†y ph·∫£n √°nh vai tr√≤ c·ªßa l√≤ng t·ªët v√† s·ª± t∆∞∆°ng tr·ª£ trong c√°c c·ªông ƒë·ªìng kh√≥ khƒÉn. 6. K·∫øt qu·∫£ ·∫¢nh h∆∞·ªüng c·ªßa vƒÉn h√≥a: VƒÉn h√≥a ƒë√≥ng vai tr√≤ quan tr·ªçng trong vi·ªác ƒë·ªãnh h√¨nh h√†nh vi c·ªßa Dictator. V√≠ d·ª•:\n·ªû c√°c qu·ªëc gia T√¢y ph∆∞∆°ng (c√° nh√¢n ch·ªß nghƒ©a), Dictator th∆∞·ªùng gi·ªØ l·∫°i ph·∫ßn l·ªõn t√†i s·∫£n. ·ªû c√°c qu·ªëc gia ƒê√¥ng ph∆∞∆°ng (t·∫≠p th·ªÉ ch·ªß nghƒ©a), Dictator c√≥ xu h∆∞·ªõng chia s·∫ª nhi·ªÅu h∆°n. ·∫¢nh h∆∞·ªüng c·ªßa kinh t·∫ø: Thu nh·∫≠p b√¨nh qu√¢n ƒë·∫ßu ng∆∞·ªùi c≈©ng ·∫£nh h∆∞·ªüng ƒë·∫øn h√†nh vi chia s·∫ª. Trong c√°c c·ªông ƒë·ªìng thu nh·∫≠p th·∫•p, l√≤ng v·ªã tha th∆∞·ªùng cao h∆°n do s·ª± t∆∞∆°ng tr·ª£ l·∫´n nhau l√† y·∫øu t·ªë s·ªëng c√≤n.\n·∫¢nh h∆∞·ªüng c·ªßa t√¥n gi√°o: C√°c nghi√™n c·ª©u t·∫°i c√°c qu·ªëc gia c√≥ truy·ªÅn th·ªëng t√¥n gi√°o m·∫°nh m·∫Ω (v√≠ d·ª•: H·ªìi gi√°o, Ph·∫≠t gi√°o) th∆∞·ªùng cho th·∫•y t·ª∑ l·ªá chia s·∫ª cao h∆°n, do c√°c gi√° tr·ªã ƒë·∫°o ƒë·ª©c khuy·∫øn kh√≠ch l√≤ng t·ªët v√† s·ª± c√¥ng b·∫±ng.\nKinh t·∫ø h·ªçc c·ªï ƒëi·ªÉn gi·∫£ ƒë·ªãnh r·∫±ng con ng∆∞·ªùi lu√¥n h√†nh ƒë·ªông v√¨ l·ª£i √≠ch c√° nh√¢n t·ªëi ƒëa, nh∆∞ng c√°c nghi√™n c·ª©u th·ª±c nghi·ªám nh∆∞ The Dictator Game ƒë√£ ch·ªâ ra r·∫±ng con ng∆∞·ªùi th∆∞·ªùng h√†nh x·ª≠ theo c√°ch phi l√Ω tr√≠ (irrational) ho·∫∑c ch·ªãu ·∫£nh h∆∞·ªüng b·ªüi c√°c y·∫øu t·ªë x√£ h·ªôi, c·∫£m x√∫c v√† ƒë·∫°o ƒë·ª©c.\nNh·ªØng ph√°t hi·ªán t·ª´ The Dictator Game ƒë√£ g√≥p ph·∫ßn c·ªßng c·ªë n·ªÅn t·∫£ng cho c√°c lƒ©nh v·ª±c nh∆∞:\nKinh t·∫ø h·ªçc h√†nh vi: Nghi√™n c·ª©u c√°ch con ng∆∞·ªùi ƒë∆∞a ra quy·∫øt ƒë·ªãnh trong th·ª±c t·∫ø, thay v√¨ d·ª±a tr√™n c√°c gi·∫£ ƒë·ªãnh l√Ω thuy·∫øt. T√¢m l√Ω h·ªçc x√£ h·ªôi: Hi·ªÉu r√µ h∆°n v·ªÅ ƒë·ªông l·ª±c th√∫c ƒë·∫©y l√≤ng v·ªã tha, s·ª± c√¥ng b·∫±ng v√† l√≤ng tham. Ch√≠nh s√°ch c√¥ng: Thi·∫øt k·∫ø c√°c ch∆∞∆°ng tr√¨nh ph√∫c l·ª£i v√† h·ªó tr·ª£ x√£ h·ªôi ph√π h·ª£p v·ªõi h√†nh vi th·ª±c t·∫ø c·ªßa con ng∆∞·ªùi. 7. V√≠ d·ª• trong doanh nghi·ªáp H√£y t∆∞·ªüng t∆∞·ª£ng m·ªôt t√¨nh hu·ªëng th·ª±c t·∫ø trong m·ªôt doanh nghi·ªáp, n∆°i √¥ng tr∆∞·ªüng ph√≤ng (gi·∫£ s·ª≠ t√™n l√† √¥ng A) ƒë∆∞·ª£c giao quy·ªÅn quy·∫øt ƒë·ªãnh ph√¢n b·ªï m·ªôt kho·∫£n ti·ªÅn th∆∞·ªüng (v√≠ d·ª•: 100 tri·ªáu ƒë·ªìng) cho nh√≥m nh√¢n vi√™n c·ªßa m√¨nh. ƒê√¢y l√† m·ªôt v√≠ d·ª• ƒëi·ªÉn h√¨nh c√≥ th·ªÉ ƒë∆∞·ª£c so s√°nh v·ªõi The Dictator Game, trong ƒë√≥ √¥ng tr∆∞·ªüng ph√≤ng ƒë√≥ng vai tr√≤ l√† \u0026ldquo;Dictator\u0026rdquo; v√† c√°c nh√¢n vi√™n l√† \u0026ldquo;Recipient\u0026rdquo;.\nB·ªëi c·∫£nh Kho·∫£n ti·ªÅn th∆∞·ªüng: 100 tri·ªáu ƒë·ªìng. Ng∆∞·ªùi quy·∫øt ƒë·ªãnh: √îng tr∆∞·ªüng ph√≤ng A. Nh√≥m nh√¢n vi√™n: G·ªìm 5 ng∆∞·ªùi (B, C, D, E, F). M·ª•c ti√™u c·ªßa doanh nghi·ªáp: Kho·∫£n ti·ªÅn th∆∞·ªüng nh·∫±m ghi nh·∫≠n ƒë√≥ng g√≥p c·ªßa nh√≥m trong d·ª± √°n v·ª´a qua. Quy·ªÅn l·ª±c c·ªßa √¥ng A: √îng A c√≥ to√†n quy·ªÅn quy·∫øt ƒë·ªãnh c√°ch ph√¢n b·ªï kho·∫£n ti·ªÅn n√†y m√† kh√¥ng c·∫ßn tham kh·∫£o √Ω ki·∫øn c·ªßa nh√¢n vi√™n. C√°c k·ªãch b·∫£n ph√¢n b·ªï ti·ªÅn th∆∞·ªüng K·ªãch b·∫£n 1: Ph√¢n b·ªï c√¥ng b·∫±ng √îng A quy·∫øt ƒë·ªãnh chia ƒë·ªÅu kho·∫£n ti·ªÅn cho 5 nh√¢n vi√™n:\nM·ªói ng∆∞·ªùi nh·∫≠n 20 tri·ªáu ƒë·ªìng. L√Ω do: √îng A mu·ªën ƒë·∫£m b·∫£o s·ª± c√¥ng b·∫±ng v√† tr√°nh xung ƒë·ªôt n·ªôi b·ªô. √îng tin r·∫±ng vi·ªác chia ƒë·ªÅu s·∫Ω t·∫°o ƒë·ªông l·ª±c l√†m vi·ªác cho c·∫£ nh√≥m trong t∆∞∆°ng lai. K·ªãch b·∫£n 2: Ph√¢n b·ªï theo ƒë√≥ng g√≥p √îng A ƒë√°nh gi√° m·ª©c ƒë·ªô ƒë√≥ng g√≥p c·ªßa t·ª´ng nh√¢n vi√™n v√† quy·∫øt ƒë·ªãnh ph√¢n b·ªï nh∆∞ sau:\nNh√¢n vi√™n B: 30 tri·ªáu ƒë·ªìng (ƒë√≥ng g√≥p nhi·ªÅu nh·∫•t).\nNh√¢n vi√™n C: 25 tri·ªáu ƒë·ªìng (ƒë√≥ng g√≥p quan tr·ªçng nh∆∞ng √≠t h∆°n B).\nNh√¢n vi√™n D: 20 tri·ªáu ƒë·ªìng (ƒë√≥ng g√≥p trung b√¨nh).\nNh√¢n vi√™n E: 15 tri·ªáu ƒë·ªìng (ƒë√≥ng g√≥p √≠t h∆°n).\nNh√¢n vi√™n F: 10 tri·ªáu ƒë·ªìng (ƒë√≥ng g√≥p √≠t nh·∫•t).\nL√Ω do: √îng A mu·ªën khuy·∫øn kh√≠ch nh√¢n vi√™n l√†m vi·ªác chƒÉm ch·ªâ h∆°n b·∫±ng c√°ch khen th∆∞·ªüng nh·ªØng ng∆∞·ªùi c√≥ ƒë√≥ng g√≥p l·ªõn.\nK·ªãch b·∫£n 3: Gi·ªØ l·∫°i ph·∫ßn l·ªõn cho m√¨nh √îng A quy·∫øt ƒë·ªãnh gi·ªØ l·∫°i 60 tri·ªáu ƒë·ªìng cho b·∫£n th√¢n v√† ch·ªâ chia 40 tri·ªáu ƒë·ªìng c√≤n l·∫°i cho nh√≥m:\nNh√¢n vi√™n B, C, D: M·ªói ng∆∞·ªùi nh·∫≠n 10 tri·ªáu ƒë·ªìng.\nNh√¢n vi√™n E, F: M·ªói ng∆∞·ªùi nh·∫≠n 5 tri·ªáu ƒë·ªìng.\nL√Ω do: √îng A cho r·∫±ng m√¨nh l√† ng∆∞·ªùi qu·∫£n l√Ω d·ª± √°n v√† ch·ªãu tr√°ch nhi·ªám ch√≠nh n√™n x·ª©ng ƒë√°ng nh·∫≠n ph·∫ßn l·ªõn ti·ªÅn th∆∞·ªüng.\nK·ªãch b·∫£n 4: Chia s·∫ª ho√†n to√†n √îng A quy·∫øt ƒë·ªãnh t·∫∑ng to√†n b·ªô 100 tri·ªáu ƒë·ªìng cho nh√≥m v√† kh√¥ng gi·ªØ l·∫°i b·∫•t k·ª≥ kho·∫£n n√†o:\nM·ªói nh√¢n vi√™n nh·∫≠n 20 tri·ªáu ƒë·ªìng. L√Ω do: √îng A mu·ªën th·ªÉ hi·ªán l√≤ng v·ªã tha v√† x√¢y d·ª±ng tinh th·∫ßn ƒëo√†n k·∫øt trong nh√≥m. √îng tin r·∫±ng vi·ªác ƒë·∫ßu t∆∞ v√†o nh√¢n vi√™n s·∫Ω mang l·∫°i l·ª£i √≠ch l√¢u d√†i cho doanh nghi·ªáp. Ph√¢n t√≠ch h√†nh vi c·ªßa √¥ng tr∆∞·ªüng ph√≤ng N·∫øu √¥ng A ch·ªçn K·ªãch b·∫£n 1 ho·∫∑c 4:\nH√†nh vi c·ªßa √¥ng A ph·∫£n √°nh l√≤ng v·ªã tha v√† mong mu·ªën duy tr√¨ s·ª± c√¥ng b·∫±ng trong nh√≥m. ƒêi·ªÅu n√†y c√≥ th·ªÉ gi√∫p tƒÉng c∆∞·ªùng ni·ªÅm tin v√† ƒë·ªông l·ª±c l√†m vi·ªác c·ªßa nh√¢n vi√™n, v√¨ h·ªç c·∫£m th·∫•y ƒë∆∞·ª£c t√¥n tr·ªçng v√† ghi nh·∫≠n. N·∫øu √¥ng A ch·ªçn K·ªãch b·∫£n 2:\nH√†nh vi c·ªßa √¥ng A ph·∫£n √°nh s·ª± c√¥ng b·∫±ng d·ª±a tr√™n ƒë√≥ng g√≥p. C√°ch ph√¢n b·ªï n√†y c√≥ th·ªÉ khuy·∫øn kh√≠ch nh√¢n vi√™n l√†m vi·ªác chƒÉm ch·ªâ h∆°n trong t∆∞∆°ng lai, nh∆∞ng c≈©ng c√≥ th·ªÉ g√¢y ra xung ƒë·ªôt n·∫øu nh√¢n vi√™n c·∫£m th·∫•y ƒë√°nh gi√° kh√¥ng c√¥ng b·∫±ng. N·∫øu √¥ng A ch·ªçn K·ªãch b·∫£n 3:\nH√†nh vi c·ªßa √¥ng A ph·∫£n √°nh l·ª£i √≠ch c√° nh√¢n t·ªëi ƒëa. ƒêi·ªÅu n√†y c√≥ th·ªÉ d·∫´n ƒë·∫øn b·∫•t m√£n trong nh√≥m nh√¢n vi√™n, gi·∫£m tinh th·∫ßn l√†m vi·ªác v√† th·∫≠m ch√≠ g√¢y ra th√°i ƒë·ªô ti√™u c·ª±c ƒë·ªëi v·ªõi √¥ng A v√† doanh nghi·ªáp. ·ª®ng d·ª•ng c·ªßa v√≠ d·ª• n√†y trong doanh nghi·ªáp ƒê√°nh gi√° nƒÉng l·ª±c l√£nh ƒë·∫°o:\nC√°ch √¥ng A ph√¢n b·ªï ti·ªÅn th∆∞·ªüng c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° phong c√°ch l√£nh ƒë·∫°o c·ªßa √¥ng. V√≠ d·ª•: M·ªôt nh√† l√£nh ƒë·∫°o c√¥ng b·∫±ng v√† v·ªã tha th∆∞·ªùng ƒë∆∞·ª£c nh√¢n vi√™n y√™u m·∫øn v√† t√¥n tr·ªçng. M·ªôt nh√† l√£nh ƒë·∫°o √≠ch k·ª∑ c√≥ th·ªÉ g√¢y ra xung ƒë·ªôt n·ªôi b·ªô v√† l√†m gi·∫£m hi·ªáu su·∫•t l√†m vi·ªác c·ªßa nh√≥m. X√¢y d·ª±ng vƒÉn h√≥a doanh nghi·ªáp:\nN·∫øu doanh nghi·ªáp khuy·∫øn kh√≠ch s·ª± c√¥ng b·∫±ng v√† h·ª£p t√°c, c√°c nh√† qu·∫£n l√Ω n√™n h·ªçc h·ªèi t·ª´ K·ªãch b·∫£n 1 ho·∫∑c 4. Ng∆∞·ª£c l·∫°i, n·∫øu doanh nghi·ªáp t·∫≠p trung v√†o hi·ªáu su·∫•t c√° nh√¢n, K·ªãch b·∫£n 2 c√≥ th·ªÉ ph√π h·ª£p h∆°n. TƒÉng c∆∞·ªùng l√≤ng trung th√†nh c·ªßa nh√¢n vi√™n:\nKhi nh√¢n vi√™n c·∫£m th·∫•y ƒë∆∞·ª£c ghi nh·∫≠n v√† ƒë·ªëi x·ª≠ c√¥ng b·∫±ng, h·ªç c√≥ xu h∆∞·ªõng g·∫Øn b√≥ l√¢u d√†i v·ªõi doanh nghi·ªáp. Ki·ªÉm tra t√≠nh minh b·∫°ch:\nDoanh nghi·ªáp c√≥ th·ªÉ s·ª≠ d·ª•ng t√¨nh hu·ªëng n√†y ƒë·ªÉ ki·ªÉm tra m·ª©c ƒë·ªô minh b·∫°ch v√† c√¥ng b·∫±ng trong c√°c ch√≠nh s√°ch l∆∞∆°ng th∆∞·ªüng. V√≠ d·ª• v·ªÅ vi·ªác √¥ng tr∆∞·ªüng ph√≤ng chia th∆∞·ªüng cho nh√¢n vi√™n l√† m·ªôt minh h·ªça r√µ r√†ng cho The Dictator Game trong b·ªëi c·∫£nh doanh nghi·ªáp. C√°ch √¥ng tr∆∞·ªüng ph√≤ng ph√¢n b·ªï ti·ªÅn th∆∞·ªüng kh√¥ng ch·ªâ ·∫£nh h∆∞·ªüng ƒë·∫øn m·ªëi quan h·ªá gi·ªØa √¥ng v√† nh√¢n vi√™n m√† c√≤n t√°c ƒë·ªông ƒë·∫øn vƒÉn h√≥a v√† hi·ªáu su·∫•t l√†m vi·ªác c·ªßa c·∫£ nh√≥m.\n8. So s√°nh v·ªõi c√°c m√¥ h√¨nh kh√°c Ultimatum Game vs. The Dictator Game ƒê·∫∑c ƒëi·ªÉm Ultimatum Game The Dictator Game S·ªë ng∆∞·ªùi tham gia 2 (Proposer v√† Responder) 2 (Dictator v√† Recipient) Quy·ªÅn l·ª±c c·ªßa Responder C√≥ quy·ªÅn ch·∫•p nh·∫≠n ho·∫∑c t·ª´ ch·ªëi Kh√¥ng c√≥ quy·ªÅn ph·∫£n h·ªìi √Åp l·ª±c x√£ h·ªôi C√≥ (Proposer s·ª£ b·ªã t·ª´ ch·ªëi) Kh√¥ng K·∫øt qu·∫£ Th∆∞·ªùng c√¥ng b·∫±ng h∆°n Th∆∞·ªùng √≠t c√¥ng b·∫±ng h∆°n B√†i vi·∫øt d∆∞·ªõi g√≥c nh√¨n c·ªßa m·ªôt con IT qu√®n, th·∫±ng IT l·ªè, vi·∫øt v·ªÅ m·ªôt v·∫•n ƒë·ªÅ kinh t·∫ø, b√† con chuy√™n ng√†nh th·∫•y sai th√¨ hoan h·ªâ c√≤m m√™n nh·∫π nh√†ng, ƒë·ª´ng bu√¥n l·ªùi cay ƒë·∫Øng.\nC·∫£m ∆°n b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\nNgu·ªìn tham kh·∫£o\ng√µ t·ª´ kho√° The Dictator Game v√† t√¨m c√°c cu·ªën sau, m·ªói cu·ªën th√¨ t√°c gi·∫£ s·∫Ω s·ª≠ d·ª•ng l√Ω thuy·∫øt cho c√°c t·∫≠p m·∫´u kh√°c nhau v√† ƒë∆∞a ra k·∫øt lu·∫≠n, m·∫•y s√°ch ƒë√≥ to√†n c√≥ b·∫£n quy·ªÅn n√™n h∆°i kh√≥ ki·∫øm. C√≥ th·ªÉ t√¨m qua ResearchGate ho·∫∑c g·ª≠i li√™n h·ªá v·ªõi t√°c gi·∫£.\nDaniel Kahneman, Jack Knetsch v√† Richard Thaler (1986) Fairness and the Assumptions of Economics.\nErnst Fehr v√† Klaus Schmidt (1999) Ernst Fehr v√† Klaus Schmidt (1999) A Theory of Fairness, Competition, and Cooperation\nJoseph Henrich at el. (2005) Economic Man\u0026rsquo; in Cross-Cultural Perspective: Behavioral Experiments in 15 Small-Scale Societies.\nColin Camerer (2003) Behavioral Game Theory: Experiments in Strategic Interaction\nRichard Thaler (2015) Misbehaving: The Making of Behavioral Economics\nHerbert Gintis (2000) Game Theory Evolving: A Problem-Centered Introduction to Modeling Strategic Interaction\nDan Ariely (2008) Predictably Irrational: The Hidden Forces That Shape Our Decisions . HarperCollins.\n","date":"Apr 7, 2025","img":"https://unsplash.it/1920/1080?image=229","permalink":"/blog/2025-04-07-the-dictator-game/","series":null,"tags":["Game Theory"],"title":"The Dictator Game - Tr√≤ Ch∆°i ƒê·ªôc T√†i"},{"categories":null,"content":" 1. L·ªãch s·ª≠ h√¨nh th√†nh \u0026amp; ph√°t tri·ªÉn 2. Ng√¥n ng·ªØ l·∫≠p tr√¨nh 3. Ph√¢n t√≠ch ∆Øu v√† Nh∆∞·ª£c ƒëi·ªÉm 4. So s√°nh ki·∫øn tr√∫c 5. G·ª£i √Ω n√™n s·ª≠ d·ª•ng lo·∫°i n√†o? 6. C√°c con s·ªë bi·∫øt n√≥i 1. L·ªãch s·ª≠ h√¨nh th√†nh \u0026 ph√°t tri·ªÉn Redis\nL·ªãch s·ª≠: ƒê∆∞·ª£c ph√°t tri·ªÉn l·∫ßn ƒë·∫ßu b·ªüi Salvatore Sanfilippo (antirez) v√†o nƒÉm 2009. T·ª´ ƒë√≥, Redis nhanh ch√≥ng tr·ªü th√†nh m·ªôt trong nh·ªØng h·ªá th·ªëng l∆∞u tr·ªØ d·ªØ li·ªáu trong b·ªô nh·ªõ ph·ªï bi·∫øn nh·∫•t nh·ªù hi·ªáu su·∫•t cao v√† t√≠nh linh ho·∫°t trong vi·ªác x·ª≠ l√Ω c√°c c·∫•u tr√∫c d·ªØ li·ªáu phong ph√∫. ƒê·ªôi ng≈© ph√°t tri·ªÉn: Ban ƒë·∫ßu do antirez t·∫°o ra, hi·ªán nay ƒë∆∞·ª£c duy tr√¨ v√† ph√°t tri·ªÉn b·ªüi Redis Labs c√πng v·ªõi s·ª± ƒë√≥ng g√≥p m·∫°nh m·∫Ω t·ª´ c·ªông ƒë·ªìng m√£ ngu·ªìn m·ªü. DragonflyDB\nL·ªãch s·ª≠: Ra ƒë·ªùi kho·∫£ng nƒÉm 2022, DragonflyDB ƒë∆∞·ª£c x√¢y d·ª±ng nh·∫±m kh·∫Øc ph·ª•c m·ªôt s·ªë h·∫°n ch·∫ø c·ªßa Redis (nh∆∞ ki·∫øn tr√∫c ƒë∆°n lu·ªìng) b·∫±ng c√°ch t·∫≠n d·ª•ng s·ª©c m·∫°nh c·ªßa c√°c CPU ƒëa l√µi v√† t·ªëi ∆∞u h√≥a vi·ªác qu·∫£n l√Ω b·ªô nh·ªõ. ƒê·ªôi ng≈© ph√°t tri·ªÉn: ƒê∆∞·ª£c ph√°t tri·ªÉn b·ªüi DragonflyDB Inc., v·ªõi s·ª± l√£nh ƒë·∫°o c·ªßa Itamar Haber v√† ƒë·ªôi ng≈© chuy√™n s√¢u v·ªÅ t·ªëi ∆∞u h√≥a hi·ªáu nƒÉng v√† kh·∫£ nƒÉng m·ªü r·ªông. Valkey\nL·ªãch s·ª≠: Xu·∫•t hi·ªán v√†o kho·∫£ng nƒÉm 2023 d∆∞·ªõi d·∫°ng m·ªôt fork c·ªßa Redis. Valkey ƒë∆∞·ª£c t·∫°o ra nh·∫±m duy tr√¨ cam k·∫øt ho√†n to√†n m√£ ngu·ªìn m·ªü sau khi Redis c√≥ nh·ªØng thay ƒë·ªïi v·ªÅ gi·∫•y ph√©p, ƒë·∫£m b·∫£o t√≠nh t∆∞∆°ng th√≠ch API v·ªõi Redis. ƒê·ªôi ng≈© ph√°t tri·ªÉn: ƒê∆∞·ª£c h·ªó tr·ª£ ch·ªß y·∫øu b·ªüi Linux Foundation c√πng v·ªõi s·ª± ƒë√≥ng g√≥p c·ªßa c·ªông ƒë·ªìng m√£ ngu·ªìn m·ªü, t·∫°o n√™n m·ªôt n·ªÅn t·∫£ng thay th·∫ø ƒë√°ng tin c·∫≠y cho Redis. 2. Ng√¥n ng·ªØ l·∫≠p tr√¨nh Redis: ƒê∆∞·ª£c vi·∫øt ch·ªß y·∫øu b·∫±ng C, cho ph√©p t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t ·ªü m·ª©c h·ªá th·ªëng. DragonflyDB: Ph√°t tri·ªÉn b·∫±ng C++, nh·∫±m t·∫≠n d·ª•ng ki·∫øn tr√∫c ƒëa lu·ªìng v√† c·∫£i thi·ªán hi·ªáu nƒÉng tr√™n h·ªá th·ªëng ƒëa l√µi. Valkey: Gi·ªØ nguy√™n c√¥ng ngh·ªá c·ªßa Redis, ƒë∆∞·ª£c vi·∫øt b·∫±ng C, gi√∫p d·ªÖ d√†ng duy tr√¨ s·ª± t∆∞∆°ng th√≠ch v·ªõi API c·ªßa Redis. 3. Ph√¢n t√≠ch ∆Øu v√† Nh∆∞·ª£c ƒëi·ªÉm Redis ∆Øu ƒëi·ªÉm: M√£ ngu·ªìn tr∆∞·ªüng th√†nh v√† ·ªïn ƒë·ªãnh: ƒê∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong nhi·ªÅu ·ª©ng d·ª•ng s·∫£n xu·∫•t v·ªõi h·ªá sinh th√°i phong ph√∫ (nhi·ªÅu module, c√¥ng c·ª• h·ªó tr·ª£, th∆∞ vi·ªán‚Ä¶). Hi·ªáu su·∫•t cao: M·∫∑c d√π s·ª≠ d·ª•ng ki·∫øn tr√∫c ƒë∆°n lu·ªìng, Redis v·∫´n ƒë·∫°t ƒë∆∞·ª£c hi·ªáu nƒÉng ·∫•n t∆∞·ª£ng nh·ªù t·ªëi ∆∞u h√≥a cho c√°c t√°c v·ª• I/O. ƒê·ªô tin c·∫≠y: ƒê∆∞·ª£c ki·ªÉm ch·ª©ng qua th·ªùi gian v·ªõi c·ªông ƒë·ªìng ng∆∞·ªùi d√πng l·ªõn v√† nhi·ªÅu t√†i li·ªáu h·ªó tr·ª£. Nh∆∞·ª£c ƒëi·ªÉm: Ki·∫øn tr√∫c ƒë∆°n lu·ªìng: H·∫°n ch·∫ø kh·∫£ nƒÉng t·∫≠n d·ª•ng t·ªëi ƒëa s·ª©c m·∫°nh c·ªßa c√°c CPU ƒëa l√µi, ƒë·∫∑c bi·ªát d∆∞·ªõi t·∫£i cao. Cluster ph·ª©c t·∫°p: Vi·ªác c·∫•u h√¨nh v√† qu·∫£n l√Ω c√°c c·ª•m Redis ƒë√¥i khi kh√° ph·ª©c t·∫°p. Th√°ch th·ª©c gi·∫•y ph√©p: Nh·ªØng thay ƒë·ªïi v·ªÅ gi·∫•y ph√©p trong c√°c phi√™n b·∫£n g·∫ßn ƒë√¢y ƒë√£ g√¢y lo ng·∫°i cho m·ªôt b·ªô ph·∫≠n ng∆∞·ªùi d√πng. DragonflyDB ∆Øu ƒëi·ªÉm: Ki·∫øn tr√∫c ƒëa lu·ªìng: T·∫≠n d·ª•ng t·ªëi ƒëa s·ª©c m·∫°nh c·ªßa CPU ƒëa l√µi, mang l·∫°i hi·ªáu su·∫•t x·ª≠ l√Ω truy v·∫•n v√† gi·∫£m ƒë·ªô tr·ªÖ ƒë√°ng k·ªÉ. Qu·∫£n l√Ω b·ªô nh·ªõ hi·ªáu qu·∫£: C√°c thu·∫≠t to√°n t·ªëi ∆∞u gi√∫p gi·∫£m m·ª©c ti√™u th·ª• b·ªô nh·ªõ d∆∞·ªõi t·∫£i cao. Tri·ªÉn khai ƒë∆°n gi·∫£n: Kh√¥ng c·∫ßn c·∫•u h√¨nh clustering ph·ª©c t·∫°p nh∆∞ Redis, ph√π h·ª£p v·ªõi nh·ªØng ·ª©ng d·ª•ng c·∫ßn hi·ªáu nƒÉng cao m√† kh√¥ng mu·ªën ƒë·∫ßu t∆∞ qu√° nhi·ªÅu v√†o h·∫° t·∫ßng. Nh∆∞·ª£c ƒëi·ªÉm: M·ªõi tr√™n th·ªã tr∆∞·ªùng: H·ªá sinh th√°i, t√†i li·ªáu v√† c·ªông ƒë·ªìng h·ªó tr·ª£ v·∫´n ƒëang trong qu√° tr√¨nh ph√°t tri·ªÉn. Ch∆∞a ki·ªÉm ch·ª©ng r·ªông r√£i: C·∫ßn th√™m th·ªùi gian ƒë·ªÉ ch·ª©ng minh t√≠nh ·ªïn ƒë·ªãnh v√† kh·∫£ nƒÉng m·ªü r·ªông trong m√¥i tr∆∞·ªùng production. H·∫°n ch·∫ø v·ªÅ clustering: M·ªôt s·ªë t√≠nh nƒÉng clustering ch∆∞a ƒë·∫°t ƒë·∫øn m·ª©c ƒë·ªô ho√†n thi·ªán nh∆∞ Redis. Valkey ∆Øu ƒëi·ªÉm: T∆∞∆°ng th√≠ch API v·ªõi Redis: Gi√∫p chuy·ªÉn ƒë·ªïi d·ªÖ d√†ng t·ª´ Redis m√† kh√¥ng c·∫ßn thay ƒë·ªïi m√£ ngu·ªìn. Ho√†n to√†n m·ªü ngu·ªìn: Kh√¥ng g·∫∑p r√†ng bu·ªôc v·ªÅ gi·∫•y ph√©p th∆∞∆°ng m·∫°i, ph√π h·ª£p v·ªõi c√°c t·ªï ch·ª©c ∆∞u ti√™n gi·∫£i ph√°p m√£ ngu·ªìn m·ªü. ·ªîn ƒë·ªãnh t·ª´ n·ªÅn t·∫£ng Redis: D·ª±a tr√™n c√¥ng ngh·ªá ƒë√£ ƒë∆∞·ª£c ki·ªÉm ch·ª©ng qua th·ªùi gian, ƒë·∫£m b·∫£o t√≠nh ·ªïn ƒë·ªãnh. Nh∆∞·ª£c ƒëi·ªÉm: √çt c·∫£i ti·∫øn v·ªÅ hi·ªáu su·∫•t: Kh√¥ng c√≥ nhi·ªÅu c·∫£i ti·∫øn v∆∞·ª£t tr·ªôi so v·ªõi Redis, ch·ªâ t·∫≠p trung v√†o vi·ªác duy tr√¨ t√≠nh m·ªü ngu·ªìn. C·ªông ƒë·ªìng nh·ªè: H·ªá sinh th√°i v√† t√†i li·ªáu h∆∞·ªõng d·∫´n v·∫´n ch∆∞a phong ph√∫ b·∫±ng Redis ho·∫∑c c√°c gi·∫£i ph√°p m·ªõi nh∆∞ DragonflyDB. S·ª± c·∫°nh tranh kh·ªëc li·ªát: Ph·∫£i ƒë·ªëi m·∫∑t v·ªõi c√°c d·ª± √°n c·∫£i ti·∫øn kh√°c nh·∫±m t·ªëi ∆∞u hi·ªáu nƒÉng v√† kh·∫£ nƒÉng m·ªü r·ªông. 4. So s√°nh ki·∫øn tr√∫c D∆∞·ªõi ƒë√¢y l√† b·∫£ng so s√°nh c√°c ƒëi·ªÉm m·ªõi trong thi·∫øt k·∫ø h·ªá th·ªëng c·ªßa DragonflyDB so v·ªõi Valkey v√† Redis: Ch√†o b·∫°n,\nD∆∞·ªõi ƒë√¢y l√† b·∫£ng so s√°nh c√°c ƒëi·ªÉm m·ªõi trong thi·∫øt k·∫ø h·ªá th·ªëng c·ªßa DragonflyDB so v·ªõi Valkey v√† Redis, v·ªõi c·ªôt \u0026ldquo;ƒê·∫∑c ƒëi·ªÉm\u0026rdquo; ƒë∆∞·ª£c t√°ch ri√™ng:\nƒê·∫∑c ƒëi·ªÉm DragonflyDB (ƒêi·ªÉm m·ªõi) Valkey Redis (Hi·ªán t·∫°i) Ki·∫øn tr√∫c x·ª≠ l√Ω ‚Äì X√¢y d·ª±ng theo ki·∫øn tr√∫c ƒëa lu·ªìng to√†n di·ªán, t·∫≠n d·ª•ng t·ªëi ƒëa s·ª©c m·∫°nh c·ªßa CPU ƒëa l√µi.\n‚Äì X·ª≠ l√Ω song song nhi·ªÅu truy v·∫•n c√πng l√∫c, gi·∫£m ƒë·ªô tr·ªÖ d∆∞·ªõi t·∫£i cao. - S·ª≠ d·ª•ng Multi-threaded v·ªõi ki·∫øn tr√∫c \u0026ldquo;shared-nothing\u0026rdquo;, chia d·ªØ li·ªáu th√†nh c√°c shard ƒë·ªôc l·∫≠p, m·ªói shard x·ª≠ l√Ω b·ªüi m·ªôt thread ri√™ng, gi·∫£m tranh ch·∫•p lock ‚Äì √Åp d·ª•ng ki·∫øn tr√∫c ƒëa lu·ªìng c·∫£i ti·∫øn cho x·ª≠ l√Ω I/O v√† th·ª±c thi l·ªánh.\n‚Äì Cho ph√©p x·ª≠ l√Ω song song nhi·ªÅu y√™u c·∫ßu, c·∫£i thi·ªán throughput v√† gi·∫£m ƒë·ªô tr·ªÖ. ‚Äì S·ª≠ d·ª•ng m√¥ h√¨nh ƒë∆°n lu·ªìng v·ªõi event loop.\n‚Äì X·ª≠ l√Ω tu·∫ßn t·ª±, t·∫≠n d·ª•ng I/O phi ƒë·ªìng b·ªô nh∆∞ng kh√¥ng x·ª≠ l√Ω song song nhi·ªÅu l·ªánh c√πng l√∫c. - D·ªÖ g√¢y ngh·∫Ωn c·ªï chai khi t·∫£i cao Qu·∫£n l√Ω b·ªô nh·ªõ ‚Äì √Åp d·ª•ng c√°c c·∫•u tr√∫c d·ªØ li·ªáu t·ªëi ∆∞u ( DashTable thay th·∫ø Redis Dictionary, gi·∫£m metadata) v√† thu·∫≠t to√°n caching ti√™n ti·∫øn, gi·∫£m m·ª©c ti√™u th·ª• b·ªô nh·ªõ.\n‚Äì Hi·ªáu qu·∫£ khi x·ª≠ l√Ω kh·ªëi l∆∞·ª£ng d·ªØ li·ªáu l·ªõn. ‚Äì C·∫£i ti·∫øn c·∫•u tr√∫c t·ª´ ƒëi·ªÉn n·ªôi b·ªô ƒë·ªÉ s·ª≠ d·ª•ng b·ªô nh·ªõ hi·ªáu qu·∫£ h∆°n.\n‚Äì Gi·∫£m chi ph√≠ t√†i nguy√™n v√† ƒë·∫£m b·∫£o hi·ªáu nƒÉng d∆∞·ªõi t·∫£i cao. ‚Äì S·ª≠ d·ª•ng c√°c c·∫•u tr√∫c d·ªØ li·ªáu truy·ªÅn th·ªëng trong C.\n‚Äì Ho·∫°t ƒë·ªông t·ªët nh∆∞ng √≠t t·ªëi ∆∞u cho m√¥i tr∆∞·ªùng ƒëa lu·ªìng v√† x·ª≠ l√Ω t·∫£i cao. X·ª≠ l√Ω I/O ‚Äì H·ªó tr·ª£ I/O b·∫•t ƒë·ªìng b·ªô k·∫øt h·ª£p v·ªõi batching, gi·∫£m overhead khi chuy·ªÉn ƒë·ªïi ng·ªØ c·∫£nh gi·ªØa c√°c lu·ªìng. ‚Äì S·ª≠ d·ª•ng ki·∫øn tr√∫c ƒëa lu·ªìng trong x·ª≠ l√Ω I/O, c·∫£i thi·ªán hi·ªáu su·∫•t v√† gi·∫£m ƒë·ªô tr·ªÖ. ‚Äì D·ª±a v√†o I/O b·∫•t ƒë·ªìng b·ªô qua event loop, x·ª≠ l√Ω t·ª´ng l·ªánh m·ªôt, d·∫´n ƒë·∫øn gi·ªõi h·∫°n khi ƒë·ªëi m·∫∑t v·ªõi t·∫£i l·ªõn. Tri·ªÉn khai \u0026amp; M·ªü r·ªông ‚Äì Thi·∫øt k·∫ø ƒë·ªÉ ƒë∆°n gi·∫£n h√≥a vi·ªác tri·ªÉn khai tr√™n single node v·ªõi hi·ªáu nƒÉng cao, h·∫°n ch·∫ø s·ª± ph·ª©c t·∫°p c·ªßa cluster.\n‚Äì D·ªÖ d√†ng m·ªü r·ªông quy m√¥ nh·ªù v√†o ki·∫øn tr√∫c ƒëa lu·ªìng n·ªôi b·ªô. - vertical scale ‚Äì T√≠ch h·ª£p c√°c c·∫£i ti·∫øn v·ªÅ clustering nh∆∞ t·ª± ƒë·ªông chuy·ªÉn ƒë·ªïi d·ª± ph√≤ng v√† ph√¢n b·ªï d·ªØ li·ªáu th√¥ng minh.\n‚Äì D·ªÖ d√†ng m·ªü r·ªông quy m√¥ trong m√¥i tr∆∞·ªùng ph√¢n t√°n. ‚Äì H·ªó tr·ª£ Redis Cluster v√† Sentinel, nh∆∞ng y√™u c·∫ßu c·∫•u h√¨nh v√† qu·∫£n l√Ω kh√° ph·ª©c t·∫°p. - horizontal scale C√¥ng ngh·ªá \u0026amp; Ng√¥n ng·ªØ ‚Äì ƒê∆∞·ª£c x√¢y d·ª±ng b·∫±ng C++ hi·ªán ƒë·∫°i, cho ph√©p t·∫≠n d·ª•ng c√°c t√≠nh nƒÉng t·ªëi ∆∞u t·ª´ ng√¥n ng·ªØ v√† th∆∞ vi·ªán ti√™n ti·∫øn. ‚Äì ƒê∆∞·ª£c vi·∫øt b·∫±ng C, gi·ªØ nguy√™n gi·∫•y ph√©p BSD 3-clause, ƒë·∫£m b·∫£o t√≠nh m·ªü ngu·ªìn ho√†n to√†n.\n‚Äì T·∫≠p trung v√†o hi·ªáu nƒÉng v√† kh·∫£ nƒÉng m·ªü r·ªông. ‚Äì ƒê∆∞·ª£c vi·∫øt b·∫±ng C, mang l·∫°i ƒë·ªô ·ªïn ƒë·ªãnh cao nh∆∞ng h·∫°n ch·∫ø m·ªôt s·ªë t·ªëi ∆∞u h√≥a hi·ªán ƒë·∫°i. Nh·ªØng c·∫£i ti·∫øn tr√™n gi√∫p DragonflyDB v√† Valkey n√¢ng cao hi·ªáu nƒÉng, t·ªëi ∆∞u h√≥a vi·ªác s·ª≠ d·ª•ng t√†i nguy√™n v√† gi·∫£m ƒë·ªô tr·ªÖ, ph·ª•c v·ª• t·ªët h∆°n cho c√°c ·ª©ng d·ª•ng th·ªùi gian th·ª±c v√† x·ª≠ l√Ω t·∫£i l·ªõn. Tuy nhi√™n, m·ªói h·ªá th·ªëng c√≥ nh·ªØng ƒë·∫∑c ƒëi·ªÉm ri√™ng, ph√π h·ª£p v·ªõi c√°c nhu c·∫ßu v√† m√¥i tr∆∞·ªùng tri·ªÉn khai kh√°c nhau.\nValkey l√† m·ªôt d·ª± √°n m√£ ngu·ªìn m·ªü, ƒë∆∞·ª£c ph√°t tri·ªÉn nh∆∞ m·ªôt fork c·ªßa Redis sau khi Redis chuy·ªÉn sang gi·∫•y ph√©p ngu·ªìn m·ªü c√≥ ƒëi·ªÅu ki·ªán. Valkey gi·ªØ nguy√™n gi·∫•y ph√©p BSD 3-clause, ƒë·∫£m b·∫£o t√≠nh m·ªü ngu·ªìn ho√†n to√†n. DragonflyDB ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi m·ªôt c√¥ng ty th∆∞∆°ng m·∫°i v√† s·ª≠ d·ª•ng gi·∫•y ph√©p ngu·ªìn m·ªü c√≥ ƒëi·ªÅu ki·ªán, cho ph√©p s·ª≠ d·ª•ng mi·ªÖn ph√≠ nh∆∞ng h·∫°n ch·∫ø vi·ªác cung c·∫•p nh∆∞ m·ªôt d·ªãch v·ª• ƒë√°m m√¢y th∆∞∆°ng m·∫°i. Redis, ban ƒë·∫ßu ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Salvatore Sanfilippo, hi·ªán ƒë√£ chuy·ªÉn sang gi·∫•y ph√©p ngu·ªìn m·ªü c√≥ ƒëi·ªÅu ki·ªán, h·∫°n ch·∫ø vi·ªác s·ª≠ d·ª•ng trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p th∆∞∆°ng m·∫°i.\n5. G·ª£i √Ω n√™n s·ª≠ d·ª•ng lo·∫°i n√†o? N·∫øu b·∫°n c·∫ßn m·ªôt gi·∫£i ph√°p ƒë√£ ƒë∆∞·ª£c ki·ªÉm ch·ª©ng, v·ªõi h·ªá sinh th√°i r·ªông l·ªõn v√† s·ª± h·ªó tr·ª£ t·ª´ c·ªông ƒë·ªìng m·∫°nh m·∫Ω: Redis l√† l·ª±a ch·ªçn ph√π h·ª£p, ƒë·∫∑c bi·ªát v·ªõi c√°c ·ª©ng d·ª•ng truy·ªÅn th·ªëng v·ªÅ b·ªô nh·ªõ ƒë·ªám, qu·∫£n l√Ω phi√™n v√† x·ª≠ l√Ω d·ªØ li·ªáu th·ªùi gian th·ª±c. Tuy nhi√™n, n·∫øu b·∫°n kh√¥ng ng·∫°i gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ li√™n quan ƒë·∫øn c·∫•u h√¨nh cluster ho·∫∑c m·ªôt s·ªë h·∫°n ch·∫ø v·ªÅ ki·∫øn tr√∫c ƒë∆°n lu·ªìng, Redis v·∫´n l√† l·ª±a ch·ªçn ƒë√°ng tin c·∫≠y.\nN·∫øu hi·ªáu nƒÉng, kh·∫£ nƒÉng t·∫≠n d·ª•ng CPU ƒëa l√µi v√† tri·ªÉn khai ƒë∆°n gi·∫£n l√† ∆∞u ti√™n h√†ng ƒë·∫ßu c·ªßa b·∫°n: DragonflyDB c√≥ th·ªÉ l√† l·ª±a ch·ªçn t·ªëi ∆∞u. N√≥ ƒëem l·∫°i t·ªëc ƒë·ªô x·ª≠ l√Ω v∆∞·ª£t tr·ªôi v√† qu·∫£n l√Ω b·ªô nh·ªõ hi·ªáu qu·∫£, ph√π h·ª£p v·ªõi c√°c ·ª©ng d·ª•ng c·∫ßn t·ªëc ƒë·ªô cao m√† kh√¥ng mu·ªën ph·ª©c t·∫°p v·ªõi vi·ªác c·∫•u h√¨nh cluster.\nN·∫øu b·∫°n ∆∞u ti√™n ho√†n to√†n m√£ ngu·ªìn m·ªü v√† mu·ªën tr√°nh c√°c r√†ng bu·ªôc gi·∫•y ph√©p th∆∞∆°ng m·∫°i, ƒë·ªìng th·ªùi v·∫´n c·∫ßn s·ª± t∆∞∆°ng th√≠ch v·ªõi Redis: Valkey l√† gi·∫£i ph√°p ƒë√°ng c√¢n nh·∫Øc. M·∫∑c d√π v·ªÅ hi·ªáu nƒÉng c√≥ th·ªÉ kh√¥ng c·∫£i thi·ªán v∆∞·ª£t tr·ªôi so v·ªõi Redis, nh∆∞ng Valkey mang l·∫°i s·ª± an t√¢m v·ªÅ m·∫∑t ph√°p l√Ω v√† h·ªó tr·ª£ c·ªông ƒë·ªìng m·ªü.\nVi·ªác l·ª±a ch·ªçn gi·ªØa Redis, DragonflyDB v√† Valkey c√≤n ph·ª• thu·ªôc v√†o y√™u c·∫ßu c·ª• th·ªÉ c·ªßa d·ª± √°n:\nRedis ph√π h·ª£p v·ªõi nh·ªØng ·ª©ng d·ª•ng c·∫ßn s·ª± ·ªïn ƒë·ªãnh, h·ªó tr·ª£ ƒëa d·∫°ng t·ª´ c·ªông ƒë·ªìng v√† m·ªôt h·ªá sinh th√°i phong ph√∫. DragonflyDB l√† gi·∫£i ph√°p ti√™n ti·∫øn, t·∫≠n d·ª•ng c√¥ng ngh·ªá ƒëa lu·ªìng ƒë·ªÉ cung c·∫•p hi·ªáu nƒÉng v∆∞·ª£t tr·ªôi tr√™n h·ªá th·ªëng ƒëa l√µi, th√≠ch h·ª£p v·ªõi c√°c ·ª©ng d·ª•ng m·ªõi ƒë√≤i h·ªèi t·ªëc ƒë·ªô cao. Valkey l√† l·ª±a ch·ªçn l√Ω t∆∞·ªüng n·∫øu b·∫°n mu·ªën duy tr√¨ ho√†n to√†n t√≠nh m·ªü ngu·ªìn v√† t∆∞∆°ng th√≠ch API v·ªõi Redis, m·∫∑c d√π c√≥ th·ªÉ thi·∫øu nh·ªØng c·∫£i ti·∫øn v∆∞·ª£t tr·ªôi v·ªÅ m·∫∑t hi·ªáu nƒÉng. 6. C√°c con s·ªë bi·∫øt n√≥i Trong th·ª≠ nghi·ªám c√πng ph·∫ßn c·ª©ng EC2 c6gn.16xlarge DragonflyDB ƒë·∫°t th√¥ng l∆∞·ª£ng 3,8 tri·ªáu y√™u c·∫ßu m·ªói gi√¢y, cao h∆°n r·∫•t nhi·ªÅu so v·ªõi redis\nTrong c√°c th·ª≠ nghi·ªám v·ªõi dung l∆∞·ª£ng l∆∞u tr·ªØ 5GB, DragonflyDB y√™u c·∫ßu √≠t h∆°n 30% b·ªô nh·ªõ so v·ªõi Redis\nHy v·ªçng v·ªõi b·∫£ng so s√°nh v√† ph√¢n t√≠ch tr√™n, b·∫°n c√≥ th·ªÉ ƒë∆∞a ra quy·∫øt ƒë·ªãnh ph√π h·ª£p nh·∫•t cho nhu c·∫ßu d·ª± √°n c·ªßa m√¨nh.\nNgu·ªìn tham kh·∫£o:\nhttps://medium.com/%40mohitdehuliya/dragonflydb-vs-redis-a-deep-dive-towards-the-next-gen-caching-infrastructure-23186397b3d3\nhttps://www.dragonflydb.io/guides/valkey-vs-redis?utm_source=phamduytung.com\nhttps://redisson.org/articles/valkey-vs-redis-comparision.html?utm_source=phamduytung.com\nhttps://en.wikipedia.org/wiki/Valkey?utm_source=phamduytung.com\nhttps://db-engines.com/en/system/Dragonfly%3BKeyDB%3BValkey?utm_source=phamduytung.com\n","date":"Feb 17, 2025","img":"https://unsplash.it/1920/1080?image=206","permalink":"/blog/2025-02-17-redis-dragonflydb-valkey/","series":null,"tags":["DragonflyDB","Redis","Valkey"],"title":"Compare DragonflyDB vs Redis vs Valkey"},{"categories":null,"content":" 1. H·ªó tr·ª£ torch.compile cho Python 3.13 2. Gi·ªõi thi·ªáu torch.compiler.set_stance 3. TƒÉng c∆∞·ªùng AOTInductor 4. H·ªó tr·ª£ FP16 tr√™n CPU X86 5. C·∫£i thi·ªán tr·∫£i nghi·ªám ng∆∞·ªùi d√πng PyTorch tr√™n GPU Intel 6. Gi·ªõi thi·ªáu torch.library.triton_op 7. FlexAttention cho LLMs tr√™n CPU X86 8. Dim.AUTO 9. Thay ƒë·ªïi trong tham s·ªë weights_only c·ªßa torch.load 10. Ng·ª´ng h·ªó tr·ª£ k√™nh Anaconda ch√≠nh th·ª©c c·ªßa PyTorch K·∫øt lu·∫≠n T√†i li·ªáu tham kh·∫£o PyTorch 2.6, ƒë∆∞·ª£c ph√°t h√†nh v√†o ng√†y 29 th√°ng 1 nƒÉm 2025, mang ƒë·∫øn nhi·ªÅu c·∫£i ti·∫øn v√† t√≠nh nƒÉng m·ªõi so v·ªõi c√°c phi√™n b·∫£n tr∆∞·ªõc ƒë√≥. D∆∞·ªõi ƒë√¢y l√† t·ªïng quan v·ªÅ nh·ªØng ƒëi·ªÉm n·ªïi b·∫≠t trong phi√™n b·∫£n n√†y:\n1. H·ªó tr·ª£ torch.compile cho Python 3.13 Tr∆∞·ªõc ƒë√¢y, torch.compile ch·ªâ h·ªó tr·ª£ ƒë·∫øn phi√™n b·∫£n Python 3.12. Trong phi√™n b·∫£n 2.6, PyTorch ƒë√£ m·ªü r·ªông h·ªó tr·ª£ cho Python 3.13, cho ph√©p ng∆∞·ªùi d√πng t·ªëi ∆∞u h√≥a m√¥ h√¨nh v·ªõi torch.compile tr√™n phi√™n b·∫£n Python m·ªõi nh·∫•t.\nƒê√°nh gi√°: Vi·ªác m·ªü r·ªông n√†y gi√∫p c·ªông ƒë·ªìng ng∆∞·ªùi d√πng Python c·∫≠p nh·∫≠t v√† s·ª≠ d·ª•ng c√°c t√≠nh nƒÉng m·ªõi nh·∫•t c·ªßa ng√¥n ng·ªØ m√† kh√¥ng g·∫∑p tr·ªü ng·∫°i v·ªÅ t∆∞∆°ng th√≠ch v·ªõi PyTorch.\n2. Gi·ªõi thi·ªáu torch.compiler.set_stance T√≠nh nƒÉng n√†y cho ph√©p ng∆∞·ªùi d√πng ch·ªâ ƒë·ªãnh c√°c h√†nh vi kh√°c nhau (\u0026ldquo;stances\u0026rdquo;) m√† torch.compile c√≥ th·ªÉ th·ª±c hi·ªán gi·ªØa c√°c l·∫ßn g·ªçi h√†m ƒë√£ bi√™n d·ªãch. M·ªôt trong nh·ªØng stance, ch·∫≥ng h·∫°n nh∆∞ \u0026ldquo;eager_on_recompile\u0026rdquo;, h∆∞·ªõng d·∫´n PyTorch th·ª±c thi eagerly khi c·∫ßn bi√™n d·ªãch l·∫°i, t√°i s·ª≠ d·ª•ng m√£ ƒë√£ bi√™n d·ªãch ƒë∆∞·ª£c l∆∞u trong b·ªô nh·ªõ cache khi c√≥ th·ªÉ.\nƒê√°nh gi√°: T√≠nh nƒÉng n√†y cung c·∫•p s·ª± linh ho·∫°t cho ng∆∞·ªùi d√πng trong vi·ªác ki·ªÉm so√°t qu√° tr√¨nh bi√™n d·ªãch, gi√∫p t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t v√† qu·∫£n l√Ω t√†i nguy√™n hi·ªáu qu·∫£ h∆°n.\n3. TƒÉng c∆∞·ªùng AOTInductor Phi√™n b·∫£n 2.6 gi·ªõi thi·ªáu m·ªôt ƒë·ªãnh d·∫°ng g√≥i m·ªõi, \u0026ldquo;PT2 archive\u0026rdquo;, ch·ª©a t·∫•t c·∫£ c√°c t·ªáp c·∫ßn thi·∫øt cho AOTInductor, cho ph√©p ng∆∞·ªùi d√πng g·ª≠i m·ªçi th·ª© c·∫ßn thi·∫øt ƒë·∫øn c√°c m√¥i tr∆∞·ªùng kh√°c. Ngo√†i ra, c√≤n c√≥ ch·ª©c nƒÉng ƒë√≥ng g√≥i nhi·ªÅu m√¥ h√¨nh v√†o m·ªôt artifact v√† l∆∞u tr·ªØ th√™m metadata b√™n trong g√≥i.\nƒê√°nh gi√°: Nh·ªØng c·∫£i ti·∫øn n√†y gi√∫p vi·ªác tri·ªÉn khai v√† ph√¢n ph·ªëi m√¥ h√¨nh tr·ªü n√™n d·ªÖ d√†ng v√† linh ho·∫°t h∆°n, ƒë·∫∑c bi·ªát h·ªØu √≠ch trong c√°c m√¥i tr∆∞·ªùng s·∫£n xu·∫•t v√† khi l√†m vi·ªác v·ªõi nhi·ªÅu m√¥ h√¨nh.\n4. H·ªó tr·ª£ FP16 tr√™n CPU X86 M·ªôt ƒëi·ªÉm n·ªïi b·∫≠t kh√°c c·ªßa phi√™n b·∫£n n√†y l√† h·ªó tr·ª£ FP16 tr√™n CPU X86, m·ªü r·ªông kh·∫£ nƒÉng t√≠nh to√°n s·ªë h·ªçc d·∫•u ph·∫©y ƒë·ªông 16-bit tr√™n c√°c CPU ph·ªï bi·∫øn.\nƒê√°nh gi√°: ƒêi·ªÅu n√†y c√≥ th·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t cho c√°c m√¥ h√¨nh y√™u c·∫ßu t√≠nh to√°n d·∫•u ph·∫©y ƒë·ªông 16-bit, ƒë·∫∑c bi·ªát h·ªØu √≠ch cho c√°c ·ª©ng d·ª•ng y√™u c·∫ßu hi·ªáu su·∫•t cao tr√™n ph·∫ßn c·ª©ng CPU.\n5. C·∫£i thi·ªán tr·∫£i nghi·ªám ng∆∞·ªùi d√πng PyTorch tr√™n GPU Intel Phi√™n b·∫£n 2.6 mang l·∫°i tr·∫£i nghi·ªám ng∆∞·ªùi d√πng ƒë∆∞·ª£c c·∫£i thi·ªán tr√™n GPU Intel, ƒë·∫∑c bi·ªát tr√™n Windows. ƒêi·ªÅu n√†y bao g·ªìm thi·∫øt l·∫≠p ph·∫ßn m·ªÅm d·ªÖ d√†ng h∆°n, c√°c binary Windows ƒë∆∞·ª£c c·∫£i thi·ªán v√† m·ªü r·ªông ph·∫°m vi c·ªßa c√°c to√°n t·ª≠ Aten tr√™n GPU Intel v·ªõi c√°c kernel SYCL.\nƒê√°nh gi√°: Nh·ªØng c·∫£i ti·∫øn n√†y l√†m cho PyTorch tr·ªü n√™n th√¢n thi·ªán h∆°n v·ªõi ng∆∞·ªùi d√πng s·ª≠ d·ª•ng GPU Intel, m·ªü r·ªông ph·∫°m vi ph·∫ßn c·ª©ng ƒë∆∞·ª£c h·ªó tr·ª£ v√† c·∫£i thi·ªán hi·ªáu su·∫•t tr√™n c√°c thi·∫øt b·ªã n√†y.\n6. Gi·ªõi thi·ªáu torch.library.triton_op torch.library.triton_op cung c·∫•p m·ªôt c√°ch ti√™u chu·∫©n ƒë·ªÉ t·∫°o c√°c to√°n t·ª≠ t√πy ch·ªânh ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi c√°c kernel triton do ng∆∞·ªùi d√πng ƒë·ªãnh nghƒ©a. Khi ng∆∞·ªùi d√πng chuy·ªÉn c√°c kernel triton do h·ªç ƒë·ªãnh nghƒ©a th√†nh c√°c to√°n t·ª≠ t√πy ch·ªânh, torch.library.triton_op cho ph√©p torch.compile xem x√©t v√†o vi·ªác tri·ªÉn khai, cho ph√©p torch.compile t·ªëi ∆∞u h√≥a kernel triton b√™n trong n√≥.\nƒê√°nh gi√°: T√≠nh nƒÉng n√†y m·ªü ra kh·∫£ nƒÉng m·ªü r·ªông v√† t√πy ch·ªânh cao h∆°n cho ng∆∞·ªùi d√πng, cho ph√©p h·ªç t√≠ch h·ª£p c√°c kernel triton t√πy ch·ªânh m·ªôt c√°ch li·ªÅn m·∫°ch v√† t·ªëi ∆∞u h√≥a ch√∫ng trong qu√° tr√¨nh bi√™n d·ªãch.\n7. FlexAttention cho LLMs tr√™n CPU X86 PyTorch 2.6 gi·ªõi thi·ªáu FlexAttention, m·ªôt c·∫£i ti·∫øn ƒë√°ng k·ªÉ cho vi·ªác x·ª≠ l√Ω m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLMs) tr√™n CPU X86. FlexAttention gi√∫p t·ªëi ∆∞u h√≥a vi·ªác t√≠nh to√°n attention, gi·∫£m ƒë·ªô tr·ªÖ v√† tƒÉng t·ªëc ƒë·ªô suy lu·∫≠n cho c√°c m√¥ h√¨nh Transformer tr√™n ph·∫ßn c·ª©ng CPU. ƒêi·ªÅu n√†y ƒë·∫∑c bi·ªát quan tr·ªçng ƒë·ªëi v·ªõi nh·ªØng h·ªá th·ªëng kh√¥ng c√≥ GPU m·∫°nh ho·∫∑c c·∫ßn ch·∫°y m√¥ h√¨nh tr√™n c√°c m√¥i tr∆∞·ªùng ti·∫øt ki·ªám chi ph√≠.\nC·ª• th·ªÉ, FlexAttention t·∫≠n d·ª•ng c√°c t·ªëi ∆∞u h√≥a v·ªÅ ph·∫ßn c·ª©ng tr√™n ki·∫øn tr√∫c X86, gi√∫p c·∫£i thi·ªán vi·ªác qu·∫£n l√Ω b·ªô nh·ªõ ƒë·ªám (cache) v√† tƒÉng hi·ªáu qu·∫£ x·ª≠ l√Ω ma tr·∫≠n trong c∆° ch·∫ø attention. Nh·ªØng c·∫£i ti·∫øn n√†y gi√∫p gi·∫£m ƒë√°ng k·ªÉ th·ªùi gian suy lu·∫≠n c·ªßa c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn nh∆∞ GPT, LLaMA khi ch·∫°y tr√™n CPU.\nƒê√°nh gi√°: Vi·ªác h·ªó tr·ª£ FlexAttention tr√™n CPU X86 l√† m·ªôt b∆∞·ªõc ti·∫øn quan tr·ªçng, gi√∫p m·ªü r·ªông kh·∫£ nƒÉng ch·∫°y m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn m√† kh√¥ng c·∫ßn ph·ª• thu·ªôc v√†o GPU. ƒêi·ªÅu n√†y mang l·∫°i l·ª£i √≠ch l·ªõn cho c√°c doanh nghi·ªáp v√† nh√† nghi√™n c·ª©u mu·ªën tri·ªÉn khai AI trong m√¥i tr∆∞·ªùng h·∫°n ch·∫ø t√†i nguy√™n. Tuy nhi√™n, ƒë·ªÉ ƒë·∫°t hi·ªáu su·∫•t t·ªëi ∆∞u, ng∆∞·ªùi d√πng v·∫´n c·∫ßn tinh ch·ªânh c√°c tham s·ªë m√¥ h√¨nh ph√π h·ª£p v·ªõi ph·∫ßn c·ª©ng c·ª• th·ªÉ c·ªßa m√¨nh.\n8. Dim.AUTO PyTorch 2.6 gi·ªõi thi·ªáu Dim.AUTO, m·ªôt t√≠nh nƒÉng m·ªõi gi√∫p ng∆∞·ªùi d√πng vi·∫øt m√£ linh ho·∫°t h∆°n khi l√†m vi·ªác v·ªõi tensor c√≥ k√≠ch th∆∞·ªõc ƒë·ªông. Thay v√¨ ph·∫£i ch·ªâ ƒë·ªãnh r√µ k√≠ch th∆∞·ªõc c·ªßa m·ªôt chi·ªÅu (dimension) trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p nh·∫•t ƒë·ªãnh, Dim.AUTO cho ph√©p PyTorch t·ª± ƒë·ªông x√°c ƒë·ªãnh k√≠ch th∆∞·ªõc ph√π h·ª£p d·ª±a tr√™n ng·ªØ c·∫£nh.\nƒê√°nh gi√°: ƒê√¢y l√† m·ªôt c·∫£i ti·∫øn nh·ªè nh∆∞ng h·ªØu √≠ch, gi√∫p ƒë∆°n gi·∫£n h√≥a m√£ ngu·ªìn v√† gi·∫£m thi·ªÉu l·ªói do vi·ªác x·ª≠ l√Ω k√≠ch th∆∞·ªõc tensor ph·ª©c t·∫°p, ƒë·∫∑c bi·ªát trong c√°c ki·∫øn tr√∫c m·∫°ng s√¢u c√≥ c·∫•u tr√∫c ƒë·ªông.\n9. Thay ƒë·ªïi trong tham s·ªë weights_only c·ªßa torch.load Tr∆∞·ªõc ƒë√¢y, torch.load c√≥ tham s·ªë weights_only=True, gi√∫p ng∆∞·ªùi d√πng ch·ªâ t·∫£i tr·ªçng s·ªë c·ªßa m√¥ h√¨nh, b·ªè qua c√°c metadata kh√°c. Tuy nhi√™n, trong PyTorch 2.6, gi√° tr·ªã m·∫∑c ƒë·ªãnh c·ªßa tham s·ªë n√†y ƒë∆∞·ª£c thay ƒë·ªïi ƒë·ªÉ tr√°nh l·ªói ti·ªÅm ·∫©n khi t·∫£i m√¥ h√¨nh.\nƒê√°nh gi√°: Vi·ªác ƒëi·ªÅu ch·ªânh gi√° tr·ªã m·∫∑c ƒë·ªãnh gi√∫p ƒë·∫£m b·∫£o t√≠nh nh·∫•t qu√°n khi t·∫£i m√¥ h√¨nh, tr√°nh c√°c tr∆∞·ªùng h·ª£p m·∫•t metadata quan tr·ªçng. Tuy nhi√™n, ƒëi·ªÅu n√†y c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn m·ªôt s·ªë pipeline ƒë√£ s·ª≠ d·ª•ng weights_only=True trong c√°c phi√™n b·∫£n tr∆∞·ªõc.\n10. Ng·ª´ng h·ªó tr·ª£ k√™nh Anaconda ch√≠nh th·ª©c c·ªßa PyTorch PyTorch 2.6 ch√≠nh th·ª©c th√¥ng b√°o ng·ª´ng cung c·∫•p g√≥i c√†i ƒë·∫∑t th√¥ng qua k√™nh Anaconda ch√≠nh th·ª©c. Thay v√†o ƒë√≥, ng∆∞·ªùi d√πng ƒë∆∞·ª£c khuy·∫øn ngh·ªã s·ª≠ d·ª•ng pip ho·∫∑c conda-forge ƒë·ªÉ c√†i ƒë·∫∑t PyTorch.\nƒê√°nh gi√°: ƒê√¢y l√† m·ªôt thay ƒë·ªïi quan tr·ªçng ·∫£nh h∆∞·ªüng ƒë·∫øn ng∆∞·ªùi d√πng Anaconda, ƒë·∫∑c bi·ªát l√† nh·ªØng ai quen v·ªõi vi·ªác c√†i ƒë·∫∑t PyTorch t·ª´ k√™nh ch√≠nh th·ª©c. Tuy nhi√™n, quy·∫øt ƒë·ªãnh n√†y gi√∫p t·∫≠p trung v√†o c√°c ph∆∞∆°ng th·ª©c c√†i ƒë·∫∑t ph·ªï bi·∫øn h∆°n, ƒë·∫£m b·∫£o t√≠nh nh·∫•t qu√°n v√† c·∫≠p nh·∫≠t nhanh h∆°n.\nK·∫øt lu·∫≠n PyTorch 2.6 mang l·∫°i nhi·ªÅu c·∫£i ti·∫øn ƒë√°ng ch√∫ √Ω, bao g·ªìm h·ªó tr·ª£ Python 3.13, c·∫£i thi·ªán hi·ªáu su·∫•t tr√™n GPU Intel, h·ªó tr·ª£ FP16 tr√™n CPU X86, v√† gi·ªõi thi·ªáu c√°c t√≠nh nƒÉng m·ªõi nh∆∞ Dim.AUTO, torch.compiler.set_stance, hay torch.library.triton_op. Nh·ªØng thay ƒë·ªïi n√†y gi√∫p PyTorch tr·ªü n√™n linh ho·∫°t h∆°n, t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t t·ªët h∆°n, v√† h·ªó tr·ª£ m·∫°nh m·∫Ω h∆°n cho c√°c m√¥ h√¨nh AI/ML.\nD√π c√≥ m·ªôt s·ªë thay ƒë·ªïi c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn c√°ch c√†i ƒë·∫∑t v√† s·ª≠ d·ª•ng PyTorch (nh∆∞ vi·ªác ng·ª´ng h·ªó tr·ª£ Anaconda), h·∫ßu h·∫øt c√°c c·∫≠p nh·∫≠t ƒë·ªÅu mang l·∫°i l·ª£i √≠ch l·ªõn cho c·ªông ƒë·ªìng ng∆∞·ªùi d√πng.\nT√†i li·ªáu tham kh·∫£o PyTorch 2.6 Release Notes Phoronix: PyTorch 2.6 Features GitHub: PyTorch Release 2.6 B√†i vi·∫øt tr√™n ƒë√£ t·ªïng h·ª£p v√† ph√¢n t√≠ch c√°c ƒëi·ªÉm m·ªõi trong PyTorch 2.6 so v·ªõi c√°c phi√™n b·∫£n tr∆∞·ªõc, gi√∫p b·∫°n ƒë·ªçc hi·ªÉu r√µ h∆°n v·ªÅ nh·ªØng thay ƒë·ªïi quan tr·ªçng. N·∫øu b·∫°n c√≥ b·∫•t k·ª≥ c√¢u h·ªèi ho·∫∑c √Ω ki·∫øn n√†o, h√£y ƒë·ªÉ l·∫°i b√¨nh lu·∫≠n b√™n d∆∞·ªõi!\n","date":"Jan 31, 2025","img":"https://unsplash.it/1920/1080?image=222","permalink":"/blog/2025-01-31-pytorch2.6/","series":null,"tags":["pytorch"],"title":"Pytorch 2.6"},{"categories":null,"content":" Ng·ªØ c·∫£nh, ch·∫©n b·ªã d·ªØ li·ªáu gi·∫£ l·∫≠p M√¥ t·∫£ d·ªØ li·ªáu: M√¥ t·∫£ D·ªØ Li·ªáu Thi·∫øu: Code m·∫´u b·∫±ng python Ph∆∞∆°ng Ph√°p t√°i t·∫°o D·ªØ Li·ªáu D·ª±a Tr√™n Decision Tree Regession ƒê√°nh gi√° hi·ªáu qu·∫£ c·ªßa vi·ªác t√°i t·∫°o d·ªØ li·ªáu 1.Statistical Comparison - So s√°nh th·ªëng k√™ 2.Autocorrelation 3. Ph√¢n t√≠ch xu h∆∞·ªõng v√† m√πa v·ª• - STL Decomposition (Trend and Seasonality) So S√°nh Xu H∆∞·ªõng (Trend Comparison) So S√°nh T√≠nh M√πa V·ª• (Seasonality Comparison) H·∫°n Ch·∫ø C·ªßa t√°i t·∫°o D·ªØ Li·ªáu B·∫±ng H·ªìi Quy Tuy·∫øn T√≠nh K·∫øt lu·∫≠n T√†i li·ªáu tham kh·∫£o ·ªû ph·∫ßn tr∆∞·ªõc ƒë√≥, ch√∫ng ta ƒë√£ n√™u l√™n b√†i to√°n d·ªØ li·ªáu chu·ªói th·ªùi gian c√≥ 10% data b·ªã NA v√† s·ª≠ d·ª•ng linear regression ƒë·ªÉ t√°i t·∫°o c√°c ƒëi·ªÉm d·ªØ li·ªáu NA tr√™n. ·ªû b√†i to√°n n√†y, ch√∫ng ta ƒëi v√†o lu√¥n ph√¢n t√≠ch s·ª≠ d·ª•ng Decision Tree Regression thay th·∫ø cho liner regression v√† xem th·ª≠ vi·ªác thay th·∫ø n√†o c√≥ mang cho d·ªØ li·ªáu c·ªßa ch√∫ng ta t·ªët h∆°n hay kh√¥ng\nNg·ªØ c·∫£nh, ch·∫©n b·ªã d·ªØ li·ªáu gi·∫£ l·∫≠p M√¥ t·∫£ d·ªØ li·ªáu: M·ªôt chu·ªói th·ªùi gian t·ª´ ng√†y 1 th√°ng 1 nƒÉm 2025 ƒë·∫øn ng√†y 30 th√°ng 4 nƒÉm 2025 ƒë∆∞·ª£c t·∫°o ra v·ªõi c√°c kho·∫£ng th·ªùi gian 10 ph√∫t. chu·ªói th·ªùi gian c√≥ chu k·ª≥ ng√†y-ƒë√™m: cao v√†o ban ng√†y (t·ª´ 6 AM ƒë·∫øn 6 PM) v√† th·∫•p v√†o ban ƒë√™m. M√¥ t·∫£ D·ªØ Li·ªáu Thi·∫øu: 10% gi√° tr·ªã nƒÉng l∆∞·ª£ng ƒë∆∞·ª£c ch·ªçn ng·∫´u nhi√™n v√† thay th·∫ø b·∫±ng NaN ƒë·ªÉ m√¥ ph·ªèng d·ªØ li·ªáu b·ªã thi·∫øu. Code m·∫´u b·∫±ng python 1import pandas as pd 2import numpy as np 3from datetime import datetime 4import matplotlib.pyplot as plt 5 6# Simulate mock energy production dataset 7def simulate_energy_data(start_date, end_date, freq=\u0026#39;10min\u0026#39;): 8 # Create a datetime index with 10-minute intervals 9 datetime_index = pd.date_range(start=start_date, end=end_date, freq=freq) 10 11 # Simulate energy production with day-night cycles 12 np.random.seed(42) # For reproducibility 13 hours = datetime_index.hour 14 day_energy = np.random.normal(loc=300, scale=30, size=len(hours)) 15 night_energy = np.random.normal(loc=50, scale=15, size=len(hours)) 16 energy_values = np.where((hours \u0026gt;= 6) \u0026amp; (hours \u0026lt;= 18), day_energy, night_energy) 17 18 # Introduce missing values (10% of the dataset) 19 num_missing = int(0.1 * len(energy_values)) # 10% of data will be missing 20 missing_indices = np.random.choice(len(energy_values), num_missing, replace=False) 21 energy_values[missing_indices] = np.nan # Set randomly selected indices to NaN 22 23 # Create DataFrame with the simulated energy data 24 energy_data = pd.DataFrame({ 25 \u0026#39;Datetime\u0026#39;: datetime_index, 26 \u0026#39;Energy_Production\u0026#39;: energy_values 27 }) 28 29 return energy_data 30 31 32def plot_origin_data(energy_data_with_missing): 33 plt.figure(figsize=(24, 6)) 34 plt.plot(energy_data_with_missing[\u0026#39;Datetime\u0026#39;], energy_data_with_missing[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Energy Production\u0026#39;) 35 plt.xlabel(\u0026#39;Datetime\u0026#39;) 36 plt.ylabel(\u0026#39;Energy Production\u0026#39;) 37 plt.title(\u0026#39;Simulated Energy Production Over Time\u0026#39;) 38 plt.legend() 39 40 plt.grid(True) 41 plt.show() 42# Main script 43if __name__ == \u0026#34;__main__\u0026#34;: 44 start_date = datetime(2025, 1, 1) 45 end_date = datetime(2025, 4, 40) 46 47 # Generate the simulated dataset 48 energy_data_with_missing = simulate_energy_data(start_date, end_date) 49 50 # Display the first few rows of the dataset 51 print(energy_data_with_missing.head()) 52 53 54 plot_origin_data(energy_data_with_missing) Ph∆∞∆°ng Ph√°p t√°i t·∫°o D·ªØ Li·ªáu D·ª±a Tr√™n Decision Tree Regession 1 2from sklearn.tree import DecisionTreeRegressor 3 4# Impute missing values using linear regression 5def impute_missing_values(data): 6 # Extract the non-missing data 7 non_missing_data = data.dropna() 8 9 # Prepare the features (X) and target (y) 10 X = non_missing_data.index.values.reshape(-1, 1) 11 y = non_missing_data[\u0026#39;Energy_Production\u0026#39;].values 12 13 # Fit the linear regression model 14 model = DecisionTreeRegressor(max_depth=5, random_state=42) 15 model.fit(X, y) 16 17 # Predict the missing values 18 missing_data = data[data[\u0026#39;Energy_Production\u0026#39;].isna()] 19 X_missing = missing_data.index.values.reshape(-1, 1) 20 predicted_values = model.predict(X_missing) 21 22 # Create a DataFrame for the imputed data 23 imputed_data = data.copy() 24 imputed_data.loc[data[\u0026#39;Energy_Production\u0026#39;].isna(), \u0026#39;Energy_Production\u0026#39;] = predicted_values 25 26 return imputed_data 27 28 29def plot_full_data(energy_data_imputed,energy_data_with_missing): 30 plt.figure(figsize=(24, 6)) 31 32 plt.plot(energy_data_imputed[\u0026#39;Datetime\u0026#39;], energy_data_imputed[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Imputed Data using Decision regression\u0026#39;, color=\u0026#39;blue\u0026#39; ) 33 plt.plot(energy_data_with_missing[\u0026#39;Datetime\u0026#39;], energy_data_with_missing[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 34 plt.xlabel(\u0026#39;Datetime\u0026#39;) 35 plt.ylabel(\u0026#39;Energy Production\u0026#39;) 36 plt.title(\u0026#39;Simulated Energy Production Over Time (Original vs Imputed)\u0026#39;) 37 plt.legend() 38 plt.grid(True) 39 plt.show() 40 41# Main script 42if __name__ == \u0026#34;__main__\u0026#34;: 43 44 start_date = datetime(2024, 1, 1) 45 end_date = datetime(2024, 4, 30) 46 47 # Generate the simulated dataset 48 energy_data_with_missing = simulate_energy_data(start_date, end_date) 49 50 51 plot_origin_data(energy_data_with_missing) 52 53 54 # Impute the missing values 55 energy_data_imputed = impute_missing_values(energy_data_with_missing.copy()) 56 57 # Display the first few rows of the dataset 58 print(energy_data_imputed.head()) 59 60 plot_full_data(energy_data_imputed,energy_data_with_missing) Nh√¨n ƒë·ªì th·ªã, ch√∫ng ta th·∫•y r·∫±ng gi√° tr·ªã c·ªßa c√°c d·ªØ li·ªáu t√°i t·∫°o kh√° t∆∞∆°ng ƒë·ªìng v·ªõi d·ªØ li·ªáu g·ªëc. M·ªôt s·ªë kho·∫£ng tr·ªëng ƒë∆∞·ª£c t√°i t·∫°o t·ªët, m·ªôt s·ªë d·ªØ li·ªáu ·ªü ƒëi·ªÉm c·ª±c tr·ªã c≈©ng ƒë∆∞·ª£c t√°i t·∫°o. C·∫ßn c√°c ph√¢n t√≠ch chuy√™n s√¢u h∆°n\nƒê√°nh gi√° hi·ªáu qu·∫£ c·ªßa vi·ªác t√°i t·∫°o d·ªØ li·ªáu 1.Statistical Comparison - So s√°nh th·ªëng k√™ So s√°nh c√°c ch·ªâ s·ªë th·ªëng k√™ (trung b√¨nh, ƒë·ªô l·ªách chu·∫©n, gi√° tr·ªã nh·ªè nh·∫•t, gi√° tr·ªã l·ªõn nh·∫•t) ƒë·ªÉ ƒë·∫£m b·∫£o d·ªØ li·ªáu t√°i t·∫°o ph√π h·ª£p v·ªõi ph√¢n ph·ªëi d·ªØ li·ªáu g·ªëc.\n1 2# Statistical comparison function using describe 3def statistical_comparison(original_data, imputed_data): 4 original_stats = original_data[\u0026#39;Energy_Production\u0026#39;].describe() 5 imputed_stats = imputed_data[\u0026#39;Energy_Production\u0026#39;].describe() 6 comparison = pd.DataFrame({ 7 \u0026#39;Metric\u0026#39;: original_stats.index, 8 \u0026#39;Original Data\u0026#39;: original_stats.values, 9 \u0026#39;Imputed Data\u0026#39;: imputed_stats.values 10 }) 11 return comparison 12 13comparison = statistical_comparison(energy_data_with_missing.dropna(), energy_data_imputed) 14print(comparison) K·∫øt qu·∫£\n1 Metric Original Data Imputed Data 20 count 15553.000000 17281.000000 31 mean 185.155737 185.170568 42 std 127.062030 120.682665 53 min -16.984058 -16.984058 64 25% 51.260972 53.345570 75 50% 257.313693 185.457881 86 75% 302.393653 298.754461 97 max 415.581945 415.581945 So s√°nh v·ªõi Linear Regression ·ªü b√†i tr∆∞·ªõc ƒë√≥\n1 Metric Original Data Imputed Data Linear Regression 20 count 15553.000000 17281.000000 31 mean 185.155737 185.155865 42 std 127.062030 120.541640 53 min -16.984058 -16.984058 64 25% 51.260972 53.436820 75 50% 257.313693 185.404682 86 75% 302.393653 298.653209 97 max 415.581945 415.581945 T·ª´ b·∫£ng so s√°nh th·ªëng k√™ ·ªü tr√™n , ch√∫ng ta c√≥ th·ªÉ r√∫t ra nh·ªØng k·∫øt lu·∫≠n sau:\nS·ªë L∆∞·ª£ng (Count): B·ªô d·ªØ li·ªáu t√°i t·∫°o ch·ª©a nhi·ªÅu ƒëi·ªÉm d·ªØ li·ªáu h∆°n, 17281, so v·ªõi b·ªô d·ªØ li·ªáu g·ªëc, 15553, do vi·ªác t√°i t·∫°o c√°c gi√° tr·ªã thi·∫øu ƒë·ªÉ ƒë·∫£m b·∫£o d·ªØ li·ªáu ƒë·∫ßy ƒë·ªß.\nTrung B√¨nh (Mean): Trung b√¨nh c·ªßa d·ªØ li·ªáu t√°i t·∫°o l√† 185.17, g·∫ßn gi·ªëng v·ªõi gi√° tr·ªã trung b√¨nh c·ªßa d·ªØ li·ªáu g·ªëc 185.15, ƒëi·ªÅu n√†y c√≥ nghƒ©a l√† xu h∆∞·ªõng trung t√¢m c·ªßa d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c duy tr√¨ trong qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu. Tuy nhi√™n, Linear Regression cho gi√° tr·ªã trung b√¨nh g·∫ßn v·ªõi t·∫≠p d·ªØ li·ªáu g·ªëc h∆°n.\nƒê·ªô L·ªách Chu·∫©n (Standard Deviation): D·ªØ li·ªáu t√°i t·∫°o c√≥ s·ª± ph√¢n t√°n th·∫•p h∆°n (ƒë·ªô l·ªách chu·∫©n = 120.6 so v·ªõi 127.06 c·ªßa d·ªØ li·ªáu g·ªëc). ƒêi·ªÅu n√†y c√≥ th·ªÉ cho th·∫•y r·∫±ng trong qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu, c√°c gi√° tr·ªã ƒë√£ tr·ªü n√™n m∆∞·ª£t m√† h∆°n, gi·∫£m b·ªõt s·ª± ph√¢n t√°n\nGi√° Tr·ªã T·ªëi Thi·ªÉu v√† T·ªëi ƒêa: Gi√° tr·ªã t·ªëi thi·ªÉu (-16.984058) v√† t·ªëi ƒëa (415.581945) l√† gi·ªëng nhau, ƒëi·ªÅu n√†y g·ª£i √Ω r·∫±ng qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu kh√¥ng t·∫°o ra c√°c gi√° tr·ªã ngo·∫°i lai c·ª±c ƒëoan ho·∫∑c kh√¥ng ƒëi ra ngo√†i ph·∫°m vi c·ªßa d·ªØ li·ªáu g·ªëc.\nC√°c Ph√¢n V·ªã (Quartiles 25%, 50%, 75%):\nPh√¢n v·ªã th·ª© 25 (quartile th·∫•p) cao h∆°n m·ªôt ch√∫t trong d·ªØ li·ªáu t√°i t·∫°o , 53.345570 so v·ªõi 51.26 c·ªßa d·ªØ li·ªáu g·ªëc, cho th·∫•y c√°c gi√° tr·ªã t√°i t·∫°o ƒë√£ l·∫•p ƒë·∫ßy nhi·ªÅu kho·∫£ng tr·ªëng ·ªü ph·∫°m vi th·∫•p.\nTrung v·ªã (50%) ƒë√£ thay ƒë·ªïi ƒë√°ng k·ªÉ t·ª´ 257.31 trong d·ªØ li·ªáu g·ªëc th√†nh 185.45 trong d·ªØ li·ªáu t√°i t·∫°o , cho th·∫•y c√°c gi√° tr·ªã t√°i t·∫°o ƒë√£ gi·∫£m ƒë·ªô l·ªách d·ªØ li·ªáu c·ªßa c√°c ph·∫ßn t·ª≠ d·ªØ li·ªáu cao.\nPh√¢n v·ªã th·ª© 75 (quartile cao) 302.39 v√† 298.75 , g·∫ßn nh∆∞ t∆∞∆°ng ƒë∆∞∆°ng nhau, ph·∫£n √°nh r·∫±ng c√°c gi√° tr·ªã cao ƒë√£ ƒë∆∞·ª£c b·∫£o t·ªìn t·ªët.\nK·∫øt lu·∫≠n: Ph∆∞∆°ng ph√°p h·ªìi quy Decision Tree ƒë√£ b·∫£o t·ªìn ph√¢n ph·ªëi t·ªïng th·ªÉ v√† ph·∫°m vi c·ªßa d·ªØ li·ªáu, trong khi l√†m gi·∫£m s·ª± bi·∫øn thi√™n v√† l√†m m∆∞·ª£t d·ªØ li·ªáu m·ªôt ch√∫t.\n2.Autocorrelation Ki·ªÉm tra xem t·ª± t∆∞∆°ng quan c·ªßa chu·ªói c√≥ ƒë∆∞·ª£c duy tr√¨ sau khi t√°i t·∫°o d·ªØ li·ªáu hay kh√¥ng.\n1 2 3# Autocorrelation analysis function 4def autocorrelation_analysis(original_data, imputed_data): 5 fig, axes = plt.subplots(1, 2, figsize=(15, 6)) 6 plot_acf(original_data[\u0026#39;Energy_Production\u0026#39;].dropna(), ax=axes[0], title=\u0026#39;ACF of Original Data\u0026#39;) 7 plot_acf(imputed_data[\u0026#39;Energy_Production\u0026#39;], ax=axes[1], title=\u0026#39;ACF of Imputed Data\u0026#39;) 8 plt.tight_layout() 9 plt.show() Quan s√°t ƒë·ªì th·ªã ACF tr√™n, ch√∫ng ta c√≥ th·ªÉ r√∫t ra c√°c √Ω ch√≠nh sau\nB·∫£o T·ªìn C√°c Ph·ª• Thu·ªôc - Preservation of Temporal Dependencies:\nH√¨nh d·∫°ng v√† s·ª± suy gi·∫£m c·ªßa ACF trong d·ªØ li·ªáu t√°i t·∫°o c√≥ s·ª± t∆∞∆°ng ƒë·ªìng ƒë√°ng k·ªÉ v·ªõi d·ªØ li·ªáu g·ªëc. ƒêi·ªÅu n√†y cho th·∫•y r·∫±ng c√°c ph·ª• thu·ªôc th·ªùi gian ƒë√£ ƒë∆∞·ª£c b·∫£o t·ªìn kh√° t·ªët sau qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu.\nHi·ªáu ·ª®ng L√†m M·ªãn - Slight Smoothing Effect:\nACF tr√™n d·ªØ li·ªáu t√°i t·∫°o cho th·∫•y gi√° tr·ªã ·ªü m·ªôt s·ªë ƒë·ªô tr·ªÖ (lags) th·∫•p h∆°n so v·ªõi d·ªØ li·ªáu g·ªëc. ƒêi·ªÅu n√†y c√≥ th·ªÉ l√† do m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh l√†m m·ªãn c√°c c·ª±c tr·ªã, d·∫´n ƒë·∫øn gi·∫£m nh·∫π m·ª©c ƒë·ªô bi·∫øn ƒë·ªông.\nC√°c M·∫´u Chu K·ª≥ Trong ACF - Cyclic Patterns:\nC√°c ƒë·ªânh chu k·ª≥ trong ACF, ch·∫≥ng h·∫°n nh∆∞ t√≠nh m√πa v·ª• h√†ng ng√†y, d∆∞·ªùng nh∆∞ ƒë∆∞·ª£c duy tr√¨ gi·ªØa d·ªØ li·ªáu g·ªëc v√† d·ªØ li·ªáu t√°i t·∫°o . ƒêi·ªÅu n√†y cho th·∫•y r·∫±ng qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu ƒë√£ b·∫£o t·ªìn c√°c h√†nh vi tu·∫ßn ho√†n trong t·∫≠p d·ªØ li·ªáu.\nT√≠nh ·ªîn ƒê·ªãnh Chung:\nS·ª± t∆∞∆°ng ƒë·ªìng gi·ªØa hai bi·ªÉu ƒë·ªì ACF l√† m·ªôt d·∫•u hi·ªáu t√≠ch c·ª±c, cho th·∫•y ph∆∞∆°ng ph√°p t√°i t·∫°o d·ªØ li·ªáu b·∫±ng h·ªìi quy tuy·∫øn t√≠nh ƒë√£ gi·ªØ l·∫°i t·ªët c·∫•u tr√∫c c·ªët l√µi trong d·ªØ li·ªáu.\nK·∫øt Lu·∫≠n:\nPh∆∞∆°ng ph√°p h·ªìi quy tuy·∫øn t√≠nh kh√¥ng ch·ªâ b·∫£o t·ªìn m·ªëi li√™n h·ªá th·ªùi gian trong d·ªØ li·ªáu m√† c√≤n duy tr√¨ c√°c m·∫´u chu k·ª≥, m·∫∑c d√π c√≥ m·ªôt ch√∫t hi·ªáu ·ª©ng l√†m m·ªãn.\n3. Ph√¢n t√≠ch xu h∆∞·ªõng v√† m√πa v·ª• - STL Decomposition (Trend and Seasonality) So S√°nh Xu H∆∞·ªõng (Trend Comparison) 1 2# STL decomposition function to extract and plot trend component 3def stl_decomposition_trend(original_data, imputed_data, period): 4 stl_original = STL(original_data[\u0026#39;Energy_Production\u0026#39;] , period=period) 5 result_original = stl_original.fit() 6 trend_original = result_original.trend 7 8 stl_imputed = STL(imputed_data[\u0026#39;Energy_Production\u0026#39;], period=period) 9 result_imputed = stl_imputed.fit() 10 trend_imputed = result_imputed.trend 11 12 plt.figure(figsize=(24, 6)) 13 plt.plot(original_data[\u0026#39;Datetime\u0026#39;], trend_original, label=\u0026#39;Trend of Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 14 plt.plot(imputed_data[\u0026#39;Datetime\u0026#39;], trend_imputed, label=\u0026#39;Trend of Imputed Data\u0026#39;, color=\u0026#39;blue\u0026#39;) 15 plt.xlabel(\u0026#39;Datetime\u0026#39;) 16 plt.ylabel(\u0026#39;Trend\u0026#39;) 17 plt.title(\u0026#39;STL Decomposition Trend of Original and Imputed Data\u0026#39;) 18 plt.legend() 19 plt.grid(True) 20 plt.show() 21 22stl_decomposition_trend(energy_data_with_missing.dropna(), energy_data_imputed, period=144) # Daily seasonality (144 10-min intervals in a day) B·∫£o T·ªìn Xu H∆∞·ªõng D√†i H·∫°n:\nƒê∆∞·ªùng Xu h∆∞·ªõng t√°i t·∫°o (m√†u xanh d∆∞∆°ng) nh√¨n chung ph√π h·ª£p v·ªõi xu h∆∞·ªõng g·ªëc (m√†u ƒë·ªè), cho th·∫•y ph∆∞∆°ng ph√°p t√°i t·∫°o h·ªìi quy tuy·∫øn t√≠nh ƒë√£ b·∫£o t·ªìn ƒë∆∞·ª£c chuy·ªÉn ƒë·ªông d√†i h·∫°n trong d·ªØ li·ªáu.\nHi·ªáu ·ª®ng L√†m M·ªãn:\nƒê∆∞·ªùng Xu h∆∞·ªõng t√°i t·∫°o m∆∞·ª£t m√† h∆°n so v·ªõi xu h∆∞·ªõng g·ªëc, ƒë·∫∑c bi·ªát ·ªü nh·ªØng n∆°i xu h∆∞·ªõng g·ªëc c√≥ nhi·ªÅu bi·∫øn ƒë·ªông. ƒêi·ªÅu n√†y l√† ƒë·∫∑c ƒëi·ªÉm c·ªßa h·ªìi quy tuy·∫øn t√≠nh, v·ªën c√≥ xu h∆∞·ªõng kh√¥ng ph·∫£n √°nh t·ªët c√°c bi·∫øn ƒë·ªông m·∫°nh v√† l√†m m·ªãn c√°c c·ª±c tr·ªã.\nSo S√°nh T√≠nh M√πa V·ª• (Seasonality Comparison) 1 2 3def stl_decomposition_seasonality(original_data, imputed_data, period): 4 stl_original = STL(original_data[\u0026#39;Energy_Production\u0026#39;], period=period) 5 result_original = stl_original.fit() 6 seasonality_original = result_original.seasonal 7 8 stl_imputed = STL(imputed_data[\u0026#39;Energy_Production\u0026#39;], period=period) 9 result_imputed = stl_imputed.fit() 10 seasonality_imputed = result_imputed.seasonal 11 12 plt.figure(figsize=(24, 6)) 13 plt.plot(original_data[\u0026#39;Datetime\u0026#39;], seasonality_original, label=\u0026#39;Seasonality of Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 14 plt.plot(imputed_data[\u0026#39;Datetime\u0026#39;], seasonality_imputed, label=\u0026#39;Seasonality of Imputed Data\u0026#39;, color=\u0026#39;blue\u0026#39;) 15 plt.xlabel(\u0026#39;Datetime\u0026#39;) 16 plt.ylabel(\u0026#39;Seasonality\u0026#39;) 17 plt.title(\u0026#39;STL Decomposition Seasonality of Original and Imputed Data\u0026#39;) 18 plt.legend() 19 plt.grid(True) 20 plt.show() 21stl_decomposition_seasonality(energy_data_with_missing.dropna(), energy_data_imputed, period=144) # Daily seasonality (144 10-min intervals in a day) B·∫£o T·ªìn t√≠nh Chu K·ª≥:\nƒê∆∞·ªùng m√πa v·ª• t√°i t·∫°o th·ªÉ hi·ªán ra c√°c m·∫´u chu k·ª≥ t∆∞∆°ng ƒë·ªëi g·∫ßn gi·ªëng v·ªõi chu k·ª≥ c·ªßa ƒë∆∞·ªùng m√πa v·ª• g·ªëc, ph·∫£n √°nh r·∫±ng d·ªØ li·ªáu c√°c chu k·ª≥ s·∫£n xu·∫•t ng√†y-ƒë√™m ƒë√£ ƒë∆∞·ª£c duy tr√¨ kh√° t·ªët.\nGi·∫£m Bi√™n ƒê·ªô Chu K·ª≥:\nBi√™n ƒë·ªô c·ªßa ƒë∆∞·ªùng m√πa v·ª• t√°i t·∫°o b·ªã gi·∫£m nh·∫π so v·ªõi g·ªëc, ƒë·∫∑c bi·ªát t·∫°i c√°c ƒë·ªânh v√† ƒë√°y. ƒêi·ªÅu n√†y cho th·∫•y qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu ƒë√£ l√†m cho c√°c bi·∫øn ƒë·ªông chu k·ª≥ ·ªü c·ª±c tr·ªã tr·ªü n√™n √≠t m·∫°nh m·∫Ω h∆°n.\nH·∫°n Ch·∫ø C·ªßa t√°i t·∫°o D·ªØ Li·ªáu B·∫±ng H·ªìi Quy Tuy·∫øn T√≠nh L√†m M·ªãn C√°c c·ª±c tr·ªã:\nT·ª´ so s√°nh th·ªëng k√™, ƒë·ªô l·ªách chu·∫©n th·∫•p h∆°n ·ªü d·ªØ li·ªáu t√°i t·∫°o cho th·∫•y t√≠nh bi·∫øn ƒë·ªông ƒë√£ b·ªã gi·∫£m.\nT·ª´ so s√°nh xu h∆∞·ªõng, xu h∆∞·ªõng t√°i t·∫°o m∆∞·ª£t h∆°n v√† thi·∫øu m·ªôt s·ªë bi·∫øn ƒë·ªông g·ªëc trong c√°c m·∫´u d√†i h·∫°n.\nGi·∫£ ƒê·ªãnh Tuy·∫øn T√≠nh:\nHi·ªáu ·ª©ng l√†m m·ªãn trong so s√°nh xu h∆∞·ªõng cho th·∫•y ph∆∞∆°ng ph√°p n√†y kh√≥ b·∫Øt k·ªãp c√°c thay ƒë·ªïi phi tuy·∫øn t√≠nh trong d·ªØ li·ªáu, ƒë·∫∑c bi·ªát t·∫°i c√°c giai ƒëo·∫°n c√≥ s·ª± thay ƒë·ªïi ƒë·ªôt ng·ªôt. Gi·∫£m Bi√™n ƒê·ªô M√πa V·ª•:\nSo s√°nh t√≠nh m√πa v·ª• cho th·∫•y bi√™n ƒë·ªô chu k·ª≥ t√°i t·∫°o th·∫•p h∆°n so v·ªõi g·ªëc, v·ªõi c√°c ƒë·ªânh v√† ƒë√°y b·ªã l√†m m·ªãn. ƒêi·ªÅu n√†y ph√π h·ª£p v·ªõi xu h∆∞·ªõng c·ªßa h·ªìi quy trong vi·ªác k√©o c√°c gi√° tr·ªã c·ª±c ƒëoan v·ªÅ trung b√¨nh. K·∫øt lu·∫≠n Ph∆∞∆°ng ph√°p t√°i t·∫°o h·ªìi quy tuy·∫øn t√≠nh b·∫£o t·ªìn ƒë∆∞·ª£c c√°c xu h∆∞·ªõng t·ªïng th·ªÉ v√† c√°c m·∫´u chu k·ª≥, nh∆∞ng l√†m gi·∫£m t√≠nh bi·∫øn ƒë·ªông v√† l√†m m·ªãn c√°c gi√° tr·ªã c·ª±c ƒëoan. Ngo√†i ra, n√≥ th·ªÉ hi·ªán s·ª± gi·∫£m nh·∫π c∆∞·ªùng ƒë·ªô c·ªßa c√°c chu k·ª≥ m√πa v·ª•, ƒëi·ªÅu n√†y ƒë∆∞·ª£c ph·∫£n √°nh trong c·∫£ ph√¢n t√≠ch th·ªëng k√™ v√† ph√¢n r√£ d·ªØ li·ªáu.\nTrong b√†i to√°n n√†y, s·ª± kh√°c bi·ªát c·ªßa Decision Tree v√† linear regression kh√¥ng r√µ r√†ng l·∫Øm, c·∫£ hai ƒë·ªÅu ƒë√°p ·ª©ng t·ªët nhu c·∫ßu t√°i t·∫°o d·ªØ li·ªáu.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt. Xin c·∫£m ∆°n v√† h·∫πn g·∫∑p l·∫°i.\nT√†i li·ªáu tham kh·∫£o https://www.geeksforgeeks.org/managing-missing-data-in-linear-regression/\nhttps://towardsdatascience.com/missing-data-in-time-series-machine-learning-techniques-6b2273ff8b45\nhttps://www.geeksforgeeks.org/dataset-for-linear-regression/\nhttps://www.geeksforgeeks.org/ml-handling-missing-values/\nhttps://codezup.com/mastering-linear-regression-time-series-forecasting/\n","date":"Jan 12, 2025","img":"https://unsplash.it/1920/1080?image=204","permalink":"/blog/2025-01-12-data-missing-time-serial-decision-tree-regression/","series":null,"tags":["Missing data","time-serials"],"title":"X·ª≠ L√Ω D·ªØ Li·ªáu Khi·∫øm Khuy·∫øt Trong D·ªØ Li·ªáu Chu·ªói Th·ªùi Gian S·ª≠ D·ª•ng Ph∆∞∆°ng Ph√°p Decision Tree Regression - Machine Learning Techniques for Mising Data in Time-Serials Using Decision Tree Regression"},{"categories":null,"content":" S·ª≠ D·ª•ng H·ªçc M√°y Cho Vi·ªác t√°i t·∫°o D·ªØ Li·ªáu Thi·∫øu Trong Chu·ªói Th·ªùi Gian Khi N√†o s·ª≠ d·ª•ng h·ªçc m√°y 1. M·∫´u d·ªØ li·ªáu Phi Tuy·∫øn T√≠nh: 2. B·ªô D·ªØ Li·ªáu C√≥ Nhi·ªÅu Chi·ªÅu: 3. Kho·∫£ng Tr·ªëng L·ªõn Trong D·ªØ Li·ªáu: 4. D·ªØ Li·ªáu b·ªã Thi·∫øu Kh√¥ng Ng·∫´u Nhi√™n: 5. T√≠nh Ch·∫Øc Ch·∫Øn: Nh·ªØng ƒê√°nh ƒê·ªïi khi s·ª≠ d·ª•ng h·ªçc m√°y thay cho c√°c ph∆∞∆°ng ph√°p truy·ªÅn th·ªëng: Ng·ªØ c·∫£nh, ch·∫©n b·ªã d·ªØ li·ªáu gi·∫£ l·∫≠p M√¥ t·∫£ d·ªØ li·ªáu: M√¥ t·∫£ D·ªØ Li·ªáu Thi·∫øu: Code m·∫´u b·∫±ng python Ph∆∞∆°ng Ph√°p t√°i t·∫°o D·ªØ Li·ªáu D·ª±a Tr√™n H·ªìi Quy ƒê√°nh gi√° hi·ªáu qu·∫£ c·ªßa vi·ªác t√°i t·∫°o d·ªØ li·ªáu 1.Statistical Comparison - So s√°nh th·ªëng k√™ 2.Autocorrelation 3. Ph√¢n t√≠ch xu h∆∞·ªõng v√† m√πa v·ª• - STL Decomposition (Trend and Seasonality) So S√°nh Xu H∆∞·ªõng (Trend Comparison) So S√°nh T√≠nh M√πa V·ª• (Seasonality Comparison) H·∫°n Ch·∫ø C·ªßa t√°i t·∫°o D·ªØ Li·ªáu B·∫±ng linear regression K·∫øt lu·∫≠n T√†i li·ªáu tham kh·∫£o D·ªØ li·ªáu b·ªã thi·∫øu trong ph√¢n t√≠ch chu·ªói th·ªùi gian l√† m·ªôt th√°ch th·ª©c ph·ªï bi·∫øn, th∆∞·ªùng x·∫£y ra do c·∫£m bi·∫øn h·ªèng, l·ªói truy·ªÅn d·ªØ li·ªáu ho·∫∑c c√°c v·∫•n ƒë·ªÅ b·∫£o tr√¨. Nh·ªØng kho·∫£ng tr·ªëng trong d·ªØ li·ªáu n√†y c√≥ th·ªÉ l√†m gi√°n ƒëo·∫°n d·ª± b√°o v√† l√†m l·ªách k·∫øt qu·∫£ ph√¢n t√≠ch, khi·∫øn cho th√¥ng tin tr·ªü n√™n kh√¥ng ƒë√°ng tin c·∫≠y.\nC√°c k·ªπ thu·∫≠t ƒë∆°n gi·∫£n nh∆∞ forward fill ho·∫∑c interpolation th∆∞·ªùng l√† gi·∫£i ph√°p m·∫∑c ƒë·ªãnh ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu. Tuy nhi√™n, khi ƒë·ªëi m·∫∑t v·ªõi c√°c m·∫´u d·ªØ li·ªáu ph·ª©c t·∫°p, xu h∆∞·ªõng phi tuy·∫øn t√≠nh ho·∫∑c ƒë·ªô bi·∫øn thi√™n cao, c√°c ph∆∞∆°ng ph√°p n√†y th∆∞·ªùng th·∫•t b·∫°i v√† t·∫°o ra k·∫øt qu·∫£ kh√¥ng ·ªïn ƒë·ªãnh.\nS·ª≠ D·ª•ng H·ªçc M√°y Cho Vi·ªác t√°i t·∫°o D·ªØ Li·ªáu Thi·∫øu Trong Chu·ªói Th·ªùi Gian H·ªçc m√°y (ML) cung c·∫•p m·ªôt ph∆∞∆°ng ph√°p m·∫°nh m·∫Ω ƒë·ªÉ t√°i t·∫°o d·ªØ li·ªáu thi·∫øu b·∫±ng c√°ch nh·∫≠n di·ªán c√°c m·∫´u v√† m·ªëi quan h·ªá trong d·ªØ li·ªáu. Kh√°c v·ªõi c√°c ph∆∞∆°ng ph√°p truy·ªÅn th·ªëng th∆∞·ªùng d·ª±a v√†o c√°c gi·∫£ ƒë·ªãnh v·ªÅ xu h∆∞·ªõng tuy·∫øn t√≠nh, h·ªçc m√°y c√≥ th·ªÉ ph√°t hi·ªán c√°c m·ªëi quan h·ªá phi tuy·∫øn t√≠nh v√† ƒëa bi·∫øn ph·ª©c t·∫°p, d·∫´n ƒë·∫øn vi·ªác t√°i t·∫°o d·ªØ li·ªáu thi·∫øu ch√≠nh x√°c h∆°n.\nKhi N√†o s·ª≠ d·ª•ng h·ªçc m√°y 1. M·∫´u d·ªØ li·ªáu Phi Tuy·∫øn T√≠nh: C√°c ph∆∞∆°ng ph√°p truy·ªÅn th·ªëng th∆∞·ªùng gi·∫£ ƒë·ªãnh r·∫±ng d·ªØ li·ªáu c√≥ xu h∆∞·ªõng tuy·∫øn t√≠nh, nh∆∞ng nhi·ªÅu b·ªô d·ªØ li·ªáu chu·ªói th·ªùi gian th·ª±c t·∫ø c√≥ c√°c m·∫´u phi tuy·∫øn m√† c√°c ph∆∞∆°ng ph√°p n√†y kh√¥ng th·ªÉ n·∫Øm b·∫Øt. C√°c thu·∫≠t to√°n h·ªçc m√°y c√≥ th·ªÉ h·ªçc v√† m√¥ h√¨nh h√≥a nh·ªØng m·∫´u ph·ª©c t·∫°p n√†y, c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c c·ªßa vi·ªác t√°i t·∫°o d·ªØ li·ªáu thi·∫øu.\n2. B·ªô D·ªØ Li·ªáu C√≥ Nhi·ªÅu Chi·ªÅu: Khi l√†m vi·ªác v·ªõi c√°c b·ªô d·ªØ li·ªáu c√≥ nhi·ªÅu ƒë·∫∑c tr∆∞ng ho·∫∑c bi·∫øn s·ªë, c√°c ph∆∞∆°ng ph√°p t√°i t·∫°o d·ªØ li·ªáu truy·ªÅn th·ªëng c√≥ th·ªÉ g·∫∑p kh√≥ khƒÉn. C√°c k·ªπ thu·∫≠t h·ªçc m√°y c√≥ th·ªÉ t·∫≠n d·ª•ng c√°c ƒë·∫∑c tr∆∞ng b·ªï sung trong b·ªô d·ªØ li·ªáu c√≥ nhi·ªÅu chi·ªÅu, gi√∫p t√°i t·∫°o d·ªØ li·ªáu thi·∫øu hi·ªáu qu·∫£ h∆°n b·∫±ng c√°ch xem x√©t ƒë·ªìng th·ªùi nhi·ªÅu bi·∫øn.\n3. Kho·∫£ng Tr·ªëng L·ªõn Trong D·ªØ Li·ªáu: ƒê·ªëi v·ªõi c√°c b·ªô d·ªØ li·ªáu c√≥ kho·∫£ng tr·ªëng l·ªõn, c√°c ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n nh∆∞ t√°i t·∫°o gi√° tr·ªã tr∆∞·ªõc c√≥ th·ªÉ kh√¥ng ƒë·ªß hi·ªáu qu·∫£. H·ªçc m√°y c√≥ th·ªÉ h·ªçc ƒë∆∞·ª£c xu h∆∞·ªõng t·ªïng th·ªÉ v√† c√°c m·∫´u trong d·ªØ li·ªáu, gi√∫p t√°i t·∫°o c√°c kho·∫£ng tr·ªëng l·ªõn m·ªôt c√°ch c√≥ √Ω nghƒ©a v√† ch√≠nh x√°c h∆°n.\n4. D·ªØ Li·ªáu b·ªã Thi·∫øu Kh√¥ng Ng·∫´u Nhi√™n: Trong c√°c tr∆∞·ªùng h·ª£p d·ªØ li·ªáu thi·∫øu kh√¥ng ng·∫´u nhi√™n (MNAR), c√°c ph∆∞∆°ng ph√°p t√°i t·∫°o d·ªØ li·ªáu truy·ªÅn th·ªëng, v·ªën gi·∫£ ƒë·ªãnh r·∫±ng d·ªØ li·ªáu thi·∫øu l√† ng·∫´u nhi√™n, c√≥ th·ªÉ d·∫´n ƒë·∫øn k·∫øt qu·∫£ sai l·ªách. C√°c ph∆∞∆°ng ph√°p h·ªçc m√°y c√≥ th·ªÉ h·ªçc c√°ch x·ª≠ l√Ω nh·ªØng sai l·ªách n√†y b·∫±ng c√°ch hi·ªÉu c√°c m·ªëi quan h·ªá ti·ªÅm ·∫©n trong d·ªØ li·ªáu, l√†m cho ch√∫ng tr·ªü n√™n m·∫°nh m·∫Ω v√† ch√≠nh x√°c h∆°n.\n5. T√≠nh Ch·∫Øc Ch·∫Øn: C√°c ph∆∞∆°ng ph√°p h·ªçc m√°y th∆∞·ªùng m·∫°nh m·∫Ω h∆°n, ƒë·∫∑c bi·ªát khi d·ªØ li·ªáu c√≥ c√°c m·∫´u ph·ª©c t·∫°p ho·∫∑c d·ªØ li·ªáu thi·∫øu tu√¢n theo c√°c c∆° ch·∫ø kh√¥ng x√°c ƒë·ªãnh. Ch√∫ng c√≥ th·ªÉ th√≠ch nghi v·ªõi c√°c lo·∫°i d·ªØ li·ªáu thi·∫øu kh√°c nhau, gi√∫p x·ª≠ l√Ω c√°c nhi·ªám v·ª• t√°i t·∫°o d·ªØ li·ªáu thi·∫øu trong chu·ªói th·ªùi gian ƒë·∫ßy th·ª≠ th√°ch. Nh·ªØng ƒê√°nh ƒê·ªïi khi s·ª≠ d·ª•ng h·ªçc m√°y thay cho c√°c ph∆∞∆°ng ph√°p truy·ªÅn th·ªëng: M·∫∑c d√π c√°c ph∆∞∆°ng ph√°p h·ªçc m√°y th∆∞·ªùng mang l·∫°i k·∫øt qu·∫£ ch√≠nh x√°c h∆°n, nh∆∞ng ch√∫ng y√™u c·∫ßu nhi·ªÅu t√†i nguy√™n t√≠nh to√°n h∆°n so v·ªõi c√°c ph∆∞∆°ng ph√°p truy·ªÅn th·ªëng. Tuy nhi√™n, t√≠nh linh ho·∫°t v√† s·ª©c m·∫°nh c·ªßa ch√∫ng khi·∫øn ch√∫ng tr·ªü th√†nh l·ª±a ch·ªçn l√Ω t∆∞·ªüng ƒë·ªÉ x·ª≠ l√Ω c√°c nhi·ªám v·ª• t√°i t·∫°o d·ªØ li·ªáu thi·∫øu trong chu·ªói th·ªùi gian, n∆°i ƒë·ªô ch√≠nh x√°c l√† y·∫øu t·ªë quan tr·ªçng.\nNg·ªØ c·∫£nh, ch·∫©n b·ªã d·ªØ li·ªáu gi·∫£ l·∫≠p M√¥ t·∫£ d·ªØ li·ªáu: M·ªôt chu·ªói th·ªùi gian t·ª´ ng√†y 1 th√°ng 1 nƒÉm 2025 ƒë·∫øn ng√†y 30 th√°ng 4 nƒÉm 2025 ƒë∆∞·ª£c t·∫°o ra v·ªõi c√°c kho·∫£ng th·ªùi gian 10 ph√∫t. chu·ªói th·ªùi gian c√≥ chu k·ª≥ ng√†y-ƒë√™m: cao v√†o ban ng√†y (t·ª´ 6 AM ƒë·∫øn 6 PM) v√† th·∫•p v√†o ban ƒë√™m. M√¥ t·∫£ D·ªØ Li·ªáu Thi·∫øu: 10% gi√° tr·ªã nƒÉng l∆∞·ª£ng ƒë∆∞·ª£c ch·ªçn ng·∫´u nhi√™n v√† thay th·∫ø b·∫±ng NaN ƒë·ªÉ m√¥ ph·ªèng d·ªØ li·ªáu b·ªã thi·∫øu. Code m·∫´u b·∫±ng python 1import pandas as pd 2import numpy as np 3from datetime import datetime 4import matplotlib.pyplot as plt 5 6# Simulate mock energy production dataset 7def simulate_energy_data(start_date, end_date, freq=\u0026#39;10min\u0026#39;): 8 # Create a datetime index with 10-minute intervals 9 datetime_index = pd.date_range(start=start_date, end=end_date, freq=freq) 10 11 # Simulate energy production with day-night cycles 12 np.random.seed(42) # For reproducibility 13 hours = datetime_index.hour 14 day_energy = np.random.normal(loc=300, scale=30, size=len(hours)) 15 night_energy = np.random.normal(loc=50, scale=15, size=len(hours)) 16 energy_values = np.where((hours \u0026gt;= 6) \u0026amp; (hours \u0026lt;= 18), day_energy, night_energy) 17 18 # Introduce missing values (10% of the dataset) 19 num_missing = int(0.1 * len(energy_values)) # 10% of data will be missing 20 missing_indices = np.random.choice(len(energy_values), num_missing, replace=False) 21 energy_values[missing_indices] = np.nan # Set randomly selected indices to NaN 22 23 # Create DataFrame with the simulated energy data 24 energy_data = pd.DataFrame({ 25 \u0026#39;Datetime\u0026#39;: datetime_index, 26 \u0026#39;Energy_Production\u0026#39;: energy_values 27 }) 28 29 return energy_data 30 31 32def plot_origin_data(energy_data_with_missing): 33 plt.figure(figsize=(24, 6)) 34 plt.plot(energy_data_with_missing[\u0026#39;Datetime\u0026#39;], energy_data_with_missing[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Energy Production\u0026#39;) 35 plt.xlabel(\u0026#39;Datetime\u0026#39;) 36 plt.ylabel(\u0026#39;Energy Production\u0026#39;) 37 plt.title(\u0026#39;Simulated Energy Production Over Time\u0026#39;) 38 plt.legend() 39 40 plt.grid(True) 41 plt.show() 42# Main script 43if __name__ == \u0026#34;__main__\u0026#34;: 44 start_date = datetime(2025, 1, 1) 45 end_date = datetime(2025, 4, 40) 46 47 # Generate the simulated dataset 48 energy_data_with_missing = simulate_energy_data(start_date, end_date) 49 50 # Display the first few rows of the dataset 51 print(energy_data_with_missing.head()) 52 53 54 plot_origin_data(energy_data_with_missing) Ph∆∞∆°ng Ph√°p t√°i t·∫°o D·ªØ Li·ªáu D·ª±a Tr√™n H·ªìi Quy Ph∆∞∆°ng ph√°p t√°i t·∫°o d·ªØ li·ªáu d·ª±a tr√™n h·ªìi quy s·ª≠ d·ª•ng c√°c m√¥ h√¨nh d·ª± ƒëo√°n ‚Äî m·ªôt l·ªõp thu·∫≠t to√°n h·ªçc m√°y, ch·∫≥ng h·∫°n nh∆∞ h·ªìi quy tuy·∫øn t√≠nh ho·∫∑c c√°c b·ªô h·ªìi quy c√¢y quy·∫øt ƒë·ªãnh ‚Äî ƒë·ªÉ ∆∞·ªõc t√≠nh gi√° tr·ªã t·ª´ c√°c m·ªëi quan h·ªá ƒë√£ bi·∫øt gi·ªØa c√°c ƒë·∫∑c tr∆∞ng kh√°c ho·∫∑c c√°c m·∫´u th·ªùi gian, nh∆∞ gi√° tr·ªã tr·ªÖ trong chu·ªói th·ªùi gian.\nM√¥ h√¨nh t√°i t·∫°o v√†o c√°c kho·∫£ng tr·ªëng b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c xu h∆∞·ªõng v√† m·ªëi quan h·ªá ti·ªÅm ·∫©n ƒë√£ h·ªçc t·ª´ d·ªØ li·ªáu.\n·ªû b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu c√°ch t√°i t·∫°o d·ªØ li·ªáu b·ªã thi·∫øu s·ª≠ d·ª•ng m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh v·ªõi th∆∞ vi·ªán LinearRegression c·ªßa sklearn\n1 2from sklearn.linear_model import LinearRegression 3 4# Impute missing values using linear regression 5def impute_missing_values(data): 6 # Extract the non-missing data 7 non_missing_data = data.dropna() 8 9 # Prepare the features (X) and target (y) 10 X = non_missing_data.index.values.reshape(-1, 1) 11 y = non_missing_data[\u0026#39;Energy_Production\u0026#39;].values 12 13 # Fit the linear regression model 14 model = LinearRegression() 15 model.fit(X, y) 16 17 # Predict the missing values 18 missing_data = data[data[\u0026#39;Energy_Production\u0026#39;].isna()] 19 X_missing = missing_data.index.values.reshape(-1, 1) 20 predicted_values = model.predict(X_missing) 21 22 # Create a DataFrame for the imputed data 23 imputed_data = data.copy() 24 imputed_data.loc[data[\u0026#39;Energy_Production\u0026#39;].isna(), \u0026#39;Energy_Production\u0026#39;] = predicted_values 25 26 return imputed_data 27 28 29def plot_full_data(energy_data_imputed,energy_data_with_missing): 30 plt.figure(figsize=(24, 6)) 31 32 plt.plot(energy_data_imputed[\u0026#39;Datetime\u0026#39;], energy_data_imputed[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Imputed Data\u0026#39;, color=\u0026#39;blue\u0026#39; ) 33 plt.plot(energy_data_with_missing[\u0026#39;Datetime\u0026#39;], energy_data_with_missing[\u0026#39;Energy_Production\u0026#39;], label=\u0026#39;Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 34 plt.xlabel(\u0026#39;Datetime\u0026#39;) 35 plt.ylabel(\u0026#39;Energy Production\u0026#39;) 36 plt.title(\u0026#39;Simulated Energy Production Over Time (Original vs Imputed)\u0026#39;) 37 plt.legend() 38 plt.grid(True) 39 plt.show() 40 41# Main script 42if __name__ == \u0026#34;__main__\u0026#34;: 43 44 start_date = datetime(2024, 1, 1) 45 end_date = datetime(2024, 4, 30) 46 47 # Generate the simulated dataset 48 energy_data_with_missing = simulate_energy_data(start_date, end_date) 49 50 51 plot_origin_data(energy_data_with_missing) 52 53 54 # Impute the missing values 55 energy_data_imputed = impute_missing_values(energy_data_with_missing.copy()) 56 57 # Display the first few rows of the dataset 58 print(energy_data_imputed.head()) 59 60 plot_full_data(energy_data_imputed,energy_data_with_missing) Code ƒë∆°n gi·∫£n ph·∫£i kh√¥ng c√°c b·∫°n, nh√¨n v√†o ƒë·ªì th·ªã th√¨ ch√∫ng ta th√°y r·∫±ng xu h∆∞·ªõng c·ªßa missing data ƒë√£ gi·ªëng g·∫ßn nh∆∞ i s√¨ v·ªõi xu h∆∞·ªõng c·ªßa d·ªØ li·ªáu g·ªëc r·ªìi ƒë√≥.\nM·∫∑c d√π ch√∫ng ta c√≥ th·ªÉ quan s√°t r·∫±ng c√°c gi√° tr·ªã t√°i t·∫°o theo xu h∆∞·ªõng chung c·ªßa d·ªØ li·ªáu g·ªëc, nh∆∞ng ƒëi·ªÅu n√†y kh√¥ng ƒë·ªß ƒë·ªÉ ƒë√°nh gi√° m·ª©c ƒë·ªô hi·ªáu qu·∫£ c·ªßa ph∆∞∆°ng ph√°p t√°i t·∫°o d·ªØ li·ªáu. Ch√∫ng ta c·∫ßn ƒë∆∞a ra c√°c ph∆∞∆°ng ph√°p ƒë·ªãnh l∆∞·ª£ng ƒë·ªÉ ch·ª©ng minh m√¥ h√¨nh n√†y ·ªïn, ·ªü m·ª©c ch·∫•p nh·∫≠n ƒë∆∞·ª£c\nƒê√°nh gi√° hi·ªáu qu·∫£ c·ªßa vi·ªác t√°i t·∫°o d·ªØ li·ªáu 1.Statistical Comparison - So s√°nh th·ªëng k√™ So s√°nh c√°c ch·ªâ s·ªë th·ªëng k√™ (trung b√¨nh, ƒë·ªô l·ªách chu·∫©n, gi√° tr·ªã nh·ªè nh·∫•t, gi√° tr·ªã l·ªõn nh·∫•t) ƒë·ªÉ ƒë·∫£m b·∫£o d·ªØ li·ªáu t√°i t·∫°o ph√π h·ª£p v·ªõi ph√¢n ph·ªëi d·ªØ li·ªáu g·ªëc.\n1 2# Statistical comparison function using describe 3def statistical_comparison(original_data, imputed_data): 4 original_stats = original_data[\u0026#39;Energy_Production\u0026#39;].describe() 5 imputed_stats = imputed_data[\u0026#39;Energy_Production\u0026#39;].describe() 6 comparison = pd.DataFrame({ 7 \u0026#39;Metric\u0026#39;: original_stats.index, 8 \u0026#39;Original Data\u0026#39;: original_stats.values, 9 \u0026#39;Imputed Data\u0026#39;: imputed_stats.values 10 }) 11 return comparison 12 13comparison = statistical_comparison(energy_data_with_missing.dropna(), energy_data_imputed) 14print(comparison) K·∫øt qu·∫£\n1 Metric Original Data Imputed Data 20 count 15553.000000 17281.000000 31 mean 185.155737 185.155865 42 std 127.062030 120.541640 53 min -16.984058 -16.984058 64 25% 51.260972 53.436820 75 50% 257.313693 185.404682 86 75% 302.393653 298.653209 97 max 415.581945 415.581945 T·ª´ b·∫£ng so s√°nh th·ªëng k√™ ·ªü tr√™n , ch√∫ng ta c√≥ th·ªÉ r√∫t ra nh·ªØng k·∫øt lu·∫≠n sau:\nS·ªë L∆∞·ª£ng (Count): B·ªô d·ªØ li·ªáu t√°i t·∫°o ch·ª©a nhi·ªÅu ƒëi·ªÉm d·ªØ li·ªáu h∆°n, 17281, so v·ªõi b·ªô d·ªØ li·ªáu g·ªëc, 15553, do vi·ªác t√°i t·∫°o c√°c gi√° tr·ªã thi·∫øu ƒë·ªÉ ƒë·∫£m b·∫£o d·ªØ li·ªáu ƒë·∫ßy ƒë·ªß.\nTrung B√¨nh (Mean): Trung b√¨nh c·ªßa d·ªØ li·ªáu t√°i t·∫°o l√† 185.1558, g·∫ßn gi·ªëng v·ªõi gi√° tr·ªã trung b√¨nh c·ªßa d·ªØ li·ªáu g·ªëc 185.1557, ƒëi·ªÅu n√†y c√≥ nghƒ©a l√† xu h∆∞·ªõng trung t√¢m c·ªßa d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c duy tr√¨ trong qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu.\nƒê·ªô L·ªách Chu·∫©n (Standard Deviation): D·ªØ li·ªáu t√°i t·∫°o c√≥ s·ª± ph√¢n t√°n th·∫•p h∆°n (ƒë·ªô l·ªách chu·∫©n = 120.54 so v·ªõi 127.06 c·ªßa d·ªØ li·ªáu g·ªëc). ƒêi·ªÅu n√†y c√≥ th·ªÉ cho th·∫•y r·∫±ng trong qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu, c√°c gi√° tr·ªã ƒë√£ tr·ªü n√™n m∆∞·ª£t m√† h∆°n, gi·∫£m b·ªõt s·ª± ph√¢n t√°n. H·ªìi quy tuy·∫øn t√≠nh ƒë√£ l√†m \u0026ldquo;ph√©p m√†u d·ª± ƒëo√°n\u0026rdquo; c·ªßa m√¨nh b·∫±ng c√°ch lu√¥n tr·∫£ v·ªÅ c√°c gi√° tr·ªã g·∫ßn v·ªõi trung b√¨nh.\nGi√° Tr·ªã T·ªëi Thi·ªÉu v√† T·ªëi ƒêa: Gi√° tr·ªã t·ªëi thi·ªÉu (-16.984058) v√† t·ªëi ƒëa (415.581945) l√† gi·ªëng nhau, ƒëi·ªÅu n√†y g·ª£i √Ω r·∫±ng qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu kh√¥ng t·∫°o ra c√°c gi√° tr·ªã ngo·∫°i lai c·ª±c ƒëoan ho·∫∑c kh√¥ng ƒëi ra ngo√†i ph·∫°m vi c·ªßa d·ªØ li·ªáu g·ªëc.\nC√°c Ph√¢n V·ªã (Quartiles 25%, 50%, 75%):\nPh√¢n v·ªã th·ª© 25 (quartile th·∫•p) cao h∆°n m·ªôt ch√∫t trong d·ªØ li·ªáu t√°i t·∫°o , 53.43 so v·ªõi 51.26 c·ªßa d·ªØ li·ªáu g·ªëc, cho th·∫•y c√°c gi√° tr·ªã t√°i t·∫°o ƒë√£ l·∫•p ƒë·∫ßy nhi·ªÅu kho·∫£ng tr·ªëng ·ªü ph·∫°m vi th·∫•p. Trung v·ªã (50%) ƒë√£ thay ƒë·ªïi ƒë√°ng k·ªÉ t·ª´ 257.31 trong d·ªØ li·ªáu g·ªëc th√†nh 185.40 trong d·ªØ li·ªáu t√°i t·∫°o , cho th·∫•y c√°c gi√° tr·ªã t√°i t·∫°o ƒë√£ gi·∫£m ƒë·ªô l·ªách d·ªØ li·ªáu c·ªßa c√°c ph·∫ßn t·ª≠ d·ªØ li·ªáu cao. Ph√¢n v·ªã th·ª© 75 (quartile cao) 302.39 v√† 298.65 , g·∫ßn nh∆∞ t∆∞∆°ng ƒë∆∞∆°ng nhau, ph·∫£n √°nh r·∫±ng c√°c gi√° tr·ªã cao ƒë√£ ƒë∆∞·ª£c b·∫£o t·ªìn t·ªët. K·∫øt lu·∫≠n: Ph∆∞∆°ng ph√°p h·ªìi quy tuy·∫øn t√≠nh ƒë√£ b·∫£o t·ªìn ph√¢n ph·ªëi t·ªïng th·ªÉ v√† ph·∫°m vi c·ªßa d·ªØ li·ªáu, trong khi l√†m gi·∫£m s·ª± bi·∫øn thi√™n v√† l√†m m∆∞·ª£t d·ªØ li·ªáu m·ªôt ch√∫t.\n2.Autocorrelation Ki·ªÉm tra xem t·ª± t∆∞∆°ng quan c·ªßa chu·ªói c√≥ ƒë∆∞·ª£c duy tr√¨ sau khi t√°i t·∫°o d·ªØ li·ªáu hay kh√¥ng.\n1 2 3# Autocorrelation analysis function 4def autocorrelation_analysis(original_data, imputed_data): 5 fig, axes = plt.subplots(1, 2, figsize=(15, 6)) 6 plot_acf(original_data[\u0026#39;Energy_Production\u0026#39;].dropna(), ax=axes[0], title=\u0026#39;ACF of Original Data\u0026#39;) 7 plot_acf(imputed_data[\u0026#39;Energy_Production\u0026#39;], ax=axes[1], title=\u0026#39;ACF of Imputed Data\u0026#39;) 8 plt.tight_layout() 9 plt.show() Quan s√°t ƒë·ªì th·ªã ACF tr√™n, ch√∫ng ta c√≥ th·ªÉ r√∫t ra c√°c √Ω ch√≠nh sau\nB·∫£o T·ªìn C√°c Ph·ª• Thu·ªôc - Preservation of Temporal Dependencies:\nH√¨nh d·∫°ng v√† s·ª± suy gi·∫£m c·ªßa ACF trong d·ªØ li·ªáu t√°i t·∫°o c√≥ s·ª± t∆∞∆°ng ƒë·ªìng ƒë√°ng k·ªÉ v·ªõi d·ªØ li·ªáu g·ªëc. ƒêi·ªÅu n√†y cho th·∫•y r·∫±ng c√°c ph·ª• thu·ªôc th·ªùi gian ƒë√£ ƒë∆∞·ª£c b·∫£o t·ªìn kh√° t·ªët sau qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu.\nHi·ªáu ·ª®ng L√†m M·ªãn - Slight Smoothing Effect:\nACF tr√™n d·ªØ li·ªáu t√°i t·∫°o cho th·∫•y gi√° tr·ªã ·ªü m·ªôt s·ªë ƒë·ªô tr·ªÖ (lags) th·∫•p h∆°n so v·ªõi d·ªØ li·ªáu g·ªëc. ƒêi·ªÅu n√†y c√≥ th·ªÉ l√† do m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh l√†m m·ªãn c√°c c·ª±c tr·ªã, d·∫´n ƒë·∫øn gi·∫£m nh·∫π m·ª©c ƒë·ªô bi·∫øn ƒë·ªông.\nC√°c M·∫´u Chu K·ª≥ Trong ACF - Cyclic Patterns:\nC√°c ƒë·ªânh chu k·ª≥ trong ACF, ch·∫≥ng h·∫°n nh∆∞ t√≠nh m√πa v·ª• h√†ng ng√†y, d∆∞·ªùng nh∆∞ ƒë∆∞·ª£c duy tr√¨ gi·ªØa d·ªØ li·ªáu g·ªëc v√† d·ªØ li·ªáu t√°i t·∫°o . ƒêi·ªÅu n√†y cho th·∫•y r·∫±ng qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu ƒë√£ b·∫£o t·ªìn c√°c h√†nh vi tu·∫ßn ho√†n trong t·∫≠p d·ªØ li·ªáu.\nT√≠nh ·ªîn ƒê·ªãnh Chung:\nS·ª± t∆∞∆°ng ƒë·ªìng gi·ªØa hai bi·ªÉu ƒë·ªì ACF l√† m·ªôt d·∫•u hi·ªáu t√≠ch c·ª±c, cho th·∫•y ph∆∞∆°ng ph√°p t√°i t·∫°o d·ªØ li·ªáu b·∫±ng h·ªìi quy tuy·∫øn t√≠nh ƒë√£ gi·ªØ l·∫°i t·ªët c·∫•u tr√∫c c·ªët l√µi trong d·ªØ li·ªáu.\nK·∫øt Lu·∫≠n:\nPh∆∞∆°ng ph√°p h·ªìi quy tuy·∫øn t√≠nh kh√¥ng ch·ªâ b·∫£o t·ªìn m·ªëi li√™n h·ªá th·ªùi gian trong d·ªØ li·ªáu m√† c√≤n duy tr√¨ c√°c m·∫´u chu k·ª≥, m·∫∑c d√π c√≥ m·ªôt ch√∫t hi·ªáu ·ª©ng l√†m m·ªãn.\n3. Ph√¢n t√≠ch xu h∆∞·ªõng v√† m√πa v·ª• - STL Decomposition (Trend and Seasonality) So S√°nh Xu H∆∞·ªõng (Trend Comparison) 1 2# STL decomposition function to extract and plot trend component 3def stl_decomposition_trend(original_data, imputed_data, period): 4 stl_original = STL(original_data[\u0026#39;Energy_Production\u0026#39;] , period=period) 5 result_original = stl_original.fit() 6 trend_original = result_original.trend 7 8 stl_imputed = STL(imputed_data[\u0026#39;Energy_Production\u0026#39;], period=period) 9 result_imputed = stl_imputed.fit() 10 trend_imputed = result_imputed.trend 11 12 plt.figure(figsize=(24, 6)) 13 plt.plot(original_data[\u0026#39;Datetime\u0026#39;], trend_original, label=\u0026#39;Trend of Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 14 plt.plot(imputed_data[\u0026#39;Datetime\u0026#39;], trend_imputed, label=\u0026#39;Trend of Imputed Data\u0026#39;, color=\u0026#39;blue\u0026#39;) 15 plt.xlabel(\u0026#39;Datetime\u0026#39;) 16 plt.ylabel(\u0026#39;Trend\u0026#39;) 17 plt.title(\u0026#39;STL Decomposition Trend of Original and Imputed Data\u0026#39;) 18 plt.legend() 19 plt.grid(True) 20 plt.show() 21 22stl_decomposition_trend(energy_data_with_missing.dropna(), energy_data_imputed, period=144) # Daily seasonality (144 10-min intervals in a day) B·∫£o T·ªìn Xu H∆∞·ªõng D√†i H·∫°n:\nƒê∆∞·ªùng Xu h∆∞·ªõng t√°i t·∫°o (m√†u xanh d∆∞∆°ng) nh√¨n chung ph√π h·ª£p v·ªõi xu h∆∞·ªõng g·ªëc (m√†u ƒë·ªè), cho th·∫•y ph∆∞∆°ng ph√°p t√°i t·∫°o h·ªìi quy tuy·∫øn t√≠nh ƒë√£ b·∫£o t·ªìn ƒë∆∞·ª£c chuy·ªÉn ƒë·ªông d√†i h·∫°n trong d·ªØ li·ªáu.\nHi·ªáu ·ª®ng L√†m M·ªãn:\nƒê∆∞·ªùng Xu h∆∞·ªõng t√°i t·∫°o m∆∞·ª£t m√† h∆°n so v·ªõi xu h∆∞·ªõng g·ªëc, ƒë·∫∑c bi·ªát ·ªü nh·ªØng n∆°i xu h∆∞·ªõng g·ªëc c√≥ nhi·ªÅu bi·∫øn ƒë·ªông. ƒêi·ªÅu n√†y l√† ƒë·∫∑c ƒëi·ªÉm c·ªßa h·ªìi quy tuy·∫øn t√≠nh, v·ªën c√≥ xu h∆∞·ªõng kh√¥ng ph·∫£n √°nh t·ªët c√°c bi·∫øn ƒë·ªông m·∫°nh v√† l√†m m·ªãn c√°c c·ª±c tr·ªã.\nSo S√°nh T√≠nh M√πa V·ª• (Seasonality Comparison) 1 2 3def stl_decomposition_seasonality(original_data, imputed_data, period): 4 stl_original = STL(original_data[\u0026#39;Energy_Production\u0026#39;], period=period) 5 result_original = stl_original.fit() 6 seasonality_original = result_original.seasonal 7 8 stl_imputed = STL(imputed_data[\u0026#39;Energy_Production\u0026#39;], period=period) 9 result_imputed = stl_imputed.fit() 10 seasonality_imputed = result_imputed.seasonal 11 12 plt.figure(figsize=(24, 6)) 13 plt.plot(original_data[\u0026#39;Datetime\u0026#39;], seasonality_original, label=\u0026#39;Seasonality of Original Data\u0026#39;, color=\u0026#39;red\u0026#39;) 14 plt.plot(imputed_data[\u0026#39;Datetime\u0026#39;], seasonality_imputed, label=\u0026#39;Seasonality of Imputed Data\u0026#39;, color=\u0026#39;blue\u0026#39;) 15 plt.xlabel(\u0026#39;Datetime\u0026#39;) 16 plt.ylabel(\u0026#39;Seasonality\u0026#39;) 17 plt.title(\u0026#39;STL Decomposition Seasonality of Original and Imputed Data\u0026#39;) 18 plt.legend() 19 plt.grid(True) 20 plt.show() 21stl_decomposition_seasonality(energy_data_with_missing.dropna(), energy_data_imputed, period=144) # Daily seasonality (144 10-min intervals in a day) B·∫£o T·ªìn t√≠nh Chu K·ª≥:\nƒê∆∞·ªùng m√πa v·ª• t√°i t·∫°o th·ªÉ hi·ªán ra c√°c m·∫´u chu k·ª≥ t∆∞∆°ng ƒë·ªëi g·∫ßn gi·ªëng v·ªõi chu k·ª≥ c·ªßa ƒë∆∞·ªùng m√πa v·ª• g·ªëc, ph·∫£n √°nh r·∫±ng d·ªØ li·ªáu c√°c chu k·ª≥ s·∫£n xu·∫•t ng√†y-ƒë√™m ƒë√£ ƒë∆∞·ª£c duy tr√¨ kh√° t·ªët.\nGi·∫£m Bi√™n ƒê·ªô Chu K·ª≥:\nBi√™n ƒë·ªô c·ªßa ƒë∆∞·ªùng m√πa v·ª• t√°i t·∫°o b·ªã gi·∫£m nh·∫π so v·ªõi g·ªëc, ƒë·∫∑c bi·ªát t·∫°i c√°c ƒë·ªânh v√† ƒë√°y. ƒêi·ªÅu n√†y cho th·∫•y qu√° tr√¨nh t√°i t·∫°o d·ªØ li·ªáu ƒë√£ l√†m cho c√°c bi·∫øn ƒë·ªông chu k·ª≥ ·ªü c·ª±c tr·ªã tr·ªü n√™n √≠t m·∫°nh m·∫Ω h∆°n.\nH·∫°n Ch·∫ø C·ªßa t√°i t·∫°o D·ªØ Li·ªáu B·∫±ng linear regression L√†m M·ªãn C√°c c·ª±c tr·ªã:\nT·ª´ so s√°nh th·ªëng k√™, ƒë·ªô l·ªách chu·∫©n th·∫•p h∆°n ·ªü d·ªØ li·ªáu t√°i t·∫°o cho th·∫•y t√≠nh bi·∫øn ƒë·ªông ƒë√£ b·ªã gi·∫£m.\nT·ª´ so s√°nh xu h∆∞·ªõng, xu h∆∞·ªõng t√°i t·∫°o m∆∞·ª£t h∆°n v√† thi·∫øu m·ªôt s·ªë bi·∫øn ƒë·ªông g·ªëc trong c√°c m·∫´u d√†i h·∫°n.\nGi·∫£ ƒê·ªãnh Tuy·∫øn T√≠nh:\nHi·ªáu ·ª©ng l√†m m·ªãn trong so s√°nh xu h∆∞·ªõng cho th·∫•y ph∆∞∆°ng ph√°p n√†y kh√≥ b·∫Øt k·ªãp c√°c thay ƒë·ªïi phi tuy·∫øn t√≠nh trong d·ªØ li·ªáu, ƒë·∫∑c bi·ªát t·∫°i c√°c giai ƒëo·∫°n c√≥ s·ª± thay ƒë·ªïi ƒë·ªôt ng·ªôt. Gi·∫£m Bi√™n ƒê·ªô M√πa V·ª•:\nSo s√°nh t√≠nh m√πa v·ª• cho th·∫•y bi√™n ƒë·ªô chu k·ª≥ t√°i t·∫°o th·∫•p h∆°n so v·ªõi g·ªëc, v·ªõi c√°c ƒë·ªânh v√† ƒë√°y b·ªã l√†m m·ªãn. ƒêi·ªÅu n√†y ph√π h·ª£p v·ªõi xu h∆∞·ªõng c·ªßa h·ªìi quy trong vi·ªác k√©o c√°c gi√° tr·ªã c·ª±c ƒëoan v·ªÅ trung b√¨nh. K·∫øt lu·∫≠n Ph∆∞∆°ng ph√°p t√°i t·∫°o h·ªìi quy tuy·∫øn t√≠nh b·∫£o t·ªìn ƒë∆∞·ª£c c√°c xu h∆∞·ªõng t·ªïng th·ªÉ v√† c√°c m·∫´u chu k·ª≥, nh∆∞ng l√†m gi·∫£m t√≠nh bi·∫øn ƒë·ªông v√† l√†m m·ªãn c√°c gi√° tr·ªã c·ª±c ƒëoan. Ngo√†i ra, n√≥ th·ªÉ hi·ªán s·ª± gi·∫£m nh·∫π c∆∞·ªùng ƒë·ªô c·ªßa c√°c chu k·ª≥ m√πa v·ª•, ƒëi·ªÅu n√†y ƒë∆∞·ª£c ph·∫£n √°nh trong c·∫£ ph√¢n t√≠ch th·ªëng k√™ v√† ph√¢n r√£ d·ªØ li·ªáu.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt. Xin c·∫£m ∆°n v√† h·∫πn g·∫∑p l·∫°i.\nT√†i li·ªáu tham kh·∫£o https://www.geeksforgeeks.org/managing-missing-data-in-linear-regression/\nhttps://towardsdatascience.com/missing-data-in-time-series-machine-learning-techniques-6b2273ff8b45\nhttps://www.geeksforgeeks.org/dataset-for-linear-regression/\nhttps://www.geeksforgeeks.org/ml-handling-missing-values/\nhttps://codezup.com/mastering-linear-regression-time-series-forecasting/\n","date":"Jan 10, 2025","img":"https://unsplash.it/1920/1080?image=203","permalink":"/blog/2025-01-10-data-missing-time-serial-linear-regression/","series":null,"tags":["Missing data","time-serials"],"title":"X·ª≠ L√Ω D·ªØ Li·ªáu Khi·∫øm Khuy·∫øt Trong D·ªØ Li·ªáu Chu·ªói Th·ªùi Gian S·ª≠ D·ª•ng Ph∆∞∆°ng Ph√°p Linear Regression - Machine Learning Techniques for Mising Data in Time-Serials Using Liner Regression"},{"categories":null,"content":" I. Bloom Filters l√† g√¨? II. Nguy√™n l√Ω Bloom Filters ho·∫°t ƒë·ªông C·∫•u tr√∫c d·ªØ li·ªáu X√°c su·∫•t d∆∞∆°ng t√≠nh sai C√¥ng th·ª©c ∆∞·ªõc l∆∞·ª£ng s·ªë ph·∫ßn t·ª≠ v√† s·ªë h√†m hash III. ∆Øu ƒëi·ªÉm c·ªßa b·ªô l·ªçc Bloom 1. Ti·∫øt ki·ªám b·ªô nh·ªõ 2. Ki·ªÉm tra th√†nh vi√™n nhanh ch√≥ng 3. Kh√¥ng c√≥ false negative 4. D·ªÖ d√†ng m·ªü r·ªông 5. Thi·∫øt k·∫ø ƒë∆°n gi·∫£n 6. Th√¢n thi·ªán v·ªõi h·ªá th·ªëng ph√¢n t√°n 7. ·ª®ng d·ª•ng r·ªông r√£i 8. H·ªó tr·ª£ t√≠nh to√°n song song 9. ·ª®ng d·ª•ng trong b·∫£o m·∫≠t v√† quy·ªÅn ri√™ng t∆∞ 10. D·ªÖ b·∫£o tr√¨ Khi n√†o n√™n s·ª≠ d·ª•ng Bloom Filter? H·∫°n ch·∫ø c·ªßa b·ªô l·ªçc Bloom Filter 1. False Positive (K·∫øt qu·∫£ d∆∞∆°ng t√≠nh gi·∫£) 2. Kh√¥ng h·ªó tr·ª£ x√≥a ph·∫ßn t·ª≠ 3. Kh√¥ng l∆∞u tr·ªØ d·ªØ li·ªáu g·ªëc 4. Kh√≥ ƒëi·ªÅu ch·ªânh t·ª∑ l·ªá false positive 5. Y√™u c·∫ßu ch·ªçn h√†m bƒÉm ph√π h·ª£p 6. Kh√¥ng hi·ªáu qu·∫£ v·ªõi t·∫≠p d·ªØ li·ªáu nh·ªè 7. Kh√¥ng th·ªÉ m·ªü r·ªông m·ªôt c√°ch ƒë∆°n gi·∫£n 8. Kh√¥ng h·ªó tr·ª£ ki·ªÉm tra ph·ªß ƒë·ªãnh (No False Negatives) 9. Kh√≥ tri·ªÉn khai v√† b·∫£o tr√¨ trong h·ªá th·ªëng l·ªõn 10. Kh√¥ng ph√π h·ª£p v·ªõi d·ªØ li·ªáu ƒë·ªông Khi n√†o kh√¥ng n√™n s·ª≠ d·ª•ng Bloom Filter? M·ªôt s·ªë bi·∫øn th·ªÉ c·ªßa Bloom Filter Double Hashing Bloom Filter: C√°ch ho·∫°t ƒë·ªông c·ªßa Double Hashing Bloom Filter ∆Øu ƒëi·ªÉm c·ªßa Double Hashing Bloom Filter H·∫°n ch·∫ø c·ªßa Double Hashing Bloom Filter ·ª®ng d·ª•ng c·ªßa Double Hashing Bloom Filter Tri·ªÉn khai Double Hashing Bloom Filter b·∫±ng Python T√≥m t·∫Øt Partitioning Bloom Filter: C√°ch ho·∫°t ƒë·ªông c·ªßa Partitioning Bloom Filter ∆Øu ƒëi·ªÉm c·ªßa Partitioning Bloom Filter H·∫°n ch·∫ø c·ªßa Partitioning Bloom Filter ·ª®ng d·ª•ng c·ªßa Partitioning Bloom Filter Tri·ªÉn khai Partitioning Bloom Filter b·∫±ng Python T√≥m t·∫Øt Counting Bloom Filter: C√°ch ho·∫°t ƒë·ªông c·ªßa Counting Bloom Filter ∆Øu ƒëi·ªÉm c·ªßa Counting Bloom Filter H·∫°n ch·∫ø c·ªßa Counting Bloom Filter ·ª®ng d·ª•ng c·ªßa Counting Bloom Filter Tri·ªÉn khai b·∫±ng Python T√≥m t·∫Øt Scalable Bloom Filter V·∫•n ƒë·ªÅ v·ªõi Bloom Filter truy·ªÅn th·ªëng Scalable Bloom Filter gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ nh∆∞ th·∫ø n√†o? C·∫•u tr√∫c v√† c√°ch ho·∫°t ƒë·ªông c·ªßa Scalable Bloom Filter ∆Øu ƒëi·ªÉm c·ªßa Scalable Bloom Filter H·∫°n ch·∫ø c·ªßa Scalable Bloom Filter ·ª®ng d·ª•ng c·ªßa Scalable Bloom Filter Tri·ªÉn khai Scalable Bloom Filter M√£ gi·∫£ Scalable Bloom Filter Striped Bloom Filter ƒê·∫∑c ƒëi·ªÉm c·ªßa Striped Bloom Filter C√°ch ho·∫°t ƒë·ªông c·ªßa Striped Bloom Filter ∆Øu ƒëi·ªÉm c·ªßa Striped Bloom Filter H·∫°n ch·∫ø c·ªßa Striped Bloom Filter Tri·ªÉn khai b·∫±ng Python Quotient Filter (B·ªô l·ªçc th∆∞∆°ng s·ªë) Nguy√™n l√Ω ho·∫°t ƒë·ªông ∆Øu ƒëi·ªÉm c·ªßa Quotient Filter H·∫°n ch·∫ø c·ªßa Quotient Filter ·ª®ng d·ª•ng c·ªßa Quotient Filter So s√°nh v·ªõi Bloom Filter V√≠ d·ª• m√£ gi·∫£ b·∫±ng Python K·∫øt lu·∫≠n Cuckoo Filter Nguy√™n l√Ω ho·∫°t ƒë·ªông Thao t√°c ch√≠nh trong Cuckoo Filter ∆Øu ƒëi·ªÉm c·ªßa Cuckoo Filter H·∫°n ch·∫ø c·ªßa Cuckoo Filter ·ª®ng d·ª•ng c·ªßa Cuckoo Filter So s√°nh v·ªõi Bloom Filter V√≠ d·ª• m√£ gi·∫£ Cuckoo Filter b·∫±ng Python K·∫øt lu·∫≠n ·ª®ng D·ª•ng c·ªßa Bloom Filter trong C√°c Lƒ©nh V·ª±c 1. Ph√°t Hi·ªán Gian L·∫≠n T√†i Ch√≠nh (Financial Fraud Detection) 2. ƒê·∫∑t Qu·∫£ng C√°o (Ad Placement - Retail, Advertising) 3. Ki·ªÉm Tra T√™n Ng∆∞·ªùi D√πng (SaaS, Content Publishing Platforms) 4. C√°c ·ª®ng D·ª•ng Kh√°c C·ªßa Bloom Filter B√†i t·∫≠p Financial Fraud Detection Spell Checker Recommendation Systems Bloom Filters Gi·∫£ s·ª≠ b·∫°n mu·ªën l·∫≠p m·ªôt t√†i kho·∫£ng ph·ªü b√≤, username l√† phamduytung, b·∫°n hƒÉng h√°i hƒÉm h·ªü g√µ v√†o c√°i t√™n ƒë√≥ trong √¥ username v√† .. b√πm, ph·ªü b√≤ b√°o l·∫°i cho b·∫°n r·∫±ng username ƒë√≥ ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng, b·∫°n c·ªë g·∫Øng th·ª≠ v·ªõi v√†i tr∆∞·ªùng h·ª£p nh∆∞ nh√©t nƒÉm sinh c·ªßa b·∫°n v√†o, nh√©t th√™m ch·ªØ vi·∫øt t·∫Øt c·ªßa tr∆∞·ªùng ƒë·∫°i h·ªçc v√†o, nh∆∞ng ph·ªü b√≤ v·∫´n tr·∫£ l·ªùi l·∫°i l√† t√™n username ƒë√≥ ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng, th·∫≠t l√† b·ª±c b·ªôi ph·∫£i kh√¥ng?\nKhoan khoan tr√∫t n·ªói b·ª±c b·ªôi ho·∫∑c t√¨m c√°ch ƒë·∫∑t t√™n ·ªü ƒë√¢y, ch√∫ng ta tr·ªü l·∫°i b·∫£n ch·∫•t c·ªßa v·∫•n ƒë·ªÅ l√† h·ªá th·ªëng search username ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?\nPh∆∞∆°ng √°n a: t√¨m ki·∫øm tuy·∫øn t√≠nh, duy·ªát t·∫•t c·∫£ c√°c username, n·∫øu g·∫∑p 1 username tr√πng v·ªõi username m√¨nh nh·∫≠p v√†o -\u0026gt; b√°o username ƒë√≥ ƒë√£ t·ªìn t·∫°i\nPh∆∞∆°ng √°n b: t√¨m ki·∫øm nh·ªã ph√¢n binary search, so s√°nh t√™n ng∆∞·ªùi d√πng v·ªõi t√™n ·ªü gi·ªØa danh s√°ch, n·∫øu kh·ªõp th√¨ tr·∫£ ra ƒë√£ c√≥ , n·∫øu kh√¥ng kh·ªõp th√¨ xem t√™n ng∆∞·ªùi d√πng l·ªõn h∆°n hay nh·ªè h∆°n t√™n ·ªü gi·ªØa, n·∫øu l·ªõn h∆°n th√¨ ch√∫ng ta s·∫Ω ch·ªâ l·∫∑p l·∫°i vi·ªác t√¨m ki·∫øm nh∆∞ tr√™n nh∆∞ng ·ªü ph·∫°m vi c√≤n 1 ph·∫ßn 2 t·ª´ t√™n ·ªü gi·ªØa ƒë·∫øn h·∫øt. N·∫øu nh·ªè h∆°n th√¨ ph·∫°m vi t√¨m ki·∫øm c≈©ng c√≤n l√† 1 ph·∫ßn 2 t·ª´ ƒë·∫ßu ƒë·∫øn t√™n ·ªü gi·ªØa, l·∫∑p ƒëi l·∫∑p l·∫°i vi·ªác n√†y ƒë·∫øn khi t√¨m th·∫•y ( tr·∫£ ra t√™n ƒë√£ s·ª≠ d·ª•ng) ho·∫∑c h·∫øt ph·∫°m vi t√¨m ki·∫øm (tr·∫£ ra t√™n kh·∫£ d·ª•ng). C√°ch n√†y ·ªïn nh∆∞ng vi·ªác t√¨m ki·∫øm c≈©ng tr·∫£i qua kh√° nhi·ªÅu b∆∞·ªõc.\nPh∆∞∆°ng √°n c: l∆∞u to√†n b·ªô user d∆∞·ªõi d·∫°ng 1 c√°i c√¢y r·ªìi duy·ªát node. C√°ch n√†y ·ªïn, nh∆∞ng kh√° t·ªën b·ªô nh·ªõ khi t√™n username d√†i\nC√≤n ph∆∞∆°ng √°n n√†o kh√°c kh√¥ng?\nC√≥, t·∫•t nhi√™n l√† c√≥ r·ªìi, ƒë√≥ ch√≠nh l√† Bloom Filters\nI. Bloom Filters l√† g√¨? Bloom filter, ƒë∆∞·ª£c ph√°t minh b·ªüi Burton Howard Bloom nƒÉm 1970, l√† m·ªôt c·∫•u tr√∫c d·ªØ li·ªáu x√°c su·∫•t d·ª±a tr√™n thu·∫≠t to√°n hasing. N√≥ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ki·ªÉm tra xem m·ªôt ph·∫ßn t·ª≠ c√≥ ph·∫£i thu·ªôc v·ªÅ m·ªôt t·∫≠p h·ª£p hay kh√¥ng. T·∫•t nhi√™n, ng∆∞·ªùi ta c≈©ng c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c c·∫•u tr√∫c d·ªØ li·ªáu kh√°c ƒë·ªÉ th·ª±c hi·ªán vi·ªác n√†y, nh∆∞ng Bloom filter c√≥ ∆∞u ƒëi·ªÉm v·ªÅ hi·ªáu qu·∫£ v·ªÅ kh√¥ng gian v√† th·ªùi gian.\nII. Nguy√™n l√Ω Bloom Filters ho·∫°t ƒë·ªông C·∫•u tr√∫c d·ªØ li·ªáu Bloom Filters ƒë∆∞·ª£c c·∫•u th√†nh t·ª´ 2 th√†nh ph·∫ßn, th·ª© nh·∫•t l√† m·ªôt m·∫£ng N bit , m·ªói ph·∫ßn t·ª≠ trong m·∫£ng mang gi√° tr·ªã 0 ho·∫∑c 1, gi√° tr·ªã kh·ªüi t·∫°o ban ƒë·∫ßu l√† 0. Th√†nh ph·∫ßn th·ª© 2 l√† k thu·∫≠t to√°n hash kh√°c nhau, m·ªói h√†m hash s·∫Ω ƒë∆∞·ª£c chia l·∫•y d∆∞ cho N, v√† k√≠ch ho·∫°t √¥ nh·ªõ t∆∞∆°ng ·ª©ng v·ªõi gi√° tr·ªã sau chia d∆∞ c·ªßa hash.\nGi·∫£ s·ª≠\nch√∫ng ta c√≥ N = 5, k =3 nghƒ©a l√† c√≥ 3 h√†m hash , ƒë·∫∑t t√™n l√† hash1, hash2, hash 3, t·ª´ kho√° c·∫ßn check v√† n·∫øu kh√¥ng c√≥ th√¨ th√™m v√†o l√† ch·ªØ \u0026ldquo;duy\u0026rdquo; v√† ch·ªØ \u0026ldquo;tung\u0026rdquo;\n·ªû th·ªùi ƒëi·ªÉm b·∫Øt ƒë·∫ßu , ch√∫ng ta c√≥ 1 m·∫£ng 5 ph·∫ßn t·ª≠ ƒë·ªÅu mang gi√° tr·ªã 0\n[0,0,0,0,0]\nki·ªÉm tra ch·ªØ \u0026ldquo;duy\u0026rdquo;\nhash1(\u0026ldquo;duy\u0026rdquo;) %5 = 1 hash2(\u0026ldquo;duy\u0026rdquo;) %5 = 2 hash3(\u0026ldquo;duy\u0026rdquo;) %5 = 4\ncheck c√°c gi√° tr·ªã ·ªü v·ªã tr√≠ 1,2,4, ch√∫ng ta c√≥ to√†n s·ªë 0, do d√≥ t·ª´ kho√° ch∆∞a c√≥ trong m·∫£ng, th√™m v√†o m·∫£ng.\nv·∫≠y m·∫£ng ch√∫ng ta thu ƒë∆∞·ª£c sau khi th√™m ch·ªØ \u0026ldquo;duy\u0026rdquo; s·∫Ω l√† [0,1,1,0,1]\nki·ªÉm tra ch·ªØ \u0026ldquo;tung\u0026rdquo;\nhash1(\u0026ldquo;tung\u0026rdquo;) %5 = 1 hash2(\u0026ldquo;tung\u0026rdquo;) %5 = 3 hash3(\u0026ldquo;tung\u0026rdquo;) %5 = 4\ncheck c√°c gi√° tr·ªã ·ªü b·ªã tr√≠ 1,3,4, ch√∫ng ta th·∫•y ·ªü 1 v√† 4 ƒë√£ l√† 1, nh∆∞ng ·ªü 3 l√† 0, v·∫≠y l√† ch·ªØ \u0026ldquo;tung\u0026rdquo; ch∆∞a c√≥, th√™m v√†o m·∫£ng\nv·∫≠y m·∫£ng ch√∫ng ta c√≥ sau khi th√™m ch·ªØ \u0026ldquo;tung\u0026rdquo; s·∫Ω l√† [0,1,1,1,1]\ngi·ªù gi·∫£ s·ª≠ th√™m ch·ªØ \u0026ldquo;pham\u0026rdquo; nha\nki·ªÉm tra ch·ªØ \u0026ldquo;pham\u0026rdquo;\nhash1(\u0026ldquo;tung\u0026rdquo;) %5 = 2 hash2(\u0026ldquo;tung\u0026rdquo;) %5 = 3 hash3(\u0026ldquo;tung\u0026rdquo;) %5 = 4\ncheck c√°c gi√° tr·ªã ·ªü b·ªã tr√≠ 2,3,4, ch√∫ng ta th·∫•y c·∫£ 3 v·ªã tr√≠ 2 , 3, 4 ƒë·ªÅu l√† 1 -\u0026gt; ch·ªØ \u0026ldquo;pham\u0026rdquo; ƒë√£ c√≥, th√¥ng b√°o v·ªõi ng∆∞·ªùi d√πng l√† ƒë√£ c√≥ , kh√¥ng th√™m v√†o\nKhoan khoan, ·ªßa g√¨ k·ª≥ v·∫≠y, r√µ r√†ng ch·ªØ \u0026ldquo;pham\u0026rdquo; ch∆∞a c√≥ m√†\nX√°c su·∫•t d∆∞∆°ng t√≠nh sai ƒê√¢y, l√† v·∫•n ƒë·ªÅ, c·∫•u tr√∫c n√†y t·ªìn t·∫°i m·ªôt c√°i g·ªçi l√† X√°c su·∫•t d∆∞∆°ng t√≠nh sai, nghƒ©a l√† ph·∫ßn t·ª≠ ch∆∞a c√≥ nh∆∞ng b√°o c√≥.\nƒê·ªÉ h·∫°n ch·∫ø c√°i n√†y, ch√∫ng ta c√≥ c√¥ng th·ª©c t√≠nh, ph·∫ßn ch·ª©ng minh x√°c xu·∫•t ƒë·ª•ng ƒë·ªô th√¨ ch·∫Øc c√°c b·∫°n ƒë·ªçc wiki ƒë·ªÉ hi·ªÉu th√™m, do n√≥ kh√° r√µ r√†ng v√† d·ªÖ hi·ªÉu ƒë·ªëi v·ªõi c√°c b·∫°n ƒë√£ h·ªçc to√°n c∆° b·∫£n r·ªìi, c√≤n b·∫°n n√†o ch∆∞a h·ªçc th√¨ b·ªè qua n√≥ ƒëi, ch·ª© m√¨nh ƒëem g√µ l·∫°i m·∫•y c√¥ng th·ª©c n√†y th√¨ c√°c b·∫°n ch∆∞a h·ªçc c≈©ng ch∆∞a ch·∫Øc s·∫Ω hi·ªÉu\nhttps://en.wikipedia.org/wiki/Bloom_filter\nC√¥ng th·ª©c ∆∞·ªõc t√≠nh s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ c√≤n l·∫°i c√≥ th·ªÉ ƒë∆∞·ª£c l∆∞u tr·ªØ\n$$ [ n* =- \\frac{m}{k}ln\\left[ 1-\\frac{X}{n} \\right] ] $$\nTrong ƒë√≥:\nn* l√† s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ ∆∞·ªõc t√≠nh c√≤n l·∫°i c√≥ th·ªÉ ƒë∆∞·ª£c l∆∞u tr·ªØ\nk l√† s·ªë l∆∞·ª£ng h√†m hash\nm l√† chi·ªÅu d√†i c·ªßa m·∫£ng\nX l√† s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ ƒë√£ ƒë∆∞·ª£c g√°n 1\nC√¥ng th·ª©c ∆∞·ªõc l∆∞·ª£ng s·ªë ph·∫ßn t·ª≠ v√† s·ªë h√†m hash C√≥ nhi·ªÅu c√°ch th·ª©c, nh∆∞ng theo wiki, ph·∫ßn Probability of false positives th√¨ ch√∫ng ta s·∫Ω c√≥, c√°c b·∫°n n√™n ƒë·ªçc k·ªπ\n$$ [ m =-n * ln(p)/ln(2)^2 ] $$\n$$ [ k =- \\frac{m}{n}ln2 ] $$\nTrong ƒë√≥:\nk l√† s·ªë h√†m hash\nm l√† chi·ªÅu d√†i m·∫£ng\nn l√† s·ªë l∆∞·ª£ng c·∫ßn l∆∞u tr·ªØ, v√≠ d·ª• facebook m√¨nh thi·∫øt k·∫ø cho 20 t·ª∑ username, th√¨ set n = 20 t·ª∑\np l√† X√°c su·∫•t d∆∞∆°ng t√≠nh sai, v√≠ d·ª• l√† 0.1% th√¨ p= 0.001\nCh√∫ng ta t√≠nh ƒë∆∞·ª£c m = 383,402,335 v√† k = 14\nIII. ∆Øu ƒëi·ªÉm c·ªßa b·ªô l·ªçc Bloom Bloom Filter l√† m·ªôt c·∫•u tr√∫c d·ªØ li·ªáu nh·ªè g·ªçn v√† hi·ªáu qu·∫£, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ki·ªÉm tra th√†nh vi√™n (membership) trong t·∫≠p h·ª£p. D∆∞·ªõi ƒë√¢y l√† c√°c ∆∞u ƒëi·ªÉm n·ªïi b·∫≠t c·ªßa Bloom Filter:\n1. Ti·∫øt ki·ªám b·ªô nh·ªõ K√≠ch th∆∞·ªõc nh·ªè g·ªçn: Bloom Filter s·ª≠ d·ª•ng √≠t b·ªô nh·ªõ h∆°n nhi·ªÅu so v·ªõi c√°c c·∫•u tr√∫c d·ªØ li·ªáu kh√°c nh∆∞ b·∫£ng bƒÉm (hash table) ho·∫∑c danh s√°ch. Th√≠ch h·ª£p cho d·ªØ li·ªáu l·ªõn: ƒê·∫∑c bi·ªát h·ªØu √≠ch khi l√†m vi·ªác v·ªõi t·∫≠p d·ªØ li·ªáu kh·ªïng l·ªì, n∆°i m√† vi·ªác l∆∞u tr·ªØ ƒë·∫ßy ƒë·ªß c√°c ph·∫ßn t·ª≠ kh√¥ng kh·∫£ thi. 2. Ki·ªÉm tra th√†nh vi√™n nhanh ch√≥ng ƒê·ªô ph·ª©c t·∫°p O(1): Bloom Filter c√≥ th·ªÉ ki·ªÉm tra m·ªôt ph·∫ßn t·ª≠ c√≥ kh·∫£ nƒÉng n·∫±m trong t·∫≠p h·ª£p hay kh√¥ng trong th·ªùi gian h·∫±ng s·ªë. Kh√¥ng l∆∞u tr·ªØ ph·∫ßn t·ª≠: ƒêi·ªÅu n√†y gi√∫p Bloom Filter ho·∫°t ƒë·ªông nhanh h∆°n v√† gi·∫£m chi ph√≠ l∆∞u tr·ªØ. 3. Kh√¥ng c√≥ false negative ƒê·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c khi ki·ªÉm tra s·ª± t·ªìn t·∫°i: N·∫øu Bloom Filter x√°c nh·∫≠n r·∫±ng m·ªôt ph·∫ßn t·ª≠ n·∫±m trong t·∫≠p h·ª£p, ƒëi·ªÅu ƒë√≥ lu√¥n ƒë√∫ng (kh√¥ng c√≥ false negative). Ki·ªÉm so√°t false positive: False positive (khi ph·∫ßn t·ª≠ kh√¥ng thu·ªôc t·∫≠p nh∆∞ng l·∫°i ƒë∆∞·ª£c b√°o l√† thu·ªôc) c√≥ th·ªÉ ƒë∆∞·ª£c gi·∫£m b·∫±ng c√°ch ƒëi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc m·∫£ng bit v√† s·ªë l∆∞·ª£ng h√†m bƒÉm. 4. D·ªÖ d√†ng m·ªü r·ªông ƒêi·ªÅu ch·ªânh linh ho·∫°t: C√≥ th·ªÉ thay ƒë·ªïi k√≠ch th∆∞·ªõc m·∫£ng bit ho·∫∑c s·ªë h√†m bƒÉm ƒë·ªÉ t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t ho·∫∑c gi·∫£m t·ª∑ l·ªá false positive. C√°c bi·∫øn th·ªÉ m·∫°nh m·∫Ω: Scalable Bloom Filter v√† Counting Bloom Filter cho ph√©p Bloom Filter m·ªü r·ªông ho·∫∑c h·ªó tr·ª£ c·∫≠p nh·∫≠t d·ªØ li·ªáu d·ªÖ d√†ng. 5. Thi·∫øt k·∫ø ƒë∆°n gi·∫£n Kh√¥ng c·∫ßn x·ª≠ l√Ω xung ƒë·ªôt: Kh√¥ng nh∆∞ b·∫£ng bƒÉm, Bloom Filter kh√¥ng c·∫ßn c√°c c∆° ch·∫ø x·ª≠ l√Ω xung ƒë·ªôt ph·ª©c t·∫°p. Kh√¥ng c·∫ßn thay ƒë·ªïi k√≠ch th∆∞·ªõc: Bloom Filter kh√¥ng y√™u c·∫ßu \u0026ldquo;resize\u0026rdquo; nh∆∞ c√°c c·∫•u tr√∫c d·ªØ li·ªáu kh√°c khi d·ªØ li·ªáu tƒÉng l√™n. 6. Th√¢n thi·ªán v·ªõi h·ªá th·ªëng ph√¢n t√°n Hi·ªáu qu·∫£ tr√™n m·∫°ng: Bloom Filter c√≥ th·ªÉ ƒë∆∞·ª£c truy·ªÅn qua m·∫°ng v·ªõi dung l∆∞·ª£ng nh·ªè, gi√∫p ƒë·ªìng b·ªô d·ªØ li·ªáu gi·ªØa c√°c h·ªá th·ªëng ph√¢n t√°n hi·ªáu qu·∫£. ·ª®ng d·ª•ng trong h·ªá th·ªëng l∆∞u tr·ªØ: Gi·∫£m s·ªë l·∫ßn truy c·∫≠p kh√¥ng c·∫ßn thi·∫øt v√†o c∆° s·ªü d·ªØ li·ªáu ph√¢n t√°n. 7. ·ª®ng d·ª•ng r·ªông r√£i ƒêa d·∫°ng ·ª©ng d·ª•ng: ƒê∆∞·ª£c s·ª≠ d·ª•ng trong c√°c h·ªá th·ªëng c∆° s·ªü d·ªØ li·ªáu, m·∫°ng, c√¥ng c·ª• t√¨m ki·∫øm, b·∫£o m·∫≠t, v√† nhi·ªÅu lƒ©nh v·ª±c kh√°c. V√≠ d·ª• s·ª≠ d·ª•ng: C∆° s·ªü d·ªØ li·ªáu: Ki·ªÉm tra nhanh s·ª± t·ªìn t·∫°i c·ªßa kh√≥a ƒë·ªÉ gi·∫£m chi ph√≠ truy c·∫≠p ·ªï ƒëƒ©a. B·ªô l·ªçc web: Lo·∫°i b·ªè nhanh c√°c URL tr√πng l·∫∑p ho·∫∑c kh√¥ng h·ª£p l·ªá. Ph√°t hi·ªán th∆∞ r√°c: X√°c ƒë·ªãnh ƒë·ªãa ch·ªâ email ho·∫∑c domain trong danh s√°ch ƒëen. 8. H·ªó tr·ª£ t√≠nh to√°n song song T√≠nh to√°n h√†m bƒÉm ƒë·ªôc l·∫≠p: C√°c h√†m bƒÉm c√≥ th·ªÉ ƒë∆∞·ª£c t√≠nh to√°n song song, gi√∫p Bloom Filter t·∫≠n d·ª•ng ƒë∆∞·ª£c h·ªá th·ªëng ƒëa l√µi ho·∫∑c ph√¢n t√°n. TƒÉng t·ªëc b·∫±ng ph·∫ßn c·ª©ng: C√≥ th·ªÉ tri·ªÉn khai tr√™n ph·∫ßn c·ª©ng (nh∆∞ FPGA, GPU) ƒë·ªÉ ƒë·∫°t hi·ªáu nƒÉng cao. 9. ·ª®ng d·ª•ng trong b·∫£o m·∫≠t v√† quy·ªÅn ri√™ng t∆∞ Truy v·∫•n ·∫©n danh: H·ªó tr·ª£ c√°c giao th·ª©c truy v·∫•n th√¥ng tin ri√™ng t∆∞ m√† kh√¥ng l√†m l·ªô d·ªØ li·ªáu. Ph√°t hi·ªán nhanh ch√≥ng: X√°c ƒë·ªãnh IP ho·∫∑c h√†nh vi ƒë√°ng ng·ªù m√† kh√¥ng c·∫ßn l∆∞u tr·ªØ to√†n b·ªô d·ªØ li·ªáu nh·∫°y c·∫£m. 10. D·ªÖ b·∫£o tr√¨ Kh√¥ng l∆∞u d·ªØ li·ªáu th√¥: V√¨ Bloom Filter kh√¥ng l∆∞u tr·ªØ ch√≠nh x√°c d·ªØ li·ªáu th√¥, chi ph√≠ qu·∫£n l√Ω v√† b·∫£o tr√¨ th·∫•p h∆°n. Ho·∫°t ƒë·ªông tƒ©nh: M·ªôt Bloom Filter ƒë∆∞·ª£c t·∫°o tr∆∞·ªõc c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng l·∫∑p l·∫°i m√† kh√¥ng c·∫ßn c·∫≠p nh·∫≠t. Khi n√†o n√™n s·ª≠ d·ª•ng Bloom Filter? B·ªô nh·ªõ h·∫°n ch·∫ø: Khi kh√¥ng gian l∆∞u tr·ªØ l√† v·∫•n ƒë·ªÅ quan tr·ªçng, ch·∫≥ng h·∫°n trong c√°c h·ªá th·ªëng nh√∫ng ho·∫∑c thi·∫øt b·ªã IoT. C·∫ßn ki·ªÉm tra nhanh: Khi t·ªëc ƒë·ªô ki·ªÉm tra th√†nh vi√™n quan tr·ªçng h∆°n ƒë·ªô ch√≠nh x√°c tuy·ªát ƒë·ªëi. Ch·∫•p nh·∫≠n false positive: C√°c ·ª©ng d·ª•ng c√≥ th·ªÉ ch·ªãu ƒë∆∞·ª£c m·ªôt s·ªë tr∆∞·ªùng h·ª£p false positive, v√≠ d·ª• nh∆∞ b·ªô l·ªçc spam. H·∫°n ch·∫ø c·ªßa b·ªô l·ªçc Bloom Filter M·∫∑c d√π Bloom Filter c√≥ nhi·ªÅu ∆∞u ƒëi·ªÉm v∆∞·ª£t tr·ªôi, nh∆∞ng c≈©ng t·ªìn t·∫°i m·ªôt s·ªë h·∫°n ch·∫ø c·∫ßn xem x√©t tr∆∞·ªõc khi s·ª≠ d·ª•ng. D∆∞·ªõi ƒë√¢y l√† c√°c nh∆∞·ª£c ƒëi·ªÉm ch√≠nh:\n1. False Positive (K·∫øt qu·∫£ d∆∞∆°ng t√≠nh gi·∫£) Kh√¥ng ch√≠nh x√°c tuy·ªát ƒë·ªëi: Bloom Filter c√≥ th·ªÉ b√°o r·∫±ng m·ªôt ph·∫ßn t·ª≠ n·∫±m trong t·∫≠p h·ª£p m·∫∑c d√π th·ª±c t·∫ø kh√¥ng ph·∫£i v·∫≠y. ƒêi·ªÅu n√†y x·∫£y ra do b·∫£n ch·∫•t x√°c su·∫•t c·ªßa c·∫•u tr√∫c d·ªØ li·ªáu. Kh√¥ng ph√π h·ª£p cho c√°c ·ª©ng d·ª•ng y√™u c·∫ßu ch√≠nh x√°c tuy·ªát ƒë·ªëi: V√≠ d·ª•, kh√¥ng th·ªÉ s·ª≠ d·ª•ng Bloom Filter ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu nh·∫°y c·∫£m ho·∫∑c khi c·∫ßn ƒë·∫£m b·∫£o 100% ƒë·ªô tin c·∫≠y. 2. Kh√¥ng h·ªó tr·ª£ x√≥a ph·∫ßn t·ª≠ Kh√¥ng th·ªÉ x√≥a trong phi√™n b·∫£n c∆° b·∫£n: M·ªôt ph·∫ßn t·ª≠ ƒë√£ ƒë∆∞·ª£c th√™m v√†o Bloom Filter kh√¥ng th·ªÉ b·ªã x√≥a, v√¨ vi·ªác thay ƒë·ªïi b·∫•t k·ª≥ bit n√†o c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn c√°c ph·∫ßn t·ª≠ kh√°c ƒë√£ ƒë∆∞·ª£c bƒÉm v√†o c√πng bit. Gi·∫£i ph√°p: S·ª≠ d·ª•ng Counting Bloom Filter, nh∆∞ng ƒëi·ªÅu n√†y ƒë√≤i h·ªèi nhi·ªÅu b·ªô nh·ªõ h∆°n. 3. Kh√¥ng l∆∞u tr·ªØ d·ªØ li·ªáu g·ªëc Kh√¥ng th·ªÉ tr√≠ch xu·∫•t l·∫°i d·ªØ li·ªáu: Bloom Filter ch·ªâ l∆∞u d·∫•u v·∫øt c·ªßa ph·∫ßn t·ª≠ th√¥ng qua m·∫£ng bit, v√¨ v·∫≠y kh√¥ng th·ªÉ truy xu·∫•t l·∫°i c√°c ph·∫ßn t·ª≠ th·ª±c t·∫ø t·ª´ Bloom Filter. ·ª®ng d·ª•ng h·∫°n ch·∫ø: Kh√¥ng th·ªÉ s·ª≠ d·ª•ng Bloom Filter trong c√°c h·ªá th·ªëng c·∫ßn l∆∞u tr·ªØ ho·∫∑c qu·∫£n l√Ω d·ªØ li·ªáu th·ª±c t·∫ø. 4. Kh√≥ ƒëi·ªÅu ch·ªânh t·ª∑ l·ªá false positive C·∫ßn thi·∫øt k·∫ø tr∆∞·ªõc: T·ª∑ l·ªá false positive ph·ª• thu·ªôc v√†o k√≠ch th∆∞·ªõc m·∫£ng bit, s·ªë l∆∞·ª£ng h√†m bƒÉm, v√† s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠. N·∫øu c√°c tham s·ªë n√†y kh√¥ng ƒë∆∞·ª£c thi·∫øt k·∫ø c·∫©n th·∫≠n t·ª´ ƒë·∫ßu, Bloom Filter c√≥ th·ªÉ ho·∫°t ƒë·ªông kh√¥ng hi·ªáu qu·∫£. Kh√¥ng linh ho·∫°t: Vi·ªác thay ƒë·ªïi c√°c tham s·ªë (nh∆∞ k√≠ch th∆∞·ªõc ho·∫∑c s·ªë h√†m bƒÉm) th∆∞·ªùng ƒë√≤i h·ªèi ph·∫£i t·∫°o l·∫°i to√†n b·ªô Bloom Filter. 5. Y√™u c·∫ßu ch·ªçn h√†m bƒÉm ph√π h·ª£p Hi·ªáu su·∫•t ph·ª• thu·ªôc v√†o h√†m bƒÉm: N·∫øu c√°c h√†m bƒÉm kh√¥ng ƒë∆∞·ª£c ch·ªçn t·ªët, ch√∫ng c√≥ th·ªÉ t·∫°o ra c√°c xung ƒë·ªôt l·ªõn, d·∫´n ƒë·∫øn t·ª∑ l·ªá false positive cao. Hao t·ªïn t√†i nguy√™n: T√≠nh to√°n c√°c h√†m bƒÉm ph·ª©c t·∫°p c√≥ th·ªÉ ti√™u t·ªën t√†i nguy√™n CPU, ƒë·∫∑c bi·ªát khi s·ª≠ d·ª•ng nhi·ªÅu h√†m bƒÉm. 6. Kh√¥ng hi·ªáu qu·∫£ v·ªõi t·∫≠p d·ªØ li·ªáu nh·ªè Qu√° ph·ª©c t·∫°p so v·ªõi b√†i to√°n nh·ªè: Khi t·∫≠p d·ªØ li·ªáu nh·ªè, vi·ªác s·ª≠ d·ª•ng Bloom Filter c√≥ th·ªÉ ph·ª©c t·∫°p v√† t·ªën t√†i nguy√™n h∆°n so v·ªõi c√°c gi·∫£i ph√°p kh√°c nh∆∞ danh s√°ch li√™n k·∫øt ho·∫∑c b·∫£ng bƒÉm. 7. Kh√¥ng th·ªÉ m·ªü r·ªông m·ªôt c√°ch ƒë∆°n gi·∫£n Kh√≥ th√™m ph·∫ßn t·ª≠ m·ªõi: Khi t·∫≠p d·ªØ li·ªáu l·ªõn h∆°n d·ª± ki·∫øn, Bloom Filter ban ƒë·∫ßu c√≥ th·ªÉ kh√¥ng ƒë·ªß ƒë·ªÉ l∆∞u tr·ªØ th√™m ph·∫ßn t·ª≠ m√† kh√¥ng tƒÉng t·ª∑ l·ªá false positive. Gi·∫£i ph√°p: S·ª≠ d·ª•ng Scalable Bloom Filter, nh∆∞ng ƒëi·ªÅu n√†y l√†m tƒÉng ƒë·ªô ph·ª©c t·∫°p v√† chi ph√≠. 8. Kh√¥ng h·ªó tr·ª£ ki·ªÉm tra ph·ªß ƒë·ªãnh (No False Negatives) Ch·ªâ ki·ªÉm tra th√†nh vi√™n: Bloom Filter ch·ªâ x√°c nh·∫≠n r·∫±ng ph·∫ßn t·ª≠ \u0026ldquo;c√≥ th·ªÉ c√≥\u0026rdquo; ho·∫∑c \u0026ldquo;ch·∫Øc ch·∫Øn kh√¥ng c√≥\u0026rdquo; trong t·∫≠p h·ª£p, v√† kh√¥ng th·ªÉ s·ª≠ d·ª•ng ƒë·ªÉ so s√°nh ho·∫∑c t√¨m ki·∫øm d·ªØ li·ªáu th·ª±c t·∫ø. ·ª®ng d·ª•ng gi·ªõi h·∫°n: Kh√¥ng ph√π h·ª£p cho c√°c b√†i to√°n y√™u c·∫ßu th√¥ng tin ch√≠nh x√°c v·ªÅ ph·∫ßn t·ª≠ (nh∆∞ v·ªã tr√≠, gi√° tr·ªã c·ª• th·ªÉ). 9. Kh√≥ tri·ªÉn khai v√† b·∫£o tr√¨ trong h·ªá th·ªëng l·ªõn C·∫ßn ƒë·ªìng b·ªô h√≥a: Trong h·ªá th·ªëng ph√¢n t√°n, Bloom Filter c·∫ßn ƒë∆∞·ª£c c·∫≠p nh·∫≠t ho·∫∑c ƒë·ªìng b·ªô li√™n t·ª•c, ƒëi·ªÅu n√†y c√≥ th·ªÉ g√¢y ph·ª©c t·∫°p khi d·ªØ li·ªáu thay ƒë·ªïi nhanh. Chi ph√≠ b·ªô nh·ªõ: M·∫∑c d√π Bloom Filter ti·∫øt ki·ªám b·ªô nh·ªõ, nh∆∞ng khi y√™u c·∫ßu t·ª∑ l·ªá false positive th·∫•p, k√≠ch th∆∞·ªõc m·∫£ng bit c√≥ th·ªÉ tr·ªü n√™n l·ªõn, l√†m gi·∫£m l·ª£i √≠ch c·ªßa n√≥. 10. Kh√¥ng ph√π h·ª£p v·ªõi d·ªØ li·ªáu ƒë·ªông Kh√¥ng t·ªëi ∆∞u cho d·ªØ li·ªáu thay ƒë·ªïi th∆∞·ªùng xuy√™n: Khi t·∫≠p d·ªØ li·ªáu thay ƒë·ªïi li√™n t·ª•c (th√™m ho·∫∑c x√≥a ph·∫ßn t·ª≠), Bloom Filter c∆° b·∫£n kh√¥ng ph√π h·ª£p v√¨ kh√¥ng h·ªó tr·ª£ x√≥a v√† t√°i s·ª≠ d·ª•ng kh√¥ng gian. Khi n√†o kh√¥ng n√™n s·ª≠ d·ª•ng Bloom Filter? Khi y√™u c·∫ßu k·∫øt qu·∫£ ch√≠nh x√°c tuy·ªát ƒë·ªëi (kh√¥ng ch·∫•p nh·∫≠n false positive). Khi d·ªØ li·ªáu thay ƒë·ªïi li√™n t·ª•c v√† c·∫ßn c·∫≠p nh·∫≠t (th√™m ho·∫∑c x√≥a ph·∫ßn t·ª≠). Khi t·∫≠p d·ªØ li·ªáu nh·ªè, Bloom Filter c√≥ th·ªÉ ph·ª©c t·∫°p v√† t·ªën t√†i nguy√™n h∆°n c√°c gi·∫£i ph√°p ƒë∆°n gi·∫£n kh√°c. M·ªôt s·ªë bi·∫øn th·ªÉ c·ªßa Bloom Filter Double Hashing Bloom Filter: Double Hashing Bloom Filter l√† m·ªôt bi·∫øn th·ªÉ c·ªßa Bloom Filter truy·ªÅn th·ªëng s·ª≠ d·ª•ng double hashing ƒë·ªÉ t√≠nh to√°n nhi·ªÅu gi√° tr·ªã bƒÉm t·ª´ m·ªôt c·∫∑p h√†m bƒÉm c∆° s·ªü thay v√¨ s·ª≠ d·ª•ng m·ªôt t·∫≠p h·ª£p c√°c h√†m bƒÉm ƒë·ªôc l·∫≠p. ƒêi·ªÅu n√†y gi√∫p gi·∫£m ƒë·ªô ph·ª©c t·∫°p v√† t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t khi tri·ªÉn khai.\nC√°ch ho·∫°t ƒë·ªông c·ªßa Double Hashing Bloom Filter √ù t∆∞·ªüng ch√≠nh c·ªßa Double Hashing:\nS·ª≠ d·ª•ng hai h√†m bƒÉm c∆° b·∫£n, ( h_1(x) ) v√† ( h_2(x) ), ƒë·ªÉ t·∫°o ra ( k ) h√†m bƒÉm cho Bloom Filter. C√°c gi√° tr·ªã bƒÉm ƒë∆∞·ª£c t√≠nh theo c√¥ng th·ª©c: [ g_i(x) = (h_1(x) + i \\cdot h_2(x)) \\mod m ] ( g_i(x) ) l√† gi√° tr·ªã bƒÉm th·ª© ( i ) cho ph·∫ßn t·ª≠ ( x ). ( m ) l√† k√≠ch th∆∞·ªõc c·ªßa m·∫£ng bit. ( i ) l√† ch·ªâ s·ªë (0 ƒë·∫øn ( k-1 )). Th√™m ph·∫ßn t·ª≠ (Insert):\nT√≠nh ( k ) gi√° tr·ªã bƒÉm t·ª´ hai h√†m bƒÉm ( h_1(x) ) v√† ( h_2(x) ). ƒê·∫∑t c√°c bit t·∫°i c√°c v·ªã tr√≠ t∆∞∆°ng ·ª©ng trong m·∫£ng th√†nh 1. Ki·ªÉm tra ph·∫ßn t·ª≠ (Check):\nT√≠nh ( k ) gi√° tr·ªã bƒÉm t∆∞∆°ng t·ª±. Ki·ªÉm tra xem t·∫•t c·∫£ c√°c bit t∆∞∆°ng ·ª©ng ƒë√£ ƒë∆∞·ª£c ƒë·∫∑t th√†nh 1 ch∆∞a. ∆Øu ƒëi·ªÉm c·ªßa Double Hashing Bloom Filter Gi·∫£m s·ªë h√†m bƒÉm c·∫ßn thi·∫øt:\nCh·ªâ c·∫ßn hai h√†m bƒÉm thay v√¨ ( k ), gi√∫p ƒë∆°n gi·∫£n h√≥a tri·ªÉn khai. TƒÉng hi·ªáu qu·∫£ t√≠nh to√°n:\nVi·ªác t√≠nh to√°n c√°c gi√° tr·ªã bƒÉm s·ª≠ d·ª•ng ( h_1(x) ) v√† ( h_2(x) ) l√† nhanh ch√≥ng v√† d·ªÖ d√†ng. T·ªëi ∆∞u h√≥a b·ªô nh·ªõ:\nKh√¥ng c·∫ßn l∆∞u tr·ªØ ho·∫∑c tri·ªÉn khai nhi·ªÅu h√†m bƒÉm ri√™ng l·∫ª. H·∫°n ch·∫ø c·ªßa Double Hashing Bloom Filter ƒê·ªô ch√≠nh x√°c ph·ª• thu·ªôc v√†o h√†m bƒÉm c∆° s·ªü:\nN·∫øu ( h_1(x) ) v√† ( h_2(x) ) kh√¥ng t·ªët, ph√¢n ph·ªëi gi√° tr·ªã bƒÉm c√≥ th·ªÉ kh√¥ng ƒë·ªÅu. False positive v·∫´n t·ªìn t·∫°i:\nGi·ªëng Bloom Filter truy·ªÅn th·ªëng, n√≥ kh√¥ng th·ªÉ tr√°nh ho√†n to√†n false positive. ·ª®ng d·ª•ng c·ªßa Double Hashing Bloom Filter C∆° s·ªü d·ªØ li·ªáu:\nGi·∫£m chi ph√≠ ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa c√°c kh√≥a trong h·ªá th·ªëng l∆∞u tr·ªØ. Cache v√† b·ªô l·ªçc web:\nX√°c ƒë·ªãnh nhanh ch√≥ng xem m·ªôt URL c√≥ n·∫±m trong danh s√°ch ch·∫∑n hay kh√¥ng. H·ªá th·ªëng m·∫°ng:\nTheo d√µi v√† l·ªçc g√≥i tin ho·∫∑c ƒë·ªãa ch·ªâ IP. Tri·ªÉn khai Double Hashing Bloom Filter b·∫±ng Python 1import hashlib 2 3class DoubleHashingBloomFilter: 4 def __init__(self, size, num_hashes): 5 self.size = size 6 self.num_hashes = num_hashes 7 self.bit_array = [0] * size 8 9 def _hashes(self, item): 10 h1 = int(hashlib.md5(item.encode()).hexdigest(), 16) % self.size 11 h2 = int(hashlib.sha256(item.encode()).hexdigest(), 16) % self.size 12 hashes = [(h1 + i * h2) % self.size for i in range(self.num_hashes)] 13 return hashes 14 15 def add(self, item): 16 indices = self._hashes(item) 17 for idx in indices: 18 self.bit_array[idx] = 1 19 20 def contains(self, item): 21 indices = self._hashes(item) 22 return all(self.bit_array[idx] for idx in indices) 23 24 25# Example Usage 26dbf = DoubleHashingBloomFilter(size=100, num_hashes=5) 27 28# Add elements 29dbf.add(\u0026#34;hello\u0026#34;) 30dbf.add(\u0026#34;world\u0026#34;) 31 32# Check elements 33print(dbf.contains(\u0026#34;hello\u0026#34;)) # True 34print(dbf.contains(\u0026#34;world\u0026#34;)) # True 35print(dbf.contains(\u0026#34;python\u0026#34;)) # False T√≥m t·∫Øt Double Hashing Bloom Filter gi·∫£m s·ªë l∆∞·ª£ng h√†m bƒÉm c·∫ßn thi·∫øt b·∫±ng c√°ch s·ª≠ d·ª•ng hai h√†m bƒÉm c∆° s·ªü ƒë·ªÉ t·∫°o ( k ) gi√° tr·ªã bƒÉm. Ph√π h·ª£p v·ªõi c√°c ·ª©ng d·ª•ng y√™u c·∫ßu hi·ªáu su·∫•t cao, d·ªÖ tri·ªÉn khai v√† b·∫£o to√†n t√≠nh ch√≠nh x√°c c·ªßa Bloom Filter. M√£ gi·∫£ ·ªü tr√™n minh h·ªça c√°ch tri·ªÉn khai b·∫±ng c·∫£ Python v√† Golang. N·∫øu c·∫ßn gi·∫£i th√≠ch th√™m ho·∫∑c c√≥ y√™u c·∫ßu c·ª• th·ªÉ, h√£y cho m√¨nh bi·∫øt nh√©! üòä\nPartitioning Bloom Filter: Partitioning Bloom Filter (PBF) l√† m·ªôt bi·∫øn th·ªÉ c·ªßa Bloom Filter, trong ƒë√≥ m·∫£ng bit ƒë∆∞·ª£c chia th√†nh c√°c ph√¢n ƒëo·∫°n ri√™ng bi·ªát (partitions). M·ªói h√†m bƒÉm ch·ªâ ·∫£nh h∆∞·ªüng ƒë·∫øn m·ªôt ph√¢n ƒëo·∫°n c·ª• th·ªÉ thay v√¨ to√†n b·ªô m·∫£ng. Ph∆∞∆°ng ph√°p n√†y c·∫£i thi·ªán kh·∫£ nƒÉng ph√¢n t√°n v√† gi·∫£m kh·∫£ nƒÉng c√°c h√†m bƒÉm kh√°c nhau ghi ƒë√® l·∫´n nhau (collision) trong m·∫£ng bit.\nC√°ch ho·∫°t ƒë·ªông c·ªßa Partitioning Bloom Filter Chia m·∫£ng bit th√†nh nhi·ªÅu ph√¢n ƒëo·∫°n (partitions):\nM·∫£ng bit t·ªïng th·ªÉ ƒë∆∞·ª£c chia th√†nh ( k ) ph√¢n ƒëo·∫°n, trong ƒë√≥ ( k ) l√† s·ªë h√†m bƒÉm. M·ªói h√†m bƒÉm ch·ªâ ho·∫°t ƒë·ªông tr√™n m·ªôt ph√¢n ƒëo·∫°n ri√™ng bi·ªát. Th√™m ph·∫ßn t·ª≠ (Insert):\nKhi m·ªôt ph·∫ßn t·ª≠ ƒë∆∞·ª£c th√™m v√†o, c√°c h√†m bƒÉm √°nh x·∫° n√≥ ƒë·∫øn c√°c v·ªã tr√≠ trong t·ª´ng ph√¢n ƒëo·∫°n. Ch·ªâ c√°c bit trong ph√¢n ƒëo·∫°n t∆∞∆°ng ·ª©ng ƒë∆∞·ª£c thi·∫øt l·∫≠p. Ki·ªÉm tra ph·∫ßn t·ª≠ (Check):\nƒê·ªÉ ki·ªÉm tra s·ª± t·ªìn t·∫°i, √°p d·ª•ng c√°c h√†m bƒÉm ƒë·ªÉ ki·ªÉm tra c√°c v·ªã tr√≠ trong c√°c ph√¢n ƒëo·∫°n t∆∞∆°ng ·ª©ng. Gi·∫£m xung ƒë·ªôt gi·ªØa c√°c h√†m bƒÉm:\nV√¨ m·ªói h√†m bƒÉm ch·ªâ l√†m vi·ªác trong m·ªôt ph√¢n ƒëo·∫°n, kh·∫£ nƒÉng ghi ƒë√® bit c·ªßa nhau (collision) gi·∫£m ƒë√°ng k·ªÉ so v·ªõi Bloom Filter th√¥ng th∆∞·ªùng. ∆Øu ƒëi·ªÉm c·ªßa Partitioning Bloom Filter Ph√¢n ph·ªëi ƒë·ªìng ƒë·ªÅu h∆°n:\nVi·ªác ph√¢n chia m·∫£ng gi√∫p gi·∫£m xung ƒë·ªôt gi·ªØa c√°c h√†m bƒÉm v√† c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c. Ki·ªÉm so√°t false positive:\nX√°c su·∫•t false positive c√≥ th·ªÉ gi·∫£m so v·ªõi Bloom Filter th√¥ng th∆∞·ªùng n·∫øu c√°c ph√¢n ƒëo·∫°n ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªëi ∆∞u. D·ªÖ d√†ng m·ªü r·ªông:\nC√≥ th·ªÉ tƒÉng s·ªë ph√¢n ƒëo·∫°n ho·∫∑c k√≠ch th∆∞·ªõc t·ª´ng ph√¢n ƒëo·∫°n ƒë·ªÉ ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ª• th·ªÉ. H·∫°n ch·∫ø c·ªßa Partitioning Bloom Filter TƒÉng ph·ª©c t·∫°p qu·∫£n l√Ω:\nC·∫ßn ƒë·∫£m b·∫£o r·∫±ng m·ªói h√†m bƒÉm ch·ªâ ho·∫°t ƒë·ªông trong ph√¢n ƒëo·∫°n t∆∞∆°ng ·ª©ng, tƒÉng ƒë·ªô ph·ª©c t·∫°p khi tri·ªÉn khai. B·ªô nh·ªõ kh√¥ng linh ho·∫°t:\nM·ªói ph√¢n ƒëo·∫°n ph·∫£i c√≥ k√≠ch th∆∞·ªõc gi·ªëng nhau, d·∫´n ƒë·∫øn vi·ªác s·ª≠ d·ª•ng b·ªô nh·ªõ kh√¥ng linh ho·∫°t n·∫øu d·ªØ li·ªáu kh√¥ng ƒë·ªìng ƒë·ªÅu. ·ª®ng d·ª•ng c·ªßa Partitioning Bloom Filter H·ªá th·ªëng l∆∞u tr·ªØ v√† cache:\nTheo d√µi s·ª± t·ªìn t·∫°i c·ªßa c√°c ph·∫ßn t·ª≠ trong c√°c v√πng d·ªØ li·ªáu ri√™ng bi·ªát. Qu·∫£n l√Ω t·∫£i trong m·∫°ng:\nChia nh·ªè d·ªØ li·ªáu theo c√°c nh√≥m (partitions) ƒë·ªÉ gi·∫£m xung ƒë·ªôt khi l∆∞u tr·ªØ. Ph√¢n v√πng c∆° s·ªü d·ªØ li·ªáu:\nGi√∫p ph√¢n t√°n truy v·∫•n v√† d·ªØ li·ªáu trong c√°c c·ª•m (cluster) c∆° s·ªü d·ªØ li·ªáu. Tri·ªÉn khai Partitioning Bloom Filter b·∫±ng Python 1import hashlib 2 3class PartitioningBloomFilter: 4 def __init__(self, total_size, num_hashes): 5 self.num_hashes = num_hashes 6 self.partition_size = total_size // num_hashes 7 self.bit_array = [0] * total_size 8 9 def _hashes(self, item): 10 hashes = [] 11 for i in range(self.num_hashes): 12 hash_value = int(hashlib.md5((str(item) + str(i)).encode()).hexdigest(), 16) 13 # Map hash to the partition 14 partition_start = i * self.partition_size 15 index = partition_start + (hash_value % self.partition_size) 16 hashes.append(index) 17 return hashes 18 19 def add(self, item): 20 indices = self._hashes(item) 21 for idx in indices: 22 self.bit_array[idx] = 1 23 24 def contains(self, item): 25 indices = self._hashes(item) 26 return all(self.bit_array[idx] for idx in indices) 27 28 29# Example Usage 30pbf = PartitioningBloomFilter(total_size=100, num_hashes=5) 31 32# Add elements 33pbf.add(\u0026#34;hello\u0026#34;) 34pbf.add(\u0026#34;world\u0026#34;) 35 36# Check elements 37print(pbf.contains(\u0026#34;hello\u0026#34;)) # True 38print(pbf.contains(\u0026#34;world\u0026#34;)) # True 39print(pbf.contains(\u0026#34;python\u0026#34;)) # False T√≥m t·∫Øt Partitioning Bloom Filter c·∫£i thi·ªán Bloom Filter b·∫±ng c√°ch chia m·∫£ng bit th√†nh c√°c ph√¢n ƒëo·∫°n ƒë·ªôc l·∫≠p. N√≥ gi·∫£m xung ƒë·ªôt gi·ªØa c√°c h√†m bƒÉm v√† c√≥ th·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c. Th√≠ch h·ª£p cho c√°c ·ª©ng d·ª•ng y√™u c·∫ßu truy v·∫•n nhanh v√† ƒë·ªìng th·ªùi trong c√°c v√πng d·ªØ li·ªáu ri√™ng bi·ªát. Counting Bloom Filter: Counting Bloom Filter (CBF) l√† m·ªôt bi·∫øn th·ªÉ c·ªßa Bloom Filter h·ªó tr·ª£ th√™m kh·∫£ nƒÉng x√≥a (delete) ph·∫ßn t·ª≠ kh·ªèi c·∫•u tr√∫c d·ªØ li·ªáu. Trong khi Bloom Filter truy·ªÅn th·ªëng ch·ªâ c√≥ th·ªÉ th√™m v√† ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa ph·∫ßn t·ª≠, Counting Bloom Filter cho ph√©p c·∫£ th√™m, x√≥a, v√† ki·ªÉm tra v·ªõi ƒë·ªô ch√≠nh x√°c t∆∞∆°ng ƒë·ªëi.\nC√°ch ho·∫°t ƒë·ªông c·ªßa Counting Bloom Filter Thay v√¨ m·∫£ng bit, s·ª≠ d·ª•ng m·∫£ng ƒë·∫øm (counting array):\nM·ªói v·ªã tr√≠ trong m·∫£ng kh√¥ng c√≤n l√† m·ªôt bit (0 ho·∫∑c 1) m√† l√† m·ªôt s·ªë nguy√™n (counter). B·ªô ƒë·∫øm ·ªü m·ªói v·ªã tr√≠ cho bi·∫øt s·ªë l·∫ßn m·ªôt ph·∫ßn t·ª≠ ho·∫∑c nhi·ªÅu ph·∫ßn t·ª≠ kh√°c nhau √°nh x·∫° ƒë·∫øn v·ªã tr√≠ ƒë√≥. Th√™m ph·∫ßn t·ª≠ (Insert):\nKhi th√™m m·ªôt ph·∫ßn t·ª≠, tƒÉng gi√° tr·ªã c·ªßa c√°c b·ªô ƒë·∫øm t·∫°i c√°c ch·ªâ m·ª•c ƒë∆∞·ª£c t√≠nh b·ªüi c√°c h√†m bƒÉm. X√≥a ph·∫ßn t·ª≠ (Delete):\nKhi x√≥a m·ªôt ph·∫ßn t·ª≠, gi·∫£m gi√° tr·ªã c·ªßa c√°c b·ªô ƒë·∫øm t·∫°i c√°c ch·ªâ m·ª•c ƒë∆∞·ª£c t√≠nh b·ªüi c√°c h√†m bƒÉm. N·∫øu b·∫•t k·ª≥ b·ªô ƒë·∫øm n√†o gi·∫£m v·ªÅ 0, v·ªã tr√≠ ƒë√≥ ƒë∆∞·ª£c coi l√† tr·ªëng. Ki·ªÉm tra ph·∫ßn t·ª≠ (Check):\nPh·∫ßn t·ª≠ ƒë∆∞·ª£c coi l√† c√≥ th·ªÉ t·ªìn t·∫°i n·∫øu t·∫•t c·∫£ c√°c ch·ªâ m·ª•c bƒÉm t∆∞∆°ng ·ª©ng c√≥ gi√° tr·ªã l·ªõn h∆°n 0. ∆Øu ƒëi·ªÉm c·ªßa Counting Bloom Filter H·ªó tr·ª£ x√≥a ph·∫ßn t·ª≠:\nKh·∫Øc ph·ª•c h·∫°n ch·∫ø l·ªõn c·ªßa Bloom Filter truy·ªÅn th·ªëng l√† kh√¥ng h·ªó tr·ª£ x√≥a. Gi·ªØ ƒë∆∞·ª£c t√≠nh g·ªçn nh·∫π:\nCh·ªâ c·∫ßn m·ªôt l∆∞·ª£ng nh·ªè b·ªô nh·ªõ b·ªï sung (c√°c b·ªô ƒë·∫øm thay v√¨ bit). Hi·ªáu qu·∫£ v·ªõi c√°c t·∫≠p d·ªØ li·ªáu ƒë·ªông:\nR·∫•t ph√π h·ª£p trong c√°c ·ª©ng d·ª•ng m√† c√°c ph·∫ßn t·ª≠ th∆∞·ªùng xuy√™n ƒë∆∞·ª£c th√™m v√† x√≥a. H·∫°n ch·∫ø c·ªßa Counting Bloom Filter False positive:\nGi·ªëng nh∆∞ Bloom Filter, CBF v·∫´n c√≥ nguy c∆° false positive (tr·∫£ v·ªÅ \u0026ldquo;c√≥ th·ªÉ t·ªìn t·∫°i\u0026rdquo; cho ph·∫ßn t·ª≠ kh√¥ng t·ªìn t·∫°i). Kh√¥ng h·ªó tr·ª£ ki·ªÉm tra \u0026ldquo;ch·∫Øc ch·∫Øn x√≥a\u0026rdquo;:\nKhi m·ªôt ph·∫ßn t·ª≠ b·ªã x√≥a, c√°c ph·∫ßn t·ª≠ kh√°c c√≥ th·ªÉ √°nh x·∫° ƒë·∫øn c√πng ch·ªâ m·ª•c v·∫´n gi·ªØ c√°c b·ªô ƒë·∫øm. TƒÉng y√™u c·∫ßu b·ªô nh·ªõ:\nM·ªói v·ªã tr√≠ trong m·∫£ng c·∫ßn l∆∞u tr·ªØ m·ªôt s·ªë nguy√™n thay v√¨ m·ªôt bit, d·∫´n ƒë·∫øn tƒÉng ƒë√°ng k·ªÉ dung l∆∞·ª£ng b·ªô nh·ªõ. ·ª®ng d·ª•ng c·ªßa Counting Bloom Filter Qu·∫£n l√Ω cache:\nTheo d√µi c√°c ph·∫ßn t·ª≠ trong cache, cho ph√©p x√≥a khi h·∫øt h·∫°n ho·∫∑c khi kh√¥ng c√≤n c·∫ßn thi·∫øt. H·ªá th·ªëng m·∫°ng:\nTheo d√µi c√°c g√≥i tin ho·∫∑c l∆∞u l∆∞·ª£ng m·∫°ng trong kho·∫£ng th·ªùi gian nh·∫•t ƒë·ªãnh. C∆° s·ªü d·ªØ li·ªáu:\nH·ªó tr·ª£ trong c√°c h·ªá th·ªëng l∆∞u tr·ªØ, n∆°i c√°c ph·∫ßn t·ª≠ c·∫ßn ƒë∆∞·ª£c th√™m v√† x√≥a th∆∞·ªùng xuy√™n. Tri·ªÉn khai b·∫±ng Python 1import hashlib 2 3class CountingBloomFilter: 4 def __init__(self, size, num_hashes): 5 self.size = size 6 self.num_hashes = num_hashes 7 self.count_array = [0] * size 8 9 def _hashes(self, item): 10 hashes = [] 11 for i in range(self.num_hashes): 12 hash_value = int(hashlib.md5((str(item) + str(i)).encode()).hexdigest(), 16) 13 hashes.append(hash_value % self.size) 14 return hashes 15 16 def add(self, item): 17 indices = self._hashes(item) 18 for idx in indices: 19 self.count_array[idx] += 1 20 21 def delete(self, item): 22 indices = self._hashes(item) 23 for idx in indices: 24 if self.count_array[idx] \u0026gt; 0: 25 self.count_array[idx] -= 1 26 27 def contains(self, item): 28 indices = self._hashes(item) 29 return all(self.count_array[idx] \u0026gt; 0 for idx in indices) 30 31 32# Example Usage 33cbf = CountingBloomFilter(size=100, num_hashes=3) 34 35# Add elements 36cbf.add(\u0026#34;hello\u0026#34;) 37cbf.add(\u0026#34;world\u0026#34;) 38 39# Check elements 40print(cbf.contains(\u0026#34;hello\u0026#34;)) # True 41print(cbf.contains(\u0026#34;world\u0026#34;)) # True 42print(cbf.contains(\u0026#34;python\u0026#34;)) # False 43 44# Delete an element 45cbf.delete(\u0026#34;hello\u0026#34;) 46print(cbf.contains(\u0026#34;hello\u0026#34;)) # False T√≥m t·∫Øt Counting Bloom Filter cho ph√©p th√™m, x√≥a v√† ki·ªÉm tra ph·∫ßn t·ª≠, m·ªü r·ªông t√≠nh nƒÉng c·ªßa Bloom Filter truy·ªÅn th·ªëng. N√≥ ph√π h·ª£p v·ªõi c√°c ·ª©ng d·ª•ng y√™u c·∫ßu thao t√°c ƒë·ªông v·ªõi t·∫≠p d·ªØ li·ªáu, nh∆∞ng v·∫´n gi·ªØ c√°c ∆∞u ƒëi·ªÉm v·ªÅ hi·ªáu su·∫•t v√† b·ªô nh·ªõ c·ªßa Bloom Filter. N·∫øu c·∫ßn h·ªó tr·ª£ th√™m, h√£y cho m√¨nh bi·∫øt nh√©! üòä\nScalable Bloom Filter Scalable Bloom Filter (SBF) l√† m·ªôt bi·∫øn th·ªÉ c·ªßa Bloom Filter ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ kh·∫Øc ph·ª•c h·∫°n ch·∫ø c·ªë h·ªØu c·ªßa Bloom Filter truy·ªÅn th·ªëng: k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh. SBF c√≥ th·ªÉ m·ªü r·ªông ƒë·ªông khi s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ tƒÉng m√† kh√¥ng l√†m m·∫•t t√≠nh hi·ªáu qu·∫£ ho·∫∑c ch√≠nh x√°c c·ªßa Bloom Filter.\nV·∫•n ƒë·ªÅ v·ªõi Bloom Filter truy·ªÅn th·ªëng Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc: Bloom Filter truy·ªÅn th·ªëng y√™u c·∫ßu k√≠ch th∆∞·ªõc m·∫£ng bit c·ªë ƒë·ªãnh khi kh·ªüi t·∫°o, d·ª±a tr√™n s·ªë ph·∫ßn t·ª≠ ∆∞·ªõc t√≠nh v√† t·ª∑ l·ªá false positive mong mu·ªën. N·∫øu s·ªë ph·∫ßn t·ª≠ v∆∞·ª£t qu√° d·ª± ƒëo√°n ban ƒë·∫ßu, t·ª∑ l·ªá false positive tƒÉng ƒë√°ng k·ªÉ. Kh√¥ng th·ªÉ thay ƒë·ªïi k√≠ch th∆∞·ªõc m√† v·∫´n gi·ªØ nguy√™n c√°c ph·∫ßn t·ª≠ ƒë√£ ƒë∆∞·ª£c th√™m. Scalable Bloom Filter gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ nh∆∞ th·∫ø n√†o? SBF kh·∫Øc ph·ª•c v·∫•n ƒë·ªÅ n√†y b·∫±ng c√°ch:\nTƒÉng k√≠ch th∆∞·ªõc ƒë·ªông: Khi s·ªë ph·∫ßn t·ª≠ v∆∞·ª£t qu√° m·ªôt ng∆∞·ª°ng (threshold), SBF th√™m m·ªôt Bloom Filter m·ªõi v·ªõi k√≠ch th∆∞·ªõc l·ªõn h∆°n. Gi·∫£m false positive: M·ªói Bloom Filter m·ªõi ƒë∆∞·ª£c t·∫°o ra s·ª≠ d·ª•ng m·ªôt t·ª∑ l·ªá false positive th·∫•p h∆°n so v·ªõi c√°c Bloom Filter tr∆∞·ªõc ƒë√≥. ƒêi·ªÅu n√†y gi√∫p gi·∫£m nguy c∆° t·ªïng th·ªÉ c·ªßa false positive. C·∫•u tr√∫c v√† c√°ch ho·∫°t ƒë·ªông c·ªßa Scalable Bloom Filter C·∫•u tr√∫c:\nSBF bao g·ªìm m·ªôt chu·ªói c√°c Bloom Filter ƒë∆∞·ª£c t·∫°o ra khi c·∫ßn m·ªü r·ªông. M·ªói Bloom Filter c√≥ k√≠ch th∆∞·ªõc v√† t·ª∑ l·ªá false positive kh√°c nhau, tƒÉng d·∫ßn theo th·ªùi gian. Ch√®n ph·∫ßn t·ª≠ (Insert):\nPh·∫ßn t·ª≠ m·ªõi ƒë∆∞·ª£c th√™m v√†o Bloom Filter hi·ªán t·∫°i (bloom filter cu·ªëi c√πng trong chu·ªói). N·∫øu Bloom Filter hi·ªán t·∫°i ƒë·∫°t ng∆∞·ª°ng t·ªëi ƒëa, m·ªôt Bloom Filter m·ªõi ƒë∆∞·ª£c t·∫°o. Ki·ªÉm tra ph·∫ßn t·ª≠ (Check):\nL·∫ßn l∆∞·ª£t ki·ªÉm tra ph·∫ßn t·ª≠ trong t·ª´ng Bloom Filter, t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi chu·ªói. N·∫øu ph·∫ßn t·ª≠ ƒë∆∞·ª£c t√¨m th·∫•y trong b·∫•t k·ª≥ Bloom Filter n√†o, k·∫øt qu·∫£ tr·∫£ v·ªÅ l√† \u0026ldquo;c√≥ th·ªÉ t·ªìn t·∫°i\u0026rdquo;. Ng∆∞·ª°ng m·ªü r·ªông (Threshold):\nSBF s·ª≠ d·ª•ng m·ªôt ng∆∞·ª°ng ki·ªÉm so√°t (th∆∞·ªùng d·ª±a tr√™n t·∫£i tr·ªçng, nh∆∞ s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ ƒë√£ th√™m) ƒë·ªÉ quy·∫øt ƒë·ªãnh khi n√†o c·∫ßn t·∫°o m·ªôt Bloom Filter m·ªõi. ∆Øu ƒëi·ªÉm c·ªßa Scalable Bloom Filter Kh·∫£ nƒÉng m·ªü r·ªông (Scalability):\nSBF kh√¥ng gi·ªõi h·∫°n s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ c√≥ th·ªÉ th√™m v√†o. TƒÉng k√≠ch th∆∞·ªõc ƒë·ªông m√† kh√¥ng c·∫ßn ƒë·ªãnh c·∫•u h√¨nh tr∆∞·ªõc. Gi·∫£m false positive hi·ªáu qu·∫£:\nM·ªói Bloom Filter m·ªõi c√≥ t·ª∑ l·ªá false positive th·∫•p h∆°n, l√†m gi·∫£m t·ª∑ l·ªá t·ªïng th·ªÉ. Ti·∫øt ki·ªám b·ªô nh·ªõ:\nSBF s·ª≠ d·ª•ng k√≠ch th∆∞·ªõc b·ªô nh·ªõ nh·ªè h∆°n so v·ªõi vi·ªác t·∫°o m·ªôt Bloom Filter r·∫•t l·ªõn ngay t·ª´ ƒë·∫ßu. Ph√π h·ª£p v·ªõi d·ªØ li·ªáu thay ƒë·ªïi:\nSBF r·∫•t h·ªØu √≠ch trong c√°c ·ª©ng d·ª•ng n∆°i s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ kh√≥ d·ª± ƒëo√°n. H·∫°n ch·∫ø c·ªßa Scalable Bloom Filter TƒÉng ƒë·ªô ph·ª©c t·∫°p:\nVi·ªác duy tr√¨ nhi·ªÅu Bloom Filter khi·∫øn ki·ªÉm tra ph·∫ßn t·ª≠ t·ªën th·ªùi gian h∆°n, ƒë·∫∑c bi·ªát khi chu·ªói Bloom Filter d√†i. Overhead b·ªô nh·ªõ:\nD√π SBF ti·∫øt ki·ªám b·ªô nh·ªõ h∆°n khi so s√°nh v·ªõi Bloom Filter truy·ªÅn th·ªëng kh√¥ng ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a, n√≥ v·∫´n c√≥ overhead v√¨ ph·∫£i qu·∫£n l√Ω nhi·ªÅu Bloom Filter. Kh√¥ng h·ªó tr·ª£ x√≥a:\nNh∆∞ Bloom Filter truy·ªÅn th·ªëng, SBF kh√¥ng h·ªó tr·ª£ x√≥a ph·∫ßn t·ª≠. ·ª®ng d·ª•ng c·ªßa Scalable Bloom Filter Qu·∫£n l√Ω cache:\nD√πng ƒë·ªÉ theo d√µi c√°c ph·∫ßn t·ª≠ trong cache v·ªõi s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ thay ƒë·ªïi ƒë·ªông. H·ªá th·ªëng l∆∞u tr·ªØ v√† c∆° s·ªü d·ªØ li·ªáu:\nƒê∆∞·ª£c s·ª≠ d·ª•ng trong c√°c h·ªá th·ªëng l∆∞u tr·ªØ ph√¢n t√°n nh∆∞ Bigtable, HBase, ho·∫∑c Cassandra. H·ªá th·ªëng ph√¢n t√°n:\nSBF gi√∫p theo d√µi tr·∫°ng th√°i c·ªßa c√°c ph·∫ßn t·ª≠ (nh∆∞ d·ªØ li·ªáu, g√≥i tin) trong h·ªá th·ªëng m√† k√≠ch th∆∞·ªõc t·∫≠p h·ª£p thay ƒë·ªïi li√™n t·ª•c. D·ªØ li·ªáu l·ªõn (Big Data):\nSBF ph√π h·ª£p v·ªõi c√°c ·ª©ng d·ª•ng x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn, n∆°i s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ kh√¥ng th·ªÉ d·ª± ƒëo√°n ch√≠nh x√°c. Tri·ªÉn khai Scalable Bloom Filter M·ªôt c√°ch ph·ªï bi·∫øn ƒë·ªÉ tri·ªÉn khai SBF:\nB·∫Øt ƒë·∫ßu v·ªõi m·ªôt Bloom Filter ban ƒë·∫ßu c√≥ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh. ƒê·∫∑t ng∆∞·ª°ng t·∫£i tr·ªçng (load factor), v√≠ d·ª•: khi s·ªë ph·∫ßn t·ª≠ ƒë·∫°t 80% dung l∆∞·ª£ng t·ªëi ƒëa. M·ªói khi th√™m m·ªôt Bloom Filter m·ªõi, tƒÉng k√≠ch th∆∞·ªõc m·∫£ng bit v√† gi·∫£m t·ª∑ l·ªá false positive b·∫±ng c√°ch thay ƒë·ªïi s·ªë l∆∞·ª£ng h√†m bƒÉm. M√£ gi·∫£ Scalable Bloom Filter 1 2import math 3import hashlib 4 5class BloomFilter: 6 def __init__(self, size, num_hashes): 7 self.size = size 8 self.num_hashes = num_hashes 9 self.bit_array = [0] * size 10 self.count = 0 11 12 def _hash(self, item, seed): 13 hash_value = int(hashlib.md5((str(item) + str(seed)).encode()).hexdigest(), 16) 14 return hash_value % self.size 15 16 def add(self, item): 17 for i in range(self.num_hashes): 18 index = self._hash(item, i) 19 self.bit_array[index] = 1 20 self.count += 1 21 22 def contains(self, item): 23 for i in range(self.num_hashes): 24 index = self._hash(item, i) 25 if self.bit_array[index] == 0: 26 return False 27 return True 28 29 30class ScalableBloomFilter: 31 def __init__(self, initial_size=100, fp_rate=0.05, growth_factor=2): 32 self.filters = [] 33 self.fp_rate = fp_rate 34 self.growth_factor = growth_factor 35 self.current_size = initial_size 36 self._add_new_filter() 37 38 def _optimal_num_hashes(self, size, items): 39 return max(1, math.ceil((size / items) * math.log(2))) 40 41 def _add_new_filter(self): 42 num_hashes = self._optimal_num_hashes(self.current_size, -math.log(self.fp_rate)) 43 self.filters.append(BloomFilter(self.current_size, num_hashes)) 44 self.current_size *= self.growth_factor 45 46 def add(self, item): 47 if self.filters[-1].count \u0026gt;= self.filters[-1].size: 48 self._add_new_filter() 49 self.filters[-1].add(item) 50 51 def contains(self, item): 52 return any(filter.contains(item) for filter in self.filters) 53 54 55# Example Usage: 56sbf = ScalableBloomFilter(initial_size=10, fp_rate=0.1) 57sbf.add(\u0026#34;hello\u0026#34;) 58print(sbf.contains(\u0026#34;hello\u0026#34;)) # True 59print(sbf.contains(\u0026#34;world\u0026#34;)) # False Striped Bloom Filter Striped Bloom Filter l√† m·ªôt bi·∫øn th·ªÉ c·ªßa Bloom Filter ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ h·ªó tr·ª£ truy c·∫≠p ƒë·ªìng th·ªùi (concurrent access) hi·ªáu qu·∫£ trong m√¥i tr∆∞·ªùng ƒëa lu·ªìng (multi-threaded). M·ª•c ti√™u ch√≠nh c·ªßa Striped Bloom Filter l√† gi·∫£m thi·ªÉu vi·ªác kh√≥a to√†n b·ªô c·∫•u tr√∫c d·ªØ li·ªáu khi c√°c lu·ªìng th·ª±c hi·ªán th√™m ho·∫∑c ki·ªÉm tra ph·∫ßn t·ª≠, qua ƒë√≥ c·∫£i thi·ªán hi·ªáu nƒÉng.\nƒê·∫∑c ƒëi·ªÉm c·ªßa Striped Bloom Filter Ph√¢n chia th√†nh c√°c ph√¢n ƒëo·∫°n ƒë·ªôc l·∫≠p (Stripes):\nM·∫£ng bit c·ªßa Bloom Filter ƒë∆∞·ª£c chia th√†nh nhi·ªÅu ph√¢n ƒëo·∫°n (segments) ƒë·ªôc l·∫≠p. M·ªói ph√¢n ƒëo·∫°n ƒë∆∞·ª£c b·∫£o v·ªá b·ªüi m·ªôt kh√≥a ri√™ng bi·ªát (lock). C√°c thao t√°c tr√™n t·ª´ng ph√¢n ƒëo·∫°n c√≥ th·ªÉ th·ª±c hi·ªán ƒë·ªìng th·ªùi m√† kh√¥ng ·∫£nh h∆∞·ªüng l·∫´n nhau. TƒÉng hi·ªáu su·∫•t truy c·∫≠p ƒë·ªìng th·ªùi:\nB·∫±ng c√°ch ph√¢n chia m·∫£ng v√† s·ª≠ d·ª•ng nhi·ªÅu kh√≥a, c√°c lu·ªìng ch·ªâ c·∫ßn kh√≥a m·ªôt ph√¢n ƒëo·∫°n thay v√¨ to√†n b·ªô m·∫£ng. ƒêi·ªÅu n√†y gi·∫£m thi·ªÉu ƒë·ªô tr·ªÖ trong c√°c h·ªá th·ªëng ƒëa lu·ªìng. Ho·∫°t ƒë·ªông gi·ªëng Bloom Filter truy·ªÅn th·ªëng:\nStriped Bloom Filter v·∫´n ƒë·∫£m b·∫£o c√°c thu·ªôc t√≠nh c∆° b·∫£n c·ªßa Bloom Filter nh∆∞ t·ª∑ l·ªá false positive v√† s·ª≠ d·ª•ng c√°c h√†m bƒÉm ƒë·ªÉ x√°c ƒë·ªãnh c√°c ch·ªâ m·ª•c. C√°ch ho·∫°t ƒë·ªông c·ªßa Striped Bloom Filter 1. Ch√®n ph·∫ßn t·ª≠ ( T√≠nh c√°c ch·ªâ m·ª•c bƒÉm (hash indices) c·ªßa ph·∫ßn t·ª≠. X√°c ƒë·ªãnh c√°c ph√¢n ƒëo·∫°n t∆∞∆°ng ·ª©ng d·ª±a tr√™n ch·ªâ m·ª•c. Kh√≥a c√°c ph√¢n ƒëo·∫°n li√™n quan ƒë·ªÉ th√™m bit. 2. Ki·ªÉm tra ph·∫ßn t·ª≠ ( T√≠nh c√°c ch·ªâ m·ª•c bƒÉm c·ªßa ph·∫ßn t·ª≠. Truy c·∫≠p c√°c ph√¢n ƒëo·∫°n t∆∞∆°ng ·ª©ng m√† kh√¥ng c·∫ßn kh√≥a (n·∫øu ch·ªâ ki·ªÉm tra). N·∫øu t·∫•t c·∫£ c√°c bit t·∫°i c√°c ch·ªâ m·ª•c ƒë∆∞·ª£c ƒë·∫∑t l√† 1, ph·∫ßn t·ª≠ c√≥ th·ªÉ t·ªìn t·∫°i. 3. Ph√¢n ƒëo·∫°n (Segment): M·∫£ng bit ƒë∆∞·ª£c chia th√†nh ( S ) ph√¢n ƒëo·∫°n. M·ªôt h√†m bƒÉm b·ªï sung ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ √°nh x·∫° m·ªôt ph·∫ßn t·ª≠ ƒë·∫øn m·ªôt ho·∫∑c nhi·ªÅu ph√¢n ƒëo·∫°n c·ª• th·ªÉ. 4. TƒÉng hi·ªáu su·∫•t ƒë·ªìng th·ªùi: C√°c lu·ªìng ch·ªâ c·∫ßn kh√≥a ph√¢n ƒëo·∫°n c·∫ßn thao t√°c, thay v√¨ to√†n b·ªô c·∫•u tr√∫c d·ªØ li·ªáu. ∆Øu ƒëi·ªÉm c·ªßa Striped Bloom Filter H·ªó tr·ª£ ƒë·ªìng th·ªùi: Nhi·ªÅu lu·ªìng c√≥ th·ªÉ th√™m ho·∫∑c ki·ªÉm tra ph·∫ßn t·ª≠ ƒë·ªìng th·ªùi m√† kh√¥ng g√¢y xung ƒë·ªôt. Gi·∫£m ƒë·ªô tr·ªÖ: Ph√¢n ƒëo·∫°n ƒë·ªôc l·∫≠p gi√∫p gi·∫£m th·ªùi gian ch·ªù c·ªßa c√°c lu·ªìng khi kh√≥a. Hi·ªáu qu·∫£ b·ªô nh·ªõ: D√π chia th√†nh nhi·ªÅu ph√¢n ƒëo·∫°n, t·ªïng b·ªô nh·ªõ s·ª≠ d·ª•ng v·∫´n t∆∞∆°ng t·ª± Bloom Filter truy·ªÅn th·ªëng. H·∫°n ch·∫ø c·ªßa Striped Bloom Filter ƒê·ªô ph·ª©c t·∫°p qu·∫£n l√Ω kh√≥a: C·∫ßn qu·∫£n l√Ω nhi·ªÅu kh√≥a h∆°n, l√†m tƒÉng ƒë·ªô ph·ª©c t·∫°p trong tri·ªÉn khai. False positive v·∫´n t·ªìn t·∫°i: Nh∆∞ Bloom Filter truy·ªÅn th·ªëng, Striped Bloom Filter v·∫´n kh√¥ng lo·∫°i b·ªè ƒë∆∞·ª£c false positive. Kh√¥ng ph√π h·ª£p v·ªõi ·ª©ng d·ª•ng ƒë∆°n lu·ªìng: Trong m√¥i tr∆∞·ªùng ƒë∆°n lu·ªìng, c∆° ch·∫ø ph√¢n ƒëo·∫°n v√† kh√≥a tr·ªü n√™n d∆∞ th·ª´a. Tri·ªÉn khai b·∫±ng Python 1import threading 2import hashlib 3 4class StripedBloomFilter: 5 def __init__(self, num_bits, num_hashes, num_stripes): 6 self.num_bits = num_bits 7 self.num_hashes = num_hashes 8 self.num_stripes = num_stripes 9 self.segment_size = num_bits // num_stripes 10 self.bit_array = [0] * num_bits 11 self.locks = [threading.Lock() for _ in range(num_stripes)] 12 13 def _hashes(self, item): 14 hashes = [] 15 for i in range(self.num_hashes): 16 hash_value = int(hashlib.md5((str(item) + str(i)).encode()).hexdigest(), 16) 17 hashes.append(hash_value % self.num_bits) 18 return hashes 19 20 def add(self, item): 21 indices = self._hashes(item) 22 locked_segments = set() 23 24 # Lock relevant segments 25 for idx in indices: 26 segment = idx // self.segment_size 27 if segment not in locked_segments: 28 self.locks[segment].acquire() 29 locked_segments.add(segment) 30 31 try: 32 for idx in indices: 33 self.bit_array[idx] = 1 34 finally: 35 # Unlock segments 36 for segment in locked_segments: 37 self.locks[segment].release() 38 39 def contains(self, item): 40 indices = self._hashes(item) 41 for idx in indices: 42 if self.bit_array[idx] == 0: 43 return False 44 return True 45 46 47# Example Usage 48sbf = StripedBloomFilter(num_bits=1024, num_hashes=3, num_stripes=4) 49 50# Adding elements 51sbf.add(\u0026#34;hello\u0026#34;) 52sbf.add(\u0026#34;world\u0026#34;) 53 54# Checking elements 55print(sbf.contains(\u0026#34;hello\u0026#34;)) # True 56print(sbf.contains(\u0026#34;world\u0026#34;)) # True 57print(sbf.contains(\u0026#34;python\u0026#34;)) # False Quotient Filter (B·ªô l·ªçc th∆∞∆°ng s·ªë) Quotient Filter (QF) l√† m·ªôt c·∫•u tr√∫c d·ªØ li·ªáu x√°c su·∫•t t∆∞∆°ng t·ª± Bloom Filter, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ki·ªÉm tra th√†nh vi√™n (membership) trong t·∫≠p h·ª£p v·ªõi hi·ªáu qu·∫£ v·ªÅ m·∫∑t b·ªô nh·ªõ. QF ho·∫°t ƒë·ªông d·ª±a tr√™n k·ªπ thu·∫≠t bƒÉm (hashing) v√† chia th∆∞∆°ng s·ªë, cung c·∫•p m·ªôt gi·∫£i ph√°p nh·ªè g·ªçn cho c√°c b√†i to√°n ki·ªÉm tra th√†nh vi√™n.\nNguy√™n l√Ω ho·∫°t ƒë·ªông BƒÉm v√† chia th∆∞∆°ng s·ªë:\nT∆∞∆°ng t·ª± Bloom Filter, QF s·ª≠ d·ª•ng h√†m bƒÉm ƒë·ªÉ t·∫°o ra m·ªôt gi√° tr·ªã bƒÉm cho ph·∫ßn t·ª≠. Gi√° tr·ªã bƒÉm ƒë∆∞·ª£c chia th√†nh hai ph·∫ßn: Th∆∞∆°ng s·ªë (Quotient): X√°c ƒë·ªãnh ch·ªâ s·ªë c·ªßa bucket (√¥ nh·ªõ) trong m·ªôt m·∫£ng c·ªë ƒë·ªãnh. Ph·∫ßn d∆∞ (Remainder): L∆∞u l·∫°i nh∆∞ m·ªôt ch·ªØ k√Ω duy nh·∫•t trong m·∫£ng ƒë·ªÉ ki·ªÉm tra. Buckets v√† m·∫£ng:\nTh∆∞∆°ng s·ªë ƒë∆∞·ª£c d√πng ƒë·ªÉ x√°c ƒë·ªãnh v·ªã tr√≠ l∆∞u ph·∫ßn d∆∞ trong m·∫£ng. Tr∆∞·ªùng h·ª£p xung ƒë·ªôt (collisions) ƒë∆∞·ª£c x·ª≠ l√Ω b·∫±ng c√°ch ki·ªÉm tra tu·∫ßn t·ª± c√°c √¥ li·ªÅn k·ªÅ (linear probing). L∆∞u tr·ªØ nh·ªè g·ªçn:\nCh·ªâ ph·∫ßn d∆∞ ƒë∆∞·ª£c l∆∞u trong m·∫£ng, gi√∫p ti·∫øt ki·ªám b·ªô nh·ªõ ƒë√°ng k·ªÉ so v·ªõi b·∫£ng bƒÉm (hash table) truy·ªÅn th·ªëng. Metadata (d·ªØ li·ªáu ph·ª•) ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ theo d√µi tr·∫°ng th√°i c·ªßa c√°c bucket (ƒë·∫ßy hay r·ªóng, ph·∫ßn t·ª≠ b·ªã d·ªùi ch·ªó). H·ªó tr·ª£ th√™m/x√≥a/ki·ªÉm tra:\nQF h·ªó tr·ª£ ba thao t√°c c∆° b·∫£n: th√™m ph·∫ßn t·ª≠, x√≥a ph·∫ßn t·ª≠, v√† ki·ªÉm tra th√†nh vi√™n, v·ªõi hi·ªáu su·∫•t cao v√† ti√™u t·ªën √≠t b·ªô nh·ªõ. ∆Øu ƒëi·ªÉm c·ªßa Quotient Filter Ti·∫øt ki·ªám b·ªô nh·ªõ:\nQF nh·ªè g·ªçn h∆°n b·∫£ng bƒÉm v√† t∆∞∆°ng ƒë∆∞∆°ng Bloom Filter v·ªÅ m·ª©c ƒë·ªô s·ª≠ d·ª•ng b·ªô nh·ªõ. H·ªó tr·ª£ x√≥a ph·∫ßn t·ª≠:\nKh√¥ng nh∆∞ Bloom Filter c∆° b·∫£n, QF h·ªó tr·ª£ vi·ªác x√≥a ph·∫ßn t·ª≠ m√† kh√¥ng c·∫ßn bi·∫øn th·ªÉ b·ªï sung nh∆∞ Counting Bloom Filter. Ch·ªâ c·∫ßn m·ªôt h√†m bƒÉm:\nQF ch·ªâ c·∫ßn m·ªôt h√†m bƒÉm duy nh·∫•t, gi√∫p gi·∫£m chi ph√≠ t√≠nh to√°n so v·ªõi Bloom Filter (y√™u c·∫ßu nhi·ªÅu h√†m bƒÉm). Hi·ªáu su·∫•t cao:\nThao t√°c th√™m, x√≥a v√† ki·ªÉm tra nhanh ch√≥ng v·ªõi ƒë·ªô ph·ª©c t·∫°p th·∫•p. Kh·∫£ nƒÉng m·ªü r·ªông ƒë·ªông:\nQF c√≥ th·ªÉ m·ªü r·ªông dung l∆∞·ª£ng ho·∫∑c t√°i c·∫•u tr√∫c m·∫£ng khi c·∫ßn thi·∫øt m√† kh√¥ng ·∫£nh h∆∞·ªüng l·ªõn ƒë·∫øn hi·ªáu su·∫•t. H·∫°n ch·∫ø c·ªßa Quotient Filter False Positive (K·∫øt qu·∫£ d∆∞∆°ng t√≠nh gi·∫£):\nT∆∞∆°ng t·ª± Bloom Filter, QF c√≥ th·ªÉ b√°o r·∫±ng m·ªôt ph·∫ßn t·ª≠ thu·ªôc t·∫≠p h·ª£p d√π th·ª±c t·∫ø kh√¥ng ph·∫£i v·∫≠y. Tuy nhi√™n, kh√¥ng c√≥ false negative (k·∫øt qu·∫£ √¢m t√≠nh gi·∫£). Ph·ª©c t·∫°p h∆°n Bloom Filter:\nVi·ªác qu·∫£n l√Ω metadata (tr·∫°ng th√°i bucket, ph·∫ßn t·ª≠ b·ªã d·ªùi) khi·∫øn QF ph·ª©c t·∫°p h∆°n trong tri·ªÉn khai. C·ªë ƒë·ªãnh dung l∆∞·ª£ng:\nDung l∆∞·ª£ng c·ªßa QF c·∫ßn ƒë∆∞·ª£c thi·∫øt k·∫ø tr∆∞·ªõc. Khi v∆∞·ª£t qu√° gi·ªõi h·∫°n, vi·ªác m·ªü r·ªông dung l∆∞·ª£ng s·∫Ω y√™u c·∫ßu t√°i c·∫•u tr√∫c m·∫£ng, g√¢y t·ªën k√©m t√†i nguy√™n. Hi·ªáu su·∫•t gi·∫£m v·ªõi c√°c t·∫≠p d·ªØ li·ªáu ph√¢n t√°n:\nQF kh√¥ng ph√π h·ª£p v·ªõi c√°c ·ª©ng d·ª•ng y√™u c·∫ßu truy c·∫≠p ng·∫´u nhi√™n, do c·∫ßn ki·ªÉm tra tu·∫ßn t·ª± trong tr∆∞·ªùng h·ª£p xung ƒë·ªôt. ·ª®ng d·ª•ng c·ªßa Quotient Filter C∆° s·ªü d·ªØ li·ªáu: L·ªçc d·ªØ li·ªáu, ki·ªÉm tra th√†nh vi√™n trong ch·ªâ m·ª•c ho·∫∑c gi·∫£m truy c·∫≠p ƒëƒ©a kh√¥ng c·∫ßn thi·∫øt. H·ªá th·ªëng m·∫°ng: L·ªçc g√≥i tin ho·∫∑c ki·ªÉm tra th√†nh vi√™n c·ªßa ƒë·ªãa ch·ªâ IP trong b·∫£ng ƒë·ªãnh tuy·∫øn. H·ªá th·ªëng ph√¢n t√°n: ƒê·ªìng b·ªô d·ªØ li·ªáu gi·ªØa c√°c n√∫t ho·∫∑c ki·ªÉm tra t√≠nh nh·∫•t qu√°n. L∆∞u tr·ªØ: Lo·∫°i b·ªè tr√πng l·∫∑p d·ªØ li·ªáu (deduplication) trong c√°c h·ªá th·ªëng l∆∞u tr·ªØ. So s√°nh v·ªõi Bloom Filter T√≠nh nƒÉng Bloom Filter Quotient Filter False Positive C√≥ th·ªÉ x·∫£y ra C√≥ th·ªÉ x·∫£y ra False Negative Kh√¥ng Kh√¥ng H·ªó tr·ª£ x√≥a Kh√¥ng (c·∫ßn Counting BF) C√≥ B·ªô nh·ªõ Hi·ªáu qu·∫£ cao Hi·ªáu qu·∫£ (k√®m metadata) H√†m bƒÉm Nhi·ªÅu M·ªôt M·ªü r·ªông ƒë·ªông C·∫ßn Scalable Bloom Filter H·ªó tr·ª£ gi·ªõi h·∫°n V√≠ d·ª• m√£ gi·∫£ b·∫±ng Python 1class QuotientFilter: 2 def __init__(self, size): 3 self.size = size 4 self.table = [None] * size 5 self.metadata = [False] * size # Tr·∫°ng th√°i bucket 6 7 def _hash(self, value): 8 h = hash(value) 9 quotient = h // self.size 10 remainder = h % self.size 11 return quotient, remainder 12 13 def insert(self, value): 14 quotient, remainder = self._hash(value) 15 while self.metadata[quotient]: # X·ª≠ l√Ω xung ƒë·ªôt 16 quotient = (quotient + 1) % self.size 17 self.table[quotient] = remainder 18 self.metadata[quotient] = True 19 20 def query(self, value): 21 quotient, remainder = self._hash(value) 22 while self.metadata[quotient]: 23 if self.table[quotient] == remainder: 24 return True 25 quotient = (quotient + 1) % self.size 26 return False 27 28 def delete(self, value): 29 quotient, remainder = self._hash(value) 30 while self.metadata[quotient]: 31 if self.table[quotient] == remainder: 32 self.table[quotient] = None 33 self.metadata[quotient] = False 34 return True 35 quotient = (quotient + 1) % self.size 36 return False K·∫øt lu·∫≠n Quotient Filter l√† m·ªôt gi·∫£i ph√°p m·∫°nh m·∫Ω, k·∫øt h·ª£p hi·ªáu qu·∫£ c·ªßa Bloom Filter v√† b·∫£ng bƒÉm, ph√π h·ª£p cho c√°c ·ª©ng d·ª•ng c·∫ßn ki·ªÉm tra th√†nh vi√™n, h·ªó tr·ª£ x√≥a, v√† ti·∫øt ki·ªám b·ªô nh·ªõ. Tuy nhi√™n, c·∫ßn xem x√©t c√°c h·∫°n ch·∫ø v·ªÅ thi·∫øt k·∫ø v√† ·ª©ng d·ª•ng ƒë·ªÉ s·ª≠ d·ª•ng t·ªëi ∆∞u trong c√°c b√†i to√°n c·ª• th·ªÉ.\nCuckoo Filter Cuckoo Filter l√† m·ªôt c·∫•u tr√∫c d·ªØ li·ªáu x√°c su·∫•t ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ki·ªÉm tra th√†nh vi√™n trong t·∫≠p h·ª£p (membership test) gi·ªëng nh∆∞ Bloom Filter, nh∆∞ng v·ªõi nhi·ªÅu c·∫£i ti·∫øn. N√≥ s·ª≠ d·ª•ng √Ω t∆∞·ªüng t·ª´ Cuckoo Hashing v√† cung c·∫•p m·ªôt s·ªë t√≠nh nƒÉng n·ªïi b·∫≠t nh∆∞ h·ªó tr·ª£ x√≥a ph·∫ßn t·ª≠ v√† hi·ªáu qu·∫£ v·ªÅ b·ªô nh·ªõ.\nNguy√™n l√Ω ho·∫°t ƒë·ªông Cuckoo Filter ho·∫°t ƒë·ªông d·ª±a tr√™n hai kh√°i ni·ªám ch√≠nh:\nFingerprinting (Ch·ªØ k√Ω):\nM·ªói ph·∫ßn t·ª≠ ƒë∆∞·ª£c bƒÉm ƒë·ªÉ t·∫°o ra m·ªôt gi√° tr·ªã fingerprint ng·∫Øn, ƒë·∫°i di·ªán cho ph·∫ßn t·ª≠ ƒë√≥. Ch·ªâ l∆∞u tr·ªØ gi√° tr·ªã fingerprint trong m·∫£ng, gi√∫p ti·∫øt ki·ªám b·ªô nh·ªõ. Cuckoo Hashing:\nM·ªói ph·∫ßn t·ª≠ c√≥ th·ªÉ ƒë∆∞·ª£c l∆∞u ·ªü m·ªôt trong hai v·ªã tr√≠ ti·ªÅm nƒÉng trong m·∫£ng (table). Khi th√™m ph·∫ßn t·ª≠ m·ªõi m√† v·ªã tr√≠ ƒë√£ b·ªã chi·∫øm, m·ªôt ph·∫ßn t·ª≠ kh√°c c√≥ th·ªÉ b·ªã \u0026ldquo;ƒë·∫©y\u0026rdquo; ƒë·∫øn v·ªã tr√≠ th·ª© hai c·ªßa n√≥, theo c√°ch t∆∞∆°ng t·ª± thu·∫≠t to√°n Cuckoo Hashing. Thao t√°c ch√≠nh trong Cuckoo Filter Th√™m ph·∫ßn t·ª≠ (Insert):\nT√≠nh hai v·ªã tr√≠ bƒÉm (bucket) cho ph·∫ßn t·ª≠ d·ª±a tr√™n gi√° tr·ªã fingerprint. N·∫øu m·ªôt trong hai v·ªã tr√≠ c√≤n tr·ªëng, l∆∞u fingerprint t·∫°i ƒë√≥. N·∫øu c·∫£ hai v·ªã tr√≠ ƒë·ªÅu ƒë·∫ßy, ch·ªçn ng·∫´u nhi√™n m·ªôt fingerprint trong bucket v√† \u0026ldquo;ƒë·∫©y\u0026rdquo; n√≥ ƒë·∫øn v·ªã tr√≠ th·ª© hai c·ªßa n√≥. Ti·∫øp t·ª•c l·∫∑p l·∫°i cho ƒë·∫øn khi ch√®n th√†nh c√¥ng ho·∫∑c v∆∞·ª£t qu√° s·ªë l·∫ßn th·ª≠ (rehash n·∫øu c·∫ßn). Ki·ªÉm tra ph·∫ßn t·ª≠ (Query):\nT√≠nh hai v·ªã tr√≠ bƒÉm d·ª±a tr√™n gi√° tr·ªã fingerprint. Ki·ªÉm tra xem gi√° tr·ªã fingerprint c√≥ t·ªìn t·∫°i t·∫°i m·ªôt trong hai bucket kh√¥ng. X√≥a ph·∫ßn t·ª≠ (Delete):\nT√≠nh hai v·ªã tr√≠ bƒÉm d·ª±a tr√™n gi√° tr·ªã fingerprint. N·∫øu gi√° tr·ªã fingerprint t·ªìn t·∫°i t·∫°i m·ªôt trong hai v·ªã tr√≠, x√≥a n√≥. ∆Øu ƒëi·ªÉm c·ªßa Cuckoo Filter H·ªó tr·ª£ x√≥a ph·∫ßn t·ª≠:\nKh√¥ng gi·ªëng Bloom Filter c∆° b·∫£n, Cuckoo Filter h·ªó tr·ª£ x√≥a ph·∫ßn t·ª≠ d·ªÖ d√†ng m√† kh√¥ng c·∫ßn c√°c bi·∫øn th·ªÉ ph·ª©c t·∫°p. T·ª∑ l·ªá false positive th·∫•p:\nCuckoo Filter cung c·∫•p t·ª∑ l·ªá d∆∞∆°ng t√≠nh gi·∫£ (false positive) th·∫•p, ƒë·∫∑c bi·ªát khi t·ªëi ∆∞u k√≠ch th∆∞·ªõc bucket v√† fingerprint. Ti·∫øt ki·ªám b·ªô nh·ªõ:\nNh·ªù ch·ªâ l∆∞u tr·ªØ gi√° tr·ªã fingerprint ng·∫Øn, Cuckoo Filter th∆∞·ªùng ti·∫øt ki·ªám b·ªô nh·ªõ h∆°n Bloom Filter trong nhi·ªÅu tr∆∞·ªùng h·ª£p. Hi·ªáu su·∫•t cao:\nThao t√°c th√™m, x√≥a v√† ki·ªÉm tra nhanh ch√≥ng, th∆∞·ªùng c√≥ ƒë·ªô ph·ª©c t·∫°p ( O(1) ) trung b√¨nh. H·ªó tr·ª£ ki·ªÉm tra √¢m t√≠nh ch√≠nh x√°c:\nKh√¥ng bao gi·ªù x·∫£y ra false negative (k·∫øt qu·∫£ √¢m t√≠nh sai). Kh·∫£ nƒÉng m·ªü r·ªông:\nCuckoo Filter c√≥ th·ªÉ m·ªü r·ªông th√¥ng qua c∆° ch·∫ø rehash ho·∫∑c tƒÉng k√≠ch th∆∞·ªõc m·∫£ng khi c·∫ßn thi·∫øt. H·∫°n ch·∫ø c·ªßa Cuckoo Filter Kh√≥ khƒÉn v·ªõi ch√®n ph·∫ßn t·ª≠ d√†y ƒë·∫∑c:\nKhi m·∫£ng qu√° ƒë·∫ßy, vi·ªác th√™m ph·∫ßn t·ª≠ m·ªõi c√≥ th·ªÉ d·∫´n ƒë·∫øn hi·ªán t∆∞·ª£ng \u0026ldquo;cuckoo evictions\u0026rdquo; (ƒë·∫©y v√≤ng l·∫∑p kh√¥ng th√†nh c√¥ng), bu·ªôc ph·∫£i t√°i c·∫•u tr√∫c (rehash) to√†n b·ªô m·∫£ng. C·∫•u tr√∫c ph·ª©c t·∫°p h∆°n Bloom Filter:\nSo v·ªõi Bloom Filter, Cuckoo Filter y√™u c·∫ßu qu·∫£n l√Ω nhi·ªÅu bucket, c∆° ch·∫ø ƒë·∫©y ph·∫ßn t·ª≠, v√† x·ª≠ l√Ω xung ƒë·ªôt ph·ª©c t·∫°p h∆°n. Kh√¥ng t·ªëi ∆∞u v·ªõi s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ l·ªõn:\nV·ªõi t·∫≠p d·ªØ li·ªáu qu√° l·ªõn, Bloom Filter c√≥ th·ªÉ hi·ªáu qu·∫£ h∆°n v·ªÅ m·∫∑t b·ªô nh·ªõ so v·ªõi Cuckoo Filter. ·ª®ng d·ª•ng c·ªßa Cuckoo Filter H·ªá th·ªëng c∆° s·ªü d·ªØ li·ªáu: Ki·ªÉm tra d·ªØ li·ªáu t·ªìn t·∫°i trong c√°c ch·ªâ m·ª•c ho·∫∑c gi·∫£m truy c·∫≠p ƒëƒ©a. H·ªá th·ªëng m·∫°ng: L·ªçc g√≥i tin ho·∫∑c ki·ªÉm tra ƒë·ªãa ch·ªâ IP trong b·∫£ng ƒë·ªãnh tuy·∫øn. H·ªá th·ªëng ph√¢n t√°n: ƒê·ªìng b·ªô d·ªØ li·ªáu, ki·ªÉm tra t√≠nh nh·∫•t qu√°n. B·ªô nh·ªõ ƒë·ªám (Cache): L·ªçc nhanh c√°c truy v·∫•n trong b·ªô nh·ªõ ƒë·ªám. So s√°nh v·ªõi Bloom Filter T√≠nh nƒÉng Bloom Filter Cuckoo Filter False Positive C√≥ th·ªÉ x·∫£y ra C√≥ th·ªÉ x·∫£y ra False Negative Kh√¥ng Kh√¥ng H·ªó tr·ª£ x√≥a Kh√¥ng (c·∫ßn Counting BF) C√≥ B·ªô nh·ªõ Ti·∫øt ki·ªám cao Ti·∫øt ki·ªám t·ªët (nh∆∞ng ph·ª©c t·∫°p h∆°n) Thao t√°c th√™m ƒê∆°n gi·∫£n, kh√¥ng ƒë·∫©y ph·∫ßn t·ª≠ Ph·ª©c t·∫°p h∆°n do ƒë·∫©y ph·∫ßn t·ª≠ Kh·∫£ nƒÉng m·ªü r·ªông C·∫ßn Scalable Bloom Filter C√≥ h·ªó tr·ª£ m·ªü r·ªông tr·ª±c ti·∫øp V√≠ d·ª• m√£ gi·∫£ Cuckoo Filter b·∫±ng Python 1import random 2 3class CuckooFilter: 4 def __init__(self, size, bucket_size=2, fingerprint_size=4): 5 self.size = size 6 self.bucket_size = bucket_size 7 self.fingerprint_size = fingerprint_size 8 self.buckets = [[] for _ in range(size)] 9 10 def _hash(self, value): 11 return hash(value) % self.size 12 13 def _fingerprint(self, value): 14 return hash(value) % (2 ** self.fingerprint_size) 15 16 def insert(self, value): 17 fingerprint = self._fingerprint(value) 18 i1 = self._hash(value) 19 i2 = (i1 ^ hash(fingerprint)) % self.size 20 21 if len(self.buckets[i1]) \u0026lt; self.bucket_size: 22 self.buckets[i1].append(fingerprint) 23 return True 24 elif len(self.buckets[i2]) \u0026lt; self.bucket_size: 25 self.buckets[i2].append(fingerprint) 26 return True 27 28 # Eviction 29 i = random.choice([i1, i2]) 30 for _ in range(self.size): 31 evicted_fingerprint = self.buckets[i].pop(0) 32 self.buckets[i].append(fingerprint) 33 fingerprint = evicted_fingerprint 34 i = (i ^ hash(fingerprint)) % self.size 35 if len(self.buckets[i]) \u0026lt; self.bucket_size: 36 self.buckets[i].append(fingerprint) 37 return True 38 39 return False # Failed to insert after many attempts 40 41 def query(self, value): 42 fingerprint = self._fingerprint(value) 43 i1 = self._hash(value) 44 i2 = (i1 ^ hash(fingerprint)) % self.size 45 46 return fingerprint in self.buckets[i1] or fingerprint in self.buckets[i2] 47 48 def delete(self, value): 49 fingerprint = self._fingerprint(value) 50 i1 = self._hash(value) 51 i2 = (i1 ^ hash(fingerprint)) % self.size 52 53 if fingerprint in self.buckets[i1]: 54 self.buckets[i1].remove(fingerprint) 55 return True 56 elif fingerprint in self.buckets[i2]: 57 self.buckets[i2].remove(fingerprint) 58 return True 59 return False K·∫øt lu·∫≠n Cuckoo Filter l√† m·ªôt c·∫•u tr√∫c d·ªØ li·ªáu m·∫°nh m·∫Ω, hi·ªáu qu·∫£ v√† ph√π h·ª£p cho c√°c ·ª©ng d·ª•ng c·∫ßn th√™m, x√≥a, v√† ki·ªÉm tra th√†nh vi√™n nhanh ch√≥ng. M·∫∑c d√π ph·ª©c t·∫°p h∆°n Bloom Filter, n√≥ mang l·∫°i nhi·ªÅu t√≠nh nƒÉng h·ªØu √≠ch nh∆∞ h·ªó tr·ª£ x√≥a v√† hi·ªáu qu·∫£ b·ªô nh·ªõ cao h∆°n trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p.\n·ª®ng D·ª•ng c·ªßa Bloom Filter trong C√°c Lƒ©nh V·ª±c 1. Ph√°t Hi·ªán Gian L·∫≠n T√†i Ch√≠nh (Financial Fraud Detection) M·ª•c ƒë√≠ch: X√°c ƒë·ªãnh h√†nh vi ƒë√°ng ng·ªù trong th√≥i quen mua s·∫Øm c·ªßa ng∆∞·ªùi d√πng.\nC√°ch s·ª≠ d·ª•ng:\nS·ª≠ d·ª•ng m·ªôt Bloom Filter ri√™ng cho m·ªói ng∆∞·ªùi d√πng. Ki·ªÉm tra m·ªçi giao d·ªãch ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi: Ng∆∞·ªùi d√πng n√†y ƒë√£ thanh to√°n t·ª´ ƒë·ªãa ƒëi·ªÉm n√†y tr∆∞·ªõc ƒë√¢y ch∆∞a? Bloom Filter cung c·∫•p ph·∫£n h·ªìi c·ª±c k·ª≥ nhanh (ƒë·ªô tr·ªÖ th·∫•p). Nh√¢n b·∫£n d·ªØ li·ªáu qua c√°c khu v·ª±c ƒë·ªÉ x·ª≠ l√Ω khi ng∆∞·ªùi d√πng di chuy·ªÉn. L·ª£i √≠ch khi s·ª≠ d·ª•ng Bloom Filter:\nGiao d·ªãch ho√†n t·∫•t nhanh ch√≥ng. Gi·∫£m nguy c∆° giao d·ªãch b·ªã gi√°n ƒëo·∫°n trong tr∆∞·ªùng h·ª£p m·∫°ng b·ªã ph√¢n v√πng (k·∫øt n·ªëi ƒë∆∞·ª£c gi·ªØ trong th·ªùi gian ng·∫Øn h∆°n). TƒÉng c∆∞·ªùng l·ªõp b·∫£o m·∫≠t cho c·∫£ ch·ªß th·∫ª t√≠n d·ª•ng v√† nh√† b√°n l·∫ª. C√°c c√¢u h·ªèi kh√°c m√† Bloom Filter c√≥ th·ªÉ h·ªó tr·ª£ trong ng√†nh t√†i ch√≠nh:\nNg∆∞·ªùi d√πng ƒë√£ t·ª´ng mua s·∫£n ph·∫©m/d·ªãch v·ª• trong danh m·ª•c n√†y ch∆∞a? C√≥ c·∫ßn b·ªè qua m·ªôt s·ªë b∆∞·ªõc b·∫£o m·∫≠t khi mua s·∫Øm v·ªõi c√°c c·ª≠a h√†ng tr·ª±c tuy·∫øn ƒë√°ng tin c·∫≠y (nh∆∞ Amazon, Apple App Store)? Th·∫ª t√≠n d·ª•ng n√†y c√≥ b·ªã b√°o m·∫•t ho·∫∑c ƒë√°nh c·∫Øp kh√¥ng? L·ª£i √≠ch b·ªï sung: C√°c t·ªï ch·ª©c t√†i ch√≠nh c√≥ th·ªÉ trao ƒë·ªïi danh s√°ch s·ªë th·∫ª b·ªã m·∫•t/m·∫•t c·∫Øp m√† kh√¥ng ti·∫øt l·ªô s·ªë th·ª±c. 2. ƒê·∫∑t Qu·∫£ng C√°o (Ad Placement - Retail, Advertising) M·ª•c ƒë√≠ch: Hi·ªÉn th·ªã qu·∫£ng c√°o ho·∫∑c ƒë·ªÅ xu·∫•t s·∫£n ph·∫©m m·ªôt c√°ch c√° nh√¢n h√≥a.\nC√°ch s·ª≠ d·ª•ng:\nS·ª≠ d·ª•ng m·ªôt Bloom Filter cho m·ªói ng∆∞·ªùi d√πng, l∆∞u tr·ªØ danh s√°ch s·∫£n ph·∫©m ƒë√£ mua. Khi h·ªá th·ªëng ƒë·ªÅ xu·∫•t s·∫£n ph·∫©m m·ªõi: N·∫øu s·∫£n ph·∫©m ch∆∞a c√≥ trong Bloom Filter, qu·∫£ng c√°o ƒë∆∞·ª£c hi·ªÉn th·ªã v√† s·∫£n ph·∫©m ƒë∆∞·ª£c th√™m v√†o Bloom Filter. N·∫øu s·∫£n ph·∫©m ƒë√£ c√≥ trong Bloom Filter, h·ªá th·ªëng ti·∫øp t·ª•c ki·ªÉm tra s·∫£n ph·∫©m kh√°c cho ƒë·∫øn khi t√¨m ƒë∆∞·ª£c s·∫£n ph·∫©m ch∆∞a c√≥. L·ª£i √≠ch khi s·ª≠ d·ª•ng Bloom Filter:\nGi·∫£i ph√°p chi ph√≠ th·∫•p ƒë·ªÉ t·∫°o tr·∫£i nghi·ªám c√° nh√¢n h√≥a g·∫ßn nh∆∞ theo th·ªùi gian th·ª±c. Kh√¥ng c·∫ßn ƒë·∫ßu t∆∞ v√†o c∆° s·ªü h·∫° t·∫ßng ƒë·∫Øt ƒë·ªè. 3. Ki·ªÉm Tra T√™n Ng∆∞·ªùi D√πng (SaaS, Content Publishing Platforms) M·ª•c ƒë√≠ch: X√°c ƒë·ªãnh t√™n ng∆∞·ªùi d√πng/email/domain name/slug ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng ch∆∞a.\nC√°ch s·ª≠ d·ª•ng:\nS·ª≠ d·ª•ng m·ªôt Bloom Filter l∆∞u t·∫•t c·∫£ c√°c t√™n ng∆∞·ªùi d√πng ƒë√£ ƒëƒÉng k√Ω. Khi ng∆∞·ªùi d√πng nh·∫≠p t√™n mong mu·ªën: N·∫øu kh√¥ng c√≥ trong Bloom Filter, t√†i kho·∫£n ƒë∆∞·ª£c t·∫°o v√† t√™n ƒë∆∞·ª£c th√™m v√†o Bloom Filter. N·∫øu c√≥, ·ª©ng d·ª•ng quy·∫øt ƒë·ªãnh ki·ªÉm tra c∆° s·ªü d·ªØ li·ªáu ch√≠nh ho·∫∑c t·ª´ ch·ªëi t√™n ƒë√≥. L·ª£i √≠ch khi s·ª≠ d·ª•ng Bloom Filter:\nPh∆∞∆°ng ph√°p r·∫•t nhanh v√† hi·ªáu qu·∫£ ƒë·ªÉ th·ª±c hi·ªán thao t√°c ph·ªï bi·∫øn. Kh√¥ng c·∫ßn ƒë·∫ßu t∆∞ v√†o c∆° s·ªü h·∫° t·∫ßng ph·ª©c t·∫°p. 4. C√°c ·ª®ng D·ª•ng Kh√°c C·ªßa Bloom Filter Ki·ªÉm Tra Ch√≠nh T·∫£ (Spell Checker):\nTrong th·ªùi k·ª≥ ƒë·∫ßu, b·ªô ki·ªÉm tra ch√≠nh t·∫£ ƒë∆∞·ª£c tri·ªÉn khai b·∫±ng Bloom Filter. C∆° S·ªü D·ªØ Li·ªáu (Databases):\nNhi·ªÅu c∆° s·ªü d·ªØ li·ªáu ph·ªï bi·∫øn s·ª≠ d·ª•ng Bloom Filter ƒë·ªÉ gi·∫£m s·ªë l·∫ßn truy c·∫≠p ƒëƒ©a t·ªën k√©m cho c√°c h√†ng/c·ªôt kh√¥ng t·ªìn t·∫°i. C√°c h·ªá th·ªëng nh∆∞ PostgreSQL, Apache Cassandra, Cloud Bigtable s·ª≠ d·ª•ng k·ªπ thu·∫≠t n√†y. C√¥ng C·ª• T√¨m Ki·∫øm (Search Engines):\nBitFunnel, m·ªôt thu·∫≠t to√°n l·∫≠p ch·ªâ m·ª•c cho c√¥ng c·ª• t√¨m ki·∫øm, s·ª≠ d·ª•ng Bloom Filter ƒë·ªÉ l∆∞u tr·ªØ ch·ªâ m·ª•c t√¨m ki·∫øm. An Ninh (Security):\nD√πng Bloom Filter ƒë·ªÉ ph√°t hi·ªán m·∫≠t kh·∫©u y·∫øu, URL ƒë·ªôc h·∫°i, v√† c√°c nguy c∆° an ninh kh√°c. B√†i t·∫≠p Financial Fraud Detection x√¢y d·ª±ng ·ª©ng d·ª•ng Financial Fraud Detection s·ª≠ d·ª•ng Bloom Filter. M·ª•c ti√™u l√† ki·ªÉm tra xem ng∆∞·ªùi d√πng ƒë√£ th·ª±c hi·ªán giao d·ªãch t·ª´ m·ªôt ƒë·ªãa ƒëi·ªÉm c·ª• th·ªÉ hay ch∆∞a ƒë·ªÉ ph√°t hi·ªán h√†nh vi gian l·∫≠n. N·∫øu ng∆∞·ªùi d√πng ch∆∞a th·ª±c hi·ªán giao d·ªãch ·ªü 1 ban n√†o ƒë√≥ trong l·ªãch s·ª≠ th√¨ c·∫£nh b√°o l√™n\n1 2import hashlib 3 4class BloomFilter: 5 def __init__(self, size, num_hash_functions): 6 # K√≠ch th∆∞·ªõc Bloom filter (s·ªë l∆∞·ª£ng bit) 7 self.size = size 8 # S·ªë h√†m bƒÉm 9 self.num_hash_functions = num_hash_functions 10 # M·∫£ng bit ƒë·ªÉ l∆∞u tr·ªØ (kh·ªüi t·∫°o v·ªõi c√°c bit = 0) 11 self.bit_array = [0] * size 12 13 def _hash(self, item, i): 14 \u0026#34;\u0026#34;\u0026#34;H√†m bƒÉm ƒë·ªÉ t·∫°o ch·ªâ s·ªë t·ª´ item, v·ªõi i l√† ch·ªâ s·ªë c·ªßa h√†m bƒÉm.\u0026#34;\u0026#34;\u0026#34; 15 return int(hashlib.sha256(f\u0026#34;{item}{i}\u0026#34;.encode(\u0026#39;utf-8\u0026#39;)).hexdigest(), 16) % self.size 16 17 def add(self, item): 18 \u0026#34;\u0026#34;\u0026#34;Th√™m m·ªôt item v√†o Bloom filter.\u0026#34;\u0026#34;\u0026#34; 19 for i in range(self.num_hash_functions): 20 index = self._hash(item, i) 21 self.bit_array[index] = 1 22 23 def check(self, item): 24 \u0026#34;\u0026#34;\u0026#34;Ki·ªÉm tra m·ªôt item c√≥ trong Bloom filter kh√¥ng.\u0026#34;\u0026#34;\u0026#34; 25 for i in range(self.num_hash_functions): 26 index = self._hash(item, i) 27 if self.bit_array[index] == 0: 28 return False # N·∫øu b·∫•t k·ª≥ bit n√†o l√† 0, ph·∫ßn t·ª≠ ch·∫Øc ch·∫Øn kh√¥ng c√≥ trong b·ªô l·ªçc 29 return True # N·∫øu t·∫•t c·∫£ c√°c bit ƒë·ªÅu l√† 1, c√≥ kh·∫£ nƒÉng ph·∫ßn t·ª≠ c√≥ trong b·ªô l·ªçc 30 31# Kh·ªüi t·∫°o Bloom filter v·ªõi k√≠ch th∆∞·ªõc 1000 bit v√† 3 h√†m bƒÉm 32bloom_filter = BloomFilter(size=1000, num_hash_functions=3) 33 34# M√¥ ph·ªèng th√¥ng tin giao d·ªãch c·ªßa ng∆∞·ªùi d√πng 35users_transactions = { 36 \u0026#34;tung\u0026#34;: [\u0026#34;New York\u0026#34;, \u0026#34;Los Angeles\u0026#34;, \u0026#34;Miami\u0026#34;], 37 \u0026#34;kim\u0026#34;: [\u0026#34;London\u0026#34;, \u0026#34;Paris\u0026#34;, \u0026#34;Berlin\u0026#34;], 38 \u0026#34;tuan\u0026#34;: [\u0026#34;Tokyo\u0026#34;, \u0026#34;Osaka\u0026#34;, \u0026#34;Kyoto\u0026#34;] 39} 40 41# Th√™m t·∫•t c·∫£ c√°c giao d·ªãch v√†o Bloom filter 42for user, locations in users_transactions.items(): 43 for location in locations: 44 bloom_filter.add(f\u0026#34;{user}-{location}\u0026#34;) # K·∫øt h·ª£p t√™n ng∆∞·ªùi d√πng v√† ƒë·ªãa ƒëi·ªÉm giao d·ªãch 45 46# Ki·ªÉm tra m·ªôt giao d·ªãch m·ªõi t·ª´ ng∆∞·ªùi d√πng 47def check_fraud(user, location): 48 if not bloom_filter.check(f\u0026#34;{user}-{location}\u0026#34;): 49 return f\u0026#34;Warning: Transaction from {location} by {user} might be suspicious!\u0026#34; 50 else: 51 return f\u0026#34;Transaction from {location} by {user} is normal.\u0026#34; 52 53# Ki·ªÉm tra m·ªôt s·ªë giao d·ªãch 54test_transactions = [ 55 (\u0026#34;tung\u0026#34;, \u0026#34;Miami\u0026#34;), # Giao d·ªãch h·ª£p l·ªá 56 (\u0026#34;tung\u0026#34;, \u0026#34;Chicago\u0026#34;), # Giao d·ªãch m·ªõi (kh√¥ng c√≥ trong Bloom filter) 57 (\u0026#34;kim\u0026#34;, \u0026#34;Paris\u0026#34;), # Giao d·ªãch h·ª£p l·ªá 58 (\u0026#34;tuan\u0026#34;, \u0026#34;Kyoto\u0026#34;) # Giao d·ªãch h·ª£p l·ªá 59] 60 61# Ki·ªÉm tra c√°c giao d·ªãch 62for user, location in test_transactions: 63 result = check_fraud(user, location) 64 print(result) K·∫øt qu·∫£:\n1Transaction from Miami by tung is normal. 2Warning: Transaction from Chicago by tung might be suspicious! 3Transaction from Paris by kim is normal. 4Transaction from Kyoto by tuan is normal. Spell Checker x√¢y d·ª±ng m·ªôt Spell Checker s·ª≠ d·ª•ng Bloom Filter. M√£ n√†y s·∫Ω ki·ªÉm tra xem m·ªôt t·ª´ c√≥ trong t·ª´ ƒëi·ªÉn (dictionary) hay kh√¥ng v√† ƒë∆∞a ra k·∫øt qu·∫£.\n1 2import hashlib 3 4class BloomFilter: 5 def __init__(self, size, num_hash_functions): 6 # K√≠ch th∆∞·ªõc c·ªßa Bloom filter (s·ªë l∆∞·ª£ng bit) 7 self.size = size 8 # S·ªë h√†m bƒÉm 9 self.num_hash_functions = num_hash_functions 10 # M·∫£ng bit ƒë·ªÉ l∆∞u tr·ªØ (ƒë∆∞·ª£c kh·ªüi t·∫°o v·ªõi t·∫•t c·∫£ c√°c bit l√† 0) 11 self.bit_array = [0] * size 12 13 def _hash(self, item, i): 14 \u0026#34;\u0026#34;\u0026#34;H√†m bƒÉm ƒë·ªÉ t·∫°o ch·ªâ s·ªë t·ª´ item, v·ªõi i l√† ch·ªâ s·ªë c·ªßa h√†m bƒÉm.\u0026#34;\u0026#34;\u0026#34; 15 # D√πng h√†m bƒÉm SHA-256 v√† ƒëi·ªÅu ch·ªânh v·ªõi ch·ªâ s·ªë i ƒë·ªÉ t·∫°o ra c√°c ch·ªâ s·ªë kh√°c nhau 16 return int(hashlib.sha256(f\u0026#34;{item}{i}\u0026#34;.encode(\u0026#39;utf-8\u0026#39;)).hexdigest(), 16) % self.size 17 18 def add(self, item): 19 \u0026#34;\u0026#34;\u0026#34;Th√™m m·ªôt item v√†o Bloom filter.\u0026#34;\u0026#34;\u0026#34; 20 for i in range(self.num_hash_functions): 21 index = self._hash(item, i) 22 self.bit_array[index] = 1 23 24 def check(self, item): 25 \u0026#34;\u0026#34;\u0026#34;Ki·ªÉm tra m·ªôt item c√≥ trong Bloom filter kh√¥ng.\u0026#34;\u0026#34;\u0026#34; 26 for i in range(self.num_hash_functions): 27 index = self._hash(item, i) 28 if self.bit_array[index] == 0: 29 return False # N·∫øu b·∫•t k·ª≥ bit n√†o l√† 0, ph·∫ßn t·ª≠ ch·∫Øc ch·∫Øn kh√¥ng c√≥ trong b·ªô l·ªçc 30 return True # N·∫øu t·∫•t c·∫£ c√°c bit ƒë·ªÅu l√† 1, c√≥ kh·∫£ nƒÉng ph·∫ßn t·ª≠ c√≥ trong b·ªô l·ªçc 31 32# T·∫°o m·ªôt Bloom filter v·ªõi k√≠ch th∆∞·ªõc 1000 bit v√† 3 h√†m bƒÉm 33bloom_filter = BloomFilter(size=1000, num_hash_functions=3) 34 35# T·ª´ ƒëi·ªÉn m·∫´u 36dictionary = [\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;spell\u0026#34;, \u0026#34;check\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;bloom\u0026#34;, \u0026#34;filter\u0026#34;] 37 38# Th√™m t·∫•t c·∫£ c√°c t·ª´ v√†o Bloom filter 39for word in dictionary: 40 bloom_filter.add(word) 41 42# Ki·ªÉm tra ch√≠nh t·∫£ c·ªßa m·ªôt s·ªë t·ª´ 43test_words = [\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;java\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;flutter\u0026#34;] 44 45for word in test_words: 46 if bloom_filter.check(word): 47 print(f\u0026#34;\u0026#39;{word}\u0026#39; c√≥ th·ªÉ l√† m·ªôt t·ª´ ƒë√∫ng.\u0026#34;) 48 else: 49 print(f\u0026#34;\u0026#39;{word}\u0026#39; ch·∫Øc ch·∫Øn l√† m·ªôt t·ª´ sai.\u0026#34;) K·∫øt qu·∫£:\n1 2\u0026#39;hello\u0026#39; c√≥ th·ªÉ l√† m·ªôt t·ª´ ƒë√∫ng. 3\u0026#39;world\u0026#39; c√≥ th·ªÉ l√† m·ªôt t·ª´ ƒë√∫ng. 4\u0026#39;java\u0026#39; ch·∫Øc ch·∫Øn l√† m·ªôt t·ª´ sai. 5\u0026#39;python\u0026#39; c√≥ th·ªÉ l√† m·ªôt t·ª´ ƒë√∫ng. Recommendation Systems Bloom Filters tri·ªÉn khai vi·ªác tr√°nh g·ª£i √Ω c√°c s·∫£n ph·∫©m m√† ng∆∞·ªùi d√πng ƒë√£ t∆∞∆°ng t√°c tr∆∞·ªõc ƒë√≥ b·∫±ng c√°ch s·ª≠ d·ª•ng Bloom Filters.\n1 2 3import hashlib 4 5class BloomFilter: 6 def __init__(self, size, num_hash_functions): 7 # K√≠ch th∆∞·ªõc Bloom filter (s·ªë l∆∞·ª£ng bit) 8 self.size = size 9 # S·ªë h√†m bƒÉm 10 self.num_hash_functions = num_hash_functions 11 # M·∫£ng bit ƒë·ªÉ l∆∞u tr·ªØ (kh·ªüi t·∫°o t·∫•t c·∫£ c√°c bit l√† 0) 12 self.bit_array = [0] * size 13 14 def _hash(self, item, i): 15 \u0026#34;\u0026#34;\u0026#34;H√†m bƒÉm ƒë·ªÉ t·∫°o ch·ªâ s·ªë t·ª´ item, v·ªõi i l√† ch·ªâ s·ªë c·ªßa h√†m bƒÉm.\u0026#34;\u0026#34;\u0026#34; 16 return int(hashlib.sha256(f\u0026#34;{item}{i}\u0026#34;.encode(\u0026#39;utf-8\u0026#39;)).hexdigest(), 16) % self.size 17 18 def add(self, item): 19 \u0026#34;\u0026#34;\u0026#34;Th√™m m·ªôt item v√†o Bloom filter.\u0026#34;\u0026#34;\u0026#34; 20 for i in range(self.num_hash_functions): 21 index = self._hash(item, i) 22 self.bit_array[index] = 1 23 24 def check(self, item): 25 \u0026#34;\u0026#34;\u0026#34;Ki·ªÉm tra m·ªôt item c√≥ trong Bloom filter kh√¥ng.\u0026#34;\u0026#34;\u0026#34; 26 for i in range(self.num_hash_functions): 27 index = self._hash(item, i) 28 if self.bit_array[index] == 0: 29 return False # N·∫øu b·∫•t k·ª≥ bit n√†o l√† 0, ph·∫ßn t·ª≠ ch·∫Øc ch·∫Øn kh√¥ng c√≥ trong b·ªô l·ªçc 30 return True # N·∫øu t·∫•t c·∫£ c√°c bit ƒë·ªÅu l√† 1, c√≥ kh·∫£ nƒÉng ph·∫ßn t·ª≠ c√≥ trong b·ªô l·ªçc 31 32# Kh·ªüi t·∫°o Bloom filter 33bloom_filter = BloomFilter(size=1000, num_hash_functions=3) 34 35# M√¥ ph·ªèng danh s√°ch s·∫£n ph·∫©m ng∆∞·ªùi d√πng ƒë√£ t∆∞∆°ng t√°c 36user_interactions = { 37 \u0026#34;tung\u0026#34;: [\u0026#34;th·ªãt b√≤\u0026#34;, \u0026#34;h√†nh t√¢y\u0026#34;, \u0026#34;khoai t√¢y\u0026#34;], 38 \u0026#34;tuan\u0026#34;: [\u0026#34;thit heo\u0026#34;, \u0026#34;tr·ª©ng\u0026#34;], 39 \u0026#34;canh\u0026#34;: [\u0026#34;th·ªãt b√≤\u0026#34;, \u0026#34;tr·ª©ng\u0026#34;, \u0026#34;s·ªØa TH\u0026#34;, \u0026#34;kem\u0026#34;] 40} 41 42# Th√™m c√°c s·∫£n ph·∫©m ƒë√£ t∆∞∆°ng t√°c v√†o Bloom filter 43for user, items in user_interactions.items(): 44 for item in items: 45 bloom_filter.add(f\u0026#34;{user}-{item}\u0026#34;) # K·∫øt h·ª£p user v√† item ƒë·ªÉ l∆∞u tr·ªØ duy nh·∫•t 46 47# H√†m g·ª£i √Ω s·∫£n ph·∫©m 48def recommend_items(user, candidate_items): 49 \u0026#34;\u0026#34;\u0026#34;ƒê∆∞a ra g·ª£i √Ω c√°c s·∫£n ph·∫©m ch∆∞a t∆∞∆°ng t√°c.\u0026#34;\u0026#34;\u0026#34; 50 recommendations = [] 51 for item in candidate_items: 52 if not bloom_filter.check(f\u0026#34;{user}-{item}\u0026#34;): 53 recommendations.append(item) # Ch·ªâ th√™m s·∫£n ph·∫©m n·∫øu ch∆∞a t∆∞∆°ng t√°c 54 return recommendations 55 56# Danh s√°ch c√°c s·∫£n ph·∫©m c√≥ th·ªÉ g·ª£i √Ω 57candidate_items = [\u0026#34;th·ªãt b√≤\u0026#34;, \u0026#34;h√†nh t√¢y\u0026#34;, \u0026#34;khoai t√¢y\u0026#34;,\u0026#34;tr·ª©ng\u0026#34;, \u0026#34;s·ªØa TH\u0026#34;, \u0026#34;kem\u0026#34;,\u0026#34;thit heo\u0026#34;] 58 59# G·ª£i √Ω s·∫£n ph·∫©m cho tung 60user = \u0026#34;tung\u0026#34; 61recommendations = recommend_items(user, candidate_items) 62 63print(f\u0026#34;Recommendations for {user}: {recommendations}\u0026#34;) K·∫øt qu·∫£:\n1Recommendations for tung: [\u0026#39;tr·ª©ng\u0026#39;, \u0026#39;s·ªØa TH\u0026#39;, \u0026#39;kem\u0026#39;, \u0026#39;thit heo\u0026#39;] https://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html\nhttps://en.wikipedia.org/wiki/Bloom_filter\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt. Xin c·∫£m ∆°n v√† h·∫πn g·∫∑p l·∫°i.\n","date":"Nov 24, 2024","img":"https://unsplash.it/1920/1080?image=202","permalink":"/blog/2024-11-24-system-design-top-10-interview-bloom-filters/","series":null,"tags":["System Design"],"title":"Top 10 Thu·∫≠t To√°n System Design C√°c B·∫°n N√™n Bi·∫øt V√† Th∆∞·ªùng ƒê∆∞·ª£c H·ªèi Trong Ph·ªèng V·∫•n - Top 3 Bloom Filters"},{"categories":null,"content":" I. Kh√°i ni·ªám II. Distributed Hash Table ƒë∆∞·ª£c s·ª≠ d·ª•ng ·ªü ƒë√¢u 1. Peer-to-peer (P2P) networks 2. Distributed databases 3. Content delivery networks 4. Event Notification 5. Distributed File Systems III. C√°c y√™u c·∫ßu c·ªßa m·ªôt lookup algorithm t·ªët Autonomy v√† decentralization Fault tolerance Scalability Load balance Low maintenance overhead IV. ƒêi·ªÉm m·∫°nh c·ªßa Distributed Hash Table Scalability Efficiency Fault tolerance Decentralization Security V. ƒêi·ªÉm kh√¥ng m·∫°nh c·ªßa Distributed Hash Table Complexity Performance Security Compatibility Limited functionality VI. Tham kh·∫£o ƒê·∫øn th·ªùi ƒëi·ªÉm hi·ªán t·∫°i, cu·ªëi nƒÉm 2024, t·ª´ kho√° Decentralization v·∫´n ƒëang l√† m·ªôt t·ª´ kho√° hot, quang tr·ªçng. T·ª´ vi·ªác b√πng n·ªï , n·ªü r·ªô c·ªßa block chain, ƒë·∫øn vi·ªác c√°c data center c·ªßa c√°c t·∫≠p ƒëo√†n l·ªõn n∆∞·ªõc ngo√†i ƒë∆∞·ª£c ƒë·∫∑t ·ªü nhi·ªÅu n∆°i, trong n∆∞·ªõc th√¨ vi·ªác s·ªë ho√° d·ªØ li·ªáu ph√°t tri·ªÉn m·∫°nh m·∫Ω.\nTrong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω c√πng nhau hi·ªÉu kh√°i ni·ªám c∆° b·∫£n c·ªßa Distributed Hash Tables, ∆∞u ƒëi·ªÉm v√† nh∆∞·ª£c ƒëi·ªÉm c·ªßa n√≥\nI. Kh√°i ni·ªám Distributed Hash Tables - DHT l√† m·ªôt h·ªá th·ªëng ph√¢n t√°n phi t·∫≠p trung cung c·∫•p d·ªãch v·ª• tra c·ª©u, t·ª±a t·ª±a nh∆∞ hash table.\nHash table: l√† m·ªôt b·∫£ng d·ªØ li·ªáu key - value. Value ƒë∆∞·ª£c l∆∞u tr·ªØ v√† truy v·∫•n th√¥ng qua key. Key ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x√°c ƒë·ªãnh n∆°i l∆∞u tr·ªØ value.\nV√≠ d·ª•\nkey :a, value:/data/2024/02/01/12/01/01/a.txt key :b, value:/data/2024/02/01/12/01/01/b.txt\nDistributed Hash Tables: d·ªØ li·ªáu c≈©ng d·∫°ng key - value, nh∆∞ng d·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u tr·ªØ ph√¢n t√°n tr√™n nhi·ªÅu node trong m·ªôt network, kh√°c v·ªõi Hash table l√† ch·ªâ l∆∞u tr·ªØ trong 1 node.\ntrong Distributed Hash Tables, m·ªói node ch·ªãu tr√°ch nhi·ªám l∆∞u tr·ªØ m·ªôt ph·∫ßn d·ªØ li·ªáu. Khi ng∆∞·ªùi d√πng truy v·∫•n ho·∫∑c l∆∞u d·ªØ li·ªáu l√™n Distributed Hash Tables, ng∆∞·ªùi d√πng s·∫Ω ƒë·∫©y d·ªØ li·ªáu l√™n network. Y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng s·∫Ω ƒë∆∞·ª£c d·∫©y l√™n node t∆∞∆°ng ·ª©ng v·ªõi kho√° c·ªßa d·ªØ li·ªáu. Node ƒë√≥ s·∫Ω ch·ªãu tr√°ch nhi·ªám l∆∞u tr·ªØ v√† truy v·∫•n d·ªØ li·ªáu c·ªßa ng∆∞·ªùi d√πng.\nV·∫≠y n√™n, m·ªôt Distributed Hash Tables c·∫ßn c√≥ √≠t nh·∫•t 3 th√†nh ph·∫ßn ch√≠nh\nDistributed application: Ch·ªãu tr√°ch nhi·ªám giao ti·∫øp v·ªõi ng∆∞·ªùi d√πng qua 2 ph∆∞∆°ng th·ª©c l√† push ( key, value) ƒë·ªÉ ng∆∞·ªùi d√πng ƒë·∫©y d·ªØ li·ªáu l√™n network v√† get(key) ƒë·ªÉ ng∆∞·ªùi d√πng l·∫•y d·ªØ li·ªáu th√¥ng qua key. App c√≥ th·ªÉ ƒë∆∞·ª£c l∆∞u tr·ªØ ph√¢n t√°n ·ªü tr√™n nhi·ªÅu node.\nDistributed hash table: hay c√≤n g·ªçi l√† DHash, ch·ªãu tr√°ch nhi·ªám l·∫•y ra node ƒëang l∆∞u d·ªØ li·ªáu c·ªßa key. Data c√≥ th·ªÉ ƒë∆∞·ª£c l∆∞u tr·ªØ tr√™n nhi·ªÅu node.\nLookup service: th√†nh ph·∫ßn n√†y ·ªû tr√™n node, tr·∫£ d·ªØ li·ªáu c·ªßa key.\nII. Distributed Hash Table ƒë∆∞·ª£c s·ª≠ d·ª•ng ·ªü ƒë√¢u l√† m·ªôt h·ªá th·ªëng ph√¢n t√°n phi t·∫≠p trung, Distributed Hash Table ƒë∆∞·ª£c s·ª≠ d·ª•ng d∆∞·ªõi nhi·ªÅu m·ª•c ƒë√≠ch kh√°c nhau, gom nh√≥m l·∫°i th√¨ ƒë·∫øn th·ªùi ƒëi·ªÉm hi·ªán t·∫°i, ch√∫ng ta c√≥ 4 nh√≥m ch√≠nh\n1. Peer-to-peer (P2P) networks ·ªû ƒë√¢y, m√¨nh ƒë·ªÅ c·∫≠p t·ªõi BitTorrent cho ƒë∆°n gi·∫£n hen\nV√≠ d·ª• , m√¨nh mu·ªën download file t√™n l√† abc.txt\nch√∫ng ta s·∫Ω d√πng Distributed application nh∆∞ BitTorrent\nDistributed hash table:\nkey s·∫Ω l√† hash (\u0026lsquo;abc.txt\u0026rsquo;)\nvalue l√† ip m√°y c√≥ ch·ª©a file \u0026lsquo;abc.txt\u0026rsquo;\nLookup service:\ng·ªçi ƒë·∫øn m√°y c√≥ ip do Distributed hash table tr·∫£ v·ªÅ v√† k√®m theo m·ªôt s·ªë l·ªánh x√°c th·ª±c ƒë·ªÉ l·∫•y file abc.txt\n2. Distributed databases Ng√†y nay, v·ªõi d·ª± ph√°t tri·ªÉn m·∫°nh m·∫Ω c·ªßa big data, iot, m·ªôt m√°y kh·ªßng long c≈©ng c√≥ th·ªÉ ch∆∞a ƒë·ªß ƒë√°p ·ª©ng t·∫£i v√† t√†i nguy√™n ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu.\n3. Content delivery networks Ch√∫ng ta t∆∞·ªüng t∆∞·ª£ng h·ªá s3 c·ªßa amazone √°, ch·∫Øc ch·∫Øn n√≥ ph·∫£i ƒë∆∞·ª£c l∆∞u tr√™n nhi·ªÅu node r·ªìi.\n4. Event Notification Gi·ªëng firebase.\n5. Distributed File Systems Qu·∫£n l√Ω file trong h·ªá th·ªëng l∆∞u tr·ªØ d·ªØ li·ªáu ph√¢n t√°n\nIII. C√°c y√™u c·∫ßu c·ªßa m·ªôt lookup algorithm t·ªët Autonomy v√† decentralization C√°c node t·ª± ƒë·ªông ph·ªëi h·ª£p v·ªõi nhau t·∫°o l√™n h·ªá th·ªëng, kh√¥ng c·∫ßn node trung t√¢m\nFault tolerance H·ªá th·ªëng ƒë√°ng tin c·∫≠y, khi c√≥ m·ªôt node trong h·ªá th·ªëng b·ªã l·ªói, th√¨ h·ªá th·ªëng v·∫´n ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng\nScalability H·ªá th·ªëng ph·∫£i ho·∫°t ƒë·ªông hi·ªáu qu·∫£ ngay c·∫£ khi c√≥ h√†ng ng√†n, h√†ng tri·ªáu node.\nLoad balance C√°c key c·∫ßn ph·∫£i ph√¢n b·ªë ƒë·ªÅu gi·ªØa c√°c node, tr√°nh cho qu√° t·∫£i 1 node n√†o ƒë√≥\nLow maintenance overhead Khi c√≥ 1 node m·ªõi tham gia v√†o h·ªá th·ªëng ho·∫∑c m·ªôt node r·ªùi kh·ªèi h·ªá th·ªëng, m·ªôt v·∫•n ƒë·ªÅ g·∫∑p ph·∫£i l√† ch√∫ng ta s·∫Ω t·ªën kha kh√° bandwidth ƒë·ªÉ g·ª≠i th√¥ng b√°o t·ªõi c√°c node c√≤n l·∫°i r·∫±ng c√≥ node m·ªõi ho·∫∑c c√≥ node r·ªùi kh·ªèi h·ªá th·ªëng. N√™n, thay v√¨ g·ª≠i th√¥ng b√°o t·ªõi to√°n b·ªô node trong network, ch√∫ng ta c√≥ th·ªÉ ch·ªâ g·ª≠i th√¥ng b√°o t·ªõi c√°c neighbors th√¥i.\nIV. ƒêi·ªÉm m·∫°nh c·ªßa Distributed Hash Table Scalability Distributed Hash Table c√≥ kh·∫£ nƒÉng m·ªü r·ªông cao v√¨ ch√∫ng c√≥ th·ªÉ l∆∞u tr·ªØ v√† truy xu·∫•t l∆∞·ª£ng l·ªõn d·ªØ li·ªáu m√† kh√¥ng c·∫ßn ƒëi·ªÅu ph·ªëi t·∫≠p trung ho·∫∑c m√°y ch·ªß ƒë·ªÉ qu·∫£n l√Ω h·ªá th·ªëng. Distributed Hash Table ph√π h·ª£p v·ªõi c√°c h·ªá th·ªëng ph√¢n t√°n quy m√¥ l·ªõn.\nEfficiency Distributed Hash Table cung c·∫•p c√°ch th·ª©c l∆∞u tr·ªØ v√† truy v·∫•n d·ªØ li·ªáu m·ªôt c√°ch hi·ªáu qu·∫£, s·ª≠ d·ª•ng kho√° d·ªØ li·ªáu ƒë·ªÉ x√°c ƒë·ªãnh v√≠ tr·ªã c·ªßa d·ªØ li·ªáu trong h·ªá th·ªëng. Ch√≠nh ƒëi·ªÅu ƒë√≥ gi√∫p cho Distributed Hash Table c√≥ th·ªÉ x√°c ƒë·ªãnh v√† truy v·∫•n d·ªØ li·ªáu nhanh ch√≥ng m√† kh√¥ng c·∫ßn ph·∫£i t√¨m ki·∫øm tr√™n to√†n b·ªô node c·ªßa h·ªá th·ªëng.\nFault tolerance Distributed Hash Table ƒë·∫£m b·∫£o to√†n v·∫πn d·ªØ li·ªáu, c√≥ th·ªÉ qu·∫£n l√Ω v√† c√¥ l·∫≠p node l·ªói m√† kh√¥ng c·∫ßn server trung t√¢m qu·∫£n l√Ω. D·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u tr·ªØ ph√¢n t√°n tr√™n c√°c node n√™n khi c√≥ node b·ªã l·ªói, node s·∫Ω b·ªã c√¥ l·∫≠p v√† d·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c tr·∫£ v·ªÅ cho ng∆∞·ªùi d√πng t·ª´ c√°c node c√≤n l·∫°i trong h·ªá th·ªëng\nDecentralization Distributed Hash Table l√† h·ªá qu·∫£n l√Ω phi t·∫≠p trung, kh√¥ng c·∫ßn central authority (CA) ho·∫∑c server qu·∫£n l√Ω trung t√¢m, do ƒë√≥ h·ªá th·ªëng √≠t b·ªã khai th√°c l·ªó h·ªïng b·∫£o m·∫≠t h∆°n khi b·ªã t·∫•n c√¥ng. √çt ch·ª© kh√¥ng ph·∫£i l√† kh√¥ng c√≥\nSecurity Distributed Hash Table cung c·∫•p c√°c c∆° ch·∫ø b·∫£o m·∫≠t ƒë·ªÉ l∆∞u tr·ªØ v√† truy v·∫•n d·ªØ li·ªáu, khi d·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u ph√¢n t√°n tr√™n nhi·ªÅu node c·ªßa h·ªá th·ªëng thay v√¨ ch·ªâ l∆∞u tr√™n m·ªôt node, ƒëi·ªÅu n√†y gi√∫p gi·∫£m thi·ªÉu r·ªßi ro khi k·∫ª gian mu·ªën thay ƒë·ªïi d·ªØ li·ªáu v√¨ m·ª•c ƒë√≠ch kh√¥ng t·ªët.\nV. ƒêi·ªÉm kh√¥ng m·∫°nh c·ªßa Distributed Hash Table Complexity Distributed Hash Table kh√° khoai khi tri·ªÉn khai v√† b·∫£o tr√¨, h·ªá th·ªëng c·∫ßn m·ªôt l∆∞·ª£ng l·ªõn nodes ƒë·ªÉ c√°c ch·ª©c nƒÉng ho·∫°t ƒë·ªông m·ªôt c√°ch tr∆°n tru, hi·ªáu qu·∫£. Do ph·∫£i qu·∫£n l√Ω qu√° nhi·ªÅu node, ng∆∞·ªùi qu·∫£n l√Ω s·∫Ω g·∫∑p th√°ch th·ª©c khi c√≥ s·ª± c·ªë xui x·∫ªo x·∫£y ra, ngo√†i ra ng∆∞·ªùi qu·∫£n l√Ω c√≤n ph·∫£i hi·ªÉu k·ªπ h·ªá th·ªëng c·ªßa m√¨nh\nPerformance Trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p x·∫•u, Distributed Hash Table c√≥ hi·ªáu nƒÉng l·ªüm h∆°n so v·ªõi c√°c h·ªá distributed systems kh√°c, ƒë·∫∑c bi·ªát l·ªüm khi h·ªá th·ªëng ƒëang g·∫ßn qu√° t·∫£i (heavy load) ho·∫∑c khi h·ªá th·ªëng qu√° l·ªõn, ng∆∞·ªùi qu·∫£n tr·ªã config s·ªë l∆∞·ª£ng neighbors ho·∫∑c s·ªë hop nhi·ªÅu.\nSecurity B·∫£n th√¢n Distributed Hash Table c√≥ trang b·ªã m·ªôt v√†i c√°ch th·ª©c b·∫£o m·∫≠t d·ªØ li·ªáu ƒë·ªÉ ƒë·∫£m b·∫£o to√†n v·∫πn d·ªØ li·ªáu c·ªßa ng∆∞·ªùi d√πng khi l∆∞u tr·ªØ v√† truy v·∫•n d·ªØ li·ªáu, nh∆∞ng v·ªÅ m·∫∑t thi·∫øt k·∫ø th√¨ h·ªá th·ªëng c√≥ th·ªÉ t·ªìn t·∫°i c√°c l·ªói h·ªïng v·ªÅ b·∫£o m·∫≠t ho·∫∑c b·ªã t·∫•n c√¥ng ki·∫øn tr√∫c h·ªá th·ªëng, v√≠ d·ª• nh∆∞ t·∫•n c√¥ng t·ª´ ch·ªëi d·ªãch v·ª• (DDoS) ho·∫∑c t·∫•n c√¥ng m·∫°o nh·∫≠n - Sybil attack, l√† h√¨nh th·ª©c t·∫•n c√¥ng v√†o c√°c m·∫°ng l∆∞·ªõi ngang h√†ng ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng c√°ch t·∫°o nhi·ªÅu th·ª±c th·ªÉ ·∫£o (t√†i kho·∫£n, node ho·∫∑c m√°y t√≠nh) ƒë·ªÉ chi·∫øm quy·ªÅn ki·ªÉm so√°t m·∫°ng l∆∞·ªõi.\nCompatibility Distributed Hash Table c√≥ th·ªÉ kh√¥ng t∆∞∆°ng th√≠ch v·ªõi to√†n b·ªô ki·ªÉu d·ªØ li·ªáu c·ªßa ng·ª´oi d√πng. M·ªôt s·ªë ki·∫øn tr√∫c y√™u c·∫ßu m·ªôt c·∫•u tr√∫c ho·∫∑c ƒë·ªãnh d·∫°ng ƒë·∫∑c bi·ªát ƒë·ªÉ ho·∫°t ƒë·ªông\nLimited functionality Distributed Hash Table ƒë∆∞·ª£c thi·∫øt ƒë·ªÉ ƒë·ªÉ l∆∞u tr·ªØ v√† l·∫•y d·ªØ li·ªáu, v√† kh√¥ng h·ªó tr·ª£ c√°c h√†m b·ªï tr·ª£\nVI. Tham kh·∫£o https://www.cs.princeton.edu/courses/archive/fall18/cos418/docs/L6-dhts.pdf\nhttps://www.cs.cmu.edu/%7Edga/15-744/S07/lectures/16-dht.pdf\nhttps://web.mit.edu/6.829/www/currentsemester/materials/chord.pdf\nhttps://www.tutorialspoint.com/distributed-hash-tables-dhts\nhttps://www.geeksforgeeks.org/distributed-hash-tables-with-kademlia/\nhttps://medium.com/the-code-vault/data-structures-distributed-hash-table-febfd01fc0af\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt. Xin c·∫£m ∆°n v√† h·∫πn g·∫∑p l·∫°i.\n","date":"Nov 23, 2024","img":"https://unsplash.it/1920/1080?image=200","permalink":"/blog/2024-11-23-system-design-top-10-interview-distributed-hash-table/","series":null,"tags":["System Design"],"title":"Top 10 Thu·∫≠t To√°n System Design C√°c B·∫°n N√™n Bi·∫øt V√† Th∆∞·ªùng ƒê∆∞·ª£c H·ªèi Trong Ph·ªèng V·∫•n - Top 2 Distributed Hash Tables"},{"categories":null,"content":" I. L√Ω thuy·∫øt cƒÉn b·∫£n Reinforcement Learning C√°c th√†nh ph·∫ßn c∆° b·∫£n c·ªßa Reinforcement Learning L√Ω thuy·∫øt to√°n h·ªçc Q-Learning C√°c kh√°i ni·ªám trong Q-learning C√°ch Q-learning ho·∫°t ƒë·ªông Double Deep Q-Network 1. V·∫•n ƒë·ªÅ c·ªßa Q-learning (Overestimation Bias): 2. C·∫£i ti·∫øn c·ªßa Double Deep Q-Network (DDQN): 3. L·ª£i √≠ch c·ªßa DDQN so v·ªõi DQN/Q-learning: 4. V√≠ d·ª• tr·ª±c quan v·ªÅ s·ª± kh√°c bi·ªát: 5. T√≥m t·∫Øt: II. Th·ª±c h√†nh v·ªõi ch∆∞∆°ng tr√¨nh mario Environment Kh·ªüi t·∫°o m√¥i tr∆∞·ªùng X·ª≠ l√Ω d·ªØ li·ªáu Agent Act Remember Learn Play Replay K·∫øt qu·∫£ III. Tham kh·∫£o Ch√†o c√°c b·∫°n, sau m·ªôt th·ªùi gian ·ªü ·∫©n, ch√∫ng ta l·∫°i ti·∫øp t·ª•c v·ªõi vi·ªác th·ª±c chi·∫øn AI, ·ªü b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω train m√¥ h√¨nh AI Reinforcement Learning v·ªõi t·ª±a game ƒë√£ ƒëi v√†o bao nhi√™u th·∫ø h·ªá tr·∫ª th∆°, Mario, tuy nhi√™n, ƒë·ªÉ b·∫Øt ƒë·∫ßu b√†i vi·∫øt, m√¨nh s·∫Ω note l·∫°i m·ªôt v√†i √Ω v·ªÅ Reinforcement Learning, Q learning, v√† c·∫£i ti·∫øn c·ªßa Deep Q-Network l√† Double Deep Q-Network , trong ph·∫ßn code m√¨nh s·∫Ω s·ª≠ d·ª•ng Double Deep Q-Network\nI. L√Ω thuy·∫øt cƒÉn b·∫£n Reinforcement Learning C√°c th√†nh ph·∫ßn c∆° b·∫£n c·ªßa Reinforcement Learning Theo l√Ω thuy·∫øt Reinforcement Learning, ch√∫ng ta c·∫ßn c√°c th√†nh ph·∫ßn sau:\nAgent: l√† ƒë·ªëi t∆∞·ª£ng gi·ªØ c√°c h√†nh ƒë·ªông (Action), th·ª±c hi·ªán c√°c h√†nh ƒë·ªông\nEnvironment : M√¥i tr∆∞·ªùng xung quanh n∆°i agent t∆∞∆°ng t√°c\nAction : Danh s√°ch c√°c h√†nh ƒë·ªông m√† Agent th·ª±c hi·ªán, v√≠ d·ª• nh·∫£y, ch·∫°y, ƒëi l√™n tr∆∞·ªõc 1 b∆∞·ªõc, ƒëi l√πi 1 b∆∞·ªõc, b·∫Øn ƒë·∫°n \u0026hellip; Khi Agent th·ª±c hi·ªán c√°c action, th√¨ environment thay ƒë·ªïi\nState : Danh s√°ch c√°c tr·∫°ng th√°i c·ªßa environment khi c√≥ action t·ª´ agent\nOptimal Action-Value function : H√†m Q*(s,a), ch·ªØ Q c√≥ th·ªÉ hi·ªÉu l√† vi·∫øt t·∫Øt c·ªßa t·ª´ quality\nReward : Agent nh·∫≠n reward t·ª´ Environment khi c√≥ action\nV√≠ d·ª•, Agent l√† con robot, Ation l√† [d·∫≠m ch√¢n, v·ªó tay ], khi con robot d·∫≠m ch√¢n, m√¥i tr∆∞·ªùng thay ƒë·ªïi, ƒë·∫•t l√∫n h∆°n m·ªôt ch√∫t, l√∫c n√†y State l√† 1 b·ª©c tranh c√≥ 1 con r√¥ b·ªët v·ªõi ch√¢n con r√¥ b·ªët h∆°i h∆°i l√∫n m·ªôt ch√∫t xu·ªëng ƒë·∫•t, v√† environment s·∫Ω tr·∫£ v·ªÅ 1 gi√° tr·ªã Reward n√†o ƒë√≥ cho Agent sau h√†nh ƒë·ªông d·∫≠m ch√¢n c·ªßa Agent, d·ªÖ hi·ªÉu ph·∫£i kh√¥ng c√°c b·∫°n.\nReward c·ªßa h√†nh ƒë·ªông d·∫≠m ch√¢n c√≥ th·ªÉ s·∫Ω c√≥ gi√° tr·ªã kh√°c so v·ªõi reward c·ªßa h√†nh ƒë·ªông v·ªó tay.\nV√¨ ch√∫ng ta kh√¥ng bi·∫øt khi n√†o h√†nh ƒë·ªông k·∫øt th√∫c, n√™n rewards s·∫Ω l√† m·ªôt chu·ªói v√¥ h·∫°n c√°c reward sau th·ªùi ƒëi·ªÉm action x·∫£y ra, t√≠nh t·ª´ th·ªùi ƒëi·ªÉm t_0 ban ƒë·∫ßu.\nChu·ªói v√¥ h·∫°n kh√¥ng c√≥ h·ªôi t·ª•, n√™n ng∆∞·ªùi ta ch·∫ø (trick) s·∫Ω th√™m 1 tham s·ªë l√† discount factor hay discount rate, ƒë·ªÉ chu·ªói n√†y h·ªôi t·ª•.\nL√Ω thuy·∫øt to√°n h·ªçc ƒë·ª©ng ƒë·∫±ng sau l√† Markov decision process v√† s·ª≠ d·ª•ng n·ªÅn t·∫£n l√† ph∆∞∆°ng tr√¨nh Bellman, Markov decision process ƒë√£ ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t t·ª´ nƒÉm 1950s, b·∫°n c√≥ th·ªÉ tra google ƒë·ªÉ t√¨m hi·ªÉu th√™m. Gi·ªù m√¨nh hi·ªÉu l√† c√≥ l√Ω thuy·∫øt to√°n h·ªçc ƒë·∫£m b·∫£o chu·ªói n√†y h·ªôi t·ª• r·ªìi, tri·ªÉn th√¥i.\nL√Ω thuy·∫øt to√°n h·ªçc ·ªû m·ª•c n√†y m√¨nh ƒë·ªÅ c·∫≠p m·ªôt ch√∫t v·ªÅ Markov decision process v√† ph∆∞∆°ng tr√¨nh Bellman, c√°c b·∫°n c√≥ th·ªÉ b·ªè qua n·∫øu th·∫•y ng√°n, m√¨nh note l·∫°i ƒë·ªÉ sau n√†y kh·ªèi m·∫•t c√¥ng t√¨m\nPh∆∞∆°ng tr√¨nh c·ªßa Markov Decision Process (MDP) ch√≠nh l√† bi·ªÉu th·ª©c m√¥ t·∫£ c√°ch gi√° tr·ªã c·ªßa c√°c tr·∫°ng th√°i ho·∫∑c h√†nh ƒë·ªông ƒë∆∞·ª£c c·∫≠p nh·∫≠t th√¥ng qua qu√° tr√¨nh ra quy·∫øt ƒë·ªãnh. Tuy nhi√™n, b·∫£n th√¢n MDP kh√¥ng c√≥ m·ªôt ph∆∞∆°ng tr√¨nh duy nh·∫•t c·ª• th·ªÉ, m√† th∆∞·ªùng ƒë∆∞·ª£c m√¥ t·∫£ qua c√°c th√†nh ph·∫ßn c∆° b·∫£n nh∆∞ t·∫≠p tr·∫°ng th√°i, h√†nh ƒë·ªông, x√°c su·∫•t chuy·ªÉn tr·∫°ng th√°i, ph·∫ßn th∆∞·ªüng, v√† h·ªá s·ªë chi·∫øt kh·∫•u.\nPh∆∞∆°ng tr√¨nh ch√≠nh x√°c nh·∫•t li√™n quan ƒë·∫øn MDP l√† ph∆∞∆°ng tr√¨nh Bellman, m√† ch√∫ng ta c√≥ th·ªÉ vi·∫øt theo hai d·∫°ng: d·∫°ng h√†m gi√° tr·ªã tr·∫°ng th√°i v√† d·∫°ng h√†m gi√° tr·ªã h√†nh ƒë·ªông. Hai ph∆∞∆°ng tr√¨nh n√†y th·ªÉ hi·ªán r√µ c√°ch t√≠nh to√°n t·ªïng ph·∫ßn th∆∞·ªüng k·ª≥ v·ªçng.\nMarkov Decision Process (MDP) MDP l√† m·ªôt khung to√°n h·ªçc d√πng ƒë·ªÉ m√¥ t·∫£ c√°c b√†i to√°n ra quy·∫øt ƒë·ªãnh trong m√¥i tr∆∞·ªùng kh√¥ng ch·∫Øc ch·∫Øn. M·ªôt MDP bao g·ªìm c√°c th√†nh ph·∫ßn sau:\nS (State space): T·∫≠p h·ª£p c√°c tr·∫°ng th√°i c√≥ th·ªÉ x·∫£y ra trong m√¥i tr∆∞·ªùng. A (Action space): T·∫≠p h·ª£p c√°c h√†nh ƒë·ªông m√† ng∆∞·ªùi ra quy·∫øt ƒë·ªãnh (agent) c√≥ th·ªÉ th·ª±c hi·ªán ·ªü m·ªói tr·∫°ng th√°i. P (Transition probability): X√°c su·∫•t chuy·ªÉn tr·∫°ng th√°i ( P(s\u0026rsquo;|s, a) ), bi·ªÉu th·ªã x√°c su·∫•t tr·∫°ng th√°i k·∫ø ti·∫øp ( s\u0026rsquo; ) x·∫£y ra khi th·ª±c hi·ªán h√†nh ƒë·ªông ( a ) t·∫°i tr·∫°ng th√°i ( s ). R (Reward function): H√†m th∆∞·ªüng ( R(s, a) ), l√† ph·∫ßn th∆∞·ªüng t·ª©c th√¨ nh·∫≠n ƒë∆∞·ª£c khi th·ª±c hi·ªán h√†nh ƒë·ªông ( a ) t·∫°i tr·∫°ng th√°i ( s ). $(\\gamma) (Discount factor)$: H·ªá s·ªë chi·∫øt kh·∫•u $( \\gamma \\in [0, 1] )$, x√°c ƒë·ªãnh m·ª©c ƒë·ªô ∆∞u ti√™n cho ph·∫ßn th∆∞·ªüng t·ª©c th√¨ so v·ªõi ph·∫ßn th∆∞·ªüng trong t∆∞∆°ng lai. Khi $( \\gamma )$ g·∫ßn b·∫±ng 1, gi√° tr·ªã c√°c ph·∫ßn th∆∞·ªüng trong t∆∞∆°ng lai c√†ng ƒë∆∞·ª£c ƒë√°nh gi√° cao. M·ª•c ti√™u c·ªßa MDP l√† t√¨m ra ch√≠nh s√°ch t·ªëi ∆∞u - optimal policy $( \\pi^* )$, t·ª©c l√† m·ªôt chu·ªói c√°c h√†nh ƒë·ªông gi√∫p t·ªëi ƒëa h√≥a t·ªïng ph·∫ßn th∆∞·ªüng k·ª≥ v·ªçng trong d√†i h·∫°n.\nPh∆∞∆°ng tr√¨nh Bellman Ph∆∞∆°ng tr√¨nh Bellman m√¥ t·∫£ m·ªëi quan h·ªá ƒë·ªá quy gi·ªØa gi√° tr·ªã c·ªßa m·ªôt tr·∫°ng th√°i ho·∫∑c m·ªôt h√†nh ƒë·ªông v·ªõi c√°c tr·∫°ng th√°i k·∫ø ti·∫øp ho·∫∑c h√†nh ƒë·ªông ti·∫øp theo. N√≥ th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√≠nh to√°n gi√° tr·ªã k·ª≥ v·ªçng c·ªßa c√°c tr·∫°ng th√°i ho·∫∑c h√†nh ƒë·ªông, gi√∫p ƒë√°nh gi√° v√† t√¨m ra ch√≠nh s√°ch t·ªëi ∆∞u.\na. Ph∆∞∆°ng tr√¨nh Bellman cho h√†m gi√° tr·ªã tr·∫°ng th√°i ( V(s) )\nH√†m gi√° tr·ªã tr·∫°ng th√°i ( V(s) ) cho bi·∫øt t·ªïng ph·∫ßn th∆∞·ªüng k·ª≥ v·ªçng khi b·∫Øt ƒë·∫ßu t·ª´ tr·∫°ng th√°i ( s ) v√† theo ch√≠nh s√°ch t·ªëi ∆∞u. Ph∆∞∆°ng tr√¨nh Bellman cho h√†m gi√° tr·ªã tr·∫°ng th√°i l√†:\n$$ [ V(s) = \\max_{a} \\left[ R(s, a) + \\gamma \\sum_{s\u0026rsquo;} P(s\u0026rsquo;|s, a)V(s\u0026rsquo;) \\right] ] $$\n·ªû ƒë√¢y:\n( V(s) ) l√† gi√° tr·ªã c·ªßa tr·∫°ng th√°i ( s ). ( R(s, a) ) l√† ph·∫ßn th∆∞·ªüng nh·∫≠n ƒë∆∞·ª£c khi th·ª±c hi·ªán h√†nh ƒë·ªông ( a ) t·∫°i tr·∫°ng th√°i ( s ). ( P(s\u0026rsquo;|s, a) ) l√† x√°c su·∫•t chuy·ªÉn t·ª´ tr·∫°ng th√°i ( s ) sang tr·∫°ng th√°i ( s\u0026rsquo; ) khi th·ª±c hi·ªán h√†nh ƒë·ªông ( a ). $( \\gamma )$ l√† h·ªá s·ªë chi·∫øt kh·∫•u, v√† $( \\sum_{s\u0026rsquo;} P(s\u0026rsquo;|s, a)V(s\u0026rsquo;) )$ l√† gi√° tr·ªã k·ª≥ v·ªçng c·ªßa c√°c tr·∫°ng th√°i ti·∫øp theo. b. Ph∆∞∆°ng tr√¨nh Bellman cho h√†m gi√° tr·ªã h√†nh ƒë·ªông ( Q(s, a) )\nH√†m gi√° tr·ªã h√†nh ƒë·ªông ( Q(s, a) ) bi·ªÉu di·ªÖn t·ªïng ph·∫ßn th∆∞·ªüng k·ª≥ v·ªçng khi b·∫Øt ƒë·∫ßu t·ª´ tr·∫°ng th√°i ( s ), th·ª±c hi·ªán h√†nh ƒë·ªông ( a ), v√† sau ƒë√≥ ti·∫øp t·ª•c theo ch√≠nh s√°ch t·ªëi ∆∞u. Ph∆∞∆°ng tr√¨nh Bellman cho h√†m gi√° tr·ªã h√†nh ƒë·ªông l√†:\n$$ [ Q(s, a) = R(s, a) + \\gamma \\sum_{s\u0026rsquo;} P(s\u0026rsquo;|s, a) \\max_{a\u0026rsquo;} Q(s\u0026rsquo;, a\u0026rsquo;) ] $$\n·ªû ƒë√¢y:\n( Q(s, a) ) l√† gi√° tr·ªã c·ªßa h√†nh ƒë·ªông ( a ) ·ªü tr·∫°ng th√°i ( s ). ( \\max_{a\u0026rsquo;} Q(s\u0026rsquo;, a\u0026rsquo;) ) l√† gi√° tr·ªã t·ªëi ∆∞u c·ªßa h√†nh ƒë·ªông ti·∫øp theo ·ªü tr·∫°ng th√°i k·∫ø ti·∫øp ( s\u0026rsquo; ). Q-Learning Q-learning l√† m·ªôt thu·∫≠t to√°n trong nh√≥m h·ªçc tƒÉng c∆∞·ªùng (reinforcement learning) , thu·ªôc nh√≥m model-free, value-based, off-policy. Thu·∫≠t to√°n s·∫Ω t√¨m ra chu·ªói h√†nh ƒë·ªông t·ªët nh·∫•t d·ª±a tr√™n tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa agent. ‚ÄúQ‚Äù ƒë·∫°i di·ªán cho ch·∫•t l∆∞·ª£ng. Ch·∫•t l∆∞·ª£ng bi·ªÉu th·ªã gi√° tr·ªã c·ªßa h√†nh ƒë·ªông trong vi·ªác t·ªëi ƒëa h√≥a (c·ª±c ƒë·∫°i h√≥a) ph·∫ßn th∆∞·ªüng ·ªü t∆∞∆°ng lai.\nC√≥ m·ªôt s·ªë key word c·∫ßn l√†m r√µ m·ªôt ch√∫t.\nCh√∫ng ta c√≥ hai nh√≥m thu·∫≠t to√°n l√† model-base v√† model-free\nmodel-base d√πng 2 h√†m l√† transition v√† reward ƒë·ªÉ ∆∞·ªõc t√≠nh ƒë∆∞·ªùng ƒëi t·ªëi ∆∞u, ch√∫ng ta ph·∫£i v·∫Øt √≥c suy nghƒ© 2 h√†m n√†y, t∆∞·ªüng t∆∞·ª£ng b·∫°n ch∆°i c·ªù v√† d·ª± ƒëo√°n tr∆∞·ªõc c√°c n∆∞·ªõc ƒëi c·ªßa ƒë·ªëi th·ªß, bi·∫øt ƒë∆∞·ª£c ƒë·ªëi th·ªß s·∫Ω ƒëi nh∆∞ th·∫ø n√†o, n√™n ta c√≥ th·ªÉ ch·ªçn nh·ªØng n∆∞·ªõc ƒëi sao cho k·∫øt qu·∫£ cu·ªëi c√πng ta s·∫Ω th·∫Øng.\nmodel-free h·ªçc t·ª´ chu·ªói h√†nh ƒë·ªông, r√∫t ra kinh nghi·ªám, v√† v·∫•p ng√£ ƒë√¢u , ƒë·ª©ng d·∫≠y ·ªü ƒë√≥, kh√¥ng c·∫ßn ƒë·ªãnh nghƒ©a transition function v√† reward function. T∆∞·ªüng t∆∞·ª£ng b·∫°n t·ª± m√¨nh h·ªçc c√°ch ƒëi xe ƒë·∫°p, b·∫°n ng√£, r√∫t kinh nghi·ªám t·ª´ l·ªói l·∫ßm v√† d·∫ßn d·∫ßn ƒëi ƒë∆∞·ª£c m√† kh√¥ng c·∫ßn b·∫£n h∆∞·ªõng d·∫´n chi ti·∫øt n√†o, c·ª© √¥m xe ƒë·∫°p m√† t·∫≠p d·∫ßn.\nTi·∫øp t·ªõi, ch√∫ng ta c√≥ 2 lo·∫°i ph∆∞∆°ng th·ª©c l√† value-based v√† policy-based\nPh∆∞∆°ng ph√°p value-based , hu·∫•n luy·ªán h√†m gi√° tr·ªã, hu·∫•n luy·ªán l√†m sao ƒë·ªÉ h√†m gi√° tr·ªã c√≥ th·ªÉ t√¨m ra tr·∫°ng th√°i m√† tr·∫°ng th√°i ƒë√≥ l√†m cho h√†m gi√° tr·ªã ƒë·∫°t gi√° tr·ªã l·ªõn nh·∫•t, ƒë·∫°t gi√° tr·ªã c·ª±c ƒë·∫°i, t·ª´ ƒë√≥ quy·∫øt ƒë·ªãnh s·ª≠ d·ª•ng h√†nh ƒë·ªông ƒë√≥. N√≥i c√°ch kh√°c, n√≥ gi√∫p agent hi·ªÉu xem ·ªü tr·∫°ng th√°i n√†o th√¨ h√†nh ƒë·ªông n√†o s·∫Ω mang l·∫°i ph·∫ßn th∆∞·ªüng cao nh·∫•t. V√≠ d·ª•, b·∫°n ch·ªçn m√¥n h·ªçc c√≥ gi√° tr·ªã nh·∫•t ƒë·ªÉ h·ªçc tr∆∞·ªõc nh·∫±m ƒë·∫°t ƒëi·ªÉm s·ªë cao nh·∫•t.\nPh∆∞∆°ng ph√°p policy-based ƒë∆∞a ra c√°c policy quy ƒë·ªãnh ·ª©ng v·ªõi t·ª´ng state, ta s·∫Ω ƒë∆∞a ra c√°c action g√¨, n√≥ h·ªçc c√°ch ƒë∆∞a ra quy·∫øt ƒë·ªãnh t·ªët nh·∫•t trong t·ª´ng tr·∫°ng th√°i. Gi·ªëng nh∆∞ khi b·∫°n kh√¥ng ch·ªâ h·ªçc l√Ω thuy·∫øt m√† th·ª±c s·ª± th·ª±c h√†nh ƒë·ªÉ bi·∫øt c√°ch h√†nh ƒë·ªông t·ªët nh·∫•t trong t·ª´ng t√¨nh hu·ªëng c·ª• th·ªÉ.\nCu·ªëi c√πng, c√≥ 2 c√°i ch√≠nh s√°ch ƒë·ªëi l·∫≠p l√† off-policy v√† on-policy\noff-policy thu·∫≠t to√°n ƒë√°nh gi√° v√† c·∫≠p nh·∫≠t l·∫°i policy m·ªõi, policy m·ªõi kh√°c v·ªõi policy ƒëang th·ª±c hi·ªán action. Nghƒ©a l√† n√≥ kh√¥ng c·∫ßn theo ƒë√∫ng ch√≠nh s√°ch hi·ªán h√†nh m√† c√≥ th·ªÉ h·ªçc v√† c·∫£i thi·ªán ch√≠nh s√°ch m·ªõi d·ª±a tr√™n d·ªØ li·ªáu v√† kinh nghi·ªám thu th·∫≠p ƒë∆∞·ª£c, ki·ªÉu nh∆∞ l√† v·ª´a ch∆°i game v·ª´a nghƒ© ra chi·∫øn l∆∞·ª£c m·ªõi thay v√¨ b√°m s√°t chi·∫øn l∆∞·ª£c c≈©.\non-policy n√≥ kh√¥ng ch·ªâ d√πng ch√≠nh s√°ch hi·ªán t·∫°i m√† c√≤n ƒëi·ªÅu ch·ªânh v√† c·∫£i thi·ªán ch√≠nh s√°ch ƒë√≥ li√™n t·ª•c d·ª±a tr√™n nh·ªØng g√¨ ƒë√£ h·ªçc ƒë∆∞·ª£c t·ª´ m·ªói h√†nh ƒë·ªông. Nh∆∞ c√°ch b·∫°n ti·∫øp t·ª•c ho√†n thi·ªán chi·∫øn l∆∞·ª£c ch∆°i game c·ªßa m√¨nh m·ªói l·∫ßn ch∆°i d·ª±a tr√™n nh·ªØng g√¨ ƒë√£ tr·∫£i qua.\nC√°c kh√°i ni·ªám trong Q-learning K·∫ø th·ª´a c√°c key trong Reinforcement Learning, ch√∫ng ta c√≥\nStates(s) : v·ªã tr√≠ hi·ªán t·∫°i c·ªßa agent trong environment\nAction(a) : H√†nh ƒë·ªông c·ªßa agent trong m·ªôt state c·ª• th·ªÉ\nRewards : Gi√° tr·ªã ph·∫ßn th∆∞·ªüng ho·∫∑c gi√° tr·ªã ph·∫°t khi m·ªôt Action x·∫£y ra\nEpisodes: K·∫øt th√∫c state, khi Agent kh√¥ng th·ªÉ th·ª±c hi·ªán m·ªôt action m·ªõi. Episodes x·∫£y ra khi agent ph√° ƒë·∫£o ho·∫∑c agent b·ªã die\n$Q(S_t+1, a)$ : Gi√° tr·ªã k·ª≥ v·ªçng ƒë·∫°t ƒë∆∞·ª£c Q value ·ªü state t+1 v√† h√†nh ƒë·ªông a\nC√°ch Q-learning ho·∫°t ƒë·ªông Q-Table Q-Table v·ªÅ c∆° b·∫£n l√† m·ªôt b·∫£ng tra c·ª©u, trong ƒë√≥ m·ªói h√†ng ƒë·∫°i di·ªán cho m·ªôt tr·∫°ng th√°i c√≥ th·ªÉ c√≥, v√† m·ªói c·ªôt ƒë·∫°i di·ªán cho m·ªôt h√†nh ƒë·ªông c√≥ th·ªÉ th·ª±c hi·ªán. B·∫£ng n√†y l∆∞u tr·ªØ c√°c gi√° tr·ªã Q-values (ph·∫ßn th∆∞·ªüng k·ª≥ v·ªçng) cho m·ªói c·∫∑p tr·∫°ng th√°i-h√†nh ƒë·ªông. Theo th·ªùi gian, Agent s·∫Ω c·∫≠p nh·∫≠t b·∫£ng n√†y ƒë·ªÉ h·ªçc c√°ch l·ª±a ch·ªçn h√†nh ƒë·ªông t·ªët nh·∫•t trong m·ªói tr·∫°ng th√°i.\nQ-value Q-value ƒë·∫°i di·ªán cho ph·∫ßn th∆∞·ªüng t∆∞∆°ng lai, k·ª≥ v·ªçng m√† Agent s·∫Ω nh·∫≠n ƒë∆∞·ª£c khi th·ª±c hi·ªán m·ªôt h√†nh ƒë·ªông nh·∫•t ƒë·ªãnh t·ª´ tr·∫°ng th√°i hi·ªán t·∫°i, v√† sau ƒë√≥ th·ª±c hi·ªán theo policy t·ªët nh·∫•t (t·ªëi ƒëa h√≥a ph·∫ßn th∆∞·ªüng).\nQ-learning Function L√† m·ªôt model-free reinforcement learning, s·ª≠ d·ª•ng ph∆∞∆°ng tr√¨nh Bellman, c·∫≠p nh·∫≠t b·∫£ng Q th√¥ng qua vi·ªác h·ªçc t·ª´ s·ª± t∆∞∆°ng t√°c v·ªõi m√¥i tr∆∞·ªùng. Khi Agent th·ª±c hi·ªán m·ªôt h√†nh ƒë·ªông, n√≥ s·∫Ω quan s√°t ph·∫ßn th∆∞·ªüng v√† tr·∫°ng th√°i m·ªõi m√† n√≥ chuy·ªÉn ƒë·∫øn. Thu·∫≠t to√°n sau ƒë√≥ s·∫Ω c·∫≠p nh·∫≠t gi√° tr·ªã Q cho c·∫∑p tr·∫°ng th√°i-h√†nh ƒë·ªông ƒë√≥ theo quy t·∫Øc c·∫≠p nh·∫≠t sau:\n$$ [ Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left( r + \\gamma \\max_a\u0026rsquo; Q(s\u0026rsquo;, a\u0026rsquo;) - Q(s, a) \\right) ] $$\nTrong ƒë√≥:\n$( Q(s, a) )$ l√† gi√° tr·ªã Q cho tr·∫°ng th√°i ( s ) v√† h√†nh ƒë·ªông ( a ) $( \\alpha )$ l√† t·ªëc ƒë·ªô h·ªçc (quy·∫øt ƒë·ªãnh m·ª©c ƒë·ªô m√† th√¥ng tin m·ªõi ghi ƒë√® th√¥ng tin c≈©) $( r )$ l√† ph·∫ßn th∆∞·ªüng nh·∫≠n ƒë∆∞·ª£c sau khi th·ª±c hi·ªán h√†nh ƒë·ªông ( a ) ·ªü tr·∫°ng th√°i ( s ) $( \\gamma )$ l√† h·ªá s·ªë chi·∫øt kh·∫•u (x√°c ƒë·ªãnh m·ª©c ƒë·ªô ph·∫ßn th∆∞·ªüng t∆∞∆°ng lai ƒë∆∞·ª£c t√≠nh ƒë·∫øn) $( \\max_a\u0026rsquo; Q(s\u0026rsquo;, a\u0026rsquo;) )$ l√† ph·∫ßn th∆∞·ªüng k·ª≥ v·ªçng l·ªõn nh·∫•t cho tr·∫°ng th√°i ti·∫øp theo ( s\u0026rsquo; ) sau h√†nh ƒë·ªông ( a\u0026rsquo; ) Theo th·ªùi gian, Agent s·ª≠ d·ª•ng Q-learning s·∫Ω d·∫ßn d·∫ßn ho√†n thi·ªán b·∫£ng Q c·ªßa m√¨nh v√† h·ªçc ƒë∆∞·ª£c c√°ch th·ª±c hi·ªán c√°c h√†nh ƒë·ªông t·ªëi ∆∞u cho m·ªói tr·∫°ng th√°i ƒë·ªÉ t·ªëi ƒëa h√≥a ph·∫ßn th∆∞·ªüng k·ª≥ v·ªçng.\nQ-learning algorithm Init Q_table -\u0026gt; Choose action -\u0026gt; Do action -\u0026gt; Mesure reward -\u0026gt; Update Q Table -\u0026gt; Choose action \u0026hellip;\nInit Q_table X√¢y d·ª±ng b·∫£ng bao g·ªìm h√†ng l√† c√°c state, c·ªôt l√† c√°c action , ƒë·∫ßu ti√™n c√≥ th·ªÉ kh·ªüi t·∫°o gi√° tr·ªã c·ªßa b·∫£ng n√†y l√† 0.\nChoose action ·ªû l·∫ßn ch·∫°y ƒë·∫ßu ti√™n, ch√∫ng ta c√≥ th·ªÉ random action, ·ªü l·∫ßn ch·∫°y sau, ch√∫ng ta l·∫•y action ·ªü b·∫£ng Q Table ·ªü tr√™n\nDo action Th·ª±c hi·ªán ch·ªçn h√†nh ƒë·ªông v√† th·ª±c hi·ªán h√†nh ƒë·ªông ƒë·∫øn khi qu√° tr√¨nh train d·ª´ng l·∫°i.\nV·ªõi m·ªói l·∫ßn Choose action v√† Do action, ch√∫ng ta s·∫Ω:\n·ªû l·∫ßn ch·∫°y ƒë·∫ßu ti√™n, ch√∫ng ta l·∫•y ng·∫´u nhi√™n 1 h√†nh ƒë·ªông, sau ƒë√≥ Agent s·∫Ω th·ª±c hi·ªán h√†nh ƒë·ªông v√† nh·∫≠n reward, update Q Table s·ª≠ d·ª•ng Q-learning Function ƒë√£ n√™u ph√≠a tr√™n. ·ªû c√°c l·∫ßn ch·∫°y sau, ch√∫ng ta l·∫•y ra h√†nh ƒë·ªông t·ªët nh·∫•t ƒë·ªÉ Agent th·ª±c hi·ªán h√†nh ƒë·ªông v√† ch√∫ng ta l·∫°i update Q Table ti·∫øp.\nV√¨ l√Ω do l√† Agent c·∫ßn t·ªëi ƒëa h√≥a ph·∫ßn th∆∞·ªüng ƒë·∫°t ƒë∆∞·ª£c, n√™n ·ªü ƒë√¢y xu·∫•t hi·ªán 2 kh√°i ni·ªám l√† exploration (kh√°m ph√°) v√† exploitation (khai th√°c), v√† c·∫ßn c√¢n b·∫±ng c·∫£ 2\nExploration (Kh√°m ph√°):\nKh√°m ph√° l√† khi Agent th·ª≠ nh·ªØng h√†nh ƒë·ªông m·ªõi ho·∫∑c ch∆∞a t·ª´ng th·ª≠ tr∆∞·ªõc ƒë√≥ ƒë·ªÉ t√¨m hi·ªÉu th√™m v·ªÅ m√¥i tr∆∞·ªùng. ƒêi·ªÅu n√†y c√≥ nghƒ©a l√† Agent c√≥ th·ªÉ s·∫Ω kh√¥ng ch·ªçn h√†nh ƒë·ªông c√≥ ph·∫ßn th∆∞·ªüng cao nh·∫•t d·ª±a tr√™n th√¥ng tin hi·ªán t·∫°i m√† thay v√†o ƒë√≥ th·ª≠ c√°c h√†nh ƒë·ªông ch∆∞a r√µ k·∫øt qu·∫£. L√Ω do: N·∫øu Agent ch·ªâ khai th√°c c√°c h√†nh ƒë·ªông c√≥ ph·∫ßn th∆∞·ªüng cao hi·ªán t·∫°i m√† kh√¥ng kh√°m ph√° c√°c h√†nh ƒë·ªông kh√°c, n√≥ c√≥ th·ªÉ b·ªè l·ª° nh·ªØng h√†nh ƒë·ªông t·ªët h∆°n ·ªü t∆∞∆°ng lai. M√¥i tr∆∞·ªùng c√≥ th·ªÉ ph·ª©c t·∫°p v√† thay ƒë·ªïi, n√™n Agent c·∫ßn ti·∫øp t·ª•c t√¨m hi·ªÉu ƒë·ªÉ c√≥ d·ªØ li·ªáu ƒë·∫ßy ƒë·ªß. Exploitation (Khai th√°c):\nKhai th√°c l√† khi Agent ch·ªçn h√†nh ƒë·ªông d·ª±a tr√™n th√¥ng tin m√† n√≥ ƒë√£ h·ªçc ƒë∆∞·ª£c ƒë·ªÉ t·ªëi ∆∞u h√≥a ph·∫ßn th∆∞·ªüng. Trong tr∆∞·ªùng h·ª£p n√†y, Agent ch·ªçn h√†nh ƒë·ªông m√† n√≥ tin l√† c√≥ ph·∫ßn th∆∞·ªüng cao nh·∫•t d·ª±a tr√™n nh·ªØng g√¨ n√≥ ƒë√£ tr·∫£i nghi·ªám. L√Ω do: Sau khi ƒë√£ t√≠ch l≈©y ƒë·ªß th√¥ng tin v·ªÅ m√¥i tr∆∞·ªùng, Agent c·∫ßn t·∫≠p trung khai th√°c c√°c h√†nh ƒë·ªông ƒë√£ ƒë∆∞·ª£c bi·∫øt l√† c√≥ l·ª£i ƒë·ªÉ t·ªëi ƒëa h√≥a ph·∫ßn th∆∞·ªüng trong d√†i h·∫°n. T·∫°i sao c·∫ßn c√≥ c·∫£ hai?\nC√¢n b·∫±ng: N·∫øu ch·ªâ khai th√°c m√† kh√¥ng kh√°m ph√°, Agent c√≥ th·ªÉ r∆°i v√†o c√°i g·ªçi l√† local optimum (c·ª±c ƒë·∫°i c·ª•c b·ªô) m√† b·ªè l·ª° c∆° h·ªôi ƒë·∫°t ƒë∆∞·ª£c global optimum (c·ª±c ƒë·∫°i to√†n c·ª•c), t·ª©c l√† gi·∫£i ph√°p t·ªët nh·∫•t. M·∫∑t kh√°c, n·∫øu ch·ªâ kh√°m ph√° m√† kh√¥ng khai th√°c, Agent s·∫Ω kh√¥ng th·ªÉ t·∫≠n d·ª•ng nh·ªØng g√¨ n√≥ ƒë√£ h·ªçc ƒë∆∞·ª£c, d·∫´n ƒë·∫øn kh√¥ng t·ªëi ∆∞u h√≥a ph·∫ßn th∆∞·ªüng. V√≠ d·ª•:\nExploration: B·∫°n ƒëi ƒÉn ·ªü m·ªôt nh√† h√†ng m·ªõi m√† b·∫°n ch∆∞a bao gi·ªù th·ª≠, hy v·ªçng t√¨m ƒë∆∞·ª£c m√≥n ƒÉn ngon h∆°n. Exploitation: B·∫°n quay l·∫°i m·ªôt nh√† h√†ng quen thu·ªôc m√† b·∫°n bi·∫øt ch·∫Øc m√≥n ƒÉn ·ªü ƒë√≥ r·∫•t ngon. Trong th·ª±c t·∫ø, c√°c thu·∫≠t to√°n nh∆∞ epsilon-greedy s·ª≠ d·ª•ng m·ªôt chi·∫øn l∆∞·ª£c k·∫øt h·ª£p c·∫£ kh√°m ph√° v√† khai th√°c, cho ph√©p Agent th·ª±c hi·ªán ph·∫ßn l·ªõn c√°c h√†nh ƒë·ªông khai th√°c nh∆∞ng ƒë√¥i khi v·∫´n kh√°m ph√° nh·ªØng h√†nh ƒë·ªông m·ªõi v·ªõi m·ªôt x√°c su·∫•t nh·ªè (epsilon).\nTrong Q-learning, ·ªü giai ƒëo·∫°n ƒë·∫ßu, gi√° tr·ªã epsilon th∆∞·ªùng l·ªõn ƒë·ªÉ x√°c xu·∫•t Exploration xu·∫•t hi·ªán nhi·ªÅu, qua m·ªói l·∫ßn l·∫∑p, Agent c√†ng ng√†y c√†ng t·ª± tin v·ªõi c√°c gi√° tr·ªã h·ªçc ƒë∆∞·ª£c ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t ·ªü Q table, n√™n gi√° tr·ªã Exploration ·ªü c√°c l·∫ßn l·∫∑p sau s·∫Ω gi·∫£m b·ªõt, nh·ªè ƒë·∫ßn, t·ª´ ƒë√≥ x√°c xu·∫•t ch·ªçn action t·ª´ Q table s·∫Ω l·ªõn h∆°n.\nMeasuring the Rewards Sau khi th·ª±c hi·ªán h√†nh ƒë·ªông, ch√∫ng ta s·∫Ω thu ƒë∆∞·ª£c k·∫øt qu·∫£ v√† ph·∫ßn th∆∞·ªüng\nC√≥ nhi·ªÅu c√°ch cho th∆∞·ªüng, t√πy , m·ªôt d·∫°ng ƒë∆°n gi·∫£n nh·∫•t ƒë√≥ l√†\nN·∫øu v·ªÅ ƒë√≠ch , +1 ƒëi·ªÉm th∆∞·ªüng\nN·∫øu th·∫•t b·∫°i, ch∆∞a v·ªÅ ƒë√≠ch , 0 ƒëi·ªÉm\nUpdate Q Table Trong Q-learning, khi m·ªôt Agent c·∫≠p nh·∫≠t gi√° tr·ªã Q cho m·ªôt c·∫∑p tr·∫°ng th√°i-h√†nh ƒë·ªông, qu√° tr√¨nh n√†y d·ª±a tr√™n s·ª± k·∫øt h·ª£p gi·ªØa gi√° tr·ªã Q c≈© (former Q-value) v√† gi√° tr·ªã Q m·ªõi ∆∞·ªõc t√≠nh (new Q-value estimation). ƒê√¢y l√† hai kh√≠a c·∫°nh quan tr·ªçng c·ªßa c√¥ng th·ª©c c·∫≠p nh·∫≠t Q-value trong Q-learning:\nFormer Q-value (Gi√° tr·ªã Q c≈©):\nƒê√¢y l√† gi√° tr·ªã Q hi·ªán t·∫°i cho m·ªôt c·∫∑p tr·∫°ng th√°i-h√†nh ƒë·ªông c·ª• th·ªÉ m√† Agent ƒë√£ ghi nh·∫≠n tr∆∞·ªõc ƒë√≥. N√≥ th·ªÉ hi·ªán ph·∫ßn th∆∞·ªüng k·ª≥ v·ªçng m√† Agent ƒë√£ t√≠nh to√°n t·ª´ c√°c l·∫ßn t∆∞∆°ng t√°c tr∆∞·ªõc ƒë√≥ v·ªõi m√¥i tr∆∞·ªùng.\nTrong c√¥ng th·ª©c c·∫≠p nh·∫≠t Q-learning:\n$$ [ Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left( r + \\gamma \\max_a\u0026rsquo; Q(s\u0026rsquo;, a\u0026rsquo;) - Q(s, a) \\right) ] $$\nPh·∫ßn $( Q(s, a) )$ b√™n ph·∫£i c·ªßa d·∫•u m≈©i t√™n l√† gi√° tr·ªã Q c≈©.\nNew Q-value estimation (Gi√° tr·ªã Q m·ªõi ∆∞·ªõc t√≠nh): ƒê√¢y l√† gi√° tr·ªã Q ƒë∆∞·ª£c c·∫≠p nh·∫≠t d·ª±a tr√™n ph·∫ßn th∆∞·ªüng v·ª´a nh·∫≠n ƒë∆∞·ª£c v√† d·ª± ƒëo√°n ph·∫ßn th∆∞·ªüng trong t∆∞∆°ng lai (d·ª±a tr√™n tr·∫°ng th√°i ti·∫øp theo v√† h√†nh ƒë·ªông t·ªët nh·∫•t c√≥ th·ªÉ th·ª±c hi·ªán).\nPh·∫ßn ( r + \\gamma \\max_a\u0026rsquo; Q(s\u0026rsquo;, a\u0026rsquo;) ) trong c√¥ng th·ª©c l√† ph·∫ßn th∆∞·ªüng m·ªõi v√† gi√° tr·ªã k·ª≥ v·ªçng c·ªßa tr·∫°ng th√°i ti·∫øp theo. ƒêi·ªÅu n√†y ƒë·∫°i di·ªán cho s·ª± ∆∞·ªõc t√≠nh m·ªõi v·ªÅ ph·∫ßn th∆∞·ªüng n·∫øu Agent ti·∫øp t·ª•c th·ª±c hi·ªán ch√≠nh s√°ch t·ªëi ∆∞u t·ª´ tr·∫°ng th√°i ti·∫øp theo.\nAlpha (Œ±) - H·ªá s·ªë h·ªçc (Learning Rate):\n-√ù nghƒ©a: Alpha ki·ªÉm so√°t m·ª©c ƒë·ªô m√† c√°c gi√° tr·ªã Q hi·ªán t·∫°i ƒë∆∞·ª£c c·∫≠p nh·∫≠t b·∫±ng th√¥ng tin m·ªõi. N√≥ quy·∫øt ƒë·ªãnh xem t√°c nh√¢n s·∫Ω h·ªçc nhanh ch√≥ng t·ª´ c√°c tr·∫£i nghi·ªám m·ªõi hay h·ªçc d·∫ßn d·∫ßn.\nPh·∫°m vi: $( 0 \\leq \\alpha \\leq 1 )$\nGi·∫£i th√≠ch:\nŒ± = 1: T√°c nh√¢n ho√†n to√†n b·ªè qua th√¥ng tin c≈© v√† ch·ªâ d√πng gi√° tr·ªã m·ªõi ∆∞·ªõc t√≠nh. Nghƒ©a l√† m·ªói khi c√≥ m·ªôt tr·∫£i nghi·ªám m·ªõi, gi√° tr·ªã Q c≈© s·∫Ω ƒë∆∞·ª£c thay th·∫ø ho√†n to√†n.\nŒ± = 0: T√°c nh√¢n ho√†n to√†n kh√¥ng c·∫≠p nh·∫≠t gi√° tr·ªã Q c≈©, c√≥ nghƒ©a l√† t√°c nh√¢n s·∫Ω kh√¥ng h·ªçc g√¨ t·ª´ tr·∫£i nghi·ªám m·ªõi.\nGi√° tr·ªã trung gian (0 \u0026lt; Œ± \u0026lt; 1): K·∫øt h·ª£p gi·ªØa gi√° tr·ªã Q c≈© v√† gi√° tr·ªã m·ªõi, t·ª©c l√† h·ªçc t·∫≠p t·ª´ c·∫£ kinh nghi·ªám c≈© v√† m·ªõi m·ªôt c√°ch t·ª´ t·ª´. Trong th·ª±c t·∫ø, alpha th∆∞·ªùng ƒë∆∞·ª£c ch·ªçn l√† m·ªôt gi√° tr·ªã nh·ªè (v√≠ d·ª•: 0.1 ho·∫∑c 0.01) ƒë·ªÉ t√°c nh√¢n c√≥ th·ªÉ h·ªçc ·ªïn ƒë·ªãnh v√† kh√¥ng thay ƒë·ªïi qu√° ƒë·ªôt ng·ªôt.\nGamma (Œ≥) - H·ªá s·ªë chi·∫øt kh·∫•u (Discount Factor):\n√ù nghƒ©a: Gamma x√°c ƒë·ªãnh m·ª©c ƒë·ªô m√† t√°c nh√¢n coi tr·ªçng c√°c ph·∫ßn th∆∞·ªüng trong t∆∞∆°ng lai. N√≥ cho ph√©p t√°c nh√¢n c√¢n nh·∫Øc gi·ªØa vi·ªác nh·∫≠n ph·∫ßn th∆∞·ªüng ngay l·∫≠p t·ª©c v√† ph·∫ßn th∆∞·ªüng ti·ªÅm nƒÉng trong t∆∞∆°ng lai. Ph·∫°m vi: $( 0 \\leq \\gamma \\leq 1 )$ Gi·∫£i th√≠ch: Œ≥ = 0: T√°c nh√¢n ch·ªâ quan t√¢m ƒë·∫øn ph·∫ßn th∆∞·ªüng t·ª©c th√¨ m√† kh√¥ng ƒë·ªÉ √Ω ƒë·∫øn ph·∫ßn th∆∞·ªüng t∆∞∆°ng lai. ƒêi·ªÅu n√†y khi·∫øn t√°c nh√¢n ch·ªâ t·ªëi ∆∞u h√≥a cho l·ª£i √≠ch ng·∫Øn h·∫°n. Œ≥ = 1: T√°c nh√¢n ƒë√°nh gi√° ph·∫ßn th∆∞·ªüng hi·ªán t·∫°i v√† t∆∞∆°ng lai m·ªôt c√°ch c√¢n b·∫±ng, t·ª©c l√† ph·∫ßn th∆∞·ªüng trong t∆∞∆°ng lai xa c√≥ c√πng tr·ªçng s·ªë v·ªõi ph·∫ßn th∆∞·ªüng ngay l·∫≠p t·ª©c. Gi√° tr·ªã trung gian (0 \u0026lt; Œ≥ \u0026lt; 1): ƒê√¢y l√† l·ª±a ch·ªçn ph·ªï bi·∫øn trong c√°c b√†i to√°n th·ª±c t·∫ø. Gamma s·∫Ω gi·∫£m d·∫ßn gi√° tr·ªã c·ªßa c√°c ph·∫ßn th∆∞·ªüng c√†ng xa trong t∆∞∆°ng lai, nh∆∞ng v·∫´n ƒë·∫£m b·∫£o r·∫±ng t√°c nh√¢n quan t√¢m ƒë·∫øn vi·ªác t·ªëi ƒëa h√≥a ph·∫ßn th∆∞·ªüng d√†i h·∫°n. T√≥m l·∫°i, vai tr√≤ c·ªßa Œ± v√† Œ≥:\nAlpha (Œ±): ƒêi·ªÅu ch·ªânh t·ªëc ƒë·ªô h·ªçc, t·ª©c l√† m·ª©c ƒë·ªô c·∫≠p nh·∫≠t gi√° tr·ªã Q d·ª±a tr√™n th√¥ng tin m·ªõi. Gamma (Œ≥): ƒêi·ªÅu ch·ªânh s·ª± ∆∞u ti√™n gi·ªØa ph·∫ßn th∆∞·ªüng hi·ªán t·∫°i v√† ph·∫ßn th∆∞·ªüng trong t∆∞∆°ng lai. C·∫£ hai tham s·ªë n√†y ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn hi·ªáu qu·∫£ h·ªçc t·∫≠p c·ªßa t√°c nh√¢n trong m√¥i tr∆∞·ªùng v√† c·∫ßn ƒë∆∞·ª£c tinh ch·ªânh ph√π h·ª£p cho t·ª´ng b√†i to√°n c·ª• th·ªÉ.\nDouble Deep Q-Network Sau khi t√¨m hi·ªÉu Q learning, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu 1 c·∫£i ti·∫øn c·ªßa n√≥ l√† Double Deep Q-Network\nDouble Deep Q-Network (DDQN) l√† m·ªôt c·∫£i ti·∫øn c·ªßa Q-learning (c·ª• th·ªÉ l√† DQN - Deep Q-Network) nh·∫±m gi·∫£i quy·∫øt m·ªôt s·ªë v·∫•n ƒë·ªÅ quan tr·ªçng trong qu√° tr√¨nh h·ªçc t·∫≠p. So v·ªõi Q-learning, DDQN gi√∫p gi·∫£m s·ª± thi√™n l·ªách ∆∞·ªõc l∆∞·ª£ng (overestimation bias) v√† c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c trong vi·ªác ch·ªçn h√†nh ƒë·ªông. D∆∞·ªõi ƒë√¢y l√† chi ti·∫øt v·ªÅ c√°c c·∫£i ti·∫øn c·ªßa DDQN so v·ªõi Q-learning:\n1. V·∫•n ƒë·ªÅ c·ªßa Q-learning (Overestimation Bias): Q-learning ti√™u chu·∫©n (bao g·ªìm c·∫£ DQN, phi√™n b·∫£n m·ªü r·ªông v·ªõi m·∫°ng n∆°-ron) c√≥ xu h∆∞·ªõng g·∫∑p ph·∫£i v·∫•n ƒë·ªÅ g·ªçi l√† thi√™n l·ªách ∆∞·ªõc l∆∞·ª£ng qu√° m·ª©c (overestimation bias). Khi t√≠nh to√°n gi√° tr·ªã Q, Q-learning ch·ªçn h√†nh ƒë·ªông d·ª±a tr√™n gi√° tr·ªã Q l·ªõn nh·∫•t trong Q-table (ho·∫∑c m·∫°ng Q trong DQN). Tuy nhi√™n, do s·ª± ng·∫´u nhi√™n trong m√¥i tr∆∞·ªùng v√† c√°c l·ªói nh·ªè khi ∆∞·ªõc t√≠nh, t√°c nh√¢n c√≥ th·ªÉ ƒë√°nh gi√° qu√° cao gi√° tr·ªã Q c·ªßa m·ªôt s·ªë h√†nh ƒë·ªông.\nC√¥ng th·ª©c c·∫≠p nh·∫≠t Q-learning:\n$$ [ Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left( r + \\gamma \\max_a Q(s\u0026rsquo;, a\u0026rsquo;) - Q(s, a) \\right) ] $$\nTrong ƒë√≥, ( \\max_a Q(s\u0026rsquo;, a\u0026rsquo;) ) ch·ªçn h√†nh ƒë·ªông c√≥ gi√° tr·ªã Q cao nh·∫•t cho tr·∫°ng th√°i ti·∫øp theo ( s\u0026rsquo; ). Vi·ªác s·ª≠ d·ª•ng c√πng m·ªôt m·∫°ng ƒë·ªÉ ch·ªçn v√† ƒë√°nh gi√° h√†nh ƒë·ªông n√†y c√≥ th·ªÉ d·∫´n ƒë·∫øn thi√™n l·ªách khi c√°c gi√° tr·ªã Q b·ªã ph√≥ng ƒë·∫°i m·ªôt c√°ch kh√¥ng ch√≠nh x√°c.\n2. C·∫£i ti·∫øn c·ªßa Double Deep Q-Network (DDQN): DDQN ƒë∆∞·ª£c ph√°t tri·ªÉn ƒë·ªÉ kh·∫Øc ph·ª•c v·∫•n ƒë·ªÅ thi√™n l·ªách ∆∞·ªõc l∆∞·ª£ng qu√° m·ª©c trong Q-learning/DQN b·∫±ng c√°ch t√°ch bi·ªát vi·ªác ch·ªçn h√†nh ƒë·ªông v√† ƒë√°nh gi√° gi√° tr·ªã c·ªßa h√†nh ƒë·ªông. Trong DDQN, hai m·∫°ng n∆°-ron kh√°c nhau ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ th·ª±c hi·ªán hai nhi·ªám v·ª• n√†y:\nM·∫°ng ch√≠nh (main network): ƒê∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ch·ªçn h√†nh ƒë·ªông t·ªët nh·∫•t cho tr·∫°ng th√°i ti·∫øp theo. M·∫°ng m·ª•c ti√™u (target network): ƒê∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ∆∞·ªõc t√≠nh gi√° tr·ªã c·ªßa h√†nh ƒë·ªông ƒë√≥. C√¥ng th·ª©c c·∫≠p nh·∫≠t DDQN:\n$$ [ Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left( r + \\gamma Q_{\\text{target}}(s\u0026rsquo;, \\arg\\max_a Q_{\\text{main}}(s\u0026rsquo;, a\u0026rsquo;)) - Q(s, a) \\right) ] $$\nTrong ƒë√≥:\n( Q_{\\text{main}}(s\u0026rsquo;, a\u0026rsquo;) ): M·∫°ng ch√≠nh ƒë∆∞·ª£c d√πng ƒë·ªÉ ch·ªçn h√†nh ƒë·ªông t·ªët nh·∫•t t·∫°i tr·∫°ng th√°i ( s\u0026rsquo; ) (t·ª©c l√† h√†nh ƒë·ªông c√≥ gi√° tr·ªã Q cao nh·∫•t).\n( Q_{\\text{target}}(s\u0026rsquo;, a\u0026rsquo;) ): M·∫°ng m·ª•c ti√™u ƒë∆∞·ª£c d√πng ƒë·ªÉ ƒë√°nh gi√° gi√° tr·ªã Q c·ªßa h√†nh ƒë·ªông ƒë√≥.\n√ù t∆∞·ªüng ch√≠nh: B·∫±ng c√°ch s·ª≠ d·ª•ng hai m·∫°ng ri√™ng bi·ªát (m·ªôt ƒë·ªÉ ch·ªçn h√†nh ƒë·ªông, m·ªôt ƒë·ªÉ ƒë√°nh gi√°), DDQN tr√°nh ƒë∆∞·ª£c vi·ªác ph√≥ng ƒë·∫°i gi√° tr·ªã Q do c√πng m·ªôt m·∫°ng ch·ªçn v√† ƒë√°nh gi√° h√†nh ƒë·ªông trong Q-learning/DQN ti√™u chu·∫©n. ƒêi·ªÅu n√†y gi√∫p gi·∫£m thi√™n l·ªách v√† c·∫£i thi·ªán hi·ªáu qu·∫£ h·ªçc t·∫≠p.\n3. L·ª£i √≠ch c·ªßa DDQN so v·ªõi DQN/Q-learning: Gi·∫£m thi√™n l·ªách ∆∞·ªõc l∆∞·ª£ng (Overestimation Bias): DDQN c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c c·ªßa ∆∞·ªõc t√≠nh gi√° tr·ªã Q b·∫±ng c√°ch t√°ch r·ªùi nhi·ªám v·ª• ch·ªçn v√† ƒë√°nh gi√° h√†nh ƒë·ªông. H·ªçc t·∫≠p ·ªïn ƒë·ªãnh h∆°n: Vi·ªác gi·∫£m thi√™n l·ªách gi√∫p DDQN ·ªïn ƒë·ªãnh h∆°n trong qu√° tr√¨nh h·ªçc t·∫≠p, ƒë·∫∑c bi·ªát khi c√°c t√°c nh√¢n t∆∞∆°ng t√°c v·ªõi nh·ªØng m√¥i tr∆∞·ªùng ph·ª©c t·∫°p v√† ng·∫´u nhi√™n. C·∫£i thi·ªán ƒë·ªô h·ªôi t·ª• (Convergence): Do c√°c gi√° tr·ªã Q kh√¥ng b·ªã ph√≥ng ƒë·∫°i m·ªôt c√°ch sai l·∫ßm, qu√° tr√¨nh h·ªçc t·∫≠p c·ªßa t√°c nh√¢n tr·ªü n√™n hi·ªáu qu·∫£ v√† nhanh h∆°n, gi√∫p h·ªá th·ªëng h·ªôi t·ª• v·ªÅ gi·∫£i ph√°p t·ªët h∆°n. 4. V√≠ d·ª• tr·ª±c quan v·ªÅ s·ª± kh√°c bi·ªát: DQN: N·∫øu c√≥ hai h√†nh ƒë·ªông A v√† B, v√† DQN ƒë√°nh gi√° h√†nh ƒë·ªông A c√≥ gi√° tr·ªã Q l√† 10 (th·ª±c t·∫ø l√† 8) v√† B l√† 9 (th·ª±c t·∫ø l√† 7), DQN s·∫Ω ch·ªçn A v√¨ $( \\max(10, 9) = 10 )$. Tuy nhi√™n, gi√° tr·ªã th·ª±c c·ªßa A ch·ªâ l√† 8, d·∫´n ƒë·∫øn ƒë√°nh gi√° sai. DDQN: Trong DDQN, m·∫°ng ch√≠nh s·∫Ω ch·ªçn A, nh∆∞ng m·∫°ng m·ª•c ti√™u s·∫Ω ƒë√°nh gi√° A d·ª±a tr√™n gi√° tr·ªã th·ª±c t·∫ø c·ªßa n√≥, l√†m gi·∫£m kh·∫£ nƒÉng ph√≥ng ƒë·∫°i gi√° tr·ªã v√† gi√∫p l·ª±a ch·ªçn ch√≠nh x√°c h∆°n. 5. T√≥m t·∫Øt: Q-learning/DQN: Ch·ªâ d√πng m·ªôt m·∫°ng ƒë·ªÉ ch·ªçn v√† ƒë√°nh gi√°, d·ªÖ g·∫∑p t√¨nh tr·∫°ng ∆∞·ªõc l∆∞·ª£ng qu√° cao (overestimation). DDQN: T√°ch bi·ªát vi·ªác ch·ªçn v√† ƒë√°nh gi√° h√†nh ƒë·ªông, gi√∫p gi·∫£m thi√™n l·ªách v√† c·∫£i thi·ªán qu√° tr√¨nh h·ªçc t·∫≠p. II. Th·ª±c h√†nh v·ªõi ch∆∞∆°ng tr√¨nh mario ·ªû b√†i th·ª±c h√†nh n√†y, m√¨nh k·∫ø th·ª´a code t·ª´ blog ch√≠nh ch·ªß c·ªßa pytorch\nTrain tr√≤ ch∆°i mario s·ª≠ d·ª•ng Reinforcement Learning\nc√°c nguy√™n li·ªáu c·∫ßn thi·∫øt\n1pip install gym==0.22.0 --update 2pip install gym-super-mario-bros==7.4.0 3pip install tensordict==0.3.0 4pip install torchrl==0.3.0 C√°c b·∫°n l∆∞u √Ω s·ª≠ d·ª•ng ƒë√∫ng phi√™n b·∫£n ƒë·ªÉ kh·ªèi b·ªã l·ªói\nEnvironment Kh·ªüi t·∫°o m√¥i tr∆∞·ªùng Trong tr√≤ ch∆°i mario, ch√∫ng ta c√≥ nhi·ªÅu ƒë·ªëi t∆∞·ª£ng khi ch∆°i, l√† c√¢y n·∫•m , c√°c ·ªëng tr·ª• m√†u xanh, c√°c vi√™n g·∫°ch \u0026hellip;\nKhi ch√∫ng ta th·ª±c hi·ªán m·ªôt h√†nh ƒë·ªông ( ·∫•n n√∫t tr√™n Joypad ), tr√≤ ch∆°i s·∫Ω ph·∫£n h·ªìi l·∫°i next_state l√† h√¨nh ·∫£nh c·ªßa khung h√¨nh sau khi ta nh·∫•n n√∫t, reward, done, info\n1 2env = gym_super_mario_bros.make(\u0026#34;SuperMarioBros-1-1-v0\u0026#34;) 3 4# Limit the action-space to 5# 0. walk right 6# 1. jump right 7env = JoypadSpace(env, [[\u0026#34;right\u0026#34;], [\u0026#34;right\u0026#34;, \u0026#34;A\u0026#34;]]) 8 9env.reset() 10next_state, reward, done, info = env.step(action=0) 11print(f\u0026#34;{next_state.shape},\\n {reward},\\n {done},\\n {info}\u0026#34;) 12 13 14(240, 256, 3), 15 0.0, 16 False, 17 {\u0026#39;coins\u0026#39;: 0, \u0026#39;flag_get\u0026#39;: False, \u0026#39;life\u0026#39;: 2, \u0026#39;score\u0026#39;: 0, \u0026#39;stage\u0026#39;: 1, \u0026#39;status\u0026#39;: \u0026#39;small\u0026#39;, \u0026#39;time\u0026#39;: 400, \u0026#39;world\u0026#39;: 1, \u0026#39;x_pos\u0026#39;: 40, \u0026#39;y_pos\u0026#39;: 79} X·ª≠ l√Ω d·ªØ li·ªáu D·ªØ li·ªáu c·ªßa state l√† m·ªôt h√¨nh c√≥ k√≠ch th∆∞·ªõc (240, 256, 3) , h·ªá bgr, ch√∫ng ta s·∫Ω convert v·ªÅ GrayScale (1 ,240, 256) v√† resize v·ªÅ h√¨nh vu√¥ng c√≥ k√≠ch th∆∞·ªõc 84x84 ƒë·ªÉ tƒÉng th·ªùi gian x·ª≠ l√Ω . C√°c b·∫°n c√≥ th·ªÉ thay ƒë·ªïi th√†nh 112x112 ho·∫∑c 96x96 t√πy th√≠ch.\nNgo√†i ra, do h√¨nh tr∆∞·ªõc khi ·∫•n v√† h√¨nh sau khi ·∫•n n√∫t th∆∞·ªùng s·∫Ω g·∫ßn g·∫ßn gi·ªëng nhau, n√™n ch√∫ng ta s·∫Ω th√™m m·ªôt l·ªõp SkipFrame, hi·ªÉu ƒë√∫ng nh∆∞ t√™n, ch√∫ng ta s·∫Ω c·ªông d·ªìn gi√° tr·ªã reward ƒë·ªÉ tr·∫£ ra cho m√¥ h√¨nh th·ª±c hi·ªán c·∫≠p nh·∫≠t tr·ªçng s·ªë. V√≠ d·ª• SkipFrame(4), nghƒ©a l√† ta s·∫Ω c·ªông d·ªìn gi√° tr·ªã reward c·ªßa 4 h√¨nh li√™n ti·∫øp th√†nh t·ªïng reward v√† c·∫≠p nh·∫≠t tr·ªçng s·ªë, c√°i n√†y gi√∫p cho m√¥ h√¨nh ch·∫°y nhanh h∆°n x√≠u m√† v·∫´n ƒë·∫£m b·∫£o th√¥ng tin, t·∫•t nhi√™n s·ªë l∆∞·ª£ng frame b·ªã skip c·∫ßn be b√© th√¥i\nCh√∫ng ta s·∫Ω t·∫°o c√°c l·ªõp , implement t·ª´ gym.Wrapper\n1 2class SkipFrame(gym.Wrapper): 3 def __init__(self, env, skip): 4 \u0026#34;\u0026#34;\u0026#34;Return only every `skip`-th frame\u0026#34;\u0026#34;\u0026#34; 5 super().__init__(env) 6 self._skip = skip 7 8 def step(self, action): 9 \u0026#34;\u0026#34;\u0026#34;Repeat action, and sum reward\u0026#34;\u0026#34;\u0026#34; 10 total_reward = 0.0 11 for i in range(self._skip): 12 # Accumulate reward and repeat the same action 13 obs, reward, done, trunk, info = self.env.step(action) 14 total_reward += reward 15 if done: 16 break 17 return obs, total_reward, done, trunk, info 18 19 20class GrayScaleObservation(gym.ObservationWrapper): 21 def __init__(self, env): 22 super().__init__(env) 23 obs_shape = self.observation_space.shape[:2] 24 self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8) 25 26 def permute_orientation(self, observation): 27 # permute [H, W, C] array to [C, H, W] tensor 28 observation = np.transpose(observation, (2, 0, 1)) 29 observation = torch.tensor(observation.copy(), dtype=torch.float) 30 return observation 31 32 def observation(self, observation): 33 observation = self.permute_orientation(observation) 34 transform = T.Grayscale() 35 observation = transform(observation) 36 return observation 37 38 39class ResizeObservation(gym.ObservationWrapper): 40 def __init__(self, env, shape): 41 super().__init__(env) 42 if isinstance(shape, int): 43 self.shape = (shape, shape) 44 else: 45 self.shape = tuple(shape) 46 47 obs_shape = self.shape + self.observation_space.shape[2:] 48 self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8) 49 50 def observation(self, observation): 51 transforms = T.Compose( 52 [T.Resize(self.shape, antialias=True), T.Normalize(0, 255)] 53 ) 54 observation = transforms(observation).squeeze(0) 55 return observation 56 57 58# Apply Wrappers to environment 59env = SkipFrame(env, skip=4) 60env = GrayScaleObservation(env) 61env = ResizeObservation(env, shape=84) 62 63env = FrameStack(env, num_stack=4) Cu·ªëi c√πng, ch√∫ng ta s·∫Ω ƒë√≥ng c√°c khai b√°o tr√™n v√†o m·ªôt FrameStack v·ªõi s·ªë l∆∞·ª£ng l·ªõp l√† 4, nghƒ©a l√† ch√∫ng ta s·∫Ω ƒë∆∞a v√†o 4 h√¨nh c√≥ k√≠ch th∆∞·ªõc (240, 256, 3), k·∫øt qu·∫£ l√† h√¨nh c√≥ k√≠ch th∆∞∆°c (4, 84, 84)\nAgent Ch√∫ng ta ch∆°i mario, n√™n t·∫°o 1 Agent t√™n l√† mario , theo l√Ω thuy·∫øt, ch√∫ng ta s·∫Ω c√≥ c√°c h√†nh ƒë·ªông cho agent\nAct : Tr·∫£ v·ªÅ 1 h√†nh ƒë·ªông t·ªëi ∆∞u , trong danh s√°ch c√°c h√†nh ƒë·ªông d·ª±a tr√™n h√¨nh ·∫£nh hi·ªánt t·∫°i\nRemember experiences. Experience = (current state, current action, reward, next state). Mario s·∫Ω l∆∞u l·∫°i c√°c h√†nh ƒë·ªông (cache) v√† nh·ªõ l·∫°i c√°c h√†nh ƒë·ªông c·ªßa m√¨nh ƒë·ªÉ r√∫t ra b√†i h·ªçc\nLearn: C·∫≠p nh·∫≠t tr·ªçng s·ªë\n1 2class Mario: 3 def __init__(): 4 pass 5 6 def act(self, state): 7 \u0026#34;\u0026#34;\u0026#34;Given a state, choose an epsilon-greedy action\u0026#34;\u0026#34;\u0026#34; 8 pass 9 10 def cache(self, experience): 11 \u0026#34;\u0026#34;\u0026#34;Add the experience to memory\u0026#34;\u0026#34;\u0026#34; 12 pass 13 14 def recall(self): 15 \u0026#34;\u0026#34;\u0026#34;Sample experiences from memory\u0026#34;\u0026#34;\u0026#34; 16 pass 17 18 def learn(self): 19 \u0026#34;\u0026#34;\u0026#34;Update online action value (Q) function with a batch of experiences\u0026#34;\u0026#34;\u0026#34; 20 pass Act Khi ch∆°i mario, h√†nh ƒë·ªông ch√∫ng ta s·∫Ω th·ª±c hi·ªán s·∫Ω l√† l·∫•y ng·∫´u nhi√™n 1 h√†nh ƒë·ªông trong t·∫≠p l·ªánh (explore), ho·∫∑c l√† th·ª±c hi·ªán l·ªánh t·ªëi ∆∞u do m√¥ h√¨nh g·ª£i √Ω (exploit). ƒê·ªÉ ƒë·∫°t ƒë∆∞·ª£c t√≠nh nƒÉng n√†y, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng exploration_rate ƒë·ªÉ ƒëi·ªÅu khi·ªÉn x√°c xu·∫•t ch·ªçn explore hay exploit.\nNgo√†i ra, do l√† m√¥ h√¨nh AI, n√™n ch√∫ng ta c·∫ßn x√¢y d·ª±ng m·ªôt l·ªõp CNN t√™n l√† MarioNet ƒë·ªÉ h√†m learn c·∫≠p nh·∫≠t tr·ªçng s·ªë\n1 2class Mario: 3 def __init__(self, state_dim, action_dim, save_dir): 4 self.state_dim = state_dim 5 self.action_dim = action_dim 6 self.save_dir = save_dir 7 8 self.device = \u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34; 9 10 # Mario\u0026#39;s DNN to predict the most optimal action - we implement this in the Learn section 11 self.net = MarioNet(self.state_dim, self.action_dim).float() 12 self.net = self.net.to(device=self.device) 13 14 self.exploration_rate = 1 15 self.exploration_rate_decay = 0.99999975 16 self.exploration_rate_min = 0.1 17 self.curr_step = 0 18 19 self.save_every = 5e5 # no. of experiences between saving Mario Net 20 21 def act(self, state): 22 \u0026#34;\u0026#34;\u0026#34; 23 Given a state, choose an epsilon-greedy action and update value of step. 24 25 Inputs: 26 state(``LazyFrame``): A single observation of the current state, dimension is (state_dim) 27 Outputs: 28 ``action_idx`` (``int``): An integer representing which action Mario will perform 29 \u0026#34;\u0026#34;\u0026#34; 30 # EXPLORE 31 if np.random.rand() \u0026lt; self.exploration_rate: 32 action_idx = np.random.randint(self.action_dim) 33 34 # EXPLOIT 35 else: 36 state = state[0].__array__() if isinstance(state, tuple) else state.__array__() 37 state = torch.tensor(state, device=self.device).unsqueeze(0) 38 action_values = self.net(state, model=\u0026#34;online\u0026#34;) 39 action_idx = torch.argmax(action_values, axis=1).item() 40 41 # decrease exploration_rate 42 self.exploration_rate *= self.exploration_rate_decay 43 self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate) 44 45 # increment step 46 self.curr_step += 1 47 return action_idx Remember Ph·∫ßn n√†y g·ªìm 2 h√†m l√† cache v√† recall. cache, hi·ªÉu ƒë√∫ng nh∆∞ t√™n, l√† l∆∞u l·∫°i c√°c gi√° tr·ªã state, next_state, action, reward, done. recall l√† l·∫•y c√°c gi√° tr·ªã ƒë√£ ƒë∆∞·ª£c nh·ªõ ra\n1 2class Mario(Mario): # subclassing for continuity 3 def __init__(self, state_dim, action_dim, save_dir): 4 super().__init__(state_dim, action_dim, save_dir) 5 self.memory = TensorDictReplayBuffer(storage=LazyMemmapStorage(100000, device=torch.device(\u0026#34;cpu\u0026#34;))) 6 self.batch_size = 32 7 8 def cache(self, state, next_state, action, reward, done): 9 \u0026#34;\u0026#34;\u0026#34; 10 Store the experience to self.memory (replay buffer) 11 12 Inputs: 13 state (``LazyFrame``), 14 next_state (``LazyFrame``), 15 action (``int``), 16 reward (``float``), 17 done(``bool``)) 18 \u0026#34;\u0026#34;\u0026#34; 19 def first_if_tuple(x): 20 return x[0] if isinstance(x, tuple) else x 21 state = first_if_tuple(state).__array__() 22 next_state = first_if_tuple(next_state).__array__() 23 24 state = torch.tensor(state) 25 next_state = torch.tensor(next_state) 26 action = torch.tensor([action]) 27 reward = torch.tensor([reward]) 28 done = torch.tensor([done]) 29 30 # self.memory.append((state, next_state, action, reward, done,)) 31 self.memory.add(TensorDict({\u0026#34;state\u0026#34;: state, \u0026#34;next_state\u0026#34;: next_state, \u0026#34;action\u0026#34;: action, \u0026#34;reward\u0026#34;: reward, \u0026#34;done\u0026#34;: done}, batch_size=[])) 32 33 def recall(self): 34 \u0026#34;\u0026#34;\u0026#34; 35 Retrieve a batch of experiences from memory 36 \u0026#34;\u0026#34;\u0026#34; 37 batch = self.memory.sample(self.batch_size).to(self.device) 38 state, next_state, action, reward, done = (batch.get(key) for key in (\u0026#34;state\u0026#34;, \u0026#34;next_state\u0026#34;, \u0026#34;action\u0026#34;, \u0026#34;reward\u0026#34;, \u0026#34;done\u0026#34;)) 39 return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze() Learn ·ªû ph·∫ßn init tr√™n, ch√∫ng ta c√≥ c√°i khai b√°o MarioNet, ·ªü ƒë√¢y, ch√∫ng ta s·ª≠ d·ª•ng m√¥ h√¨nh DDQN - Double Q-learning https://arxiv.org/pdf/1509.06461\nDDQN s·ª≠ d·ª•ng hai CNN ƒë·∫∑t t√™n l√† Q_online v√† Q_target. Hai m√¥ h√¨nh cnn n√†y ƒë·ªôc l·∫≠p v·ªõi nhau\nCh√∫ng ta s·∫Ω chia s·∫Ω chung features c·ªßa Q_online v√† Q_target, nh∆∞ng FC classifiers s·∫Ω ƒë·ªôc l·∫≠p nhau, c√°c gi√° tr·ªã tr·ªçng s·ªë c·ªßa Q_target s·∫Ω b·ªã frozen ƒë·ªÉ ngƒÉng c·∫≠p nh·∫≠t tr·ªçng s·ªë t·ª´ backprop\n1 2class MarioNet(nn.Module): 3 \u0026#34;\u0026#34;\u0026#34;mini CNN structure 4 input -\u0026gt; (conv2d + relu) x 3 -\u0026gt; flatten -\u0026gt; (dense + relu) x 2 -\u0026gt; output 5 \u0026#34;\u0026#34;\u0026#34; 6 7 def __init__(self, input_dim, output_dim): 8 super().__init__() 9 c, h, w = input_dim 10 11 if h != 84: 12 raise ValueError(f\u0026#34;Expecting input height: 84, got: {h}\u0026#34;) 13 if w != 84: 14 raise ValueError(f\u0026#34;Expecting input width: 84, got: {w}\u0026#34;) 15 16 self.online = self.__build_cnn(c, output_dim) 17 18 self.target = self.__build_cnn(c, output_dim) 19 self.target.load_state_dict(self.online.state_dict()) 20 21 # Q_target parameters are frozen. 22 for p in self.target.parameters(): 23 p.requires_grad = False 24 25 def forward(self, input, model): 26 if model == \u0026#34;online\u0026#34;: 27 return self.online(input) 28 elif model == \u0026#34;target\u0026#34;: 29 return self.target(input) 30 31 def __build_cnn(self, c, output_dim): 32 return nn.Sequential( 33 nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4), 34 nn.ReLU(), 35 nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2), 36 nn.ReLU(), 37 nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1), 38 nn.ReLU(), 39 nn.Flatten(), 40 nn.Linear(3136, 512), 41 nn.ReLU(), 42 nn.Linear(512, output_dim), 43 ) Estimate Do ch√∫ng ta c√≥ 2 l·ªõp cnn, n√™n ch√∫ng ta c·∫ßn x√¢y 2 h√†m Estimate\nV·ªõi Q_online, ch√∫ng ta th·ª±c hi·ªán infer, xong.\nV·ªõi Q_target, gi√° tr·ªã reward h∆°i ph·ª©c t·∫°p m·ªôt ch√∫t, ph√¢n t√≠ch ch√∫ng\nch√∫ng ta c√≥ gi√° tr·ªã reward hi·ªán t·∫°i\nCh√∫ng ta c·∫ßn k·∫øt h·ª£p v·ªõi reward c·ªßa Q_target, nh∆∞ng action th√¨ kh√¥ng bi·∫øt, v·∫≠y n√™n ch√∫ng ta s·∫Ω l·∫•y action t·ªëi ∆∞u t·ª´ Q_online v·ªõi state hi·ªán t·∫°i\n1 2class Mario(Mario): 3 def __init__(self, state_dim, action_dim, save_dir): 4 super().__init__(state_dim, action_dim, save_dir) 5 self.gamma = 0.9 6 7 def td_estimate(self, state, action): 8 current_Q = self.net(state, model=\u0026#34;online\u0026#34;)[ 9 np.arange(0, self.batch_size), action 10 ] # Q_online(s,a) 11 return current_Q 12 13 @torch.no_grad() 14 def td_target(self, reward, next_state, done): 15 next_state_Q = self.net(next_state, model=\u0026#34;online\u0026#34;) 16 best_action = torch.argmax(next_state_Q, axis=1) 17 next_Q = self.net(next_state, model=\u0026#34;target\u0026#34;)[ 18 np.arange(0, self.batch_size), best_action 19 ] 20 return (reward + (1 - done.float()) * self.gamma * next_Q).float() C·∫≠p nh·∫≠t model S·ª≠ d·ª•ng cnn, n√™n ch√∫ng ta c·∫ßn ƒë·ªãnh nghƒ©a l√† loss v√† h√†m optimizer, sau khi update tr·ªçng s·ªë c·ªßa Q_online, ch√∫ng ta s·∫Ω c·∫≠p nh·∫≠t tr·ªçng s·ªë ƒë√≥ cho Q_target\n1 2class Mario(Mario): 3 def __init__(self, state_dim, action_dim, save_dir): 4 super().__init__(state_dim, action_dim, save_dir) 5 self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025) 6 self.loss_fn = torch.nn.SmoothL1Loss() 7 8 def update_Q_online(self, td_estimate, td_target): 9 loss = self.loss_fn(td_estimate, td_target) 10 self.optimizer.zero_grad() 11 loss.backward() 12 self.optimizer.step() 13 return loss.item() 14 15 def sync_Q_target(self): 16 self.net.target.load_state_dict(self.net.online.state_dict()) Save checkpoint 1class Mario(Mario): 2 def save(self): 3 save_path = ( 4 self.save_dir / f\u0026#34;mario_net_{int(self.curr_step // self.save_every)}.chkpt\u0026#34; 5 ) 6 torch.save( 7 dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate), 8 save_path, 9 ) 10 print(f\u0026#34;MarioNet saved to {save_path} at step {self.curr_step}\u0026#34;) Gom v√†o h√†m learn 1 2class Mario(Mario): 3 def __init__(self, state_dim, action_dim, save_dir): 4 super().__init__(state_dim, action_dim, save_dir) 5 self.burnin = 1e4 # min. experiences before training 6 self.learn_every = 3 # no. of experiences between updates to Q_online 7 self.sync_every = 1e4 # no. of experiences between Q_target \u0026amp; Q_online sync 8 9 def learn(self): 10 if self.curr_step % self.sync_every == 0: 11 self.sync_Q_target() 12 13 if self.curr_step % self.save_every == 0: 14 self.save() 15 16 if self.curr_step \u0026lt; self.burnin: 17 return None, None 18 19 if self.curr_step % self.learn_every != 0: 20 return None, None 21 22 # Sample from memory 23 state, next_state, action, reward, done = self.recall() 24 25 # Get TD Estimate 26 td_est = self.td_estimate(state, action) 27 28 # Get TD Target 29 td_tgt = self.td_target(reward, next_state, done) 30 31 # Backpropagate loss through Q_online 32 loss = self.update_Q_online(td_est, td_tgt) 33 34 return (td_est.mean().item(), loss) Play Ch√∫ng ta th·ª±c hi·ªán learn 40000 l·∫ßn\n1 2use_cuda = torch.cuda.is_available() 3print(f\u0026#34;Using CUDA: {use_cuda}\u0026#34;) 4print() 5 6save_dir = Path(\u0026#34;checkpoints\u0026#34;) / datetime.datetime.now().strftime(\u0026#34;%Y-%m-%dT%H-%M-%S\u0026#34;) 7save_dir.mkdir(parents=True) 8 9mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir) 10 11logger = MetricLogger(save_dir) 12 13episodes = 40000 14for e in range(episodes): 15 16 state = env.reset() 17 18 # Play the game! 19 while True: 20 21 # Run agent on the state 22 action = mario.act(state) 23 24 # Agent performs action 25 next_state, reward, done, trunc, info = env.step(action) 26 27 # Remember 28 mario.cache(state, next_state, action, reward, done) 29 30 # Learn 31 q, loss = mario.learn() 32 33 # Logging 34 logger.log_step(reward, loss, q) 35 36 # Update state 37 state = next_state 38 39 # Check if end of game 40 if done or info[\u0026#34;flag_get\u0026#34;]: 41 break 42 43 logger.log_episode() 44 45 if (e % 20 == 0) or (e == episodes - 1): 46 logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step) Replay ·ªû h√†m n√†y, m√¨nh load model l√™n v√† cho auto ch∆°i, sau v√†i v√≤ng l·∫∑p c≈©ng s·∫Ω v·ªÅ ƒë√≠ch ƒë∆∞·ª£c :)\n·ªû ƒë√¢y, c√°c b·∫°n ch√∫ √Ω phi√™n b·∫£n gym 0.22.0, ·ªü b√†i vi·∫øt g·ªëc h·ªç x√†i gym 0.17.x n√™n kh√¥ng c√≥ h√†m save video, ph·∫£i t·ª± vi·∫øt l·∫°i, c√≤n c√°c b·∫£n cao h∆°n th√¨ h·ªç t√°ch r√µ bi·∫øn done c·ªßa env.step th√†nh 2 bi·∫øn n√™n n·∫øu b·∫°n n√†o x√†i code th√¨ s·∫Ω b·ªã l·ªói.\n1 2import random, datetime 3from pathlib import Path 4 5import gym 6import gym_super_mario_bros 7from gym.wrappers import FrameStack, GrayScaleObservation, TransformObservation 8from nes_py.wrappers import JoypadSpace 9 10from metrics import MetricLogger 11from agent import Mario 12from wrappers import ResizeObservation, SkipFrame 13 14 15word = 1 16state = 1 17env = gym_super_mario_bros.make(f\u0026#39;SuperMarioBros-{word}-{state}-v0\u0026#39;) 18 19 20 21env = JoypadSpace( 22 env, 23 [[\u0026#39;right\u0026#39;], 24 [\u0026#39;right\u0026#39;, \u0026#39;A\u0026#39;]] 25) 26 27env = SkipFrame(env, skip=4) 28env = GrayScaleObservation(env, keep_dim=False) 29env = ResizeObservation(env, shape=84) 30env = TransformObservation(env, f=lambda x: x / 255.) 31env = FrameStack(env, num_stack=4) 32env = gym.wrappers.RecordVideo(env=env, video_folder=\u0026#34;video\u0026#34;, name_prefix=f\u0026#34;mario_-{word}-{state}\u0026#34;) 33 34env.reset() 35 36 37 38# Start the recorder 39env.start_video_recorder() 40 41save_dir = Path(\u0026#39;checkpoints\u0026#39;) / \u0026#34;test\u0026#34; 42save_dir.mkdir(parents=True,exist_ok=True) 43 44checkpoint = Path(\u0026#39;checkpoints/2024-10-12T14-02-01/mario_net_15.chkpt\u0026#39;) 45mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir, checkpoint=checkpoint) 46mario.exploration_rate = mario.exploration_rate_min 47 48logger = MetricLogger(save_dir) 49 50episodes = 50 51 52for e in range(episodes): 53 54 state = env.reset() 55 56 while True: 57 58 env.render() 59 60 action = mario.act(state) 61 62 next_state, reward, done, info = env.step(action) 63 64 mario.cache(state, next_state, action, reward, done) 65 # print(next_state, reward, done, info) 66 67 logger.log_step(reward, None, None) 68 69 state = next_state 70 71 if done or info[\u0026#39;flag_get\u0026#39;]: 72 break 73 74 logger.log_episode() 75 76 if e % 20 == 0: 77 logger.record( 78 episode=e, 79 epsilon=mario.exploration_rate, 80 step=mario.curr_step 81 ) 82 83env.close_video_recorder() 84 85# Close the environment 86env.close() code ch√≠nh ch·ªß https://pytorch.org/tutorials/intermediate/mario_rl_tutorial.html\nK·∫øt qu·∫£ ƒê·ª£i t·∫ßm 48h khi ch·∫°y b·∫±ng GPU, m√¨nh train b·∫±ng RTX 4060 TI 16G, kh√° l√¢u\nN·∫øu train v·ªõi ph·∫ßn c·ª©ng m·∫°nh h∆°n, nh∆∞ RTX 4090, ho·∫∑c A100, ho·∫∑c ƒë·ªïi m·ªôt model m·∫°nh h∆°n nh∆∞ Proximal Policy Optimizatio, s·∫Ω nhanh h∆°n\nModel tr√™n m√¨nh train v·ªõi level 1, ƒë·ªÉ ch·∫°y auto cho level 2,3\u0026hellip; 32, m√¨nh ph·∫£i ch·∫°y 32 l·∫ßn train t∆∞∆°ng ·ª©ng cho m·ªói level.\nM√¨nh th·ª≠ ƒë·ªÉ model ch·∫°y th·ª≠ cho level 2,3 nh∆∞ng kh√¥ng v·ªÅ ƒë√≠ch ƒë∆∞·ª£c, ph·∫£i train l·∫°i\nYour browser does not support the video tag. Ph·∫ßn ti·∫øp theo, m√¨nh s·∫Ω train th·ª≠ model PPO thay DDQN\nIII. Tham kh·∫£o https://arxiv.org/pdf/1509.06461\nhttps://www.geeksforgeeks.org/what-is-reinforcement-learning/\nhttps://pytorch.org/tutorials/intermediate/mario_rl_tutorial.html\nhttps://github.com/yfeng997/MadMario\nhttps://towardsdatascience.com/reinforcement-learning-101-e24b50e1d292\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt. Xin c·∫£m ∆°n v√† h·∫πn g·∫∑p l·∫°i.\n","date":"Oct 27, 2024","img":"https://unsplash.it/1920/1080?image=1","permalink":"/blog/2024-10-27-mario-reinfomation-learning-double-dqn/","series":null,"tags":["Reinformation Learning","DeepLearning"],"title":"S·ª≠ D·ª•ng M√¥ H√¨nh Double DQN  Hu·∫•n Luy·ªán M√¥ H√¨nh Reinforcement Learning V·ªõi Game Mario"},{"categories":null,"content":" Hashing l√† g√¨? Consistent Hashing l√† g√¨? ·ª®ng d·ª•ng c·ªßa Consistent Hashing Implement Consistent Hashing ∆Øu v√† nh∆∞·ª£c ƒëi·ªÉm c·ªßa Consistent Hashing Hashing l√† g√¨? Hasing, ti·∫øng vi·ªát c√≥ th·ªÉ d·ªãch l√† \u0026ldquo;bƒÉm\u0026rdquo; l√† qu√° tr√¨nh ch√∫ng ta ƒë∆∞a m·ªôt chu·ªói v√†o m·ªôt h√†m bƒÉm v√† bƒÉm n√≥ ra, r·ªìi n√©n n√≥ l·∫°i trong m·ªôt v√πng kh√¥ng gian, thu ƒë∆∞·ª£c v·ªã tr√≠ c·ªßa chu·ªói ƒë·∫ßu v√†o trong v√πng kh√¥ng gian n√©n ƒë√≥.\nC√¥ng th·ª©c bi·ªÉu di·ªÖn\n1 2vi_tri = ham_bam(dau_vao)%kich_thuoc_khong_gian V√≠ d·ª•:\n1 2Gi·∫£ s·ª≠ ch√∫ng ta c√≥ k√≠ch th∆∞·ªõc kh√¥ng gian kich_thuoc_khong_gian = 10 3 4Ch√∫ng ta mu·ªën l∆∞u tr·ªØ chu·ªói ƒë·∫ßu v√†o l√† dau_vao = \u0026#34;Hello\u0026#34; 5 6S·ª≠ d·ª•ng h√†m bƒÉm ham_bam(\u0026#34;Hello\u0026#34;) ra k·∫øt qu·∫£ l√† 16 7 8ta c√≥ vi_tri = ham_bam(\u0026#34;Hello\u0026#34;) % 10 = 16 % 10 = 6 9 10V·∫≠y chu·ªói d·ªØ li·ªáu \u0026#34;Hello\u0026#34; s·∫Ω ƒë∆∞·ª£c l∆∞u tr·ªØ t·∫°i v·ªã tr√≠ 6 trong kh√¥ng gian nh·ªõ size 10. Qu√° tr√¨nh n√†y cho ph√©p ch√∫ng ta bi·∫øn m·ªôt chu·ªói d·ªØ li·ªáu th√†nh m·ªôt v·ªã tr√≠ trong kh√¥ng gian nh·ªõ, gi√∫p cho vi·ªác l∆∞u tr·ªØ v√† truy xu·∫•t d·ªØ li·ªáu tr·ªü n√™n hi·ªáu qu·∫£ h∆°n.\nConsistent Hashing l√† g√¨? Consistent Hashing (bƒÉm nh·∫•t qu√°n) l√† k·ªπ thu·∫≠t ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ph√¢n ph·ªëi c√°c kho√° (key) ƒë·ªÅu tr√™n c√°c c·ª•m m√°y t√≠nh (clusters), m·ª•c ti√™u l√† gi·∫£m thi·ªÉu s·ªë l∆∞·ª£ng c√°c kho√° c·∫ßn di chuy·ªÉn khi th√™m nodes ho·∫∑c xo√° nodes ( xo√° trong tr∆∞·ªùng h·ª£p l·ªói , th√™m trong tr∆∞·ªùng h·ª£p mu·ªën scale h·ªá th·ªëng), gi·∫£m s·ªë l∆∞·ª£ng c√°c kho√° c·∫ßn di chuy·ªÉn g√≥p ph·∫ßn l√†m ·ªïn ƒë·ªãnh h·ªá th·ªëng, v√† gi·∫£m t√°c ƒë·ªông ti√™u c·ª±c c·ªßa s·ª± thay ƒë·ªïi n√†y l√™n h·ªá th·ªëng\nM·ª•c ti√™u:\nPh√¢n ph·ªëi c√°c kh√≥a (keys) ƒë·ªÅu tr√™n m·ªôt c·ª•m c√°c n√∫t (nodes) trong h·ªá th·ªëng.\nGi·∫£m thi·ªÉu s·ªë l∆∞·ª£ng kh√≥a c·∫ßn di chuy·ªÉn khi th√™m ho·∫∑c x√≥a n√∫t kh·ªèi c·ª•m.\nC·∫•u tr√∫c:\nS·ª≠ d·ª•ng m·ªôt v√≤ng ·∫£o (hashring) ƒë·ªÉ bi·ªÉu di·ªÖn c√°c y√™u c·∫ßu c·ªßa server/clients v√† c√°c server nodes.\nS·ªë l∆∞·ª£ng v·ªã tr√≠ tr√™n v√≤ng kh√¥ng c·ªë ƒë·ªãnh, nh∆∞ng ƒë∆∞·ª£c coi l√† c√≥ v√¥ s·ªë ƒëi·ªÉm.\nC√°c n√∫t m√°y ch·ªß c√≥ th·ªÉ ƒë∆∞·ª£c ƒë·∫∑t t·∫°i c√°c v·ªã tr√≠ ng·∫´u nhi√™n tr√™n v√≤ng b·∫±ng c√°ch s·ª≠ d·ª•ng h√†m bƒÉm (hashing).\nC√°c y√™u c·∫ßu (requests) t·ª´ ng∆∞·ªùi d√πng, m√°y t√≠nh ho·∫∑c ch∆∞∆°ng tr√¨nh kh√¥ng c√≥ m√°y ch·ªß c≈©ng ƒë∆∞·ª£c ƒë·∫∑t tr√™n c√πng m·ªôt v√≤ng b·∫±ng c√°ch s·ª≠ d·ª•ng c√πng m·ªôt h√†m bƒÉm.\nL·ª£i √≠ch:\nKhi th√™m ho·∫∑c x√≥a n√∫t kh·ªèi c·ª•m, ch·ªâ c·∫ßn di chuy·ªÉn m·ªôt s·ªë nh·ªè kh√≥a ƒë·∫øn c√°c n√∫t kh√°c.\nGi·∫£m thi·ªÉu t√°c ƒë·ªông c·ªßa vi·ªác th√™m ho·∫∑c x√≥a n√∫t ƒë·∫øn to√†n b·ªô h·ªá th·ªëng.\nC·∫£i thi·ªán hi·ªáu su·∫•t v√† ƒë·ªô tin c·∫≠y c·ªßa h·ªá th·ªëng.\nC√°ch th·ª©c ho·∫°t ƒë·ªông:\nKhi m·ªôt y√™u c·∫ßu ƒë∆∞·ª£c g·ª≠i ƒë·∫øn h·ªá th·ªëng, n√≥ s·∫Ω ƒë∆∞·ª£c bƒÉm (hash) ƒë·ªÉ t·∫°o ra m·ªôt gi√° tr·ªã bƒÉm.\nGi√° tr·ªã bƒÉm n√†y s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x√°c ƒë·ªãnh v·ªã tr√≠ c·ªßa y√™u c·∫ßu tr√™n v√≤ng ·∫£o.\nH·ªá th·ªëng s·∫Ω t√¨m n√∫t m√°y ch·ªß g·∫ßn nh·∫•t v·ªõi v·ªã tr√≠ c·ªßa y√™u c·∫ßu tr√™n v√≤ng v√† g·ª≠i y√™u c·∫ßu ƒë·∫øn n√∫t ƒë√≥.\nN·∫øu n√∫t m√°y ch·ªß ƒë√≥ kh√¥ng kh·∫£ d·ª•ng, h·ªá th·ªëng s·∫Ω t√¨m n√∫t m√°y ch·ªß ti·∫øp theo tr√™n v√≤ng v√† g·ª≠i y√™u c·∫ßu ƒë·∫øn n√∫t ƒë√≥.\nK·ªπ thu·∫≠t Consistent Hashing gi√∫p ph√¢n ph·ªëi t·∫£i tr·ªçng ƒë·ªÅu tr√™n c√°c n√∫t m√°y ch·ªß v√† gi·∫£m thi·ªÉu t√°c ƒë·ªông c·ªßa vi·ªác th√™m ho·∫∑c x√≥a n√∫t ƒë·∫øn to√†n b·ªô h·ªá th·ªëng.\n·ª®ng d·ª•ng c·ªßa Consistent Hashing Ng√†y nay Consistent Hashing l√† m·ªôt k·ªπ thu·∫≠t ph·ªï bi·∫øn ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c h·ªá th·ªëng ph√¢n t√°n ƒë·ªÉ gi·∫£i quy·∫øt th√°ch th·ª©c ph√¢n ph·ªëi hi·ªáu qu·∫£ c√°c kh√≥a ho·∫∑c ph·∫ßn t·ª≠ d·ªØ li·ªáu tr√™n nhi·ªÅu n√∫t/m√°y ch·ªß trong m·ªôt m·∫°ng l∆∞·ªõi.\nB·∫±ng c√°ch s·ª≠ d·ª•ng Consistent Hashing, c√°c h·ªá th·ªëng ph√¢n t√°n c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c nhi·ªÅu l·ª£i √≠ch, bao g·ªìm:\nC·∫£i thi·ªán kh·∫£ nƒÉng m·ªü r·ªông: Consistent Hashing cho ph√©p c√°c h·ªá th·ªëng ph√¢n t√°n m·ªü r·ªông d·ªÖ d√†ng h∆°n, v√¨ c√°c n√∫t m·ªõi c√≥ th·ªÉ ƒë∆∞·ª£c th√™m ho·∫∑c x√≥a m√† kh√¥ng l√†m gi√°n ƒëo·∫°n to√†n b·ªô h·ªá th·ªëng.\nGi·∫£m thi·ªÉu chi ph√≠ √°nh x·∫° l·∫°i: B·∫±ng c√°ch gi·∫£m thi·ªÉu s·ªë l∆∞·ª£ng c√°c ph√©p √°nh x·∫° l·∫°i c·∫ßn thi·∫øt, Consistent Hashing gi√∫p gi·∫£m thi·ªÉu chi ph√≠ li√™n quan ƒë·∫øn vi·ªác th√™m ho·∫∑c x√≥a n√∫t, gi√∫p duy tr√¨ hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng.\nTƒÉng c∆∞·ªùng kh·∫£ nƒÉng ch·ªãu l·ªói: Consistent Hashing gi√∫p ph√¢n ph·ªëi c√°c ph·∫ßn t·ª≠ d·ªØ li·ªáu tr√™n nhi·ªÅu n√∫t, gi√∫p tƒÉng c∆∞·ªùng kh·∫£ nƒÉng ch·ªãu l·ªói c·ªßa h·ªá th·ªëng v√† gi·∫£m thi·ªÉu r·ªßi ro m·∫•t d·ªØ li·ªáu trong tr∆∞·ªùng h·ª£p n√∫t b·ªã l·ªói.\nC√¢n b·∫±ng t·∫£i t·ªët h∆°n: Consistent Hashing c√≥ th·ªÉ gi√∫p ph√¢n ph·ªëi t·∫£i tr√™n c√°c n√∫t m·ªôt c√°ch ƒë·ªìng ƒë·ªÅu h∆°n, gi√∫p c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng v√† gi·∫£m thi·ªÉu r·ªßi ro c√°c ƒëi·ªÉm n√≥ng.\nConsistent Hashing ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong c√°c h·ªá th·ªëng ph√¢n t√°n kh√°c nhau, bao g·ªìm:\nC∆° s·ªü d·ªØ li·ªáu ph√¢n t√°n: Consistent Hashing ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c c∆° s·ªü d·ªØ li·ªáu ph√¢n t√°n ƒë·ªÉ ph√¢n ph·ªëi c√°c ph·∫ßn t·ª≠ d·ªØ li·ªáu tr√™n nhi·ªÅu n√∫t v√† c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng.\nH·ªá th·ªëng l∆∞u tr·ªØ ƒë·ªám: Consistent Hashing ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c h·ªá th·ªëng l∆∞u tr·ªØ ƒë·ªám ƒë·ªÉ ph√¢n ph·ªëi c√°c ph·∫ßn t·ª≠ ƒë·ªám tr√™n nhi·ªÅu n√∫t v√† c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng.\nM·∫°ng l∆∞·ªõi ph√¢n ph·ªëi n·ªôi dung (CDN): Consistent Hashing ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c m·∫°ng l∆∞·ªõi ph√¢n ph·ªëi n·ªôi dung ƒë·ªÉ ph√¢n ph·ªëi n·ªôi dung tr√™n nhi·ªÅu n√∫t v√† c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng.\nH·ªá th·ªëng l∆∞u tr·ªØ ƒë√°m m√¢y: Consistent Hashing ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c h·ªá th·ªëng l∆∞u tr·ªØ ƒë√°m m√¢y ƒë·ªÉ ph√¢n ph·ªëi c√°c ph·∫ßn t·ª≠ d·ªØ li·ªáu tr√™n nhi·ªÅu n√∫t v√† c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng.\nT√≥m l·∫°i, Consistent Hashing l√† m·ªôt k·ªπ thu·∫≠t m·∫°nh m·∫Ω gi√∫p c√°c h·ªá th·ªëng ph√¢n t√°n ph√¢n ph·ªëi c√°c kh√≥a ho·∫∑c ph·∫ßn t·ª≠ d·ªØ li·ªáu tr√™n nhi·ªÅu n√∫t m·ªôt c√°ch hi·ªáu qu·∫£, gi·∫£m thi·ªÉu s·ªë l∆∞·ª£ng c√°c ph√©p √°nh x·∫° l·∫°i c·∫ßn thi·∫øt khi th√™m ho·∫∑c x√≥a n√∫t, v√† c·∫£i thi·ªán kh·∫£ nƒÉng m·ªü r·ªông, kh·∫£ nƒÉng ch·ªãu l·ªói v√† c√¢n b·∫±ng t·∫£i c·ªßa h·ªá th·ªëng.\nImplement Consistent Hashing ƒê·ªÉ tri·ªÉn khai m·ªôt h·ªá th·ªëng s·ª≠ d·ª•ng consistent hasing, ch√∫ng ta c·∫ßn x√°c ƒë·ªãnh 7 b∆∞·ªõc sau\nB∆∞·ªõc 1: Ch·ªçn h√†m bƒÉm\nCh·ªçn m·ªôt h√†m bƒÉm t·∫°o ra m·ªôt d·∫£i gi√° tr·ªã bƒÉm ph√¢n b·ªë ƒë·ªÅu. C√°c l·ª±a ch·ªçn ph·ªï bi·∫øn bao g·ªìm MD5, SHA-1 ho·∫∑c SHA-256. B∆∞·ªõc 2: ƒê·ªãnh nghƒ©a v√≤ng bƒÉm\nBi·ªÉu di·ªÖn d·∫£i gi√° tr·ªã bƒÉm nh∆∞ m·ªôt v√≤ng.\nV√≤ng n√†y n√™n bao ph·ªß to√†n b·ªô d·∫£i gi√° tr·ªã bƒÉm c√≥ th·ªÉ v√† ƒë∆∞·ª£c ph√¢n b·ªë ƒë·ªÅu.\nB∆∞·ªõc 3: G√°n n√∫t v√†o v√≤ng\nG√°n m·ªói n√∫t trong h·ªá th·ªëng m·ªôt v·ªã tr√≠ tr√™n v√≤ng bƒÉm.\nƒêi·ªÅu n√†y th∆∞·ªùng ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng c√°ch bƒÉm ƒë·ªãnh danh c·ªßa n√∫t b·∫±ng h√†m bƒÉm ƒë√£ ch·ªçn.\nB∆∞·ªõc 4: √Ånh x·∫° kh√≥a\nKhi c·∫ßn l∆∞u tr·ªØ ho·∫∑c truy xu·∫•t m·ªôt kh√≥a, bƒÉm kh√≥a b·∫±ng h√†m bƒÉm ƒë√£ ch·ªçn ƒë·ªÉ thu ƒë∆∞·ª£c gi√° tr·ªã bƒÉm.\nT√¨m v·ªã tr√≠ tr√™n v√≤ng bƒÉm n∆°i gi√° tr·ªã bƒÉm r∆°i v√†o.\nƒêi theo chi·ªÅu kim ƒë·ªìng h·ªì tr√™n v√≤ng ƒë·ªÉ t√¨m n√∫t ƒë·∫ßu ti√™n g·∫∑p ph·∫£i. N√∫t n√†y tr·ªü th√†nh n√∫t s·ªü h·ªØu kh√≥a.\nB∆∞·ªõc 5: Th√™m n√∫t\nKhi m·ªôt n√∫t m·ªõi ƒë∆∞·ª£c th√™m v√†o, t√≠nh to√°n v·ªã tr√≠ c·ªßa n√≥ tr√™n v√≤ng bƒÉm b·∫±ng h√†m bƒÉm.\nX√°c ƒë·ªãnh d·∫£i kh√≥a s·∫Ω ƒë∆∞·ª£c s·ªü h·ªØu b·ªüi n√∫t m·ªõi. ƒêi·ªÅu n√†y th∆∞·ªùng li√™n quan ƒë·∫øn vi·ªác t√¨m n√∫t ti·ªÅn nhi·ªám tr√™n v√≤ng.\nC·∫≠p nh·∫≠t v√≤ng ƒë·ªÉ bao g·ªìm n√∫t m·ªõi v√† √°nh x·∫° l·∫°i c√°c kh√≥a b·ªã ·∫£nh h∆∞·ªüng ƒë·∫øn n√∫t m·ªõi.\nB∆∞·ªõc 6: X√≥a n√∫t\nKhi m·ªôt n√∫t b·ªã x√≥a, x√°c ƒë·ªãnh v·ªã tr√≠ c·ªßa n√≥ tr√™n v√≤ng bƒÉm.\nX√°c ƒë·ªãnh d·∫£i kh√≥a s·∫Ω b·ªã ·∫£nh h∆∞·ªüng b·ªüi vi·ªác x√≥a n√∫t. ƒêi·ªÅu n√†y th∆∞·ªùng li√™n quan ƒë·∫øn vi·ªác t√¨m n√∫t k·∫ø ti·∫øp tr√™n v√≤ng.\nC·∫≠p nh·∫≠t v√≤ng ƒë·ªÉ lo·∫°i tr·ª´ n√∫t ƒë√£ x√≥a v√† √°nh x·∫° l·∫°i c√°c kh√≥a b·ªã ·∫£nh h∆∞·ªüng ƒë·∫øn n√∫t k·∫ø ti·∫øp.\nB∆∞·ªõc 7: C√¢n b·∫±ng t·∫£i\nƒê·ªãnh k·ª≥ ki·ªÉm tra t·∫£i tr√™n m·ªói n√∫t b·∫±ng c√°ch theo d√µi s·ªë l∆∞·ª£ng kh√≥a n√≥ s·ªü h·ªØu.\nN·∫øu c√≥ s·ª± m·∫•t c√¢n b·∫±ng, h√£y xem x√©t vi·ªác ph√¢n ph·ªëi l·∫°i m·ªôt s·ªë kh√≥a ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c s·ª± ph√¢n b·ªë ƒë·ªÅu h∆°n.\nD∆∞·ªõi d√¢y l√† code golang , coi nh∆∞ l√† demo example 7 b∆∞·ªõc tr√™n\n1 2package main 3 4import ( 5\t\u0026#34;crypto/md5\u0026#34; 6\t\u0026#34;fmt\u0026#34; 7\t\u0026#34;sort\u0026#34; 8\t\u0026#34;strconv\u0026#34; 9\t\u0026#34;sync\u0026#34; 10) 11 12type ConsistentHashRing struct { 13\tring map[uint64]string 14\tsortedKeys []uint64 15\treplicas int 16\tmu sync.RWMutex 17} 18 19func NewConsistentHashRing(replicas int) *ConsistentHashRing { 20\treturn \u0026amp;ConsistentHashRing{ 21\tring: make(map[uint64]string), 22\tsortedKeys: make([]uint64, 0), 23\treplicas: replicas, 24\t} 25} 26 27// B∆∞·ªõc 1: Ch·ªçn h√†m bƒÉm, ·ªü ƒë√¢y d√πng md5. 28 29func (chr *ConsistentHashRing) getHash(value string) uint64 { 30\thash := md5.Sum([]byte(value)) 31\tvar hashValue uint64 32\tfor i := 0; i \u0026lt; 8; i++ { 33\thashValue = (hashValue \u0026lt;\u0026lt; 8) | uint64(hash[i]) 34\t} 35\treturn hashValue 36} 37 38// B∆∞·ªõc 3: G√°n n√∫t v√†o v√≤ng. 39func (chr *ConsistentHashRing) assignNodesToRing() { 40\tsort.Slice(chr.sortedKeys, func(i, j int) bool { 41\treturn chr.sortedKeys[i] \u0026lt; chr.sortedKeys[j] 42\t}) 43} 44 45// B∆∞·ªõc 5: Th√™m n√∫t 46func (chr *ConsistentHashRing) AddNode(node string) { 47\tfor i := 0; i \u0026lt; chr.replicas; i++ { 48\treplicaKey := chr.getHash(node + \u0026#34;_\u0026#34; + strconv.Itoa(i)) 49\tchr.ring[replicaKey] = node 50\tchr.sortedKeys = append(chr.sortedKeys, replicaKey) 51 52\tfmt.Printf(\u0026#34;Added node: %s with hash: %d on replica %d\\n\u0026#34;, node, replicaKey, i) 53\t} 54\tchr.assignNodesToRing() 55} 56 57// B∆∞·ªõc 6: X√≥a n√∫t 58func (chr *ConsistentHashRing) RemoveNode(node string) { 59\tfor i := 0; i \u0026lt; chr.replicas; i++ { 60\treplicaKey := chr.getHash(node + \u0026#34;_\u0026#34; + strconv.Itoa(i)) 61\tdelete(chr.ring, replicaKey) 62\tchr.sortedKeys = removeUint64Slice(chr.sortedKeys, replicaKey) 63\t} 64} 65 66// B∆∞·ªõc 4: √Ånh x·∫° kh√≥a 67func (chr *ConsistentHashRing) KeyMap(key string) string { 68\tchr.mu.RLock() 69\tdefer chr.mu.RUnlock() 70 71\thashValue := chr.getHash(key) 72\tindex := sort.Search(len(chr.sortedKeys), func(i int) bool { 73\treturn chr.sortedKeys[i] \u0026gt;= hashValue 74\t}) 75 76\tif index == len(chr.sortedKeys) { 77\t// Wrap around to the beginning of the ring 78\treturn chr.ring[chr.sortedKeys[0]] 79\t} 80 81\treturn chr.ring[chr.sortedKeys[index]] 82} 83 84func removeUint64Slice(s []uint64, e uint64) []uint64 { 85\tfor i, a := range s { 86\tif a == e { 87\treturn append(s[:i], s[i+1:]...) 88\t} 89\t} 90\treturn s 91} 92 93// B∆∞·ªõc 7: C√¢n b·∫±ng t·∫£i 94// LoadBalancing ki·ªÉm tra t·∫£i tr√™n m·ªói n√∫t v√† ph√¢n ph·ªëi l·∫°i kh√≥a n·∫øu c·∫ßn 95func (chr *ConsistentHashRing) LoadBalancing() { 96\tchr.mu.Lock() 97\tdefer chr.mu.Unlock() 98 99\tnodeCount := make(map[string]int) 100\tfor _, node := range chr.ring { 101\tnodeCount[node]++ 102\t} 103 104\tavgCount := len(chr.ring) / len(nodeCount) 105\tfor node, count := range nodeCount { 106\tif count \u0026gt; avgCount { 107\t// Node n√†y c√≥ t·∫£i qu√° cao, ph√¢n ph·ªëi l·∫°i kh√≥a 108\tfmt.Printf(\u0026#34;Node %s c√≥ t·∫£i qu√° cao, ph√¢n ph·ªëi l·∫°i kh√≥a\\n\u0026#34;, node) 109\t// ... 110\t} 111\t} 112} 113 114func (chr *ConsistentHashRing) PrintMap(key string) { 115\tnode := chr.KeyMap(key) 116 117\tfmt.Printf(\u0026#34;The key \u0026#39;%s\u0026#39; is mapped to node: %s\\n\u0026#34;, key, node) 118} 119func main() { 120\thashRing := NewConsistentHashRing(3) 121 122\t// Add nodes to the ring 123\thashRing.AddNode(\u0026#34;sw_hn\u0026#34;) 124\thashRing.AddNode(\u0026#34;sw_dn\u0026#34;) 125\thashRing.AddNode(\u0026#34;sw_hcm\u0026#34;) 126 127\t// // Get the node for a key 128\t// key := \u0026#34;T√°c gi·∫£ Ph·∫°m Duy T√πng\u0026#34; 129\thashRing.PrintMap(\u0026#34;T√°c gi·∫£ Ph·∫°m Duy T√πng\u0026#34;) 130\thashRing.PrintMap(\u0026#34;Ng√†y c·∫≠p nh·∫≠t 08/09/2024\u0026#34;) 131\thashRing.PrintMap(\u0026#34;Ng√†y m∆∞a b√£o\u0026#34;) 132\thashRing.PrintMap(\u0026#34;Vi·∫øt v√†o ng√†y b√£o, T√™n c∆°n b√£o l√† Yagi\u0026#34;) 133\thashRing.PrintMap(\u0026#34;T√°c gi·∫£ Ph·∫°m Duy T√πng, C·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt\u0026#34;) 134\thashRing.LoadBalancing() 135 136} L∆∞u √Ω: code demo th√¥i, x√†i h√†m hash ƒë∆°n gi·∫£n, v√† s·ª≠ d·ª•ng t√¨m ki·∫øm nh·ªã ph√¢n ƒë·ªÉ t√¨m v·ªã tr√≠ c·ªßa ph·∫ßn t·ª≠ trong v√≤ng. Th·ª±c t·∫ø th√¨ ch·∫Øc kh√¥ng ai ch∆°i m·∫•y h√†m n√†y :)\nK·∫øt qu·∫£:\n1\u0026gt;\u0026gt;\u0026gt;\u0026gt; go run consistent_hashing.go 2 3Added node: sw_hn with hash: 17429720091564777933 on replica 0 4Added node: sw_hn with hash: 6206559145603051050 on replica 1 5Added node: sw_hn with hash: 501148381563080863 on replica 2 6Added node: sw_dn with hash: 10372921504992544131 on replica 0 7Added node: sw_dn with hash: 10352104123016491672 on replica 1 8Added node: sw_dn with hash: 4947674849506040391 on replica 2 9Added node: sw_hcm with hash: 13712729030455601798 on replica 0 10Added node: sw_hcm with hash: 13299855957139837304 on replica 1 11Added node: sw_hcm with hash: 15146544336749671394 on replica 2 12The key \u0026#39;T√°c gi·∫£ Ph·∫°m Duy T√πng\u0026#39; is mapped to node: sw_dn 13The key \u0026#39;Ng√†y c·∫≠p nh·∫≠t 08/09/2024\u0026#39; is mapped to node: sw_dn 14The key \u0026#39;Ng√†y m∆∞a b√£o\u0026#39; is mapped to node: sw_dn 15The key \u0026#39;Vi·∫øt v√†o ng√†y b√£o, T√™n c∆°n b√£o l√† Yagi\u0026#39; is mapped to node: sw_hn 16The key \u0026#39;T√°c gi·∫£ Ph·∫°m Duy T√πng, C·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt\u0026#39; is mapped to node: sw_dn ∆Øu v√† nh∆∞·ª£c ƒëi·ªÉm c·ªßa Consistent Hashing ∆Øu ƒëi·ªÉm c·ªßa vi·ªác s·ª≠ d·ª•ng Consistent Hashing\nC√¢n b·∫±ng t·∫£i: Consistent Hashing gi√∫p ph√¢n ph·ªëi t·∫£i tr·ªçng c·ªßa m·∫°ng ƒë·ªÅu gi·ªØa c√°c n√∫t, b·∫£o v·ªá hi·ªáu su·∫•t v√† kh·∫£ nƒÉng ƒë√°p ·ª©ng c·ªßa h·ªá th·ªëng ngay c·∫£ khi l∆∞·ª£ng d·ªØ li·ªáu tƒÉng l√™n v√† thay ƒë·ªïi theo th·ªùi gian.\nKh·∫£ nƒÉng m·ªü r·ªông: Consistent Hashing r·∫•t linh ho·∫°t v√† c√≥ th·ªÉ th√≠ch nghi v·ªõi s·ª± thay ƒë·ªïi c·ªßa s·ªë l∆∞·ª£ng n√∫t ho·∫∑c l∆∞·ª£ng d·ªØ li·ªáu ƒë∆∞·ª£c x·ª≠ l√Ω m√† kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn hi·ªáu su·∫•t c·ªßa to√†n b·ªô h·ªá th·ªëng.\nT·ªëi thi·ªÉu ho√° s·ªë l∆∞·ª£ng √°nh x·∫° l·∫°i: Consistent Hashing gi·∫£m thi·ªÉu s·ªë l∆∞·ª£ng kh√≥a c·∫ßn √°nh x·∫° l·∫°i khi th√™m ho·∫∑c x√≥a n√∫t, ƒë·∫£m b·∫£o r·∫±ng h·ªá th·ªëng lu√¥n ·ªïn ƒë·ªãnh v√† nh·∫•t qu√°n ngay c·∫£ khi m·∫°ng thay ƒë·ªïi theo th·ªùi gian.\nTƒÉng kh·∫£ nƒÉng ch·ªãu l·ªói: Consistent Hashing gi√∫p d·ªØ li·ªáu lu√¥n kh·∫£ d·ª•ng v√† c·∫≠p nh·∫≠t, ngay c·∫£ trong tr∆∞·ªùng h·ª£p n√∫t b·ªã l·ªói. Kh·∫£ nƒÉng sao ch√©p kh√≥a tr√™n nhi·ªÅu n√∫t v√† √°nh x·∫° l·∫°i kh√≥a ƒë·∫øn n√∫t kh√°c trong tr∆∞·ªùng h·ª£p l·ªói gi√∫p tƒÉng c∆∞·ªùng ƒë·ªô ·ªïn ƒë·ªãnh v√† tin c·∫≠y c·ªßa to√†n b·ªô h·ªá th·ªëng.\nƒê∆°n gi·∫£n h√≥a ho·∫°t ƒë·ªông: Consistent Hashing gi√∫p ƒë∆°n gi·∫£n h√≥a qu√° tr√¨nh th√™m ho·∫∑c x√≥a n√∫t kh·ªèi m·∫°ng, gi√∫p d·ªÖ d√†ng qu·∫£n l√Ω v√† duy tr√¨ h·ªá th·ªëng ph√¢n t√°n l·ªõn.\nNh∆∞·ª£c ƒëi·ªÉm c·ªßa vi·ªác s·ª≠ d·ª•ng Consistent Hashing\nH√†m bƒÉm: Hi·ªáu su·∫•t c·ªßa Consistent Hashing ph·ª• thu·ªôc v√†o vi·ªác s·ª≠ d·ª•ng h√†m bƒÉm ph√π h·ª£p. H√†m bƒÉm ph·∫£i t·∫°o ra gi√° tr·ªã duy nh·∫•t cho m·ªói kh√≥a v√† ph·∫£i l√† x√°c ƒë·ªãnh ƒë·ªÉ c√≥ hi·ªáu qu·∫£. S·ª± ph·ª©c t·∫°p c·ªßa h√†m bƒÉm c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn hi·ªáu su·∫•t v√† hi·ªáu qu·∫£ c·ªßa to√†n b·ªô h·ªá th·ªëng.\nT·ªën k√©m hi·ªáu su·∫•t: Vi·ªác s·ª≠ d·ª•ng Consistent Hashing c√≥ th·ªÉ d·∫´n ƒë·∫øn m·ªôt s·ªë t·ªën k√©m hi·ªáu su·∫•t do c·∫ßn ph·∫£i s·ª≠ d·ª•ng t√†i nguy√™n t√≠nh to√°n ƒë·ªÉ √°nh x·∫° kh√≥a ƒë·∫øn n√∫t, sao ch√©p kh√≥a v√† √°nh x·∫° l·∫°i kh√≥a trong tr∆∞·ªùng h·ª£p th√™m ho·∫∑c x√≥a n√∫t.\nThi·∫øu linh ho·∫°t: Trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p, gi·ªõi h·∫°n c·ªë ƒë·ªãnh c·ªßa Consistent Hashing c√≥ th·ªÉ h·∫°n ch·∫ø kh·∫£ nƒÉng c·ªßa h·ªá th·ªëng ƒë·ªÉ th√≠ch nghi v·ªõi s·ª± thay ƒë·ªïi c·ªßa nhu c·∫ßu ho·∫∑c ƒëi·ªÅu ki·ªán m·∫°ng.\nS·ª≠ d·ª•ng t√†i nguy√™n cao: Trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p, vi·ªác s·ª≠ d·ª•ng Consistent Hashing c√≥ th·ªÉ d·∫´n ƒë·∫øn s·ª≠ d·ª•ng t√†i nguy√™n cao khi th√™m ho·∫∑c x√≥a n√∫t kh·ªèi m·∫°ng, ƒëi·ªÅu n√†y c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn hi·ªáu su·∫•t v√† hi·ªáu qu·∫£ c·ªßa to√†n b·ªô h·ªá th·ªëng.\nPh·ª©c t·∫°p c·ªßa qu·∫£n l√Ω: Vi·ªác qu·∫£n l√Ω v√† duy tr√¨ h·ªá th·ªëng s·ª≠ d·ª•ng Consistent Hashing c√≥ th·ªÉ ph·ª©c t·∫°p v√† ƒë√≤i h·ªèi chuy√™n m√¥n v√† k·ªπ nƒÉng ƒë·∫∑c bi·ªát.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt. Xin c·∫£m ∆°n v√† h·∫πn g·∫∑p l·∫°i. B√†i sau s·∫Ω n√≥i v·ªÅ Distributed Hash Tables\n","date":"Sep 8, 2024","img":"https://unsplash.it/1920/1080?image=2","permalink":"/blog/2024-09-05-system-design-top-10-interview-consistent-hashing/","series":null,"tags":["System Design"],"title":"Top 10 Thu·∫≠t To√°n System Design C√°c B·∫°n N√™n Bi·∫øt V√† Th∆∞·ªùng ƒê∆∞·ª£c H·ªèi Trong Ph·ªèng V·∫•n - Top 1 Consistent Hashing"},{"categories":null,"content":" Netflix: Ph√°t Tri·ªÉn Kh·∫Øc Ph·ª•c S·ª± C·ªë Big Data Picnic: C·∫£i Thi·ªán Truy Xu·∫•t T√¨m Ki·∫øm Uber: C√° Nh√¢n H√≥a Th√¥ng Tin Ngo√†i ·ª®ng D·ª•ng GitLab: X√°c Th·ª±c v√† Ki·ªÉm Tra M√¥ H√¨nh AI LinkedIn: K·∫øt N·ªëi Th√†nh Vi√™n v·ªõi S·∫£n Ph·∫©m Cao C·∫•p Swiggy: ƒê·ªÅ Xu·∫•t S·∫£n Ph·∫©m Cho Ng∆∞·ªùi D√πng M·ªõi Careem: Gi·∫£m Gian L·∫≠n B·∫±ng Ti·ªÅn T·∫°m ·ª®ng Slack: AI Cho Tin Nh·∫Øn B·∫£o M·∫≠t Trong Doanh Nghi·ªáp Picnic: H·ªó Tr·ª£ Y√™u C·∫ßu Kh√°ch H√†ng Foodpanda: T·ªëi ∆Øu H√≥a Cung v√† C·∫ßu Etsy: T√¨m Ki·∫øm v√† ƒê·ªÅ Xu·∫•t B·∫±ng H√¨nh ·∫¢nh LinkedIn: Ph√°t Hi·ªán H√¨nh ·∫¢nh Do AI T·∫°o Ra Discord: C√°c Tr∆∞·ªùng H·ª£p S·ª≠ D·ª•ng AI T·∫°o Sinh Pinterest: C·∫£i Thi·ªán Hi·ªáu Su·∫•t Qu·∫£ng C√°o Expedia: T√¨m Ki·∫øm Ng·ªØ Nghƒ©a Cho Du L·ªãch 15 V√≠ d·ª• Th·ª±c T·∫ø v·ªÅ ·ª®ng D·ª•ng c·ªßa LLM Trong C√°c Ng√†nh C√¥ng Nghi·ªáp Kh√°c Nhau\nB·ªüi Sana Hassan - 3 Th√°ng 7, 2024\nTrong th·∫ø gi·ªõi c√¥ng ngh·ªá ƒë·∫ßy bi·∫øn ƒë·ªông, c√°c M√¥ H√¨nh Ng√¥n Ng·ªØ L·ªõn (LLM) ƒë√£ tr·ªü n√™n quan tr·ªçng trong nhi·ªÅu ng√†nh c√¥ng nghi·ªáp kh√°c nhau. Kh·∫£ nƒÉng x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n, t·∫°o n·ªôi dung v√† ph√¢n t√≠ch d·ªØ li·ªáu c·ªßa ch√∫ng ƒë√£ m·ªü ƒë∆∞·ªùng cho nhi·ªÅu ·ª©ng d·ª•ng. H√£y c√πng kh√°m ph√° 15 v√≠ d·ª• chi ti·∫øt v·ªÅ c√°ch c√°c c√¥ng ty t·∫≠n d·ª•ng LLM trong c√°c t√¨nh hu·ªëng th·ª±c t·∫ø.\nNetflix: Ph√°t Tri·ªÉn Kh·∫Øc Ph·ª•c S·ª± C·ªë Big Data Netflix ƒë√£ chuy·ªÉn t·ª´ c√°c b·ªô ph√¢n lo·∫°i d·ª±a tr√™n quy t·∫Øc truy·ªÅn th·ªëng sang c√°c h·ªá th·ªëng kh·∫Øc ph·ª•c t·ª± ƒë·ªông d·ª±a tr√™n h·ªçc m√°y ƒë·ªÉ x·ª≠ l√Ω c√°c c√¥ng vi·ªác big data b·ªã l·ªói. S·ª± chuy·ªÉn ƒë·ªïi n√†y ƒë√£ cho ph√©p Netflix t·ª± ƒë·ªông ph√°t hi·ªán, ch·∫©n ƒëo√°n v√† s·ª≠a c√°c v·∫•n ƒë·ªÅ trong c√°c quy tr√¨nh d·ªØ li·ªáu c·ªßa m√¨nh, gi·∫£m ƒë√°ng k·ªÉ th·ªùi gian ng·ª´ng ho·∫°t ƒë·ªông v√† ƒë·∫£m b·∫£o d·ªãch v·ª• ph√°t tr·ª±c tuy·∫øn li·ªÅn m·∫°ch. LLM gi√∫p hi·ªÉu d·ªØ li·ªáu log, x√°c ƒë·ªãnh c√°c m·∫´u l·ªói v√† ƒë·ªÅ xu·∫•t ho·∫∑c th·ª±c hi·ªán c√°c bi·ªán ph√°p s·ª≠a ch·ªØa, n√¢ng cao hi·ªáu qu·∫£ v√† ƒë·ªô tin c·∫≠y c·ªßa ho·∫°t ƒë·ªông.\nPicnic: C·∫£i Thi·ªán Truy Xu·∫•t T√¨m Ki·∫øm Picnic, m·ªôt d·ªãch v·ª• giao h√†ng t·∫°p h√≥a tr·ª±c tuy·∫øn, ƒë√£ t√≠ch h·ª£p LLM ƒë·ªÉ c·∫£i thi·ªán s·ª± li√™n quan c·ªßa k·∫øt qu·∫£ t√¨m ki·∫øm cho c√°c danh s√°ch s·∫£n ph·∫©m. Vi·ªác s·ª≠ d·ª•ng c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn cho ph√©p Picnic hi·ªÉu r√µ h∆°n c√°c truy v·∫•n c·ªßa ng∆∞·ªùi d√πng v√† ng·ªØ c·∫£nh, mang l·∫°i k·∫øt qu·∫£ t√¨m ki·∫øm ch√≠nh x√°c v√† c√° nh√¢n h√≥a h∆°n. S·ª± c·∫£i thi·ªán n√†y n√¢ng cao tr·∫£i nghi·ªám kh√°ch h√†ng v√† tƒÉng t·ª∑ l·ªá chuy·ªÉn ƒë·ªïi b·∫±ng c√°ch gi√∫p kh√°ch h√†ng d·ªÖ d√†ng t√¨m th·∫•y s·∫£n ph·∫©m h·ªç c·∫ßn.\nUber: C√° Nh√¢n H√≥a Th√¥ng Tin Ngo√†i ·ª®ng D·ª•ng H·ªá th·ªëng ƒë·ªÅ xu·∫•t ti√™n ti·∫øn c·ªßa Uber c√° nh√¢n h√≥a th√¥ng tin ngo√†i ·ª©ng d·ª•ng ƒë·ªÉ tƒÉng c∆∞·ªùng s·ª± t∆∞∆°ng t√°c c·ªßa ng∆∞·ªùi d√πng. B·∫±ng c√°ch s·ª≠ d·ª•ng c√°c thu·∫≠t to√°n ƒë·ªÅ xu·∫•t d·ª±a tr√™n LLM tinh vi, Uber c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh th√¥ng b√°o v√† g·ª£i √Ω theo s·ªü th√≠ch v√† h√†nh vi c·ªßa t·ª´ng ng∆∞·ªùi d√πng. S·ª± c√° nh√¢n h√≥a n√†y m·ªü r·ªông ra ngo√†i ·ª©ng d·ª•ng, ƒë·∫£m b·∫£o ng∆∞·ªùi d√πng nh·∫≠n ƒë∆∞·ª£c c√°c c·∫≠p nh·∫≠t v√† ∆∞u ƒë√£i li√™n quan qua email, SMS v√† c√°c k√™nh kh√°c, t·ª´ ƒë√≥ c·∫£i thi·ªán s·ª± duy tr√¨ v√† s·ª± h√†i l√≤ng c·ªßa ng∆∞·ªùi d√πng.\nGitLab: X√°c Th·ª±c v√† Ki·ªÉm Tra M√¥ H√¨nh AI GitLab ƒë√£ ph√°t tri·ªÉn GitLab Duo, m·ªôt n·ªÅn t·∫£ng x√°c th·ª±c v√† ki·ªÉm tra c√°c k·∫øt qu·∫£ do AI t·∫°o ra. S√°ng ki·∫øn n√†y s·ª≠ d·ª•ng LLM ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng, ƒë·ªô ch√≠nh x√°c v√† ƒë·ªô tin c·∫≠y c·ªßa c√°c m√¥ h√¨nh AI ·ªü quy m√¥ l·ªõn. GitLab Duo gi√∫p x√°c ƒë·ªãnh c√°c thi√™n v·ªã ti·ªÅm ·∫©n, l·ªói v√† c√°c khu v·ª±c c·∫ßn c·∫£i thi·ªán trong c√°c m√¥ h√¨nh AI, ƒë·∫£m b·∫£o r·∫±ng c√°c m√¥ h√¨nh tri·ªÉn khai ƒë·∫°t ti√™u chu·∫©n hi·ªáu su·∫•t v√† ƒë·ªô tin c·∫≠y cao. Quy tr√¨nh ki·ªÉm tra nghi√™m ng·∫∑t n√†y r·∫•t quan tr·ªçng ƒë·ªÉ duy tr√¨ ni·ªÅm tin v√†o c√°c t√≠nh nƒÉng do AI ƒëi·ªÅu khi·ªÉn.\nLinkedIn: K·∫øt N·ªëi Th√†nh Vi√™n v·ªõi S·∫£n Ph·∫©m Cao C·∫•p LinkedIn s·ª≠ d·ª•ng LLM ƒë·ªÉ ƒë·ªÅ xu·∫•t c√°c s·∫£n ph·∫©m cao c·∫•p ph√π h·ª£p cho ng∆∞·ªùi d√πng. B·∫±ng c√°ch ph√¢n t√≠ch d·ªØ li·ªáu ng∆∞·ªùi d√πng, bao g·ªìm l·ªãch s·ª≠ c√¥ng vi·ªác, s·ªü th√≠ch v√† m√¥ h√¨nh ho·∫°t ƒë·ªông, h·ªá th·ªëng ƒë·ªÅ xu·∫•t c·ªßa LinkedIn c√≥ th·ªÉ k·∫øt n·ªëi th√†nh vi√™n v·ªõi c√°c d·ªãch v·ª• v√† s·∫£n ph·∫©m cao c·∫•p ph√π h·ª£p nh·∫•t v·ªõi nhu c·∫ßu c·ªßa h·ªç. C√°ch ti·∫øp c·∫≠n c√≥ m·ª•c ti√™u n√†y gi√∫p LinkedIn n√¢ng cao s·ª± h√†i l√≤ng c·ªßa ng∆∞·ªùi d√πng v√† th√∫c ƒë·∫©y ƒëƒÉng k√Ω v√†o c√°c d·ªãch v·ª• cao c·∫•p c·ªßa m√¨nh.\nSwiggy: ƒê·ªÅ Xu·∫•t S·∫£n Ph·∫©m Cho Ng∆∞·ªùi D√πng M·ªõi Swiggy, m·ªôt n·ªÅn t·∫£ng giao ƒë·ªì ƒÉn h√†ng ƒë·∫ßu, s·ª≠ d·ª•ng h·ªçc t·∫≠p li√™n mi·ªÅn ph√¢n c·∫•p ƒë·ªÉ cung c·∫•p c√°c ƒë·ªÅ xu·∫•t s·∫£n ph·∫©m cho ng∆∞·ªùi d√πng m·ªõi. B·∫±ng c√°ch ph√¢n t√≠ch d·ªØ li·ªáu t·ª´ c√°c mi·ªÅn kh√°c nhau v√† h·ªçc h·ªèi t·ª´ c√°c t∆∞∆°ng t√°c c·ªßa ng∆∞·ªùi d√πng, h·ªá th·ªëng ƒë·ªÅ xu·∫•t c·ªßa Swiggy c√≥ th·ªÉ ƒë∆∞a ra c√°c g·ª£i √Ω c√° nh√¢n h√≥a ph√π h·ª£p v·ªõi s·ªü th√≠ch c·ªßa ng∆∞·ªùi d√πng m·ªõi. C√°ch ti·∫øp c·∫≠n n√†y hi·ªáu qu·∫£ trong vi·ªác ti·∫øp c·∫≠n v√† gi·ªØ ch√¢n kh√°ch h√†ng m·ªõi.\nCareem: Gi·∫£m Gian L·∫≠n B·∫±ng Ti·ªÅn T·∫°m ·ª®ng Careem, m·ªôt d·ªãch v·ª• g·ªçi xe, s·ª≠ d·ª•ng c√°c m√¥ h√¨nh h·ªçc m√°y ƒë·ªÉ gi·∫£m r·ªßi ro gian l·∫≠n th√¥ng qua c√°c k·ªπ thu·∫≠t ti·ªÅn t·∫°m ·ª©ng. B·∫±ng c√°ch √°p d·ª•ng c√°c kho·∫£n gi·ªØ t·∫°m th·ªùi tr√™n c√°c giao d·ªãch, Careem c√≥ th·ªÉ ph√¢n t√≠ch c√°c m·∫´u giao d·ªãch v√† ƒë√°nh d·∫•u c√°c ho·∫°t ƒë·ªông ƒë√°ng ng·ªù theo th·ªùi gian th·ª±c. C∆° ch·∫ø ph√°t hi·ªán gian l·∫≠n ch·ªß ƒë·ªông n√†y, ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi LLM, gi√∫p gi·∫£m c√°c v·ª• gian l·∫≠n, b·∫£o v·ªá c√¥ng ty v√† ng∆∞·ªùi d√πng kh·ªèi c√°c t·ªïn th·∫•t ti·ªÅm ·∫©n.\nSlack: AI Cho Tin Nh·∫Øn B·∫£o M·∫≠t Trong Doanh Nghi·ªáp Slack ƒë√£ ph√°t tri·ªÉn c√°c kh·∫£ nƒÉng AI ƒë·ªÉ n√¢ng cao b·∫£o m·∫≠t v√† ri√™ng t∆∞ cho tin nh·∫Øn trong doanh nghi·ªáp. S·ª≠ d·ª•ng LLM, c√°c t√≠nh nƒÉng AI c·ªßa Slack c√≥ th·ªÉ x·ª≠ l√Ω v√† ph√¢n t√≠ch tin nh·∫Øn trong khi ƒë·∫£m b·∫£o ti√™u chu·∫©n cao v·ªÅ b·∫£o m·∫≠t v√† quy·ªÅn ri√™ng t∆∞. C√°c t√≠nh nƒÉng n√†y bao g·ªìm t√≥m t·∫Øt tin nh·∫Øn t·ª± ƒë·ªông, tr·∫£ l·ªùi th√¥ng minh v√† ƒë·ªÅ xu·∫•t theo ng·ªØ c·∫£nh ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ c·∫£i thi·ªán hi·ªáu qu·∫£ giao ti·∫øp m√† kh√¥ng l√†m gi·∫£m b·∫£o v·ªá d·ªØ li·ªáu.\nPicnic: H·ªó Tr·ª£ Y√™u C·∫ßu Kh√°ch H√†ng Picnic ƒë√£ v∆∞·ª£t qua r√†o c·∫£n ng√¥n ng·ªØ trong h·ªó tr·ª£ kh√°ch h√†ng b·∫±ng c√°ch s·ª≠ d·ª•ng x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP). B·∫±ng c√°ch chuy·ªÉn h∆∞·ªõng y√™u c·∫ßu h·ªó tr·ª£ ƒë·∫øn c√°c nh√¢n vi√™n ph√π h·ª£p nh·∫•t v√† cung c·∫•p d·ªãch thu·∫≠t theo th·ªùi gian th·ª±c, Picnic ƒë·∫£m b·∫£o r·∫±ng kh√°ch h√†ng nh·∫≠n ƒë∆∞·ª£c s·ª± h·ªó tr·ª£ k·ªãp th·ªùi v√† ch√≠nh x√°c b·∫•t k·ªÉ ng√¥n ng·ªØ. H·ªá th·ªëng h·ªó tr·ª£ d·ª±a tr√™n NLP n√†y n√¢ng cao ch·∫•t l∆∞·ª£ng d·ªãch v·ª• kh√°ch h√†ng v√† gi√∫p Picnic ph·ª•c v·ª• m·ªôt c∆° s·ªü kh√°ch h√†ng ƒëa d·∫°ng.\nFoodpanda: T·ªëi ∆Øu H√≥a Cung v√† C·∫ßu Foodpanda s·ª≠ d·ª•ng h·ªçc m√°y ƒë·ªÉ c√¢n b·∫±ng cung v√† c·∫ßu cho c√°c d·ªãch v·ª• giao ƒë·ªì ƒÉn. B·∫±ng c√°ch s·ª≠ d·ª•ng ph√¢n t√≠ch d·ª± ƒëo√°n v√† c√°c thu·∫≠t to√°n ti√™n ti·∫øn, Foodpanda c√≥ th·ªÉ d·ª± b√°o c√°c m·∫´u nhu c·∫ßu v√† ph√¢n b·ªï t√†i nguy√™n. Vi·ªác t·ªëi ∆∞u h√≥a n√†y gi√∫p qu·∫£n l√Ω th·ªùi gian giao h√†ng, gi·∫£m chi ph√≠ v·∫≠n h√†nh v√† ƒë·∫£m b·∫£o tr·∫£i nghi·ªám t·ªët h∆°n cho kh√°ch h√†ng v√† ƒë·ªëi t√°c giao h√†ng.\nEtsy: T√¨m Ki·∫øm v√† ƒê·ªÅ Xu·∫•t B·∫±ng H√¨nh ·∫¢nh Etsy ƒë√£ tri·ªÉn khai k·ªπ thu·∫≠t h·ªçc bi·ªÉu di·ªÖn v√† ƒë√°nh gi√° b·∫±ng h√¨nh ·∫£nh cho t√¨m ki·∫øm v√† ƒë·ªÅ xu·∫•t t∆∞∆°ng t·ª±. B·∫±ng c√°ch t·∫≠n d·ª•ng th·ªã gi√°c m√°y t√≠nh v√† LLM, h·ªá th·ªëng c·ªßa Etsy c√≥ th·ªÉ ph√¢n t√≠ch h√¨nh ·∫£nh s·∫£n ph·∫©m v√† cung c·∫•p cho ng∆∞·ªùi d√πng c√°c m·∫∑t h√†ng t∆∞∆°ng t·ª± v·ªÅ m·∫∑t h√¨nh ·∫£nh. T√≠nh nƒÉng n√†y n√¢ng cao tr·∫£i nghi·ªám mua s·∫Øm b·∫±ng c√°ch gi√∫p ng∆∞·ªùi d√πng d·ªÖ d√†ng t√¨m th·∫•y c√°c s·∫£n ph·∫©m ph√π h·ª£p v·ªõi s·ªü th√≠ch c·ªßa h·ªç d·ª±a tr√™n c√°c thu·ªôc t√≠nh h√¨nh ·∫£nh.\nLinkedIn: Ph√°t Hi·ªán H√¨nh ·∫¢nh Do AI T·∫°o Ra LinkedIn ƒë√£ ph√°t tri·ªÉn c√°c h·ªá th·ªëng ƒë·ªÉ ph√°t hi·ªán h√¨nh ·∫£nh do AI t·∫°o ra (deepfake). S·ª≠ d·ª•ng c√°c thu·∫≠t to√°n nh·∫≠n di·ªán h√¨nh ·∫£nh ti√™n ti·∫øn v√† LLM, LinkedIn c√≥ th·ªÉ x√°c ƒë·ªãnh v√† ƒë√°nh d·∫•u n·ªôi dung deepfake, ƒë·∫£m b·∫£o t√≠nh to√†n v·∫πn v√† ƒë√°ng tin c·∫≠y c·ªßa h·ªì s∆° ng∆∞·ªùi d√πng v√† n·ªôi dung tr√™n n·ªÅn t·∫£ng. Kh·∫£ nƒÉng n√†y r·∫•t quan tr·ªçng trong vi·ªác duy tr√¨ m·ªôt m√¥i tr∆∞·ªùng ng∆∞·ªùi d√πng an to√†n v√† x√°c th·ª±c.\nDiscord: C√°c Tr∆∞·ªùng H·ª£p S·ª≠ D·ª•ng AI T·∫°o Sinh Discord, m·ªôt n·ªÅn t·∫£ng giao ti·∫øp ph·ªï bi·∫øn, ƒë√£ kh√°m ph√° nhi·ªÅu tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng AI t·∫°o sinh ƒë·ªÉ tƒÉng c∆∞·ªùng s·ª± t∆∞∆°ng t√°c c·ªßa ng∆∞·ªùi d√πng. B·∫±ng c√°ch ph√°t tri·ªÉn v√† t√≠ch h·ª£p nhanh ch√≥ng c√°c t√≠nh nƒÉng AI t·∫°o sinh, Discord c√≥ th·ªÉ cung c·∫•p cho ng∆∞·ªùi d√πng c√°c c√¥ng c·ª• s√°ng t·∫°o nh∆∞ avatar do AI t·∫°o ra, ki·ªÉm duy·ªát n·ªôi dung v√† ph·∫£n h·ªìi t·ª± ƒë·ªông. C√°c t√≠nh nƒÉng n√†y t·∫≠n d·ª•ng LLM ƒë·ªÉ c·∫£i thi·ªán tr·∫£i nghi·ªám ng∆∞·ªùi d√πng v√† th√∫c ƒë·∫©y c·ªông ƒë·ªìng t∆∞∆°ng t√°c h∆°n.\nPinterest: C·∫£i Thi·ªán Hi·ªáu Su·∫•t Qu·∫£ng C√°o Pinterest ƒë√£ ph√°t tri·ªÉn c√°c m√¥ h√¨nh t·ªëi ∆∞u h√≥a chuy·ªÉn ƒë·ªïi qu·∫£ng c√°o ƒë·ªÉ n√¢ng cao hi·ªáu su·∫•t qu·∫£ng c√°o. B·∫±ng c√°ch t·∫≠n d·ª•ng LLM, Pinterest c√≥ th·ªÉ ph√¢n t√≠ch h√†nh vi v√† s·ªü th√≠ch c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ cung c·∫•p c√°c qu·∫£ng c√°o m·ª•c ti√™u v√† li√™n quan. Vi·ªác t·ªëi ∆∞u h√≥a n√†y d·∫´n ƒë·∫øn t·ª∑ l·ªá chuy·ªÉn ƒë·ªïi cao h∆°n, tr·∫£i nghi·ªám ng∆∞·ªùi d√πng t·ªët h∆°n v√† tƒÉng doanh thu cho c√°c nh√† qu·∫£ng c√°o tr√™n n·ªÅn t·∫£ng.\nExpedia: T√¨m Ki·∫øm Ng·ªØ Nghƒ©a Cho Du L·ªãch Expedia s·ª≠ d·ª•ng c√°c bi·ªÉu di·ªÖn cho c√°c kh√°i ni·ªám du l·ªãch l∆∞u tr√∫ ƒë·ªÉ n√¢ng cao kh·∫£ nƒÉng t√¨m ki·∫øm ng·ªØ nghƒ©a. B·∫±ng c√°ch hi·ªÉu nghƒ©a ng·ªØ c·∫£nh c·ªßa c√°c truy v·∫•n c·ªßa ng∆∞·ªùi d√πng, h·ªá th·ªëng t√¨m ki·∫øm c·ªßa Expedia c√≥ th·ªÉ cung c·∫•p c√°c k·∫øt qu·∫£ ch√≠nh x√°c v√† li√™n quan h∆°n cho c√°c kh√°ch s·∫°n v√† ch·ªó ·ªü du l·ªãch. Ch·ª©c\nnƒÉng t√¨m ki·∫øm ng·ªØ nghƒ©a n√†y, ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi LLM, c·∫£i thi·ªán tr·∫£i nghi·ªám ƒë·∫∑t ch·ªó b·∫±ng c√°ch gi√∫p ng∆∞·ªùi d√πng t√¨m th·∫•y c√°c t√πy ch·ªçn t·ªët nh·∫•t d·ª±a tr√™n nhu c·∫ßu v√† s·ªü th√≠ch c·ªßa h·ªç.\nT√≥m l·∫°i, c√°c v√≠ d·ª• n√†y minh h·ªça t√°c ƒë·ªông chuy·ªÉn ƒë·ªïi c·ªßa LLM tr√™n nhi·ªÅu lƒ©nh v·ª±c, th√∫c ƒë·∫©y ƒë·ªïi m·ªõi v√† hi·ªáu qu·∫£. Khi c√¥ng ngh·ªá LLM ti·∫øn b·ªô, c√°c ·ª©ng d·ª•ng c·ªßa n√≥ ƒë∆∞·ª£c d·ª± ƒëo√°n s·∫Ω m·ªü r·ªông, cung c·∫•p c√°c gi·∫£i ph√°p ph·ª©c t·∫°p h∆°n cho c√°c th√°ch th·ª©c trong ng√†nh. C√°c c√¥ng ty n√™n c√¢n nh·∫Øc t·∫≠n d·ª•ng c√°c n·ªÅn t·∫£ng chuy√™n d·ª•ng nh∆∞ AI Drive Pro ƒë·ªÉ qu·∫£n l√Ω v√† t·ªëi ∆∞u h√≥a vi·ªác tri·ªÉn khai LLM c·ªßa h·ªç ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªëi ∆∞u.\nTham kh·∫£o\nhttps://www.evidentlyai.com/ml-system-design\n","date":"Jul 6, 2024","img":"https://unsplash.it/1920/1080?image=3","permalink":"/blog/2024-07-06-llm-applications-in-real/","series":null,"tags":["bigdata"],"title":"C√°c ·ª®ng D·ª•ng C·ªßa LLM Trong Th·ª±c T·∫ø"},{"categories":null,"content":"Gi·ªõi thi·ªáu Hi·ªán nay, NVIDA ƒëang l√† nh√† s·∫£n xu·∫•t GPU h√†ng ƒë·∫ßu th·∫ø gi·ªõi, v√† c√πng v·ªõi s·ª± ph√°t tri·ªÉn c·ªßa c·ªßa m√¥ h√¨nh AI, chip NVIDIA ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r·∫£i v√¨ c√°c t√≠nh nƒÉng sau\n1. Hi·ªáu Su·∫•t Cao T·∫≠n D·ª•ng GPU\nCUDA ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a ƒë·ªÉ t·∫≠n d·ª•ng s·ª©c m·∫°nh x·ª≠ l√Ω song song c·ªßa GPU, cho ph√©p th·ª±c hi·ªán h√†ng ng√†n t√°c v·ª• t√≠nh to√°n ƒë·ªìng th·ªùi. GPU c√≥ nhi·ªÅu l√µi h∆°n so v·ªõi CPU, gi√∫p tƒÉng t·ªëc ƒë·ªô t√≠nh to√°n ƒë√°ng k·ªÉ khi x·ª≠ l√Ω c√°c t√°c v·ª• li√™n quan ƒë·∫øn AI v√† h·ªçc s√¢u. T·ªëi ∆Øu H√≥a To√°n H·ªçc\nCUDA cung c·∫•p c√°c th∆∞ vi·ªán to√°n h·ªçc hi·ªáu su·∫•t cao nh∆∞ cuBLAS, cuDNN, v√† cuFFT, gi√∫p t·ªëi ∆∞u h√≥a c√°c ph√©p to√°n ma tr·∫≠n v√† ph√©p bi·∫øn ƒë·ªïi Fourier, c√°c ph√©p to√°n ph·ªï bi·∫øn trong c√°c m√¥ h√¨nh AI. 2. Th∆∞ Vi·ªán v√† H·ªá Sinh Th√°i Phong Ph√∫ Th∆∞ Vi·ªán AI\nC√°c th∆∞ vi·ªán h·ªçc s√¢u ph·ªï bi·∫øn nh∆∞ TensorFlow, PyTorch, v√† MXNet ƒë·ªÅu c√≥ h·ªó tr·ª£ CUDA, gi√∫p d·ªÖ d√†ng tri·ªÉn khai v√† t·ªëi ∆∞u h√≥a c√°c m√¥ h√¨nh AI tr√™n GPU. C√°c th∆∞ vi·ªán n√†y t√≠ch h·ª£p ch·∫∑t ch·∫Ω v·ªõi CUDA, cung c·∫•p c√°c c√¥ng c·ª• v√† API m·∫°nh m·∫Ω ƒë·ªÉ x√¢y d·ª±ng, hu·∫•n luy·ªán, v√† tri·ªÉn khai c√°c m√¥ h√¨nh AI. C·ªông ƒê·ªìng v√† H·ªó Tr·ª£\nNVIDIA c√≥ m·ªôt c·ªông ƒë·ªìng l·ªõn c√°c nh√† ph√°t tri·ªÉn v√† nh√† nghi√™n c·ª©u, cung c·∫•p h·ªó tr·ª£ qua c√°c di·ªÖn ƒë√†n, t√†i li·ªáu, v√† kh√≥a h·ªçc tr·ª±c tuy·∫øn. C√°c c√¥ng c·ª• ph√°t tri·ªÉn nh∆∞ NVIDIA CUDA Toolkit, NVIDIA Nsight, v√† cuDNN Debugger gi√∫p d·ªÖ d√†ng ph√°t tri·ªÉn v√† g·ª° l·ªói ·ª©ng d·ª•ng AI. 3. T√≠nh T∆∞∆°ng Th√≠ch v√† Di ƒê·ªông Ph·∫ßn C·ª©ng T∆∞∆°ng Th√≠ch\nCUDA t∆∞∆°ng th√≠ch v·ªõi h·∫ßu h·∫øt c√°c GPU c·ªßa NVIDIA, t·ª´ c√°c d√≤ng s·∫£n ph·∫©m ti√™u d√πng ƒë·∫øn c√°c d√≤ng s·∫£n ph·∫©m chuy√™n d·ª•ng cho trung t√¢m d·ªØ li·ªáu. ƒêi·ªÅu n√†y cho ph√©p s·ª≠ d·ª•ng c√°c m√¥ h√¨nh AI tr√™n nhi·ªÅu lo·∫°i ph·∫ßn c·ª©ng, t·ª´ m√°y t√≠nh c√° nh√¢n ƒë·∫øn c√°c h·ªá th·ªëng m√°y ch·ªß l·ªõn. T∆∞∆°ng Th√≠ch Ph·∫ßn M·ªÅm\nCUDA h·ªó tr·ª£ nhi·ªÅu ng√¥n ng·ªØ l·∫≠p tr√¨nh v√† framework, gi√∫p d·ªÖ d√†ng t√≠ch h·ª£p v√†o c√°c d·ª± √°n hi·ªán c√≥ m√† kh√¥ng c·∫ßn thay ƒë·ªïi nhi·ªÅu v·ªÅ m√£ ngu·ªìn. 4. Kh·∫£ NƒÉng M·ªü R·ªông v√† T√≠nh Linh Ho·∫°t Hu·∫•n Luy·ªán Ph√¢n T√°n\nCUDA h·ªó tr·ª£ c√°c k·ªπ thu·∫≠t hu·∫•n luy·ªán ph√¢n t√°n, cho ph√©p hu·∫•n luy·ªán c√°c m√¥ h√¨nh l·ªõn tr√™n nhi·ªÅu GPU ho·∫∑c th·∫≠m ch√≠ nhi·ªÅu m√°y t√≠nh. C√°c framework nh∆∞ Horovod (do Uber ph√°t tri·ªÉn) s·ª≠ d·ª•ng CUDA ƒë·ªÉ th·ª±c hi·ªán hu·∫•n luy·ªán ph√¢n t√°n hi·ªáu qu·∫£. Kh·∫£ NƒÉng T√πy Ch·ªânh\nCUDA cung c·∫•p kh·∫£ nƒÉng t√πy ch·ªânh cao, cho ph√©p c√°c nh√† ph√°t tri·ªÉn t·ªëi ∆∞u h√≥a c√°c thu·∫≠t to√°n c·ª• th·ªÉ cho ·ª©ng d·ª•ng c·ªßa h·ªç. CUDA cung c·∫•p quy·ªÅn truy c·∫≠p tr·ª±c ti·∫øp v√†o ph·∫ßn c·ª©ng GPU, gi√∫p t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t theo y√™u c·∫ßu c·ª• th·ªÉ. 5. Hi·ªáu Qu·∫£ Kinh T·∫ø T·ªëi ∆Øu Chi Ph√≠:\nS·ª≠ d·ª•ng GPU v√† CUDA ƒë·ªÉ hu·∫•n luy·ªán c√°c m√¥ h√¨nh AI c√≥ th·ªÉ gi√∫p ti·∫øt ki·ªám chi ph√≠ b·∫±ng c√°ch gi·∫£m th·ªùi gian hu·∫•n luy·ªán so v·ªõi vi·ªác s·ª≠ d·ª•ng CPU. T√≠nh hi·ªáu qu·∫£ cao c·ªßa GPU gi√∫p gi·∫£m t·ªïng chi ph√≠ cho ph·∫ßn c·ª©ng v√† nƒÉng l∆∞·ª£ng. C√°c th∆∞ vi·ªán l·∫≠p tr√¨nh song song kh√°c ngo√†i CUDA 1. OpenCL (Open Computing Language) T·ªïng quan:\nOpenCL l√† m·ªôt ti√™u chu·∫©n m·ªü cho l·∫≠p tr√¨nh song song tr√™n c√°c n·ªÅn t·∫£ng d·ªã th·ªÉ, bao g·ªìm CPU, GPU, DSP v√† FPGA. N√≥ ƒë∆∞·ª£c qu·∫£n l√Ω b·ªüi Khronos Group. ƒê·∫∑c ƒëi·ªÉm ch√≠nh:\nƒê·ªôc l·∫≠p v·ªõi n·ªÅn t·∫£ng: Ho·∫°t ƒë·ªông tr√™n c√°c ph·∫ßn c·ª©ng t·ª´ nhi·ªÅu nh√† cung c·∫•p kh√°c nhau, bao g·ªìm AMD, Intel v√† NVIDIA. T√≠nh to√°n song song: H·ªó tr·ª£ t√≠nh to√°n d·ª±a tr√™n t√°c v·ª• v√† d·ªØ li·ªáu. Hi·ªáu su·∫•t: Th∆∞·ªùng c√≥ m·ªôt ch√∫t chi ph√≠ hi·ªáu su·∫•t so v·ªõi CUDA do t√≠nh ch·∫•t t·ªïng qu√°t c·ªßa n√≥. Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng:\nT√≠nh to√°n khoa h·ªçc X·ª≠ l√Ω h√¨nh ·∫£nh v√† video th·ªùi gian th·ª±c M√¥ h√¨nh t√†i ch√≠nh ∆Øu ƒëi·ªÉm:\nT√≠nh di ƒë·ªông: Vi·∫øt m·ªôt l·∫ßn, ch·∫°y m·ªçi n∆°i. H·ªó tr·ª£ ph·∫ßn c·ª©ng r·ªông r√£i: C√≥ th·ªÉ ch·∫°y tr√™n CPU, GPU v√† c√°c b·ªô tƒÉng t·ªëc kh√°c t·ª´ nhi·ªÅu nh√† cung c·∫•p. Nh∆∞·ª£c ƒëi·ªÉm:\nHi·ªáu su·∫•t: C√≥ th·ªÉ kh√¥ng t·ªëi ∆∞u nh∆∞ CUDA tr√™n GPU c·ªßa NVIDIA. Ph·ª©c t·∫°p: API m·ª©c th·∫•p c√≥ th·ªÉ kh√≥ l·∫≠p tr√¨nh h∆°n CUDA. 2. AMD ROCm (Radeon Open Compute) T·ªïng quan:\nAMD ROCm l√† m·ªôt n·ªÅn t·∫£ng m√£ ngu·ªìn m·ªü cho t√≠nh to√°n GPU. N√≥ cung c·∫•p c√°c c√¥ng c·ª• ƒë·ªÉ chuy·ªÉn ƒë·ªïi c√°c ·ª©ng d·ª•ng CUDA sang ch·∫°y tr√™n GPU c·ªßa AMD. ƒê·∫∑c ƒëi·ªÉm ch√≠nh:\nHIP (Heterogeneous-Compute Interface for Portability): M·ªôt runtime v√† API cho ph√©p m√£ CUDA ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi ƒë·ªÉ ch·∫°y tr√™n ph·∫ßn c·ª©ng AMD. H·ªó tr·ª£ TensorFlow v√† PyTorch: T√≠ch h·ª£p cho c√°c khung m√°y h·ªçc ph·ªï bi·∫øn. Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng:\nH·ªçc m√°y v√† AI T√≠nh to√°n hi·ªáu nƒÉng cao Trung t√¢m d·ªØ li·ªáu v√† ƒëi·ªán to√°n ƒë√°m m√¢y ∆Øu ƒëi·ªÉm:\nM√£ ngu·ªìn m·ªü: ƒê∆∞·ª£c c·ªông ƒë·ªìng ƒë√≥ng g√≥p v·ªõi s·ª± tham gia c·ªßa nhi·ªÅu t·ªï ch·ª©c. T∆∞∆°ng th√≠ch CUDA: D·ªÖ d√†ng chuy·ªÉn m√£ CUDA th√¥ng qua HIP. Nh∆∞·ª£c ƒëi·ªÉm:\nH·∫°n ch·∫ø ph·∫ßn c·ª©ng: Ch·ªß y·∫øu h·ªó tr·ª£ GPU c·ªßa AMD. ƒê·ªô tr∆∞·ªüng th√†nh: √çt tr∆∞·ªüng th√†nh h∆°n so v·ªõi CUDA, √≠t t√†i nguy√™n v√† c√¥ng c·ª• h∆°n. 3. SYCL (C++ for Heterogeneous Computing) T·ªïng quan:\nSYCL l√† m·ªôt m√¥ h√¨nh l·∫≠p tr√¨nh m·ª©c cao d·ª±a tr√™n C++ cho t√≠nh to√°n d·ªã th·ªÉ, cho ph√©p m√£ di ƒë·ªông tr√™n c√°c ph·∫ßn c·ª©ng kh√°c nhau bao g·ªìm CPU, GPU v√† FPGA. ƒê·∫∑c ƒëi·ªÉm ch√≠nh:\nL·∫≠p tr√¨nh ngu·ªìn ƒë∆°n: Cho ph√©p m√£ cho m√°y ch·ªß v√† thi·∫øt b·ªã ƒë∆∞·ª£c vi·∫øt trong m·ªôt t·ªáp ngu·ªìn duy nh·∫•t. T√≠ch h·ª£p C++: S·ª≠ d·ª•ng c√°c t√≠nh nƒÉng C++ hi·ªán ƒë·∫°i cho m√£ an to√†n v√† bi·ªÉu c·∫£m h∆°n. Backend: C√≥ th·ªÉ bi√™n d·ªãch sang OpenCL, CUDA (th√¥ng qua hipSYCL), v√† nhi·ªÅu h∆°n n·ªØa. Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng:\n·ª®ng d·ª•ng ƒëa n·ªÅn t·∫£ng H·ªá th·ªëng th·ªùi gian th·ª±c Nghi√™n c·ª©u khoa h·ªçc ∆Øu ƒëi·ªÉm:\nT√≠nh di ƒë·ªông: T√≠nh di ƒë·ªông cao tr√™n c√°c n·ªÅn t·∫£ng ph·∫ßn c·ª©ng kh√°c nhau. C++ hi·ªán ƒë·∫°i: L·ª£i √≠ch t·ª´ s·ª± an to√†n v√† t√≠nh m·∫°nh m·∫Ω c·ªßa C++. Nh∆∞·ª£c ƒëi·ªÉm:\nƒê∆∞·ªùng cong h·ªçc t·∫≠p: Y√™u c·∫ßu quen thu·ªôc v·ªõi c·∫£ C++ hi·ªán ƒë·∫°i v√† c√°c kh√°i ni·ªám l·∫≠p tr√¨nh song song. Ph·ª• thu·ªôc v√†o c√¥ng c·ª•: Hi·ªáu su·∫•t v√† t√≠nh nƒÉng c√≥ th·ªÉ ph·ª• thu·ªôc nhi·ªÅu v√†o vi·ªác tri·ªÉn khai SYCL (v√≠ d·ª•: DPC++, hipSYCL). 4. Vulkan Compute T·ªïng quan:\nVulkan Compute l√† m·ªôt ph·∫ßn c·ªßa API ƒë·ªì h·ªça Vulkan h·ªó tr·ª£ c√°c shader t√≠nh to√°n cho t√≠nh to√°n t·ªïng qu√°t tr√™n GPU. ƒê·∫∑c ƒëi·ªÉm ch√≠nh:\nKi·ªÉm so√°t m·ª©c th·∫•p: Cung c·∫•p ki·ªÉm so√°t chi ti·∫øt v·ªÅ c√°c ho·∫°t ƒë·ªông c·ªßa GPU. ƒêa n·ªÅn t·∫£ng: Ho·∫°t ƒë·ªông tr√™n nhi·ªÅu h·ªá ƒëi·ªÅu h√†nh v√† nh√† cung c·∫•p ph·∫ßn c·ª©ng kh√°c nhau. Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng:\n·ª®ng d·ª•ng ƒë·ªì h·ªça v√† t√≠nh to√°n th·ªùi gian th·ª±c Ph√°t tri·ªÉn tr√≤ ch∆°i M√¥ ph·ªèng v√† h√¨nh ·∫£nh h√≥a ∆Øu ƒëi·ªÉm:\nHi·ªáu su·∫•t: Hi·ªáu qu·∫£ cao nh·ªù truy c·∫≠p m·ª©c th·∫•p v√†o ph·∫ßn c·ª©ng GPU. H·ªó tr·ª£ ƒëa nh√† cung c·∫•p: T∆∞∆°ng th√≠ch v·ªõi nhi·ªÅu lo·∫°i GPU. Nh∆∞·ª£c ƒëi·ªÉm:\nPh·ª©c t·∫°p: API m·ª©c th·∫•p y√™u c·∫ßu hi·ªÉu bi·∫øt chi ti·∫øt v·ªÅ ki·∫øn tr√∫c GPU. C√¥ng s·ª©c ph√°t tri·ªÉn: ƒê√≤i h·ªèi nhi·ªÅu c√¥ng s·ª©c ƒë·ªÉ thi·∫øt l·∫≠p v√† b·∫£o tr√¨ so v·ªõi c√°c API m·ª©c cao h∆°n. 5. Intel oneAPI T·ªïng quan:\nIntel oneAPI l√† m·ªôt m√¥ h√¨nh l·∫≠p tr√¨nh h·ª£p nh·∫•t thi·∫øt k·∫ø ƒë·ªÉ ƒë∆°n gi·∫£n h√≥a vi·ªác ph√°t tri·ªÉn tr√™n c√°c ki·∫øn tr√∫c ƒëa d·∫°ng nh∆∞ CPU, GPU, FPGA v√† b·ªô tƒÉng t·ªëc AI. ƒê·∫∑c ƒëi·ªÉm ch√≠nh:\nDPC++ (Data Parallel C++): M·ªôt ph·∫ßn m·ªü r·ªông c·ªßa SYCL cho oneAPI, h·ªó tr·ª£ m√£ ch·∫°y tr√™n c√°c ph·∫ßn c·ª©ng kh√°c nhau. Th∆∞ vi·ªán t·ªëi ∆∞u h√≥a: Cung c·∫•p c√°c th∆∞ vi·ªán hi·ªáu nƒÉng cho to√°n h·ªçc, ph√¢n t√≠ch d·ªØ li·ªáu, h·ªçc s√¢u, v.v. Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng:\nT√≠nh to√°n hi·ªáu nƒÉng cao AI v√† h·ªçc m√°y Ph√¢n t√≠ch d·ªØ li·ªáu ∆Øu ƒëi·ªÉm:\nKi·∫øn tr√∫c ch√©o: Cho ph√©p m·ªôt m√£ ngu·ªìn duy nh·∫•t ch·∫°y tr√™n nhi·ªÅu ph·∫ßn c·ª©ng Intel v√† kh√¥ng ph·∫£i Intel. H·ªá sinh th√°i: H·ªá sinh th√°i m·∫°nh v·ªõi nhi·ªÅu c√¥ng c·ª• v√† th∆∞ vi·ªán. Nh∆∞·ª£c ƒëi·ªÉm:\nT·∫≠p trung v√†o Intel: Ch·ªß y·∫øu t·ªëi ∆∞u h√≥a cho ph·∫ßn c·ª©ng Intel, c√≥ th·ªÉ kh√¥ng hi·ªáu qu·∫£ tr√™n c√°c thi·∫øt b·ªã kh√¥ng ph·∫£i c·ªßa Intel. M·ªõi: V·∫´n ƒëang ph√°t tri·ªÉn, c√≥ th·ªÉ √≠t t√†i nguy√™n so v·ªõi CUDA. 6. OpenMP (Open Multi-Processing) T·ªïng quan:\nOpenMP l√† m·ªôt API h·ªó tr·ª£ l·∫≠p tr√¨nh ƒëa n·ªÅn t·∫£ng b·ªô nh·ªõ chia s·∫ª ƒëa x·ª≠ l√Ω trong C, C++ v√† Fortran. C√°c phi√™n b·∫£n g·∫ßn ƒë√¢y bao g·ªìm c√°c ch·ªâ th·ªã ƒë·ªÉ t√≠nh to√°n tr√™n GPU. ƒê·∫∑c ƒëi·ªÉm ch√≠nh:\nCh·ªâ th·ªã tr√¨nh bi√™n d·ªãch: ƒê∆°n gi·∫£n h√≥a l·∫≠p tr√¨nh song song v·ªõi c√°c ch·ªâ th·ªã tr√¨nh bi√™n d·ªãch. H·ªó tr·ª£ CPU v√† GPU: C√°c phi√™n b·∫£n g·∫ßn ƒë√¢y h·ªó tr·ª£ t√≠nh to√°n tr√™n GPU. Song song h√≥a d·∫ßn d·∫ßn: Cho ph√©p song song h√≥a d·∫ßn d·∫ßn c√°c m√£ ngu·ªìn hi·ªán c√≥. Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng:\nB·ªô nh·ªõ chia s·∫ª ƒëa x·ª≠ l√Ω Song song h√≥a m√£ CPU hi·ªán c√≥ T√≠nh to√°n khoa h·ªçc hi·ªáu nƒÉng cao ∆Øu ƒëi·ªÉm:\nD·ªÖ s·ª≠ d·ª•ng: M√¥ h√¨nh song song ƒë∆°n gi·∫£n h∆°n so v·ªõi l·∫≠p tr√¨nh ƒëa lu·ªìng r√µ r√†ng. M√£ ngu·ªìn k·∫ø th·ª´a: T·ªët cho vi·ªác song song h√≥a c√°c m√£ ngu·ªìn CPU hi·ªán c√≥. Nh∆∞·ª£c ƒëi·ªÉm:\nKh·∫£ nƒÉng m·ªü r·ªông: Ph√π h·ª£p nh·∫•t cho c√°c h·ªá th·ªëng b·ªô nh·ªõ chia s·∫ª, c√≥ th·ªÉ kh√¥ng m·ªü r·ªông t·ªët cho c√°c h·ªá th·ªëng ph√¢n t√°n l·ªõn. Hi·ªáu su·∫•t: T√≠nh to√°n tr√™n GPU c√≥ th·ªÉ k√©m hi·ªáu qu·∫£ h∆°n so v·ªõi CUDA. L·ªùi k·∫øt C√°c l·ª±a ch·ªçn thay th·∫ø n√†y ƒë·ªÅu c√≥ nh·ªØng ƒëi·ªÉm m·∫°nh v√† y·∫øu ri√™ng, v√† l·ª±a ch·ªçn t·ªët nh·∫•t th∆∞·ªùng ph·ª• thu·ªôc v√†o c√°c y√™u c·∫ßu c·ª• th·ªÉ c·ªßa ·ª©ng d·ª•ng v√† c∆° s·ªü h·∫° t·∫ßng hi·ªán c√≥ c·ªßa ch√≠nh b·∫°n. C·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt. H·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Jun 12, 2024","img":"https://unsplash.it/1920/1080?image=15","permalink":"/blog/2024-06-12-cuda-alternate/","series":null,"tags":["Machine Learning","Parallel Computing","Cuda"],"title":"M·ªôt S·ªë Th∆∞ Vi·ªán T√≠nh To√°n Song Song Thay Th·∫ø Cho Cuda"},{"categories":null,"content":" 1. Ph√¢n t√≠ch h·ªìi quy (regression analysis) 1.1. Linear Regression: 1.2. Simple Linear Regression: 1.3. Multiple Linear Regression: 2. Ph√¢n t√≠ch nh√¢n t·ªë (Factor analysis) 3. Neural network 4. Ph√¢n t√≠ch c·ª•m (Cluster analysis) 5. Ph√¢n t√≠ch t·ªï h·ª£p - Ph√¢n t√≠ch theo nh√≥m (Cohort analysis) Cohort D·ª±a tr√™n Th·ªùi gian Cohort D·ª±a tr√™n l·ª£i √≠ch 6. Ph√¢n t√≠ch thu·ªôc t√≠nh - Ph√¢n t√≠ch k·∫øt h·ª£p (conjoint analysis) 7. Ph√¢n t√≠ch vƒÉn b·∫£n (Text analysis) 8. Ph√¢n t√≠ch chu·ªói th·ªùi gian (time series analysis) 9. Khai th√°c d·ªØ li·ªáu (Data mining) 10. C√¢y quy·∫øt ƒë·ªãnh (decision tree) Ngu·ªìn: Nh√¢n d·ªãp t·∫øt, r·∫£nh r·ªói ch·∫°y kpi vi·∫øt b√†i ƒë·ªÉ ƒë·∫£m b·∫£o s·ªë l∆∞·ª£ng b√†i vi·∫øt, ch·ª© ƒë·ªÉ c√°i website n√≥ mu·ªën m·ªëc meo h·∫øt c·∫£ r·ªìi. C∆° m√† vi·∫øt c√†ng nhi·ªÅu th√¨ c√†ng kh√¥ng ƒë·ªß, c√°i g√¨ c≈©ng mu·ªën vi·∫øt, th√†nh ra n√≥ d√†i d√≤ng, l√™ th√™, ng·ªìi ƒë·ªçc l·∫°i th·∫•y ch√°n ng√°n, n√™n ph·∫£i ng·ªìi t√©m t√©m n·ªôi dung l·∫°i. B√† con ƒë·ªçc th·∫•y ch·ªó n√†o c√≤n d√†i , c·∫ßn t√≥m, t√©m, g·ªçt th√¨ vui l√≤ng th·∫£y c√°i commend hen.\n1. Ph√¢n t√≠ch h·ªìi quy (regression analysis) Regression analysis l√† m·ªôt ph∆∞∆°ng ph√°p th·ªëng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn ph·ª• thu·ªôc (hay c√≤n ƒë∆∞·ª£c g·ªçi l√† bi·∫øn \u0026lsquo;outcome\u0026rsquo; ho·∫∑c bi·∫øn \u0026lsquo;response\u0026rsquo; ) v√† m·ªôt ho·∫∑c nhi·ªÅu bi·∫øn ƒë·ªôc l·∫≠p ( c≈©ng ƒë∆∞·ª£c g·ªçi v·ªõi t√™n l√† \u0026lsquo;predictors\u0026rsquo;, \u0026lsquo;covariates\u0026rsquo;, \u0026rsquo;explanatory variables\u0026rsquo;, \u0026lsquo;features\u0026rsquo;). Chi ti·∫øt:\n1.1. Linear Regression: H·ªìi quy tuy·∫øn t√≠nh l√† h√¨nh th·ª©c ph√¢n t√≠ch h·ªìi quy ph·ªï bi·∫øn nh·∫•t. N√≥ nh·∫±m m·ª•c ƒë√≠ch t√¨m ra ƒë∆∞·ªùng th·∫≥ng kh·ªõp v·ªõi d·ªØ li·ªáu nh·∫•t ( fitted line) theo m·ªôt s·ªë ti√™u ch√≠ to√°n h·ªçc c·ª• th·ªÉ n√†o ƒë√≥.\nH·ªìi quy tuy·∫øn t√≠nh gi·∫£ ƒë·ªãnh r·∫±ng c√°c m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn l√† tuy·∫øn t√≠nh v√† tho·∫£ c√°c gi·∫£ ƒë·ªãnh l√† normality of residuals v√† independence of errors. 1.2. Simple Linear Regression: Trong h·ªìi quy tuy·∫øn t√≠nh ƒë∆°n gi·∫£n, ch√∫ng ta ƒë√°nh gi√° m·ªëi quan h·ªá gi·ªØa m·ªôt bi·∫øn ph·ª• thu·ªôc duy nh·∫•t (Y) v√† m·ªôt bi·∫øn ƒë·ªôc l·∫≠p (X). Ph∆∞∆°ng tr√¨nh: Y = x +bX + epsilon\n1.3. Multiple Linear Regression: L√† bi·∫øn th·ªÉ m·ªü r·ªông c·ªßa h·ªìi quy tuy·∫øn t√≠nh ƒë∆°n gi·∫£n, v·ªõi nhi·ªÅu bi·∫øn ƒë·ªôc l·∫≠p X Ph∆∞∆°ng tr√¨nh: Y = x + bX1 + cX2 + dX3 ... + epsilon 2. Ph√¢n t√≠ch nh√¢n t·ªë (Factor analysis) Factor analysis l√† m·ªôt k·ªπ thu·∫≠t th·ªëng k√™, ph√¢n t√≠ch y·∫øu t·ªë nh·∫≠n di·ªán c·∫•u tr√∫c c∆° b·∫£n c·ªßa m·ªôt t·∫≠p h·ª£p c√°c bi·∫øn v√† gi·∫£i th√≠ch ch√∫ng d∆∞·ªõi d·∫°ng m·ªôt s·ªë l∆∞·ª£ng nh·ªè h∆°n c√°c y·∫øu t·ªë chung. Ph√¢n t√≠ch y·∫øu t·ªë gi√∫p gi·∫£m chi·ªÅu d·ªØ li·ªáu v√† s·ª± ph·ª©c t·∫°p c·ªßa n√≥, c≈©ng nh∆∞ kh√°m ph√° nh·ªØng y·∫øu t·ªë ti·ªÅm ·∫©n g√¢y ra s·ª± bi·∫øn ƒë·ªông chung c·ªßa c√°c bi·∫øn quan s√°t.\nPh√¢n lo·∫°i:\nExploratory factor analysis (EFA): Lo·∫°i ph√¢n t√≠ch n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng khi ng∆∞·ªùi ph√¢n t√≠ch kh√¥ng c√≥ hi·ªÉu bi·∫øt g√¨ v·ªÅ d·ªØ li·ªáu. M·ª•c ti√™u c·ªßa ph√¢n t√≠ch n√†y l√† t√¨m s·ªë factor t·ªëi ∆∞u v·ªõi ƒëi·ªÅu ki·ªán c·ª±c ƒë·∫°i ho√° c√°c bi·∫øn trong d·ªØ li·ªáu.\nConfirmatory factor analysis (CFA): Lo·∫°i ph√¢n t√≠ch n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng khi ng∆∞·ªùi ph√¢n t√≠ch c√≥ m√¥ h√¨nh l√Ω thu√™ts ho·∫∑c gi·∫£ thueyets v·ªÅ c√°c factor v√† m·ªëi quan h·ªá gi·ªØa ch√∫ng.\nPrincipal component analysis (PCA): D·∫°ng ph√¢n t√≠ch n√†y th∆∞·ªùng nh·∫ßm l·∫´n v·ªõi EFA, nh∆∞ng ch√∫ng kh√°c m·ª•c ti√™u v√† kh√°c gi·∫£ ƒë·ªãnh. M·ª•c ti√™u c·ªßa PCA l√† t√¨m ra s·ª± k·∫øt h·ª£p tuy·∫øn t√≠nh c·ªßa c√°c bi·∫øn quan s√°t ƒë·ªÉ thu ƒë∆∞·ª£c ph∆∞∆°ng sai l·ªõn nh·∫•t trong d·ªØ li·ªáu, m√† kh√¥ng gi·∫£ ƒë·ªãnh v·ªÅ b·∫•t k·ª≥ y·∫øu t·ªë ti·ªÅm ·∫©n n√†o. PCA th√≠ch h·ª£p h∆°n cho vi·ªác gi·∫£m k√≠ch th∆∞·ªõc d·ªØ li·ªáu v√† t√≥m t·∫Øt, trong khi Ph√¢n t√≠ch Y·∫øu t·ªë Kh√°m ph√° (EFA) th√≠ch h·ª£p h∆°n cho vi·ªác t√¨m ra c√°c kh√°i ni·ªám ti·ªÅm ·∫©n v√† m·ªëi quan h·ªá nguy√™n nh√¢n.\nFactor analysis tr·∫£i qua c√°c nhi·ªÅu b∆∞·ªõc sau:\nData preparation:Xem s·ªë d√≤ng, s·ªë c·ªôt, ph√¢n ph·ªëi c·ªßa c√°c bi·∫øn, m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn.\nFactor extraction: X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng c√°c factor c·∫ßn r√∫t tr√≠ch. S·ª≠ d·ª•ng principal component analysis, maximum likelihood, principal axis factoring, 3 ch·∫•m \u0026hellip;\nFactor rotation: B∆∞·ªõc n√†y d√πng ƒë·ªÉ c·∫£i thi·ªán kh·∫£ nƒÉng di·ªÖn gi·∫£i v√† tƒÉng t√≠nh r√µ r√†ng c·ªßa c√°c y·∫øu t·ªë b·∫±ng c√°ch thay ƒë·ªïi h∆∞·ªõng v√† v·ªã tr√≠ c·ªßa ch√∫ng. C√≥ hai lo·∫°i ch√≠nh : xoay g√≥c v√† xoay ch√©o. Xoay g√≥c gi·∫£ ƒë·ªãnh r·∫±ng c√°c y·∫øu t·ªë kh√¥ng t∆∞∆°ng quan, trong khi xoay ch√©o cho ph√©p m·ªôt s·ªë t∆∞∆°ng quan gi·ªØa c√°c y·∫øu t·ªë .\nFactor interpretation: ƒë·∫∑t t√™n cho c√°c factor ( b∆∞·ªõc n√†y kh√° kh√≥, do t√™n ph·∫£i cover ƒë∆∞·ª£c d·ªØ li·ªáu m√† n√≥ ƒëang handle).\nPh√¢n t√≠ch y·∫øu t·ªë l√† m·ªôt c√¥ng c·ª• h·ªØu √≠ch v√† m·∫°nh m·∫Ω ƒë·ªÉ kh√°m ph√° v√† x√°c nh·∫≠n c·∫•u tr√∫c c·ªßa d·ªØ li·ªáu, nh∆∞ng n√≥ c≈©ng mang ƒë·∫øn m·ªôt s·ªë h·∫°n ch·∫ø v√† th√°ch th·ª©c\nSubjectivity: M·ªói nh√† ph√¢n t√≠ch c√≥ m·ªôt chi·∫øn l∆∞·ª£c ph√¢n t√≠ch kh√°c nhau, n√™n c√≥ th·ªÉ s·∫Ω c√≥ c√°c b√°o c√°o kh√°c nhau, tr√™n c√πng m·ªôt d·ªØ li·ªáu.\nComplexity: Ph∆∞∆°ng ph√°p Factor analysis kh√° kh√≥ ti·∫øp c·∫≠n, ƒë√≤i h·ªèi ng∆∞·ªùi ph√¢n t√≠ch c√≥ ki·∫øn th·ª©c chuy√™n s√¢u v·ªÅ d·ªØ li·ªáu h·ªç ƒëang c√≥, v√† c√≥ ki·∫øn th·ª©c v·ªØng ch·∫Øc v·ªÅ th·ªëng k√™, gi·∫£i ƒë·ªãnh, c√≥ kh·∫£ nƒÉng s·ª≠ d·ª•ng c√°c tool ph√¢n t√≠ch d·ªØ li·ªáu l·ªõn.\nValidity: Ph∆∞∆°ng ph√°p n√†y kh√¥ng th·ªÉ d·ª©ng minh m·ªëi quan h·ªá nh√¢n qu·∫£ , t√≠nh h·ª£p l·ªá c·ªßa c√°c y·∫øu t·ªë. M·ªçi th√¥ng tin ƒë∆∞·ª£c r√∫t ra t·ª´ trong d·ªØ li·ªáu d·ª±a tr√™n c√°c ti√™u ch√≠ th·ªëng k√™ v√† c√°c gi·∫£ ƒëinh.\n3. Neural network M·ªôt m·∫°ng neural l√† m·ªôt lo·∫°i tr√≠ tu·ªá nh√¢n t·∫°o c·ªë g·∫Øng m√¥ ph·ªèng c√°ch n√£o ng∆∞·ªùi ho·∫°t ƒë·ªông. N√≥ bao g·ªìm nhi·ªÅu ƒë∆°n v·ªã ƒë∆∞·ª£c k·∫øt n·ªëi g·ªçi l√† neuron, ch√∫ng x·ª≠ l√Ω th√¥ng tin v√† h·ªçc t·ª´ d·ªØ li·ªáu. M·∫°ng neural c√≥ th·ªÉ th·ª±c hi·ªán nhi·ªÅu nhi·ªám v·ª• kh√°c nhau, nh∆∞ nh·∫≠n d·∫°ng gi·ªçng n√≥i, ph√¢n t√≠ch h√¨nh ·∫£nh v√† x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë kh√°i ni·ªám ch√≠nh c·ªßa m·∫°ng neural:\nM·ªôt m·∫°ng neural c√≥ nhi·ªÅu l·ªõp c·ªßa c√°c neuron, nh∆∞ l√† m·ªôt l·ªõp ƒë·∫ßu v√†o, m·ªôt ho·∫∑c nhi·ªÅu l·ªõp ·∫©n, v√† m·ªôt l·ªõp ƒë·∫ßu ra. M·ªói l·ªõp nh·∫≠n ƒë·∫ßu v√†o t·ª´ l·ªõp tr∆∞·ªõc ƒë√≥ v√† chuy·ªÉn ƒë·∫ßu ra cho l·ªõp k·∫ø ti·∫øp.\nM·ªói neuron c√≥ m·ªôt tr·ªçng s·ªë v√† m·ªôt ƒë·ªô l·ªách, quy·∫øt ƒë·ªãnh m·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa n√≥ ƒë·ªëi v·ªõi ƒë·∫ßu ra. Tr·ªçng s·ªë v√† ƒë·ªô l·ªách ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh trong qu√° tr√¨nh hu·∫•n luy·ªán, n∆°i m·∫°ng h·ªçc t·ª´ d·ªØ li·ªáu v√† c·∫£i thi·ªán hi·ªáu su·∫•t.\nM·ªói neuron c≈©ng c√≥ m·ªôt h√†m k√≠ch ho·∫°t, quy·∫øt ƒë·ªãnh li·ªáu neuron c√≥ ƒë∆∞·ª£c k√≠ch ho·∫°t hay kh√¥ng d·ª±a tr√™n ƒë·∫ßu v√†o. M·ªôt s·ªë h√†m k√≠ch ho·∫°t ph·ªï bi·∫øn bao g·ªìm sigmoid, tanh, v√† ReLU.\nC√≥ nhi·ªÅu lo·∫°i m·∫°ng neural kh√°c nhau, nh∆∞ m·∫°ng neural feedforward, m·∫°ng neural h·ªìi quy, m·∫°ng neural t√≠ch ch·∫≠p, v√† m·∫°ng neural s√¢u. M·ªói lo·∫°i c√≥ ki·∫øn tr√∫c, ∆∞u ƒëi·ªÉm v√† ·ª©ng d·ª•ng ri√™ng.\n4. Ph√¢n t√≠ch c·ª•m (Cluster analysis) Ph√¢n t√≠ch c·ª•m l√† m·ªôt ph∆∞∆°ng ph√°p ph√¢n t√≠ch d·ªØ li·ªáu nh√≥m c√°c ƒë·ªëi t∆∞·ª£ng d·ª±a tr√™n c√°c thu·ªôc t√≠nh chung c·ªßa ch√∫ng. N√≥ c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong h·ªçc m√°y, ph√¢n t√≠ch h√¨nh ·∫£nh, khai th√°c d·ªØ li·ªáu v√† nh·∫≠n d·∫°ng m·∫´u.\nT√¨m ra c·∫•u tr√∫c v√† s·ªë l∆∞·ª£ng c·ª•ng t·ªëi ∆∞u ph√π h·ª£p v·ªõi d·ªØ li·ªáu. C√≥ nhi·ªÅu lo·∫°i c·ª•m nh∆∞ c·ª•m c·∫ßu, c·ª•m ph√¢n c·∫•p, c·ª•m d·ª±a tr√™n m·∫≠t ƒë·ªô, c·ª•m kh√¥ng gian con, v√† c·ª•m d·ª±a tr√™n m√¥ h√¨nh.\nPh√¢n t√≠ch c·ª•m ƒë√≤i h·ªèi vi·ªác l·ª±a ch·ªçn m·ªôt thu·∫≠t to√°n ph√¢n c·ª•m ph√π h·ª£p v√† c√†i ƒë·∫∑t c√°c tham s·ªë c·ªßa n√≥. M·ªôt s·ªë thu·∫≠t to√°n ph√¢n c·ª•m ph·ªï bi·∫øn bao g·ªìm K-means, ph√¢n c·ª•m ph√¢n c·∫•p, DBSCAN, ph√¢n c·ª•m ph·ªï, v√† m√¥ h√¨nh h·ªón h·ª£p Gaussian.\nPh√¢n t√≠ch c·ª•m c≈©ng y√™u c·∫ßu ki·ªÉm ƒë·ªãnh v√† di·ªÖn gi·∫£i k·∫øt qu·∫£ ph√¢n c·ª•m. ƒêi·ªÅu n√†y c√≥ th·ªÉ ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c ph∆∞∆°ng ph√°p kh√°c nhau nh∆∞ ki·ªÉm ƒë·ªãnh th·ªëng k√™, so s√°nh v·ªõi c√°c l·ªõp ƒë√£ bi·∫øt, ho·∫∑c c√°c ti√™u ch√≠ c·ª• th·ªÉ cho t·ª´ng lƒ©nh v·ª±c.\nPh√¢n t√≠ch c·ª•m l√† m·ªôt c√¥ng c·ª• h·ªØu √≠ch v√† m·∫°nh m·∫Ω ƒë·ªÉ kh√°m ph√° v√† x√°c nh·∫≠n c·∫•u tr√∫c c·ªßa d·ªØ li·ªáu, nh∆∞ng n√≥ c≈©ng c√≥ m·ªôt s·ªë h·∫°n ch·∫ø v√† th√°ch th·ª©c:\nT√≠nh ch·ªß quan: Ph√¢n t√≠ch c·ª•m li√™n quan ƒë·∫øn nhi·ªÅu quy·∫øt ƒë·ªãnh v√† ƒë√°nh gi√° t·ª´ ph√≠a nghi√™n c·ª©u, nh∆∞ lo·∫°i ph√¢n t√≠ch c·ª•m, ph∆∞∆°ng ph√°p ph√¢n c·ª•m, s·ªë l∆∞·ª£ng c·ª•m, v√† c√°ch di·ªÖn gi·∫£i c·ª•m. Nh·ªØng l·ª±a ch·ªçn n√†y c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn k·∫øt qu·∫£ v√† k·∫øt lu·∫≠n c·ªßa ph√¢n t√≠ch, v√† c√°c nh√† nghi√™n c·ª©u kh√°c nhau c√≥ th·ªÉ thu ƒë∆∞·ª£c k·∫øt qu·∫£ kh√°c nhau t·ª´ c√πng m·ªôt d·ªØ li·ªáu.\nƒê·ªô ph·ª©c t·∫°p: Ph√¢n t√≠ch c·ª•m c√≥ th·ªÉ kh√≥ hi·ªÉu v√† √°p d·ª•ng ƒë√∫ng, ƒë·∫∑c bi·ªát l√† ƒë·ªëi v·ªõi ng∆∞·ªùi m·ªõi h·ªçc v√† ng∆∞·ªùi kh√¥ng chuy√™n v·ªÅ th·ªëng k√™. N√≥ ƒë√≤i h·ªèi s·ª± hi·ªÉu bi·∫øt t·ªët v·ªÅ l√Ω thuy·∫øt c∆° b·∫£n, gi·∫£ ƒë·ªãnh, ph∆∞∆°ng ph√°p v√† c√¥ng th·ª©c c∆° b·∫£n, c≈©ng nh∆∞ kh·∫£ nƒÉng s·ª≠ d·ª•ng ph·∫ßn m·ªÅm v√† c√¥ng c·ª• ph√π h·ª£p.\nT√≠nh h·ª£p l·ªá: Ph√¢n t√≠ch c·ª•m kh√¥ng ch·ª©ng minh s·ª± nh√¢n qu·∫£ ho·∫∑c t√≠nh h·ª£p l·ªá c·ªßa c√°c c·ª•m. N√≥ ch·ªâ cung c·∫•p m·ªôt gi·∫£i th√≠ch c√≥ th·ªÉ v·ªÅ d·ªØ li·ªáu d·ª±a tr√™n ti√™u ch√≠ th·ªëng k√™ v√† gi·∫£ ƒë·ªãnh. Ng∆∞·ªùi nghi√™n c·ª©u lu√¥n n√™n ki·ªÉm tra t√≠nh h·ª£p l·ªá v√† ƒë·ªô tin c·∫≠y c·ªßa c√°c c·ª•m b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c ph∆∞∆°ng ph√°p kh√°c nh∆∞ ch·ªâ s·ªë alpha c·ªßa Cronbach, t√≠nh h·ª£p l·ªá x√¢y d·ª±ng, t√≠nh h·ª£p l·ªá h·ªôi t·ª•, t√≠nh h·ª£p l·ªá ph√¢n lo·∫°i.\n5. Ph√¢n t√≠ch t·ªï h·ª£p - Ph√¢n t√≠ch theo nh√≥m (Cohort analysis) Ph√¢n t√≠ch nh√≥m l√† m·ªôt k·ªπ thu·∫≠t quan tr·ªçng trong lƒ©nh v·ª±c ph√¢n t√≠ch h√†nh vi.\nPh√¢n t√≠ch nh√≥m li√™n quan ƒë·∫øn vi·ªác chia d·ªØ li·ªáu t·ª´ m·ªôt b·ªô d·ªØ li·ªáu th√†nh c√°c nh√≥m li√™n quan, ƒë∆∞·ª£c g·ªçi l√† cohort, thay v√¨ xem x√©t d·ªØ li·ªáu nh∆∞ m·ªôt ƒë∆°n v·ªã duy nh·∫•t.\nC√°c nh√≥m n√†y c√≥ c√°c ƒë·∫∑c ƒëi·ªÉm t∆∞∆°ng t·ª±, ch·∫≥ng h·∫°n nh∆∞ th·ªùi gian tham gia ho·∫∑c k√≠ch th∆∞·ªõc.\nCohort analysis th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nhi·ªÅu lƒ©nh v·ª±c, v√≠ nh∆∞ doanh nghi·ªáp cung c·∫•p d·ªãch v·ª• ƒë√°m m√¢y, doanh nghi·ªáp kinh doanh tr√≤ ch∆°i , c√°c n·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠, c√°c doanh nghi·ªáp b√°n l·∫ª, b·∫•t ƒë·ªông s·∫£n, ng√¢n h√†ng \u0026hellip;.\nM·ª•c ti√™u ch√≠nh c·ªßa ph√¢n t√≠ch nh√≥m l√† hi·ªÉu h√†nh vi c·ªßa kh√°ch h√†ng qua to√†n b·ªô v√≤ng ƒë·ªùi c·ªßa m·ªói kh√°ch h√†ng.\nB·∫±ng c√°ch nh√≥m kh√°ch h√†ng th√†nh c√°c nh√≥m qu·∫£n l√Ω ƒë∆∞·ª£c, doanh nghi·ªáp c√≥ c√°i nh√¨n s√¢u s·∫Øc v·ªÅ xu h∆∞·ªõng v√† m√¥ h√¨nh theo th·ªùi gian.\nN√≥ gi√∫p ƒëi·ªÅu ch·ªânh c√°c ∆∞u ƒë√£i s·∫£n ph·∫©m v√† chi·∫øn l∆∞·ª£c ti·∫øp th·ªã cho c√°c ph√¢n kh√∫c kh√°ch h√†ng c·ª• th·ªÉ.\nCohort D·ª±a tr√™n Th·ªùi gian C√°c nh√≥m n√†y bao g·ªìm kh√°ch h√†ng ƒëƒÉng k√Ω s·ª≠ d·ª•ng s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª• trong m·ªôt kho·∫£ng th·ªùi gian c·ª• th·ªÉ (v√≠ d·ª•, h√†ng th√°ng ho·∫∑c h√†ng qu√Ω).\nPh√¢n t√≠ch nh√≥m d·ª±a tr√™n th·ªùi gian cho th·∫•y c√°ch h√†nh vi c·ªßa kh√°ch h√†ng thay ƒë·ªïi d·ª±a tr√™n th·ªùi ƒëi·ªÉm h·ªç b·∫Øt ƒë·∫ßu s·ª≠ d·ª•ng s·∫£n ph·∫©m c·ªßa c√¥ng ty.\nV√≠ d·ª•, so s√°nh t·ª∑ l·ªá gi·ªØ l·∫°i gi·ªØa ƒëƒÉng k√Ω Q1 v√† Q2 c√≥ th·ªÉ l√†m n·ªïi b·∫≠t c√°c v·∫•n ƒë·ªÅ ti·ªÅm ·∫©n ho·∫∑c th√°ch th·ª©c t·ª´ ƒë·ªëi th·ªß.\nN√≥ c≈©ng gi√∫p ƒë√°nh gi√° t·ª∑ l·ªá chuy·ªÉn ƒë·ªïi v√† x√°c ƒë·ªãnh nguy√™n nh√¢n ƒë·∫±ng sau vi·ªác m·∫•t kh√°ch h√†ng.\nCohort D·ª±a tr√™n l·ª£i √≠ch Hi·ªÉu R√µ H√†nh Vi Kh√°ch H√†ng: Ph√¢n t√≠ch nh√≥m mang l·∫°i c√°i nh√¨n t·ª∑ m·ªã v·ªÅ c√°ch c√°c nh√≥m kh√°ch h√†ng kh√°c nhau th·ªÉ hi·ªán h√†nh vi qua th·ªùi gian.\nT·ªëi ∆Øu H√≥a Ti·∫øp Th·ªã: B·∫±ng c√°ch hi·ªÉu h√†nh vi nh√≥m, doanh nghi·ªáp c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh n·ªó l·ª±c ti·∫øp th·ªã v√† chi·∫øn l∆∞·ª£c giao ti·∫øp.\nC·∫£i Ti·∫øn S·∫£n Ph·∫©m: C√°c th√¥ng tin t·ª´ ph√¢n t√≠ch nh√≥m h∆∞·ªõng d·∫´n cho s·ª± c·∫£i ti·∫øn s·∫£n ph·∫©m v√† ph√°t tri·ªÉn t√≠nh nƒÉng.\nC√¢u n√≥i ƒÉn ti·ªÅn: ph√¢n t√≠ch kh√¥ng ch·ªâ ƒë∆°n thu·∫ßn l√† v·ªÅ nh·ªØng con s·ªë; n√≥ l√† v·ªÅ vi·ªác hi·ªÉu nh·ªØng c√¢u chuy·ªán ƒë·∫±ng sau nh·ªØng con s·ªë ƒë√≥ v√† ra quy·∫øt ƒë·ªãnh th√¥ng tin d·ª±a tr√™n h√†nh vi c·ªßa kh√°ch h√†ng.\n6. Ph√¢n t√≠ch thu·ªôc t√≠nh - Ph√¢n t√≠ch k·∫øt h·ª£p (conjoint analysis) Ph√¢n t√≠ch k·∫øt h·ª£p l√† m·ªôt k·ªπ thu·∫≠t th·ªëng k√™ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nghi√™n c·ª©u th·ªã tr∆∞·ªùng ƒë·ªÉ hi·ªÉu c√°ch kh√°ch h√†ng ƒë√°nh gi√° c√°c thu·ªôc t√≠nh kh√°c nhau c·ªßa m·ªôt s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª•.\nN√≥ d·ª±a tr√™n nguy√™n t·∫Øc r·∫±ng b·∫•t k·ª≥ s·∫£n ph·∫©m n√†o c≈©ng c√≥ th·ªÉ ph√¢n r√£ th√†nh m·ªôt t·∫≠p h·ª£p c√°c thu·ªôc t√≠nh ·∫£nh h∆∞·ªüng ƒë·∫øn gi√° tr·ªã ƒë∆∞·ª£c ng∆∞·ªùi d√πng c·∫£m nh·∫≠n ƒë·ªëi v·ªõi m·ªôt m·ª•c ho·∫∑c d·ªãch v·ª•.\nPh√¢n t√≠ch k·∫øt h·ª£p th∆∞·ªùng ƒë∆∞·ª£c th·ª±c hi·ªán th√¥ng qua m·ªôt cu·ªôc kh·∫£o s√°t chuy√™n bi·ªát y√™u c·∫ßu ng∆∞·ªùi ti√™u d√πng x·∫øp h·∫°ng s·ª± quan tr·ªçng c·ªßa c√°c ƒë·∫∑c ƒëi·ªÉm c·ª• th·ªÉ. Ph√¢n t√≠ch k·∫øt qu·∫£ cho ph√©p c√¥ng ty g√°n gi√° tr·ªã cho m·ªói ƒë·∫∑c ƒëi·ªÉm.\nC√≥ nhi·ªÅu lo·∫°i ph√¢n t√≠ch k·∫øt h·ª£p, bao g·ªìm\nPh√¢n t√≠ch H·ªôi t·ª• D·ª±a tr√™n S·ª± L·ª±a Ch·ªçn (CBC)\nPh√¢n t√≠ch H·ªôi t·ª• Th√≠ch ·ª©ng (ACA)\nPh√¢n t√≠ch H·ªôi t·ª• To√†n b·ªô\nPh√¢n t√≠ch H·ªôi t·ª• MaxDiff\nVi·ªác c√°c c√¥ng ty s·ª≠ d·ª•ng lo·∫°i ph√¢n t√≠ch h·ªôi t·ª• n√†o, ph·ª• thu·ªôc v√†o m·ª•c ti√™u ƒë·ªãnh h√¨nh ph√¢n t√≠ch v√† lo·∫°i s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª• ƒëang ƒë∆∞·ª£c ƒë√°nh gi√°.\nPh√¢n t√≠ch h·ªôi t·ª• c√≥ th·ªÉ gi√∫p doanh nghi·ªáp hi·ªÉu ƒë∆∞·ª£c nh·ªØng ƒë·∫∑c t√≠nh n√†o c·ªßa s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª• c·ªßa h·ªç ƒë∆∞·ª£c kh√°ch h√†ng ƒë√°nh gi√° cao nh·∫•t, v√† g√°n m·ªôt gi√° tr·ªã c·ª• th·ªÉ cho m·ªói ƒë·∫∑c t√≠nh. Hi·ªÉu bi·∫øt n√†y cho ph√©p x√¢y d·ª±ng chi·∫øn l∆∞·ª£c c√≥ th√¥ng tin h∆°n t·ª´ l√¢u d√†i ƒë·∫øn gi√° c·∫£ v√† b√°n h√†ng.\n7. Ph√¢n t√≠ch vƒÉn b·∫£n (Text analysis) Ph√¢n t√≠ch vƒÉn b·∫£n l√† qu√° tr√¨nh tr√≠ch xu·∫•t th√¥ng tin gi√° tr·ªã t·ª´ d·ªØ li·ªáu vƒÉn b·∫£n kh√¥ng c√≥ c·∫•u tr√∫c. N√≥ c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng cho nhi·ªÅu m·ª•c ƒë√≠ch kh√°c nhau nh∆∞ hi·ªÉu ph·∫£n h·ªìi c·ªßa kh√°ch h√†ng, t√≥m t·∫Øt t√†i li·ªáu, x√°c ƒë·ªãnh ch·ªß ƒë·ªÅ v√† ph√¢n lo·∫°i c·∫£m x√∫c. Ph√¢n t√≠ch vƒÉn b·∫£n c√≥ th·ªÉ th·ª±c hi·ªán b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c ph∆∞∆°ng ph√°p v√† k·ªπ thu·∫≠t kh√°c nhau, ph·ª• thu·ªôc v√†o lo·∫°i vƒÉn b·∫£n v√† m·ª•c ti√™u nghi√™n c·ª©u. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë ph∆∞∆°ng ph√°p ph·ªï bi·∫øn:\nSentiment analysis: Ph∆∞∆°ng ph√°p n√†y x√°c ƒë·ªãnh c·∫£m x√∫c c·ªßa vƒÉn b·∫£n, nh∆∞ t√≠ch c·ª±c, ti√™u c·ª±c ho·∫∑c trung t√≠nh. N√≥ c√≥ th·ªÉ gi√∫p doanh nghi·ªáp ƒëo l∆∞·ªùng s·ª± h√†i l√≤ng c·ªßa kh√°ch h√†ng, danh ti·∫øng th∆∞∆°ng hi·ªáu v√† ƒë√°nh gi√° s·∫£n ph·∫©m.\nPh√¢n t√≠ch ch·ªß ƒë·ªÅ: Ph∆∞∆°ng ph√°p n√†y x√°c ƒë·ªãnh c√°c ch·ªß ƒë·ªÅ ch√≠nh c·ªßa vƒÉn b·∫£n, nh∆∞ th·ªÉ thao, ch√≠nh tr·ªã, ho·∫∑c gi·∫£i tr√≠. N√≥ c√≥ th·ªÉ gi√∫p doanh nghi·ªáp t·ªï ch·ª©c v√† ph√¢n lo·∫°i l∆∞·ª£ng l·ªõn d·ªØ li·ªáu vƒÉn b·∫£n nh∆∞ email, b√†i vi·∫øt tr√™n m·∫°ng x√£ h·ªôi v√† y√™u c·∫ßu h·ªó tr·ª£.\nTr√≠ch xu·∫•t t·ª´ kh√≥a: Ph∆∞∆°ng ph√°p n√†y tr√≠ch xu·∫•t c√°c t·ª´ ho·∫∑c c·ª•m t·ª´ quan tr·ªçng nh·∫•t t·ª´ vƒÉn b·∫£n, nh∆∞ t√™n, ƒë·ªãa ƒëi·ªÉm ho·∫∑c kh√°i ni·ªám. N√≥ c√≥ th·ªÉ gi√∫p doanh nghi·ªáp t√¨m ki·∫øm th√¥ng tin quan tr·ªçng nh∆∞ v·∫•n ƒë·ªÅ c·ªßa kh√°ch h√†ng, ƒë·∫∑c ƒëi·ªÉm s·∫£n ph·∫©m ho·∫∑c xu h∆∞·ªõng th·ªã tr∆∞·ªùng.\nPh√¢n t√≠ch vƒÉn b·∫£n c√≥ th·ªÉ th·ª±c hi·ªán th·ªß c√¥ng ho·∫∑c t·ª± ƒë·ªông. Ph√¢n t√≠ch vƒÉn b·∫£n th·ªß c√¥ng t·ªën th·ªùi gian, d·ªÖ ch√°n v√† d·ªÖ g·∫∑p l·ªói. Ph√¢n t√≠ch vƒÉn b·∫£n t·ª± ƒë·ªông s·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t h·ªçc m√°y ƒë·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu vƒÉn b·∫£n m·ªôt c√°ch nhanh ch√≥ng, ch√≠nh x√°c v√† c√≥ th·ªÉ m·ªü r·ªông. Hi·ªán nay, C√≥ nhi·ªÅu c√¥ng c·ª• tr·ª±c tuy·∫øn gi√∫p th·ª±c hi·ªán ph√¢n t√≠ch vƒÉn b·∫£n m·ªôt c√°ch t·ª± ƒë·ªông. V·ªÅ ti·∫øng vi·ªát th√¨ ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng th∆∞ vi·ªán under the sea, ho·∫∑c n·∫øu c√°c b·∫°n c√≥ d·ªØ li·ªáu l·ªõn th√¨ c√≥ th·ªÉ implement l·∫°i c√°c thu·∫≠t to√°n ƒë√£ public v√† train l·∫°i m√¥ h√¨nh\n8. Ph√¢n t√≠ch chu·ªói th·ªùi gian (time series analysis) Ph√¢n t√≠ch chu·ªói th·ªùi gian l√† m·ªôt c√°ch c·ª• th·ªÉ ƒë·ªÉ ph√¢n t√≠ch m·ªôt chu·ªói ƒëi·ªÉm d·ªØ li·ªáu ƒë∆∞·ª£c thu th·∫≠p trong m·ªôt kho·∫£ng th·ªùi gian. Kh√°c v·ªõi vi·ªác thu th·∫≠p d·ªØ li·ªáu ng·∫´u nhi√™n ho·∫∑c r·∫£i r√°c, ph√¢n t√≠ch chu·ªói th·ªùi gian li√™n quan ƒë·∫øn vi·ªác ghi l·∫°i c√°c ƒëi·ªÉm d·ªØ li·ªáu ·ªü c√°c kho·∫£ng th·ªùi gian ƒë·ªÅu ƒë·∫∑n trong m·ªôt kho·∫£ng th·ªùi gian c·ªë ƒë·ªãnh. S·ª± kh√°c bi·ªát ch√≠nh n·∫±m ·ªü c√°ch c√°c bi·∫øn thay ƒë·ªïi theo th·ªùi gian. D·ªØ li·ªáu chu·ªói th·ªùi gian cung c·∫•p th√¥ng tin qu√Ω gi√° v·ªÅ xu h∆∞·ªõng, d·ª± ƒëo√°n.\nPh√¢n t√≠ch chu·ªói th·ªùi gian x·ª≠ l√Ω c√°c ƒëi·ªÉm d·ªØ li·ªáu ƒë∆∞·ª£c s·∫Øp x·∫øp theo th·ªùi gian. V√≠ d·ª• bao g·ªìm chi·ªÅu cao c·ªßa ƒë·ª£t th·ªßy tri·ªÅu, t·ªëc ƒë·ªô gi√≥ tr√™n bi·ªÉn, ƒë·ªô d√†y c·ªßa s∆∞∆°ng m√π, gi√° ƒë√≥ng c·ª≠a h√†ng ng√†y tr√™n th·ªã tr∆∞·ªùng ch·ª©ng kho√°n, ƒë·ªÉ:\nHi·ªÉu r√µ Xu h∆∞·ªõng: C√°c t·ªï ch·ª©c s·ª≠ d·ª•ng ph√¢n t√≠ch chu·ªói th·ªùi gian ƒë·ªÉ hi·ªÉu nguy√™n nh√¢n c∆° b·∫£n c·ªßa c√°c xu h∆∞·ªõng ho·∫∑c m√¥ h√¨nh h·ªá th·ªëng theo th·ªùi gian. C√°c bi·ªÉu ƒë·ªì minh h·ªça xu h∆∞·ªõng theo m√πa v·ª•, v√† c√°c n·ªÅn t·∫£ng ph√¢n t√≠ch hi·ªán ƒë·∫°i v∆∞·ª£t xa c√°c bi·ªÉu ƒë·ªì ƒë∆∞·ªùng ƒë∆°n gi·∫£n.\nD·ª± ƒëo√°n: D·ª± b√°o chu·ªói th·ªùi gian d·ª± ƒëo√°n gi√° tr·ªã t∆∞∆°ng lai d·ª±a tr√™n d·ªØ li·ªáu l·ªãch s·ª≠. N√≥ gi√∫p d·ª± ƒëo√°n c√°c bi·∫øn ƒë·ªïi, nh∆∞ m√πa v·ª• ho·∫∑c h√†nh vi chu k·ª≥.\nT√†i ch√≠nh: Ph√¢n t√≠ch bi·∫øn ƒë·ªông ti·ªÅn t·ªá, gi√° c·ªï phi·∫øu v√† c√°c ch·ªâ s·ªë kinh t·∫ø.\nB√°n l·∫ª: Nghi√™n c·ª©u d·ªØ li·ªáu b√°n h√†ng v√† m√¥ h√¨nh y√™u c·∫ßu.\nD·ª± b√°o th·ªùi ti·∫øt: D·ª± ƒëo√°n ƒëi·ªÅu ki·ªán th·ªùi ti·∫øt d·ª±a tr√™n d·ªØ li·ªáu l·ªãch s·ª≠.\nChƒÉm s√≥c s·ª©c kh·ªèe: Gi√°m s√°t c√°c ch·ªâ s·ªë quan tr·ªçng c·ªßa b·ªánh nh√¢n theo th·ªùi gian.\nKinh t·∫ø h·ªçc: Theo d√µi c√°c ch·ªâ s·ªë kinh t·∫ø nh∆∞ tƒÉng tr∆∞·ªüng GDP.\n9. Khai th√°c d·ªØ li·ªáu (Data mining) Khai th√°c d·ªØ li·ªáu l√† qu√° tr√¨nh tr√≠ch xu·∫•t v√† kh√°m ph√° c√°c m√¥ h√¨nh trong c√°c t·∫≠p d·ªØ li·ªáu l·ªõn li√™n quan ƒë·∫øn c√°c ph∆∞∆°ng ph√°p ·ªü s·ª± giao l·ªô gi·ªØa h·ªçc m√°y, th·ªëng k√™ v√† h·ªá th·ªëng c∆° s·ªü d·ªØ li·ªáu. Khai th√°c d·ªØ li·ªáu c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng cho nhi·ªÅu m·ª•c ƒë√≠ch, nh∆∞ hi·ªÉu c·∫•u tr√∫c v√† m√¥ h√¨nh c∆° b·∫£n c·ªßa d·ªØ li·ªáu, ph√¢n t√≠ch hi·ªáu su·∫•t c·ªßa m·ªôt c√¥ng ty, ho·∫∑c d·ª± ƒëo√°n doanh thu v√† ·∫£nh h∆∞·ªüng c·ªßa quy·∫øt ƒë·ªãnh kinh doanh. Khai th√°c d·ªØ li·ªáu ph·ª• thu·ªôc v√†o vi·ªác thu th·∫≠p d·ªØ li·ªáu hi·ªáu qu·∫£, l∆∞u tr·ªØ v√† x·ª≠ l√Ω m√°y t√≠nh.\nC√°c b√†i to√°n trong data mining bao g·ªìm: Classification, Clustering, Association rule mining, Sequential pattern mining, Anomaly detection\nKhai th√°c d·ªØ li·ªáu c√≥ th·ªÉ ƒë∆∞·ª£c √°p d·ª•ng trong nhi·ªÅu lƒ©nh v·ª±c nh∆∞ t√†i ch√≠nh, b√°n l·∫ª, d·ª± b√°o th·ªùi ti·∫øt, chƒÉm s√≥c s·ª©c kh·ªèe v√† kinh t·∫ø. Khai th√°c d·ªØ li·ªáu c√≥ th·ªÉ gi√∫p t·ªï ch·ª©c ƒë·∫°t ƒë∆∞·ª£c th√¥ng tin, ƒë∆∞a ra quy·∫øt ƒë·ªãnh t·ªët h∆°n v√† c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa h·ªç. Tuy nhi√™n, khai th√°c d·ªØ li·ªáu c≈©ng ƒë·∫∑t ra m·ªôt s·ªë th√°ch th·ª©c v√† r·ªßi ro, nh∆∞ ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu, quy·ªÅn ri√™ng t∆∞, an ninh v√† ƒë·∫°o ƒë·ª©c. Do ƒë√≥, khai th√°c d·ªØ li·ªáu n√™n ƒë∆∞·ª£c th·ª±c hi·ªán c·∫©n th·∫≠n v√† t√¥n tr·ªçng ƒë·ªëi v·ªõi d·ªØ li·ªáu v√† nh·ªØng ng∆∞·ªùi li√™n quan.\n10. C√¢y quy·∫øt ƒë·ªãnh (decision tree) M·ªôt c√¢y quy·∫øt ƒë·ªãnh l√† m·ªôt bi·ªÉu di·ªÖn c·ªßa c√°c duy·ªát ƒë·ªãnh d·ª©oi d·∫°ng c√¢y. N√≥ c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng cho c·∫£ c√°c nhi·ªám v·ª• ph√¢n lo·∫°i v√† h·ªìi quy trong h·ªçc m√°y gi√°m s√°t. M·ªôt c√¢y quy·∫øt ƒë·ªãnh bao g·ªìm c√°c n√∫t, nh√°nh v√† l√° t∆∞∆°ng ·ª©ng v·ªõi c√°c ƒë·∫∑c tr∆∞ng, quy t·∫Øc v√† d·ª± ƒëo√°n c·ªßa d·ªØ li·ªáu. M·ªôt c√¢y quy·∫øt ƒë·ªãnh ƒë∆∞·ª£c x√¢y d·ª±ng b·∫±ng c√°ch chia d·ªØ li·ªáu th√†nh c√°c t·∫≠p con d·ª±a tr√™n gi√° tr·ªã c·ªßa c√°c ƒë·∫∑c tr∆∞ng cho ƒë·∫øn khi ƒë·∫°t ƒë·∫øn m·ªôt ti√™u ch√≠ d·ª´ng. Ti√™u ch√≠ chia th∆∞·ªùng d·ª±a tr√™n m·ªôt ƒë·ªô ƒë·ªìng nh·∫•t ho·∫∑c ph∆∞∆°ng sai, ch·∫≥ng h·∫°n nh∆∞ entropy ho·∫∑c ch·ªâ s·ªë Gini\nM·ªôt s·ªë ∆∞u ƒëi·ªÉm c·ªßa c√¢y quy·∫øt ƒë·ªãnh bao g·ªìm:\nD·ªÖ hi·ªÉu v√† gi·∫£i th√≠ch, v√¨ ch√∫ng gi·ªëng nh∆∞ qu√° tr√¨nh suy lu·∫≠n c·ªßa con ng∆∞·ªùi.\nC√≥ th·ªÉ x·ª≠ l√Ω c·∫£ d·ªØ li·ªáu s·ªë v√† d·ªØ li·ªáu ph√¢n lo·∫°i, c≈©ng nh∆∞ c√≥ th·ªÉ x·ª≠ l√Ω gi√° tr·ªã thi·∫øu.\nCh·ªãu ƒë∆∞·ª£c ·∫£nh h∆∞·ªüng t·ª´ nhi·ªÖu v√† gi·ªØ nguy√™n t√≠nh ch·∫•t khi d·ªØ li·ªáu kh√¥ng c√¢n b·∫±ng.\nM·ªôt s·ªë nh∆∞·ª£c ƒëi·ªÉm c·ªßa c√¢y quy·∫øt ƒë·ªãnh l√†:\nD·ªÖ b·ªã overfitting, c√¢y c√†ng s√¢u, c√†ng ph·ª©c t·∫°p th√¨ c√†ng d·ªÖ b·ªã overfitting.\nC√≥ th·ªÉ kh√¥ng ·ªïn ƒë·ªãnh, v√¨ nh·ªØng thay ƒë·ªïi nh·ªè trong d·ªØ li·ªáu c√≥ th·ªÉ d·∫´n ƒë·∫øn nh·ªØng thay ƒë·ªïi l·ªõn trong c·∫•u tr√∫c c√¢y.\nC√≥ th·ªÉ b·ªã thi√™n v·ªã, v√¨ ch√∫ng c√≥ xu h∆∞·ªõng ∆∞a th√≠ch ƒë·∫∑c tr∆∞ng c√≥ nhi·ªÅu c·∫•p ƒë·ªô ho·∫∑c lo·∫°i.\nNgu·ªìn: Regression analysis - Wikipedia. https://en.wikipedia.org/wiki/Regression_analysis.\nRegression Analysis - Formulas, Explanation, Examples and Definitions. https://corporatefinanceinstitute.com/resources/data-science/regression-analysis/.\nSimple Linear Regression | An Easy Introduction \u0026amp; Examples - Scribbr. https://www.scribbr.com/statistics/simple-linear-regression/.\nFactor analysis - Wikipedia. https://en.wikipedia.org/wiki/Factor_analysis.\nFactor Analysis Guide with an Example - Statistics By Jim. https://statisticsbyjim.com/basics/factor-analysis/.\nFactor Analysis - Steps, Methods and Examples - Research Method. https://researchmethod.net/factor-analysis/.\nFactor analysis - Wikipedia. https://en.wikipedia.org/wiki/Factor_analysis.\nFactor Analysis Guide with an Example - Statistics By Jim. https://statisticsbyjim.com/basics/factor-analysis/.\nFactor Analysis - Steps, Methods and Examples - Research Method. https://researchmethod.net/factor-analysis/.\nWhat are Neural Networks? | IBM. https://www.ibm.com/topics/neural-networks.\nNeural network - Wikipedia. https://en.wikipedia.org/wiki/Neural_network.\nWhat are Neural Networks? | IBM. https://www.ibm.com/topics/neural-networks.\nNeural network - Wikipedia. https://en.wikipedia.org/wiki/Neural_network.\nWhat Is a Neural Network? - Investopedia. https://www.investopedia.com/terms/n/neuralnetwork.asp.\nWhat is a neural network? A computer scientist explains - The Conversation. https://theconversation.com/what-is-a-neural-network-a-computer-scientist-explains-151897.\nCluster analysis - Wikipedia. https://en.wikipedia.org/wiki/Cluster_analysis.\nCluster Analysis - Types, Methods and Examples - Research Method. https://researchmethod.net/cluster-analysis/.\nWhat Is Cluster Analysis? (Examples + Applications) | Built In. https://builtin.com/data-science/cluster-analysis.\nCluster analysis - Wikipedia. https://en.wikipedia.org/wiki/Cluster_analysis.\nCluster Analysis - Types, Methods and Examples - Research Method. https://researchmethod.net/cluster-analysis/.\nWhat Is Cluster Analysis? (Examples + Applications) | Built In. https://builtin.com/data-science/cluster-analysis.\nGetty Images. https://www.gettyimages.com/detail/illustration/big-data-illustration-with-structuring-map-royalty-free-illustration/1139303464.\nhttps://online.hbs.edu/blog/post/what-is-conjoint-analysis\nWhat Is Conjoint Analysis \u0026amp; How Can You Use It? | HBS Online. https://online.hbs.edu/blog/post/what-is-conjoint-analysis.\nConjoint analysis - Wikipedia. https://en.wikipedia.org/wiki/Conjoint_analysis.\nWhat is a Conjoint Analysis? Types \u0026amp; Use Cases - Qualtrics. https://www.qualtrics.com/experience-management/research/types-of-conjoint/.\nen.wikipedia.org. https://en.wikipedia.org/wiki/Conjoint_analysis.\nText Analysis: Definition, Benefits \u0026amp; Examples - Qualtrics XM. https://www.qualtrics.com/experience-management/research/text-analysis/.\nTextual Analysis | Guide, 3 Approaches \u0026amp; Examples - Scribbr. https://www.scribbr.com/methodology/textual-analysis/.\nTime Series Analysis: Definition, Types \u0026amp; Techniques | Tableau. https://www.tableau.com/learn/articles/time-series-analysis.\nTime series - Wikipedia. https://en.wikipedia.org/wiki/Time_series.\nTime Series Analysis and Forecasting | Data-Driven Insights. https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-to-time-series-analysis/.\nData mining - Wikipedia. https://en.wikipedia.org/wiki/Data_mining.\nWhat Is Data Mining? How It Works, Benefits, Techniques, and Examples. https://www.investopedia.com/terms/d/datamining.asp.\nWhat is Data Mining? | IBM. https://www.ibm.com/topics/data-mining.\nDecision tree - Wikipedia. https://en.wikipedia.org/wiki/Decision_tree.\nDecision Tree - GeeksforGeeks. https://www.geeksforgeeks.org/decision-tree/.\nWhat is a Decision Tree | IBM. https://www.ibm.com/topics/decision-trees.\nen.wikipedia.org. https://en.wikipedia.org/wiki/Decision_tree.\n","date":"Feb 16, 2024","img":"https://unsplash.it/1920/1080?image=4","permalink":"/blog/2024-02-16-cac-phuong-phap-phan-tich-du-lieu-lon/","series":null,"tags":["bigdata"],"title":"C√°c Ph∆∞∆°ng Ph√°p Ph√¢n T√≠ch D·ªØ Li·ªáu L·ªõn"},{"categories":null,"content":" 1. M√¥ h√¨nh th√°c n∆∞·ªõc (waterfall model) 2. M√¥ h√¨nh ch·ªØ V (V model) 3. M√¥ h√¨nh ti·∫øp c·∫≠n l·∫∑p (Interactive Model) 4. M√¥ h√¨nh xo·∫Øn ·ªëc (Spiral model) 6. Nh√≥m m√¥ h√¨nh Agile 6.1 M√¥ h√¨nh SCRUM 6.2 M√¥ h√¨nh KANBAN 6.3 M√¥ h√¨nh EXTREME PROGRAMMING - l·∫≠p tr√¨nh c·ª±c h·∫°n - XP Ch√†o t·∫•t c·∫£ c√°c b·∫°n, ch√∫c c√°c b·∫°n nƒÉm m·ªõi an l√†nh v√† h·∫°nh ph√∫c.\nH√¥m nay, m√πng 4 t·∫øt, m√¨nh r·∫£nh r·ªói x√≠u n√™n chia s·∫Ω v·ªõi m·ªçi ng∆∞·ªùi b√†i vi·∫øt m·ªõi, t·ªïng h·ª£p nh·ªè v·ªÅ c√°c m√¥ h√¨nh ph√°t tri·ªÉn ph·∫ßn m·ªÅm\n1. M√¥ h√¨nh th√°c n∆∞·ªõc (waterfall model) M√¥ h√¨nh th√°c n∆∞·ªõc l√† m·ªôt m√¥ h√¨nh tuy·∫øn t√≠nh, trong ƒë√≥ c√°c giai ƒëo·∫°n ph√°t tri·ªÉn di·ªÖn ra theo m·ªôt tr√¨nh t·ª± tuy·∫øn t√≠nh. M·ªói giai ƒëo·∫°n ch·ªâ ƒë∆∞·ª£c th·ª±c hi·ªán ti·∫øp khi giai ƒëo·∫°n tr∆∞·ªõc ƒë√£ k·∫øt th√∫c. M√¥ h√¨nh n√†y d·ªÖ s·ª≠ d·ª•ng, d·ªÖ ti·∫øp c·∫≠n, nh∆∞ng r·∫•t kh√≥ ƒë·ªÉ quay l·∫°i giai ƒëo·∫°n n√†o khi n√≥ ƒë√£ k·∫øt th√∫c v√† √≠t t√≠nh linh ho·∫°t.\nC√°c giai ƒëo·∫°n ƒëi theo t·ª´ng b∆∞·ªõc:\nRequirements Gathering and Analysis \u0026raquo; System Design \u0026raquo; Implementation \u0026raquo; Testing Deployment \u0026raquo; Maintenance\n2. M√¥ h√¨nh ch·ªØ V (V model) l√† m√¥ h√¨nh th√°c n∆∞·ªõc m·ªü r·ªông, ph√°t tri·ªÉn c√°c b√†i ki·ªÉm tra v√† ki·ªÉm th·ª≠ song song v·ªõi t·ª´ng giai ƒëo·∫°n ph√°t tri·ªÉn, nh·∫±m h·∫°n ch·∫ø nh·ªØng khuy·∫øt ƒëi·ªÉm c·ªßa m√¥ h√¨nh waterfall. Ph√π h·ª£p v·ªõi d·ª± √°n v·ª´a v√† nh·ªè.\nV·∫Ω h∆°i x·∫•u\nRequirements Gathering and Analysis \u003c\u003c acceptance test design \u003e\u003e acceptance testing ‚Üì ‚Üë System Design \u003c\u003c system test design \u003e\u003eSystem testing ‚Üì ‚Üë Architecture Design \u003c\u003c integration test design \u003e\u003e integration testing ‚Üì ‚Üë Module design \u003c\u003c Unit test design \u003e\u003e Unit test ‚Üì ‚Üë Implementation ƒê·ªëi v·ªõi d·ª± √°n l·ªõn, th√¨ kh√¥ng n√™n √°p d·ª•ng m√¥ h√¨nh n√†y.\n3. M√¥ h√¨nh ti·∫øp c·∫≠n l·∫∑p (Interactive Model) m·ªói quy tr√¨nh ph√°t tri·ªÉn l√† m·ªôt v√≤ng l·∫∑p\nRequirement ==\u0026gt; Analytic and design ‚Üë ‚Üì init ==\u0026gt; plaining implement =\u0026gt; deploy ‚Üë ‚Üì evaluation \u0026lt;== testing\n4. M√¥ h√¨nh xo·∫Øn ·ªëc (Spiral model) M√¥ h√¨nh linh ho·∫°t k·∫øt h·ª£p c√°c kh√≠a c·∫°nh c·ªßa m√¥ h√¨nh th√°c n∆∞·ªõc v√† ph∆∞∆°ng ph√°p Agile. M√¥ h√¨nh n√†y ch√∫ tr·ªçng v√†o ph√¢n t√≠ch r·ªßi ro d·ª± √°n, b·∫Øt ƒë·∫ßu v·ªõi y√™u c·∫ßu/m·ª•c ti√™u thi·∫øt k·∫ø v√† k·∫øt th√∫c v·ªõi vi·ªác kh√°ch h√†ng ki·ªÉm tra ti·∫øn ƒë·ªô c·ªßa t·ª´ng giai ƒëo·∫°n. M√¥ h√¨nh n√†y c√≥ t√≠nh linh ho·∫°t cao, nh∆∞ng c≈©ng t·ªën nhi·ªÅu th·ªùi gian v√† t√†i nguy√™n\n∆Øu: ƒë·∫∑t tr·ªçng t√¢m v√†o qu·∫£n l√Ω v√† gi·∫£m thi·ªÉu r·ªßi ro\nNh∆∞·ª£c: chi ph√≠ cao\nth√≠ch h·ª£p cho c√°c d·ª± √°n l·ªõn, d·ª± √°n ph·ª©c t·∫°p, d·ª± √°n c√≥ nguy c∆° thay ƒë·ªïi cao, d·ª± √°n l·∫ßn ƒë∆∞·ªùng d√≤ b∆∞·ªõc.\nM√¥ h√¨nh tƒÉng tr∆∞·ªüng (Incremental model): M√¥ h√¨nh ph√°t tri·ªÉn t·ª´ng b∆∞·ªõc m·ªôt, b·ªï sung c√°c t√≠nh nƒÉng m·ªõi v√†o phi√™n b·∫£n c≈© cho ƒë·∫øn khi ƒë·∫°t ƒë∆∞·ª£c phi√™n b·∫£n ho√†n ch·ªânh.\nM√¥ h√¨nh n√†y gi√∫p s·∫£n xu·∫•t ph·∫ßn m·ªÅm l√†m vi·ªác ·ªü giai ƒëo·∫°n trung gian, nh∆∞ng c≈©ng c√≥ th·ªÉ g√¢y kh√≥ khƒÉn trong vi·ªác t√≠ch h·ª£p c√°c phi√™n b·∫£n kh√°c nhau.\n6. Nh√≥m m√¥ h√¨nh Agile 6.1 M√¥ h√¨nh SCRUM M√¥ h√¨nh n√†y hi·ªán ƒëang ƒë∆∞·ª£c r·∫•t nhi·ªÅu c√¥ng ty product v√† outsource s·ª≠ d·ª•ng, g·ªìm c√≥ c√°c th√†nh ph·∫ßn c∆° b·∫£n sau\nT·ªï ch·ª©c Organization : Product Owner, ScrumMaster, Development Team\nT√†i li·ªáu (Atifacts): Product Backlog, Sprint Backlog, Estimation\nQui tr√¨nh(Process): Sprint Planning meeting, Review, Daily Scrum Meeting\n∆Øu ƒëi·ªÉm c·ªßa m√¥ h√¨nh:\nM·ªôt ng∆∞·ªùi c√≥ th·ªÉ th·ª±c hi·ªán nhi·ªÅu vi·ªác v√≠ d·ª• nh∆∞ dev c√≥ th·ªÉ test.\nPh√°t hi·ªán l·ªói s·ªõm.\nC√≥ kh·∫£ nƒÉng √°p d·ª•ng ƒë∆∞·ª£c cho nh·ªØng d·ª± √°n m√† y√™u c·∫ßu kh√°ch h√†ng kh√¥ng r√µ r√†ng ngay t·ª´ ƒë·∫ßu.\nNh∆∞·ª£c ƒëi·ªÉm c·ªßa m√¥ h√¨nh:\nTr√¨nh ƒë·ªô c·ªßa nh√≥m c·∫ßn c√≥ m·ªôt k·ªπ nƒÉng nh·∫•t ƒë·ªãnh.\nPh·∫£i c√≥ s·ª± hi·ªÉu bi·∫øt v·ªÅ m√¥ h√¨nh aglie.\nKh√≥ khƒÉn trong vi·ªác x√°c ƒë·ªãnh ng√¢n s√°ch v√† th·ªùi gian.\nLu√¥n nghe √Ω ki·∫øn ph·∫£n h·ªìi t·ª´ kh√°ch h√†ng v√† thay ƒë·ªïi theo n√™n th·ªùi gian s·∫Ω k√©o d√†i.\n6.2 M√¥ h√¨nh KANBAN M√¥ h√¨nh n√†y x√¢y d·ª±ng 1 b·∫£ng t√™n l√† KANBAN ƒë·ªÉ qu·∫£n l√Ω c√¥ng vi·ªác, c√°i n√†y kh√° ƒë∆°n gi·∫£n nh∆∞ng c·ª±c k·ª≥ hi·ªáu qu·∫£, ch√∫ng ta c√≥ th·ªÉ x√¢y d·ª±ng team KANBAN v√† member KANBAN (m·ªói member t·ª± x√¢y d·ª±ng)\n6.3 M√¥ h√¨nh EXTREME PROGRAMMING - l·∫≠p tr√¨nh c·ª±c h·∫°n - XP Kh√°c v·ªõi m√¥ h√¨nh Scrum t·∫≠p trung v√†o c·∫•p ƒë·ªô qu·∫£n l√Ω d·ª± √°n tr·ªçng t√¢m l√† ∆∞u ti√™n c√¥ng vi·ªác v√† l·∫•y ph·∫£n h·ªìi, XP l·∫°i t·∫≠p trung v√†o ph√°t tri·ªÉn ph·∫ßn m·ªÅm ch·∫•t l∆∞·ª£ng cao song song v·ªõi ch·∫•t l∆∞·ª£ng cu·ªôc s·ªëng c·ªßa nh√≥m ph√°t tri·ªÉn\nC√°c vai tr√≤ trong CP: Hu·∫•n luy·ªán vi√™n(Coach), Kh√°ch h√†ng (Customer), L·∫≠p tr√¨nh vi√™n (Programmer), v√† Ki·ªÉm ƒë·ªãnh vi√™n (Tester).\nC√°c y·∫øu t·ªë c·ªët l√µi c·ªßa XP:\nGi√° tr·ªã:\nGiao ti·∫øp: XP nh·∫•n m·∫°nh c√°c cu·ªôc th·∫£o lu·∫≠n tr·ª±c ti·∫øp k√®n theo b·∫£ng v√† b√∫t, n√≥i chung l√† th·∫£o lu·∫≠n face-to-face, kh√¥ng screen.\nƒê∆°n gi·∫£n: T·∫≠p trung v√†o gi·∫£i ph√°p ƒë∆°n gi·∫£n nh·∫•t m√† v·∫´n ƒë√°p ·ª©ng nhu c·∫ßu ho·∫°t ƒë·ªông. Tr√°nh s·ª± ph·ª©c t·∫°p kh√¥ng c·∫ßn thi·∫øt, tr√°nh s·ª± d·ª± ƒëo√°n.\nPh·∫£n h·ªìi: Li√™n t·ª•c thu th·∫≠p ph·∫£n h·ªìi ƒë·ªÉ c·∫£i thi·ªán.\nD≈©ng c·∫£m: H√†nh ƒë·ªông m·∫°nh m·∫Ω tr∆∞·ªõc s·ª± s·ª£ h√£i. S·∫µn l√≤ng n√™u l√™n v·∫•n ƒë·ªÅ t·ªï ch·ª©c, d·ª´ng c√°c th·ª±c h√†nh kh√¥ng hi·ªáu qu·∫£ v√† ch·∫•p nh·∫≠n ph·∫£n h·ªìi.\nT√¥n tr·ªçng: C√°c th√†nh vi√™n trong nh√≥m ph·∫£i t√¥n tr·ªçng l·∫´n nhau ƒë·ªÉ giao ti·∫øp hi·ªáu qu·∫£ v√† c·ªông t√°c, t∆∞∆°ng t√°c t·ªët v·ªõi nhau (h∆°i kh√≥).\nC√°ch th·ª©c th·ª±c hi·ªán:\nPh√°t h√†nh Th∆∞·ªùng xuy√™n: Chu k·ª≥ ph√°t tri·ªÉn ng·∫Øn, c·∫≠p nh·∫≠t th∆∞·ªùng xuy√™n.\nL·∫≠p Tr√¨nh ƒê√¥i: Nh√† ph√°t tri·ªÉn l√†m vi·ªác theo c·∫∑p, li√™n t·ª•c xem x√©t v√† c·∫£i thi·ªán m√£ ngu·ªìn.\nKi·ªÉm th·ª≠ ƒê∆°n v·ªã: Ki·ªÉm th·ª≠ t·∫•t c·∫£ m√£ ngu·ªìn ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c.\nThi·∫øt k·∫ø ƒê∆°n gi·∫£n: Gi·ªØ cho thi·∫øt k·∫ø h·ªá th·ªëng c√†ng ƒë∆°n gi·∫£n c√†ng t·ªët.\nT∆∞∆°ng T√°c v·ªõi Kh√°ch h√†ng: Giao ti·∫øp th∆∞·ªùng xuy√™n v·ªõi kh√°ch h√†ng ƒë·ªÉ hi·ªÉu r√µ y√™u c·∫ßu ƒëang thay ƒë·ªïi.\nXP ph√π h·ª£p cho:\nY√™u c·∫ßu ph·∫ßn m·ªÅm thay ƒë·ªïi ƒë·ªông.\nR·ªßi ro trong c√°c d·ª± √°n c√≥ th·ªùi gian c·ªë ƒë·ªãnh s·ª≠ d·ª•ng c√¥ng ngh·ªá m·ªõi.\nNh√≥m ph√°t tri·ªÉn nh·ªè, ƒë·∫∑t t·∫°i c√πng m·ªôt ƒë·ªãa ƒëi·ªÉm.\nC√¥ng ngh·ªá cho ph√©p ki·ªÉm th·ª≠ t·ª± ƒë·ªông ƒë∆°n v·ªã v√† ch·ª©c nƒÉng.\nNgu·ªìn:\nhttps://en.wikipedia.org/wiki/Extreme_programming\n","date":"Feb 13, 2024","img":"https://unsplash.it/1920/1080?image=5","permalink":"/blog/2024-02-13-mo-hinh-phat-trien-phan-mem/","series":null,"tags":["software"],"title":"M√¥ H√¨nh Ph√°t Tri·ªÉn Ph·∫ßn M·ªÅm"},{"categories":null,"content":" I. Ph√¢n lo·∫°i c√°c lo·∫°i data analytics 1. No analytics: 2. Descriptive analytics - Ph√¢n t√≠ch m√¥ t·∫£ M·ªôt s·ªë v√≠ d·ª• s·ª≠ d·ª•ng Descriptive analytics 3 Diagnostic analytics - Ph√¢n t√≠ch ch·∫©n ƒëo√°n T√¨m hi·ªÉu m·ªôt s·ªë kh√°i ni·ªám c∆° b·∫£n c·ªßa Diagnostic analytics M·ªôt s·ªë v√≠ d·ª• s·ª≠ d·ª•ng diagnostic analytics 4 Predictive analytics: 5 V√≠ d·ª• c·ªßa PREDICTIVE ANALYTICS trong th·ª±c t·∫ø 5 Prescriptive analytics: II. S√°u b∆∞·ªõc c∆° b·∫£n b·∫Øt ƒë·∫ßu m·ªôt d·ª± √°n Data Analytics B∆∞·ªõc 0 : Prepair - Chu·∫©n b·ªã B∆∞·ªõc 1: Define analytics requirement - T√¨m ra c√°c c√¢u h·ªèi c·∫ßn tr·∫£ l·ªùi B∆∞·ªõc 2: Collecting data B∆∞·ªõc 3: Clearning data B∆∞·ªõc 4: Analyzing data B∆∞·ªõc 5: Presenting Report III. C√°c b√†i to√°n th√¥ng d·ª•ng nh·∫•t c·ªßa DA ƒêo l∆∞·ªùng t√°c ƒë·ªông c·ªßa thay ƒë·ªïi so v·ªõi hi·ªán t·∫°i ( Quan tr·ªçng nh·∫•t) D·ª± b√°o ( Quan tr·ªçng) Ph√¢n t√≠ch kh√°ch h√†ng Nh·∫≠n d·∫°ng kh√°ch h√†ng ( Quan tr·ªçng nh·∫•t) Cross selling Customer journey Basket analytics ƒêo l∆∞·ªùng th·ªùi h·∫°n t√°c ƒë·ªông c·ªßa m·ªôt c·∫£i ti·∫øn / sale Th·ª© t·ª± quan t√¢m c·ªßa c√°c c√¥ng ty Sale -\u0026gt; marketing -\u0026gt; product -\u0026gt; h∆∞·ªõng ph√°t tri·ªÉn.\nHi·ªán nay, c√°c c√¥ng ty th√¥ng th∆∞·ªùng s·∫Ω tuy·ªÉn c√°c b·∫°n Data Analytics l√† nh·ªØng b·∫°n c√≥ \u0026ldquo;ki·∫øn th·ª©c ng√†nh c·ª©ng\u0026rdquo; c·ªông v·ªõi k·ªπ nƒÉng v·ªÅ data. B·ªüi v·∫≠y, ngh·ªÅ n√†y c√≥ m·ª©c ƒë·ªô c·∫°nh tranh kh√° kh·ªëc li·ªát. M·ªôt s·ªë ng√†nh c·ª©ng hi·ªán gi·ªù m√¨nh c√≥ th·ªÉ k·ªÉ t√™n l√† marketting, qu·∫£n l√Ω chu·ªói cung ·ª©ng, v·∫≠n h√†nh, kho b√£i, t√†i ch√≠nh, v.v\nI. Ph√¢n lo·∫°i c√°c lo·∫°i data analytics T√≥m t·∫Øt ng·∫Øn g·ªçn, cho nh·ªØng ai l∆∞·ªùi ƒë·ªçc:\nN·∫øu t·ªï ch·ª©c c·ªßa b·∫°n ch∆∞a bao gi·ªù ph√¢n t√≠ch d·ªØ li·ªáu, h√£y b·∫Øt ƒë·∫ßu t·∫≠p l√†m quen v·ªõi vi·ªác ph√¢n t√≠ch, b·∫±ng c√°ch ƒë∆∞a ra nh·ªØng c√¢u h·ªèi c·∫ßn s·ª± tr·∫£ l·ªùi, ƒë∆∞a ra c√°c quy tr√¨nh c·∫ßn s·ª± t·ªëi ∆∞u, thu th·∫≠p d·ªØ li·ªáu xung quanh c√°c c√¢u h·ªèi, c√°c quy tr√¨nh v√† s·ª≠ d·ª•ng m·ªôt trong c√°c ki·ªÉu ph√¢n t√≠ch b√™n d∆∞·ªõi ƒë·ªÉ v·∫Ω l·∫°i b·ª©c tranh ƒë·∫ßy ƒë·ªß.\nDescriptive: Trend c·ªßa data ch·ªâ ra c√°i g√¨?\nDiagnostic: Y·∫øu t·ªë n√†o ƒë√≥ng g√≥p v√†o c√°c trend tr√™n, t·∫°i sao trend l·∫°i x·∫£y ra?\nPredictive: N·∫øu c√≥ th·ªÉ, x√°c ƒë·ªãnh khi n√†o trend l√† m·ªôt y·∫øu t·ªë m√† n√≥ v·∫´n c√≤n ti·∫øp t·ª•c ( c√≤n trend ·ªü th·ªùi ƒëi·ªÉm hi·ªán t·∫°i) ho·∫∑c trend s·∫Ω l·∫∑p l·∫°i (chu k·ª≥)\nPrescriptive: ƒê√†o s√¢u v√†o ph√¢n t√≠ch.\nN·∫øu ch√∫ng ta c√≥ c√°c thu·∫≠t to√°n ƒë·ªôc quy·ªÅn ho·∫∑c c√≥ c√°c c√¥ng c·ª• ph√¢n t√≠ch c·ªßa b√™n th·ª© ba, ch·∫°y thu·∫≠t to√°n ƒë√≥ tr√™n d·ªØ li·ªáu c·ªßa m√¨nh.\nN·∫øu kh√¥ng c√≥, h√£y x√¢y d·ª±ng manual analysis c√°c \u0026ldquo;n∆∞·ªõc\u0026rdquo; ph√¢n t√≠ch d·ª±a tr√™n nh·ªØng kh√°m ph√° c·ªßa b·∫°n v·ªÅ quy tr√¨nh c·∫ßn t·ªëi ∆∞u ho·∫∑c v·ªÅ c√¢u h·ªèi c·∫ßn s·ª± tr·∫£ l·ªùi. i·∫øn h√†nh ph√¢n t√≠ch th·ªß c√¥ng c√°c b∆∞·ªõc ti·∫øp theo c√≥ th·ªÉ th·ª±c hi·ªán ƒë∆∞·ª£c d·ª±a tr√™n nh·ªØng g√¨ b·∫°n ƒë√£ kh√°m ph√° ƒë∆∞·ª£c v·ªÅ c√¢u h·ªèi ho·∫∑c quy tr√¨nh c·ªßa m√¨nh. M·ªói l·ª±a ch·ªçn \u0026ldquo;n∆∞·ªõc\u0026rdquo; ƒëi ƒë√≥ s·∫Ω t√°c ƒë·ªông nh∆∞ th·∫ø n√†o ƒë·∫øn k·∫øt qu·∫£ c·ªßa c√°c t√¨nh hu·ªëng v√† t·ª´ ƒë√≥ n√≥ s·∫Ω t√°c ƒë·ªông nh∆∞ th·∫ø n√†o ƒë·∫øn m·ª•c ti√™u c·ªßa b·∫°n?\n1. No analytics: Kh√¥ng c√≥ ph√¢n t√≠ch, ch·∫°y theo c·∫£m h·ª©ng v√† kinh nghi·ªám c·ªßa m·ªôt s·ªë ng∆∞·ªùi.\n2. Descriptive analytics - Ph√¢n t√≠ch m√¥ t·∫£ Descriptive analytics l√† m·ªôt ph·∫ßn trong lƒ©nh v·ª±c ph√¢n t√≠ch d·ªØ li·ªáu (data analytics) v√† n√≥ t·∫≠p trung v√†o vi·ªác t√≥m t·∫Øt, m√¥ t·∫£ v√† hi·ªÉu s·ª± th·ª±c t·∫°i c·ªßa d·ªØ li·ªáu. M·ª•c ti√™u ch√≠nh c·ªßa descriptive analytics l√† cung c·∫•p th√¥ng tin d·ª±a tr√™n d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ gi√∫p t·ªï ch·ª©c ho·∫∑c ng∆∞·ªùi qu·∫£n l√Ω hi·ªÉu r√µ t√¨nh h√¨nh hi·ªán t·∫°i, kh√°m ph√° m√¥ h√¨nh ho·∫∑c xu h∆∞·ªõng trong d·ªØ li·ªáu, v√† ƒë∆∞a ra c√°c quy·∫øt ƒë·ªãnh t∆∞∆°ng lai d·ª±a tr√™n ki·∫øn th·ª©c n√†y.\nC√°c ph∆∞∆°ng ph√°p v√† c√¥ng c·ª• ph·ªï bi·∫øn trong descriptive analytics bao g·ªìm:\nB√°o c√°o v√† Bi·ªÉu ƒë·ªì: S·ª≠ d·ª•ng bi·ªÉu ƒë·ªì, bi·ªÉu ƒë·ªì, v√† b√°o c√°o ƒë·ªÉ bi·ªÉu th·ªã d·ªØ li·ªáu v√† th·ªÉ hi·ªán m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn s·ªë. C√°c bi·ªÉu ƒë·ªì v√† b√°o c√°o n√†y gi√∫p t·∫°o ra c√°i nh√¨n t·ªïng quan v·ªÅ d·ªØ li·ªáu.\nT√≥m t·∫Øt Th·ªëng k√™: T√≠nh to√°n c√°c th·ªëng k√™ m√¥ t·∫£ nh∆∞ trung b√¨nh, ph∆∞∆°ng sai, t·ª∑ l·ªá, v√† ph√¢n ph·ªëi d·ªØ li·ªáu. ƒêi·ªÅu n√†y gi√∫p trong vi·ªác m√¥ t·∫£ c√°c t√≠nh ch·∫•t quan tr·ªçng c·ªßa d·ªØ li·ªáu.\nPh√¢n t√≠ch d·ªØ li·ªáu l·ªãch s·ª≠: Xem x√©t d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ x√°c ƒë·ªãnh xu h∆∞·ªõng, bi·∫øn ƒë·ªông, v√† c√°c s·ª± ki·ªán quan tr·ªçng trong qu√° kh·ª©. ƒêi·ªÅu n√†y c√≥ th·ªÉ gi√∫p d·ª± ƒëo√°n s·ª± ki·ªán t∆∞∆°ng lai d·ª±a tr√™n d·ªØ li·ªáu l·ªãch s·ª≠.\nPh√¢n lo·∫°i v√† nh√≥m d·ªØ li·ªáu: Nh√≥m d·ªØ li·ªáu v√†o c√°c ph√¢n lo·∫°i ƒë·ªÉ hi·ªÉu r√µ c√°c nh√≥m v√† s·ª± t∆∞∆°ng quan gi·ªØa ch√∫ng.\nKh√°m ph√° d·ªØ li·ªáu (Data Exploration): S·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t kh√°m ph√° d·ªØ li·ªáu ƒë·ªÉ ph√°t hi·ªán th√¥ng tin m·ªõi v√† b·∫•t th∆∞·ªùng trong d·ªØ li·ªáu, ch·∫≥ng h·∫°n nh∆∞ vi·ªác s·ª≠ d·ª•ng m√¥ h√¨nh ph√¢n c·ª•m.\nL·ªçc v√† t√¨m ki·∫øm d·ªØ li·ªáu: T√¨m ki·∫øm d·ªØ li·ªáu c·ª• th·ªÉ ho·∫∑c l·ªçc d·ªØ li·ªáu ƒë·ªÉ t·∫≠p trung v√†o c√°c y·∫øu t·ªë quan tr·ªçng.\nDescriptive analytics th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ m√¥ t·∫£ hi·ªán t∆∞·ª£ng, hi·ªÉu r√µ t√¨nh h√¨nh hi·ªán t·∫°i, v√† x√°c ƒë·ªãnh c√°c v·∫•n ƒë·ªÅ ho·∫∑c c∆° h·ªôi c∆° b·∫£n. N√≥ cung c·∫•p n·ªÅn t·∫£ng cho c√°c giai ƒëo·∫°n ph√¢n t√≠ch ti·∫øp theo nh∆∞ predictive analytics (d·ª± ƒëo√°n t∆∞∆°ng lai) v√† prescriptive analytics (ƒë∆∞a ra h∆∞·ªõng d·∫´n v√† ƒë·ªÅ xu·∫•t h√†nh ƒë·ªông).\nM·ªôt s·ªë v√≠ d·ª• s·ª≠ d·ª•ng Descriptive analytics Traffic and Engagement Reports Ng·ªØ c·∫£nh l√† b·∫°n ƒëang c√≥ m·ªôt website b√°n h√†ng, c√≥ l∆∞u l·∫°i h√†nh vi t∆∞∆°ng t√°c c·ªßa kh√°ch h√†ng l√™n tr√™n website s·ª≠ d·ª•ng GA. M·ªôt s·ªë b√°o c√°o b·∫°n c√≥ th·ªÉ x√¢y d·ª±ng.\nB√°o c√°o k√™nh truy·ªÅn th√¥ng n√†o ƒëang thu h√∫t nhi·ªÅu l∆∞u l∆∞·ª£ng truy c·∫≠p tr√™n trang web c·ªßa b·∫°n nh·∫•t.\nX√°c ƒë·ªãnh s·ªë l∆∞·ª£ng ng∆∞·ªùi d√πng t·ª´ m·ªói ngu·ªìn\nSo s√°nh s·ªë ng∆∞·ªùi d√πng ·ªü th·ªùi ƒëi·ªÉm hi·ªán t·∫°i v·ªõi qu√° kh·ª© t·ª´ c√πng m·ªôt ngu·ªìn.\nXem s·ªë l∆∞·ª£ng truy c·∫≠p t·ª´ qu·∫£ng c√°o tr·∫£ ph√≠ ƒëang tƒÉng l√™n bao nhi√™u ph·∫ßn trƒÉm\nC√°c y·∫øu t·ªë m√¨nh li·ªát k√™ ·ªü tr√™n l√† m·ªôt trong c√°c th√¥ng tin quan tr·ªçng ƒë·ªÉ c√°c lo·∫°i ph√¢n t√≠ch kh√°c b√™n d∆∞·ªõi ƒë√†o s√¢u h∆°n l√Ω do.\nV√¨ sao ngu·ªìn truy c·∫≠p t·ª´ facebook l·∫°i tƒÉng theo th·ªùi gian\nXu h∆∞·ªõng tƒÉng n√†y c√≥ c√≤n ti·∫øp t·ª•c ·ªü t∆∞∆°ng lai\nH√†nh ƒë·ªông ti·∫øp theo c·ªßa ch√∫ng ta l√† g√¨\nFinancial Statement Analysis B√°o c√°o t√†i ch√≠nh l√† b√°o c√°o ƒë·ªãnh k·ª≥ n√™u chi ti·∫øt th√¥ng tin t√†i ch√≠nh v·ªÅ m·ªôt doanh nghi·ªáp v√† c√πng nhau ƒë∆∞a ra c√°i nh√¨n to√†n di·ªán v·ªÅ t√¨nh h√¨nh t√†i ch√≠nh c·ªßa c√¥ng ty.\nC√≥ m·ªôt s·ªë lo·∫°i b√°o c√°o t√†i ch√≠nh, bao g·ªìm b·∫£ng c√¢n ƒë·ªëi k·∫ø to√°n, b√°o c√°o k·∫øt qu·∫£ ho·∫°t ƒë·ªông kinh doanh, b√°o c√°o l∆∞u chuy·ªÉn ti·ªÅn t·ªá v√† b√°o c√°o v·ªën ch·ªß s·ªü h·ªØu c·ªßa c·ªï ƒë√¥ng. M·ªói k√™nh ph·ª•c v·ª• m·ªôt ƒë·ªëi t∆∞·ª£ng c·ª• th·ªÉ v√† truy·ªÅn t·∫£i nh·ªØng th√¥ng tin kh√°c nhau v·ªÅ t√†i ch√≠nh c·ªßa c√¥ng ty.\nPh√¢n t√≠ch b√°o c√°o t√†i ch√≠nh c√≥ th·ªÉ ƒë∆∞·ª£c th·ª±c hi·ªán theo ba c√°ch ch√≠nh: d·ªçc, ngang v√† t·ª∑ l·ªá.\nPh√¢n t√≠ch theo chi·ªÅu d·ªçc l√† vi·ªác ƒë·ªçc c√°c d√≤ng d·ªØ li·ªáu theo th·ª© t·ª± t·ª´ tr√™n xu·ªëng d∆∞·ªõi v√† so s√°nh t·ª´ng m·ª•c v·ªõi c√°c m·ª•c ·ªü tr√™n v√† d∆∞·ªõi n√≥. ƒêi·ªÅu n√†y gi√∫p x√°c ƒë·ªãnh m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn. V√≠ d·ª•: n·∫øu m·ªói chi ti·∫øt ƒë∆°n h√†ng l√† m·ªôt t·ª∑ l·ªá ph·∫ßn trƒÉm c·ªßa t·ªïng s·ªë th√¨ vi·ªác so s√°nh ch√∫ng c√≥ th·ªÉ cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ chi ti·∫øt ƒë∆°n h√†ng n√†o chi·∫øm t·ª∑ l·ªá ph·∫ßn trƒÉm l·ªõn h∆°n v√† nh·ªè h∆°n trong t·ªïng s·ªë.\nPh√¢n t√≠ch theo chi·ªÅu ngang l√† vi·ªác ƒë·ªçc m·ªôt b√°o c√°o t·ª´ tr√°i sang ph·∫£i v√† so s√°nh t·ª´ng m·ª•c v·ªõi ch√≠nh n√≥ ·ªü k·ª≥ tr∆∞·ªõc. Lo·∫°i ph√¢n t√≠ch n√†y x√°c ƒë·ªãnh s·ª± thay ƒë·ªïi theo th·ªùi gian.\nCu·ªëi c√πng, ph√¢n t√≠ch t·ª∑ l·ªá l√† vi·ªác vi·ªác so s√°nh m·ªôt ph·∫ßn c·ªßa b√°o c√°o v·ªõi ph·∫ßn kh√°c d·ª±a tr√™n m·ªëi quan h·ªá c·ªßa ch√∫ng v·ªõi t·ªïng th·ªÉ. ƒêi·ªÅu n√†y so s√°nh tr·ª±c ti·∫øp c√°c m·∫∑t h√†ng qua c√°c th·ªùi k·ª≥, c≈©ng nh∆∞ t·ª∑ l·ªá c·ªßa c√¥ng ty b·∫°n v·ªõi ng√†nh ƒë·ªÉ ƒë√°nh gi√° xem c√¥ng ty c·ªßa b·∫°n ho·∫°t ƒë·ªông hi·ªáu qu·∫£ h∆°n hay k√©m h∆°n.\nM·ªói ph∆∞∆°ng ph√°p ph√¢n t√≠ch b√°o c√°o t√†i ch√≠nh n√†y l√† v√≠ d·ª• v·ªÅ descriptive analytics v√¨ ch√∫ng cung c·∫•p th√¥ng tin v·ªÅ xu h∆∞·ªõng v√† m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn d·ª±a tr√™n d·ªØ li·ªáu hi·ªán t·∫°i v√† l·ªãch s·ª≠.\nDemand Trends Descriptive analytics c≈©ng c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x√°c ƒë·ªãnh xu h∆∞·ªõng trong s·ªü th√≠ch v√† h√†nh vi c·ªßa kh√°ch h√†ng, ƒë·ªìng th·ªùi ƒë∆∞a ra c√°c gi·∫£ ƒë·ªãnh v·ªÅ nhu c·∫ßu ƒë·ªëi v·ªõi c√°c s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª• c·ª• th·ªÉ.\nM·ªôt usecase th∆∞·ªùng ƒë∆∞·ª£c nh·∫Øc t·ªõi l√† Netflix‚Äôs. Team c·ªßa h·ªç ƒë√£ thu th·∫≠p m·ªôt l∆∞·ª£ng l·ªõn h√†nh vi c·ªßa ng∆∞·ªùi d√πng tr√™n n·ªÅn t·∫£ng c·ªßa h·ªç. H·ªç ph√¢n t√≠ch d·ªØ li·ªáu n√†y ƒë·ªÉ x√°c ƒë·ªãnh ra c√°c ch∆∞∆°ng tr√¨nh TV v√† c√°c b·ªô phim ƒëang l√† trending ·ªü th·ªùi ƒëi·ªÉm hi·ªán t·∫°i v√† ƒë∆∞a ra c√°c g·ª£i √Ω phim trending ·ªü trang ch·ªß.\nKh√¥ng d·ª´ng l·∫°i ·ªü ƒë√≥, c√°c d·ªØ li·ªáu n√†y c√≤n gi√∫p Netflix bi·∫øt ƒë∆∞·ª£c r·∫±ng lo·∫°i phim n√†o, di·ªÖn vi√™n n√†o, ƒë·∫°o di·ªÖn n√†o hi·ªán t·∫°i ƒëang ƒë∆∞·ª£c y√™u th√≠ch. V√† n√≥ gi√∫p ƒë∆∞a quy·∫øt ƒë·ªãnh v·ªÅ n·ªôi dung c√°c phim s·∫Øp t·ªõi s·∫Ω ƒë∆∞·ª£c b·∫•m m√°y, h·ª£p ƒë·ªìng v·ªõi nh√† s·∫£n xu·∫•t phim, ƒë∆∞a ra c√°c chi·∫øn d·ªãch qu·∫£n c√°o, retargeting qu·∫£n c√°o.\nAggregated Survey Results Descriptive analytics c≈©ng h·ªØu √≠ch trong nghi√™n c·ª©u th·ªã tr∆∞·ªùng.\nV√≠ d·ª•: b·∫°n c√≥ th·ªÉ ti·∫øn h√†nh m·ªôt cu·ªôc kh·∫£o s√°t v√† x√°c ƒë·ªãnh r·∫±ng khi ƒë·ªô tu·ªïi c·ªßa ng∆∞·ªùi tr·∫£ l·ªùi tƒÉng l√™n th√¨ kh·∫£ nƒÉng h·ªç mua s·∫£n ph·∫©m c·ªßa b·∫°n c≈©ng tƒÉng theo. N·∫øu b·∫°n ƒë√£ th·ª±c hi·ªán kh·∫£o s√°t n√†y nhi·ªÅu l·∫ßn trong nhi·ªÅu nƒÉm, th√¨ ph√¢n t√≠ch m√¥ t·∫£ c√≥ th·ªÉ cho b·∫°n bi·∫øt li·ªáu m·ªëi t∆∞∆°ng quan gi·ªØa ƒë·ªô tu·ªïi mua h√†ng n√†y lu√¥n t·ªìn t·∫°i hay n√≥ ch·ªâ x·∫£y ra trong nƒÉm nay.\nNh·ªØng hi·ªÉu bi·∫øt s√¢u s·∫Øc nh∆∞ th·∫ø n√†y c√≥ th·ªÉ m·ªü ƒë∆∞·ªùng cho c√°c ph√¢n t√≠ch ch·∫©n ƒëo√°n gi·∫£i th√≠ch l√Ω do t·∫°i sao m·ªôt s·ªë y·∫øu t·ªë nh·∫•t ƒë·ªãnh l·∫°i c√≥ m·ªëi t∆∞∆°ng quan v·ªõi nhau. Sau ƒë√≥, b·∫°n c√≥ th·ªÉ t·∫≠n d·ª•ng c√°c ph√¢n t√≠ch d·ª± ƒëo√°n v√† ph√¢n t√≠ch theo quy ƒë·ªãnh ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch c·∫£i ti·∫øn s·∫£n ph·∫©m ho·∫∑c chi·∫øn d·ªãch ti·∫øp th·ªã trong t∆∞∆°ng lai d·ª±a tr√™n nh·ªØng xu h∆∞·ªõng ƒë√≥.\nProgress to Goals descriptive analytics c√≥ th·ªÉ ƒë∆∞·ª£c √°p d·ª•ng ƒë·ªÉ theo d√µi ti·∫øn tr√¨nh ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u (Progress to Goals). C√°c b√°o c√°o v·ªÅ ti·∫øn ƒë·ªô c·ªßa KPIs c√≥ th·ªÉ gi√∫p team c·ªßa b·∫°n hi·ªÉu ƒë∆∞·ª£c r·∫±ng c√¥ng vi·ªác m√¨nh l√†m c√≥ ƒëang ƒëi ƒë√∫ng h∆∞·ªõng, hay n√≥ ƒëang ƒëi sai h∆∞·ªõng v√† ch√∫ng ta c·∫ßn ƒëi·ªÅu ch·ªânh l·∫°i ƒë·ªÉ ƒëi ƒë√∫ng h∆∞·ªõng.\nV√≠ d·ª•: n·∫øu t·ªï ch·ª©c c·ªßa b·∫°n ƒë·∫∑t m·ª•c ti√™u ƒë·∫°t ƒë∆∞·ª£c 500.000 unique page views / month, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng d·ªØ li·ªáu l∆∞u l∆∞·ª£ng truy c·∫≠p ƒë·ªÉ theo d√µi. Gi·∫£ s·ª≠, trong n·ª≠a th√°ng, b·∫°n ƒë·∫°t ƒë∆∞·ª£c 200.000 l∆∞·ª£t xem, v·∫≠y l√† ƒëi n·ªØa ch·∫∑n ƒë∆∞·ªùng r·ªìi nh∆∞ng ch√∫ng ta ch∆∞a ƒë·∫°t ƒë∆∞·ª£c 1 n·ªØa m·ª•c ti√™u. Ph√¢n t√≠ch d·∫°ng n√†y ch·ªâ cho ch√∫ng ta ƒëi·ªÅu ƒë√≥ v√† ch√∫ng ta c·∫ßn s·ª≠ d·ª•ng nh·ªØng ph√¢n t√≠ch chuy√™n s√¢u h∆°n b√™n d∆∞·ªõi ƒë·ªÉ c·∫£i thi·ªán l∆∞u l∆∞·ª£ng truy c·∫≠p ƒë·ªÉ quay l·∫°i h∆∞·ªõng ƒë√∫ng KPI c·ªßa b·∫°n.\n3 Diagnostic analytics - Ph√¢n t√≠ch ch·∫©n ƒëo√°n Diagnostic analytics (ph√¢n t√≠ch ch·∫©n ƒëo√°n) l√† m·ªôt lo·∫°i ph√¢n t√≠ch d·ªØ li·ªáu trong lƒ©nh v·ª±c qu·∫£n l√Ω d·ª±a tr√™n d·ªØ li·ªáu (data analytics), n∆°i m·ª•c ti√™u ch√≠nh l√† t√¨m hi·ªÉu v√† hi·ªÉu r√µ nguy√™n nh√¢n ho·∫∑c l√Ω do x·∫£y ra c·ªßa m·ªôt s·ª± ki·ªán ho·∫∑c t√¨nh hu·ªëng c·ª• th·ªÉ. M·ª•c ƒë√≠ch ch√≠nh c·ªßa diagnostic analytics l√† gi√∫p t·ªï ch·ª©c ho·∫∑c ng∆∞·ªùi qu·∫£n l√Ω ƒë·ªëi m·∫∑t v·ªõi c√°c v·∫•n ƒë·ªÅ ho·∫∑c s·ª± c·ªë, cung c·∫•p th√¥ng tin ƒë·ªÉ l√†m r√µ t·∫°i sao ch√∫ng x·∫£y ra v√† gi√∫p ƒë∆∞a ra quy·∫øt ƒë·ªãnh ho·∫∑c bi·ªán ph√°p s·ª≠a ch·ªØa.\nC√°c ƒëi·ªÉm ch√≠nh c·ªßa diagnostic analytics bao g·ªìm:\nT√¨m hi·ªÉu nguy√™n nh√¢n: Lo·∫°i ph√¢n t√≠ch n√†y t·∫≠p trung v√†o vi·ªác ph√¢n t√≠ch d·ªØ li·ªáu ƒë·ªÉ t√¨m ra nguy√™n nh√¢n g·ªëc r·ªÖ c·ªßa m·ªôt s·ª± ki·ªán ho·∫∑c t√¨nh hu·ªëng c·ª• th·ªÉ. ƒêi·ªÅu n√†y gi√∫p hi·ªÉu r√µ t·∫°i sao ƒëi·ªÅu ƒë√≥ x·∫£y ra v√† t·∫°o c∆° h·ªôi ƒë·ªÉ ngƒÉn ch·∫∑n s·ª± ki·ªán t∆∞∆°ng t·ª± trong t∆∞∆°ng lai.\nS·ª≠ d·ª•ng d·ªØ li·ªáu l·ªãch s·ª≠: Diagnostic analytics s·ª≠ d·ª•ng d·ªØ li·ªáu l·ªãch s·ª≠ v√† th√¥ng tin v·ªÅ s·ª± ki·ªán c·ª• th·ªÉ ƒë·ªÉ ph√¢n t√≠ch v√† ph√°t hi·ªán c√°c m√¥ h√¨nh ho·∫∑c m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn.\nH·ªó tr·ª£ quy·∫øt ƒë·ªãnh: K·∫øt qu·∫£ c·ªßa diagnostic analytics c√≥ th·ªÉ h·ªó tr·ª£ quy·∫øt ƒë·ªãnh v·ªÅ vi·ªác x·ª≠ l√Ω c√°c v·∫•n ƒë·ªÅ ho·∫∑c s·ª± c·ªë. D·ª±a v√†o th√¥ng tin n√†y, ng∆∞·ªùi qu·∫£n l√Ω c√≥ th·ªÉ ƒë∆∞a ra c√°c bi·ªán ph√°p c·∫£i thi·ªán ho·∫∑c ƒëi·ªÅu ch·ªânh quy tr√¨nh l√†m vi·ªác ƒë·ªÉ ngƒÉn ch·∫∑n c√°c v·∫•n ƒë·ªÅ t∆∞∆°ng t·ª±.\nV√≠ d·ª• v·ªÅ ·ª©ng d·ª•ng c·ªßa diagnostic analytics bao g·ªìm vi·ªác ph√¢n t√≠ch t·∫°i sao s·∫£n ph·∫©m c√≥ t·ª∑ l·ªá tr·∫£ h√†ng cao, l√†m r√µ t·∫°i sao m·ªôt d·ª± √°n ƒë√£ tr·ªÖ h·∫°n, ho·∫∑c t√¨m hi·ªÉu l√Ω do t·∫°i sao doanh s·ªë b√°n h√†ng c·ªßa m·ªôt s·∫£n ph·∫©m c·ª• th·ªÉ ƒë√£ gi·∫£m s√∫t. Khi hi·ªÉu ƒë∆∞·ª£c nguy√™n nh√¢n, t·ªï ch·ª©c c√≥ th·ªÉ ƒë∆∞a ra c√°c bi·ªán ph√°p s·ª≠a ch·ªØa ho·∫∑c c·∫£i thi·ªán qu√° tr√¨nh l√†m vi·ªác ƒë·ªÉ gi·∫£m thi·ªÉu c√°c v·∫•n ƒë·ªÅ n√†y trong t∆∞∆°ng lai.\nC√≥ m·ªôt s·ªë kh√°i ni·ªám c·∫ßn hi·ªÉu tr∆∞·ªõc khi ƒëi s√¢u v√†o ph√¢n t√≠ch ch·∫©n ƒëo√°n: ki·ªÉm tra gi·∫£ thuy·∫øt (hypothesis testing), s·ª± kh√°c nhau gi·ªØa m·ªëi t∆∞∆°ng quan v√† quan h·ªá nh√¢n qu·∫£, ph√¢n t√≠ch h·ªìi quy ch·∫©n ƒëo√°n (diagnostic regression analysis).\nT√¨m hi·ªÉu m·ªôt s·ªë kh√°i ni·ªám c∆° b·∫£n c·ªßa Diagnostic analytics Hypothesis Testing Ki·ªÉm ƒë·ªãnh gi·∫£ thuy·∫øt (Hypothesis Testing) l√† m·ªôt ph∆∞∆°ng ph√°p th·ªëng k√™ c∆° b·∫£n ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë∆∞a ra quy·∫øt ƒë·ªãnh v·ªÅ c√°c tham s·ªë c·ªßa qu·∫ßn th·ªÉ d·ª±a tr√™n d·ªØ li·ªáu m·∫´u. ƒê√¢y l√† m·ªôt quy tr√¨nh h·ªá th·ªëng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° xem c√≥ ƒë·ªß b·∫±ng ch·ª©ng ƒë·ªÉ h·ªó tr·ª£ ho·∫∑c ph·ªß ƒë·ªãnh m·ªôt gi·∫£ thuy·∫øt c·ª• th·ªÉ v·ªÅ qu·∫ßn th·ªÉ hay kh√¥ng. D∆∞·ªõi ƒë√¢y l√† c√°c b∆∞·ªõc v√† kh√°i ni·ªám ch√≠nh li√™n quan ƒë·∫øn ki·ªÉm ƒë·ªãnh gi·∫£ thuy·∫øt\nX√¢y d·ª±ng Gi·∫£ Thuy·∫øt: Gi·∫£ thuy·∫øt kh√¥ng (H0): ƒê√¢y l√† gi·∫£ thuy·∫øt m·∫∑c ƒë·ªãnh ho·∫∑c tr·∫°ng th√°i hi·ªán h√†nh. N√≥ cho r·∫±ng kh√¥ng c√≥ hi·ªáu ·ª©ng, kh√¥ng c√≥ s·ª± kh√°c bi·ªát ho·∫∑c kh√¥ng c√≥ m·ªëi quan h·ªá n√†o trong qu·∫ßn th·ªÉ. Th∆∞·ªùng ƒë∆∞·ª£c k√Ω hi·ªáu l√† H0.\nGi·∫£ thuy·∫øt thay th·∫ø (Ha ho·∫∑c H1): ƒê√¢y l√† gi·∫£ thuy·∫øt m√† b·∫°n mu·ªën ki·ªÉm tra. N√≥ ƒë·∫°i di·ªán cho m·ªôt kh·∫≥ng ƒë·ªãnh c·ª• th·ªÉ ho·∫∑c hi·ªáu ·ª©ng m√† b·∫°n mu·ªën ch·ª©ng minh. Th∆∞·ªùng ƒë∆∞·ª£c k√Ω hi·ªáu l√† Ha ho·∫∑c H1.\nCh·ªçn M·ª©c √ù Nghƒ©a (Œ±): M·ª©c √Ω nghƒ©a, k√Ω hi·ªáu l√† Œ± (alpha), ƒë·∫°i di·ªán cho x√°c su·∫•t c·ªßa l·ªói lo·∫°i I, t·ª©c l√† l·ªói sai khi t·ª´ ch·ªëi m·ªôt gi·∫£ thuy·∫øt kh√¥ng ƒë√∫ng. M·ª©c √Ω nghƒ©a th∆∞·ªùng bao g·ªìm 0,05 (5%) v√† 0,01 (1%), nh∆∞ng s·ª± l·ª±a ch·ªçn ph·ª• thu·ªôc v√†o ng·ªØ c·∫£nh v√† m·ª©c ƒë·ªô tin c·∫≠y y√™u c·∫ßu.\nThu th·∫≠p v√† Ph√¢n T√≠ch D·ªØ Li·ªáu: Thu th·∫≠p m·ªôt m·∫´u t·ª´ qu·∫ßn th·ªÉ quan t√¢m v√† th·ª±c hi·ªán ph√¢n t√≠ch th·ªëng k√™ c·∫ßn thi·∫øt ƒë·ªÉ t√≠nh to√°n th·ªëng k√™ ki·ªÉm ƒë·ªãnh, ƒëo l∆∞·ªùng m·ªëi quan h·ªá ho·∫∑c hi·ªáu ·ª©ng ƒëang ƒë∆∞·ª£c nghi√™n c·ª©u.\nT√≠nh To√°n Th·ªëng K√™ Ki·ªÉm ƒê·ªãnh: Th·ªëng k√™ ki·ªÉm ƒë·ªãnh ph·ª• thu·ªôc v√†o lo·∫°i ki·ªÉm ƒë·ªãnh ƒëang th·ª±c hi·ªán (v√≠ d·ª•: ki·ªÉm ƒë·ªãnh t-student, ki·ªÉm ƒë·ªãnh chi b√¨nh ph∆∞∆°ng, ki·ªÉm ƒë·ªãnh z). N√≥ ƒëo l∆∞·ªùng m·ª©c ƒë·ªô m√† th·ªëng k√™ m·∫´u kh√°c bi·ªát so v·ªõi gi√° tr·ªã k·ª≥ v·ªçng d∆∞·ªõi gi·∫£ thuy·∫øt kh√¥ng.\nX√°c ƒë·ªãnh V√πng Quan Tr·ªçng ho·∫∑c Gi√° tr·ªã p (P-Value): V√πng Quan Tr·ªçng: Trong ki·ªÉm ƒë·ªãnh gi·∫£ thuy·∫øt, v√πng quan tr·ªçng ƒë·∫°i di·ªán cho t·∫≠p h·ª£p c√°c gi√° tr·ªã c·ªßa th·ªëng k√™ ki·ªÉm ƒë·ªãnh m√† b·∫°n s·∫Ω t·ª´ ch·ªëi gi·∫£ thuy·∫øt kh√¥ng. C√°c gi√° tr·ªã n√†y ƒë∆∞·ª£c x√°c ƒë·ªãnh d·ª±a tr√™n m·ª©c √Ω nghƒ©a ƒë√£ ch·ªçn v√† ph√¢n ph·ªëi c·ªßa th·ªëng k√™ ki·ªÉm ƒë·ªãnh.\nGi√° tr·ªã p (P-Value): Gi√° tr·ªã p l√† x√°c su·∫•t c·ªßa vi·ªác thu ƒë∆∞·ª£c th·ªëng k√™ ki·ªÉm ƒë·ªãnh c√†ng \u0026ldquo;t∆∞∆°ng ƒë·ªëi\u0026rdquo; ho·∫∑c \u0026ldquo;t∆∞∆°ng ƒë·ªëi h∆°n\u0026rdquo; so v·ªõi th·ªëng k√™ ki·ªÉm ƒë·ªãnh quan s√°t trong m·∫´u d·ªØ li·ªáu, gi·∫£ s·ª≠ r·∫±ng gi·∫£ thuy·∫øt kh√¥ng ƒë√∫ng. Gi√° tr·ªã p nh·ªè (th∆∞·ªùng nh·ªè h∆°n Œ±) cho th·∫•y c√≥ ƒë·ªß b·∫±ng ch·ª©ng ƒë·ªÉ ph·ªß ƒë·ªãnh gi·∫£ thuy·∫øt kh√¥ng.\nƒê∆∞a Ra Quy·∫øt ƒê·ªãnh: N·∫øu th·ªëng k√™ ki·ªÉm ƒë·ªãnh n·∫±m trong v√πng quan tr·ªçng (t·ª©c l√† x√°c su·∫•t x·∫£y ra do s·ª± t√¨nh c·ªù th·∫•p), b·∫°n t·ª´ ch·ªëi gi·∫£ thuy·∫øt kh√¥ng ƒë·ªÉ ·ªßng h·ªô gi·∫£ thuy·∫øt thay th·∫ø.\nN·∫øu th·ªëng k√™ ki·ªÉm ƒë·ªãnh kh√¥ng n·∫±m trong v√πng quan tr·ªçng, b·∫°n kh√¥ng t·ª´ ch·ªëi gi·∫£ thuy·∫øt kh√¥ng, t·ª©c l√† kh√¥ng c√≥ ƒë·ªß b·∫±ng ch·ª©ng ƒë·ªÉ ·ªßng h·ªô gi·∫£ thuy·∫øt thay th·∫ø.\nƒê∆∞a Ra K·∫øt Lu·∫≠n: D·ª±a tr√™n quy·∫øt ƒë·ªãnh ·ªü b∆∞·ªõc 6, b·∫°n ƒë∆∞a ra k·∫øt lu·∫≠n v·ªÅ tham s·ªë c·ªßa qu·∫ßn th·ªÉ b·∫°n ƒëang ki·ªÉm tra. B·∫°n c√≥ th·ªÉ k·∫øt lu·∫≠n r·∫±ng c√≥ ƒë·ªß b·∫±ng ch·ª©ng cho m·ªôt hi·ªáu ·ª©ng, m·ªôt s·ª± kh√°c bi·ªát, ho·∫∑c m·ªôt m·ªëi quan h·ªá (t·ª´ ch·ªëi gi·∫£ thuy·∫øt kh√¥ng) ho·∫∑c r·∫±ng kh√¥ng c√≥ ƒë·ªß b·∫±ng ch·ª©ng ƒë·ªÉ l√†m ƒëi·ªÅu ƒë√≥ (kh√¥ng t·ª´ ch·ªëi gi·∫£ thuy·∫øt kh√¥ng).\nHypothesis testing l√† quy tr√¨nh th·ªëng k√™ (the statistical process) ƒë·ªÉ ch·ª©ng minh ho·∫∑c b√°c b·ªè m·ªôt gi·∫£ ƒë·ªãnh.\nHypotheses c√≥ th·ªÉ l√† future-oriented (v√≠ d·ª•, N·∫øu ch√∫ng ta ƒë·ªïi logo c·ªßa c√¥ng ty ch√∫ng ta, nhi·ªÅu ng·ª´i ·ªü B·∫Øc M·ªπ s·∫Ω mua s·∫£n ph·∫©m c·ªßa ch√∫ng ta), trong predictive analytics ho·∫∑c prescriptive analytics.\nTrong diagnostic analytics, hypotheses l√† historically-oriented (v√≠ d·ª•, T√¥i d·ª± ƒëo√°n doanh s·ªë b√°n h√†ng th√°ng n√†y s·ª•t gi·∫£m l√† do s·∫£n ph·∫©m c·ªßa ch√∫ng t√¥i tƒÉng gi√° g·∫ßn ƒë√¢y.). C√°c gi·∫£ ƒë·ªãnh ƒë·ªãnh h∆∞·ªõng vi·ªác ph√¢n t√≠ch c·ªßa b·∫°n v√† ƒë∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ m·ªôt l·ªùi nh·∫Øc nh·ªü v·ªÅ ƒëi·ªÅu b·∫°n ƒëang mu·ªën ch·ª©ng minh ho·∫∑c b√°c b·ªè.\nCorrelation vs. Causation T∆∞∆°ng quan v√† nh√¢n qu·∫£ (Correlation and Causation) l√† hai kh√°i ni·ªám quan tr·ªçng trong th·ªëng k√™ v√† khoa h·ªçc d·ªØ li·ªáu. Tuy c√πng li√™n quan ƒë·∫øn s·ª± li√™n k·∫øt gi·ªØa hai bi·∫øn, nh∆∞ng ch√∫ng c√≥ √Ω nghƒ©a kh√°c nhau:\nT∆∞∆°ng Quan (Correlation): T∆∞∆°ng quan ch·ªâ ƒë∆°n gi·∫£n l√† m√¥ t·∫£ m·ªëi quan h·ªá t∆∞∆°ng ƒë·ªëi gi·ªØa hai bi·∫øn. N√≥ ch·ªâ cho ta bi·∫øt n·∫øu c√≥ s·ª± thay ƒë·ªïi theo c√πng h∆∞·ªõng ho·∫∑c ng∆∞·ª£c h∆∞·ªõng gi·ªØa c√°c bi·∫øn. Khi hai bi·∫øn t∆∞∆°ng quan, c√≥ th·ªÉ c√≥ s·ª± thay ƒë·ªïi chung nh∆∞ng kh√¥ng c√≥ li√™n quan nh√¢n qu·∫£. ƒêi·ªÅu n√†y c√≥ th·ªÉ l√† do t√¨nh c·ªù ho·∫∑c c√≥ bi·∫øn kh√°c ·∫©n sau m·ªëi quan h·ªá t∆∞∆°ng quan. V√≠ d·ª•: C√≥ m·ªôt t∆∞∆°ng quan m·∫°nh gi·ªØa vi·ªác s·ª≠ d·ª•ng √¥ t√¥ v√† l∆∞·ª£ng d·∫ßu ti√™u th·ª• h√†ng nƒÉm. Tuy nhi√™n, ƒëi·ªÅu n√†y kh√¥ng c√≥ nghƒ©a r·∫±ng vi·ªác s·ª≠ d·ª•ng √¥ t√¥ g√¢y ra s·ª± tƒÉng ti√™u th·ª• d·∫ßu.\nNh√¢n Qu·∫£ (Causation): Nh√¢n qu·∫£ ƒë·ªÅ c·∫≠p ƒë·∫øn m·ªëi quan h·ªá nguy√™n nh√¢n v√† k·∫øt qu·∫£ gi·ªØa hai bi·∫øn, trong ƒë√≥ m·ªôt bi·∫øn (bi·∫øn nguy√™n nh√¢n) g√¢y ra s·ª± thay ƒë·ªïi trong bi·∫øn k·∫øt qu·∫£.\nƒê·ªÉ k·∫øt lu·∫≠n v·ªÅ m·ªëi quan h·ªá nh√¢n qu·∫£, c·∫ßn c√≥ nhi·ªÅu b·∫±ng ch·ª©ng h∆°n so v·ªõi ch·ªâ t∆∞∆°ng quan. Th√¥ng th∆∞·ªùng, c·∫ßn ti·∫øn h√†nh th·ª≠ nghi·ªám ki·ªÉm tra nh√¢n qu·∫£ ho·∫∑c s·ª≠ d·ª•ng thi·∫øt k·∫ø nghi√™n c·ª©u ƒë·ªÉ lo·∫°i tr·ª´ c√°c y·∫øu t·ªë kh√°c.\nV√≠ d·ª•: N·∫øu b·∫°n th·ª±c hi·ªán m·ªôt th·ª≠ nghi·ªám ng·∫´u nhi√™n ƒë·ªÉ ƒëo l∆∞·ª£ng vitamin C ƒë∆∞·ª£c cung c·∫•p cho m·ªôt nh√≥m ng∆∞·ªùi v√† xem x√©t t√°c ƒë·ªông c·ªßa n√≥ ƒë·ªëi v·ªõi s·ª©c kh·ªèe, b·∫°n c√≥ th·ªÉ ƒë∆∞a ra k·∫øt lu·∫≠n v·ªÅ m·ªëi quan h·ªá nh√¢n qu·∫£ gi·ªØa vitamin C v√† s·ª©c kh·ªèe.\nT√≥m l·∫°i, t∆∞∆°ng quan ch·ªâ m√¥ t·∫£ m·ªëi quan h·ªá gi·ªØa hai bi·∫øn, trong khi nh√¢n qu·∫£ ƒë·ªÅ c·∫≠p ƒë·∫øn m·ªëi quan h·ªá nguy√™n nh√¢n v√† k·∫øt qu·∫£. Vi·ªác x√°c ƒë·ªãnh m·ªëi quan h·ªá nh√¢n qu·∫£ th∆∞·ªùng ph·ª©c t·∫°p h∆°n v√† ƒë√≤i h·ªèi nhi·ªÅu nghi√™n c·ª©u v√† b·∫±ng ch·ª©ng ƒë·ªÉ c√≥ th·ªÉ ch·∫Øc ch·∫Øn r·∫±ng m·ªôt bi·∫øn g√¢y ra s·ª± thay ƒë·ªïi trong bi·∫øn kh√°c.\nN·∫øu t·ªï ch·ª©c c·ªßa b·∫°n c√≥ ƒë·ªß t√†i nguy√™n, b·∫°n c√≥ th·ªÉ ch·∫°y th·ª±c nghi·ªám ƒë·ªÉ t√¨m ra m·ªëi quan h·ªá nh√¢n qu·∫£. N·∫øu x√°c ƒë·ªãnh ƒë∆∞·ª£c m·ªëi quan h·ªá nh√¢n qu·∫£ c·ªßa 2 bi·∫øn, m·ªëi t∆∞∆°ng quan v·∫´n c√≥ th·ªÉ mang l·∫°i c√°i nh√¨n s√¢u s·∫Øc c·∫ßn thi·∫øt ƒë·ªÉ hi·ªÉu d·ªØ li·ªáu c·ªßa b·∫°n v√† s·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√≥ ƒë·ªÉ ƒë∆∞a ra c√°c quy·∫øt ƒë·ªãnh ch√≠nh x√°c h∆°n.\nDiagnostic Regression Analysis M·ªôt s·ªë m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn c√≥ th·ªÉ d·ªÖ d√†ng nh·∫≠n ra, nh∆∞ng m·ªôt s·ªë kh√°c y√™u c·∫ßu ph√¢n t√≠ch s√¢u h∆°n. Ph√¢n t√≠ch h·ªìi quy ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x√°c ƒë·ªãnh m·ªëi quan h·ªá gi·ªØa hai bi·∫øn (single linear regression) ho·∫∑c ba bi·∫øn tr·ªü l√™n (multiple regression). M·ªëi quan h·ªá ƒë∆∞·ª£c th·ªÉ hi·ªán b·∫±ng m·ªôt ph∆∞∆°ng tr√¨nh to√°n h·ªçc chuy·ªÉn th√†nh ƒë·ªô d·ªëc c·ªßa ƒë∆∞·ªùng ph√π h·ª£p nh·∫•t v·ªõi m·ªëi quan h·ªá c·ªßa c√°c bi·∫øn.\nRegression gi√∫p ch√∫ng ta x√°c ƒë·ªãnh insight v·ªÅ c·∫•u tr√∫c c·ªßa m·ªëi quan h·ªá trong 2 hay nhi·ªÅu bi·∫øn v√† cung c·∫•p th∆∞·ªõc ƒëo m·ª©c ƒë·ªô ph√π h·ª£p c·ªßa d·ªØ li·ªáu v·ªõi m·ªëi quan h·ªá( c·ªßa 2 hay nhi·ªÅu bi·∫øn) ƒë√≥\nnostic analytics l√† vi·ªác ch√∫ng ta s·ª≠ d·ª•ng ph√¢n t√≠ch h·ªìi quy ƒë·ªÉ gi·∫£i th√≠ch m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn trong d·ªØ li·ªáu l·ªãch s·ª≠. Sau ƒë√≥, ƒë∆∞·ªùng h·ªìi quy c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ d·ª± ƒëo√°n cho t∆∞∆°ng lai ( l√† v√≠ d·ª• c·ªßa nh√≥m predictive analytics).\nM·ªôt s·ªë v√≠ d·ª• s·ª≠ d·ª•ng diagnostic analytics Examining Market Demand M·ªôt usecase c·ªßa diagnostic analytics l√† x√°c ƒë·ªãnh l√Ω do ƒë·∫±ng sau nhu c·∫ßu s·∫£n ph·∫©m.\nV√≠ d·ª•: C√¥ng ty HelloFresh - c√¥ng ty ƒë·∫°i ch√∫ng qu·ªëc t·∫ø cung c·∫•p ƒë·ªì ƒÉn s∆° ch·∫ø s·∫µn c√≥ tr·ª• s·ªü t·∫°i Berlin, ƒê·ª©c. ƒê√¢y l√† nh√† cung c·∫•p ƒë·ªì ƒÉn s∆° ch·∫ø s·∫µn l·ªõn nh·∫•t ·ªü Hoa K·ª≥, v√† c≈©ng c√≥ ho·∫°t ƒë·ªông ·ªü Canada, T√¢y √Çu. C√¥ng ty thu th·∫≠p h√†ng tri·ªáu ƒëi·ªÉm d·ªØ li·ªáu t·ª´ ng∆∞·ªùi d√πng to√†n c·∫ßu, bao g·ªìm th√¥ng tin v·ªÅ v·ªã tr√≠ ƒë·ªãa l√Ω, d·ªØ li·ªáu nh√¢n kh·∫©u h·ªçc ƒë∆∞·ª£c ti·∫øt l·ªô, lo·∫°i b·ªØa ƒÉn, s·ªü th√≠ch v·ªÅ h∆∞∆°ng v·ªã c≈©ng nh∆∞ nh·ªãp v√† th·ªùi gian ƒë·∫∑t h√†ng th√¥ng th∆∞·ªùng.\nNh√≥m c·ªßa HelloFresh s·ª≠ d·ª•ng d·ªØ li·ªáu n√†y ƒë·ªÉ x√°c ƒë·ªãnh m·ªëi quan h·ªá gi·ªØa c√°c xu h∆∞·ªõng v·ªÅ thu·ªôc t√≠nh v√† h√†nh vi c·ªßa kh√°ch h√†ng. Nh∆∞ m·ªôt v√≠ d·ª• gi·∫£ ƒë·ªãnh, h√£y t∆∞·ªüng t∆∞·ª£ng nh√≥m HelloFresh x√°c ƒë·ªãnh ƒë∆∞·ª£c s·ª± gia tƒÉng ƒë·ªôt bi·∫øn v·ªÅ ƒë∆°n ƒë·∫∑t h√†ng c√¥ng th·ª©c ch·∫ø bi·∫øn t·ª´ c√°. Sau khi ti·∫øn h√†nh ph√¢n t√≠ch ch·∫©n ƒëo√°n, h·ªç ph√°t hi·ªán ra r·∫±ng c√°c thu·ªôc t√≠nh c√≥ m·ªëi t∆∞∆°ng quan cao nh·∫•t v·ªõi vi·ªác ƒë·∫∑t h√†ng c√°c c√¥ng th·ª©c n·∫•u c√° ƒë∆∞·ª£c x√°c ƒë·ªãnh l√† n·ªØ v√† s·ªëng ·ªü v√πng ƒë√¥ng b·∫Øc Hoa K·ª≥.\nT·ª´ ƒë√≥, nh√≥m c√≥ th·ªÉ ti·∫øn h√†nh nghi√™n c·ª©u th·ªã tr∆∞·ªùng v·ªõi nh√≥m nh√¢n kh·∫©u h·ªçc c·ª• th·ªÉ ƒë√≥ ƒë·ªÉ t√¨m hi·ªÉu th√™m v·ªÅ nhu c·∫ßu v·ªÅ c√¥ng th·ª©c n·∫•u c√°. C√≥ ph·∫£i nguy√™n nh√¢n l√† do m·ªôt nghi√™n c·ª©u khoa h·ªçc g·∫ßn ƒë√¢y ca ng·ª£i l·ª£i √≠ch s·ª©c kh·ªèe c·ªßa c√° ƒë·ªëi v·ªõi ph·ª• n·ªØ? C√≥ l·∫Ω nh·ªØng ng∆∞·ªùi s·ªëng ·ªü v√πng ƒë√¥ng b·∫Øc Hoa K·ª≥ c√≥ kh·∫©u v·ªã h·∫£i s·∫£n tinh t·∫ø v√¨ h·ªç s·ªëng t∆∞∆°ng ƒë·ªëi g·∫ßn ƒê·∫°i T√¢y D∆∞∆°ng. L√Ω lu·∫≠n c·ªßa h·ªç c√≥ th·ªÉ cung c·∫•p nh·ªØng hi·ªÉu bi·∫øt s√¢u s·∫Øc c√≥ t√°c ƒë·ªông cho HelloFresh.\nKhi nghi√™n c·ª©u c√°c lo·∫°i ph√¢n t√≠ch kh√°c, nh√≥m c≈©ng c√≥ th·ªÉ xem x√©t li·ªáu xu h∆∞·ªõng n√†y c√≥ ti·∫øp t·ª•c hay kh√¥ng (ph√¢n t√≠ch d·ª± ƒëo√°n) v√† li·ªáu vi·ªác t·∫°o ra nhi·ªÅu c√¥ng th·ª©c n·∫•u ƒÉn t·ª´ c√° h∆°n c√≥ x·ª©ng ƒë√°ng v·ªõi c√¥ng s·ª©c v√† ti·ªÅn b·∫°c ƒë·ªÉ ƒë√°p ·ª©ng s·ªü th√≠ch c·ªßa ƒë·ªëi t∆∞·ª£ng n√†y hay kh√¥ng (ph√¢n t√≠ch theo quy ƒë·ªãnh).\nExplaining Customer Behavior ƒê·ªëi v·ªõi c√°c c√¥ng ty, vi·ªác thu th·∫≠p d·ªØ li·ªáu kh√°ch h√†ng, ph√¢n t√≠ch, ch·∫©n ƒëo√°n l√† ch√¨a kh√≥a ƒë·ªÉ hi·ªÉu l√Ω do t·∫°i sao kh√°ch h√†ng l√†m nh∆∞ v·∫≠y. Nh·ªØng th√¥ng tin chi ti·∫øt n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ c·∫£i thi·ªán s·∫£n ph·∫©m v√† tr·∫£i nghi·ªám ng∆∞·ªùi d√πng (UX), ƒë·ªãnh v·ªã l·∫°i th√¥ng ƒëi·ªáp th∆∞∆°ng hi·ªáu v√† ƒë·∫£m b·∫£o s·∫£n ph·∫©m ph√π h·ª£p v·ªõi ƒë·ªëi t∆∞·ª£ng.\nTi·∫øp t·ª•c v·ªõi v√≠ d·ª• HelloFresh, h√£y xem x√©t gi√° tr·ªã c·ªßa vi·ªác gi·ªØ ch√¢n kh√°ch h√†ng ƒë·ªëi v·ªõi c√¥ng ty ho·∫°t ƒë·ªông theo m√¥ h√¨nh ƒëƒÉng k√Ω. Gi·ªØ ch√¢n kh√°ch h√†ng s·∫Ω ti·∫øt ki·ªám chi ph√≠ h∆°n so v·ªõi vi·ªác c√≥ ƒë∆∞·ª£c kh√°ch h√†ng m·ªõi, v√¨ v·∫≠y HelloFresh s·ª≠ d·ª•ng ph√¢n t√≠ch ch·∫©n ƒëo√°n ƒë·ªÉ x√°c ƒë·ªãnh l√Ω do khi·∫øn kh√°ch h√†ng r·ªùi ƒëi ch·ªçn h·ªßy ƒëƒÉng k√Ω.\nTrong qu√° tr√¨nh h·ªßy, kh√°ch h√†ng r·ªùi ƒëi ph·∫£i cung c·∫•p l√Ω do h·ªßy. C√°c t√πy ch·ªçn bao g·ªìm t·ª´ ‚Äúkh√¥ng ph√π h·ª£p v·ªõi t√∫i ti·ªÅn c·ªßa t√¥i‚Äù ƒë·∫øn ‚Äúkh√¥ng ph√π h·ª£p v·ªõi l·ªãch tr√¨nh ho·∫∑c nhu c·∫ßu ƒÉn ki√™ng c·ªßa t√¥i‚Äù v√† c≈©ng c√≥ t√πy ch·ªçn ƒë·ªÉ vi·∫øt c√¢u tr·∫£ l·ªùi. B·∫±ng c√°ch thu th·∫≠p d·ªØ li·ªáu n√†y, HelloFresh c√≥ th·ªÉ ph√¢n t√≠ch c√°c l√Ω do m·∫•t kh√°ch h√†ng ƒë∆∞·ª£c n√™u nhi·ªÅu nh·∫•t ·ªü c√°c khu v·ª±c v√† nh√¢n kh·∫©u h·ªçc c·ª• th·ªÉ, ƒë·ªìng th·ªùi s·ª≠ d·ª•ng ph√¢n t√≠ch ch·∫©n ƒëo√°n ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi ‚ÄúT·∫°i sao m·ªçi ng∆∞·ªùi h·ªßy ƒëƒÉng k√Ω?‚Äù\nNh·ªØng hi·ªÉu bi·∫øt s√¢u s·∫Øc n√†y c√≥ th·ªÉ gi√∫p c·∫£i thi·ªán tr·∫£i nghi·ªám ng∆∞·ªùi d√πng v√† s·∫£n ph·∫©m c·ªßa HelloFresh ƒë·ªÉ tr√°nh m·∫•t th√™m kh√°ch h√†ng v√¨ nh·ªØng l√Ω do ƒë√≥.\nIdentifying Technology Issues M·ªôt v√≠ d·ª• v·ªÅ diagnostic analytics trong b√†i to√°n n√†y l√† c√°c tester b·ªã y√™u c·∫ßu s·ª≠ d·ª•ng ch∆∞∆°ng tr√¨nh ph·∫ßn m·ªÅm v√† ch·∫°y th·ª≠ nghi·ªám (test) ƒë·ªÉ x√°c ƒë·ªãnh nguy√™n nh√¢n c·ªßa s·ª± c·ªë, c√°c l·ªói. ƒêi·ªÅu n√†y th∆∞·ªùng ƒë∆∞·ª£c g·ªçi l√† \u0026ldquo;ch·∫°y ch·∫©n ƒëo√°n\u0026rdquo; v√† c√≥ th·ªÉ l√† ƒëi·ªÅu b·∫°n ƒë√£ l√†m tr∆∞·ªõc ƒë√¢y khi g·∫∑p s·ª± c·ªë m√°y t√≠nh.\nM·ªôt s·ªë thu·∫≠t to√°n ch·∫°y li√™n t·ª•c v√† ho·∫°t ƒë·ªông ·ªü ch·∫ø ƒë·ªô n·ªÅn c·ªßa m√°y, trong khi nh·ªØng thu·∫≠t to√°n kh√°c c·∫ßn do con ng∆∞·ªùi th·ª±c hi·ªán. M·ªôt lo·∫°i ki·ªÉm tra ch·∫©n ƒëo√°n m√† b·∫°n c√≥ th·ªÉ quen thu·ªôc l√† ch·∫©n ƒëo√°n d·ª±a tr√™n gi·∫£i ph√°p, ph√°t hi·ªán v√† g·∫Øn c·ªù c√°c tri·ªáu ch·ª©ng c·ªßa c√°c v·∫•n ƒë·ªÅ ƒë√£ bi·∫øt v√† ti·∫øn h√†nh qu√©t ƒë·ªÉ x√°c ƒë·ªãnh nguy√™n nh√¢n g·ªëc r·ªÖ. ƒêi·ªÅu n√†y c√≥ th·ªÉ cho ph√©p b·∫°n gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ v√† b√°o c√°o v·∫•n ƒë·ªÅ n·∫øu nguy√™n nh√¢n nghi√™m tr·ªçng.\nImproving Company Culture Diagnostic analytics c≈©ng c√≥ th·ªÉ ƒë∆∞·ª£c t·∫≠n d·ª•ng ƒë·ªÉ c·∫£i thi·ªán vƒÉn h√≥a n·ªôi b·ªô c√¥ng ty. B·ªô ph·∫≠n nh√¢n s·ª± c√≥ th·ªÉ thu th·∫≠p th√¥ng tin v·ªÅ c·∫£m gi√°c an to√†n v·ªÅ th·ªÉ ch·∫•t v√† t√¢m l√Ω c·ªßa nh√¢n vi√™n, nh·ªØng v·∫•n ƒë·ªÅ h·ªç quan t√¢m c≈©ng nh∆∞ nh·ªØng ph·∫©m ch·∫•t v√† k·ªπ nƒÉng gi√∫p ai ƒë√≥ th√†nh c√¥ng v√† h·∫°nh ph√∫c. Nhi·ªÅu th√¥ng tin chi ti·∫øt trong s·ªë n√†y ƒë·∫øn t·ª´ vi·ªác th·ª±c hi·ªán c√°c cu·ªôc kh·∫£o s√°t n·ªôi b·ªô, ·∫©n danh v√† th·ª±c hi·ªán c√°c cu·ªôc ph·ªèng v·∫•n th√¥i vi·ªác ƒë·ªÉ x√°c ƒë·ªãnh c√°c y·∫øu t·ªë g√≥p ph·∫ßn khi·∫øn nh√¢n vi√™n mu·ªën ·ªü l·∫°i ho·∫∑c r·ªùi ƒëi.\nThu th·∫≠p th√¥ng tin v·ªÅ suy nghƒ© v√† c·∫£m x√∫c c·ªßa nh√¢n vi√™n cho ph√©p b·∫°n ph√¢n t√≠ch d·ªØ li·ªáu v√† x√°c ƒë·ªãnh c√°ch c·∫£i thi·ªán c√°c lƒ©nh v·ª±c nh∆∞ vƒÉn h√≥a v√† l·ª£i √≠ch c√¥ng ty. ƒêi·ªÅu n√†y c√≥ th·ªÉ bao g·ªìm b·∫•t c·ª© ƒëi·ªÅu g√¨ t·ª´ mong mu·ªën c√¥ng ty ƒë√≥ng g√≥p nhi·ªÅu h∆°n cho tr√°ch nhi·ªám x√£ h·ªôi c·ªßa doanh nghi·ªáp (CSR) cho ƒë·∫øn c·∫£m gi√°c b·ªã ph√¢n bi·ªát ƒë·ªëi x·ª≠ t·∫°i n∆°i l√†m vi·ªác. Trong nh·ªØng tr∆∞·ªùng h·ª£p n√†y, d·ªØ li·ªáu tr√¨nh b√†y m·ªôt tr∆∞·ªùng h·ª£p ph√¢n b·ªï nhi·ªÅu ngu·ªìn l·ª±c h∆°n cho CSR v√† c√°c n·ªó l·ª±c ƒëa d·∫°ng, c√¥ng b·∫±ng, h√≤a nh·∫≠p v√† thu·ªôc v·ªÅ.\nNh·ªØng hi·ªÉu bi·∫øt s√¢u s·∫Øc t·ª´ c√°c cu·ªôc kh·∫£o s√°t v√† ph·ªèng v·∫•n c≈©ng c√≥ th·ªÉ cho ph√©p ng∆∞·ªùi qu·∫£n l√Ω tuy·ªÉn d·ª•ng x√°c ƒë·ªãnh nh·ªØng ph·∫©m ch·∫•t v√† k·ªπ nƒÉng n√†o gi√∫p ai ƒë√≥ th√†nh c√¥ng t·∫°i c√¥ng ty ho·∫∑c trong nh√≥m c·ª• th·ªÉ c·ªßa b·∫°n, t·ª´ ƒë√≥ gi√∫p thu h√∫t v√† tuy·ªÉn d·ª•ng nh·ªØng ·ª©ng vi√™n t·ªët h∆°n cho c√°c vai tr√≤ c√≤n tr·ªëng.\nPh√¢n t√≠ch ch·∫©n ƒëo√°n c√≥ th·ªÉ gi√∫p n√¢ng cao m·ª©c ƒë·ªô h√†i l√≤ng, an to√†n v√† gi·ªØ ch√¢n nh√¢n vi√™n, c≈©ng nh∆∞ gi√∫p quy tr√¨nh tuy·ªÉn d·ª•ng hi·ªáu qu·∫£ h∆°n.\n4 Predictive analytics: Predictive analytics l√† m·ªôt ph∆∞∆°ng ph√°p trong lƒ©nh v·ª±c ph√¢n t√≠ch d·ªØ li·ªáu (data analytics) s·ª≠ d·ª•ng ƒë·ªÉ d·ª± ƒëo√°n c√°c s·ª± ki·ªán t∆∞∆°ng lai ho·∫∑c k·∫øt qu·∫£ d·ª±a tr√™n d·ªØ li·ªáu l·ªãch s·ª≠ v√† m√¥ h√¨nh h√≥a th·ªëng k√™. ƒê√¢y l√† m·ªôt c√¥ng c·ª• m·∫°nh m·∫Ω trong nhi·ªÅu lƒ©nh v·ª±c v√† ng√†nh c√¥ng nghi·ªáp, nh∆∞ ti·∫øp th·ªã, t√†i ch√≠nh, y t·∫ø, s·∫£n xu·∫•t, v√† nhi·ªÅu lƒ©nh v·ª±c kh√°c.\nC√°c b∆∞·ªõc ch√≠nh trong qu√° tr√¨nh predictive analytics bao g·ªìm:\nThu th·∫≠p d·ªØ li·ªáu: B∆∞·ªõc ƒë·∫ßu ti√™n l√† thu th·∫≠p v√† t·ªïng h·ª£p d·ªØ li·ªáu li√™n quan ƒë·∫øn v·∫•n ƒë·ªÅ c·∫ßn d·ª± ƒëo√°n. D·ªØ li·ªáu n√†y c√≥ th·ªÉ l√† d·ªØ li·ªáu l·ªãch s·ª≠ ho·∫∑c d·ªØ li·ªáu th·ªùi gian th·ª±c.\nTi·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu: D·ªØ li·ªáu th∆∞·ªùng c·∫ßn ph·∫£i ƒë∆∞·ª£c l√†m s·∫°ch v√† ti·ªÅn x·ª≠ l√Ω tr∆∞·ªõc khi s·ª≠ d·ª•ng. ƒêi·ªÅu n√†y bao g·ªìm vi·ªác lo·∫°i b·ªè d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá ho·∫∑c thi·∫øu s√≥t, x·ª≠ l√Ω gi√° tr·ªã thi·∫øu, v√† bi·∫øn ƒë·ªïi d·ªØ li·ªáu n·∫øu c·∫ßn.\nX√¢y d·ª±ng m√¥ h√¨nh: Trong b∆∞·ªõc n√†y, c√°c m√¥ h√¨nh th·ªëng k√™ ho·∫∑c machine learning ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu v√† d·ª± ƒëo√°n c√°c s·ª± ki·ªán t∆∞∆°ng lai. C√°c m√¥ h√¨nh ph·ªï bi·∫øn bao g·ªìm h·ªìi quy tuy·∫øn t√≠nh, c√¢y quy·∫øt ƒë·ªãnh, m·∫°ng n∆°-ron, v√† nhi·ªÅu m√¥ h√¨nh kh√°c.\nƒê√°nh gi√° v√† tinh ch·ªânh m√¥ h√¨nh: M√¥ h√¨nh ƒë∆∞·ª£c ƒë√°nh gi√° b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c ph∆∞∆°ng ph√°p ki·ªÉm tra v√† ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng d·ª± ƒëo√°n. N·∫øu c·∫ßn, m√¥ h√¨nh ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t.\nTri·ªÉn khai m√¥ h√¨nh: Sau khi m√¥ h√¨nh ƒë∆∞·ª£c ƒë√°nh gi√° v√† ch·∫•p nh·∫≠n, n√≥ c√≥ th·ªÉ ƒë∆∞·ª£c tri·ªÉn khai ƒë·ªÉ s·ª≠ d·ª•ng trong th·ª±c t·∫ø. C√°c d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh c√≥ th·ªÉ ƒë∆∞·ª£c t√≠ch h·ª£p v√†o quy tr√¨nh kinh doanh ho·∫∑c h·ªá th·ªëng th√¥ng tin.\nPredictive analytics c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nhi·ªÅu m·ª•c ƒë√≠ch, ch·∫≥ng h·∫°n nh∆∞ d·ª± ƒëo√°n doanh s·ªë b√°n h√†ng, ph√¢n t√≠ch r·ªßi ro t√≠n d·ª•ng, d·ª± ƒëo√°n bi·∫øn ƒë·ªông th·ªã tr∆∞·ªùng, qu·∫£n l√Ω t·ªìn kho, d·ª± ƒëo√°n th·ªùi ti·∫øt, v√† nhi·ªÅu ·ª©ng d·ª•ng kh√°c. ƒê√¢y l√† c√¥ng c·ª• quan tr·ªçng gi√∫p doanh nghi·ªáp v√† t·ªï ch·ª©c l√†m quy·∫øt ƒë·ªãnh d·ª±a tr√™n d·ªØ li·ªáu v√† c·∫£i thi·ªán hi·ªáu su·∫•t kinh doanh.\n5 V√≠ d·ª• c·ªßa PREDICTIVE ANALYTICS trong th·ª±c t·∫ø Finance: Forecasting Future Cash Flow Gi√°o s∆∞ V.G. Narayanan c·ªßa HBS n√≥i: ‚ÄúC√°c nh√† qu·∫£n l√Ω c·∫ßn ph·∫£i nh√¨n v·ªÅ ph√≠a tr∆∞·ªõc ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch cho t√¨nh h√¨nh ho·∫°t ƒë·ªông kinh doanh trong t∆∞∆°ng lai c·ªßa h·ªç‚Äù. ‚ÄúB·∫•t k·ªÉ b·∫°n l√†m vi·ªác trong lƒ©nh v·ª±c n√†o, lu√¥n c√≥ r·∫•t nhi·ªÅu ƒëi·ªÅu kh√¥ng ch·∫Øc ch·∫Øn li√™n quan ƒë·∫øn qu√° tr√¨nh n√†y.‚Äù\nM·ªçi doanh nghi·ªáp ƒë·ªÅu c·∫ßn l∆∞u gi·ªØ h·ªì s∆° t√†i ch√≠nh ƒë·ªãnh k·ª≥ v√† ph√¢n t√≠ch d·ª± ƒëo√°n c√≥ th·ªÉ ƒë√≥ng m·ªôt vai tr√≤ l·ªõn trong vi·ªác d·ª± b√°o t√¨nh tr·∫°ng t∆∞∆°ng lai c·ªßa c√¥ng ty. S·ª≠ d·ª•ng d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ c√°c b√°o c√°o t√†i ch√≠nh tr∆∞·ªõc ƒë√≥ c≈©ng nh∆∞ d·ªØ li·ªáu t·ª´ ng√†nh r·ªông h∆°n, b·∫°n c√≥ th·ªÉ d·ª± ƒëo√°n s·ªë b√°n, doanh thu v√† chi ph√≠ ƒë·ªÉ t·∫°o ra b·ª©c tranh v·ªÅ t∆∞∆°ng lai v√† ƒë∆∞a ra quy·∫øt ƒë·ªãnh.\nD·ª± b√°o d√≤ng ti·ªÅn trong t∆∞∆°ng lai l√† m·ªôt quy tr√¨nh ph√¢n t√≠ch t√†i ch√≠nh quan tr·ªçng, bao g·ªìm vi·ªác ∆∞·ªõc t√≠nh d√≤ng ti·ªÅn v√†o v√† ra m√† m·ªôt doanh nghi·ªáp d·ª± ki·∫øn ‚Äã‚Äãs·∫Ω t·∫°o ra trong m·ªôt kho·∫£ng th·ªùi gian c·ª• th·ªÉ trong t∆∞∆°ng lai. D·ª± b√°o d√≤ng ti·ªÅn ch√≠nh x√°c l√† r·∫•t quan tr·ªçng ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch t√†i ch√≠nh hi·ªáu qu·∫£, ng√¢n s√°ch v√† quy·∫øt ƒë·ªãnh trong m·ªôt c√¥ng ty. D∆∞·ªõi ƒë√¢y l√† m·ªôt c√°i nh√¨n t·ªïng quan v·ªÅ c√°c b∆∞·ªõc v√† y·∫øu t·ªë c·∫ßn xem x√©t khi d·ª± b√°o d√≤ng ti·ªÅn trong t∆∞∆°ng lai:\nThu th·∫≠p D·ªØ li·ªáu L·ªãch s·ª≠: B·∫Øt ƒë·∫ßu b·∫±ng vi·ªác thu th·∫≠p v√† ph√¢n t√≠ch d·ªØ li·ªáu t√†i ch√≠nh l·ªãch s·ª≠, bao g·ªìm b√°o c√°o d√≤ng ti·ªÅn, b√°o c√°o l·ª£i nhu·∫≠n v√† b·∫£ng c√¢n ƒë·ªëi k·∫ø to√°n. D·ªØ li·ªáu l·ªãch s·ª≠ cung c·∫•p th√¥ng tin qu√Ω b√°u v·ªÅ c√°c m√¥ h√¨nh v√† xu h∆∞·ªõng d√≤ng ti·ªÅn trong qu√° kh·ª©.\nX√°c ƒë·ªãnh C√°c Th√†nh Ph·∫ßn D√≤ng Ti·ªÅn: Ph√¢n chia d√≤ng ti·ªÅn th√†nh c√°c th√†nh ph·∫ßn kh√°c nhau, bao g·ªìm d√≤ng ti·ªÅn t·ª´ ho·∫°t ƒë·ªông kinh doanh, d√≤ng ti·ªÅn t·ª´ ho·∫°t ƒë·ªông ƒë·∫ßu t∆∞ v√† d√≤ng ti·ªÅn t·ª´ ho·∫°t ƒë·ªông t√†i ch√≠nh. ƒêi·ªÅu n√†y gi√∫p hi·ªÉu r√µ d√≤ng ti·ªÅn ƒë·∫øn t·ª´ ƒë√¢u v√† ƒëi·ªÅu g√¨ l√†m ti√™u hao d√≤ng ti·ªÅn.\n∆Ø·ªõc T√≠nh Doanh S·ªë v√† Doanh Thu: ∆Ø·ªõc t√≠nh doanh s·ªë b√°n h√†ng v√† doanh thu t∆∞∆°ng lai d·ª±a tr√™n nghi√™n c·ª©u th·ªã tr∆∞·ªùng, d·ªØ li·ªáu doanh s·ªë b√°n h√†ng l·ªãch s·ª≠ v√† xu h∆∞·ªõng trong ng√†nh. Xem x√©t c√°c y·∫øu t·ªë nh∆∞ m√πa v·ª•, s·ª± ph√°t tri·ªÉn c·ªßa th·ªã tr∆∞·ªùng v√† ƒë·ªông th√°i c·∫°nh tranh.\n∆Ø·ªõc T√≠nh Chi Ph√≠ v√† Ph√≠: D·ª± ƒëo√°n c√°c chi ph√≠ ho·∫°t ƒë·ªông, bao g·ªìm chi ph√≠ v·ªën h√†ng b√°n, chi ph√≠ ho·∫°t ƒë·ªông c·ªë ƒë·ªãnh v√† chi ph√≠ bi·∫øn ƒë·ªïi. Xem x√©t l·∫°m ph√°t, xu h∆∞·ªõng chi ph√≠ v√† c√°c bi·ªán ph√°p ti·∫øt ki·ªám chi ph√≠ c√≥ th·ªÉ th·ª±c hi·ªán.\nThay ƒê·ªïi V·ªën L√†m Vi·ªác: Ph√¢n t√≠ch thay ƒë·ªïi trong v·ªën l√†m vi·ªác, bao g·ªìm c√°c t√†i kho·∫£n ph·∫£i thu, t√†i kho·∫£n ph·∫£i tr·∫£ v√† v√≤ng quay t·ªìn kho. Thay ƒë·ªïi trong v·ªën l√†m vi·ªác c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ ƒë·∫øn d√≤ng ti·ªÅn.\nL·∫≠p K·∫ø Ho·∫°ch ƒê·∫ßu T∆∞ C·ªë ƒê·ªãnh (CapEx): D·ª± ƒëo√°n c√°c kho·∫£n ƒë·∫ßu t∆∞ c·ªë ƒë·ªãnh cho vi·ªác mua s·∫Øm t√†i s·∫£n, thi·∫øt b·ªã v√† c∆° s·ªü h·∫° t·∫ßng. CapEx c√≥ th·ªÉ c√≥ ·∫£nh h∆∞·ªüng l·ªõn ƒë·∫øn d√≤ng ti·ªÅn, v√¨ v·∫≠y c·∫ßn l·∫≠p k·∫ø ho·∫°ch cho nh·ªØng kho·∫£n chi n√†y.\nQu·∫£n L√Ω N·ª£ v√† V·ªën Ch·ªß S·ªü H·ªØu: Xem x√©t b·∫•t k·ª≥ kho·∫£n tr·∫£ n·ª£, vay m·ªõi ho·∫∑c c·∫•p v·ªën ch·ªß s·ªü h·ªØu. D·ªãch v·ª• n·ª£, l√£i su·∫•t v√† v·ªën c·ªï ph·∫ßn ·∫£nh h∆∞·ªüng ƒë·∫øn d√≤ng ti·ªÅn.\nPh√¢n T√≠ch K·ªãch B·∫£n: Ti·∫øn h√†nh ph√¢n t√≠ch nh·∫°y c·∫£m v√† l·∫≠p k·∫ø ho·∫°ch cho c√°c k·ªãch b·∫£n kh√°c nhau ƒë·ªÉ t√≠nh ƒë·∫øn c√°c k·∫øt qu·∫£ kh·∫£ dƒ© kh√°c nhau. ƒêi·ªÅu n√†y gi√∫p ƒë√°nh gi√° t√°c ƒë·ªông c·ªßa c√°c k·ªãch b·∫£n kh√°c nhau l√™n d√≤ng ti·ªÅn.\nT·∫°o B√°o C√°o D√≤ng Ti·ªÅn: Ph√°t tri·ªÉn b√°o c√°o d·ª± b√°o d√≤ng ti·ªÅn bao g·ªìm d√≤ng ti·ªÅn v√†o v√† ra trong kho·∫£ng th·ªùi gian d·ª± b√°o. B√°o c√°o n√†y n√™n cung c·∫•p c√°i nh√¨n r√µ r√†ng v·ªÅ d√≤ng ti·ªÅn theo t·ª´ng th√°ng ho·∫∑c qu√Ω.\nTheo D√µi v√† ƒê√°nh Gi√°: Li√™n t·ª•c theo d√µi v√† ƒë√°nh gi√° d√≤ng ti·ªÅn th·ª±c t·∫ø so v·ªõi s·ªë li·ªáu d·ª± b√°o. ƒêi·ªÅu ch·ªânh d·ª± b√°o khi c·∫ßn d·ª±a tr√™n hi·ªáu su·∫•t th·ª±c t·∫ø v√† thay ƒë·ªïi trong ƒëi·ªÅu ki·ªán th·ªã tr∆∞·ªùng.\nC√¥ng C·ª• D·ª± B√°o D√≤ng Ti·ªÅn: Xem x√©t vi·ªác s·ª≠ d·ª•ng ph·∫ßn m·ªÅm m√¥ h√¨nh t√†i ch√≠nh ho·∫∑c c√¥ng c·ª• b·∫£ng t√≠nh ƒë·ªÉ t·ªëi ∆∞u h√≥a qu√° tr√¨nh d·ª± b√°o v√† th·ª±c hi·ªán ph√¢n t√≠ch nh·∫°y c·∫£m.\nƒê√°nh Gi√° R·ªßi Ro: X√°c ƒë·ªãnh v√† ƒë√°nh gi√° c√°c r·ªßi ro c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn d√≤ng ti·ªÅn, ch·∫≥ng h·∫°n nh∆∞ suy tho√°i kinh t·∫ø, thay ƒë·ªïi trong h√†nh vi c·ªßa kh√°ch h√†ng ho·∫∑c s·ª± c·ªë trong chu·ªói cung ·ª©ng.\nD·ª± b√°o d√≤ng ti·ªÅn hi·ªáu qu·∫£ l√† quan tr·ªçng ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng m·ªôt c√¥ng ty c√≥ th·ªÉ ƒë√°p ·ª©ng c√°c nghƒ©a v·ª• t√†i ch√≠nh c·ªßa m√¨nh, t·∫≠n d·ª•ng c∆° h·ªôi tƒÉng tr∆∞·ªüng v√† ƒë·ªëi m·∫∑t v·ªõi nh·ªØng th√°ch th·ª©c t√†i ch√≠nh. N√≥ c≈©ng gi√∫p t·ªëi ∆∞u h√≥a chi·∫øn l∆∞·ª£c qu·∫£n l√Ω ti·ªÅn m·∫∑t v√† ƒë∆∞a ra quy·∫øt ƒë·ªãnh ƒë·∫ßu t∆∞ d·ª±a tr√™n th√¥ng tin. Ngo√†i ra, c√°c d·ª± b√°o d√≤ng ti·ªÅn ch√≠nh x√°c th∆∞·ªùng ƒë∆∞·ª£c y√™u c·∫ßu b·ªüi c√°c nh√† cho vay v√† nh√† ƒë·∫ßu t∆∞ nh∆∞ m·ªôt ph·∫ßn c·ªßa qu√° tr√¨nh ki·ªÉm tra t√†i ch√≠nh.\nEntertainment \u0026amp; Hospitality: Determining Staffing Needs M·ªôt v√≠ d·ª• l√† vi·ªác s√≤ng b·∫°c v√† kh√°ch s·∫°n Caesars Entertainment s·ª≠ d·ª•ng ph√¢n t√≠ch d·ª± ƒëo√°n ƒë·ªÉ x√°c ƒë·ªãnh nhu c·∫ßu nh√¢n s·ª± c·ªßa c√°c ƒë·ªãa ƒëi·ªÉm kinh doanh c·ªßa m√¨nh v√†o nh·ªØng th·ªùi ƒëi·ªÉm c·ª• th·ªÉ.\nTrong ng√†nh gi·∫£i tr√≠ v√† kh√°ch s·∫°n, l∆∞·ª£ng kh√°ch h√†ng ƒë·∫øn v√† ƒëi ph·ª• thu·ªôc v√†o nhi·ªÅu y·∫øu t·ªë kh√°c nhau, t·∫•t c·∫£ ƒë·ªÅu ·∫£nh h∆∞·ªüng ƒë·∫øn s·ªë l∆∞·ª£ng nh√¢n vi√™n m√† m·ªôt ƒë·ªãa ƒëi·ªÉm ho·∫∑c kh√°ch s·∫°n c·∫ßn t·∫°i m·ªôt th·ªùi ƒëi·ªÉm nh·∫•t ƒë·ªãnh. Vi·ªác s·ª≠ d·ª•ng qu√° nhi·ªÅu nh√¢n l·ª±c s·∫Ω t·ªën ti·ªÅn v√† vi·ªác thi·∫øu nh√¢n l·ª±c c√≥ th·ªÉ d·∫´n ƒë·∫øn tr·∫£i nghi·ªám kh√°ch h√†ng t·ªìi t·ªá, nh√¢n vi√™n l√†m vi·ªác qu√° s·ª©c v√† nh·ªØng sai l·∫ßm t·ªën k√©m.\nƒê·ªÉ d·ª± ƒëo√°n s·ªë l∆∞·ª£t nh·∫≠n ph√≤ng kh√°ch s·∫°n v√†o m·ªôt ng√†y nh·∫•t ƒë·ªãnh, m·ªôt nh√≥m ƒë√£ ph√°t tri·ªÉn m√¥ h√¨nh h·ªìi quy b·ªôi xem x√©t m·ªôt s·ªë y·∫øu t·ªë. M√¥ h√¨nh n√†y cho ph√©p Caesars b·ªë tr√≠ nh√¢n s·ª± cho c√°c kh√°ch s·∫°n v√† s√≤ng b·∫°c c·ªßa m√¨nh v√† tr√°nh s·ª≠ d·ª•ng qu√° nhi·ªÅu nh√¢n l·ª±c ·ªü m·ª©c t·ªët nh·∫•t c√≥ th·ªÉ.\nMarketing: Behavioral Targeting Trong ti·∫øp th·ªã, d·ªØ li·ªáu ng∆∞·ªùi ti√™u d√πng r·∫•t phong ph√∫ v√† ƒë∆∞·ª£c t·∫≠n d·ª•ng ƒë·ªÉ t·∫°o n·ªôi dung, t·∫°o qu·∫£ng c√°o v√† t·∫°o c√°c chi·∫øn l∆∞·ª£c nh·∫±m ti·∫øp c·∫≠n kh√°ch h√†ng ti·ªÅm nƒÉng t·ªët h∆°n. B·∫±ng c√°ch ki·ªÉm tra d·ªØ li·ªáu h√†nh vi l·ªãch s·ª≠ v√† s·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√≥ ƒë·ªÉ d·ª± ƒëo√°n ƒëi·ªÅu g√¨ s·∫Ω x·∫£y ra trong t∆∞∆°ng lai, b·∫°n ƒë√£ s·ª≠ d·ª•ng ph√¢n t√≠ch d·ª± ƒëo√°n.\nPh√¢n t√≠ch d·ª± ƒëo√°n c√≥ th·ªÉ ƒë∆∞·ª£c √°p d·ª•ng trong ti·∫øp th·ªã ƒë·ªÉ d·ª± b√°o xu h∆∞·ªõng b√°n h√†ng v√†o c√°c th·ªùi ƒëi·ªÉm kh√°c nhau trong nƒÉm v√† l√™n k·∫ø ho·∫°ch cho c√°c chi·∫øn d·ªãch ph√π h·ª£p.\nManufacturing: Preventing Malfunction C√°c v√≠ d·ª• tr√™n s·ª≠ d·ª•ng ph√¢n t√≠ch d·ª± ƒëo√°n ƒë·ªÉ th·ª±c hi·ªán h√†nh ƒë·ªông d·ª±a tr√™n c√°c t√¨nh hu·ªëng c√≥ th·ªÉ x·∫£y ra, nh∆∞ng b·∫°n c≈©ng c√≥ th·ªÉ s·ª≠ d·ª•ng ph√¢n t√≠ch d·ª± ƒëo√°n ƒë·ªÉ ngƒÉn x·∫£y ra c√°c t√¨nh hu·ªëng kh√¥ng mong mu·ªën ho·∫∑c c√≥ h·∫°i. V√≠ d·ª•, trong lƒ©nh v·ª±c s·∫£n xu·∫•t, c√°c thu·∫≠t to√°n c√≥ th·ªÉ ƒë∆∞·ª£c ƒë√†o t·∫°o b·∫±ng c√°ch s·ª≠ d·ª•ng d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ d·ª± ƒëo√°n ch√≠nh x√°c khi n√†o m·ªôt b·ªô ph·∫≠n m√°y m√≥c c√≥ th·ªÉ g·∫∑p tr·ª•c tr·∫∑c.\nKhi ƒë√°p ·ª©ng c√°c ti√™u ch√≠ cho s·ª± c·ªë s·∫Øp x·∫£y ra, thu·∫≠t to√°n s·∫Ω ƒë∆∞·ª£c k√≠ch ho·∫°t ƒë·ªÉ c·∫£nh b√°o nh√¢n vi√™n c√≥ th·ªÉ d·ª´ng m√°y v√† c√≥ kh·∫£ nƒÉng ti·∫øt ki·ªám cho c√¥ng ty h√†ng ngh√¨n, n·∫øu kh√¥ng mu·ªën n√≥i l√† h√†ng tri·ªáu ƒë√¥ la chi ph√≠ s·∫£n ph·∫©m b·ªã h∆∞ h·ªèng v√† s·ª≠a ch·ªØa. Ph√¢n t√≠ch n√†y d·ª± ƒëo√°n c√°c t√¨nh hu·ªëng tr·ª•c tr·∫∑c t·∫°i th·ªùi ƒëi·ªÉm n√†y thay v√¨ tr∆∞·ªõc nhi·ªÅu th√°ng ho·∫∑c nhi·ªÅu nƒÉm.\nM·ªôt s·ªë thu·∫≠t to√°n th·∫≠m ch√≠ c√≤n ƒë·ªÅ xu·∫•t c√°c b·∫£n s·ª≠a l·ªói v√† t·ªëi ∆∞u h√≥a ƒë·ªÉ tr√°nh c√°c tr·ª•c tr·∫∑c trong t∆∞∆°ng lai v√† n√¢ng cao hi·ªáu qu·∫£, ti·∫øt ki·ªám th·ªùi gian, ti·ªÅn b·∫°c v√† c√¥ng s·ª©c. ƒê√¢y l√† m·ªôt v√≠ d·ª• v·ªÅ ph√¢n t√≠ch theo quy ƒë·ªãnh; th∆∞·ªùng xuy√™n h∆°n kh√¥ng, m·ªôt ho·∫∑c nhi·ªÅu lo·∫°i ph√¢n t√≠ch ƒë∆∞·ª£c s·ª≠ d·ª•ng song song ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ.\nHealth Care: Early Detection of Allergic Reactions M·ªôt v√≠ d·ª• kh√°c v·ªÅ vi·ªác s·ª≠ d·ª•ng thu·∫≠t to√°n ƒë·ªÉ ph√¢n t√≠ch d·ª± ƒëo√°n nhanh ch√≥ng nh·∫±m ph√≤ng ng·ª´a ƒë·∫øn t·ª´ ng√†nh chƒÉm s√≥c s·ª©c kh·ªèe. Vi·ªán Wyss t·∫°i ƒê·∫°i h·ªçc Harvard h·ª£p t√°c v·ªõi Qu·ªπ KeepSmilin4Abbie ƒë·ªÉ ph√°t tri·ªÉn m·ªôt thi·∫øt b·ªã c√¥ng ngh·ªá c√≥ th·ªÉ ƒëeo ƒë∆∞·ª£c nh·∫±m d·ª± ƒëo√°n ph·∫£n ·ª©ng d·ªã ·ª©ng ph·∫£n v·ªá v√† t·ª± ƒë·ªông truy·ªÅn epinephrine c·ª©u s·ªëng.\nC·∫£m bi·∫øn, ƒë∆∞·ª£c g·ªçi l√† AbbieSense, ph√°t hi·ªán c√°c d·∫•u hi·ªáu sinh l√Ω s·ªõm c·ªßa s·ªëc ph·∫£n v·ªá nh∆∞ nh·ªØng y·∫øu t·ªë d·ª± b√°o ph·∫£n ·ª©ng ti·∫øp theo ‚Äî v√† n√≥ th·ª±c hi·ªán nhanh h∆°n nhi·ªÅu so v·ªõi kh·∫£ nƒÉng c·ªßa con ng∆∞·ªùi. Khi m·ªôt ph·∫£n ·ª©ng ƒë∆∞·ª£c d·ª± ƒëo√°n s·∫Ω x·∫£y ra, m·ªôt ph·∫£n ·ª©ng thu·∫≠t to√°n s·∫Ω ƒë∆∞·ª£c k√≠ch ho·∫°t. Thu·∫≠t to√°n c√≥ th·ªÉ d·ª± ƒëo√°n m·ª©c ƒë·ªô nghi√™m tr·ªçng c·ªßa ph·∫£n ·ª©ng, c·∫£nh b√°o cho c√° nh√¢n v√† ng∆∞·ªùi chƒÉm s√≥c, ƒë·ªìng th·ªùi t·ª± ƒë·ªông ti√™m epinephrine khi c·∫ßn thi·∫øt. Kh·∫£ nƒÉng d·ª± ƒëo√°n ph·∫£n ·ª©ng c·ªßa c√¥ng ngh·ªá n√†y v·ªõi t·ªëc ƒë·ªô nhanh h∆°n t·ªëc ƒë·ªô ph√°t hi·ªán th·ªß c√¥ng c√≥ th·ªÉ c·ª©u ƒë∆∞·ª£c m·∫°ng s·ªëng.\n5 Prescriptive analytics: ƒê∆∞a ra, g·ª£i √Ω business modelling m·ªõi, Data ƒë∆∞a ra l·ªùi khuy√™n ƒë·ªÉ thay ƒë·ªïi m√¥ h√¨nh kinh doanh.\nPrescriptive analytics l√† m·ªôt lo·∫°i ph√¢n t√≠ch d·ªØ li·ªáu trong lƒ©nh v·ª±c qu·∫£n l√Ω d·ª±a tr√™n d·ªØ li·ªáu (data analytics), n∆°i m·ª•c ti√™u ch√≠nh l√† cung c·∫•p c√°c h∆∞·ªõng d·∫´n v√† ƒë·ªÅ xu·∫•t v·ªÅ c√°ch th·ª±c hi·ªán m·ªôt h√†nh ƒë·ªông c·ª• th·ªÉ ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªëi ∆∞u d·ª±a tr√™n m·ªôt lo·∫°t c√°c bi·∫øn s·ªë v√† h·∫°n ch·∫ø. Kh√°i ni·ªám n√†y ƒë·∫∑t ra c√¢u h·ªèi \u0026ldquo;N√™n l√†m g√¨?\u0026rdquo; v√† ƒë∆∞a ra c√°c gi·∫£i ph√°p ho·∫∑c h∆∞·ªõng d·∫´n ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u mong mu·ªën.\nPrescriptive analytics th∆∞·ªùng bao g·ªìm c√°c b∆∞·ªõc sau:\nThu th·∫≠p d·ªØ li·ªáu: B·∫Øt ƒë·∫ßu b·∫±ng vi·ªác thu th·∫≠p v√† t·ªïng h·ª£p d·ªØ li·ªáu li√™n quan ƒë·∫øn v·∫•n ƒë·ªÅ ho·∫∑c qu√° tr√¨nh c·∫ßn ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a. ƒêi·ªÅu n√†y c√≥ th·ªÉ bao g·ªìm d·ªØ li·ªáu l·ªãch s·ª≠, d·ªØ li·ªáu hi·ªán t·∫°i v√† c√°c th√¥ng tin kh√°c li√™n quan.\nTi·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu: D·ªØ li·ªáu th∆∞·ªùng c·∫ßn ƒë∆∞·ª£c l√†m s·∫°ch, bi·∫øn ƒë·ªïi v√† chu·∫©n h√≥a tr∆∞·ªõc khi s·ª≠ d·ª•ng cho ph√¢n t√≠ch. ƒêi·ªÅu n√†y bao g·ªìm vi·ªác lo·∫°i b·ªè d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá, x·ª≠ l√Ω gi√° tr·ªã thi·∫øu v√† chu·∫©n h√≥a ƒë·ªãnh d·∫°ng.\nX√¢y d·ª±ng m√¥ h√¨nh: S·ª≠ d·ª•ng c√°c ph∆∞∆°ng ph√°p ph√¢n t√≠ch d·ªØ li·ªáu ph·ª©c t·∫°p nh∆∞ t·ªëi ∆∞u h√≥a, m√¥ h√¨nh h√≥a to√°n h·ªçc, m√¥ h√¨nh h·ªçc m√°y v√† m√¥ h√¨nh l·∫≠p k·∫ø ho·∫°ch ƒë·ªÉ t·∫°o ra c√°c k·ªãch b·∫£n v√† gi·∫£i ph√°p t·ªëi ∆∞u d·ª±a tr√™n d·ªØ li·ªáu v√† c√°c y·∫øu t·ªë h·∫°n ch·∫ø.\nƒê∆∞a ra gi·∫£i ph√°p v√† quy·∫øt ƒë·ªãnh: D·ª±a tr√™n k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh ph√¢n t√≠ch, prescriptive analytics ƒë∆∞a ra c√°c gi·∫£i ph√°p ho·∫∑c quy·∫øt ƒë·ªãnh c·ª• th·ªÉ ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u t·ªëi ∆∞u. ƒêi·ªÅu n√†y c√≥ th·ªÉ bao g·ªìm vi·ªác ƒë·ªÅ xu·∫•t k·∫ø ho·∫°ch s·∫£n xu·∫•t, qu·∫£n l√Ω t·ªìn kho, l·∫≠p l·ªãch giao h√†ng, ho·∫∑c c√°c h√†nh ƒë·ªông kinh doanh kh√°c.\nTri·ªÉn khai v√† theo d√µi: C√°c gi·∫£i ph√°p v√† quy·∫øt ƒë·ªãnh ƒë∆∞·ª£c tri·ªÉn khai trong th·ª±c t·∫ø v√† theo d√µi ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh hi·ªáu qu·∫£ v√† ƒë·ªÅ xu·∫•t ƒëi·ªÅu ch·ªânh n·∫øu c·∫ßn.\nPrescriptive analytics th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nhi·ªÅu lƒ©nh v·ª±c, nh∆∞ t√†i ch√≠nh, s·∫£n xu·∫•t, d·ª± √°n, y t·∫ø v√† qu·∫£n l√Ω chu·ªói cung ·ª©ng ƒë·ªÉ gi√∫p t·ªï ch·ª©c ra quy·∫øt ƒë·ªãnh chi·∫øn l∆∞·ª£c, t·ªëi ∆∞u h√≥a qu√° tr√¨nh kinh doanh v√† t·∫°o ra gi√° tr·ªã t·ªëi ∆∞u.\n6 V√≠ d·ª• PRESCRIPTIVE ANALYTICS trong th·ª±c t·∫ø\nVenture Capital: Investment Decisions C√°c quy·∫øt ƒë·ªãnh ƒë·∫ßu t∆∞, m·∫∑c d√π th∆∞·ªùng d·ª±a tr√™n tr·ª±c gi√°c, nh∆∞ng c√≥ th·ªÉ ƒë∆∞·ª£c c·ªßng c·ªë b·∫±ng c√°c thu·∫≠t to√°n c√¢n nh·∫Øc r·ªßi ro v√† ƒë∆∞a ra khuy·∫øn ngh·ªã c√≥ n√™n ƒë·∫ßu t∆∞ hay kh√¥ng.\nM·ªôt v√≠ d·ª• trong lƒ©nh v·ª±c ƒë·∫ßu t∆∞ m·∫°o hi·ªÉm l√† m·ªôt th·ª≠ nghi·ªám ki·ªÉm tra t√≠nh hi·ªáu qu·∫£ c·ªßa c√°c quy·∫øt ƒë·ªãnh c·ªßa thu·∫≠t to√°n v·ªÅ vi·ªác n√™n ƒë·∫ßu t∆∞ v√†o c√¥ng ty kh·ªüi nghi·ªáp n√†o so v·ªõi quy·∫øt ƒë·ªãnh c·ªßa c√°c nh√† ƒë·∫ßu t∆∞ thi√™n th·∫ßn.\nNh·ªØng ph√°t hi·ªán n√†y c√≥ nhi·ªÅu s·∫Øc th√°i. Thu·∫≠t to√°n ho·∫°t ƒë·ªông t·ªët h∆°n c√°c nh√† ƒë·∫ßu t∆∞ thi√™n th·∫ßn, nh·ªØng ng∆∞·ªùi √≠t kinh nghi·ªám ƒë·∫ßu t∆∞ h∆°n v√† k√©m k·ªπ nƒÉng h∆°n trong vi·ªác ki·ªÉm so√°t th√†nh ki·∫øn nh·∫≠n th·ª©c c·ªßa h·ªç; tuy nhi√™n, c√°c nh√† ƒë·∫ßu t∆∞ thi√™n th·∫ßn ƒë√£ v∆∞·ª£t tr·ªôi h∆°n thu·∫≠t to√°n khi h·ªç c√≥ kinh nghi·ªám ƒë·∫ßu t∆∞ v√† c√≥ th·ªÉ ki·ªÉm so√°t nh·ªØng th√†nh ki·∫øn ‚Äã‚Äãnh·∫≠n th·ª©c c·ªßa m√¨nh.\nTh·ª≠ nghi·ªám n√†y l√†m s√°ng t·ªè vai tr√≤ b·ªï sung m√† ph√¢n t√≠ch theo quy ƒë·ªãnh ph·∫£i ƒë√≥ng trong vi·ªác ƒë∆∞a ra quy·∫øt ƒë·ªãnh v√† ti·ªÅm nƒÉng c·ªßa n√≥ trong vi·ªác h·ªó tr·ª£ vi·ªác ra quy·∫øt ƒë·ªãnh khi kh√¥ng c√≥ kinh nghi·ªám v√† c·∫ßn g·∫Øn c·ªù nh·ªØng th√†nh ki·∫øn v·ªÅ nh·∫≠n th·ª©c. M·ªôt thu·∫≠t to√°n ch·ªâ kh√¥ng thi√™n v·ªã khi d·ªØ li·ªáu ƒë∆∞·ª£c ƒë√†o t·∫°o c√πng v·ªõi n√≥, do ƒë√≥ c·∫ßn c√≥ s·ª± ƒë√°nh gi√° c·ªßa con ng∆∞·ªùi cho d√π c√≥ s·ª≠ d·ª•ng thu·∫≠t to√°n hay kh√¥ng.\nSales: Lead Scoring Prescriptive analytics ƒë√≥ng m·ªôt vai tr√≤ n·ªïi b·∫≠t trong vi·ªác b√°n h√†ng th√¥ng qua vi·ªác ch·∫•m ƒëi·ªÉm kh√°ch h√†ng ti·ªÅm nƒÉng, c√≤n ƒë∆∞·ª£c g·ªçi l√† x·∫øp h·∫°ng kh√°ch h√†ng ti·ªÅm nƒÉng. Ghi ƒëi·ªÉm kh√°ch h√†ng ti·ªÅm nƒÉng l√† qu√° tr√¨nh ch·ªâ ƒë·ªãnh gi√° tr·ªã ƒëi·ªÉm cho c√°c h√†nh ƒë·ªông kh√°c nhau d·ªçc theo k√™nh b√°n h√†ng, cho ph√©p b·∫°n ho·∫∑c thu·∫≠t to√°n x·∫øp h·∫°ng kh√°ch h√†ng ti·ªÅm nƒÉng d·ª±a tr√™n kh·∫£ nƒÉng h·ªç chuy·ªÉn ƒë·ªïi th√†nh kh√°ch h√†ng.\nC√°c h√†nh ƒë·ªông b·∫°n c√≥ th·ªÉ g√°n gi√° tr·ªã bao g·ªìm:\nL∆∞·ª£t xem trang\nT∆∞∆°ng t√°c qua email\nT√¨m ki·∫øm trang web\nT∆∞∆°ng t√°c n·ªôi dung, ch·∫≥ng h·∫°n nh∆∞ tham d·ª± h·ªôi th·∫£o tr√™n web, t·∫£i xu·ªëng s√°ch ƒëi·ªán t·ª≠ ho·∫∑c xem video\nKhi g√°n cho m·ªói h√†nh ƒë·ªông m·ªôt gi√° tr·ªã ƒëi·ªÉm, h√£y ch·ªâ ƒë·ªãnh s·ªë ƒëi·ªÉm cao nh·∫•t cho nh·ªØng h√†nh ƒë·ªông ng·ª• √Ω √Ω ƒë·ªãnh mua h√†ng (v√≠ d·ª•: truy c·∫≠p trang s·∫£n ph·∫©m) v√† ƒëi·ªÉm ti√™u c·ª±c cho nh·ªØng h√†nh ƒë·ªông ti·∫øt l·ªô √Ω ƒë·ªãnh kh√¥ng mua h√†ng (v√≠ d·ª•: xem tin tuy·ªÉn d·ª•ng tr√™n trang web c·ªßa b·∫°n ). ƒêi·ªÅu n√†y c√≥ th·ªÉ gi√∫p ∆∞u ti√™n ti·∫øp c·∫≠n nh·ªØng kh√°ch h√†ng ti·ªÅm nƒÉng c√≥ nhi·ªÅu kh·∫£ nƒÉng chuy·ªÉn ƒë·ªïi th√†nh kh√°ch h√†ng nh·∫•t, c√≥ kh·∫£ nƒÉng ti·∫øt ki·ªám th·ªùi gian v√† ti·ªÅn b·∫°c cho t·ªï ch·ª©c c·ªßa b·∫°n.\nContent Curation: Algorithmic Recommendations N·∫øu b·∫°n ƒë√£ t·ª´ng s·ª≠ d·ª•ng m·ªôt m·∫°ng x√£ h·ªôi ho·∫∑c ·ª©ng d·ª•ng h·∫πn h√≤, b·∫°n c√≥ th·ªÉ ƒë√£ tr·ª±c ti·∫øp tr·∫£i nghi·ªám c√°c Prescriptive analytics th√¥ng qua c√°c ƒë·ªÅ xu·∫•t n·ªôi dung thu·∫≠t to√°n.\nThu·∫≠t to√°n c·ªßa doanh nghi·ªáp thu th·∫≠p d·ªØ li·ªáu d·ª±a tr√™n l·ªãch s·ª≠ t∆∞∆°ng t√°c c·ªßa b·∫°n tr√™n n·ªÅn t·∫£ng c·ªßa h·ªç (v√† c√≥ th·ªÉ c·∫£ nh·ªØng n·ªÅn t·∫£ng kh√°c). S·ª± k·∫øt h·ª£p c√°c h√†nh vi tr∆∞·ªõc ƒë√¢y c·ªßa b·∫°n c√≥ th·ªÉ ƒë√≥ng vai tr√≤ l√† t√°c nh√¢n k√≠ch ho·∫°t thu·∫≠t to√°n ƒë∆∞a ra ƒë·ªÅ xu·∫•t c·ª• th·ªÉ. V√≠ d·ª•: n·∫øu b·∫°n th∆∞·ªùng xuy√™n xem video ƒë√°nh gi√° gi√†y tr√™n YouTube, thu·∫≠t to√°n c·ªßa n·ªÅn t·∫£ng c√≥ th·ªÉ s·∫Ω ph√¢n t√≠ch d·ªØ li·ªáu ƒë√≥ v√† khuy√™n b·∫°n n√™n xem nhi·ªÅu h∆°n c√πng lo·∫°i video ho·∫∑c n·ªôi dung t∆∞∆°ng t·ª± m√† b·∫°n c√≥ th·ªÉ th·∫•y th√∫ v·ªã.\nTr√™n m·∫°ng x√£ h·ªôi, ngu·ªìn c·∫•p d·ªØ li·ªáu ‚ÄúD√†nh cho b·∫°n‚Äù c·ªßa TikTok l√† m·ªôt v√≠ d·ª• v·ªÅ ho·∫°t ƒë·ªông ph√¢n t√≠ch theo quy ƒë·ªãnh. Trang web c·ªßa c√¥ng ty gi·∫£i th√≠ch r·∫±ng c√°c t∆∞∆°ng t√°c c·ªßa ng∆∞·ªùi d√πng tr√™n ·ª©ng d·ª•ng, gi·ªëng nh∆∞ vi·ªác ghi ƒëi·ªÉm trong doanh s·ªë b√°n h√†ng, ƒë∆∞·ª£c t√≠nh tr·ªçng s·ªë d·ª±a tr√™n d·∫•u hi·ªáu quan t√¢m.\n‚ÄúV√≠ d·ª•‚Äù, trang web c·ªßa TikTok cho bi·∫øt, ‚Äún·∫øu b·∫°n xem h·∫øt m·ªôt video, ƒë√≥ l√† d·∫•u hi·ªáu m·∫°nh m·∫Ω cho th·∫•y b·∫°n quan t√¢m. Sau ƒë√≥, c√°c video ƒë∆∞·ª£c x·∫øp h·∫°ng ƒë·ªÉ x√°c ƒë·ªãnh kh·∫£ nƒÉng b·∫°n quan t√¢m ƒë·∫øn t·ª´ng video v√† ƒë∆∞·ª£c g·ª≠i t·ªõi t·ª´ng ngu·ªìn c·∫•p d·ªØ li·ªáu \u0026lsquo;D√†nh cho b·∫°n\u0026rsquo; duy nh·∫•t.‚Äù\nTr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng ph√¢n t√≠ch theo quy ƒë·ªãnh n√†y c√≥ th·ªÉ gi√∫p t·ª∑ l·ªá t∆∞∆°ng t√°c c·ªßa kh√°ch h√†ng cao h∆°n, m·ª©c ƒë·ªô h√†i l√≤ng c·ªßa kh√°ch h√†ng tƒÉng l√™n v√† kh·∫£ nƒÉng nh·∫Øm m·ª•c ti√™u l·∫°i kh√°ch h√†ng b·∫±ng qu·∫£ng c√°o d·ª±a tr√™n l·ªãch s·ª≠ h√†nh vi c·ªßa h·ªç.\nBanking: Fraud Detection B√†i to√°n prescriptive analytics ·ªü ƒë√¢y l√† ph√°t hi·ªán v√† g·∫Øng nh√£n gian l·∫≠n ng√¢n h√†ng.\nV·ªõi kh·ªëi l∆∞·ª£ng d·ªØ li·ªáu kh·ªïng l·ªì ƒë∆∞·ª£c l∆∞u tr·ªØ trong h·ªá th·ªëng c·ªßa ng√¢n h√†ng, m·ªôt ng∆∞·ªùi g·∫ßn nh∆∞ kh√¥ng th·ªÉ ph√°t hi·ªán th·ªß c√¥ng b·∫•t k·ª≥ ho·∫°t ƒë·ªông ƒë√°ng ng·ªù n√†o trong m·ªôt t√†i kho·∫£n. M·ªôt thu·∫≠t to√°n‚Äîƒë∆∞·ª£c ƒë√†o t·∫°o b·∫±ng c√°ch s·ª≠ d·ª•ng d·ªØ li·ªáu giao d·ªãch l·ªãch s·ª≠ c·ªßa kh√°ch h√†ng‚Äîph√¢n t√≠ch v√† qu√©t d·ªØ li·ªáu giao d·ªãch m·ªõi ƒë·ªÉ t√¨m nh·ªØng ƒëi·ªÉm b·∫•t th∆∞·ªùng. V√≠ d·ª•: c√≥ l·∫Ω b·∫°n th∆∞·ªùng chi 3.000 ƒë√¥ la m·ªói th√°ng, nh∆∞ng th√°ng n√†y, th·∫ª t√≠n d·ª•ng c·ªßa b·∫°n b·ªã t√≠nh ph√≠ 30.000 ƒë√¥ la.\nThu·∫≠t to√°n ph√¢n t√≠ch c√°c m·∫´u trong d·ªØ li·ªáu giao d·ªãch c·ªßa b·∫°n, c·∫£nh b√°o ng√¢n h√†ng v√† ƒë∆∞a ra h∆∞·ªõng h√†nh ƒë·ªông ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t. Trong v√≠ d·ª• n√†y, h√†nh ƒë·ªông c√≥ th·ªÉ l√† h·ªßy th·∫ª t√≠n d·ª•ng v√¨ n√≥ c√≥ th·ªÉ ƒë√£ b·ªã ƒë√°nh c·∫Øp.\nProduct Management: Development and Improvement Prescriptive analytics c≈©ng c√≥ th·ªÉ cung c·∫•p th√¥ng tin cho vi·ªác ph√°t tri·ªÉn v√† c·∫£i ti·∫øn s·∫£n ph·∫©m. Ng∆∞·ªùi qu·∫£n l√Ω s·∫£n ph·∫©m c√≥ th·ªÉ thu th·∫≠p d·ªØ li·ªáu ng∆∞·ªùi d√πng b·∫±ng c√°ch kh·∫£o s√°t kh√°ch h√†ng, ch·∫°y th·ª≠ nghi·ªám phi√™n b·∫£n beta c·ªßa s·∫£n ph·∫©m, ti·∫øn h√†nh nghi√™n c·ª©u th·ªã tr∆∞·ªùng v·ªõi nh·ªØng ng∆∞·ªùi hi·ªán kh√¥ng ph·∫£i l√† ng∆∞·ªùi d√πng s·∫£n ph·∫©m v√† thu th·∫≠p d·ªØ li·ªáu h√†nh vi khi ng∆∞·ªùi d√πng hi·ªán t·∫°i t∆∞∆°ng t√°c. T·∫•t c·∫£ d·ªØ li·ªáu n√†y c√≥ th·ªÉ ƒë∆∞·ª£c ph√¢n t√≠ch‚Äîtheo c√°ch th·ªß c√¥ng ho·∫∑c b·∫±ng thu·∫≠t to√°n‚Äîƒë·ªÉ x√°c ƒë·ªãnh xu h∆∞·ªõng, kh√°m ph√° l√Ω do c·ªßa nh·ªØng xu h∆∞·ªõng ƒë√≥ v√† d·ª± ƒëo√°n li·ªáu c√°c xu h∆∞·ªõng ƒë∆∞·ª£c d·ª± ƒëo√°n c√≥ t√°i di·ªÖn hay kh√¥ng.\nPh√¢n t√≠ch theo quy ƒë·ªãnh c√≥ th·ªÉ gi√∫p x√°c ƒë·ªãnh nh·ªØng t√≠nh nƒÉng n√†o n√™n ƒë∆∞a v√†o ho·∫∑c lo·∫°i b·ªè kh·ªèi s·∫£n ph·∫©m v√† nh·ªØng t√≠nh nƒÉng n√†o c·∫ßn thay ƒë·ªïi ƒë·ªÉ ƒë·∫£m b·∫£o tr·∫£i nghi·ªám ng∆∞·ªùi d√πng t·ªëi ∆∞u.\nMarketing: Email Automation T·ª± ƒë·ªông h√≥a email l√† m·ªôt v√≠ d·ª• r√µ r√†ng v·ªÅ ph√¢n t√≠ch theo quy ƒë·ªãnh t·∫°i n∆°i l√†m vi·ªác. C√°c nh√† ti·∫øp th·ªã s·ª≠ d·ª•ng t√≠nh nƒÉng t·ª± ƒë·ªông h√≥a email ƒë·ªÉ s·∫Øp x·∫øp kh√°ch h√†ng ti·ªÅm nƒÉng th√†nh c√°c danh m·ª•c d·ª±a tr√™n ƒë·ªông l·ª±c, suy nghƒ© v√† √Ω ƒë·ªãnh c·ªßa h·ªç, ƒë·ªìng th·ªùi g·ª≠i n·ªôi dung email cho h·ªç d·ª±a tr√™n c√°c danh m·ª•c ƒë√≥. M·ªçi t∆∞∆°ng t√°c c·ªßa kh√°ch h√†ng ti·ªÅm nƒÉng v·ªõi email ƒë·ªÅu c√≥ th·ªÉ x·∫øp h·ªç v√†o danh m·ª•c kh√°c, d·∫´n ƒë·∫øn k√≠ch ho·∫°t m·ªôt nh√≥m th√¥ng b√°o kh√°c.\nM·∫∑c d√π ƒë√¢y ch·ªâ l√† ph√¢n t√≠ch quy ƒë·ªãnh theo thu·∫≠t to√°n thu·∫ßn t√∫y, nh∆∞ng m·ªôt ng∆∞·ªùi n√™n l·∫≠p k·∫ø ho·∫°ch, t·∫°o v√† gi√°m s√°t c√°c lu·ªìng t·ª± ƒë·ªông h√≥a. T·ª± ƒë·ªông h√≥a email cho ph√©p c√°c c√¥ng ty cung c·∫•p tin nh·∫Øn ƒë∆∞·ª£c c√° nh√¢n h√≥a tr√™n quy m√¥ l·ªõn v√† tƒÉng c∆° h·ªôi chuy·ªÉn ƒë·ªïi kh√°ch h√†ng ti·ªÅm nƒÉng th√†nh kh√°ch h√†ng b·∫±ng c√°ch s·ª≠ d·ª•ng n·ªôi dung ph√π h·ª£p v·ªõi ƒë·ªông c∆° v√† nhu c·∫ßu c·ªßa h·ªç.\nII. S√°u b∆∞·ªõc c∆° b·∫£n b·∫Øt ƒë·∫ßu m·ªôt d·ª± √°n Data Analytics B∆∞·ªõc 0 : Prepair - Chu·∫©n b·ªã Ki·∫øn th·ª©c ng√†nh\nS·∫£n ph·∫©m nh∆∞ th·∫ø n√†o\nKh√°ch h√†ng l√† ai (who)\nKh√°i ni·ªám ƒë·∫∑c th√π\nB∆∞·ªõc 1: Define analytics requirement - T√¨m ra c√°c c√¢u h·ªèi c·∫ßn tr·∫£ l·ªùi C√¢u h·ªèi ƒë∆∞·ª£c ƒë∆∞a ra t·ª´ c√°c b·ªô ph·∫≠n trong c√¥ng ty\nC√¢u h·ªèi ƒë∆∞·ª£c ƒë∆∞a ra t·ª´ ch√≠nh b·∫°n trong qu√° tr√¨nh c√°c b·∫°n l√†m vi·ªác trong c√¥ng ty\nB∆∞·ªõc 2: Collecting data N·∫Øm r√µ d·ªØ li·ªáu m√¨nh ƒëang c√≥\nN·∫Øm r√µ data m√¨nh c√≥ th·ªÉ l·∫•y ƒë∆∞·ª£c t·ª´\nData Engineer\nData analytics lead\nData sciencetist\nT·ª´ nh·ªØng ng∆∞·ªùi c√≥ ki·∫øn th·ª©c li√™n quan t·ªõi data m√¨nh c·∫ßn thu th·∫≠p\nB∆∞·ªõc 3: Clearning data X·ª≠ l√Ω d·ªØ li·ªáu r·ªóng\nX·ª≠ l√Ω outliers\nX·ª≠ l√Ω gi√° tr·ªã sai l·ªách\nƒê∆∞a c√°c gi√° tr·ªã s·ªë v·ªÅ c√πng 1 range khi c√≥ s·ª± ch√™nh l·ªách qu√° l·ªõn\nB∆∞·ªõc 4: Analyzing data S·ª≠ d·ª•ng c√°c m√¥ h√¨nh\nSegmentation -\u0026gt; clustering\nPredict prices -\u0026gt; time series\nKh√°ch h√†ng ti·ªÅm ·∫©n -\u0026gt; classification\nƒê√°nh gi√° campain -\u0026gt; A/B testing\nB∆∞·ªõc 5: Presenting Report T·∫°o c√°c Reporting cho ban gi√°m ƒë·ªëc v√† c√°c ƒë·ªëi t∆∞·ª£ng li√™n quan\nThu nh·∫≠n c√°c g√≥p √Ω\nQuay l·∫°i b∆∞·ªõc 0 ƒë·ªÉ ch·ªânh s·ª≠a\nIII. C√°c b√†i to√°n th√¥ng d·ª•ng nh·∫•t c·ªßa DA C√≥ 3 b√†i to√†n th√¥ng d·ª•ng nh·∫•t, m√¨nh ch·ªâ li·ªát k√™ t√≥m t·∫Øt, do m·ªói m·ª•c l√† m·ªôt ch·ªß ƒë·ªÅ si√™u to kh·ªïng l·ªì v√† c√≥ th·ªÉ ƒë∆∞·ª£c ti·∫øp t·ª•c tr√¨nh b√†y ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\nƒêo l∆∞·ªùng t√°c ƒë·ªông c·ªßa thay ƒë·ªïi so v·ªõi hi·ªán t·∫°i ( Quan tr·ªçng nh·∫•t) S·ª± thay ƒë·ªïi v·ªÅ s·∫£n ph·∫©m\nS·ª± thay ƒë·ªïi v·ªÅ s√°ng ki·∫øn\nS·ª≠ d·ª•ng A/B testing\nA l·∫•y 1 t·∫≠p nh·ªè ƒë·ªÉ c·∫£i ti·∫øn, g·ªçi l√† A\nB l√† ph·∫ßn c≈©, l√∫c ch∆∞a thay ƒë·ªïi\nD·ª± b√°o ( Quan tr·ªçng) S·ª≠ d·ª•ng trong t√†i ch√≠nh, marketing\nD·ª± b√°o doanh thu c·ªßa qu√Ω\nD·ª± b√°o doanh thu c·ªßa nƒÉm\nD·ª± ƒëo√°n gi√° c·ªï phi·∫øu , gi√° v√†ng, s·ª©c mua \u0026hellip;.\nS·ª≠ d·ª•ng m√¥ h√¨nh time series\nPh√¢n t√≠ch kh√°ch h√†ng Nh·∫≠n d·∫°ng kh√°ch h√†ng ( Quan tr·ªçng nh·∫•t) Customer segmentation\nCustomer profiling\nS·ª≠ d·ª•ng thu·∫≠t to√°n clustering\nS·ª≠ d·ª•ng m√¥ h√¨nh RFM\nC√°c b·∫°n c√≥ th·ªÉ xem v√≠ d·ª• trong b√†i vi·∫øt n√†y c·ªßa m√¨nh v·ªÅ m√¥ h√¨nh RFM\nhttps://www.phamduytung.com/blog/2022-12-03-marketing-with-python/\nCross selling T√¨m kh√°ch h√†ng ti·ªÅm nƒÉng s·∫Ω mua h√†ng\nCustomer propensity model\nS·ª≠ d·ª•ng logistic regression\nCustomer journey Ph√¢n t√≠ch ph·ªÖu kh√°ch h√†ng\nt√¨m hi·ªÉu l·ªô tr√¨nh c·ªßa kh√°ch h√†ng\nFunnel analysis\nBasket analytics Ph√¢n t√≠ch gi·ªè h√†ng\nM·ªôt kh√°ch h√†ng s·∫Ω nhi·ªÅu kh·∫£ nƒÉng mua m·ªôt lo·∫°i h√†ng n√†o ti·∫øp theo th√¨ s·ª≠ d·ª•ng Basket analytics\nLu·∫≠t k·∫øt h·ª£p\nƒêo l∆∞·ªùng th·ªùi h·∫°n t√°c ƒë·ªông c·ªßa m·ªôt c·∫£i ti·∫øn / sale Survival analytics\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\nT√†i li·ªáu tham kh·∫£o\nhttps://online.hbs.edu/blog/post/descriptive-analytics\nhttps://online.hbs.edu/blog/post/diagnostic-analytics\nKho√° h·ªçc n√™n h·ªçc\nhttps://www.coursera.org/specializations/statistical-inference-for-data-science-applications\n","date":"Jul 29, 2023","img":"https://unsplash.it/1920/1080?image=6","permalink":"/blog/2023-09-02-data-analytics-step-by-step/","series":null,"tags":["Data Analytics"],"title":"Data Analytics  - Ngh·ªÅ M·ªõi Th·ªùi Th∆∞·ª£ng"},{"categories":null,"content":" I. ƒê·∫∑t v·∫•n ƒë·ªÅ II. C√°ch th·ª©c th·ª±c hi·ªán III. C√°ch ti·∫øp c·∫≠n Store Capacity Clustering Store Attribute Clustering Category Sales Clustering Productivity-based Clustering Price-based Clustering Multi-dimensional clustering IV. M·ªôt s·ªë v√≠ d·ª• th·ª±c ti·ªÖn T·ª± thi·∫øt l·∫≠p ph√¢n kh√∫c gi√°. L·∫≠p k·∫ø ho·∫°ch ph√°t t·ªù r∆°i qu·∫£ng c√°o B√†i to√°n t√†i x·∫ø giao h√†ng grab B√†i vi·∫øt n√†y l√† g√≥c nh√¨n c·ªßa m·ªôt √¥ng IT ƒëang t·∫≠p t√†nh Data Driven Development, vi·∫øt note l·∫°i ch∆°i ch∆°i d·ª±a v√†o c√°c t√†i li·ªáu ƒë·ªçc ƒë∆∞·ª£c v√†o t·ª´ kho√° store clustering retail, vi·∫øt b·∫≠y vi·∫øt b·∫°, c√°c b·∫°n c√≥ √Ω t∆∞·ªüng hay ho c√≥ th·ªÉ g√≥p √Ω gi√∫p m√¨nh c√≥ th√™m nhi·ªÅu g√≥c nh√¨n h∆°n nha.\nI. ƒê·∫∑t v·∫•n ƒë·ªÅ Trong m√¥ h√¨nh kinh doanh b√°n l·∫ª, c√≥ hai m√¥ h√¨nh d·∫°ng chu·ªói c·ª≠a h√†ng kh√°c nhau, m·ªói m√¥ h√¨nh ƒë·ªÅu c√≥ ∆∞u v√† nh∆∞·ª£c ƒëi·ªÉm ri√™ng:\nD·∫°ng chu·ªói m√† t·∫•t c·∫£ c√°c c·ª≠a h√†ng gi·ªëng h·ªát nhau ( v√≠ d·ª• Starbucks), d·∫°ng chu·ªói n√†y th√¨ vi·ªác v·∫≠n h√†nh ƒë∆°n gi·∫£n, theo quy tr√¨nh c√≥ s·∫µn, ƒë·ªìng nh·∫•t, nh·∫•t qu√°n, mang l·∫°i tr·∫£i nghi·ªám xuy√™n su·ªët v·ªõi kh√°ch h√†ng. H·∫ßu nh∆∞ l√† qu·∫£n l√Ω kh√° nh√†n.\nD·∫°ng chu·ªói th·ª© 2, c√°c Qu·∫£n l√Ω ƒë∆∞·ª£c xem nh∆∞ l√† √¥ng ch·ªß nh·ªè c·ªßa c·ª≠a h√†ng, c√≥ quy·ªÅn t·ª± quy·∫øt trong vi·ªác ph√¢n lo·∫°i, ƒë·ªãnh gi√°, v√† khuy·∫øn m√£i. V√≠ d·ª•: c√°c nh√† b√°n l·∫ª nh∆∞ T·∫≠p ƒëo√†n Aeon , ICA, Metro, ho·∫∑c b√°ch ho√° xanh c·ªßa Vi·ªát Nam trao kh√° nhi·ªÅu quy·ªÅn ki·ªÉm so√°t cho c√°c qu·∫£n l√Ω c·ª≠a h√†ng.\nD√π m√¥ h√¨nh kinh doanh l√† d·∫°ng 1 hay d·∫°ng 2, th√¨ vi·ªác nh√≥m c√°c si√™u th·ªã c√≥ t√≠nh ch·∫•t t∆∞∆°ng ƒë·ªìng th√†nh c√°c nh√≥m ƒë·ªìng nh·∫•t v·ªõi nhau v·ªÅ c√°c kh√≠a c·∫°nh n√†o ƒë√≥ ( trong machine learning g·ªçi l√† gom c·ª•m), c≈©ng gi√∫p cho ng∆∞·ªùi ƒëi·ªÅu h√†nh c√≥ th·ªÉ scale ƒë∆∞·ª£c c√°c chi·∫øn l∆∞·ª£c marketing, s·ª≠ d·ª•ng c√°ch ti·∫øp c·∫≠n cookie-cutter (( t·ª´ kho√° cookie cutter approach in business) ƒë·∫°i lo·∫°i l√† n·∫øu 1 m√¥ h√¨nh marketing th√†nh c√¥ng cho c·ª≠a h√†ng A, th√¨ c≈©ng c√≥ th·ªÉ scale out v√† th√†nh c√¥ng ·ªü c√°c c·ª≠a h√†ng A1.. An c√≥ c√πng c·ª•m v·ªõi c·ª≠a h√†ng A.) , c√°ch ti·∫øp c·∫≠n n√†y c≈©ng c√≥ th·ªÉ √°p d·ª•ng v·ªõi m√¥ h√¨nh kinh doanh nh∆∞·ª£ng quy·ªÅn (franchisee).\nII. C√°ch th·ª©c th·ª±c hi·ªán Kh√°i ni·ªám ph√¢n lo·∫°i c·ª≠a h√†ng kh√¥ng m·ªõi, nh∆∞ng c√≥ r·∫•t √≠t nh√† b√°n l·∫ª ·ªü c√°c th·ªã tr∆∞·ªùng nh·ªè s·ª≠ d·ª•ng c√°c ph∆∞∆°ng th·ª©c khoa h·ªçc ƒë·ªÉ t·∫°o m√¥ h√¨nh. V√† r·∫•t r·∫•t √≠t nh√† b√°n l·∫ª h·ªá th·ªëng ho√° quy tr√¨nh ph√¢n lo·∫°i | gom c·ª•m, c√≥ th·ªÉ l√† l√Ω do t√†i ch√≠nh kh√¥ng cho ph√©p, ho·∫∑c vi·ªác thu√™ ƒë∆°n v·ªã t∆∞ v·∫•n ƒë·ªôc l·∫≠p kh√° t·ªën k√©m. M√¥ h√¨nh m√¨nh ƒë·ªÅ c·∫≠p t·ªõi ·ªü ƒë√¢y l√†: Data Science l·∫≠p ph√¢n t√≠ch, Business ki·ªÉm ch·ª©ng, v√† c·∫ßn c√≥ s·ª± th√¥ng su·ªët v·ªÅ m·∫∑t data gi·ªØa Data Science v√† Business.\nC√°c y·∫øu t·ªë tham chi·∫øu ch√≠nh:\n% b√°n h√†ng tr√™n deal v·ªõi nh√† cung c·∫•p\n% t·ª∑ l·ªá b√°n h√†ng h·ªón h·ª£p h·ª£p(category mix) \u0026hellip;\nC√°c y·∫øu t·ªë tham chi·∫øu b·ªï sung b√™n c·∫°nh ƒë√≥:\nS·ª± hi·ªán di·ªán c·ªßa ƒë·ªëi th·ªß\nV·ªã tr√≠ ƒë·ªãa l√Ω\nNh√¢n kh·∫©u h·ªçc \u0026hellip;\n·ªû ƒë√¢y, m√¨nh ch·ªâ li·ªát k√™ m·ªôt v√†i y·∫øu t·ªë, m·ªôt v√†i y·∫øu t·ªë chi ti·∫øt ƒë∆∞·ª£c li·ªát k√™ ·ªü ph·∫ßn ti·∫øp theo.\nC√°c y·∫øu t·ªë tham chi·∫øu b·ªï sung s·∫Ω gi√∫p ch√∫ng ta ph√¢n bi·ªát c√°c c·ª•m r√µ r√†ng h∆°n v√† nh√¨n th·∫•y s·ª± kh√°c nhau gi·ªØa c√°c c·ª•m ƒë√≥.\ntheo solvoyo.com, ng√†y nay, ng∆∞·ªùi ta th∆∞·ªùng ph√¢n lo·∫°i theo category level thay v√¨ store level. Category level m·∫°ng l·∫°i s·ª± ch√≠nh x√°c cao h∆°n, nh∆∞ng khi th·ª±c hi·ªán l·∫°i ph·ª©c t·∫°p h∆°n\nSau ƒë√≥, ch√∫ng ta s·∫Ω x√¢y d·ª±ng model d·ª±a tr√™n c√°c y·∫øu t·ªë tr√™n, v√† ki·ªÉm ch·ª©ng model. C√≥ m·ªôt v√†i m√¥ h√¨nh clustering trong machine learning c√°c b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng nh∆∞ KNN, SVC, DBScan, kmean \u0026hellip;\nTh√¥ng qua vi·ªác s·ª≠ d·ª•ng ph√¢n c·ª•m, c√°c nh√† b√°n l·∫ª c√≥ th·ªÉ s·ªë ho√° nhu c·∫ßu c·ªßa t·ª´ng khu v·ª±c v√† ƒë·ªÅ ra nh·ªØng ph∆∞∆°ng √°n v·∫≠n h√†nh (m·ªõi) hi·ªáu qu·∫£ h∆°n (t·∫•t nhi√™n, ƒë√¢y m·ªõi ch·ªâ l√† ph·∫ßn l√Ω thuy·∫øt, c·∫ßn th·ª≠ nghi·ªám ƒë·ªÉ ch·ª©ng minh t√≠nh ƒë√∫ng ƒë·∫Øn xem r·∫±ng c√°c c·ª•m ch√∫ng ta ƒë·ªÅ xu·∫•t c√≥ th·∫≠t s·ª± li√™n quan m·∫°nh v·ªõi nhau hay kh√¥ng, hay c√≤n y·∫øu t·ªë ·∫©n quan tr·ªçng n√†o ƒë√≥ m√† ch√∫ng ta ƒë√£ b·ªè l·ª° trong qu√° tr√¨nh thu th·∫≠p d·ªØ li·ªáu).\nV√≠ d·ª•: m·ªôt chu·ªói c·ª≠a h√†ng ti·ªán l·ª£i c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh c√°ch ti·∫øp c·∫≠n kh√°ch h√†ng b·∫±ng c√°ch b√°n h√†ng theo gi·ªè h√†ng, chia th√†nh g√≥i gi·ªè h√†ng bu·ªïi s√°ng, gi·ªè h√†ng bu·ªïi tr∆∞a, gi·ªè h√†ng bu·ªïi t·ªëi, ph√π h·ª£p v·ªõi m·ª•c ti√™u mua s·∫Øm v√† v·ªã tr√≠ c·ªßa kh√°ch h√†ng.\nV√≠ d·ª• kh√°c: C·ª≠a h√†ng c√† ph√™ m·ªõi, c·ª≠a h√†ng b√°nh ng·ªçt m·ªõi, c·ª≠a h√†ng ph·ªü m·ªõi, ·ªü g·∫ßn v·ªã tr√≠ ƒë·ªãa l√Ω, k√≠ch th∆∞·ªõc g·∫ßn gi·ªëng nhau, nh∆∞ng tri·ªÉn v·ªçng ph√°t tri·ªÉn c√≥ th·ªÉ s·∫Ω kh√°c nhau, do tri·ªÉn v·ªçng ph√°t tri·ªÉn c·ªßa th·ª±c ph·∫©m mang ƒëi kh√°c ho√†n to√†n v·ªõi th·ª±c ph·∫©m ƒÉn t·∫°i ch·ªó.\nVi·ªác ph√¢n c·ª•m c·ª≠a h√†ng l√† b∆∞·ªõc ƒë·∫ßu gi√∫p cho c√°c nh√† qu·∫£n l√Ω c√≥ m·ªôt b·ª©c tranh ∆∞·ªõm ch·ª´ng khi ƒë∆∞a ra quy·∫øt ƒë·ªãnh, v√† gi√∫p h·ªç ƒë∆∞a ra k·∫øt lu·∫≠n m·ªôt c√°ch ƒë·ªãnh l∆∞·ª£ng h∆°n.\nIII. C√°ch ti·∫øp c·∫≠n Store Capacity Clustering Net selling space ( ƒëo l∆∞·ª£ng tr√™n ƒë∆°n v·ªã m√©t vu√¥ng)\nShelf capacity ( ƒëo l∆∞·ª£ng tr√™n ƒë∆°n v·ªã s·ªë l∆∞·ª£ng s·∫£n ph·∫©m / ƒë∆°n v·ªã chu·∫©n (k·ªá))\nOption capacity ( s·ªë l∆∞·ª£ng sku tr√™n m·ªói c·ª≠a h√†ng c√≥ th·ªÉ ƒë∆∞·ª£c tr∆∞ng b√†y t·∫°i 1 th·ªùi ƒëi·ªÉm)\nUnit capacity ( S·ªë l∆∞·ª£ng s·∫£n ph·∫©m c√≥ th·ªÉ tr∆∞ng b√†y t·∫°i 1 th·ªùi ƒëi·ªÉm)\nStore Attribute Clustering L∆∞·ª£t kh√°ch trung b√¨nh c·ªßa c·ª≠a h√†ng\nV·ªã tr√≠ ( ƒë·ªô th·ªã, n√¥ng th√¥n, khu c√¥ng nghi·ªáp, khu ch·∫ø xu·∫•t, khu x√¢y d·ª±ng m·ªõi)\nIncome profiles\nCultural profiles ( x√©t tr√™n kh√°ch h√†ng trung th√†nh, v√≠ d·ª• nh∆∞ d√¢n t·ªôc)\nMall type ( ƒë·∫°i si√™u th·ªã, c·ª≠a h√†ng nh·ªè)\n\u0026hellip;\nCategory Sales Clustering Weekly unit sales\nWeekly revenue\nInventory turn (d·ª±a tr√™n y·∫øu t·ªë bao l√¢u h√†ng v·ªÅ m·ªôt l·∫ßn)\nProductivity-based Clustering Revenue per square meter (or sq. foot)\nGM per square meter\nUnit sales per product (option, or SKU)\nPrice-based Clustering Average unit retail\nPrice profile performance (d·ª±a tr√™n s·ª± ƒë√≥ng g√≥p c·ªßa doanh s·ªë b√°n h√†ng t·ª´ c√°c ph√¢n kh√∫c gi√° kh√°c nhau nh∆∞ cao, trung b√¨nh, th·∫•p ho·∫∑c d·ª±a tr√™n s·ª± ƒë√≥ng g√≥p c·ªßa doanh s·ªë gi·∫£m gi√° v√† b√°n h√†ng nguy√™n gi√°)\nPrice elasticity (d·ª±a tr√™n s·ª± thay ƒë·ªïi v·ªÅ nhu c·∫ßu ƒë·ªÉ ƒë√°p ·ª©ng v·ªõi nh·ªØng thay ƒë·ªïi v·ªÅ gi√°, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c h·ªá th·ªëng l·∫≠p k·∫ø ho·∫°ch khuy·∫øn m√£i v√† t·ªëi ∆∞u h√≥a gi·∫£m gi√°)\nMulti-dimensional clustering ƒê√¢y l√† ph∆∞∆°ng ph√°p nh√≥m c√°c c·ª≠a h√†ng d·ª±a tr√™n c√°c metric v√† c√°c attributes ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p ·ªü ph√≠a tr√™n.\nV√≠ d·ª•, v·ªõi m·ªói category c·ªßa c·ª≠a h√†ng, c√≥ th·ªÉ ƒë∆∞·ª£c ph√¢n c·ª•m d·ª±a v√†o sale performance, capacity, price performance\nIV. M·ªôt s·ªë v√≠ d·ª• th·ª±c ti·ªÖn T·ª± thi·∫øt l·∫≠p ph√¢n kh√∫c gi√°. C√°c n∆°i c√≥ t·ª∑ l·ªá kh√°ch h√†ng mua m·ªôt l·∫ßn cao th∆∞·ªùng s·∫Ω thi·∫øt l·∫≠p m·ªôt m·ª©c gi√° cao h∆°n nh·ªØng n∆°i c√≥ t·ª∑ l·ªá kh√°ch h√†ng trung th√†nh cao. V√≠ d·ª•:\nC√°c website h√£ng\nS·∫£n ph·∫©m ƒë∆∞·ª£c b√°n ·ªü s√¢n bay so v·ªõi b√°n ·ªü c√°c c·ª≠a h√†ng xung quanh n∆°i b·∫°n sinh s·ªëng.\nT·∫•t nhi√™n, s·∫Ω c√≥ nhi·ªÅu b·∫°n s·∫Ω c·∫£i l·∫°i r·∫±ng gi√° ·ªü s√¢n bay cao do c√°c chi ph√≠ thu√™ nh√¢n vi√™n, chi ph√≠ m·∫∑t b·∫±ng, chi ph√≠ t·ª´ abc ƒë·∫øn xyz cao \u0026hellip;\nVi·ªác ph√¢n c·ª•m, ƒë·ªãnh danh c√°c nh√≥m c·ª≠a h√†ng c√≥ ƒë·∫∑c ƒëi·ªÉm ri√™ng bi·ªát nh∆∞ tr√™n, v√≠ d·ª• nh∆∞ c·ª≠a h√†ng li·ªÅn k·ªÅ khu du l·ªãch, s·∫Ω gi√∫p c√°c b·∫°n c√≥ g√≥c nh√¨n khoa h·ªçc h∆°n v√†o quy ho·∫°ch ph√¢n v√πng gi√° ho·∫∑c quy tr√¨nh b√°n h√†ng.\nL·∫≠p k·∫ø ho·∫°ch ph√°t t·ªù r∆°i qu·∫£ng c√°o T·ªëi ∆∞u ho√° chi ph√≠ in ·∫•n\nƒêa d·∫°ng ho√° t·ªù r∆°i\nD·ª± ƒëo√°n ƒë∆∞·ª£c t·ª∑ l·ªá mua h√†ng , ƒë·ªÅ ra chi·∫øn l∆∞·ª£c mua b√°n h·ª£p l√Ω h∆°n.\nB√†i to√°n t√†i x·∫ø giao h√†ng grab Trong b·∫•t k·ª≥ s·ª± thay ƒë·ªïi n√†o v·ªÅ m·∫∑t v·∫≠n h√†nh v√† qu·∫£n l√Ω, ch√∫ng ta n√™n ƒëo l∆∞·ªùng s·ª± tƒÉng tr∆∞·ªüng v√† ki·ªÉm ƒë·ªãnh l·∫°i ƒë·ªÉ ch·ª©ng minh gi√° tr·ªã thay ƒë·ªïi l√† ƒë√∫ng ƒë·∫Øn v√† h·ªó tr·ª£ t·ªët cho vi·ªác tri·ªÉn khai ra quy m√¥ l·ªõn.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\nT√†i li·ªáu tham kh·∫£o\nhttps://analyticsindiamag.com/analytics-driven-store-clustering-sales-and-profits-retail/\nhttps://www.solvoyo.com/whitepapers/approaches-to-retail-store-clustering/\nhttps://www.davinciretail.com/resources/what-is-retail-store-clustering\nhttps://www.forbes.com/sites/forbestechcouncil/2022/04/20/clustering-the-new-world-of-retail-product-segmentation\n","date":"Jul 29, 2023","img":"https://unsplash.it/1920/1080?image=7","permalink":"/blog/2023-07-29-store-clustering/","series":null,"tags":["Retail"],"title":"Ph√¢n C·ª•m C·ª≠a H√†ng ƒê·ªÉ ƒê∆∞a Ra Quy·∫øt ƒê·ªãnh Th√¥ng Minh H∆°n - L√Ω Thuy·∫øt"},{"categories":null,"content":" ƒê·∫∑t v·∫•n ƒë·ªÅ M·ªü b√†i Project l√† g√¨ Product l√† g√¨ 1. M·ªôt s·ªë h∆∞·ªõng d·∫´n ƒë·ªÉ chuy·ªÉn t∆∞ duy t·ª´ project mindset sang product mindset 1.1 T·∫°o ra c√°c team s·∫£n ph·∫©m nh·ªè 1.2 ƒê√≥n nh·∫≠n s·ª± thay ƒë·ªïi v√† ch·∫•p nh·∫≠n s·ª± th√≠ch nghi 1.3 ƒê·ª´ng d√≠ dealine 1.4 ƒê·ª´ng c·ªë g·∫Øng b·∫•u v√≠u v√†o √Ω t∆∞·ªüng ƒë·∫ßu ti√™n 1.5 C·ªë g·∫Øng g·∫Øng k·∫øt roadmap v·ªõi mindset 2. M·ªôt s·ªë kinh nghi·ªám v·ªÅ product mindset 2.1 Trao gi√° tr·ªã, kh√¥ng trao t√≠nh nƒÉng 2.2 Ph√°t tri·ªÉn s·∫£n ph·∫©m d·ª±a tr√™n d·ªØ li·ªáu (Data Driven development) 2.3 T·∫≠p trung v√†o s·∫£n ph·∫©m Ph√°t tri·ªÉn UX 2.4 Minimum Viable Product C√°c x√°c ƒë·ªãnh Minimum Viable Product V√≠ d·ª• c√°c c√¥ng ty kh·ªüi nghi·ªáp v·ªõi Minimum Viable Product Airbnb Foursquare T√†i li·ªáu tham kh·∫£o ƒê·∫∑t v·∫•n ƒë·ªÅ C√≥ bao gi·ªù b·∫°n g·∫∑p m·ªôt trong c√°c tr∆∞·ªùng h·ª£p sau ƒë√¢y:\nB·∫°n release m·ªôt s·∫£n ph·∫©m ra th·ªã tr∆∞·ªùng v√† n√≥ ƒë√£ l·ªói th·ªùi l√∫c b·∫°n release\nB·∫°n release m·ªôt s·∫£n ph·∫©m, v√† ng∆∞·ªùi d√πng kh√¥ng th√®m s·ª≠ d·ª•ng.\nN·∫øu b·∫°n g·∫∑p v·∫•n ƒë·ªÅ tr√™n, h√£y h·ªçc b√†i vi·∫øt n√†y, n·∫øu kh√¥ng b·∫°n h√£y ƒë·ªçc c√°c b√†i vi·∫øt kh√°c trong website c·ªßa m√¨nh www.phamduytung.com\nL∆∞u √Ω nh·ªè: ƒê√¢y l√† mindset, kh√¥ng ph·∫£i l√† toolset, n√™n ch√∫ng ta c·∫ßn th·ª±c h√†nh n√≥, c·∫ßn s·ª± tr·∫£i nghi·ªám trong c√¢u \u0026ldquo;ki·∫øn th·ª©c, kinh nghi·ªám, tr·∫£i nghi·ªám\u0026rdquo; th√¨ m·ªõi th·∫•m d·∫ßn d·∫ßn ƒë∆∞·ª£c. T·∫°i th·ªùi ƒëi·ªÉm vi·∫øt b√†i vi·∫øt n√†y, m√¨nh ch·ªâ c√≥ m·ªôt x√≠u x√≠u tr·∫£i nghi·ªám nh∆∞ v·∫≠y, c√≥ th·ªÉ qua v√†i nƒÉm n·ªØa, tr·∫£i nghi·ªám c·ªßa m√¨nh s·∫Ω kh√°c ƒëi, v√† m√¨nh s·∫Ω vi·∫øt b√†i vi·∫øt kh√°c ƒë·ªÉ c·∫≠p nh·∫≠t s·ª± tr·∫£i nghi·ªám c·ªßa m√¨nh.\nM·ªü b√†i T·ª´ tr∆∞·ªõc t·ªõi nay, ch√∫ng ta th∆∞·ªùng v√¥ t√¨nh b·ªã ƒë√≥ng trong c√°i khung t∆∞ duy project, ƒë·∫∑c bi·ªát l√† c√°c b·∫°n tr∆∞·ªüng th√†nh t·ª´ freelancer. H·∫ßu h·∫øt ch√∫ng ta l√† \u0026ldquo;l√≠nh ƒë√°nh thu√™\u0026rdquo;, v·ªõi ki·ªÉu l√†m d·ª± √°n A trong v√≤ng 3 th√°ng, xong , l·ª•m ti·ªÅn. Nh·∫£y v√†o d·ª± √°n B, l√†m, l·ª•m ti·ªÅn. \u0026hellip; cho ƒë·∫øn khi b·∫°n ra ngo√†i kh·ªüi nghi·ªáp v·ªõi m·ªôt √Ω t∆∞·ªüng hay ho n√†o ƒë√≥, ho·∫∑c b·∫°n v√†o c√¥ng ty product l√†m ch·ªâ ƒë√∫ng 1 product.\nProject l√† g√¨ C√°c d·ª± √°n, theo ƒë·ªãnh nghƒ©a, l√† nh·ªØng n·ªó l·ª±c t·∫°m th·ªùi. M·ªôt t·∫≠p h·ª£p c√°c c√° nh√¢n v√† t·ªï ch·ª©c ƒë·∫£m nh·∫≠n c√°c nhi·ªám v·ª• c·∫ßn thi·∫øt ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c m·ªôt m·ª•c ti√™u c·ª• th·ªÉ. C√≥ m·ªôt l·ªãch tr√¨nh, ng√¢n s√°ch, ƒëi·ªÉm kh·ªüi ƒë·∫ßu v√† ƒëi·ªÉm cu·ªëi. Ti·∫øn ƒë·ªô c·ªßa d·ª± √°n ƒë∆∞·ª£c ƒëo l∆∞·ªùng v√† k·∫øt th√∫c sau khi ƒë·∫°t ƒë∆∞·ª£c c√°c m·ª•c ti√™u v√† c·ªôt m·ªëc ƒë·ªãnh tr∆∞·ªõc.\nN√≥i t√≥m l·∫°i, m·ªôt d·ª± √°n b·∫Øt ƒë·∫ßu v·ªõi m·ªôt k·∫øt lu·∫≠n ƒë∆∞·ª£c x√°c ƒë·ªãnh r√µ r√†ng v√† ƒë∆∞·ª£c hi·ªÉu r√µ. T·ª´ ƒë√≥, nh√≥m ph·∫•n ƒë·∫•u ƒë·ªÉ tr√°nh ƒëi ch·ªách kh·ªèi k·∫ø ho·∫°ch ho·∫∑c l·ªãch tr√¨nh. C√°c b√™n li√™n quan bi·∫øt ƒëi·ªÅu g√¨ s·∫Ω x·∫£y ra, khi n√†o v√† chi ph√≠ bao nhi√™u.\nProduct l√† g√¨ S·∫£n ph·∫©m l√† m·ªëi quan t√¢m li√™n t·ª•c. M·ª•c ti√™u c·ªßa s·∫£n ph·∫©m kh√¥ng ph·∫£i l√† khi n√†o n√≥ k·∫øt th√∫c. C√°c t·ªï ch·ª©c s·∫Ω s·ª≠ d·ª•ng nghi·ªáp v·ª± t·ªëi ∆∞u ho√° c·ªßa m√¨nh ƒë·ªÉ c·ª±c ƒë·∫°i ho√° l·ª£i nhu·∫≠n v√† c√°c KPIs li√™n quan, b·∫±ng c√°ch ph√¢n t√≠ch m·ª©c ƒë·ªô s·ª≠ d·ª•ng (usage), s·ª± tƒÉng tr∆∞·ªüng (growth), v√† s·ª± trung th√†nh c·ªßa ng∆∞·ªùi d√πng (loyalty)\nM·ªôt s·∫£n ph·∫©m m·ªõi c√≥ th·ªÉ l√† k·∫øt qu·∫£ c·ªßa m·ªôt d·ª± √°n ho·∫∑c nhi·ªÅu d·ª± √°n, nh∆∞ng sau khi s·∫£n ph·∫©m ƒë∆∞·ª£c gi·ªõi thi·ªáu, v·∫´n c√≥ nhi·ªÅu c·∫£i ti·∫øn v√† c·∫≠p nh·∫≠t l·∫∑p ƒëi l·∫∑p l·∫°i. C√¥ng vi·ªác c·ªßa nh√≥m s·∫£n ph·∫©m s·∫Ω kh√¥ng bao gi·ªù k·∫øt th√∫c ch·ª´ng n√†o s·∫£n ph·∫©m v·∫´n c√≤n tr√™n th·ªã tr∆∞·ªùng.\nT√≥m l·∫°i, c√°c s·∫£n ph·∫©m li√™n t·ª•c ph√°t tri·ªÉn d·ª±a tr√™n c√°c b√†i h·ªçc, ph·∫£n h·ªìi, s·ª± thay ƒë·ªïi c·ªßa th·ªã tr∆∞·ªùng ¬∞ v√† c√°c nguy√™n t·∫Øc c∆° b·∫£n v·ªÅ t√†i ch√≠nh ¬∞¬∞ (financial fundamentals). Lu√¥n c√≥ ch·ªó ƒë·ªÉ c·∫£i ti·∫øn, n√¢ng cao v√† m·ªü r·ªông sang c√°c th·ªã tr∆∞·ªùng v√† tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng m·ªõi.\n¬∞ V√≠ d·ª• nh∆∞ covid ·∫≠p t·ªõi, ch√∫ng ta ph·∫£i l√†m g√¨\n¬∞¬∞ V√≠ d·ª• nh∆∞ thu·∫ø gtgt gi·∫£m t·ª´ 10% xu·ªëng 8%\nƒê·ªëi v·ªõi c√°c nh√≥m kh·ªüi nghi·ªáp, s·∫£n ph·∫©m hi·∫øm khi n√†o ho√†n th√†nh ngay l·∫≠p t·ª©c ( tr·ª´ m·ªôt s·ªë tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát). H·∫ßu h·∫øt ch√∫ng ta th∆∞·ªùng ƒë∆∞a ra th·ªã tr∆∞·ªùng m·ªôt b·∫£n thƒÉm d√≤ th·ªã tr∆∞·ªùng (c√≥ th·ªÉ c√≥ 1 ho·∫∑c nhi·ªÅu phrases, m·ªói pharse s·∫Ω ho√†n thi·ªán m·ªôt t√≠nh nƒÉng n√†o ƒë√≥) ƒë·ªÉ ƒë√°nh gi√°.\n1. M·ªôt s·ªë h∆∞·ªõng d·∫´n ƒë·ªÉ chuy·ªÉn t∆∞ duy t·ª´ project mindset sang product mindset 1.1 T·∫°o ra c√°c team s·∫£n ph·∫©m nh·ªè N·∫øu team member l√† coder , thua. Ch√∫ng ta ƒë·ªÅu c√≥ ch√≠nh ki·∫øn, ƒë·ªÅu c√≥ ni·ªÅm t·ª± h√†o, ƒë·ªÅu c√≥ suy nghƒ© , ƒë·ªÅu c√≥ √Ω t∆∞·ªüng | gi·∫£i ph√°p \u0026ldquo;ƒëi√™n r·ªì\u0026rdquo; cho m·ªôt v·∫•n ƒë·ªÅ n√†o ƒë√≥.\nC√≥ m·ªôt t·∫ßng nhu c·∫ßu trong th√°p nhu c·∫ßu maslow g·∫Øng li·ªÅn s√¢u xa v·ªõi c√°i n√†y, m√¨nh c·∫£m th·∫•y v·∫≠y.\n1.2 ƒê√≥n nh·∫≠n s·ª± thay ƒë·ªïi v√† ch·∫•p nh·∫≠n s·ª± th√≠ch nghi T∆∞ duy s·∫£n ph·∫©m b·∫Øt ngu·ªìn t·ª´ vi·ªác t·∫°o ra tr·∫£i nghi·ªám ƒë·ªôc ƒë√°o cho ng∆∞·ªùi d√πng d·ª±a tr√™n vi·ªác h·ªçc h·ªèi v√† ph·∫£n h·ªìi. ƒê·ªÉ th√∫c ƒë·∫©y m√¥i tr∆∞·ªùng n√†y, nh√≥m ph·∫£i lu√¥n c·ªüi m·ªü ƒë·ªÉ th∆∞·ªùng xuy√™n ƒëi·ªÅu ch·ªânh k·∫ø ho·∫°ch\u0026hellip; v√† ƒë√¥i khi lo·∫°i b·ªè ch√∫ng ho√†n to√†n.\n1.3 ƒê·ª´ng d√≠ dealine √Åp l·ª±c t·∫°o ra kim c∆∞∆°ng, t·∫°o ra s·ª± ƒë·ªôt ph√° hay √°p l·ª±c t·∫°o n√™n t√¢m l√Ω s·ª£ h√£i, cu·ªôc s·ªëng b·∫ø t·∫Øc, ch√°n n·∫£n, s·ª£ ng√†y ch·ªß nh·∫≠t, s·ª£ ng√†y X ph·∫£i release s·∫£n ph·∫©m \u0026hellip;.\nTu·ª≥\n1.4 ƒê·ª´ng c·ªë g·∫Øng b·∫•u v√≠u v√†o √Ω t∆∞·ªüng ƒë·∫ßu ti√™n T∆∞ duy c·ªßa product l√† t∆∞ duy m·ªü, ƒë√≥n nh·∫≠n nh·ªØng s·ª± thay ƒë·ªïi m·ªôt c√°ch li√™n t·ª•c, cho n√™n s·∫£n ph·∫©m khi ho√†n th√†nh ƒë·∫øn tay ng∆∞·ªùi d√πng n√≥ c√≥ th·ªÉ ƒëi xa m·ªôt v·∫°n t√°m ng√†n d·∫∑m so v·ªõi √Ω t∆∞·ªüng ban ƒë·∫ßu c·ªßa m√¨nh r·ªìi.\n1.5 C·ªë g·∫Øng g·∫Øng k·∫øt roadmap v·ªõi mindset C√≥ m·ªôt th·ª© g·ªçi l√† Theme-Based Roadmap ƒë∆∞·ª£c s·ª≠ d·ª•ng trong t∆∞ duy product. N√≥ s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ thay th·∫ø cho feature roadmap\n2. M·ªôt s·ªë kinh nghi·ªám v·ªÅ product mindset 2.1 Trao gi√° tr·ªã, kh√¥ng trao t√≠nh nƒÉng H·∫ßu h·∫øt, ng∆∞·ªùi d√πng kh√¥ng c·∫ßn t·ªõi nh·ªØng t√≠nh nƒÉng, h·ªç c·∫ßn nh·ªØng th·ª© m√† c√≥ th·ªÉ gi·∫£i quy·∫øt ƒë∆∞·ª£c v·∫•n ƒë·ªÅ c·ªßa h·ªç. Ch√∫ng ta c·∫ßn th·ª±c s·ª± hi·ªÉu ƒë∆∞·ª£c gi√° tr·ªã th·ª±c s·ª± m√† nh·ªØng th·ª© ch√∫ng ta l√†m ra s·∫Ω mang l·∫°i g√¨ cho ng∆∞·ªùi d√πng, l√∫c ƒë√≥, team s·∫Ω th·ª±c s·ª± hi·ªÉu t·∫°i sao c·∫ßn ph·∫£i l√†m n√≥ v√† ƒë√≥ m·ªõi l√† s·∫£n ph·∫©m c√≥ √≠ch.\nƒê·ªÉ trao ƒë∆∞·ª£c c√°c gi√° tr·ªã c√≥ √≠ch, team member c·∫ßn bi·∫øt ƒë∆∞·ª£c v·∫•n ƒë·ªÅ l√† g√¨. BA ho·∫∑c PO ho·∫∑c PM ph·∫£i hi·ªÉu ƒë∆∞·ª£c vi·ªác c·∫ßn l√†m mang l·∫°i gi√° tr·ªã g√¨. Dev c≈©ng c·∫ßn hi·ªÉu \u0026ldquo;v·∫•n ƒë·ªÅ l√† g√¨\u0026rdquo; ƒë·ªÉ ƒë∆∞a ƒë∆∞·ª£c c√°c l·∫≠p tr√¨nh ph√π h·ª£p v√† c√≥ th·ªÉ g√≥p √Ω ng∆∞·ª£c l·∫°i cho BA.\nN·∫øu dev ch·ªâ hi·ªÉu t√≠nh nƒÉng -\u0026gt; BA c·ª±c -\u0026gt; DEV y√™u c·∫ßu BA m√¥ t·∫£ ph·∫£i th·∫≠t s·ª± r√µ r√†ng. (dev l√∫c n√†y ch·ªâ l√† √¥ng coder)\nN·∫øu ph∆∞∆°ng √°n c·ªßa BA kh√¥ng h·ª£p l√Ω -\u0026gt; v·∫•n ƒë·ªÅ ch∆∞a ƒë∆∞·ª£c gi·∫£i quy·∫øt tr·ªçn v·∫πn.\nTam sao th·∫•t b·∫£n gi·ªØ c√°c l·∫ßn trao ƒë·ªïi , t·ª´ ƒë·ªëi t√°c =\u0026gt; Sale =\u0026gt; BA =\u0026gt; Dev -\u0026gt; Dev c·∫ßn c√≥ m·∫∑t trong c√°c cu·ªôc th·∫£o lu·∫≠n c·ªßa BA v·ªõi kh√°ch h√†ng, v·ªõi sale (c√°i n√†y h∆°i kh√≥, nh·∫•t l√† khi l√†m d·ª± √°n v·ªõi ƒë·ªëi t√°c Nh·∫≠t)\nThi·∫øu ƒë·ªãnh nghƒ©a / m√¥ t·∫£ r√µ r√†ng v·ªÅ vi·ªác ho√†n th√†nh t√≠nh nƒÉng -\u0026gt; bem nhau -\u0026gt; toang.\n2.2 Ph√°t tri·ªÉn s·∫£n ph·∫©m d·ª±a tr√™n d·ªØ li·ªáu (Data Driven development) Data Driven l√† m·ªôt thu·∫≠t ng·ªØ kinh doanh ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác s·ª≠ d·ª•ng d·ªØ li·ªáu ƒë·ªÉ cung c·∫•p th√¥ng tin gi√∫p b·∫°n ra quy·∫øt ƒë·ªãnh nhanh h∆°n. N√≥i c√°ch kh√°c, quy·∫øt ƒë·ªãnh ƒë∆∞·ª£c ƒë∆∞a ra v·ªõi b·∫±ng ch·ª©ng th·ª±c nghi·ªám th·ª±c t·∫ø ch·ª© kh√¥ng ph·∫£i suy ƒëo√°n ho·∫∑c kinh nghi·ªám c√° nh√¢n.\nData driven l√† th·ª© b·∫Øt bu·ªôc ph·∫£i l√†m ƒë·ªÉ c√≥ th·ªÉ x√¢y d·ª±ng s·∫£n ph·∫©m th√†nh c√¥ng. M·ªçi th·ª© c·∫ßn ƒë∆∞·ª£c ƒëo ƒë·∫°c ·ªü t·∫•t c·∫£ c√°c kh√¢u, v√† l√† n·ªÅn t·∫£ng c·ªßa vi·ªác ra quy·∫øt ƒë·ªãnh.\nVi·ªác ƒë√°nh gi√° m·ªôt t√≠nh nƒÉng c√≥ ho√†n th√†nh hay kh√¥ng c≈©ng ph·∫£i d·ª±a v√†o con s·ªë, ph·∫£i ƒë·ªãnh l∆∞·ª£ng ƒë∆∞·ª£c, kh√¥ng th·ªÉ phan b·ª´a ph√°n b·∫≠y ƒë∆∞·ª£c. N·∫øu ch√∫ng ta kh√¥ng ƒë·ªãnh l∆∞·ª£ng ƒë∆∞·ª£c k·∫øt qu·∫£ b·∫±ng m·ªôt con s·ªë c·ª• th·ªÉ th√¨ vi·ªác ta c√≥ l√†m hay kh√¥ng l√†m s·∫Ω ch·∫≥ng kh√°c g√¨ nhau c·∫£.\nCh√∫ng ta c·∫ßn ch·ªçn thang ƒëo ƒë·ªÉ ƒë√°nh gi√°, n·∫øu ch·ªçn sai thang ƒë√≥ th√¨ gi√° tr·ªã c·ªßa d·ªØ li·ªáu r·∫•t th·∫•p. Thang ƒëo ph·∫£i ƒë∆∞·ª£c ƒë√°nh gi√° r·∫•t c·∫ßn th·∫≠n ƒë·ªÉ c√≥ ƒë∆∞·ª£c d·ªØ li·ªáu c√≥ gi√° tr·ªã. D·ªØ li·ªáu c·∫ßn ƒë∆∞·ª£c ƒë·∫∑t trong m·ªôt ng·ªØ c·∫£nh c·ª• th·ªÉ th√¨ m·ªõi ph√°t huy ƒë∆∞·ª£c h·∫øt gi√° tr·ªã c·ªßa d·ªØ li·ªáu. C√≤n n·∫øu kh√¥ng c√≥ ng·ªØ c·∫£nh, th√¨ d·ªØ li·ªáu ƒë√≥ c≈©ng ch·ªâ l√† d·ªØ li·ªáu r√°c m√† th√¥i.\nThang ƒëo n√†y s·∫Ω s·ª≠ d·ª•ng c√°c gi√° tr·ªã ch√∫ng ta ƒë√£ thu th·∫≠p ·ªü tr√™n, ƒë·ªÉ ƒë∆∞a ra nh·∫≠n x√©t.\nV√≠ d·ª• kinh ƒëi·ªÉn: Khi c·∫ßn dev m·ªôt s·∫£n ph·∫©m mobile m·ªõi mang l·∫°i gi√° tr·ªã ABCD \u0026hellip; cho kh√°ch h√†ng, team dev b·ªã v∆∞·ªõng v√†o b√†i to√°n, ch·ªçn react-native, hay flutter, hay kortin + swift \u0026hellip;\nƒê·ªÉ ƒë√°nh gi√°, ch√∫ng ta c·∫ßn ph·∫£i x√¢y d·ª±ng m·ªôt thang ƒëo d·ª±a tr√™n d·ªØ li·ªáu ƒë·ªãnh l∆∞·ª£ng. v√≠ d·ª• c√¥ng ngh·ªá c√≥ ·ªïn ƒë·ªãnh? c√≥ nhi·ªÅu th∆∞ vi·ªán h·ªó tr·ª£?, c√≥ c·ªông ƒë·ªìng m·∫°nh? c√≥ group telegram l·ªõn h∆°n 100 ng√†n dev , c√≥ tay to ·ªü sau ch·ªëng l∆∞ng, \u0026hellip;.\n2.3 T·∫≠p trung v√†o s·∫£n ph·∫©m C√°i kh√°c h√†ng mong mu·ªën l√† l√† s·∫£n ph·∫©m, l√† gi√° tr·ªã, kh√°ch h√†ng kh√¥ng quan t√¢m c√¥ng s·ª©c ch√∫ng ta b·ªè ra l√† bao nhi√™u, ch√∫ng ta ƒë√£ t·ªëi ∆∞u code b·∫±ng gi·∫£i thu·∫≠t n√†y gi·∫£i thu·∫≠t n·ªç, ch√∫ng ta s·ª≠ d·ª•ng c√¥ng ngh·ªá A, c√¥ng ngh·ªá B,\u0026hellip; h·∫ßm b√† l·∫±ng.\nN√≥i m·ªôt c√°ch h∆°i ph≈©, c√¥ng ngh·ªá c√≥ t·ªët t·ªõi m·ª©c n√†o m√† kh√¥ng gi·∫£i quy·∫øt d∆∞·ª£c v·∫•n ƒë·ªÅ c·ªßa kh√°ch h√†ng th√¨ n√≥ l√† v√¥ nghƒ©a. B·∫£n th√¢n m√¨nh c≈©ng hay b·ªã ch√∫ t√¢m qu√° m·ª©c v√†o c√¥ng ngh·ªá, k√©o d·ªØ li·ªáu, k√©o source code v·ªÅ ƒë·ªÉ th·ª≠ t√≠nh nƒÉng n√†y , ch·ª©c nƒÉng kia, bla, bla, bla, m√† kh√¥ng nh·∫≠n th·ª©c r·∫±ng n√≥ kh√¥ng ph·∫£i l√† m·ªëi quan t√¢m ƒë·∫ßu ti√™n. ·ªû ƒë√¢y m√¨nh c·∫ßn m·ªü ngo·∫∑c m·ªôt ch√∫t l√† n·∫øu c√¥ng ngh·ªá ƒë∆∞a ra m√† t·∫°o ra gi√° tr·ªã l·ªõn th√¨ l√∫c n√†o c≈©ng ƒë∆∞·ª£c welcome.\nPh√°t tri·ªÉn UX M·ªôt s·∫£n ph·∫©m t·ªët m√† c√≥ UX t·ªìi th√¨ c≈©ng kh√≥ c√≥ kh·∫£ nƒÉng l√¥i k√©o, gi·ªØ ch√¢n kh√°ch h√†ng, c√°i n√†y ƒë·ªÉ l·∫°i cho c√°c b·∫°n tr·∫£i nghi·ªám ƒë·ªÉ m·ªùi √¥ng Designer v√†o :)\n2.4 Minimum Viable Product Minimum Viable Product MVP, l√† m·ªôt s·∫£n ph·∫©m c√≥ ƒë·ªß t√≠nh nƒÉng ƒë·ªÉ thu h√∫t kh√°ch h√†ng ch·∫•p nh·∫≠n s·ªõm v√† x√°c nh·∫≠n √Ω t∆∞·ªüng s·∫£n ph·∫©m s·ªõm trong chu k·ª≥ ph√°t tri·ªÉn s·∫£n ph·∫©m. Trong c√°c ng√†nh c√¥ng nghi·ªáp nh∆∞ ph·∫ßn m·ªÅm, MVP c√≥ th·ªÉ gi√∫p nh√≥m s·∫£n ph·∫©m nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi c·ªßa ng∆∞·ªùi d√πng c√†ng nhanh c√†ng t·ªët ƒë·ªÉ l·∫∑p l·∫°i v√† c·∫£i thi·ªán s·∫£n ph·∫©m.\nEric Ries, ng∆∞·ªùi ƒë√£ gi·ªõi thi·ªáu kh√°i ni·ªám MVP nh∆∞ m·ªôt ph·∫ßn c·ªßa ph∆∞∆°ng ph√°p Lean Startup c·ªßa m√¨nh, m√¥ t·∫£ m·ª•c ƒë√≠ch c·ªßa MVP theo c√°ch n√†y: ƒê√¢y l√† phi√™n b·∫£n c·ªßa m·ªôt s·∫£n ph·∫©m m·ªõi cho ph√©p m·ªôt nh√≥m thu th·∫≠p s·ªë l∆∞·ª£ng t√¨m hi·ªÉu t·ªëi ƒëa ƒë∆∞·ª£c x√°c nh·∫≠n v·ªÅ kh√°ch h√†ng v·ªõi √≠t n·ªó l·ª±c nh·∫•t.\nM·ªôt c√¥ng ty c√≥ th·ªÉ ch·ªçn ph√°t tri·ªÉn v√† ph√°t h√†nh m·ªôt s·∫£n ph·∫©m kh·∫£ thi t·ªëi thi·ªÉu v√¨ nh√≥m s·∫£n ph·∫©m c·ªßa h·ªç mu·ªën:\nPh√°t h√†nh s·∫£n ph·∫©m ra th·ªã tr∆∞·ªùng c√†ng nhanh c√†ng t·ªët\nTh·ª≠ nghi·ªám √Ω t∆∞·ªüng v·ªõi ng∆∞·ªùi d√πng th·ª±c tr∆∞·ªõc khi cam k·∫øt ng√¢n s√°ch l·ªõn cho s·ª± ph√°t tri·ªÉn ƒë·∫ßy ƒë·ªß c·ªßa s·∫£n ph·∫©m\nT√¨m hi·ªÉu nh·ªØng g√¨ c·ªông h∆∞·ªüng v·ªõi th·ªã tr∆∞·ªùng m·ª•c ti√™u c·ªßa c√¥ng ty v√† nh·ªØng g√¨ kh√¥ng\nNgo√†i vi·ªác cho ph√©p c√¥ng ty c·ªßa b·∫°n x√°c nh·∫≠n √Ω t∆∞·ªüng cho m·ªôt s·∫£n ph·∫©m m√† kh√¥ng c·∫ßn x√¢y d·ª±ng to√†n b·ªô s·∫£n ph·∫©m, MVP c≈©ng c√≥ th·ªÉ gi√∫p gi·∫£m thi·ªÉu th·ªùi gian v√† ngu·ªìn l·ª±c m√† b·∫°n c√≥ th·ªÉ cam k·∫øt\nC√°c x√°c ƒë·ªãnh Minimum Viable Product L√†m th·∫ø n√†o ƒë·ªÉ b·∫°n ph√°t tri·ªÉn MVP v√† l√†m th·∫ø n√†o ƒë·ªÉ nh√≥m c·ªßa b·∫°n bi·∫øt khi n√†o b·∫°n c√≥ MVP s·∫µn s√†ng ra m·∫Øt? D∆∞·ªõi ƒë√¢y l√† m·ªôt v√†i b∆∞·ªõc chi·∫øn l∆∞·ª£c c·∫ßn th·ª±c hi·ªán.\nƒê·∫£m b·∫£o MVP theo k·∫ø ho·∫°ch ph√π h·ª£p v·ªõi m·ª•c ti√™u kinh doanh Tr∆∞·ªõc khi c√¢n nh·∫Øc nh·ªØng t√≠nh nƒÉng n√†o c·∫ßn x√¢y d·ª±ng, b∆∞·ªõc ƒë·∫ßu ti√™n trong vi·ªác ph√°t tri·ªÉn MVP l√† ƒë·∫£m b·∫£o s·∫£n ph·∫©m s·∫Ω ph√π h·ª£p v·ªõi m·ª•c ti√™u chi·∫øn l∆∞·ª£c c·ªßa nh√≥m ho·∫∑c c√¥ng ty b·∫°n.\nNh·ªØng m·ª•c ti√™u ƒë√≥ l√† g√¨? B·∫°n ƒëang l√†m vi·ªác h∆∞·ªõng t·ªõi m·ªôt con s·ªë doanh thu trong s√°u th√°ng t·ªõi? B·∫°n c√≥ ngu·ªìn l·ª±c h·∫°n ch·∫ø? Nh·ªØng c√¢u h·ªèi n√†y c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn vi·ªác li·ªáu b√¢y gi·ªù c√≥ ph·∫£i l√† l√∫c ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√°t tri·ªÉn MVP m·ªõi hay kh√¥ng.\nNgo√†i ra, h√£y h·ªèi m·ª•c ƒë√≠ch c·ªßa s·∫£n ph·∫©m MVP n√†y s·∫Ω ph·ª•c v·ª• g√¨? V√≠ d·ª•: n√≥ s·∫Ω thu h√∫t ng∆∞·ªùi d√πng m·ªõi trong m·ªôt th·ªã tr∆∞·ªùng li·ªÅn k·ªÅ v·ªõi th·ªã tr∆∞·ªùng cho c√°c s·∫£n ph·∫©m hi·ªán c√≥ c·ªßa b·∫°n? N·∫øu ƒë√≥ l√† m·ªôt trong nh·ªØng m·ª•c ti√™u kinh doanh hi·ªán t·∫°i c·ªßa b·∫°n, th√¨ k·∫ø ho·∫°ch MVP n√†y c√≥ th·ªÉ kh·∫£ thi v·ªÅ m·∫∑t chi·∫øn l∆∞·ª£c.\nNh∆∞ng n·∫øu ∆∞u ti√™n hi·ªán t·∫°i c·ªßa c√¥ng ty b·∫°n l√† ti·∫øp t·ª•c t·∫≠p trung v√†o c√°c th·ªã tr∆∞·ªùng c·ªët l√µi c·ªßa b·∫°n, b·∫°n c√≥ th·ªÉ c·∫ßn ph·∫£i g√°c l·∫°i √Ω t∆∞·ªüng n√†y v√† thay v√†o ƒë√≥, t·∫≠p trung v√†o m·ªôt MVP ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ cung c·∫•p ch·ª©c nƒÉng m·ªõi cho kh√°ch h√†ng hi·ªán t·∫°i c·ªßa b·∫°n.\nB·∫Øt ƒë·∫ßu x√°c ƒë·ªãnh c√°c v·∫•n ƒë·ªÅ c·ª• th·ªÉ m√† b·∫°n mu·ªën gi·∫£i quy·∫øt ho·∫∑c c√°c c·∫£i ti·∫øn b·∫°n mu·ªën k√≠ch ho·∫°t cho t√≠nh c√°ch ng∆∞·ªùi d√πng c·ªßa m√¨nh. B√¢y gi·ªù b·∫°n ƒë√£ x√°c ƒë·ªãnh k·∫ø ho·∫°ch MVP ph√π h·ª£p v·ªõi m·ª•c ti√™u kinh doanh c·ªßa m√¨nh, b·∫°n c√≥ th·ªÉ b·∫Øt ƒë·∫ßu suy nghƒ© th√¥ng qua c√°c gi·∫£i ph√°p c·ª• th·ªÉ m√† b·∫°n mu·ªën s·∫£n ph·∫©m c·ªßa m√¨nh cung c·∫•p cho ng∆∞·ªùi d√πng. Nh·ªØng gi·∫£i ph√°p n√†y, m√† b·∫°n c√≥ th·ªÉ vi·∫øt trong c√¢u chuy·ªán c·ªßa ng∆∞·ªùi d√πng, kh√¥ng ƒë·∫°i di·ªán cho t·∫ßm nh√¨n t·ªïng th·ªÉ c·ªßa s·∫£n ph·∫©m ‚Äî ch·ªâ l√† t·∫≠p h·ª£p con c·ªßa t·∫ßm nh√¨n ƒë√≥. Ch√∫ng ta ch·ªâ c√≥ th·ªÉ ph√°t tri·ªÉn m·ªôt l∆∞·ª£ng nh·ªè ch·ª©c nƒÉng cho MVP c·ªßa m√¨nh.\nB·∫°n s·∫Ω c·∫ßn ph·∫£i c√≥ chi·∫øn l∆∞·ª£c trong vi·ªác quy·∫øt ƒë·ªãnh ch·ª©c nƒÉng h·∫°n ch·∫ø n√†o s·∫Ω ƒë∆∞a v√†o MVP c·ªßa m√¨nh. B·∫°n c√≥ th·ªÉ d·ª±a tr√™n c√°c quy·∫øt ƒë·ªãnh n√†y d·ª±a tr√™n m·ªôt s·ªë y·∫øu t·ªë, bao g·ªìm:\nNghi√™n c·ª©u ng∆∞·ªùi d√πng\nPh√¢n t√≠ch c·∫°nh tranh\nB·∫°n s·∫Ω c√≥ th·ªÉ l·∫∑p l·∫°i m·ªôt s·ªë lo·∫°i ch·ª©c nƒÉng nhanh nh∆∞ th·∫ø n√†o khi nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi c·ªßa ng∆∞·ªùi d√πng\nChi ph√≠ t∆∞∆°ng ƒë·ªëi ƒë·ªÉ th·ª±c hi·ªán c√°c c√¢u chuy·ªán ng∆∞·ªùi d√πng\nChuy·ªÉn ch·ª©c nƒÉng MVP c·ªßa b·∫°n th√†nh m·ªôt k·∫ø ho·∫°ch h√†nh ƒë·ªông ph√°t tri·ªÉn. B√¢y gi·ªù b·∫°n ƒë√£ c√¢n nh·∫Øc c√°c y·∫øu t·ªë chi·∫øn l∆∞·ª£c ·ªü tr√™n v√† gi·∫£i quy·∫øt ch·ª©c nƒÉng h·∫°n ch·∫ø m√† b·∫°n mu·ªën cho MVP c·ªßa m√¨nh, ƒë√£ ƒë·∫øn l√∫c chuy·ªÉn ƒëi·ªÅu n√†y th√†nh m·ªôt k·∫ø ho·∫°ch h√†nh ƒë·ªông ƒë·ªÉ ph√°t tri·ªÉn.\nL∆∞u √Ω: ƒêi·ªÅu c·∫ßn thi·∫øt l√† ph·∫£i ghi nh·ªõ ch·ªØ V trong MVP ‚Äî s·∫£n ph·∫©m ph·∫£i kh·∫£ thi. ƒêi·ªÅu ƒë√≥ c√≥ nghƒ©a l√† n√≥ ph·∫£i cho ph√©p kh√°ch h√†ng c·ªßa b·∫°n ho√†n th√†nh to√†n b·ªô nhi·ªám v·ª• ho·∫∑c d·ª± √°n v√† cung c·∫•p tr·∫£i nghi·ªám ng∆∞·ªùi d√πng ch·∫•t l∆∞·ª£ng cao. MVP kh√¥ng th·ªÉ l√† giao di·ªán ng∆∞·ªùi d√πng v·ªõi nhi·ªÅu c√¥ng c·ª• v√† t√≠nh nƒÉng ƒë∆∞·ª£c x√¢y d·ª±ng d·ªü dang. N√≥ ph·∫£i l√† m·ªôt s·∫£n ph·∫©m ho·∫°t ƒë·ªông m√† c√¥ng ty c·ªßa b·∫°n s·∫Ω c√≥ th·ªÉ b√°n.\nV√≠ d·ª• c√°c c√¥ng ty kh·ªüi nghi·ªáp v·ªõi Minimum Viable Product C√≥ hai v√≠ d·ª• kinh ƒëi·ªÉn th∆∞·ªùng ƒë∆∞·ª£c nh·∫Øc t·ªõi, ƒë√≥ l√†:\nAirbnb Kh·ªüi ƒë·∫ßu vi·ªác kinh doanh v·ªõi m·ªôt s·ªë v·ªën √≠t ·ªèi, c√°c nh√† s√°ng l·∫≠p Airbnb ƒë√£ s·ª≠ d·ª•ng ch√≠nh nh·ªØng cƒÉng h·ªô c·ªßa h·ªç ƒë·ªÉ ki·ªÉm ch·ª©ng √Ω t∆∞·ªüng c·ªßa h·ªç ƒë·ªÉ t·∫°o ta market offering short-term, peer-to-peer rental housing online (m√¨nh ƒë·ªÉ t·ª´ ti·∫øng anh ·ªü ƒë√¢y , l√† t·ª´ kho√° cho c√°c b·∫°n tham kh·∫£o). H·ªç t·∫°o ra m·ªôt trang web r·∫•t t·ªëi gi·∫£n, quƒÉng l√™n ƒë√≥ h√¨nh v√† chi ti·∫øt v·ªÅ ng√¥i nh√† c·ªßa h·ªç, v√† g·∫ßn nh∆∞ ngay l·∫≠p t·ª©c, ƒë√£ c√≥ kh√°ch h√†ng tr·∫£ ti·ªÅn cho d·ªãch v·ª• c·ªßa h·ªç.\nGi·∫£ s·ª≠ trong tr∆∞·ªùng h·ª£p v√†i th√°ng sau kh√¥ng c√≥ ai thu√™ nh√†, c√°c nh√† s√°ng l·∫≠p Airbnb s·∫Ω l√†m g√¨ ti·∫øp theo nh·ªâ? :) :)\nFoursquare Foursquare l√† m·ªôt m·∫°ng x√£ h·ªôi ƒë∆∞·ª£c s√°ng l·∫≠p nƒÉm 2009, ƒë∆∞·ª£c ra ƒë·ªùi v·ªõi m·ªôt MVP duy nh·∫•t: \u0026ldquo;offering only check-ins and gamification rewards\u0026rdquo; - check-in -\u0026gt; ki·ªÉm ƒëi·ªÉm -\u0026gt; nh·∫≠n th∆∞·ªüng.\nNh√≥m ph√°t tri·ªÉn Foursquare b·∫Øt ƒë·∫ßu th√™m v√†o c√°c t√≠nh nƒÉng recommendations, city guides ƒë·∫øn khi n·ªç ki·ªÉm ch·ª©ng d∆∞·ª£c √Ω t∆∞·ªüng c·ªßa m√¨nh, th∆∞·ªõc ƒëo c·ªßa kinh doanh l√† s·ª± tƒÉng tr∆∞·ªüng c·ªßa ng∆∞·ªùi s·ª≠ d·ª•ng d·ªãch v·ª•.\nT√†i li·ªáu tham kh·∫£o https://hbr.org/2020/05/approach-your-data-with-a-product-mindset\nhttps://www.productplan.com/learn/product-mindset-vs-project-mindset/\nhttps://www.productplan.com/glossary/minimum-viable-product/\nhttps://www.productplan.com/learn/theme-based-roadmap/\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\n","date":"Jul 23, 2023","img":"https://unsplash.it/1920/1080?image=9","permalink":"/blog/2023-07-23-product-mindset/","series":null,"tags":["mindset"],"title":"T∆∞ Duy L√†m S·∫£n Ph·∫©m - The Product Mindset"},{"categories":null,"content":" I. Gi·ªõi thi·ªáu II. N-gram Tokenizer III. S·ª≠ d·ª•ng N-gram trong tr∆∞·ªùng h·ª£p t√¨m ki·∫øm IV. C√°c ph∆∞∆°ng ph√°p thay th·∫ø n-gram V. K·∫øt lu·∫≠n I. Gi·ªõi thi·ªáu Chi ph√≠ li√™n quan ƒë·∫øn n-gram tokenizer ·ªü ElasticSearch v√† opensearch th∆∞·ªùng kh√¥ng ƒë·ªÅ c·∫≠p chi ti·∫øt trong c√°c t√†i li·ªáu, do ƒë√≥, c√≥ khi n√≥ s·∫Ω g√¢y ra c√°c h·∫≠u qu·∫£ kh√° nghi√™m tr·ªçng v·ªÅ chi ph√≠ v√† hi·ªáu nƒÉng. D·∫´n ƒë·∫øn tr∆∞·ªùng h·ª£p l√† ch√∫ng ta ph·∫£i \u0026ldquo;l·∫•y th·ªãt ƒë√® ng∆∞·ªùi\u0026rdquo; b·∫±ng c√°ch tƒÉng chi ph√≠ ph·∫ßn c·ª©ng m·ªôt c√°ch l√£ng ph√≠. Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω ƒë·ªÅ c·∫≠p ƒë·∫øn v√†i use-case s·ª≠ d·ª•ng n-gram tokenizer, m·ªôt s·ªë ph∆∞∆°ng ph√°p c·∫£i ti·∫øn, ho·∫∑c m·ªôt v√†i ph∆∞∆°ng ph√°p thay th·∫ø n√≥ b·∫±ng c√°ch kh√°ch hi·ªáu qu·∫£ h∆°n.\nNg√†y nay, Elasticsearch v√† OpenSearch l√† hai engines ƒë∆∞·ª£c nhi·ªÅu c√¥ng ty s·ª≠ d·ª•ng ƒë·ªÉ l√†m t√¨m ki·∫øm vƒÉn b·∫£n n·ªôi b·ªô, l√†m b·ªô m√°y t√¨m ki·∫øm ch√≠nh ƒë·ªÉ s·ª≠ d·ª•ng n·ªôi b·ªô ho·∫∑c cung c·∫•p d·ªãch v·ª• cho kh√°ch h√†ng b√™n ngo√†i.\nH·∫ßu h·∫øt c√°c l·∫≠p tr√¨nh vi√™n s·∫Ω s·ª≠ d·ª•ng h√†m analyzers v√† tokenizers m·∫∑c ƒë·ªãnh do Elasticsearch v√† OpenSearch cung c·∫•p s·∫µn, ƒë·ªÉ chia nh·ªè ƒëo·∫°n vƒÉn b·∫£n th√†nh c√°c token. V√≠ d·ª• nh∆∞ c√¢u \u0026ldquo;ƒê√¢y l√† nƒÉm r·∫•t l·∫° l√πng\u0026rdquo; khi s·ª≠ d·ª•ng analyzer m·∫∑c ƒë·ªãnh th√¨ s·∫Ω chia th√†nh danh s√°ch c√°c t·ª´ [ ƒê√¢y, l√†, nƒÉm, r·∫•t, l·∫°, l√πng], m·ªói t·ª´ trong danh s√°ch c√°c t·ª´ tr√™n ƒë·ªÅu c√≥ th·ªÉ d·ªÖ d√†ng ƒë∆∞·ª£c search. ƒê√¢y l√† c√°i m√† ch√∫ng ta th∆∞·ªùng g·ªçi l√† \u0026ldquo;full-text-search\u0026rdquo;, l√† t√¨m ki·∫øm vƒÉn b·∫£n b·∫±ng d·ª±a tr√™n m·ªôt ho·∫∑c m·ªôt v√†i t·ª´ c√≥ t·ªìn t·∫°i trong ƒëo·∫°n vƒÉn b·∫£n ƒë√≥.\nTrong m·ªôt s·ªë tr∆∞·ªùng h·ª£p h·ª£p, ng∆∞·ªùi ta s·∫Ω s·ª≠ d·ª•ng c√°c analyzer ƒë·∫∑c bi·ªát ƒë·ªÉ l√†m c√°c c√¥ng vi·ªác ƒë·∫∑c bi·ªát, kh√¥ng ph·∫£i l√† full text search.\nM·ªôt trong nh·ªØng th√†nh ph·∫ßn ƒë·∫∑c bi·ªát trong elasticsearch v√† open search l√† n-gram tokenizer. H√£y ƒëi·ªÉm qua m·ªôt v√†i ·ª©ng d·ª•ng c·ªßa n√≥ m√† ng∆∞·ªùi c·∫•u h√¨nh th∆∞·ªùng hay s·ª≠ d·ª•ng sai\nII. N-gram Tokenizer N-gram Tokenizer t·∫°o ra m·ªôt nh√≥m c√°c k√Ω t·ª±, nh·ªØng token n√≥ t·∫°o ra kh√¥ng nh·∫•t thi·∫øt l√† nh·ªØng t·ª´ gi·ªëng nh∆∞ analyzer ti√™u chu·∫©n, n√≥ ch·ª©a nh·ªØng t·ª´ li√™n ti√™n ti·∫øp nhau, chi·ªÅu d√†i c·ªßa token ph·ª• thu·ªôc v√†o N. V√≠ d·ª• trong tr∆∞·ªùng h·ª£p N = 2 v√† t·ª´ c·ªßa c√∫ng ta l√† \u0026ldquo;l·∫° l√πng\u0026rdquo;, ch√∫ng ta c√≥ c√°c token l√† [l, l·∫°, ·∫°, \u0026ldquo;·∫° \u0026ldquo;, \u0026quot; \u0026ldquo;, \u0026quot; l\u0026rdquo;, l, l√π, √π, √πn, n, ng, g]\nB·∫°n c√≥ th·ªÉ th·∫•y r·∫±ng, thay v√¨ ch·ªâ t·∫°o ra hai token [l·∫°, l√πng], n-gram s·∫Ω chia d·ªØ li·ªáu th√†nh nh√≥m c√°c k√Ω t·ª±. Ph·ª• thu·ªôc v√†o N m√† ta c√≥ s·ªë l∆∞·ª£ng token kh√°c nhau, Trong v√≠ d·ª• tr√™n, ch√∫ng ta c√≥ 17 token v·ªõi N = 2 , nghƒ©a l√† s·ªë l∆∞·ª£ng token ƒë√£ tƒÉng h∆°n 6 l·∫ßn. Trong tr∆∞·ªùng h·ª£p N=3, N=4, ho·∫∑c trong tr∆∞·ªùng h·ª£p t·ª´ c·∫ßn index d√†i h∆°n, s·ªë l∆∞·ª£ng token c√≤n b·ªã nh√¢n l√™n g·∫•p nhi·ªÅu l·∫ßn n·ªØa\nIII. S·ª≠ d·ª•ng N-gram trong tr∆∞·ªùng h·ª£p t√¨m ki·∫øm C√≥ r·∫•t nhi·ªÅu t∆∞ v·∫•n tr√™n m·∫°ng v·ªÅ c√°ch s·ª≠ d·ª•ng n-gram, v√† c√°c t∆∞ v·∫•n tr√™n th∆∞·ªùng xoay quanh c√°c ch·ªß ƒë·ªÅ sau\nPh√°t hi·ªán l·ªói ch√≠nh t·∫£ Vi·ªác g√µ vƒÉn b·∫£n sai ch√≠nh t·∫£ l√† m·ªôt v·∫•n ƒë·ªÅ th∆∞·ªùng g·∫∑p, ngay c·∫£ c√°c b√°o ch√≠ ch√≠nh th·ªëng c≈©ng g·∫∑p tr∆∞·ªùng h·ª£p tr√™n. V√≠ d·ª• ng∆∞·ªùi d√πng c√≥ th·ªÉ g√µ sai t·ª´ \u0026ldquo;apple\u0026rdquo; th√†nh \u0026ldquo;aple\u0026rdquo; (ƒëi·ªán tho·∫°i apple). Vi·ªác s·ª≠ d·ª•ng n-grams s·∫Ω gi√∫p ta gi·∫£i ph√°t hi·ªán t·ª´ b·ªã g√µ sai, trong khi ƒë√≥, analyzer m·∫∑c ƒë·ªãnh s·∫Ω kh√¥ng ph√°t hi·ªán ra.\nT√¨m ki·∫øm trong l√∫c g√µ Th·ª±c hi·ªán vi·ªác search trong l√∫c ng∆∞·ªùi d√πng g√µ tr√™n thanh t√¨m ki·∫øm. N√≥ s·∫Ω t√¨m ki·∫øm tr∆∞·ªõc c√°c k·∫øt qu·∫£ h·ª£p l·ªá ngay c·∫£ khi ng∆∞·ªùi d√πng ch∆∞a ho√†n t·∫•t vi·ªác t√¨m ki·∫øm. V√≠ d·ª• g·ª£i √Ω t·ª´ kho√° \u0026ldquo;iphone 14 promax\u0026rdquo; khi ng∆∞·ªùi d√πng ch·ªâ m·ªõi g√µ ƒë·∫øn t·ª´ \u0026ldquo;ipho\u0026rdquo;\nPrefix searches T√¨m ki·∫øm vƒÉn b·∫£n b·∫Øt ƒë·∫ßu c·ªßa t·ª´, v√≠ d·ª• ng∆∞·ªùi d√πng g√µ \u0026ldquo;ip\u0026rdquo; th√¨ s·∫Ω kh·ªõp v·ªõi \u0026ldquo;iphone\u0026rdquo;, khi t·ª´ \u0026ldquo;ip\u0026rdquo; ƒë∆∞·ª£c index l√† token c·ªßa t·ª´ \u0026ldquo;iphone\u0026rdquo;. Prefix search ch·ªâ l·∫•y index, kh√¥ng th·ª±c hi·ªán prefix query\nSuffix searches ƒê·ªëi l·∫≠p v·ªõi Prefix searches, ƒë√¥i l√∫c ch√∫ng ta s·∫Ω c·∫ßn t√¨m ki·∫øm c√°c k√Ω t·ª± ·ªü cu·ªëi, v√≠ d·ª• nh∆∞ bi·ªÉn s·ªë xe (th∆∞·ªùng ng∆∞·ªùi d√πng s·∫Ω kh√¥ng nh·ªõ ph·∫ßn k√Ω hi·ªáu v√† k√Ω s·ªë ƒë·∫ßu, v√≠ d·ª• 50A1), s·ªë ƒëi·ªán tho·∫°i ( t√¨m ki·∫øm 4 k√Ω t·ª± cu·ªëi).\nInfix searches T∆∞∆°ng t·ª± nh∆∞ tr√™n, nh∆∞ng t√¨m ·ªü gi·ªØa.\nTrong nh·ªØng tr∆∞·ªùng h·ª£p tr√™n, l·∫≠p tr√¨nh vi√™n hay ƒë∆∞·ª£c t∆∞ v·∫•n l√† x√†i n-gram. N-gram c√≥ th·ªÉ gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ tr√™n, nh∆∞ng ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu c√°c kh√°c hi·ªáu qu·∫£ h∆°n.\nL√Ω do kh√¥ng n√™n x√†i n-gram l√† v√¨ s·ª± b√πng n·ªï token do ch√≠nh n-gram mang l·∫°i, d·∫´n ƒë·∫øn ch√∫ng ta c·∫ßn ti√™u t·ªën nhi·ªÅu t√†i nguy√™n nh∆∞ CPU, RAM ƒë·ªÉ x·ª≠ l√Ω index, t·∫°o token trong l√∫c index v√† search, t·ªën nhi·ªÅu ·ªï c·ª©ng ƒë·ªÉ l∆∞u tr·ªØ. Cu·ªëi c√πng, hi·ªáu nƒÉng truy v·∫•n s·∫Ω gi·∫£m.\nIV. C√°c ph∆∞∆°ng ph√°p thay th·∫ø n-gram Ch√∫ng ta s·∫Ω xem x√©t t·ª´ng tr∆∞·ªùng h·ª£p c·ª• th·ªÉ\nG√µ sai ch√≠nh t·∫£ Thay v√¨ s·ª≠ d·ª•ng n-gram, ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng term suggester v√† phrase suggester trong elastic search, link https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters.html#phrase-suggester, https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters.html#term-suggester, ƒë∆°n gi·∫£n.\nT√¨m ki·∫øm trong l√∫c g√µ C√°i n√†y th√¨ ch√∫ng ta x√†i n-gram c≈©ng ƒë∆∞·ª£c, nh∆∞ng m√† elastic search c√≥ h·ªó tr·ª£ cho ch√∫ng ta m·ªôt v√†i ti·ªán √≠ch ƒë∆°n gi·∫£n h∆°n nhi·ªÅu, ch√∫ng ta kh√¥ng c·∫ßn ph·∫£i v·∫Øt √≥c suy nghƒ© c·∫•u h√¨nh n b·∫±ng bao nhi√™u. ƒê√≥ l√† s·ª≠ d·ª•ng tr∆∞·ªùng d·ªØ li·ªáu search-as-you-type https://www.elastic.co/guide/en/elasticsearch/reference/current/search-as-you-type.html. Ho·∫∑c ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng completion suggester v√† context suggester, link https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters.html#completion-suggester , https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters.html#context-suggester\nPrefix searches Elastic c≈©ng h·ªó tr·ª£ s·∫µn lu√¥n, ƒë√≥ l√† Prefix queryedit https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-prefix-query.html\nSuffix searches Ch·ªó n√†y ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng combo Reverse token filter v√† Match phrase prefix query https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-reverse-tokenfilter.html, https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase-prefix.html#query-dsl-match-query-phrase-prefix\nV√≠ d·ª• nh∆∞ ch√∫ng ta c√≥ s·ªë ƒëi·ªán tho·∫°i 0902987235, ch√∫ng ta s·∫Ω Reverse token filter th√†nh 5327892090, 4 s·ªë cu·ªëi c·∫ßn t√¨m l√† 7235 s·∫Ω b·ªã reverser th√†nh 5327, th·ª±c hi·ªán Match phrase prefix query 5327, ch√∫ng ta s·∫Ω t√¨m ƒë∆∞·ª£c 5327892090 , Reverse l·∫°i ra chu·ªói s·ªë ƒëi·ªán tho·∫°i c·∫ßn t√¨m.\nInfix searches ƒê√¢y l√† √¥ng t·ªën nhi·ªÅu chi ph√≠ nh·∫•t, v·ªõi sql engine, ch√∫ng ta x√†i t·ª´ kho√° like d·∫´n ƒë·∫øn b·ªã m·∫•t index, v·ªõi n-gram, ch√∫ng ta ph·∫£i index h·∫øt to√†n b·ªô token, v√†o. Trong elastic c√≥ h·ªó tr·ª£ ch√∫ng ta Word delimiter graph token filter, gi·∫£i quy·∫øt c√°i n√†y d·ªÖ d√†ng https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-word-delimiter-graph-tokenfilter.html\nV. K·∫øt lu·∫≠n V·ªõi c√°c c√¥ng ngh·ªá tr√™n, ch√∫ng s·∫Ω gi√∫p ch√∫ng ta nh√†n h∆°n khi s·ª≠ d·ª•ng elastic, opensearch. C√°c b·∫°n n·∫øu c√≥ ƒëang b·ªã nh·ªØng v∆∞·ªõng m·∫Øc tr√™n, h√£y th·ª≠ c√°c c√°ch ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t, bi·∫øt ƒë√¢u b·∫•t ng·ªù s·∫Ω x·∫£y ra.\nNgu·ªìn: https://blog.bigdataboutique.com/2023/01/dont-use-n-gram-in-elasticsearch-and-opensearch-6f0b48\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\n","date":"Mar 25, 2023","img":"https://unsplash.it/1920/1080?image=10","permalink":"/blog/2023-03-25-elasticsearch-opensearch-ngram/","series":null,"tags":["RFM","Recommendation","Marketing"],"title":"N-Gram Trong Elastic Search V√† Opensearch - Khi N√†o Kh√¥ng N√™n S·ª≠ D·ª•ng"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu Symbolic AI l√† g√¨ Connectionist AI l√† g√¨ Ch√∫ng ta n√™n ch·ªçn c√°i n√†o H∆∞·ªõng ph√°t tri·ªÉn ti·∫øp theo c·ªßa AI Tham kh·∫£o L·ªùi m·ªü ƒë·∫ßu D·∫°o g·∫ßn ƒë√¢y, khi c√°c ·ª©ng d·ª•ng AI ƒëang h√¥ m∆∞a g·ªçi gi√≥ tr√™n to√†n c√µi, ƒëi·ªÉn h√¨nh l√† hot keywork chatGPT, th√¨ trong c·ªông ƒë·ªìng nghi√™n c·ª©u c≈©ng n·ªï ra cu·ªôc chi·∫øn gi·ªØa hai phe Symbolic AI v√† Connectionist AI. C√≥ v·∫ª nh∆∞ ·ªü n∆°i n√†o c√≥ chia nh√≥m, th√¨ s·∫Ω c√≥ m·ªôt nh√≥m ng∆∞·ªùi ch·ªçn phe n√†y, v√† m·ªôt nh√≥m kh√°c ch·ªçn phe c√≤n l·∫°i, m·ªôt nh√≥m kh√°c n·ªØa ƒë·ª©ng ·ªü c·∫£ hai, nh√≥m kh√°c n·ªØa kh√¥ng ch·ªçn nh√≥m n√†o c·∫£. Hai nh√≥m l√† nh√≥m ƒë·ª©ng c·∫£ hai v√† nh√≥m kh√¥ng ch·ªçn nh√≥m n√†o c·∫£ th∆∞·ªùng √≠t ho·∫∑c kh√¥ng l√†m g√¨ c·∫£, c√≤n nh√≥m ch·ªçn phe n√†y v√† nh√≥m ch·ªçn phe kia s·∫Ω ƒë·ªëi ƒë·∫ßu nhau r·∫•t gay g·∫Øt.\nD∆∞·ªõi s·ª± c∆∞·ªùng ƒëi·ªáu c·ªßa gi·ªõi truy·ªÅn th√¥ng, c√πng v·ªõi vi·ªác n·ªïi nh∆∞ c·ªìn c·ªßa nh·ªØng ·ª©ng d·ª•ng ƒë∆∞·ª£c PR m·ªôt c√°ch m·∫°nh m·∫Ω, th√¨ nh√≥m Connectionist AI ƒëang b·ªã xem l√† \u0026hellip; AI.\nS·ª± th·∫≠t l√† m·ªói nh√≥m thu·∫≠t to√°n ƒë·ªÅu c√≥ ch·ªó ƒë·ª©ng c·ªßa n√≥. Kh√¥ng c√≥ m·ªôt thu·∫≠t to√°n AI n√†o to√†n nƒÉng ·ªü th·ªùi ƒëi·ªÉm hi·ªán t·∫°i, gi√∫p gi·∫£i c√°c b√†i to√°n, hay n√≥i c√°ch kh√°c l√† ch√∫ng ta kh√¥ng c√≥ \u0026ldquo;vi√™n ƒë·∫°n b·∫°c\u0026rdquo; n√†o trong AI. M·ªói c√¥ng c·ª• ƒë·ªÅu c√≥ ƒëi·ªÉm m·∫°nh v√† ƒëi·ªÉm y·∫øu ri√™ng, v√† vi·ªác ch√∫ng ta s·ª≠ d·ª•ng ƒë√∫ng c√¥ng c·ª• s·∫Ω l√† ch√¨a kho√° cho s·ª± th√†nh c√¥ng.\nSymbolic AI l√† g√¨ Nh√≥m thu·∫≠t to√°n n√†y ƒë√¥i khi c√≤n ƒë∆∞·ª£c g·ªçi l√† GOFAI (Good Old Fashioned A.I.), kh√¥ng n√™n hi·ªÉu n√≥ theo nghƒ©a l√† c√¥ng ngh·ªá c≈© hay c√¥ng ngh·ªá l·ªói th·ªùi. M√† n√™n hi·ªÉu l√† n√≥ l√† c√°ch ti·∫øp c·∫≠n c·ªï ƒëi·ªÉn c·ªßa vi·ªác bi·∫øn th√¥ng tin tri th·ª©c v√† v√† c√°c lu·∫≠t c·ªßa con ng∆∞·ªùi th√†nh nh·ªØng d√≤ng code tr√™n m√°y t√≠nh.\nCon ng∆∞·ªùi th∆∞·ªùng xuy√™n s·ª≠ d·ª•ng c√°c \u0026ldquo;bi·ªÉu t∆∞·ª£ng\u0026rdquo; ƒë·ªÉ g√°n √Ω nghƒ©a cho c√°c s·ª± v·∫≠t v√† s·ª± ki·ªán trong m√¥i tr∆∞·ªùng c·ªßa h·ªç. V√≠ d·ª•, n·∫øu ai ƒë√≥ n√≥i v·ªõi b·∫°n c·ªßa h·ªç r·∫±ng h·ªç v·ª´a mua m·ªôt b√≥ hoa h·ªìng, ng∆∞·ªùi nghe tin ƒë√≥ c√≥ th·ªÉ nhanh ch√≥ng li√™n t∆∞·ªüng ƒë·∫øn h√¨nh ·∫£nh c·ªßa nh·ªØng b√¥ng hoa. √ù t∆∞·ªüng c·ªßa symbolic AI l√† nh·ªØng \u0026ldquo;bi·ªÉu t∆∞·ª£ng\u0026rdquo; n√†y ƒë∆∞·ª£c x√¢y d·ª±ng th√†nh kh·ªëi nh·∫≠n th·ª©c.\nC√°c h·ªá th·ªëng thu·ªôc lo·∫°i n√†y th∆∞·ªùng li√™n quan ƒë·∫øn l√Ω lu·∫≠n suy di·ªÖn, suy lu·∫≠n logic v√† m·ªôt s·ªë thu·∫≠t to√°n t√¨m ki·∫øm ƒë·ªÉ t√¨m ra gi·∫£i ph√°p trong c√°c r√†ng bu·ªôc c·ªßa m√¥ h√¨nh ƒë√£ ch·ªâ ƒë·ªãnh. Ch√∫ng bao g·ªìm c√°c h·ªá th·ªëng chuy√™n gia, s·ª≠ d·ª•ng c√°c quy t·∫Øc v√† c√¢y quy·∫øt ƒë·ªãnh ƒë·ªÉ suy ra k·∫øt lu·∫≠n t·ª´ d·ªØ li·ªáu ƒë·∫ßu v√†o, b·ªô gi·∫£i r√†ng bu·ªôc, t√¨m ki·∫øm gi·∫£i ph√°p trong m·ªôt kh√¥ng gian kh·∫£ nƒÉng v√† h·ªá th·ªëng l·∫≠p k·∫ø ho·∫°ch, c·ªë g·∫Øng t√¨m m·ªôt chu·ªói c√°c h√†nh ƒë·ªông ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c m·ªôt m·ª•c ti√™u ƒë∆∞·ª£c x√°c ƒë·ªãnh r√µ r√†ng t·ª´ m·ªôt s·ªë tr·∫°ng th√°i ban ƒë·∫ßu. Ch√∫ng c≈©ng th∆∞·ªùng c√≥ c√°c bi·∫øn th·ªÉ c√≥ kh·∫£ nƒÉng x·ª≠ l√Ω s·ª± kh√¥ng ch·∫Øc ch·∫Øn v√† r·ªßi ro.\nC√°c thu·∫≠t to√°n nh∆∞ v·∫≠y th∆∞·ªùng c√≥ ƒë·ªô ph·ª©c t·∫°p thu·∫≠t to√°n l√† NP-hard, khi gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ trong th·∫ø gi·ªõi th·ª±c, nh√≥m n√†y ph·∫£i ƒë·ªëi m·∫∑t v·ªõi kh√¥ng gian t√¨m ki·∫øm si√™u l·ªõn. ƒêi·ªÅu n√†y c√≥ nghƒ©a l√† c√°c thu·∫≠t to√°n thuy·ªÅn th·ªëng trang b·ªã k·ªπ nƒÉng t√¨m ki·∫øm ng·∫´u nhi√™n s·∫Ω kh√¥ng ho·∫°t ƒë·ªông, ngo·∫°i tr·ª´ c√°c tr∆∞·ªùng h·ª£p ngo·∫°i l·ªá, Do kh·∫£ nƒÉng cao l√† l·ªùi gi·∫£n s·∫Ω v√©t c·∫°n kh√¥ng gian t√¨m ki·∫øm.\nC√≥ r·∫•t nhi·ªÅu nh√≥m thu·∫≠t to√°n trong nh√≥m n√†y:\nBranch and bound algorithms C√°c thu·∫≠t to√°n thu·ªôc nh√≥m Branch and bound ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c b√†i to√°n t·ªëi ∆∞u ho√° ho·∫∑c b√†i to√°n r√†ng bu·ªôc c√≥ ƒëi·ªÅu ki·ªán. Khi m√† ch√∫ng ta kh√¥ng th·ªÉ √°p d·ª•ng heuristic trong c√°c b√†i to√°n ƒë√≥. C√°ch th·ª©c ho·∫°t ƒë·ªông c·ªßa c√°c b√†i to√°n d·∫°ng n√†y l√† ph√¢n v·∫•n ƒë·ªÅ th√†nh c√°c v√πng nh·ªè s·ª≠ d·ª•ng upper bound v√† lower bound, v√† th·ª±c hi·ªán t√¨m ki·∫øm gi·∫£i ph√°p tr√™n c√°c v√πng ƒë√≥.\nLocal search T√¨m ki·∫øm c·ª•c b·ªô xem x√©t c√°c bi·∫øn th·ªÉ g·∫ßn ƒë√∫ng v√† s·ª≠ d·ª•ng c√°c bi·∫øn th·ªÉ ƒë√≥ ƒë·ªÉ c·ªë g·∫Øng c·∫£i thi·ªán n√≥ d·∫ßn d·∫ßn. ƒê√¥i khi, th·ª±c hi·ªán c√°c b∆∞·ªõc nh·∫£y ng·∫´u nhi√™n nh·∫±m tho√°t kh·ªèi t·ªëi ∆∞u c·ª•c b·ªô.\nMeta-heuristics Si√™u kinh nghi·ªám s·ª≠ d·ª•ng c√°c thu·∫≠t to√°n ti·∫øn h√≥a, b·∫Øt ch∆∞·ªõc c√°c c∆° ch·∫ø c·ªông t√°c ho·∫∑c ph√¢n t√°n ƒë∆∞·ª£c t√¨m th·∫•y trong t·ª± nhi√™n, ch·∫≥ng h·∫°n nh∆∞ ch·ªçn l·ªçc t·ª± nhi√™n ho·∫∑c c√°c h√†nh vi ƒë∆∞·ª£c l·∫•y c·∫£m h·ª©ng t·ª´ b·∫ßy ƒë√†n.\nHeuristic search Heuristic search s·ª≠ d·ª•ng h√†m l∆∞·ª£ng gi√° ƒë·ªÉ x√°c ƒë·ªãnh m·ª©c ƒë·ªô li√™n quan c·ªßa ƒëi·ªÉm d·ªØ li·ªáu v√† m·ª•c ti√™u.\nC√°c thu·∫≠t to√°n n√†y th∆∞·ªùng kh√¥ng ph√π h·ª£p v·ªõi d·ªØ li·ªáu ƒë·∫ßu v√†o l√† nhi·ªÖu, ho·∫∑c trong c√°c t√¨nh hu·ªëng m√¥ h√¨nh kh√¥ng ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a r√µ r√†ng. Ch√∫ng t·ªè ra hi·ªáu qu·∫£ trong ng·ªØ c·∫£nh ch√∫ng ta c√≥ c√°c h√†nh ƒë·ªông r√µ r√†ng v√† c·ª• th·ªÉ, v√† h·ªá th·ªëng c·∫ßn cung c·∫•p m·ªôt k·ªπ thu·∫≠t chu·∫©n ƒë·ªÉ tri·ªÉn khai c√°c h√†nh ƒë·ªông tr√™n.\nConnectionist AI l√† g√¨ C√°i t√™n ƒë∆∞·ª£c l·∫•y t·ª´ li√™n k·∫øt m·∫°ng m√† c√°c thu·∫≠t to√°n trong nh√≥m n√†y s·ª≠ d·ª•ng. K·ªπ thu·∫≠t ph·ªï bi·∫øn trong nh√≥m n√†y l√† s·ª≠ d·ª•ng Artificial Neural Network (ANN). Ch√∫ng bao g·ªìm nhi·ªÅu l·ªõp m·∫°ng, m·ªói l·ªõp s·∫Ω c√≥ nhi·ªÅu node, ch√∫ng s·∫Ω x·ª≠ l√Ω c√°c t√≠n hi·ªáu ƒë·∫ßu v√†o, k·∫øt h·ª£p ch√∫ng v·ªõi c√°c tr·ªçng s·ªë, v√† bi·∫øn ƒë·ªïi ch√∫ng tr∆∞·ªõc khi ƒë∆∞a v√†o l·ªõp ti·∫øp theo. Support Vector Machines (SVMs) c≈©ng thu·ªôc nh√≥m n√†y.\nANNs c√≥ r·∫•t nhi·ªÅu bi·∫øn th·ªÉ, v√≠ d·ª• Convolution Neural Networks (ƒë∆∞·ª£c s·ª≠ d·ª•ng ch·ªß y·∫øu trong x·ª≠ l√Ω ·∫£nh), Long Short-term Memory Networks ( th∆∞·ªùng ƒë∆∞·ª£c d√πng trong b√†i to√°n ph√¢n t√≠ch time series ho·∫∑c c√°c b√†i to√°n m√† th·ªùi gian l√† ƒë·∫∑c tr∆∞ng quan tr·ªçng, b·ªã ·∫©n ƒëi d∆∞·ªõi lƒÉng k√≠nh b√¨nh th∆∞·ªùng (vƒÉn b·∫£n :) ). Deep learning v·ªÅ c∆° b·∫£n l√† ƒë·ªìng nghƒ©a v·ªõi Artificial Neural Networks.\nGi√° tr·ªã c·ªët l√µi c·ªßa lo·∫°i k·ªπ thu·∫≠t n√†y l√† ng∆∞·ªùi d√πng kh√¥ng c·∫ßn ch·ªâ ƒë·ªãnh c√°c quy t·∫Øc c·ªßa mi·ªÅn ƒë∆∞·ª£c m√¥ h√¨nh h√≥a. M·∫°ng t·ª± ph√°t hi·ªán ra c√°c quy t·∫Øc t·ª´ training data. Ng∆∞·ªùi d√πng cung c·∫•p d·ªØ li·ªáu ƒë·∫ßu v√†o v√† d·ªØ li·ªáu ƒë·∫ßu ra m·∫´u (b·ªô d·ªØ li·ªáu c√†ng l·ªõn v√† ƒëa d·∫°ng c√†ng t·ªët). C√°c thu·∫≠t to√°n k·∫øt n·ªëi sau ƒë√≥ √°p d·ª•ng c√°c m√¥ h√¨nh h·ªìi quy th·ªëng k√™ ƒë·ªÉ ƒëi·ªÅu ch·ªânh c√°c h·ªá s·ªë tr·ªçng s·ªë c·ªßa c√°c bi·∫øn trung gian c·ªßa ch√∫ng, cho ƒë·∫øn khi t√¨m th·∫•y m√¥ h√¨nh ph√π h·ª£p nh·∫•t. C√°c tr·ªçng s·ªë ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh theo h∆∞·ªõng gi·∫£m thi·ªÉu l·ªói t√≠ch l≈©y t·ª´ t·∫•t c·∫£ c√°c ƒëi·ªÉm d·ªØ li·ªáu hu·∫•n luy·ªán, s·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t nh∆∞ gi·∫£m ƒë·ªô d·ªëc.\nV√¨ c√°c k·ªπ thu·∫≠t n√†y s·ª≠ d·ª•ng c√°c thu·∫≠t to√°n c·ª±c ti·ªÉu ho√° ƒë·ªô l·ªói, n√™n ch√∫ng v·ªën c√≥ kh·∫£ nƒÉng ch·ªëng nhi·ªÖu. Ch√∫ng s·∫Ω lo·∫°i b·ªè c√°c gi√° tr·ªã ngo·∫°i l·ªá v√† ƒë∆∞a ra gi·∫£i ph√°p ph√¢n lo·∫°i d·ªØ li·ªáu trong ph·∫°m vi sai s·ªë nh·∫•t ƒë·ªãnh.\nC√°c thu·∫≠t to√°n n√†y kh√¥ng c·∫ßn m·ªôt m√¥ h√¨nh ƒë∆∞·ª£c cung c·∫•p tr∆∞·ªõc. N√≥ ch·ªâ c·∫ßn ƒë·ªß d·ªØ li·ªáu m·∫´u v√† n√≥ s·∫Ω t·ª± suy ra m√¥ h√¨nh. ƒê√¢y l√† m·ªôt ƒë·∫∑c ƒëi·ªÉm r·∫•t m·∫°nh m·∫Ω, nh∆∞ng c≈©ng l√† m·ªôt ƒëi·ªÉm y·∫øu. C√°c t√≠nh nƒÉng ƒë·∫ßu v√†o ph·∫£i ƒë∆∞·ª£c l·ª±a ch·ªçn r·∫•t c·∫©n th·∫≠n. Ch√∫ng c≈©ng ph·∫£i ƒë∆∞·ª£c chu·∫©n h√≥a ho·∫∑c chia t·ª∑ l·ªá, ƒë·ªÉ tr√°nh m·ªôt t√≠nh nƒÉng √°p ƒë·∫£o c√°c t√≠nh nƒÉng kh√°c v√† ƒë∆∞·ª£c x·ª≠ l√Ω tr∆∞·ªõc ƒë·ªÉ c√≥ √Ω nghƒ©a h∆°n ƒë·ªëi v·ªõi vi·ªác ph√¢n lo·∫°i.\nFeature engineering th∆∞·ªùng c√≥ th·ªÉ l√† y·∫øu t·ªë quy·∫øt ƒë·ªãnh th√†nh c√¥ng ch√≠nh c·ªßa m·ªôt d·ª± √°n m√°y h·ªçc. Vi·ªác c√≥ qu√° nhi·ªÅu ƒë·∫∑c tr∆∞ng ho·∫∑c kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu m·∫´u ƒë·∫°i di·ªán cho to√†n b·ªô v·∫•n ƒë·ªÅ, c√≥ th·ªÉ d·∫´n d·∫øn overfitting ho·∫∑c underfitting. Ngay c·∫£ v·ªõi s·ª± gi√∫p ƒë·ª° c·ªßa nh√† khoa h·ªçc d·ªØ li·ªáu l√†nh ngh·ªÅ nh·∫•t, b·∫°n v·∫´n ph·∫£i ch·ªãu s·ª± ph·ª• thu·ªôc v√†o ch·∫•t l∆∞·ª£ng c·ªßa d·ªØ li·ªáu m√† b·∫°n c√≥. C√°c k·ªπ thu·∫≠t n√†y c≈©ng kh√¥ng tr√°nh kh·ªèi curse of dimensionality, ho·∫∑c s·ªë l∆∞·ª£ng input feature tƒÉng, ho·∫∑c r·ªßi ro c·ªßa gi·∫£i ph√°p kh√¥ng h·ª£p l·ªá.\nC√°c thu·∫≠t to√°n m·∫∑c nhi√™n gi·∫£ ƒë·ªãnh r·∫±ng m√¥ h√¨nh th·∫ø gi·ªõi m√† ch√∫ng ƒëang n·∫Øm b·∫Øt l√† t∆∞∆°ng ƒë·ªëi ·ªïn ƒë·ªãnh. ƒêi·ªÅu n√†y l√†m cho ch√∫ng r·∫•t hi·ªáu qu·∫£ ƒë·ªëi v·ªõi c√°c v·∫•n ƒë·ªÅ m√† lu·∫≠t ch∆°i kh√¥ng thay ƒë·ªïi nhi·ªÅu ho·∫∑c thay ƒë·ªïi v·ªõi t·ªëc ƒë·ªô ƒë·ªß ch·∫≠m ƒë·ªÉ cho ph√©p thu th·∫≠p ƒë·ªß c√°c m·∫´u d·ªØ li·ªáu m·ªõi ƒë·ªÉ ƒë√†o t·∫°o l·∫°i v√† th√≠ch ·ª©ng v·ªõi th·ª±c t·∫ø m·ªõi. Nh·∫≠n d·∫°ng h√¨nh ·∫£nh l√† c√¢u chuy·ªán th√†nh c√¥ng, b·ªüi v√¨ con ch√≥ nƒÉm nay v·ªõi nƒÉm sau th∆∞·ªùng kh√¥ng thay ƒë·ªïi nhi·ªÅu.\nCh√∫ng ta n√™n ch·ªçn c√°i n√†o Vi·ªác ch·ªçn thu·∫≠t to√°n d·ª±a v√†o v·∫•n ƒë·ªÅ ch√∫ng ta c·∫ßn gi·∫£i quy·∫øt. Ng√†y nay, vi·ªác ch·ªçn sai k·ªπ thu·∫≠t ƒëang d·∫ßn tr·ªü n√™n ph·ªï bi·∫øn. Nguy√™n nh√¢n r·∫•t nhi·ªÅu, c√≥ th·ªÉ l√† do s·ª± c∆∞·ªùng ƒëi·ªáu ho√° c·ªßa k·ªπ thu·∫≠t ƒë√≥, ho·∫∑c s·ª± thi·∫øu nh·∫≠n th·ª©c v·ªÅ b·ªëi c·∫£nh c·ªßa thu·∫≠t to√°n AI. Khi b·∫°n c·∫ßm trong tay m·ªôt c√°i b√∫a, m·ªôt th·ª© b·∫Øt b·∫Øt ƒë·∫ßu gi·ªëng m·ªôt c√°i ƒëinh.\nKhi AI ph√°t tri·ªÉn m·∫°nh m·∫Ω trong m·ªçi kh√≠a c·∫°nh c·ªßa cu·ªôc s·ªëng c·ªßa ch√∫ng ta, c√°c y√™u c·∫ßu cho AI c√†ng ng√†y c√†ng tr·ªü n√™n ph·ª©c t·∫°p h∆°n, r·∫•t c√≥ kh·∫£ nƒÉng ·ª©ng d·ª•ng c·ªßa ch√∫ng ta s·∫Ω c·∫ßn c·∫£ hai k·ªπ thu·∫≠t n√†y. D·ªØ li·ªáu ti·∫øng ·ªìn ƒë∆∞·ª£c thu th·∫≠p th√¥ng qua c√°c c·∫£m bi·∫øn c√≥ th·ªÉ ƒë∆∞·ª£c x·ª≠ l√Ω th√¥ng qua ANN ƒë·ªÉ suy ra th√¥ng tin r·ªùi r·∫°c v·ªÅ m√¥i tr∆∞·ªùng, trong khi thu·∫≠t to√°n tsymbolic s·ª≠ d·ª•ng th√¥ng tin ƒë√≥ ƒë·ªÉ t√¨m ki·∫øm kh√¥ng gian c·ªßa c√°c h√†nh ƒë·ªông kh·∫£ thi c√≥ th·ªÉ d·∫´n ƒë·∫øn m·ªôt s·ªë k·∫øt lu·∫≠n r√µ r√†ng h∆°n.\nM·ªôt thu·∫≠t to√°n h·ªçc m√°y c√≥ th·ªÉ r·∫•t hi·ªáu qu·∫£ trong vi·ªác suy lu·∫≠n m√¥i tr∆∞·ªùng xung quanh c·ªßa m·ªôt ph∆∞∆°ng ti·ªán c√° nh√¢n trong m·ªôt m·ª©c x√°c su·∫•t nh·∫•t ƒë·ªãnh, nh∆∞ng kh·∫£ nƒÉng x·∫£y ra sai s√≥t l√† kh√¥ng th·ªÉ ch·∫•p nh·∫≠n ƒë∆∞·ª£c n·∫øu sai s√≥t ƒë√≥ c√≥ th·ªÉ khi·∫øn chi·∫øc xe lao xu·ªëng v·ª±c, nguy√™n nh√¢n l√† sai s√≥t ƒë√≥ ch∆∞a c√≥ tr·ªçng training data. H∆°n n·ªØa, vi·ªác ƒë∆∞a c√¥ng ngh·ªá h·ªçc s√¢u v√†o c√°c ·ª©ng d·ª•ng quan tr·ªçng ƒëang t·ªè ra l√† m·ªôt th√°ch th·ª©c, ƒë·∫∑c bi·ªát l√† khi m·ªôt chi·∫øc xe tay ga b·ªã nh·∫ßm l·∫´n v·ªõi m·ªôt chi·∫øc d√π khi n√≥ b·ªã l·∫≠t ng·ª≠a.\nVi·ªác k·∫øt h·ª£p v·ªõi symbolic AI ƒë·∫£m b·∫£o r·∫±ng nh·ªØng g√¨ r√µ r√†ng v·ªÅ m·∫∑t logic v·∫´n ƒë∆∞·ª£c th·ª±c thi, ngay c·∫£ khi l·ªõp h·ªçc s√¢u b√™n d∆∞·ªõi n√≥i kh√°c ƒëi do m·ªôt s·ªë sai l·ªách th·ªëng k√™ ho·∫∑c s·ªë ƒë·ªçc c·∫£m bi·∫øn nhi·ªÖu. ƒêi·ªÅu n√†y ng√†y c√†ng tr·ªü n√™n quan tr·ªçng ƒë·ªëi v·ªõi c√°c ·ª©ng d·ª•ng c√≥ r·ªßi ro cao, nh∆∞ qu·∫£n l√Ω nh√† m√°y ƒëi·ªán, ƒëi·ªÅu ƒë·ªông t√†u h·ªèa, h·ªá th·ªëng l√°i t·ª± ƒë·ªông v√† ·ª©ng d·ª•ng kh√¥ng gian. H·ªá l·ª•y c·ªßa vi·ªác ph√¢n lo·∫°i sai trong c√°c h·ªá th·ªëng nh∆∞ v·∫≠y nghi√™m tr·ªçng h∆°n nhi·ªÅu so v·ªõi vi·ªác gi·ªõi thi·ªáu sai phim.\nM·ªôt h·ªá th·ªëng k·∫øt h·ª£p s·ª≠ d·ª•ng c·∫£ thu·∫≠t to√°n connectionist v√† symbolic s·∫Ω t·∫≠n d·ª•ng ƒëi·ªÉm m·∫°nh c·ªßa c·∫£ hai trong khi kh·∫Øc ph·ª•c ƒëi·ªÉm y·∫øu c·ªßa nhau. C√°c gi·ªõi h·∫°n c·ªßa vi·ªác s·ª≠ d·ª•ng m·ªôt k·ªπ thu·∫≠t ri√™ng l·∫ª ƒë√£ ƒë∆∞·ª£c x√°c ƒë·ªãnh v√† nghi√™n c·ª©u m·ªõi nh·∫•t ƒë√£ b·∫Øt ƒë·∫ßu ch·ªâ ra r·∫±ng vi·ªác k·∫øt h·ª£p c·∫£ hai ph∆∞∆°ng ph√°p c√≥ th·ªÉ d·∫´n ƒë·∫øn m·ªôt gi·∫£i ph√°p th√¥ng minh h∆°n.\nH∆∞·ªõng ph√°t tri·ªÉn ti·∫øp theo c·ªßa AI Theo quy lu·∫≠t t·ª± nhi√™n, c√°i g√¨ ƒë·∫°t m·ª©c ƒë·ªô c·ª±c th·ªãnh th√¨ l√† th·ªùi ƒëi·ªÉm b·∫Øt ƒë·∫ßu d·∫´n t·ªõi c·ª±c suy, AI c≈©ng kh√¥ng ngo·∫°i l·ªá, do ƒë√≥, theo ph·ªèng ƒëo√°n, AI c√≥ th·ªÉ ti·∫øn ho√° theo c√°c chi·ªÅu h∆∞·ªõng sau:\nTi·∫øn ho√° c·ªßa Symbolic AI Symbolic AI s·∫Ω ti·∫øn ho√° b·∫±ng m·ªôt c√°ch n√†o ƒë√≥, s·∫Ω quay l·∫°i th·ªëng tr·ªã\nK·∫øt h·ª£p Symbolic AI v√† Connectionist AI Connectionist AI v√† Symbolic AI b·∫±ng m·ªôt c√°ch n√†o ƒë√≥ s·∫Ω k·∫øt h·ª£p v·ªõi nhau\nM·ªôt h∆∞·ªõng ƒëi m·ªõi kh√°c ƒë∆∞·ª£c khai ph√° ra, v√† c·∫°nh trang s√≤ng ph·∫≥ng v·ªõi Symbolic AI l·∫´n Connectionist AI ƒêi·ªÅu n√†y kh√° kh√≥, nh∆∞ng kh√¥ng g√¨ l√† kh√¥ng th·ªÉ.\nD√π AI c√≥ ti·∫øn ho√° nh∆∞ th·∫ø n√†o, chung quy l·∫°i th√¨ ch√∫ng ƒë∆∞·ª£c t·∫°o ra ƒë·ªÉ ph·ª•c v·ª• nhu c·∫ßu v√† m·ª•c ƒë√≠ch c·ªßa con ng∆∞·ªùi.\nTham kh·∫£o https://towardsdatascience.com/symbolic-vs-connectionist-a-i-8cf6b656927\nhttps://blog.re-work.co/the-difference-between-symbolic-ai-and-connectionist-ai/\nhttps://medium.com/synthetic-intelligence/dialectic-of-ai-connectionism-vs-symbolism-d8b9888d4268\nhttps://www.forbes.com/sites/forbestechcouncil/2020/09/01/symbolism-versus-connectionism-in-ai-is-there-a-third-way/?sh=2f3074fb7549\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo\n","date":"Feb 18, 2023","img":"https://unsplash.it/1920/1080?image=16","permalink":"/blog/2023-02-18-symbolic-vs-connectionist/","series":null,"tags":["RFM","Recommendation","Marketing"],"title":"Symbolic AI V√† Connectionist AI"},{"categories":null,"content":" 1. Gi·ªõi thi·ªáu RFM 2. Gi·ªõi thi·ªáu data v√† t√¨m hi·ªÉu data 2.1 Gi·ªõi thi·ªáu data 2.2 Th·ª±c hi·ªán m·ªôt s·ªë ph√©p th·ªëng k√™ tr√™n d·ªØ li·ªáu 2.3 Ph√¢n t√≠ch d·ªØ li·ªáu 2.3.1 T√≠nh doanh thu theo th√°ng 2.3.2 Th·ªëng k√™ tƒÉng tr∆∞·ªüng c·ªßa doanh thu 2.3.3 Ph√¢n t√≠ch s·ªë l∆∞·ª£ng kh√°ch h√†ng th√°ng 2.3.4 S·ªë ƒë∆°n ƒë·∫∑t h√†ng trong th√°ng 2.3.5 Doanh thu trung b√¨nh m·ªói ƒë∆°n h√†ng 2.3.6 S·ªë l∆∞·ª£ng kh√°ch h√†ng m·ªõi/ c≈© theo t·ª´ng th√°ng 2.3.7 T·ª∑ l·ªá tƒÉng tr∆∞·ªüng kh√°ch h√†ng m·ªõi 2.3.8 T·ª∑ l·ªá gi·ªØ ch√¢n kh√°ch h√†ng c≈© h√†ng th√°ng 3. Ph√¢n Kh√∫c Kh√°ch H√†ng 3.1 Clean data 3.1 T√≠nh Recency 3.2 T√≠nh Frequency 3.3 T√≠nh Monetary 3.4 T·∫°o b·∫£ng RFM 3.5 Ph√¢n nh√≥m kh√°ch h√†ng s·ª≠ d·ª•ng RFM Tham kh·∫£o 1. Gi·ªõi thi·ªáu RFM RFM l√† 3 k√Ω t·ª± ƒë·∫ßu ti√™n c·ªßa Recency, frequency, monetary. N√≥ l√† c√¥ng c·ª• ph√¢n t√≠ch ƒë∆∞·ª£c marketing s·ª≠ d·ª•ng ƒë·ªÉ ƒë·ªãnh danh kh√°ch h√†ng c·ªßa c√¥ng ty d·ª±a tr√™n th√≥i quen mua s·∫Øm t·ª± nhi√™n c·ªßa h·ªç.\nRFM ph√¢n t√≠ch v√† ƒë√°nh gi√° kh√°ch h√†ng b·∫±ng c√°ch t√≠nh ƒëi·ªÉm h√†nh vi mua s·∫Øm c·ªßa h·ªç d·ª±a tr√™n ba ti√™u ch√≠:\nRecency: Kho·∫£ng th·ªùi gian mua h√†ng g·∫ßn nh·∫•t l√† bao l√¢u. N·∫øu h·ªç ƒë√£ mua h√†ng g·∫ßn ƒë√¢y, x√°c su·∫•t h·ªç s·∫Ω mua th√™m m·ªôt l·∫ßn n·ªØa r·∫•t cao. Tuy nhi√™n, n·∫øu kh√°ch h√†ng kh√¥ng th·ª±c hi·ªán b·∫•t k·ª≥ m·ªôt giao d·ªãch n√†o trong m·ªôt kho·∫£ng th·ªùi gian d√†i, ch√∫ng ta c√≥ th·ªÉ l√¥i k√©o h·ªç b·∫±ng m·ªôt offer ƒë·∫∑c bi·ªát, ho·∫∑c gi·ªõi thi·ªáu l·∫°i th∆∞∆°ng hi·ªáu c·ªßa m√¨nh cho h·ªç.\nFrequency: T·∫ßn su·∫•t mua h√†ng c·ªßa kh√°ch h√†ng. N·∫øu kh√°ch h√†ng c√≥ t·∫ßng su·∫•t mua d√†y ƒë·∫∑c, ch√∫ng ta s·∫Ω bi·∫øt th√≥i quen v√† s·ªü th√≠ch c·ªßa h·ªç. N·∫øu h·ªç ch·ªâ mua m·ªôt l·∫ßn v√† ch∆∞a bao gi·ªù tr·ªü l·∫°i, h·ªç c√≥ th·ªÉ l√† m·ªôt ·ª©ng vi√™n t·ªët ƒë·ªÉ th·ª±c hi·ªán b√†i kh·∫£o s√°t s·ª± h√†i l√≤ng c·ªßa kh√°ch h√†ng.\nMonetary: S·ªë ti·ªÅn trung b√¨nh kh√°ch h√†ng s·ª≠ d·ª•ng tr√™n m·ªói giao d·ªãch. Tuy nhi√™n, ƒë·ª´ng qu√° ch√∫ tr·ªçng v√†o con s·ªë n√†y. T·∫•t c·∫£ c√°c giao d·ªãch mua h√†ng ƒë·ªÅu c√≥ gi√° tr·ªã. Monetary t√°c ƒë·ªông tr·ª±c ti·∫øp ƒë·∫øn doanh thu c·ªßa c√¥ng ty, t√°c ƒë·ªông gi√°n ti·∫øp v·ªõi 2 ch·ªâ s·ªë ·ªü tr√™n kia. N·∫øu ch√∫ng ta g·∫∑p m·ªôt kh√°ch h√†ng th·ª±c hi·ªán nhi·ªÅu l·∫ßn mua h√†ng g·∫ßn ƒë√¢y v·ªõi m·ª©c gi√° cao, nh·ªØng ng∆∞·ªùi ƒë√≥ c√≥ th·ªÉ l√† kh√°ch h√†ng trung th√†nh c·ªßa ch√∫ng ta.\nRMF c√≥ thang ƒëi·ªÉm t·ª´ 1-5 ( 1 l√† t·ªá, 5 l√† t·ªët) c·ªßa m·ªói kh√°ch h√†ng cho m·ªói ti√™u ch√≠.\nRFM gi√∫p c√¥ng ty c√≥ kh·∫£ nƒÉng d·ª± ƒëo√°n nh·ªØng kh√°ch h√†ng n√†o c√≥ kh·∫£ nƒÉng cao s·∫Ω mua l·∫°i s·∫£n ph·∫©m c·ªßa h·ªç, doanh thu ƒë·∫øn t·ª´ kh√°ch h√†ng m·ªõi l√† bao nhi√™u, c√°ch bi·∫øn c∆° h·ªôi mua h√†ng th√†nh th√≥i quen.\n2. Gi·ªõi thi·ªáu data v√† t√¨m hi·ªÉu data 2.1 Gi·ªõi thi·ªáu data D·ªØ li·ªáu ·ªü b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng t·ª´ ngu·ªìn https://www.kaggle.com/datasets/lissetteg/ecommerce-dataset.\nCode load c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n1 2# This Python 3 environment comes with many helpful analytics libraries installed 3# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python 4# For example, here\u0026#39;s several helpful packages to load in 5 6import numpy as np # linear algebra 7import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) 8 9# Input data files are available in the \u0026#34;../input/\u0026#34; directory. 10 11import time, warnings 12import datetime as dt 13 14#visualizations 15import matplotlib.pyplot as plt 16from pandas.plotting import scatter_matrix 17%matplotlib inline 18import seaborn as sns 19 20warnings.filterwarnings(\u0026#34;ignore\u0026#34;) Code load data v√† in ra 20 d√≤ng ƒë·∫ßu ti√™n\n1 2#load the dataset 3retail_df = pd.read_csv(\u0026#39;../input/data.csv\u0026#39;,encoding=\u0026#34;ISO-8859-1\u0026#34;,dtype={\u0026#39;CustomerID\u0026#39;: str,\u0026#39;InvoiceID\u0026#39;: str}) 4retail_df.head(20) H√¨nh 1: T·ªïng quan v·ªÅ d·ªØ li·ªáu\n2.2 Th·ª±c hi·ªán m·ªôt s·ªë ph√©p th·ªëng k√™ tr√™n d·ªØ li·ªáu Sau khi nh·∫≠n d·ªØ li·ªáu, ch√∫ng ta c·∫ßn xem x√©t s∆° l∆∞·ª£c t·ªïng quan v·ªÅ d·ªØ li·ªáu b·∫±ng m·ªôt s·ªë h√†m th·ªëng k√™ c∆° b·∫£n\n1 2print(retail_df.describe()) 3print(retail_df.info()) H√¨nh 2: Ph√¢n t√≠ch x√°c su·∫•t v·ªÅ d·ªØ li·ªáu\nD·ª±a v√†o k·∫øt qu·∫£ h√¨nh 2, ch√∫ng ta th·∫•y r·∫±ng data c√≥ t·ªïng c·ªông 541909 d√≤ng, 8 c·ªôt, trong ƒë√≥ c√≥ m·ªôt s·ªë ch·ªó c√≥ gi√° tr·ªã null. C·ªôt CustomerID c√≥ gi√° tr·ªã null nhi·ªÅu nh·∫•t.\n2.3 Ph√¢n t√≠ch d·ªØ li·ªáu 2.3.1 T√≠nh doanh thu theo th√°ng Doanh thu c·ªßa m·ªôt ƒë∆°n h√†ng b·∫±ng s·ªë l∆∞·ª£ng nh√¢n ƒë∆°n gi√°.\nC√¥ng vi·ªác c·∫ßn l√†m:\nT·∫°o m·ªôt key chung ƒë·∫°i di·ªán cho bi·∫øn th√°ng trong nƒÉm ( ·ªü ƒë√¢y m√¨nh ƒë·∫∑t t√™n l√† MonthKey) T√≠nh doanh thu Group doanh thu theo th√°ng In ra m√†n h√¨nh doanh thu theo th√°ng V·∫Ω chart doanh thu theo th√°ng ƒêo·∫°n code m·∫´u m√¥ t·∫£ c√°c b∆∞·ªõc c·∫ßn l√†m ·ªü tr√™n\n1 2#converting the type of Invoice Date Field from string to datetime. 3retail_df[\u0026#39;InvoiceDate\u0026#39;] = pd.to_datetime(retail_df[\u0026#39;InvoiceDate\u0026#39;]) 4 5#creating MonthKey field for reporting and visualization 6retail_df[\u0026#39;MonthKey\u0026#39;] = retail_df[\u0026#39;InvoiceDate\u0026#39;].map(lambda date: 100*date.year + date.month) 7 8#calculate Revenue for each row and create a new dataframe with MonthKey - Revenue columns 9retail_df[\u0026#39;Revenue\u0026#39;] = retail_df[\u0026#39;UnitPrice\u0026#39;] * retail_df[\u0026#39;Quantity\u0026#39;] 10revenue_by_month = retail_df.groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;Revenue\u0026#39;].sum().reset_index() 11print(revenue_by_month) 12 13# plot data 14revenue_by_month[\u0026#39;MonthKey\u0026#39;] = revenue_by_month[\u0026#39;MonthKey\u0026#39;].apply(str) 15%matplotlib inline 16plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 17plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;Revenue\u0026#39;, data=revenue_by_month, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 18plt.title(\u0026#34;Revenue by Month\u0026#34;) 19plt.show() K·∫øt qu·∫£ ch√∫ng m√¨nh nh·∫≠n ƒë∆∞·ª£c\n1 2 3\tMonthKey\tRevenue 40\t201012\t748957.020 51\t201101\t560000.260 62\t201102\t498062.650 73\t201103\t683267.080 84\t201104\t493207.121 95\t201105\t723333.510 106\t201106\t691123.120 117\t201107\t681300.111 128\t201108\t682680.510 139\t201109\t1019687.622 1410\t201110\t1070704.670 1511\t201111\t1461756.250 1612\t201112\t433668.010 H√¨nh 3: Doanh thu theo th√°ng\nNh√¨n v√†o h√¨nh 3 ·ªü tr√™n, ch√∫ng ta th·∫•y r·∫±ng, doanh thu b·∫Øt ƒë·∫ßu tƒÉng t·ª´ th√°ng 8, ƒë·∫°t ƒë·ªânh ƒëi·ªÉm ·ªü th√°ng 11, th√°ng 12 doanh thu si√™u th·∫•p, ng√≥ qua th√°ng 12 nƒÉm ngo√°i th√¨ doanh thu kh√° ·ªïn, n√™n c√≥ th·ªÉ t·∫°m k·∫øt lu·∫≠n l√† data th√°ng 12 nƒÉm hi·ªán t·∫°i c√≥ th·ªÉ ch∆∞a ƒë·ªß th√°ng. Ch√∫ng ta c√≥ th·ªÉ b·ªè data th√°ng 12 ra kh·ªèi dataset ƒë·ªÉ tr√°nh b·ªã nhi·ªÖu.\n2.3.2 Th·ªëng k√™ tƒÉng tr∆∞·ªüng c·ªßa doanh thu ƒê·ªÉ t√≠nh tƒÉng tr∆∞·ªüng doanh thu, ta l·∫•y doanh thu th√°ng hi·ªán t·∫°i chia cho doanh thu th√°ng tr∆∞·ªõc -1\nTrong pandas, ch√∫ng ta s·ª≠ d·ª•ng h√†m pct_change\n1 2revenue_by_month[\u0026#39;MonthlyGrowth\u0026#39;] = revenue_by_month[\u0026#39;Revenue\u0026#39;].pct_change() 3 4 5# Plot data 6 7plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 8plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;MonthlyGrowth\u0026#39;, data=revenue_by_month, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 9plt.plot(range(1,len(revenue_by_month.index)+1),[0 for i in range(len(revenue_by_month.index))], color=\u0026#34;k\u0026#34;, lw=2.5) 10plt.title(\u0026#34;Monthly Revenue Growth Rate\u0026#34;) 11plt.show() H√¨nh 4: Bi·∫øn ƒë·ªông doanh thu theo th√°ng\nQua s∆° ƒë·ªì h√¨nh 4, ch√∫ng ta th·∫•y r·∫±ng ·ªü th√°ng 4 c√≥ s·ª± s·ª•t gi·∫£m m·∫°nh v·ªÅ doanh thu, nh√≥m kinh doanh c·∫ßn ph·∫£i ph√¢n t√≠ch k·ªπ h∆°n c√°c y·∫øu t·ªë ·∫£nh h∆∞·ªüng ƒë·∫øn s·ª± s·ª•t gi·∫£m nghi√™m tr·ªçng v·ªÅ m·∫∑t doanh thu trong th√°ng n√†y.\n2.3.3 Ph√¢n t√≠ch s·ªë l∆∞·ª£ng kh√°ch h√†ng th√°ng ƒê·ªÉ t√≠nh l∆∞·ª£t kh√°ch mua h√†ng h·∫±ng th√°ng, ch√∫ng ta ƒë·∫øm kh√¥ng tr√πng m√£ kh√°ch h√†ng trong th√°ng\n1 2customer_by_month = retail_df.groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;CustomerID\u0026#39;].nunique().reset_index() 3customer_by_month 4 5 6customer_by_month[\u0026#39;MonthKey\u0026#39;] = customer_by_month[\u0026#39;MonthKey\u0026#39;].apply(str) 7%matplotlib inline 8plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 9plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;CustomerID\u0026#39;, data=customer_by_month, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 10plt.title(\u0026#34;Customer by Month\u0026#34;) 11plt.show() 1 2 3\tMonthKey\tCustomerID 40\t201012\t948 51\t201101\t783 62\t201102\t798 73\t201103\t1020 84\t201104\t899 95\t201105\t1079 106\t201106\t1051 117\t201107\t993 128\t201108\t980 139\t201109\t1302 1410\t201110\t1425 1511\t201111\t1711 1612\t201112\t686 H√¨nh 5: L∆∞·ª£t kh√°ch theo th√°ng\nNh·∫≠n x√©t r·∫±ng, l∆∞·ª£t kh√°ch tƒÉng t·ª´ th√°ng 8 tr·ªü v·ªÅ sau, t·ª´ th√°ng 5 ƒë·∫øn th√°ng 8 th√¨ l∆∞·ª£t kh√°ch gi·∫£m nh·∫π, ƒë·ªÅu. Th√°ng 1 v√† 2 l∆∞·ª£t kh√°ch r·∫•t th·∫•p.\n2.3.4 S·ªë ƒë∆°n ƒë·∫∑t h√†ng trong th√°ng C≈©ng gi·ªëng nh∆∞ l∆∞·ª£t kh√°ch, ch√∫ng ta s·∫Ω ƒë·∫øm s·ªë l∆∞·ª£ng InvoiceNo trong t·ª´ng th√°ng\n1 2order_by_month = retail_df.groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;InvoiceNo\u0026#39;].count().reset_index() 3order_by_month 4order_by_month[\u0026#39;MonthKey\u0026#39;] = order_by_month[\u0026#39;MonthKey\u0026#39;].apply(str) 5%matplotlib inline 6plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 7plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;InvoiceNo\u0026#39;, data=order_by_month, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 8plt.title(\u0026#34;Count total order in Month\u0026#34;) 9plt.show() H√¨nh 6: S·ªë l∆∞·ª£ng ƒë∆°n ƒë·∫∑t h√†ng trong th√°ng\nT·ª´ th√°ng 5 ƒë·∫øn th√°ng 7, s·ªë l∆∞·ª£ng ƒë∆°n ƒë·∫∑t h√†ng tƒÉng nh·∫π, t·ª∑ l·ªá ngh·ªãch v·ªõi l∆∞·ª£t kh√°ch\nT·ª´ th√°ng 8 tr·ªü ƒëi, s·ªë ƒë∆°n ƒë·∫∑t h√†ng tƒÉng cao, t·ª∑ l·ªá thu·∫≠n v·ªõi l∆∞·ª£t kh√°ch\n2.3.5 Doanh thu trung b√¨nh m·ªói ƒë∆°n h√†ng Trong pandas, ch√∫ng ta ch·ªâ c·∫ßn g·ªçi h√†m mean ƒë·ªÉ t√≠nh trung b√¨nh\n1 2avg_order_revenue = retail_df.groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;Revenue\u0026#39;].mean().reset_index() 3 4avg_order_revenue[\u0026#39;MonthKey\u0026#39;] = avg_order_revenue[\u0026#39;MonthKey\u0026#39;].apply(str) 5 6# Plot regression line 7 8plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 9plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;Revenue\u0026#39;, data=avg_order_revenue, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 10plt.title(\u0026#34;Average Revenue per Order\u0026#34;) 11plt.show() H√¨nh 7: Doanh thu trung b√¨nh m·ªói ƒë∆°n h√†ng\nNh·∫≠n x√©t r·∫±ng, th√°ng 10, 11, l∆∞·ª£t kh√°ch tƒÉng, s·ªë l∆∞·ª£ng ƒë∆°n h√†ng tƒÉng, nh∆∞ng trung b√¨nh m·ªói ƒë∆°n h√†ng l·∫°i th·∫•p.\n2.3.6 S·ªë l∆∞·ª£ng kh√°ch h√†ng m·ªõi/ c≈© theo t·ª´ng th√°ng Kh√°ch h√†ng m·ªõi v√† kh√°ch h√†ng c≈© ƒë·ªÅu ƒë√≥ng vai tr√≤ r·∫•t quan tr·ªçng trong chi·∫øn l∆∞·ª£c marketing. Vi·ªác gi·ªØ ch√¢n kh√°ch h√†ng c≈© gi√∫p ch√∫ng ta hi·ªÉu h∆°n v·ªÅ h·ªç v√† ph·ª•c v·ª• h·ªç t·ªët h∆°n. Vi·ªác ph√°t tri·ªÉn kh√°ch h√†ng m·ªõi gi√∫p ch√∫ng ta ph√°t tri·ªÉn l·ªõn l√™n.\nTrong ng·ªØ c·∫£nh b√†i n√†y, ch√∫ng ta s·∫Ω x√©t y·∫øu t·ªët kh√°ch h√†ng m·ªõi/c≈© nh∆∞ sau\nKh√°ch h√†ng m·ªõi l√† kh√°ch h√†ng tr∆∞·ªõc ƒë√≥ ch∆∞a t·ª´ng mua h√†ng. Kh√¥ng quan t√¢m th√°ng hi·ªán t·∫°i kh√°ch ƒë√£ mua bao nhi√™u ƒë∆°n.\nKh√°ch h√†ng c≈© l√† kh√°ch h√†ng ƒë√£ mua √≠t nh·∫•t 1 ƒë∆°n h√†ng ·ªü th√°ng tr∆∞·ªõc ƒë√≥.\nDo ƒë∆°n v·ªã ch√∫ng ta th·ªëng k√™ t√≠nh b·∫±ng th√°ng, cho n√™n n·∫øu 1 kh√°ch h√†ng c√≥ mua 2 ho·∫∑c nhi·ªÅu h∆°n ƒë∆°n h√†ng ·ªü th√°ng hi·ªán t·∫°i, ch∆∞a t·ª´ng mua ƒë∆°n h√†ng n√†o ·ªü c√°c th√°ng tr∆∞·ªõc ƒë√≥, kh√°ch h√†ng ƒë√≥ ƒë∆∞·ª£c coi l√† kh√°ch h√†ng m·ªõi.\nK·ªπ thu·∫≠t l·∫≠p tr√¨nh ·ªü ƒë√¢y nh∆∞ sau:\nL·∫•y ra danh s√°ch kh√°ch h√†ng v√† ng√†y mua h√†ng ƒë·∫ßu ti√™n c·ªßa h·ªç\nQuy ƒë·ªïi ng√†y mua h√†ng ƒë·∫ßu ti√™n th√†nh th√°ng mua h√†ng ƒë·∫ßu ti√™n\nT·∫°o th√™m c·ªôt lo·∫°i kh√°ch h√†ng cho t·ª´ng ƒë∆°n h√†ng (UserType). G√°n m·∫∑c ƒë·ªãnh UserType = New. N·∫øu th√°ng l√™n ƒë∆°n l·ªõn h∆°n th√°ng mua ƒë·∫ßu ti√™n -\u0026gt; ƒë∆°n h√†ng c·ªßa kh√°ch c≈© (UserType=Existing).\n1 2create a dataframe contaning CustomerID and first purchase date 3df_min_date_purchase =retail_df.groupby(\u0026#39;CustomerID\u0026#39;).InvoiceDate.min().reset_index() 4df_min_date_purchase.columns = [\u0026#39;CustomerID\u0026#39;,\u0026#39;MinPurchaseDate\u0026#39;] 5df_min_date_purchase[\u0026#39;MinMonthKey\u0026#39;] = df_min_date_purchase[\u0026#39;MinPurchaseDate\u0026#39;].map(lambda date: 100*date.year + date.month) 6 7#merge first purchase date column to our main dataframe (tx_uk) 8retail_new_df = pd.merge(retail_df, df_min_date_purchase, on=\u0026#39;CustomerID\u0026#39;) 9 10retail_new_df.head() 11 12#create a column called User Type and assign Existing 13#if User\u0026#39;s First Purchase Year Month before the selected Invoice Year Month 14retail_new_df[\u0026#39;UserType\u0026#39;] = \u0026#39;New\u0026#39; 15retail_new_df.loc[retail_new_df[\u0026#39;MonthKey\u0026#39;]\u0026gt;retail_new_df[\u0026#39;MinMonthKey\u0026#39;],\u0026#39;UserType\u0026#39;] = \u0026#39;Existing\u0026#39; 16 17#calculate the Revenue per month for each user type 18revenue_per_month = retail_new_df.groupby([\u0026#39;MonthKey\u0026#39;,\u0026#39;UserType\u0026#39;])[\u0026#39;Revenue\u0026#39;].sum().reset_index() 19 20#filtering the dates and plot the result 21revenue_per_month = revenue_per_month.query(\u0026#34;MonthKey != 201012 and MonthKey != 201112\u0026#34;) 22 23revenue_per_month[\u0026#39;MonthKey\u0026#39;] = revenue_per_month[\u0026#39;MonthKey\u0026#39;].apply(str) 24revenue_per_month.set_index(\u0026#39;MonthKey\u0026#39;,inplace=True) 25# Plot regression line 26 27plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 28fig, ax = plt.subplots() 29for label, grp in revenue_per_month.groupby(\u0026#39;UserType\u0026#39;): 30 grp.plot(x = grp.index, y = \u0026#39;Revenue\u0026#39;,ax = ax, label = label,style=\u0026#39;.-\u0026#39;) 31plt.title(\u0026#34;Old and New user\u0026#34;) 32plt.show() H√¨nh 8: S·ªë l∆∞·ª£ng kh√°ch h√†ng m·ªõi/ c≈© theo t·ª´ng th√°ng\nNh·∫≠n x√©t r·∫±ng, doanh thu cho kh√°ch c≈© tƒÉng d·∫ßn theo th·ªùi gian, c√≤n doanh thu cho kh√°ch m·ªõi c√≥ v·∫ª gi·∫£m. ƒê·ªÉ ch·∫Øc ch·∫Øn, ch√∫ng ta th·ª≠ v·∫Ω ra t·ª∑ l·ªá tƒÉng tr∆∞·ªüng kh√°ch h√†ng m·ªõi xem sao\n2.3.7 T·ª∑ l·ªá tƒÉng tr∆∞·ªüng kh√°ch h√†ng m·ªõi Ta t√≠nh t·ª∑ l·ªá kh√°ch h√†ng m·ªõi / kh√°ch h√†ng c≈© theo t·ª´ng th√°ng\nTrong pandas, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng h√†m crosstab\n1 2new_user_ratio = retail_new_df.query(\u0026#34;UserType == \u0026#39;New\u0026#39;\u0026#34;).groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;CustomerID\u0026#39;].nunique()/retail_new_df.query(\u0026#34;UserType == \u0026#39;Existing\u0026#39;\u0026#34;).groupby([\u0026#39;MonthKey\u0026#39;])[\u0026#39;CustomerID\u0026#39;].nunique() 3new_user_ratio = new_user_ratio.reset_index() 4new_user_ratio = new_user_ratio.dropna() 5new_user_ratio.columns = [\u0026#34;MonthKey\u0026#34;,\u0026#34;NewCustomerRatio\u0026#34;] 6 7new_user_ratio = new_user_ratio.query(\u0026#34;MonthKey != 201012 and MonthKey != 201112\u0026#34;) 8new_user_ratio[\u0026#39;MonthKey\u0026#39;] = new_user_ratio[\u0026#39;MonthKey\u0026#39;].apply(str) 9 10# Plot regression line 11 12plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 13plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;NewCustomerRatio\u0026#39;, data=new_user_ratio, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 14plt.title(\u0026#34;New Customer Ratio\u0026#34;) 15plt.show() H√¨nh 9: T·ª∑ l·ªá tƒÉng tr∆∞·ªüng kh√°ch h√†ng m·ªõi\nNh∆∞ h√¨nh tr√™n, ch√∫ng ta th·∫•y r·∫±ng t·ª∑ l·ªá kh√°ch h√†ng m·ªõi / kh√°ch h√†ng c≈© gi·∫£m d·∫ßn theo th·ªùi gian\n2.3.8 T·ª∑ l·ªá gi·ªØ ch√¢n kh√°ch h√†ng c≈© h√†ng th√°ng Kh√°ch h√†ng c≈© ƒë∆∞·ª£c hi·ªÉu theo nghƒ©a l√† kh√°ch h√†ng th√°ng tr∆∞·ªõc c√≥ mua, th√°ng n√†y c√≥ mua\nT·ª∑ l·ªá gi·ªØ ch√¢n kh√°ch h√†ng l√† t·ª∑ l·ªá kh√°ch h√†ng c≈© mua h√†ng / t·ªïng kh√°ch h√†ng trong th√°ng\nCh√∫ng ta s·ª≠ d·ª•ng h√†m crosstab tr√™n kh√°ch h√†ng v√† th√°ng, ƒë·ªÉ xem th·ª≠ th√°ng ƒë√≥ kh√°ch c√≥ mua h√†ng hay kh√¥ng.\n1#identify which users are active by looking at their revenue per month 2df_user_purchase = retail_df.groupby([\u0026#39;CustomerID\u0026#39;,\u0026#39;MonthKey\u0026#39;])[\u0026#39;Revenue\u0026#39;].sum().reset_index() 3 4#create retention matrix with crosstab 5df_retention = pd.crosstab(df_user_purchase[\u0026#39;CustomerID\u0026#39;], df_user_purchase[\u0026#39;MonthKey\u0026#39;]).reset_index() 6 7print(df_retention.head()) 8 9#create an array of dictionary which keeps Retained \u0026amp; Total User count for each month 10months = df_retention.columns[2:] 11retention_array = [] 12for i in range(len(months)-1): 13 retention_data = {} 14 selected_month = months[i+1] 15 prev_month = months[i] 16 retention_data[\u0026#39;MonthKey\u0026#39;] = int(selected_month) 17 retention_data[\u0026#39;TotalUserCount\u0026#39;] = df_retention[selected_month].sum() 18 retention_data[\u0026#39;RetainedUserCount\u0026#39;] = df_retention[(df_retention[selected_month]\u0026gt;0) \u0026amp; (df_retention[prev_month]\u0026gt;0)][selected_month].sum() 19 retention_array.append(retention_data) 20 21#convert the array to dataframe and calculate Retention Rate 22df_retention = pd.DataFrame(retention_array) 23df_retention[\u0026#39;RetentionRate\u0026#39;] = df_retention[\u0026#39;RetainedUserCount\u0026#39;]/df_retention[\u0026#39;TotalUserCount\u0026#39;] 24 25df_retention = df_retention.query(\u0026#34;MonthKey != 201012 and MonthKey != 201112\u0026#34;) 26df_retention[\u0026#39;MonthKey\u0026#39;] = df_retention[\u0026#39;MonthKey\u0026#39;].apply(str) 27 28# Plot regression line 29 30plt.rcParams[\u0026#34;figure.figsize\u0026#34;] = [20, 10] 31plt.plot(\u0026#39;MonthKey\u0026#39;, \u0026#39;RetentionRate\u0026#39;, data=df_retention, linestyle=\u0026#39;-\u0026#39;, marker=\u0026#39;o\u0026#39;) 32plt.title(\u0026#34;Monthly Retention Rate\u0026#34;) 33plt.show() K·∫øt qu·∫£\n1# h√†m crosstab tr·∫£ ra ma tr·∫≠n t∆∞∆°ng quan gi·ªØa kh√°ch h√†ng v√† th√°ng, v√≠ d·ª• nh∆∞ kh√°ch h√†ng 12346 th√°ng 201012 kh√¥ng c√≥ mua h√†ng, nh∆∞ng 201101 l·∫°i c√≥ 2\u0026gt;\u0026gt; print(df_retention.head()) 3MonthKey CustomerID 201012 201101 201102 201103 201104 201105 201106 \\ 40 12346 0 1 0 0 0 0 0 51 12347 1 1 0 0 1 0 1 62 12348 1 1 0 0 1 0 0 73 12349 0 0 0 0 0 0 0 84 12350 0 0 1 0 0 0 0 9 10MonthKey 201107 201108 201109 201110 201111 201112 110 0 0 0 0 0 0 121 0 1 0 1 0 1 132 0 0 1 0 0 0 143 0 0 0 0 1 0 154 0 0 0 0 0 0 H√¨nh 10: T·ª∑ l·ªá gi·ªØ ch√¢n kh√°ch h√†ng c≈©\nNh√¨n h√¨nh, ta th·∫•y r·∫±ng kh√°ch h√†ng c≈© mua l·∫°i kh√° nhi·ªÅu ·ªü giai ƒëo·∫°n th√°ng 6 ƒë·∫øn th√°ng 8, sau ƒë√≥ t·ª∑ l·ªá l·∫°i tr·ªü l·∫°i b√¨nh th∆∞·ªùng.\n3. Ph√¢n Kh√∫c Kh√°ch H√†ng ·ªû m·ª•c tr√™n, ch√∫ng ta ƒë√£ ph√¢n t√≠ch d·ªØ li·ªáu c·ªßa c√¥ng ty b√°n l·∫ª tr·ª±c tuy·∫øn v√† t√¨m ra y·∫øu t·ªë ·∫£nh h∆∞·ªüng ƒë·∫øn doanh thu c·ªßa c√¥ng ty. ·ªû m·ª•c n√†y, ch√∫ng ta s·∫Ω ti·∫øn h√†nh ph√¢n lo·∫°i kh√°ch h√†ng theo nh√≥m, ƒë·ªÉ ph·ª•c v·ª• cho nhu c·∫ßu marketing sau n√†y.\nCh√∫ng ta ph·∫£i ti·∫øn h√†nh ph√¢n lo·∫°i kh√°ch h√†ng, b·ªüi v√¨ ch√∫ng ta kh√¥ng th·ªÉ ƒë·ªëi x·ª≠ v·ªõi t·∫•t c·∫£ kh√°ch h√†ng gi·ªëng nhau ƒë∆∞·ª£c. V√≠ d·ª• l√† kh√¥ng th·ªÉ g·ª≠i chi·∫øn d·ªãch marketing v·ªÅ th·ªãt cho ng∆∞·ªùi ƒÉn chay. Ho·∫∑c b√°n l∆∞·ª£c cho nh√† s∆∞ (ƒë√¢y l√† v√≠ d·ª• minh ho·∫° c·ªßa m√¨nh nha, c√≤n tr√™n c√≥ v√†i case-study v·ªÅ b√°n c√°c s·∫£n ph·∫©m ƒë√≥ cho ƒë·ªëi t∆∞·ª£ng ƒë√≥, m√¨nh kh√¥ng n√≥i v·ªÅ nh·ªØng tr∆∞·ªùng h·ª£p ƒë√≥ nha).\n·ªû ph·∫ßn n√†y, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu nhu c·∫ßu kh√°ch h√†ng s·ª≠ d·ª•ng m√¥ h√¨nh RFB.\nNh∆∞ ƒë√£ ƒë·ªÅ c·∫≠p ·ªü m·ª•c 1, m√¥ h√¨nh RFB bao g·ªìm Recency, Frequency and Monetary\n3.1 Clean data ƒê·ªÉ m√¥ h√¨nh ch√≠nh x√°c h∆°n, ch√∫ng ta s·∫Ω clean data, tr·∫£i qua c√°c b∆∞·ªõc sau:\nLo·∫°i ra c√°c ƒë∆°n h√†ng c√≥ Quantity \u0026lt;=0\nLo·∫°i b·ªè nh·ªØng ƒë∆°n h√†ng CustomerID NA\nLo·∫°i b·ªè nh·ªØng ƒë∆°n h√†ng b√°n th√°ng 12 nƒÉm 2010\nLo·∫°i b·ªè nh·ªØng ƒë∆°n h√†ng b√°n th√°ng 12 nƒÉm 2011, do ph√¢n t√≠ch ·ªü tr√™n l√† data th√°ng 12 kh√¥ng ƒë·ªß.\n1retail_rfm_df = retail_df.copy() 2#remove canceled orders 3retail_rfm_df = retail_rfm_df[retail_rfm_df[\u0026#39;Quantity\u0026#39;]\u0026gt;0] 4#remove rows where customerID are NA 5retail_rfm_df.dropna(subset=[\u0026#39;CustomerID\u0026#39;],how=\u0026#39;all\u0026#39;,inplace=True) 6retail_rfm_df = retail_rfm_df[retail_rfm_df[\u0026#39;InvoiceDate\u0026#39;]\u0026gt; \u0026#34;2010-12-31\u0026#34;] 7retail_rfm_df = retail_rfm_df[retail_rfm_df[\u0026#39;InvoiceDate\u0026#39;]\u0026lt; \u0026#34;2011-12-01\u0026#34;] 3.1 T√≠nh Recency ƒê·ªÉ t√≠nh th√¥ng s·ªë n√†y, ch√∫ng ta c·∫ßn t√¨m ra ng√†y mua g·∫ßn nh·∫•t c·ªßa kh√°ch h√†ng, v√† s·ªë ng√†y kh√¥ng mua h√†ng, k·ªÉ t·ª´ ng√†y mua cu·ªëi ƒë·∫øn hi·ªán t·∫°i.\nK·ªπ thu·∫≠t l·∫≠p tr√¨nh ·ªü ƒë√¢y:\nG√°n ng√†y hi·ªán t·∫°i l√† ng√†y 30 th√°ng 11 nƒÉm 2011\nL·∫•y ra ng√†y mua h√†ng cu·ªëi c√πng c·ªßa m·ªói user\nT√≠nh ra kho·∫£ng th·ªùi gian k·ªÉ t·ª´ l·∫ßn mua h√†ng cu·ªëi c√πng ƒë·∫øn th·ªùi ƒëi·ªÉm hi·ªán t·∫°i\n1now = dt.date(2011,11,30) 2#create a new column called date which contains the date of invoice only 3retail_rfm_df[\u0026#39;date\u0026#39;] = pd.DatetimeIndex(retail_rfm_df[\u0026#39;InvoiceDate\u0026#39;]).date 4 5#group by customers and check last date of purshace 6recency_df = retail_rfm_df.groupby(by=\u0026#39;CustomerID\u0026#39;, as_index=False)[\u0026#39;date\u0026#39;].max() 7recency_df.columns = [\u0026#39;CustomerID\u0026#39;,\u0026#39;LastPurshaceDate\u0026#39;] 8 9#calculate recency 10recency_df[\u0026#39;Recency\u0026#39;] = recency_df[\u0026#39;LastPurshaceDate\u0026#39;].apply(lambda x: (now - x).days) 11recency_df.drop(\u0026#39;LastPurshaceDate\u0026#39;,axis=1,inplace=True) 12print(recency_df.head()) K·∫øt qu·∫£\n1\u0026gt;\u0026gt; recency_df.head() 2 CustomerID Recency 30 12346 316 41 12347 30 52 12348 66 63 12349 9 74 12350 301 8 9\u0026gt;\u0026gt; recency_df.Recency.describe() 10count 4174.000000 11mean 82.557499 12std 88.535941 13min 0.000000 1425% 15.000000 1550% 45.000000 1675% 128.000000 17max 330.000000 Ch·ªâ s·ªë th·ªëng k√™ cho th·∫•y, gi√° tr·ªã trung b√¨nh c·ªßa Recency l√† 82, 50% ng∆∞·ªùi d√πng l·∫∑p l·∫°i chu k·ª≥ mua h√†ng trong v√≤ng 45 ng√†y\n3.2 T√≠nh Frequency T·∫ßn su·∫•t gi√∫p ch√∫ng ta bi·∫øt ƒë∆∞·ª£c kh√°ch h√†ng ƒë√£ mua h√†ng bao nhi√™u l·∫ßn\nK·ªπ thu·∫≠t l·∫≠p tr√¨nh ·ªü ƒë√¢y kh√° ƒë∆°n gi·∫£n, gom nh√≥m ƒë∆°n h√†ng theo user v√† ƒë·∫øm\n1 2# drop duplicates 3retail_rfm_df_copy = retail_rfm_df 4retail_rfm_df_copy.drop_duplicates(subset=[\u0026#39;InvoiceNo\u0026#39;, \u0026#39;CustomerID\u0026#39;], keep=\u0026#34;first\u0026#34;, inplace=True) 5#calculate frequency of purchases 6frequency_df = retail_rfm_df_copy.groupby(by=[\u0026#39;CustomerID\u0026#39;], as_index=False)[\u0026#39;InvoiceNo\u0026#39;].count() 7frequency_df.columns = [\u0026#39;CustomerID\u0026#39;,\u0026#39;Frequency\u0026#39;] 8frequency_df.head() K·∫øt qu·∫£\n1\tCustomerID\tFrequency 20\t12346\t1 31\t12347\t5 42\t12348\t3 53\t12349\t1 64\t12350\t1 3.3 T√≠nh Monetary Monetary l√† t·ªïng ti·ªÅn kh√°ch h√†ng ƒë√£ s·ª≠ d·ª•ng\nDo ƒë√£ t√≠nh doanh thu t·ª´ tr∆∞·ªõc, n√™n gi·ªù ch√∫ng ta s·ª≠ d·ª•ng l·∫°i, ch·ªâ c·∫ßn gom nh√≥m theo m√£ kh√°ch h√†ng l√† ƒë∆∞·ª£c\n1 2monetary_df = retail_rfm_df.groupby([\u0026#39;CustomerID\u0026#39;])[\u0026#39;Revenue\u0026#39;].sum().reset_index() 3monetary_df.columns = [\u0026#39;CustomerID\u0026#39;,\u0026#39;Monetary\u0026#39;] 4monetary_df.head() K·∫øt qu·∫£\n1\tCustomerID\tMonetary 20\t12346\t77183.60 31\t12347\t120.56 42\t12348\t291.76 53\t12349\t15.00 64\t12350\t25.20 3.4 T·∫°o b·∫£ng RFM C√°i n√†y th√¨ si√™u ƒë∆°n gi·∫£n, ch√∫ng ta merge 3 b·∫£ng tr√™n l·∫°i l√† xong\n1 2#merge recency dataframe with frequency dataframe 3temp_df = recency_df.merge(frequency_df,on=\u0026#39;CustomerID\u0026#39;) 4#merge with monetary dataframe to get a table with the 3 columns 5rfm_df = temp_df.merge(monetary_df,on=\u0026#39;CustomerID\u0026#39;) 6#use CustomerID as index 7rfm_df.set_index(\u0026#39;CustomerID\u0026#39;,inplace=True) 8#check the head 9rfm_df.head() K·∫øt qu·∫£\n1 2\tRecency\tFrequency\tMonetary 3CustomerID 412346\t316\t1\t77183.60 512347\t30\t5\t120.56 612348\t66\t3\t291.76 712349\t9\t1\t15.00 812350\t301\t1\t25.20 3.5 Ph√¢n nh√≥m kh√°ch h√†ng s·ª≠ d·ª•ng RFM C√°ch ƒë∆°n gi·∫£n nh·∫•t ƒë·ªÉ ph√¢n nh√≥m kh√°ch h√†ng l√† s·ª≠ d·ª•ng Quartiles. Ch√∫ng ta c√≥ th·ªÉ chia t·∫≠p kh√°ch h√†ng th√†nh 3 ho·∫∑c 4 ho·∫∑c 5 nh√≥m g√¨ ƒë√≥, tu·ª≥ m·ª•c ƒë√≠ch kinh doanh.\n·ªû ƒë√¢y, gi·∫£ s·ª≠ m√¨nh chia l√†m 4 nh√≥m, s·ª≠ d√πng h√†m quantile c·ªßa pandas\nK·ªπ thu·∫≠t l·∫≠p tr√¨nh nh∆∞ sau:\nChia c√°c gi√° tr·ªã c·ªßa Recency, Frequency, Monetary th√†nh 4 nh√≥m, c√≥ mi·ªÅn gi√° tr·ªã t·ª´ 0 ƒë·∫øn 3, ƒë∆∞·ª£c 4 c√°i ph·∫ßn t∆∞ v·ªã cho m·ªói nh√≥m\nGi√° tr·ªã Recency c√†ng nh·ªè c√†ng t·ªët, trong khi ƒë√≥, gi√° tr·ªã Frequency v√† Monetary c√†ng l·ªõn c√†ng t·ªët, ƒë·ªÉ th·ªëng nh·∫•t chung, ch√∫ng ta s·∫Ω ƒë·ªïi d·∫•u c·ªßa Recency, ƒë·ªÉ c·∫£ 3 c√πng tho·∫£ t√≠nh ch·∫•t c√†ng l·ªõn c√†ng t·ªët.\n1 2#RFM Quartiles 3rfm_df[\u0026#39;Recency\u0026#39;] = -rfm_df[\u0026#39;Recency\u0026#39;] 4quantiles = rfm_df.quantile(q=[0.25,0.5,0.75]) 5print(quantiles) 6quantiles.to_dict() 7 8### Creation of RFM Segments 9 10# Arguments (x = value, p = recency, monetary_value, frequency, k = quartiles dict) 11def FMScore(x,p,d): 12 if x \u0026lt;= d[p][0.25]: 13 return 0 14 elif x \u0026lt;= d[p][0.50]: 15 return 1 16 elif x \u0026lt;= d[p][0.75]: 17 return 2 18 else: 19 return 3 20 21#create rfm segmentation table 22rfm_segmentation = rfm_df 23rfm_segmentation[\u0026#39;R_Quartile\u0026#39;] = rfm_segmentation[\u0026#39;Recency\u0026#39;].apply(FMScore, args=(\u0026#39;Recency\u0026#39;,quantiles,)) 24rfm_segmentation[\u0026#39;F_Quartile\u0026#39;] = rfm_segmentation[\u0026#39;Frequency\u0026#39;].apply(FMScore, args=(\u0026#39;Frequency\u0026#39;,quantiles,)) 25rfm_segmentation[\u0026#39;M_Quartile\u0026#39;] = rfm_segmentation[\u0026#39;Monetary\u0026#39;].apply(FMScore, args=(\u0026#39;Monetary\u0026#39;,quantiles,)) 26 27rfm_segmentation.head() 28 29 30rfm_segmentation[\u0026#39;RFMScore\u0026#39;] = rfm_segmentation.R_Quartile.map(str) \\ 31 + rfm_segmentation.F_Quartile.map(str) \\ 32 + rfm_segmentation.M_Quartile.map(str) 33rfm_segmentation.head() 34 35 36#How many customers do we have in each segment? 37 38print(\u0026#34;Best Customers: \u0026#34;,len(rfm_segmentation[rfm_segmentation[\u0026#39;RFMScore\u0026#39;]==\u0026#39;333\u0026#39;])) 39print(\u0026#39;Loyal Customers: \u0026#39;,len(rfm_segmentation[rfm_segmentation[\u0026#39;F_Quartile\u0026#39;]==3])) 40print(\u0026#34;Big Spenders: \u0026#34;,len(rfm_segmentation[rfm_segmentation[\u0026#39;M_Quartile\u0026#39;]==3])) 41print(\u0026#39;Almost Lost: \u0026#39;, len(rfm_segmentation[rfm_segmentation[\u0026#39;RFMScore\u0026#39;]==\u0026#39;133\u0026#39;])) 42print(\u0026#39;Lost Customers: \u0026#39;,len(rfm_segmentation[rfm_segmentation[\u0026#39;RFMScore\u0026#39;]==\u0026#39;033\u0026#39;])) 43print(\u0026#39;Lost Cheap Customers: \u0026#39;,len(rfm_segmentation[rfm_segmentation[\u0026#39;RFMScore\u0026#39;]==\u0026#39;000\u0026#39;])) K·∫øt qu·∫£\n1\u0026gt;\u0026gt; print(quantiles) 2\u0026gt;\u0026gt; quantiles.to_dict() 3 4 Recency Frequency Monetary 50.25 15.0 1.0 17.4000 60.50 45.0 2.0 43.5000 70.75 128.0 4.0 119.6625 8{\u0026#39;Frequency\u0026#39;: {0.25: 1.0, 0.5: 2.0, 0.75: 4.0}, 9 \u0026#39;Monetary\u0026#39;: {0.25: 17.399999999999999, 0.5: 43.5, 0.75: 119.66250000000001}, 10 \u0026#39;Recency\u0026#39;: {0.25: 15.0, 0.5: 45.0, 0.75: 128.0}} 11 12\u0026gt;\u0026gt;rfm_segmentation.head() 13 14\tRecency\tFrequency\tMonetary\tR_Quartile\tF_Quartile\tM_Quartile\tRFMScore 15CustomerID 1612346\t316\t1\t77183.60\t3\t0\t3\t303 1712347\t30\t5\t120.56\t1\t3\t3\t133 1812348\t66\t3\t291.76\t2\t2\t3\t223 1912349\t9\t1\t15.00\t0\t0\t0\t000 2012350\t301\t1\t25.20\t3\t0\t1\t301 21 22Best Customers: 10 23Loyal Customers: 980 24Big Spenders: 1044 25Almost Lost: 188 26Lost Customers: 374 27Lost Cheap Customers: 101 Tham kh·∫£o https://blog.hubspot.com/service/rfm-analysis\nhttps://www.investopedia.com/terms/r/rfm-recency-frequency-monetary-value.asp\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ d√†nh th·ªùi gian ƒë·ªçc b√†i. N·∫øu c√≥ b·∫•t k·ª≥ v·∫•n ƒë·ªÅ g√¨, h√£y ƒë·ªÉ l·∫°i comment b√™n d∆∞·ªõi ho·∫∑c email cho m√¨nh qua ƒë·ªãa ch·ªâ alexblack2202@gmail.com. H·∫πn g·∫∑p l·∫°i c√°c b·∫°n ·ªü b√†i vi·∫øt ti·∫øp theo.\nSource code m√¨nh c√≥ ƒë·ªÉ ·ªü https://www.kaggle.com/code/alexblack2202/customer-segmentation-using-rfm-analysis\n","date":"Dec 4, 2022","img":"https://unsplash.it/1920/1080?image=17","permalink":"/blog/2022-12-03-marketing-with-python/","series":null,"tags":["RFM","Recommendation","Marketing"],"title":"Marketing Th·ª±c Chi·∫øn - Ph√¢n Lo·∫°i Kh√°ch H√†ng S·ª≠ D·ª•ng RFM Analysis"},{"categories":null,"content":"Nh∆∞ c√°c b·∫°n ƒë√£ bi·∫øt, tiktok hi·ªán nay l√† m·ªôt ·ª©ng d·ª•ng gi·∫£i tr√≠ ph·ªï bi·∫øn v√† ƒë·ª©ng top 1 trong s·ªë l∆∞·ª£t t·∫£i xu·ªëng t·ª´ CH play v√† AppStore. Th√†nh c√¥ng c·ªßa tiktok l√† do h·ªç ƒë√£ x√¢y d·ª±ng kh√° th√†nh c√¥ng thu·∫≠t to√°n g·ª£i √Ω video cho ng∆∞·ªùi d√πng, l√†m cho ng∆∞·ªùi d√πng \u0026ldquo;cu·ªën\u0026rdquo; v√†o c√°c video h·ªç ƒë·ªÅ xu·∫•t, m√† kh√¥ng bi·∫øt ch√°n. Ng√†y 27/09/2022, h·ªç ƒë√£ c√¥ng b·ªë b√†i b√°o c√≥ t·ª± ƒë·ªÅ Monolith: Real Time Recommendation System With Collisionless Embedding Table t·∫°i ƒë·ªãa ch·ªâ https://arxiv.org/pdf/2209.07663.pdf. Ch·ªß ƒë·ªÅ n√†y kh√° n·∫∑ng v·ªÅ kh·∫£ nƒÉng x√¢y d·ª±ng h·ªá th·ªëng ƒë·ªÉ l√†m sao ƒë·∫°t ƒë∆∞·ª£c m√¥ h√¨nh ch·∫•t l∆∞·ª£ng v·ªõi th·ªùi gian near-realtime. ƒê·ªÉ c√≥ th·ªÉ hi·ªÉu s√¢u b√†i n√†y, c√°c b·∫°n c√≥ n√™n c√≥ ki·∫øn th·ª©c v·ªÅ Recurrent Neural Networks for Recommendations.\nPh·∫ßn d·∫´n nh·∫≠p - Ch√†o ƒë·∫ßu 1. Ph·∫ßn gi·ªõi thi·ªáu 1.1 Sparsity v√† Dynamism 1.2 Non-stationary Distribution 2. Design colisionless Hash Table v√† Online Training 2.1 X√¢y d·ª±ng Hash Table 2.2 Online training 2.2.1 Streaming Engine 2.2 .2 Online Joiner 2.2.3 Parameter Synchronization 2.3 Fault Tolerance 3. ƒê√°nh gi√° - EVALUATION 3.1 Thi·∫øt l·∫≠p th√≠ nghi·ªám 3.1.1 X√¢y d·ª±ng embedding table 3.1.2 Online training 3.2 K·∫øt qu·∫£ v√† ph√¢n t√≠ch 3.2.1 Hi·ªáu qu·∫£ c·ªßa embedding collision 3.2.2 Online Training: Trading-off Reliability For Realtime. T√†i li·ªáu tham kh·∫£o c·ªßa paper Tham kh·∫£o Ph·∫ßn d·∫´n nh·∫≠p - Ch√†o ƒë·∫ßu C√°c doanh nghi·ªáp c√≥ nhu c·∫ßu x√¢y d·ª±ng real-time recommendation ƒë·ªÉ ph·ª•c v·ª• kh√°ch h√†ng t·ªët h∆°n.\nC√°c framwork deep-learning ƒë∆∞·ª£c s·ª≠ d·ª•ng trong production th∆∞·ªùng kh√¥ng ƒë√°p ·ª©ng ƒë∆∞·ª£c nhu c·∫ßu recommend c·ªßa doanh nghi·ªáp, l√Ω do l√†:\nTinh ch·ªânh h·ªá th·ªëng d·ª±a tr√™n c√°c tham s·ªë tƒ©nh v√† th·ª±c hi·ªán nhi·ªÅu ph√©p t√≠nh to√°n tr√™n feature th∆∞a (sparse) v√† ƒë·ªông (dinamic) l√†m gi·∫£m ch·∫•t l∆∞·ª£ng m√¥ h√¨nh.\nVi·ªác training v√† serving t√°ch b·∫°ch nhau, kh√¥ng c√≥ online training (model kh√¥ng th·ªÉ retrain ngay l·∫≠p t·ª©c khi c√≥ feedback c·ªßa ng∆∞·ªùi d√πng)\nV√¨ nh·ªØng nguy√™n nh√¢n tr√™n, nh√≥m t√°c gi·∫£ c·ªßa ByteDance ƒë√£ thi·∫øt k·∫ø m·ªôt m√¥ h√¨nh online training m·ªõi, ƒë·∫∑t t√™n l√† Monolith.\nM√¥ h√¨nh m·ªõi c√≥ 2 th√†nh t·ªë m·ªõi:\nƒê·ªÅ xu·∫•t collisionless embedding table v·ªõi c√°c t·ªëi ∆∞u nh∆∞ expirable embeddings v√† frequency filtering ƒë·ªÉ gi·∫£m l∆∞·ª£ng b·ªô nh·ªõ ti√™u th·ª•.\nƒê·ªÅ xu·∫•t m·ªôt m√¥ h√¨nh ki·∫øn tr√∫c production-ready online training v·ªõi high fault-tolerance.\nCu·ªëi c√πng, ch·ª©ng minh r·∫±ng ƒë·ªô tin c·∫≠y c·ªßa h·ªá th·ªëng c√≥ th·ªÉ ƒë√°nh ƒë·ªïi b·∫±ng vi·ªác h·ªçc theo th·ªùi gian th·ª±c.\n1. Ph·∫ßn gi·ªõi thi·ªáu \u0026ldquo;H√¨nh 1: Monolith Online Training Architecture - H√¨nh ·∫£nh ƒë∆∞·ª£c c·∫Øt t·ª´ paper\nData c·ªßa recommendation kh√°c xa data c·ªßa language modeling ho·∫∑c computer vision ·ªü 2 kh√≠a c·∫°nh:\nH·∫ßu h·∫øt c√°c ƒë·∫∑c tr∆∞ng r·∫•t th∆∞a, c√≥ t√≠nh ph√¢n lo·∫°i v√† thay ƒë·ªïi linh ho·∫°t.\nPh√¢n ph·ªëi c·ªßa data l√† kh√¥ng d·ª´ng (non-stationary) , vd Concept Drift. [8]\n1.1 Sparsity v√† Dynamism Nh·∫Øc l·∫°i, d·ªØ li·ªáu cho recommendation h·∫ßu h·∫øt l√† c√°c ƒë·∫∑c tr∆∞ng category d·∫°ng th∆∞a, m·ªôt v√†i trong s·ªë ƒë√≥ c√≥ t·∫ßng su·∫•t xu·∫•t hi·ªán r·∫•t th·∫•p. Vi·ªác mapping ch√∫ng l√™n kh√¥ng gian ƒë·∫∑c tr∆∞ng cao chi·ªÅu h∆°n s·∫Ω g·∫∑p c√°c v·∫•n ƒë·ªÅ:\nKh√¥ng gi·ªëng nh∆∞ c√°c m√¥ h√¨nh ng√¥n ng·ªØ c√≥ s·ªë l∆∞·ª£ng t·ª´ h·∫°n ch·∫ø, data user ranking item th∆∞·ªùng r·∫•t r·∫•t l·ªõn. Kh·∫£ nƒÉng cao l√† 1 m√°y ch·ªß si√™u m·∫°nh hi·ªán nay c·ªßa c√°c doanh nghi·ªáp kh√¥ng ch·ª©a n·ªïi Embedding table tr√™n b·ªô nh·ªõ ch√≠nh.\nTr∆∞·ªùng h·ª£p t·ªá nh·∫•t,k√≠ch th∆∞·ªõc c·ªßa Embedding table s·∫Ω ti·∫øp t·ª•c tƒÉng theo th·ªùi gian do ng∆∞·ªùi d√πng v√† s·∫£n ph·∫©m m·ªõi li√™n t·ª•c ƒë∆∞·ª£c th√™m v√†o h·ªá th·ªëng. Trong khi ƒë√≥, m·ªôt s·ªë frameword recommendation s·ª≠ d·ª•ng fixed-size dense variables ƒë·ªÉ bi·ªÉu di·ªÖn embedding table. V√≠ d·ª• framework [1,17]\nTrong th·ª±c t·∫ø, nhi·ªÅu thu·∫≠t to√°n ƒë√£ d√πng v√†i \u0026ldquo;m·∫πo\u0026rdquo;, nh∆∞ x√†i hashing nh∆∞ b√†i b√°o [3] v√† b√†i b√°o [6] , ƒë·ªÉ gi·∫£m l∆∞·ª£ng memory ti√™u th·ª• v√† cho ph√©p tƒÉng ID. √ù t∆∞·ªüng n√†y d·ª±a tr√™n gi·∫£ ƒë·ªãnh l√† ID trong Embedding table ph√¢n ph·ªëi ƒë·ªÅu v√† vi·ªác collisions th√¨ v√¥ h·∫°i. Gi·∫£ ƒë·ªãnh n√†y kh√¥ng ƒë√∫ng trong hi·ªán th·ª±c, khi m√† m·ªôt nh√≥m nh·ªè user ho·∫∑c item c√≥ t·∫ßng su·∫•t xu·∫•t hi·ªán cao h∆°n. V·ªõi s·ª± tƒÉng tr∆∞·ªüng t·ª± nhi√™n c·ªßa embedding table, x√°c su·∫•t hash key ƒë·ª•ng ƒë·ªô s·∫Ω c√†ng cao, d·∫´n ƒë·∫øn gi·∫£m ch·∫•t l∆∞·ª£ng m√¥ h√¨nh.\nDo ƒë√≥, nhu c·∫ßu t·ª± nhi√™n c·ªßa m·ªôt h·ªá th·ªëng g·ª£i √Ω l√† c√≥ kh·∫£ nƒÉng capture c√†ng nhi·ªÅu ƒë·∫∑c tr∆∞ng trong ch√≠nh c√°c tham s·ªë c·ªßa m√¥ h√¨nh, v√† c√≥ kh·∫£ nƒÉng ƒëi·ªÅu ch·ªânh linh ho·∫°t s·ªë user v√† s·ªë item m√† n√≥ c√≥ kh·∫£ nƒÉng l∆∞u gi·ªØ.\n1.2 Non-stationary Distribution C√°c pattern m·ªõi v·ªÅ h√¨nh ·∫£nh v√† ng√¥n ng·ªØ trong b√†i to√°n x·ª≠ l√Ω ·∫£nh v√† x·ª≠ l√Ω ng√¥n ng·ªØ th∆∞·ªùng kh√¥ng thay ƒë·ªïi nhi·ªÅu trong h√†ng th·∫ø k·ª∑. Trong khi ƒë√≥, s·ª± quan t√¢m c·ªßa ng∆∞·ªùi d√πng v·ªÅ m·ªôt ch·ªß ƒë·ªÅ n√†o ƒë√≥ c√≥ th·ªÉ thay ƒë·ªïi t·ª´ng ph√∫t m·ªôt. K·∫øt qu·∫£ l√†, ph√¢n ph·ªëi c·ªßa d·ªØ li·ªáu ng∆∞·ªùi d√πng l√† kh√¥ng c·ªë ƒë·ªãnh, v√† hi·ªán t∆∞·ª£ng n√†y th∆∞·ªùng ƒë∆∞·ª£c g·ªçi v·ªõi t√™n l√† Concept Drift.\nTh√¥ng th∆∞·ªùng, th√¥ng tin l·ªãch s·ª≠ g·∫ßn nh·∫•t th∆∞·ªùng c√≥ ƒë√≥ng g√≥p hi·ªáu qu·∫£ nh·∫•t cho vi·ªác d·ª± ƒëo√°n vi·ªác thay ƒë·ªïi h√†nh vi ng∆∞·ªùi d√πng. ƒê·ªÉ gi·∫£m thi·ªÉu t√°c ƒë·ªông c·ªßa Concept Drift, c√°c m√¥ h√¨nh \u0026ldquo;serving\u0026rdquo; c·∫ßn ph·∫£i c·∫≠p nh·∫≠t th∆∞·ªùng xuy√™n t·ª´ nh·ªØng ph·∫£n h·ªìi c·ªßa ng∆∞·ªùi d√πng, c√†ng real-time c√†ng t·ªët, ƒë·ªÉ ph·∫£n √°nh t·ªët nh·∫•t xu h∆∞·ªõng quan t√¢m c·ªßa ng∆∞·ªùi d√πng.\nD·ª±a tr√™n c√°c ph√¢n t√≠ch tr√™n, nh√≥m t√°c gi·∫£ ƒë√£ x√¢y d·ª±ng n√™n monolith, c√≥ kh·∫£ nƒÉng:\nCung c·∫•p ƒë·∫ßy ƒë·ªß nƒÉng l·ª±c x·ª≠ l√Ω cho c√°c ƒë·∫∑c tr∆∞ng th∆∞a b·∫±ng c√°ch thi·∫øt k·∫ø m·ªôt collisionless hash table v√† c∆° ch·∫ø lo·∫°i b·ªè c√°c dynamic feature.\nƒê∆∞a th√¥ng tin feedback c·ªßa ng∆∞·ªùi d√πng v√†o training realtime v·ªõi online training\nD·ª±a v√†o ki·∫øn tr√∫c n√†y, m√¥ h√¨nh monolith v∆∞·ª£t tr·ªôi h∆°n so v·ªõi c√°c h·ªá th·ªëng s·ª≠ d·ª•ng collisions hash table v·ªõi dung l∆∞·ª£ng b·ªô nh·ªõ s·ª≠ d·ª•ng l√† t∆∞∆°ng ƒë∆∞∆°ng nhau\n2. Design colisionless Hash Table v√† Online Training H√¨nh 2: Worker-PS Architecture - H√¨nh ·∫£nh ƒë∆∞·ª£c c·∫Øt t·ª´ paper\nKi·∫øn tr√∫c c·ªßa Monolith s·ª≠ d·ª•ng TensorFlow‚Äôs distributed Worker-ParameterServer (Worker-PS) nh∆∞ h√¨nh tr√™n. Trong m√¥ h√¨nh, c√°c m√°y ƒë∆∞·ª£c ph√¢n c√¥ng v·ªõi c√°c nhi·ªám v·ª• kh√°c nhau. Worker machine ch·ªãu tr√°ch nhi·ªám t√≠nh to√°n theo ƒë·ªãnh nghƒ©a tr∆∞·ªõc, PS machine l∆∞u tr·ªØ c√°c tham s·ªë v√† c·∫≠p nh·∫≠t k·∫øt qu·∫£ tham s·ªë theo workers.\nTrong m√¥ h√¨nh recommendation, c√°c tham s·ªë ƒë∆∞·ª£c ph√¢n lo·∫°i l√†m hai nh√≥m: nh√≥m dense v√† nh√≥m sparse. C√°c tham s·ªë Dense l√† c√°c tr·ªçng s·ªë c·ªßa m√¥ h√¨nh DNN, c√°c tham s·ªë sparse tham chi·∫øu t·ªõi embedding table t∆∞∆°ng ·ª©ng v·ªõi c√°c sparse feature. C·∫£ Dense parameter v√† sparse parameter ƒë·ªÅu l√† c√°c ph·∫ßn c·ªßa TensorFlow Graph, v√† ƒë∆∞·ª£c l∆∞u tr·ªØ tr√™n parameters servers.\n2.1 X√¢y d·ª±ng Hash Table H√¨nh 3: Cuckoo HashMap. - H√¨nh ·∫£nh ƒë∆∞·ª£c c·∫Øt t·ª´ paper\nNguy√™n t·∫Øc ƒë·∫ßu ti√™n ƒë·ªÉ x√¢y d·ª±ng c√°c tham s·ªë bi·ªÉu di·ªÖn t√≠nh th∆∞a l√† tr√°nh thu g·ªçn th√¥ng tin t·ª´ c√°c IDs kh√°c nhau v·ªÅ c√πng m·ªôt fixed-sze embedding.\nVi·ªác x√¢y d·ª±ng m·ªôt embedding table s·ª≠ d·ª•ng TensorFlow Variable s·∫Ω d·∫´n ƒë·∫øn vi·ªác ƒë·ª•ng ƒë·ªô ID khi s·ªë l∆∞·ª£ng ID m·ªõi v√† table tƒÉng l√™nh. Do ƒë√≥, thay v√¨ x√¢y embedding table d·ª±a tr√™n Variable, t√°c gi·∫£ ƒë√£ ph√°t tri·ªÉn m·ªôt key-value HashTable cho c√°c tham s·ªë th∆∞a.\nHashTable n√†y s·ª≠ d·ª•ng Cuckoo Hashmap [16], h·ªó tr·ª£ vi·ªác th√™m m·ªôt key m·ªõi m√† kh√¥ng ƒë·ª•ng ƒë·ªô v·ªõi key c≈©. Cuckoo Hashing trong tr∆∞·ªùng h·ª£p x·∫•u nh·∫•t c√≥ ƒë·ªô ph·ª©c t·∫°p O(1) trong vi·ªác t√¨m ki·∫øm v√† xo√°, v√† O(1) cho vi·ªác th√™m m·ªõi. Nh∆∞ trong h√¨nh 3, n√≥ s·ª≠ d·ª•ng hai b·∫£ng T0 v√† T1 v·ªõi hai h√†m hash kh√°c nhau c√≥ t√™n l√† h0(x) v√† h1(x), v√† m·ªôt ph·∫ßn t·ª≠ s·∫Ω ƒë∆∞·ª£c l∆∞u tr·ªØ trong m·ªôt trong hai b·∫£ng tr√™n. Khi c·ªë g√°n th√™m m·ªôt ph·∫ßn t·ª≠ A v√†o T0, ƒë·∫ßu ti√™n, n√≥ c·ªë g√°n ƒë·∫∑t A v√†o h0(A). N·∫øu h0(A) ƒë√£ hold 1 ph·∫ßn t·ª≠ B n√†o ƒë√≥, n√≥ s·∫Ω xo√° B t·ª´ T0 v√† g√°n B v√†o T1 v·ªõi logic t∆∞∆°ng t·ª±. Qu√° tr√¨nh n√†y ƒë∆∞·ª£c l·∫∑p ƒëi l·∫∑p l·∫°i ƒë·∫øn khi ·ªïn ƒë·ªãnh.\nVi·ªác gi·∫£m b·ªô nh·ªõ l∆∞u tr·ªØ c≈©ng l√† m·ªôt y·∫øu t·ªë quang tr·ªçng trong thi·∫øt k·∫ø h·ªá th·ªëng. M·ªôt c√°ch t·ª± nhi√™n, vi·ªác m·ªói l·∫ßn th√™m 1 ph·∫ßn t·ª≠ m·ªõi v√†o HashTable s·∫Ω l√†m cho b·ªô nh·ªõ nhanh ch√≥ng ƒë·∫ßy. C√≥ 2 k·∫øt lu·∫≠n c√≥ th·ªÉ ƒë∆∞·ª£c r√∫t ra:\nC√°c ID xu·∫•t hi·ªán v√†i l·∫ßn c√≥ ƒë√≥ng g√≥p r·∫•t h·∫°n ch·∫ø ƒë·ªëi v·ªõi vi·ªác c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng m√¥ h√¨nh. C√°c quan s√°t quan tr·ªçng l√† c√°c quan s√°t m√† c√°c IDs ·ªü d·∫°ng long-tail distributed, khi c√°c ID ph·ªï bi·∫øn c√≥ s·ªë l·∫ßn xu·∫•t hi·ªán h√†ng tri·ªáu l·∫ßn, trong khi ƒë√≥, c√°c ID kh√¥ng ph·ªï bi·∫øn xu·∫•t hi·ªán kh√¥ng qu√° m∆∞·ªùi l·∫ßn. C√°c ID t·∫ßng su·∫•t th·∫•p l√†m m√¥ h√¨nh underfit do thi·∫øu data training v√† model s·∫Ω kh√¥ng c√≥ kh·∫£ nƒÉng ƒë∆∞a ra d·ª± ƒëo√°n t·ªët d∆∞a tr√™n nh·ªØng th√¥ng tin m√† ch√∫ng cung c·∫•p. H∆°n h·∫øt, c√°c th√¥ng tin c·ªßa c√°c ID tr√™n th∆∞·ªùng √≠t ·∫£nh h∆∞·ªüng ƒë·∫øn k·∫øt qu·∫£ c·ªßa m√¥ h√¨nh, do ƒë√≥, vi·ªác xo√° ƒëi c√°c ID c√≥ t·∫ßng su·∫•t th·∫•p kh√¥ng ·∫£nh h∆∞·ªüng nhi·ªÅu ƒë·∫øn ch·∫•t l∆∞·ª£ng m√¥ h√¨nh.\nL·ªãch s·ª≠ t·ª´ th·ªùi napoleon c√≥ ƒë√≥ng g√≥p r·∫•t th·∫•p v√†o m√¥ h√¨nh hi·ªán t·∫°i. Do ng∆∞·ªùi d√πng ng·ª´ng ho·∫°t ƒë·ªông, ho·∫∑c l√† video ƒë√£ l·ªói th·ªùi. Vi·ªác l∆∞u tr·ªØ embedding cho c√°c ID n√†y kh√¥ng gi√∫p √≠ch cho m√¥ h√¨nh, ng∆∞·ª£c l·∫°i ch√∫ng c√≤n g√≥p ph·∫ßn l√†m tƒÉng chi ph√≠ l∆∞u tr·ªØ v√† chi ph√≠ t√≠nh to√°n.\nD·ª±a tr√™n nh·ªØng ƒëi·ªÅu tr√™n, nh√≥m k·ªπ s∆∞ ƒë·ªÅ xu·∫•t thi·∫øt k·∫ø ID filtering heuristic ƒë·ªÉ gi√∫p t·ªëi ∆∞u ho√° b·ªô nh·ªõ l∆∞u tr·ªØ:\nC√°c ID ƒë∆∞·ª£c l·ªçc tr∆∞·ªõc khi ƒë∆∞·ª£c ƒë∆∞a v√†o trong h·ªá th·ªëng embedding table. C√≥ 2 ph∆∞∆°ng ph√°p l·ªçc L·ªçc theo t·∫ßng xu·∫•t xu·∫•t hi·ªán tr∆∞·ªõc khi ID ƒë∆∞·ª£c th√™m v√†o. Gi√° tr·ªã ng∆∞·ª°ng l√† si√™u tham s·ªë v√† ƒë∆∞·ª£c turning. L·ªçc theo x√°c xu·∫•t, gi√∫p cho gi·∫£m b·ªô nh·ªõ ti√™u th·ª•. ID ƒë∆∞·ª£c g√°n th·ªùi gian v√† b·ªã expire sau m·ªôt kho·∫£ng th·ªùi gian inactive. HashTable ƒë∆∞·ª£c implement d∆∞·ªõi d·∫°ng Tensorflow resource operation.\n2.2 Online training Vi·ªác trainnig ƒë∆∞·ª£c chia l√†m 2 giai ƒëo·∫°n:\nGiai ƒëo·∫°n Batch training. Giai ƒëo·∫°n n√†y ho·∫°t ƒë·ªông nh∆∞ vi·ªác training m√¥ h√¨nh TF b√¨nh th∆∞·ªùng. Trong m·ªói b∆∞·ªõc training, c√°c worker ƒë·ªçc m·ªôt mini-batch data training t·ª´ storage, l·∫•y tham s·ªë t·ª´ PS, t√≠nh lan truy·ªÅn xu√¥i, lan truy·ªÅn ng∆∞·ª£c, v√† c·∫≠p nh·∫≠t tham s·ªë v√†o PS. Dataset ƒë∆∞·ª£c train 1 l·∫ßn duy nh·∫•t.\nGiai ƒëo·∫°n training online. Sau khi model ƒë∆∞·ª£c deploy v√†o online serving, vi·ªác traning kh√¥ng c√≥ d·ª´ng h·∫µng, m√† chuy·ªÉn qua giai ƒëo·∫°n online training. Thay v√¨ ƒë·ªçc c√°c mini-batch data t·ª´ storage, training worker s·∫Ω l·∫•y realtime data ƒë·ªÉ train v√† c·∫≠p nh·∫≠t l·∫°i PS. Training PS s·∫Ω ƒë·ªãnh k·ª≥ c·∫≠p nh·∫≠t c√°c tham s·ªë v√†o serving PS.\n2.2.1 Streaming Engine H√¨nh 4: Streaming Engine. The information feedback loop from [User ‚Üí Model Server ‚Üí Training Worker ‚Üí Model Server ‚Üí User] would spend a long time when taking the Batch Training path, while the Online Training will close the loop more instantly - H√¨nh ·∫£nh ƒë∆∞·ª£c c·∫Øt t·ª´ paper\nH√¨nh 4 ph√≠a tr√™n m√¥ t·∫£ vi·ªác chuy·ªÉn ƒë·ªïi li·ªÅn m·∫°ch gi·ªØa batch training v√† online training.\nM√¥ h√¨nh s·ª≠ d·ª•ng Kafka Queue [13] ƒë·ªÉ log l·∫°i c√°c h√†nh ƒë·ªông c·ªßa user ( click item, like item, th·∫£ tim\u0026hellip;. ) v√† m·ªôt Kafka queue kh√°c l∆∞u l·∫°i c√°c ƒë·∫∑c tr∆∞ng. Core engine l√† Flink [4] stream job cho online feature joiner. Online joiner k·∫øt h·ª£p c√°c ƒë·∫∑c tr∆∞ng v·ªõi nh√£n t·ª´ user action t·∫°o th√†nh training example, sau ƒë√≥ ƒë·∫©y v√†o kafka queue. Queue cho training example ƒë∆∞·ª£c consumer b·ªõi online training v√† batch training.\nV·ªõi online training, training worker tr·ª±c ti·∫øp ƒë·ªçc d·ªØ li·ªáu t·ª´ kafka Queue.\nV·ªõi batch training, data s·∫Ω ƒë∆∞·ª£c ƒë√≥ng g√≥i v√†o file HDFS (dump job handle vi·ªác n√†y). Sau khi data trong HDFS t√≠ch lu·ªπ v·ªõi s·ªë l∆∞·ª£ng ƒë·ªß d√πng, training worker s·∫Ω load data t·ª´ HDFS v√† th·ª±c hi·ªán batch training.\n2.2 .2 Online Joiner H√¨nh 5: : Online Joiner - H√¨nh ·∫£nh ƒë∆∞·ª£c c·∫Øt t·ª´ paper\nTrong ·ª©ng d·ª•ng th·ª±c t·∫ø, h√†nh ƒë·ªông c·ªßa user v√† feature c·ªßa user ƒë∆∞·ª£c stream v√†o online joiner m√† kh√¥ng ƒë·∫£m b·∫£o th·ª© t·ª± v·ªÅ th·ªùi gian. Do ƒë√≥, c·∫ßn ph√°t sinh m·ªôt unique key cho m·ªói request ƒë·ªÉ ƒë·∫£m b·∫£o pair ƒë∆∞·ª£c ch√∫ng v·ªõi nhau.\nVi·ªác user b·ªã lag c≈©ng l√† m·ªôt v·∫•n ƒë·ªÅ c·∫ßn ƒë∆∞·ª£c xem x√©t. V√≠ d·ª•, m·ªôt user c√≥ kh·∫£ nƒÉng m·∫•t v√†i ng√†y m·ªõi ra quy·∫øt ƒë·ªãnh mua m·ªôt s·∫£n ph·∫©m m√† h·ªç ƒë√£ xem v√†i ng√†y tr∆∞·ªõc ƒë√≥. ƒê√¢y l√† m·ªôt th√°ch th·ª©c th·∫≠t s·ª±, b·ªüi v√¨ n·∫øu to√†n b·ªô c√°c ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c l∆∞u tr·ªØ trong b·ªô nh·ªõ ch√≠nh, th√¨ ch√∫ng ta s·∫Ω kh√¥ng ƒë·ªß b·ªô nh·ªõ ƒë·ªÉ l∆∞u tr·ªØ. Nh√≥m t√°c gi·∫£ ƒë√£ s·ª≠ d·ª•ng on-disk key-value storage ƒë·ªÉ l∆∞u tr·ªØ c√°c ƒë·∫∑c tr∆∞ng c·ªßa ng∆∞·ªùi d√πng ·ªü qu√° kh·ª©. Khi log c·ªßa ng∆∞·ªùi d√πng ƒë∆∞·ª£c ƒë·∫©y v√†o h·ªá th·ªëng, tr∆∞·ªõc h·∫øt n√≥ s·∫Ω ƒë∆∞·ª£c t√¨m ki·∫øm trong memory cache, trong tr∆∞·ªùng h·ª£p mising cache, n√≥ s·∫Ω t√¨m trong key-value storage.\nM·ªôt v·∫•n ƒë·ªÅ n·ªØa l√† ph√¢n b·ªë m·∫´u √¢m v√† m·∫´u d∆∞∆°ng trong data kh√¥ng ƒë·ªìng ƒë·ªÅu. Trong ƒë√≥, l∆∞·ª£ng m·∫´u d∆∞∆°ng th∆∞·ªùng cao h∆°n r·∫•t nhi·ªÅu so v·ªõi m·∫´u √¢m. ƒê·ªÉ ngƒÉn ch·∫∑ng th·∫±ng m·∫´u d∆∞∆°ng th·ªëng tr·ªã, m·ªôt chi·∫øn l∆∞·ª£c th∆∞·ªùng hay ƒë∆∞·ª£c s·ª≠ d·ª•ng l√† sampling m·∫´u √¢m. T·∫•t nhi√™n vi·ªác n√†y s·∫Ω l√†m thay ƒë·ªïi ph√¢n b·ªë c·ªßa m√¥ h√¨nh hu·∫•n luy·ªán. V√† s·ª≠ d·ª•ng log odds corection trong qu√° tr√¨nh serving [19]\n2.2.3 Parameter Synchronization Trong su·ªët qu√° tr√¨nh training, d·ªØ li·ªáu s·∫Ω li√™n t·ª•c ƒë·ªï v·ªÅ online serving module v√† c·∫≠p nh·∫≠t tham s·ªë tr√™n PS. Trong m√¥i tr∆∞·ªùng th·∫≠t, s·∫Ω c√≥ m·ªôt v√†i th√°ch th·ª©c:\nModel tr√™n online serving PS b·∫Øt bu·ªôc ph·∫£i ho·∫°t ƒë·ªông khi update. K√≠ch th∆∞·ªõc model kh√° l·ªõn, v√† vi·ªác update to√†n b·ªô tham s·ªë s·∫Ω t·ªën kha kh√° th·ªùi gian (l∆∞u √Ω ·ªü ƒë√¢y l√† kh√¥ng th·ªÉ th·ª±c hi·ªán update t·ª´ng ph·∫ßn, m√† ph·∫£i update to√†n b·ªô tham s·ªë). N√™n ph·∫£i t√¨m c√°ch th·ª©c n√†o ƒë√≥ ƒë·ªÉ vi·ªác update kh√¥ng ·∫£nh h∆∞·ªüng t·ªõi vi·ªác infer c·ªßa model.\nVi·ªác tranfer model c√≥ k√≠ch th∆∞·ªõc l·ªõn t·ª´ training PS t·ªõi online server PS s·∫Ω g√¢y √°p l·ª±c l·ªõn ƒë·∫øn bƒÉng th√¥ng m·∫°ng v√† b·ªô nh·ªõ tr√™n PS. M·ªôt y√™u c·∫ßu t·ªëi thi·ªÉu l√† b·ªô nh·ªõ ph·∫£i c√≥ k√≠ch th∆∞·ªõc √≠t nh·∫•t l√† g·∫•p 2 l·∫ßn k√≠ch th∆∞·ªõc c·ªßa model (tr√™n RAM)\nƒê·ªÉ scale up model cho ph√π h·ª£p v·ªõi nghi·ªáp v·ª• kinh doanh, nh√≥m t√°c gi·∫£ ƒë√£ thi·∫øt k·∫ø ri√™ng m·ªôt c∆° ch·∫ø ƒë·ªìng b·ªô ho√°, d·ª±a tr√™n c√°c quan s√°t sau:\nC√°c tham s·ªë th∆∞a th√¨ th∆∞·ªùng th·ªëng tr·ªã k√≠ch th∆∞·ªõc c·ªßa m√¥ h√¨nh g·ª£i √Ω.\nTrong m·ªôt kho·∫£ng th·ªùi gian ng·∫Øn (short range of time window), ch·ªâ m·ªôt nh√≥m nh·ªè c√°c ID ƒë∆∞·ª£c training, v√† ch·ªâ nh·ªØng embedding c·ªßa nh·ªØng ID ƒë√≥ ƒë∆∞·ª£c c·∫≠p nh·∫≠t.\nC√°c bi·∫øn Dense tranfer ch·∫≠m h∆°n so v·ªõi spare embeddings. B·ªüi v√¨ size c·ªßa Dense variable r·∫•t l·ªõn.\nNh·∫≠n ƒë·ªãnh 1 v√† 2 ·ªü nh·∫≠n cho ph√©p ch√∫ng ta tr√°nh c·∫≠p nh·∫≠t sparse c·ªßa to√†n b·ªô c√°c ƒë·∫∑c tr∆∞ng c·ªßa ID. Trong m√¥ h√¨nh, c√°c ID ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán k·ªÉ t·ª´ l·∫ßn hu·∫•n luy·ªán cu·ªëi c√πng s·∫Ω ƒë∆∞·ª£c ƒë·∫©y v√†o touched key. Sau khi training xong, ch√∫ng ta s·∫Ω ƒë·∫©y c√°c sparse parameter trong touched key v√†o online serving PS v·ªõi t·∫ßn su·∫•t t√≠nh b·∫±ng ph√∫t. G√≥i c·∫≠p nh·∫≠t n√†y kh√° nh·ªè (so v·ªõi to√†n b·ªô ), n√™n ch√∫ng √≠t s·∫Ω s·ª≠ d·ª•ng bƒÉng th√¥ng m·∫°ng r·∫•t th·∫•p, v√† s·∫Ω kh√¥ng t·∫°o m√¥ h√¨nh rƒÉng c∆∞a cho b·ªô nh·ªõ RAM trong qu√° tr√¨nh ƒë·ªìng b·ªô.\nV·ªõi nh·∫≠n ƒë·ªãnh (3), ch√∫ng ta s·∫Ω gi·∫£m I/O m·∫°ng v√† b·ªô nh·ªõ s·ª≠ d·ª•ng b·∫±ng c√°ch ƒë·∫∑t l·ªãch ƒë·ªìng b·ªô ho√° d√†y h∆°n cho c√°c tham s·ªë th∆∞a, trong khi ƒë√≥ s·∫Ω c√≥ t·∫ßng xu·∫•t c·∫≠p nh·∫≠t tham s·ªë dense √≠t h∆°n. Vi·ªác n√†y c≈©ng g√¢y ra t√¨nh hu·ªëng l√† c√°c tham s·ªë th∆∞a s·∫Ω m·ªõi h∆°n r·∫•t nhi·ªÅu so v·ªõi tham s·ªë dense, do ƒë√≥ s·∫Ω c√≥ m·∫•t m√°t x·∫£y ra. M·∫•t m√°t n√†y ƒë∆∞·ª£c ch·∫•p nh·∫≠n do n√≥ kh√¥ng qu√° nghi√™m tr·ªçng. Trong ph·∫ßn cu·ªëi c√≥ th√≠ nghi·ªám v·ªÅ v·∫•n ƒë·ªÅ n√†y.\n2.3 Fault Tolerance ƒê·ªëi v·ªõi h·ªá th·ªëng th·ª±c, ki·∫øn tr√∫c c·ªßa h·ªá th·ªëng ph·∫£i ƒë·∫£m b·∫£o kh·∫£ nƒÉng ph·ª•c h·ªìi trong tr∆∞·ªùng h·ª£p c√≥ l·ªói x·∫£y ra. M·ªôt l·ª±a ch·ªçn ph·ªï bi·∫øn th∆∞·ªùng ƒë∆∞·ª£c hay d√πng l√† snapshot tr·∫°ng th√°i c·ªßa model ƒë·ªãnh k·ª≥, v√† ph·ª•c h·ªìi d·ªØ li·ªáu t·ª´ l·∫ßn snapshot cu·ªëi c√πng khi nh·∫≠n th·∫•y c√≥ l·ªói. Vi·ªác l·ª±a ch·ªçn t·∫ßng su·∫•t snapshot d·ª±a v√†o hai y·∫øu t·ªë ch√≠nh:\nCh·∫•t l∆∞·ª£ng model. Dƒ© nhi√™n r·∫±ng model snapshot ·ªü c√†ng g·∫ßn phi√™n b·∫£n cu·ªëi c√†ng t·ªët, do ƒë√≥ t·∫ßng su·∫•t snapshot ph·∫£i tƒÉng l√™n.\nChi ph√≠ s·ª≠ d·ª•ng h·ªá th·ªëng. Vi·ªác snapshot m·ªôt model c√≥ k√≠ch th∆∞·ªõc l·ªõn s·∫Ω t·ªën kha kh√° cpu v√† b·ªô nh·ªõ ƒë·ªÉ copy data, ngo√†i ra c√≤ng tƒÉng disk I/O\nƒê·ªÉ c√¢n b·∫±ng gi·ªØa 2 c√°i tr√™n, Monolith snapshot to√†n b·ªô training PS m·ªói ng√†y. Ch√∫ng ta s·∫Ω m·∫•t 1 ng√†y update data khi l·ªói x·∫£y ra. Nh∆∞ng qua c√°c th·ª≠ nghi·ªám c·ªßa nh√≥m k·ªπ s∆∞ ByteDance, th√¨ hi·ªáu nƒÉng suy gi·∫£m v·∫´n ·ªü m·ª©c ch·∫•p nh·∫≠n ƒë∆∞·ª£c.\n3. ƒê√°nh gi√° - EVALUATION ƒê·ªÉ hi·ªÉu h∆°n v·ªÅ l·ª£i √≠ch v√† s·ª± ƒë√°nh ƒë·ªïi c·ªßa m√¥ h√¨nh ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t,ch√∫ng ta x√¢y d·ª±ng m·ªôt v√†i th√≠ nghi·ªám v√† A/B testing tr√™n m√¥i tr∆∞·ªùng th·ª±c. M·ª•c ti√™u l√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi sau:\nL·ª£i √≠ch c·ªßa collisionless hashtable l√† bao nhi√™u?\nM·ª©c ƒë·ªô quang tr·ªçng c·ªßa realtime training online?\nLi·ªáu r·∫±ng m√¥ h√¨nh thi·∫øt k·∫ø c·ªßa Monolith v·ªõi c√°c tham s·ªë ƒë∆∞·ª£c ƒë·ªìng b·ªô nh∆∞ tr√™n ƒë√£ ƒë·ªß t·ªët trong m√¥i tr∆∞·ªùng th·ª±c t·∫ø?\n3.1 Thi·∫øt l·∫≠p th√≠ nghi·ªám 3.1.1 X√¢y d·ª±ng embedding table Nh∆∞ m√¥ t·∫£ ·ªü m·ª•c 2.1, embedding table trong monolith l√† collisionless hashtable. ƒê·ªÉ ch·ª©ng minh s·ª± c·∫ßn thi·∫øt c·ªßa vi·ªác tr√°nh ƒë·ª•ng ƒë·ªô trong vi·ªác thi·∫øt k·∫ø embedding table v√† l·ª£i √≠ch nh·∫≠n ƒë∆∞·ª£c t·ª´ phi√™n b·∫£n collisionless m√† m√¥ h√¨nh ƒë·ªÅ xu·∫•t, ch√∫ng ta th·ª±c hi·ªán hai nh√≥m th√≠ nghi·ªám tr√™n t·∫≠p Movielens v√† trong t·∫≠p internal production dataset c·ªßa ByteDance.\nH√¨nh 6: DeepFM model architecture - H√¨nh ·∫£nh ƒë∆∞·ª£c c·∫Øt t·ª´ paper\nMovieLens. L√† t·∫≠p dataset chu·∫©n , m·ªü, bao g·ªìm 25 tri·ªáu ƒë√°nh gi√° t·ª´ x·∫•p x·ªâ 162000 user v√† 62000 b·ªô phim: Ti·ªÅn x·ª≠ l√Ω label. Label g·ªëc c·ªßa t·∫≠p c√≥ gi√° tr·ªã t·ª´ 0.5 ƒë·∫øn 5, trong khi ƒë√≥, m√¥ h√¨nh monolith nh·∫≠n gi√° tr·ªã binary t·ª´ user. Ch√∫ng ta s·∫Ω chuy·ªÉn gi√° tr·ªã t·ª´ scale label sang binary label b·∫±ng vi·ªác ƒë·∫∑t ng∆∞·ª°ng \u0026gt;=3.5 l√† positive sample v√† b√© h∆°n 3.5 l√† negative sample\nƒê√°nh gi√° Model v√† metrics. Ch√∫ng ta s·∫Ω implement DeepFM model, m·ªôt ki·∫øn tr√∫c model ph·ªï bi·∫øn cho b√†i to√°n recommend. N√≥ bao g·ªìm th√†nh ph·∫ßn FM v√† th√†nh ph·∫ßn dense (xem k·ªπ h√¨nh 6).S·ª≠ d·ª•ng AUC ƒë·ªÉ ƒë√°nh gi√° gi√° tr·ªã predict.\nƒê√°nh gi√° Embedding collisions. Dataset n√†y c√≥ g·∫ßn 160k user v√† 60k movie. ƒê·ªÉ so s√°nh, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng MD5 l√†m qu√¢n ƒë·ªè v√† mapping v√†o m·ªôt nh√≥m nh·ªè ID space, m·ª•c ƒë√≠ch l√† l√†m cho m·ªôt v√†i ID s·∫Ω d√πng chung embedding v·ªõi nhau. B·∫£ng b√™n d∆∞·ªõi s·∫Ω hi·ªÉn th·ªã chi ti·∫øt th·ªëng k√™ c·ªßa user v√† movie tr∆∞·ªõc v√† sau hash\nVPB User IDs Movie IDs # Before Hashing 162541 59047 # After Hashing 149970 57361 Collision rate 7.73% 2.86% B·∫£ng 1: Th·ªëng k√™ ID tr∆∞·ªõc v√† sau khi hash\n3.1.2 Online training Trong qu√° tr√¨nh online training, ch√∫ng ta s·∫Ω c·∫≠p nh·∫≠t tham s·ªë t·ª´ training PS sang online PS v·ªõi t·∫ßn su·∫•t theo ph√∫t. Ch√∫ng ta thi·∫øt k·∫ø hai nh√≥m th√≠ nghi·ªám ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng c·ªßa m√¥ h√¨nh v√† ƒë·ªô t·∫£i c·ªßa h·ªá th·ªëng.\nUpdate frequency. ƒê·ªÉ ƒë√°nh gi√° s·ª± c·∫ßn thi·∫øt c·ªßa vi·ªác update theo ph√∫t, ch√∫ng ta x√¢y d·ª±ng th√≠ nghi·ªám v·ªõi t·∫ßng xu·∫•t update kh√°c nhau v√† xem s·ª± hi·ªáu qu·∫£. Ch√∫ng ta s·ª≠ d·ª•ng Criteo Display Ads Challenge dataset (https://www.kaggle.com/competitions/criteo-display-ad-challenge/data), ƒë√¢y l√† dataset ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ benchmarking CTR model. Data bao g·ªìm 7 ng√†y d·ªØ li·ªáu, ghi nh·∫≠n feature v√† h√†nh ƒë·ªông click c·ªßa ng∆∞·ªùi d√πng. Trong th√≠ nghi·ªám n√†y, ch√∫ng ta x√†i m√¥ h√¨nh DeepFM m√¥ t·∫£ trong h√¨nh 6. ƒê·ªÉ m√¥ ph·ªèng online training, ch√∫ng ta s·∫Ω chia t·∫≠p d·ªØ li·ªáu th√†nh 2 ph·∫ßn. Ph·∫ßn ƒë·∫ßu ti√™n l√† 5 ng√†y, d√πng ƒë·ªÉ train, ph·∫ßn th·ª© 2 l√† 2 ng√†y c√≤n l·∫°i, d√πng cho online training. Trong 2 ng√†y d·ªØ li·ªáu c·ªßa ph·∫ßn 2, ch√∫ng ta s·∫Ω chia th√†nh N shard. Th√≠ nghi·ªám v·ªõi N =10, 50, 100, t∆∞∆°ng ·ª©ng 5h (2 ng√†y = 48 ti·∫øng / 10 = 4.8 ti·∫øng ~ 5 ti·∫øng), 1h ( 48/50 ) v√† 30 ph√∫t c·∫≠p nh·∫≠t d·ªØ li·ªáu m·ªôt l·∫ßn.\nLive experiment. Th√™m n·ªØa, ch√∫ng ta s·∫Ω th·ª±c hi·ªán th√≠ nghi·ªám th·ª±c th·∫ø v·ªõi real serving traffice ƒë·ªÉ m√¥ ph·ªèng s·ª± quang tr·ªçng c·ªßa online training trong ·ª©ng d·ª•ng th·ª±c. Th√≠ nghi·ªám A/B testing n√†y so online training (A) vs batch training (B). 3.2 K·∫øt qu·∫£ v√† ph√¢n t√≠ch 3.2.1 Hi·ªáu qu·∫£ c·ªßa embedding collision H√¨nh 7: Effect of Embedding Collision On DeepFM, MovieLens\nC·∫£ hai k·∫øt qu·∫£ t·ª´ MovieLens dataset v√† Internal recommedation dataset ƒë·ªÅu ch·ªâ ra r·∫±ng collisions embedding g√¢y t·ªïn h·∫°i cho ch·∫•t l∆∞·ª£ng c·ªßa m√¥ h√¨nh.\nM√¥ h√¨nh v·ªõi collisionless HashTable cho k·∫øt qu·∫£ t·ªët h∆°n, lu√¥n c√≥ ƒë·ªì th·ªã n·∫±m ·ªü ngo√†i so v·ªõi m√¥ h√¨nh collision. K·∫øt lu·∫≠n n√†y lu√¥n lu√¥n ƒë√∫ng, cho d√π: TƒÉng s·ªë l∆∞·ª£ng training epoch. Nh∆∞ k·∫øt qu·∫£ ·ªü h√¨nh 7. M√¥ h√¨nh collisionless embedding table c√≥ AUC cao h∆°n ·ªü epoch ƒë·∫ßu ti√™n, v√† h·ªôi t·ª• v·ªõi gi√° tr·ªã cao h∆°n.\nThay ƒë·ªïi ph√¢n ph·ªëi theo th·ªùi gian (Concept Drift). Nh∆∞ hi·ªÉn th·ªã trong h√¨nh 8, m√¥ h√¨nh v·ªõi collisionless embedding table c≈©ng cho k·∫øt qu·∫£ r·∫•t t·ªët trong ng·ªØ c·∫£nh user/items thay ƒë·ªïi.\nT√≠nh th∆∞a c·ªßa data ƒë∆∞·ª£c sinh ra b·ªüi collisionless embedding table s·∫Ω kh√¥ng l√†m cho m√¥ h√¨nh b·ªã overfit. Nh∆∞ k·∫øt qu·∫£ ·ªü h√¨nh 7, m√¥ h√¨nh kh√¥ng b·ªã overfit sau khi n√≥ ƒë√£ h·ªôi t·ª• 3.2.2 Online Training: Trading-off Reliability For Realtime. H√¨nh 8: Effect of Embedding Collision On A Recommendation Model In Production.\nCh√∫ng ta kh√°m ph√° ra r·∫±ng vi·ªác ƒë·ªìng b·ªô c√°c tham s·ªë v·ªõi t·∫ßng su·∫•t cao th√¨ lu√¥n lu√¥n c·∫£i ti·∫øn online serving AUC, v√† m√¥ h√¨nh t·ªët h∆°n so v·ªõi k·ª≥ v·ªçng.\nThe Effect of Parameter Synchronization Frequency. Trong th√≠ nghi·ªám v·ªÅ online stream training v·ªõi Criteo Display Ads Challenge dataset, ch·∫•t l∆∞·ª£ng model s·∫Ω t·ªët h∆°n n·∫øu tƒÉng t·∫ßng su·∫•t ƒë·ªìng b·ªô ho√° m√¥ h√¨nh, ch·ª©ng minh b·∫±ng hai kh√≠a c·∫°nh sau: Model c√≥ online training s·∫Ω t·ªët h∆°n so v·ªõi m√¥ h√¨nh kh√¥ng c√≥ online training. Xem h√¨nh 9\nModel c√≥ t·∫ßn su·∫•t c·∫≠p nh·∫≠t cao s·∫Ω t·ªët h∆°n so v·ªõi m√¥ h√¨nh c√≥ tu·∫ßn su·∫•t c·∫≠p nh·∫≠t th·∫•p. Xem h√¨nh 10 v√† b·∫£ng 2\nH√¨nh 9: : Online training v.s. Batch training on Criteo dataset. Blue lines: AUC of models with online training; Yellow lines: AUC of batch training models evaluated against streaming data.\nSync Interval Average AUC (online) Average AUC (batch) 5 hr 79.66 ¬± 0.020 79.42 ¬± 0.026 1 hr 79.78 ¬± 0.005 79.44 ¬± 0.030 30 min 79.80 ¬± 0.008 79.43 ¬± 0.025 B·∫£ng 2: Average AUC comparison for DeepFM model on Criteo dataset\nH√¨nh 10: Comparison of different sync intervals for online training.\nB√™n c·∫°nh c√°c quan s√°t n√†y, ch√∫ng ta th·ª±c hi·ªán ƒë·ªìng b·ªô sparse parameter v√†o serving PS v·ªõi t·∫ßng su·∫•t c√†ng s·ªõm c√†ng t·ªët (theo ph√∫t) ƒë·ªÉ m·ªü r·ªông kh·∫£ nƒÉng t√≠nh to√°n v√† ƒë·ªô tin c·∫≠y c·ªßa h·ªá th·ªëng.\nGi·∫£ s·ª≠ r·∫±ng c√°c dense parameter y√™u c·∫ßu t·∫ßng su·∫•t c·∫≠p nh·∫≠t √≠t h∆°n nh∆∞ th·∫£o lu·∫≠n ·ªü m·ª•c 2.2.3, ch√∫ng ta s·∫Ω c·∫≠p nh·∫≠t ch√∫ng ·ªü m·ª©c ng√†y, v√† x√°c xu·∫•t h·ªá th·ªëng b·ªã qu√° t·∫£i s·∫Ω r·∫•t th·∫•p. V√≠ d·ª• ch√∫ng ta c√≥ 100k ID ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong 1 ph√∫t, embedding c√≥ k√≠ch th∆∞·ªõc 1024, t·ªïng k√≠ch th∆∞·ªõc c·ªßa data c·∫ßn ƒë·ªÉ chuy·ªÉn 4KB x 100000 = 40000 MB m·ªôt ph√∫t. V·ªõi dense parameter, n·∫øu ch√∫ng ta th·ª±c hi·ªán daily sync, ch√∫ng ta s·∫Ω ch·ªçn th·ªùi ƒëi·ªÉm sync m√† traffice l√† th·∫•p nh·∫•t ( g·∫ßn s√°ng ch·∫≥ng h·∫°n)\nThe effect of PS reliability V·ªõi vi·ªác ƒë·ªìng b·ªô ho√° c√°c tham s·ªë ·ªü m·ª©c ph√∫t, ch√∫ng ta t·ª± nhi√™n suy nghƒ© trong ƒë·∫ßu r·∫±ng t·∫ßng su·∫•t snapshot c≈©ng n√™n ph·∫£i t∆∞∆°ng ƒë∆∞∆°ng nh∆∞ v·∫≠y. Tuy nhi√™n trong th·ª±c t·∫ø, khi ch√∫ng ta s·ª≠ d·ª•ng snapshot v·ªõi t·∫ßng su·∫•t 1 ng√†y delay, ch·∫•t l∆∞·ª£ng m√¥ h√¨nh c≈©ng kh√¥ng gi·∫£m qu√° nhi·ªÅu.\nVi·ªác t√¨m ki·∫øm ƒëi·ªÉm c√¢n b·∫±ng gi·ªØa ch·∫•t l∆∞·ª£ng m√¥ h√¨nh v√† nƒÉng l·ª±c t√≠nh to√°n l√† r·∫•t kh√≥ trong b√†nh to√°n personalized ranking. Khi user c·ª±c k·ª≥ nh·∫°y c·∫£m v·ªõi ch·∫•t l∆∞·ª£ng recommendation. Theo truy·ªÅn th·ªëng, c√°c h·ªá th·ªëng l·ªõn th∆∞·ªùng c√≥ xu h∆∞·ªõng ƒë·∫∑t t·∫ßng xu·∫•t retrain theo h∆∞·ªõng hi sinh nƒÉng l·ª±c t√≠nh to√°n (ch·∫°y √¨ ·∫°ch, l√¢u c≈©ng ƒë∆∞·ª£c) v√† ƒë√°nh ƒë·ªïi b·ªüi c·ª±c ti·ªÉu ho√° ƒë·ªô l·ªói.\nV√≠ d·ª• v·ªõi t·ª∑ l·ªá l·ªói 0.01 c·ªßa PS machine / day, ch√∫ng ta s·∫Ω snapshot l·∫°i tham s·ªë c·ªßa ng√†y h√¥m tr∆∞·ªõc, Gi·∫£ s·ª≠ d√∫ng ta sharding parameter v√†o 1000PS, ch√∫ng snapshot m·ªói ng√†y. T·ª∑ l·ªá l·ªói 0.01%, m·ªói m·ªôt m√°y s·∫Ω b·ªã l·ªói sau 10 ng√†y , v√† ch√∫ng ta s·∫Ω m·∫•t to√†n b·ªô data c·ªßa 1 ng√†y c·∫≠p nh·∫≠t. Gi·∫£ s·ª≠ DAU c·ªßa 10 tri·ªáu v√† ch√∫ng ta m·∫•t 1 ng√†y d·ªØ li·ªáu c·ªßa 5k user m·ªói 10 ng√†y. ƒêi·ªÅu n√†y c√≥ th·ªÉ ƒë∆∞·ª£c ch·∫•p nh·∫≠n b·ªüi v√¨\na. V·ªõi c√°c ƒë·∫∑c tr∆∞ng th∆∞a c·ªßa user, n√≥ t∆∞∆°ng ƒë∆∞∆°ng v·ªõi t·ª∑ l·ªá m·∫•t 0.01% DAU\nb. V·ªõi c√°c ƒë·∫∑c tr∆∞ng Dense, ch√∫ng ta c·∫≠p nh·∫≠t kh√° ch·∫≠m, nh∆∞ th·∫£o lu·∫≠n ·ªü m·ª•c 2.2.3, vi·ªác m·∫•t 1 ng√†y update c·ªßa 1000 PS l√† kh√¥ng ƒë√°ng k·ªÉ.\nQua nh·ªØng quan s√°t v√† t√≠nh to√°n ·ªü tr√™n, ch√∫ng ta c√≥ th·ªÉ k·∫øt lu·∫≠n r·∫±ng t·∫ßng xu·∫•t snapshot th·∫•p kh√¥ng ·∫£nh h∆∞·ªüng nhi·ªÅu ƒë·∫øn kh·∫£ nƒÉng ch·ªãu l·ªói, v√† gi·∫£m kh·∫£ nƒÉng x·ª≠ l√Ω c·ªßa h·ªá th·ªëng.\nC·∫£m ∆°n nh√≥m k·ªπ s∆∞ ByteDance ƒë√£ cung c·∫•p r·∫•t nhi·ªÅu th√¥ng tin h·ªØu √≠ch trong b√†i vi·∫øt. Hi v·ªçng l·∫ßn sau s·∫Ω ƒë·ªçc ƒë∆∞·ª£c nhi·ªÅu b√†i ch·∫•t l∆∞·ª£ng h∆°n th·∫ø n·ªØa.\nT√†i li·ªáu tham kh·∫£o c·ªßa paper [1] \u0026ldquo;Mart√≠n Abadi, Paul Barham, Jianmin Chen, Z. Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek Gordon Murray, Benoit Steiner, Paul A. Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zhang. 2016. TensorFlow: A system for large-scale machine learning. ArXiv abs/1605.08695 (2016).\u0026rdquo;\n[2] Andrew P. Bradley. 1997. The use of the area under the ROC curve in the evaluation of machine learning algorithms. Pattern Recognit. 30 (1997), 1145‚Äì1159.\n[3] Thomas Bredillet. 2019. Core modeling at Instagram. https://instagram\u0002engineering.com/core-modeling-at-instagram-a51e0158aa48\n[4] Paris Carbone, Asterios Katsifodimos, Stephan Ewen, Volker Markl, Seif Haridi, and Kostas Tzoumas. 2015. Apache Flink‚Ñ¢: Stream and Batch Processing in a Single Engine. IEEE Data Eng. Bull. 38 (2015), 28‚Äì38.\n[5] Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishikesh B. Aradhye, Glen Anderson, Gregory S. Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah. 2016. Wide \u0026amp; Deep Learning for Recommender Systems. Proceedings of the 1st Workshop on Deep Learning for Recommender Systems (2016).\n[6] Paul Covington, Jay K. Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. Proceedings of the 10th ACM Conference on Recommender Systems (2016).\n[7] Alexandra Egg. 2021. Online Learning for Recommendations at Grubhub. Fif\u0002teenth ACM Conference on Recommender Systems (2021).\n[8] Jo√£o Gama, Indre ≈Ωliobait Àô e, Albert Bifet, Mykola Pechenizkiy, and A. Bouchachia. 2014. A survey on concept drift adaptation. ACM Computing Surveys (CSUR) 46 (2014), 1 ‚Äì 37.\n[9] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. In IJCAI.\n[10] Udit Gupta, Xiaodong Wang, Maxim Naumov, Carole-Jean Wu, Brandon Reagen, David M. Brooks, Bradford Cottel, Kim M. Hazelwood, Bill Jia, Hsien-Hsin S. Lee, Andrey Malevich, Dheevatsa Mudigere, Mikhail Smelyanskiy, Liang Xiong, and Xuan Zhang. 2020. The Architectural Implications of Facebook‚Äôs DNN-Based Personalized Recommendation. 2020 IEEE International Symposium on High Performance Computer Architecture (HPCA) (2020), 488‚Äì501.\n[11] F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Trans. Interact. Intell. Syst. 5 (2015), 19:1‚Äì19:19.\n[12] Biye Jiang, Chao Deng, Huimin Yi, Zelin Hu, Guorui Zhou, Yang Zheng, Sui Huang, Xinyang Guo, Dongyue Wang, Yue Song, Liqin Zhao, Zhi Wang, PengSun, Yu Zhang, Di Zhang, Jinhui Li, Jian Xu, Xiaoqiang Zhu, and Kun Gai. 2019 XDL: an industrial deep learning framework for high-dimensional sparse data. Proceedings of the 1st International Workshop on Deep Learning Practice for High\u0002Dimensional Sparse Data (2019).\n[13] Jay Kreps. 2011. Kafka : a Distributed Messaging System for Log Processing.\n[14] Xiangru Lian, Binhang Yuan, Xuefeng Zhu, Yulong Wang, Yongjun He, Honghuan Wu, Lei Sun, Haodong Lyu, Chengjun Liu, Xing Dong, Yiqiao Liao, Mingnan Luo, Congfei Zhang, Jingru Xie, Haonan Li, Lei Chen, Renjie Huang, Jianying Lin, Chengchun Shu, Xue-Bo Qiu, Zhishan Liu, Dongying Kong, Lei Yuan, Haibo Yu, Sen Yang, Ce Zhang, and Ji Liu. 2021. Persia: An Open, Hybrid System Scaling Deep Learning-based Recommenders up to 100 Trillion Parameters. ArXivabs/2111.05897 (2021).\n[15] Meituan. 2021. Distributed Training Optimization for TensorFlow in Recom\u0002mender Systems (in Chinese). https://tech.meituan.com/202112/09/meituantensorflow-in-recommender-systems.html\n[16] R. Pagh and Flemming Friche Rodler. 2001. Cuckoo Hashing. In ESA.\n[17] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas K√∂pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In NeurIPS.\n[18] Konstantin V. Shvachko, Hairong Kuang, Sanjay R. Radia, and Robert J. Chansler. 2010. The Hadoop Distributed File System. 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST) (2010), 1‚Äì10.\n[19] HaiYing Wang, Aonan Zhang, and Chong Wang. 2021. Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data. In Advances in Neural Information Processing Systems.\n[20] Minhui Xie, Kai Ren, Youyou Lu, Guangxu Yang, Qingxing Xu, Bihai Wu, Jiazhen Lin, Hongbo Ao, Wanhong Xu, and Jiwu Shu. 2020. Kraken: Memory-Efficient Continual Learning for Large-Scale Real-Time Recommendations. SC20: Inter\u0002national Conference for High Performance Computing, Networking, Storage and Analysis (2020), 1‚Äì17.\n[21] Weijie Zhao, Jingyuan Zhang, Deping Xie, Yulei Qian, Ronglai Jia, and Ping Li.2019. AIBox: CTR Prediction Model Training on a Single Node. Proceedings of the 28th ACM International Conference on Information and Knowledge Management (2019).\nTham kh·∫£o https://arxiv.org/pdf/2209.07663.pdf\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ d√†nh th·ªùi gian ƒë·ªçc b√†i t√≥m t·∫Øt n√†y c·ªßa m√¨nh. N·∫øu c√≥ b·∫•t k·ª≥ v·∫•n ƒë·ªÅ g√¨, h√£y ƒë·ªÉ l·∫°i comment b√™n d∆∞·ªõi ho·∫∑c email cho m√¨nh qua ƒë·ªãa ch·ªâ alexblack2202@gmail.com. H·∫πn g·∫∑p l·∫°i c√°c b·∫°n ·ªü b√†i vi·∫øt ti·∫øp theo.\n","date":"Dec 1, 2022","img":"https://unsplash.it/1920/1080?image=18","permalink":"/blog/2022-12-01-tiktok-recommendation/","series":null,"tags":["Machine Learning","Tikok","Deep Learning","ByteDance","Recommendation"],"title":"Tiktok Real Time Recommendation"},{"categories":null,"content":"M·ª•c ti√™u c·ªßa ch√∫ng ta h√¥m nay l√† kh√°m ph√° t·∫≠p dataset netflix n√†y, ƒë·ªÉ kh√°m ph√° v√† ƒë√†o x·ªõi nh·ªØng th√¥ng tin ·∫©n b√™n trong, ph·ª•c v·ª• cho vi·ªác ra quy·∫øt ƒë·ªãnh lo·∫°i phim/ ch∆∞∆°ng tr√¨nh n√†o n√™n s·∫£n xu·∫•t v√† ch√∫ng ta n√™n ƒë·ªÅ xu·∫•t lo·∫°i h√¨nh kinh doanh n√†o cho m·ªói qu·ªëc gia kh√°c nhau.\nTr·ª±c quan ho√° d·ªØ li·ªáu - Data Visualization Tr·ª±c quan ho√° d·ªØ li·ªáu - Data Visualization Dataset c√°c b·∫°n c√≥ th·ªÉ download ·ªü ƒë√¢y: https://www.kaggle.com/datasets/shivamb/netflix-shows\nƒê·∫ßu ti√™n, ch√∫ng ta s·∫Ω import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt ƒë·ªÉ ph·ª•c v·ª• cho vi·ªác ph√¢n t√≠ch. C√°c nh∆∞ vi·ªán kh√¥ng th·ªÉ thi·∫øu l√† pandas, matplotlib, seaborn, numpy.\n1 2import matplotlib.pyplot as plt 3 4import seaborn as sns 5 6import pandas as pd Ng√≥ s∆° qua dataset, ch√∫ng ta c√≥ c√°c c·ªôt nh∆∞ sau:\nShow_id: m√£ ƒë·ªãnh danh duy nh·∫•t cho c√°c show / phim\nType: Lo·∫°i ch∆∞∆°ng tr√¨nh\nTitle: T√™n phim / show\nDirector: T√™n ƒë·∫°o di·ªÖn\nCast: Di·ªÖn vi√™n ch√≠nh\nCountry: Qu·ªëc gia n∆°i b·ªô phim ƒë∆∞·ª£c s·∫£n xu·∫•t\nDate_added: Ng√†y ƒë∆∞·ª£c ƒë∆∞a l√™n h·ªá th·ªëng netflix\nRelease_year: Ng√†y ho√†n th√†nh b·ªô phim\nRating: ƒêi·ªÉm y√™u th√≠ch c·ªßa b·ªô phim\nDuration: Th·ªùi gian c·ªßa b·ªô phim, ho·∫∑c s·ªë t·∫≠p .\nListed_in: Th·ªÉ lo·∫°i phim\nDescription: M√¥ t·∫£ s∆° b·ªô v·ªÅ b·ªô phim\nB√¢y gi·ªù, ch√∫ng ta load d·ªØ li·ªáu b·∫±ng pandas v√† ph√¢n t√≠ch th·ª≠\n1 2data=pd.read_csv(\u0026#39;netflix.csv\u0026#39;) 3 4print(data.shape) 5 6\u0026gt;\u0026gt;\u0026gt;(8807, 12) Data c√≥ 12 c·ªôt nh∆∞ ƒë√£ ƒë·ªÅ c·∫≠p ·ªü tr√™n, 8807 d√≤ng. Ng√≥ xem ph√¢n b·ªë d·ªØ li·ªáu r·ªóng nh∆∞ th·∫ø n√†o\n1 2plt.figure(figsize=(8,8)) 3sns.heatmap(data.isna()) 4 5plt.show() Nh√¨n v√†o bi·ªÉu ƒë·ªì tr√™n, ch√∫ng ta th·∫•y r·∫±ng c·ªôt director b·ªã l·ªßng NA nhi·ªÅu nh·∫•t, ti·∫øp ƒë·∫øn l√† c·ªôt cast v√† c·ªôt country. C·ªôt Date_added v√† v√† rating l·ªßng ch√∫t ch√∫t, c√°c c·ªôt c√≤n l·∫°i kh√° t·ªët.\nDo c·ªôt director b·ªã l·ªßng nhi·ªÅu, n√™n ch√∫ng ta s·∫Ω b·ªè qua, kh√¥ng ph√¢n t√≠ch top 10 ƒë·∫°o ƒëi·ªÖn c√≥ s·ªë l∆∞·ª£ng phim nhi·ªÅu nh·∫•t. T∆∞∆°ng t·ª± nh∆∞ v·∫≠y v·ªõi c·ªôt di·ªÖn vi√™n ch√≠nh (cast), v√† c·ªôt qu·ªëc gia s·∫£n xu·∫•t (country). Ng√≥ ƒëi ng√≥ l·∫°i, ch·ªâ c√≤n c√≥ li·ªát k√™ top 10 th·ªÉ lo·∫°i phim (Listed_in) ƒë∆∞·ª£c s·∫£n xu·∫•t nhi·ªÅu nh·∫•t .\n1 2plt.figure(figsize=(16,16)) 3data[\u0026#34;listed_in\u0026#34;].value_counts()[:10].plot(kind=\u0026#34;barh\u0026#34;, color=\u0026#34;orange\u0026#34;) 4plt.title(\u0026#34;Top 10 th·ªÉ lo·∫°i phim tr√™n NETFLIX\u0026#34;,size=20) 5 6plt.show() Phim truy·ªÅn h√¨nh v√† phim t√†i li·ªáu c√≥ s·ªë l∆∞·ª£ng phim nhi·ªÅu nh·∫•t, ti·∫øp theo l√† phim h√†i\nDo Na ·ªü c·ªôt country kh√° nhi·ªÅu, n√™n ch√∫ng ta s·∫Ω lo·∫°i b·ªè h·∫øt c√°c d√≤ng c√≥ contry na ƒëi\n1 2df = data.copy() 3df[\u0026#39;country\u0026#39;] = df[\u0026#39;country\u0026#39;].ffill(axis=0) 4df.head(10) Quan s√°t d·ªØ li·ªáu c·ªôt country, ch√∫ng ta nh·∫≠n th·∫•y r·∫±ng c√≥ nhi·ªÅu phim ƒë∆∞·ª£c quay ·ªü nhi·ªÅu ƒë·ªãa ƒëi·ªÉm, n√™n ch√∫ng ta ta c·∫ßn x·ª≠ l√Ω l·∫°i ch·ªó n√†y m·ªôt ch√∫t. ƒê∆°n gi·∫£n l√† m√¨nh ch·ªâ l·∫•y qu·ªëc gia ƒë·∫ßu ti√™n xu·∫•t hi·ªán trong c·ªôt country.\n1 2df[\u0026#39;trim_country\u0026#39;] = df[\u0026#39;country\u0026#39;].apply(lambda x: x.split(\u0026#39;,\u0026#39;)[0]) 3df.head(10) Th·ª≠ show ra bi·ªÉu ƒë·ªì rating c·ªßa top 5 qu·ªëc gia nhi·ªÅu phim nh·∫•t\n1 2 3countries = df[\u0026#39;trim_country\u0026#39;].unique() 4 5ratings = df[\u0026#39;rating\u0026#39;].unique() 6 7fig = plt.figure( 8 figsize=(20,30) 9 ) 10 11for i, name in enumerate(countries[:5]): 12 frame = df[df[\u0026#39;trim_country\u0026#39;] == str(name)] 13 ax = fig.add_subplot(len(countries[:5]),1,i+1) 14 topic = name 15 sns.countplot(x=\u0026#39;rating\u0026#39;, data= frame[frame[\u0026#39;rating\u0026#39;].isin(ratings)]) 16 ax.set_title(topic) 17 plt.subplots_adjust(left=0.1, 18 bottom=0.1, 19 right=0.9, 20 top=0.9, 21 wspace=0.4, 22 hspace=0.4) 23 ax.set(ylabel=\u0026#39;Content Produced\u0026#39;) Th·ª≠ show ra bi·ªÉu ƒë·ªì ƒë·∫øm th·ªÉ lo·∫°i phim ƒë∆∞·ª£c quay tr√™n top 5 qu·ªëc gia c√≥ nhi·ªÅu phim nh·∫•t xem nh∆∞ th·∫ø n√†o\n1 2countries = df[\u0026#39;trim_country\u0026#39;].unique() 3 4listing = df[\u0026#39;trim_listed_in\u0026#39;].unique() 5ratings = df[\u0026#39;rating\u0026#39;].unique() 6 7fig = plt.figure( 8 figsize=(40,30) 9 ) 10 11for i, name in enumerate(countries[:5]): 12 frame = df[df[\u0026#39;trim_country\u0026#39;] == str(name)] 13 ax = fig.add_subplot(len(countries[:5]),1,i+1) 14 topic = name 15 sns.countplot(x=\u0026#39;trim_listed_in\u0026#39;, data= frame[frame[\u0026#39;trim_listed_in\u0026#39;].isin(listing)]) 16 ax.set_title(topic) 17 plt.subplots_adjust(left=0.1, 18 bottom=0.1, 19 right=0.9, 20 top=0.9, 21 wspace=0.4, 22 hspace=0.4) 23 ax.set(ylabel=\u0026#39;Content Produced\u0026#39;) C√≤n nhi·ªÅu c√°i ƒë·ªÉ kh√°m ph√° n·ªØa, v√≠ d·ª•\nTop 10 di·ªÖn vi√™n xu·∫•t hi·ªán nhi·ªÅu nh·∫•t tr√™n TV Shows\nTop 10 di·ªÖn vi√™n xu·∫•t hi·ªán nhi·ªÅu nh·∫•t tr√™n Movies\nTV Shows nhi·ªÅu m√πa nh·∫•t\nTh·ªùi gian c√¥ng chi·∫øu d√†i nh·∫•t\nTham kh·∫£o:\nhttps://www.kaggle.com/code/shivamb/netflix-shows-and-movies-exploratory-analysis/notebook\nhttps://www.analyticsvidhya.com/blog/2021/09/performing-eda-of-netflix-dataset-with-plotly/\nhttps://medium.datadriveninvestor.com/netflix-data-exploration-and-visualization-1d270234c2d4\nhttps://public.tableau.com/views/DataVizProject_16166857387730/dashboard_assignement?%3Aembed=y\u0026%3AshowVizHome=no\u0026%3Adisplay_count=y\u0026%3Adisplay_static_image=y\u0026%3AbootstrapWhenNotified=true\u0026%3Alanguage=en\u0026%3Amobile=true\u0026:embed=y\u0026:showVizHome=n\u0026:apiID=host0\nhttps://jovian.ai/shagunsharma04061998/netflix-data-analysis/v/1?utm_source=embed#C33\n","date":"Aug 2, 2022","img":"https://unsplash.it/1920/1080?image=19","permalink":"/blog/2022-08-02-data-exploration-and-data-visualization/","series":null,"tags":["Machine Learning","Normalization","Deep Learning"],"title":"Data Visualization - Ph·∫ßn 1 - Ph√¢n T√≠ch D·ªØ Li·ªáu Netflix"},{"categories":null,"content":"Photo m√¨nh l·∫•y t·ª´ unsplash\nPython l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh n·ªïi ti·∫øng v√¨ t√≠nh c·ª±c k·ª≥ linh ho·∫°t. Trong b√†i vi·∫øt n√†y, m√¨nh s·∫Ω li·ªát k√™ 7 c√°ch ƒë·ªÉ ƒë·ªçc n·ªôi dung file s·ª≠ d·ª•ng ng√¥n ng·ªØ Python.\nC√°ch 1: S·ª≠ d·ª•ng h√†m open C√°ch 2: m·ªü file s·ª≠ d·ª•ng context manager C√°ch 3: S·ª≠ d·ª•ng th∆∞ vi·ªán pathlib C√°ch 4: S·ª≠ d·ª•ng shell C√°ch 5: X√¢y d·ª±ng m·ªôt th∆∞ vi·ªán ƒë·ªçc file b·∫±ng c C√°ch 1: S·ª≠ d·ª•ng h√†m open C√°ch ƒë·∫ßu ti√™n, c≈©ng l√† c√°ch v·ª° l√≤ng / gi√°o khoa/ tr∆∞·ªùng l·ªõp, l√† s·ª≠ d·ª•ng h√†m open, tr·∫£ v·ªÅ m·ªôt stream. Sau ƒë√≥, ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m read ƒë·ªÉ l·∫•y n·ªôi dung t·ª´ stream.\nV√≠ d·ª•, ch√∫ng ta s·∫Ω ƒë·ªçc file thegioididong.txt b·∫±ng ng√¥n ng·ªØ python nh∆∞ sau:\n1 2tgdd = open(\u0026#39;thegioididong.txt\u0026#39;,\u0026#39;r\u0026#39;) 3 4lines = tgdd.read() 5print(lines) 6 7tgdd.close() ∆Øu ƒëi·ªÉm:\nKh√¥ng ph·∫£i include th√™m th∆∞ vi·ªán\nCode ng·∫Øn g·ªçn\nKhuy·∫øt ƒëi·ªÉm:\nPh·∫£i close file sau khi s·ª≠ d·ª•ng xong C√°ch 2: m·ªü file s·ª≠ d·ª•ng context manager Tr√™n stackoverflow th∆∞·ªùng khuy√™n ch√∫ng ta s·ª≠ d·ª•ng c√°ch n√†y\n1 2with open(\u0026#39;thegioididong.txt\u0026#39;,\u0026#39;r\u0026#39;) as tgdd: 3 4 lines = tgdd.read() 5 print(lines) ∆Øu ƒëi·ªÉm:\nKh√¥ng ph·∫£i ƒë√≥ng file sau khi s·ª≠ d·ª•ng xong\nNgƒÉng ng·ª´a memory leaks khi c√≥ l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω v√† kh√¥ng g·ªçi ƒë√≥ng file.\nC√°ch 3: S·ª≠ d·ª•ng th∆∞ vi·ªán pathlib C√°ch d√πng c≈©ng kh√° d·ªÖ, ch·ªâ c·∫ßn include th∆∞ vi·ªán v√†o l√† x√†i th√¥i\n1 2import pathlib 3tgdd = pathlib.Path(\u0026#34;thegioididong.txt\u0026#34;) 4lines = tgdd.read_text() C√°ch n√†y c≈©ng hay, kh√¥ng ph·∫£i ƒë√≥ng m·ªü file, ch·ªâ c·∫ßn g·ªçi h√†m ƒë·ªçc l√† ƒë∆∞·ª£c. Code th√¨ ng·∫Øn g·ªçn, l·∫°i kh√¥ng ph·∫£i th√≤ ra th·ª•t v√†o nh∆∞ l√† context manager\nC√°ch 4: S·ª≠ d·ª•ng shell Ch√∫ng ta c√≥ th·ªÉ d√πng python, g·ªçi shell script trong linux , v√† l·∫•y k·∫øt qu·∫£ tr·∫£ v·ªÅ.\nƒê·ªÉ s·ª≠ d·ª•ng c√°ch n√†y, ch√∫ng ta s·ª≠ d·ª•ng th∆∞ vi·ªán subprocess\n1 2import subprocess 3output = subprocess.run([\u0026#34;cat\u0026#34;, \u0026#34;thegioididong.txt\u0026#34;], capture_output=True) 4lines = output.stdout.decode() N√†y l√† m·ªôt c√°ch c√≥ th·ªÉ d√πng ƒë∆∞·ª£c, tuy nhi√™n, m·ªôt s·ªë file c√≥ th·ªÉ b·ªã l·ªói encode. T√∫m l·∫°i l√† kh√¥ng n√™n x√†i c√°i n√†y\nC√°ch 5: X√¢y d·ª±ng m·ªôt th∆∞ vi·ªán ƒë·ªçc file b·∫±ng c ƒê·ªÉ s·ª≠ d·ª•ng c√°ch n√†y, c√°c b·∫°n c·∫ßn ph·∫£i c√†i b·∫£n python3-dev v√†o m√°y tr∆∞·ªõc (tr√™n ubuntu).\nV√≠ d·ª•, ch√∫ng ta s·∫Ω t·∫°o m·ªôt file mwg_file.c nh∆∞ sau\n1#define PY_SSIZE_T_CLEAN 2#include \u0026lt;Python.h\u0026gt; 3 4 5PyObject* mwgread(PyObject* self, PyObject* args) { 6 7 8 FILE * pFile; 9 size_t lSize; 10 char * buffer; 11 size_t result; 12 13 // Parse the Python object arguments into C variables 14 char* filename; 15 if (!PyArg_ParseTuple(args, \u0026#34;s\u0026#34;, \u0026amp;filename)) { 16 return NULL; 17 } 18 19 // Try to open the file 20 pFile = fopen(filename, \u0026#34;r\u0026#34;); 21 if (pFile == NULL) { 22 return NULL; 23 } 24 25 // obtain file size: 26 fseek (pFile , 0 , SEEK_END); 27 lSize = ftell (pFile); 28 rewind (pFile); 29 30 // allocate memory to contain the whole file: 31 buffer = (char*) malloc (sizeof(char)*lSize); 32 if (buffer == NULL) {fputs (\u0026#34;Memory error\u0026#34;,stderr); exit (2);} 33 34 // copy the file into the buffer: 35 result = fread (buffer,1,lSize,pFile); 36 if (result != lSize) {fputs (\u0026#34;Reading error\u0026#34;,stderr); exit (3);} 37 38 /* the whole file is now loaded in the memory buffer. */ 39 40 // terminate 41 fclose (pFile); 42 return Py_BuildValue(\u0026#34;s\u0026#34;, buffer); 43} 44 45 46PyMethodDef module_methods[] = { 47 {\u0026#34;read\u0026#34;, mwgread, METH_VARARGS, \u0026#34;Reads a file and returns its contents\u0026#34;}, 48 {NULL} 49}; 50 51struct PyModuleDef file_module = { 52 PyModuleDef_HEAD_INIT, 53 \u0026#34;MWGFile\u0026#34;, 54 NULL, 55 -1, 56 module_methods 57}; 58 59PyMODINIT_FUNC PyInit_MWGFile(void) { 60 return PyModule_Create(\u0026amp;file_module); 61} M·ªôt ph·∫ßn code c tr√™n m√¨nh l·∫•y t·ª´ https://cplusplus.com/reference/cstdio/fread/\nSau ƒë√≥, ch√∫ng ta s·∫Ω t·∫°o file setup.py, file n√†y ƒë·ªÉ chung th∆∞ m·ª•c v·ªõi file .c\n1 2from distutils.core import setup, Extension 3 4setup( 5 name=\u0026#39;MWGFile\u0026#39;, 6 ext_modules=[Extension(\u0026#39;MWGFile\u0026#39;, sources=[\u0026#39;mwg_file.c\u0026#39;])] 7) Cu·ªëi c√πng, ch√∫ng ta g·ªçi h√†m ƒë·ªÉ bi√™n d·ªãch file c v√† c√†i v√†o th∆∞ vi·ªán h·ªá th·ªëng\n1 2python3 setup.py build 3python3 setup.py install --user ƒê·ªÉ ch·∫°y th∆∞ vi·ªán c v·ª´a m·ªõi bi√™n d·ªãch, ch√∫ng ta s·ª≠ d·ª•ng l·ªánh sau\n1 2import MWGFile 3contents = MWGFile.read_file(\u0026#34;thegioididong.txt\u0026#34;) 4print(contents) C√°ch n√†y kh√° c·ª±c, ph·∫£i reimplement l·∫°i nh·ªØng g√¨ c·ªông ƒë·ªìng ƒë√£ l√†m s·∫µn, nh∆∞ng m√† c≈©ng n√™n th·ª≠ ƒë·ªÉ x√¢y d·ª±ng c√°c th∆∞ vi·ªán n·ªôi b·ªô c·ªßa ri√™ng m√¨nh.\nT√†i li·ªáu tham kh·∫£o\nhttps://www.w3schools.com/python/python_file_open.asp\nhttps://betterprogramming.pub/7-ways-of-reading-a-file-in-python-855340b002dc\n","date":"Jul 31, 2022","img":"https://unsplash.it/1920/1080?image=20","permalink":"/blog/2022-07-31-5-way-open-file/","series":null,"tags":["Machine Learning","Normalization","Deep Learning"],"title":"5 C√°ch M·ªü File Trong Python"},{"categories":"python","content":"N·ªôi dung b√†i vi·∫øt n√†y s·∫Ω ƒë·ªÅ c·∫≠p ƒë·∫øn c√°c ch·ªß ƒë·ªÅ\nH√†m trong python Tham s·ªë m·∫∑c ƒë·ªãnh Arbitrary Arguments Keyword Arguments Arbitrary Keyword Arguments H√†m Lambda trong python H√†m map H√†m filter H√†m reduce H√†m trong python H√†m l√† m·ªôt kh·ªëi l·ªánh, ƒë∆∞·ª£c th·ª±c thi khi ƒë∆∞·ª£c g·ªçi.\nH√†m ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a b·∫±ng t·ª´ kho√° def.\nH√†m c√≥ th·ªÉ nh·∫≠n d·ªØ li·ªáu truy·ªÅn v√†o, ƒë∆∞·ª£c g·ªçi l√† tham s·ªë\nH√†m c√≥ th·ªÉ tr·∫£ v·ªÅ d·ªØ li·ªáu\nV√≠ d·ª•\n1 2def isSoChan(x:int): # khai b√°o h√†m c√≥ t√™n l√† isSoChan, v·ªõi tham s·ªë truy·ªÅn v√†o ki·ªÉu int 3 if x \u0026lt;0: 4 return False 5 if x % 2 != 0: 6 return False 7 return True 8 9isSoChan(5) # g·ªçi th·ª±c thi h√†m isSoChan, v·ªõi gi√° tr·ªã c·ªßa tham s·ªë x l√† 5 Tham s·ªë m·∫∑c ƒë·ªãnh M·ªôt s·ªë h√†m s·∫Ω c√≥ tham s·ªë m·∫∑c ƒë·ªãnh, s·ª≠ d·ª•ng khi ta b·ªè tr·ªëng, kh√¥ng truy·ªÅn gi√° tr·ªã cho tham s·ªë, v√≠ d·ª• nh∆∞ l√† tham s·ªë start c·ªßa h√†m range c√≥ gi√° tr·ªã m·∫∑c ƒë·ªãnh l√† 0.\n1 2def printCountry(contry_name = \u0026#34;Vi·ªát Nam\u0026#34;): 3 print(contry_name) 4 5 6printCountry(\u0026#34;USA\u0026#34;) 7printCountry() 8 9#K·∫øt qu·∫£ 10 11\u0026gt;\u0026gt;\u0026gt; printCountry(\u0026#34;USA\u0026#34;) 12USA 13\u0026gt;\u0026gt;\u0026gt; printCountry() 14Vi·ªát Nam Arbitrary Arguments ƒê√¥i khi, ch√∫ng ta kh√¥ng th·ªÉ x√°c ƒë·ªãnh ƒë∆∞·ª£c s·ªë l∆∞·ª£ng tham s·ªë truy·ªÅn v√†o, python h·ªó tr·ª£ ta quƒÉng c√°c gi√° tr·ªã truy·ªÅn d∆∞ v√†o m·ªôt tham s·ªë c·∫•p 1. T√™n vi·∫øt t·∫Øt c·ªßa d·∫°ng n√†y l√† *args\nV√≠ d·ª•\n1def info(name, *args): 2 print(f\u0026#34;input name: {name}\u0026#34;) 3 for item in args: 4 print(f\u0026#34;other info: {item}\u0026#34;) 5 6info(\u0026#34;alex\u0026#34;,\u0026#34;18\u0026#34;,\u0026#34;staff\u0026#34;,\u0026#34;samsung\u0026#34;,\u0026#34;apple\u0026#34;) 7 8#K·∫øt qu·∫£: 9 10input name: alex 11other info: 18 12other info: staff 13other info: samsung 14other info: apple Keyword Arguments ƒê·ªÉ g·ªçi h√†m m·ªôt c√°ch t∆∞·ªùng minh, python cho ph√©p truy·ªÅn tham s·ªë b·∫±ng c√°ch ch·ªâ r√µ t√™n tham s·ªë c·∫ßn truy·ªÅn d·ªØ li·ªáu\nV√≠ d·ª•\n1def info(name, age, position): 2 print(f\u0026#34;name {name} age {age} position {position}\u0026#34;) 3 4info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 5 6 7info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 8 9# K·∫øt qu·∫£: 10 11\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 12name alex age 18 position staff 13\u0026gt;\u0026gt;\u0026gt; 14\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 15name bill age 18 position staff Arbitrary Keyword Arguments Trong tr∆∞·ªùng h·ª£p c√≥ nhi·ªÅu tham s·ªë qu√°, ch√∫ng ta c√≥ th·ªÉ vi·∫øt t·ªïng h·ª£p c√°c tham s·ªë d∆∞·ªõi d·∫°ng tham s·ªë c·∫•p 2. T√™n vi·∫øt t·∫Øt c·ªßa d·∫°ng n√†y l√† **kwargs\nV√≠ d·ª•\n1 2def info(**data): 3 print(f\u0026#34;name {data[\u0026#39;name\u0026#39;]} age {data[\u0026#39;age\u0026#39;]} position {data[\u0026#39;position\u0026#39;]}\u0026#34;) 4 5info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 6 7 8info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 9 10 11# K·∫øt qu·∫£ 12 13\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 14name alex age 18 position staff 15\u0026gt;\u0026gt;\u0026gt; 16\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;bill\u0026#34;, position=\u0026#34;staff\u0026#34; , age=18) 17name bill age 18 position staff H√†m Lambda trong python H√†m Lambda l√† h√†m ch·ªâ c√≥ m·ªôt bi·ªÉu th·ª©c\nH√†m Lambda c√≥ th·ªÉ nh·∫≠n nhi·ªÅu tham s·ªë\nC√∫ ph√°p\n1 2lambda arguments : expression V√≠ d·ª•:\n1 2info = lambda name, age, position : f\u0026#34;name {name} age {age} position {position}\u0026#34; 3 4info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 5 6# K·∫øt qu·∫£ 7\u0026gt;\u0026gt;\u0026gt; info(name=\u0026#34;alex\u0026#34;, age=18, position=\u0026#34;staff\u0026#34;) 8\u0026#39;name alex age 18 position staff\u0026#39; S·ª©c m·∫°nh c·ªßa lambda ƒë∆∞·ª£c khai th√°c t·ªëi ƒëa, khi lamda l√† tham s·ªë c·ªßa m·ªôt h√†m kh√°c.\nH√†m map C√∫ ph√°p\n1 2map(function, iterable) Do input c·ªßa map l√† function, n√™n n√≥ c√≥ th·ªÉ l√† m·ªôt h√†m t∆∞·ªùng minh, ho·∫∑c l√† m·ªôt lambda function\nV√≠ d·ª•:\nH√£y nh√¢n ƒë√¥i t·∫•t c·∫£ c√°c gi√° tr·ªã trong list\n1 2aList = [1,2,3,4,5] 3 4# C√°ch vi·∫øt th√¥ng th∆∞·ªùng 5 6def square(x:int): 7 return x**2 8 9newList = [] 10for x in aList: 11 newList.append(square(x)) 12 13print(newList) 14 15# C√°ch vi·∫øt s·ª≠ d·ª•ng list comprehension 16 17newList = [x**2 for x in newList] 18print(newList) 19 20# C√°ch vi·∫øt s·ª≠ d·ª•ng map k·∫øt h·ª£p lambda 21 22newList = list(map(lambda x:x**2,aList)) 23 24print(newList) 25 26\u0026gt;\u0026gt;\u0026gt; print(newList) 27[1, 4, 9, 16, 25] H√†m filter C√∫ ph√°p\n1 2filter(function, iterable) H√†m n√†y t·ª±a t·ª±a nh∆∞ list comprehension v·ªõi if contion\nV√≠ d·ª•:\nH√£y l·ªçc ra c√°c ph·∫ßn t·ª≠ l√† s·ªë ch·∫µn\n1 2aList = [1,2,3,4,5] 3 4# C√°ch vi·∫øt th√¥ng th∆∞·ªùng 5 6def isEven(x:int): 7 return x%2==0 8 9newList = [] 10for x in aList: 11 newList.append(isEven(x)) 12 13print(newList) 14 15# C√°ch vi·∫øt s·ª≠ d·ª•ng list comprehension 16 17newList = [x for x in newList if x %2 ==0] 18print(newList) 19 20# C√°ch vi·∫øt s·ª≠ d·ª•ng filter k·∫øt h·ª£p lambda 21 22newList = list(filter(lambda x:x%2==0,aList)) 23 24print(newList) 25 26\u0026gt;\u0026gt;\u0026gt; print(newList) 27[2, 4] H√†m reduce H√†m c√≥ nhi·ªám v·ª• t√≠ch lu·ªπ t·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ v√† tr·∫£ v·ªÅ m·ªôt gi√° tr·ªã duy nh·∫•t\nC√∫ ph√°p\n1 2reduce(function, iterable, [, initializer]) V√≠ d·ª•:\nT√≠nh t·ªïng c√°c ph·∫ßn t·ª≠ trong list s·ª≠ d·ª•ng reduce\n1 2from functools import reduce 3 4aList = [1,2,3,4,5] 5 6print(reduce(lambda x,y: x+y,aList)) 7 8K·∫øt qu·∫£: 9\u0026gt;\u0026gt;\u0026gt; print(reduce(lambda x,y: x+y,aList)) 1015 ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa s·ªë ch·∫µn trong list\n1 2from functools import reduce 3 4aList = [1,2,3,5,9] 5 6print(reduce(lambda acc,x: acc+1 if x%2 == 0 else acc,aList,0)) 7 8K·∫øt qu·∫£: 9\u0026gt;\u0026gt;\u0026gt; print(reduce(lambda x,y: x+y,aList,0)) 1015 C·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt.\n","date":"Jul 16, 2022","img":"","permalink":"/courses/python/5_python_function/","series":["Kh√≥a h·ªçc python cƒÉn b·∫£n"],"tags":["python"],"title":"B√†i 4: H√†m Trong Python"},{"categories":"python","content":"Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω ƒë·ªÅ c·∫≠p t·ªõi c√°c c√¢u l·ªánh ƒëi·ªÅu khi·ªÉn trong python. C√°c c√¢u l·ªánh ƒëi·ªÅu khi·ªÉn bao g·ªìm if, if-else, for, while\nC√¢u l·ªánh ƒëi·ªÅu khi·ªÉn if C√¢u l·ªánh ƒëi·ªÅu khi·ªÉn for H√†m range K·∫øt h·ª£p c√¢u l·ªánh for v·ªõi if t·ª´ kho√° break, t·ª´ kho√° continue, t·ª´ kho√° pass V√≤ng l·∫∑p while K·ªπ thu·∫≠t duy·ªát container trong python Duy·ªát container s·ª≠ d·ª•ng h√†m enumerate Duy·ªát container s·ª≠ d·ª•ng h√†m zip Duy·ªát dic s·ª≠ d·ª•ng h√†m items Duy·ªát container s·ª≠ d·ª•ng h√†m sorted Duy·ªát container s·ª≠ d·ª•ng h√†m reversed List Comprehension C√¢u l·ªánh ƒëi·ªÅu khi·ªÉn if C√¢u l·ªánh if l√† c√¢u l·ªánh cƒÉn b·∫£n v√† quan trong nh·∫•t. C√¢u l·ªánh ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ quy·∫øt ƒë·ªãnh xem m·ªôt kh·ªëi l·ªánh c√≥ ƒë∆∞·ª£c th·ª±c hi·ªán hay kh√¥ng. V·ªÅ c∆° b·∫£n, ch√∫ng ta c√≥ th·ªÉ ph√¢n lo·∫°i th√†nh 3 nh√≥m c√¢u l·ªánh if nh∆∞ sau.\nNh√≥m if lo·∫°i 1. C√¢u l·ªánh if b√¨nh th∆∞·ªùng\n1 2if \u0026lt;ƒëi·ªÅu ki·ªán\u0026gt;: 3 # tr∆∞·ªùng h·ª£p \u0026lt;ƒëi·ªÅu ki·ªán\u0026gt; l√† ƒë√∫ng 4 c√¢u l·ªánh 1 5 ... 6 c√¢u l·ªánh n 7c√¢u l·ªánh n+1 Nh√≥m if lo·∫°i 2. C√¢u l·ªánh if c√≥ else\n1 2if \u0026lt;ƒëi·ªÅu ki·ªán\u0026gt;: 3 # tr∆∞·ªùng h·ª£p \u0026lt;ƒëi·ªÅu ki·ªán\u0026gt; l√† ƒë√∫ng 4 c√¢u l·ªánh 1 5 ... 6 c√¢u l·ªánh n 7else: 8 # tr∆∞·ªùng h·ª£p \u0026lt;ƒëi·ªÅu ki·ªán\u0026gt; l√† sai 9 c√¢u l·ªánh 1 10 ... 11 c√¢u l·ªánh n 12 13c√¢u l·ªánh n+1 Nh√≥m if lo·∫°i 3. C√¢u l·ªánh if else l·ªìng nhau\n1 2if \u0026lt;ƒëi·ªÅu ki·ªán 1\u0026gt;: 3 # tr∆∞·ªùng h·ª£p \u0026lt;ƒëi·ªÅu ki·ªán\u0026gt; l√† ƒë√∫ng 4 c√¢u l·ªánh 1 5 ... 6 c√¢u l·ªánh n 7elif \u0026lt;ƒëi·ªÅu ki·ªán 2\u0026gt;: 8 # tr∆∞·ªùng h·ª£p \u0026lt;ƒëi·ªÅu ki·ªán 1\u0026gt; l√† sai, \u0026lt;ƒëi·ªÅu ki·ªán 2\u0026gt; l√† ƒë√∫ng 9 c√¢u l·ªánh 1 10 ... 11 c√¢u l·ªánh n 12... 13elif \u0026lt;ƒëi·ªÅu ki·ªán n\u0026gt;: 14 15 # tr∆∞·ªùng h·ª£p \u0026lt;ƒëi·ªÅu ki·ªán 1\u0026gt; l√† sai, \u0026lt;ƒëi·ªÅu ki·ªán 2\u0026gt; l√† sai, ... \u0026lt;ƒëi·ªÅu ki·ªán n-1\u0026gt; l√† sai, \u0026lt;ƒëi·ªÅu ki·ªán n\u0026gt; l√† ƒë√∫ng 16 c√¢u l·ªánh 1 17 ... 18 c√¢u l·ªánh n 19else: 20 # tr∆∞·ªùng h·ª£p \u0026lt;ƒëi·ªÅu ki·ªán 1\u0026gt; l√† sai, ..., \u0026lt;ƒëi·ªÅu ki·ªán 2\u0026gt; l√† sai 21 c√¢u l·ªánh 1 22 ... 23 c√¢u l·ªánh n 24 25 26c√¢u l·ªánh n+1 V√≠ d·ª•:\nM·∫π b√© Thu tr∆∞·ªõc khi ƒëi l√†m n√≥i v·ªõi b√© Thu r·∫±ng: \u0026ldquo;N·∫øu tr·ªùi s·∫Øp m∆∞a, con h√£y r√∫t qu·∫ßn √°o ·ªü d√¢y ph∆°i ƒë·ªì, h·ªët l√∫a c·∫•t v√†o b·ªì, b·∫ø em v√†o nh√†, g√†i then ƒë√≥ng c·ª≠a th·∫≠t ch·∫∑t, g√†i then ƒë√≥ng c·ª≠a th·∫≠t ch·∫∑t. Con ngoan ·ªü nh√†, chi·ªÅu m·∫π v·ªÅ mua k·∫πo cho con ƒÉn\u0026rdquo;. Ch√∫ng ta s·∫Ω bi·∫øn ƒë·ªïi l·ªùi cƒÉn d·∫∑n c·ªßa m·∫π b√© Thu th√†nh c√¢u l·ªánh if nh∆∞ sau:\n1 2thoi_tiet = \u0026#39;sap_mua\u0026#39; 3is_be_thu_ngoan = True 4if thoi_tiet == \u0026#39;sap_mua\u0026#39;: 5 print(\u0026#39;r√∫t qu·∫ßn √°o ·ªü d√¢y ph∆°i ƒë·ªì\u0026#39;) 6 print(\u0026#39;h·ªët l√∫a c·∫•t v√†o b·ªì\u0026#39;) 7 print(\u0026#39;b·∫ø em v√†o nh√†\u0026#39;) 8 print(\u0026#39;g√†i then ƒë√≥ng c·ª≠a th·∫≠t ch·∫∑t\u0026#39;) 9 print(\u0026#39;r√∫t qu·∫ßn √°o ·ªü d√¢y ph∆°i ƒë·ªì\u0026#39;) 10 11if is_be_thu_ngoan: 12 print(\u0026#39;M·∫π b√© Thu mua k·∫πo\u0026#39;) 13 print(\u0026#39;M·∫π b√© Thu cho b√© Thu ƒÉn k·∫πo\u0026#39;) 14 15K·∫øt qu·∫£ 16 17r√∫t qu·∫ßn √°o ·ªü d√¢y ph∆°i ƒë·ªì 18h·ªët l√∫a c·∫•t v√†o b·ªì 19b·∫ø em v√†o nh√† 20g√†i then ƒë√≥ng c·ª≠a th·∫≠t ch·∫∑t 21r√∫t qu·∫ßn √°o ·ªü d√¢y ph∆°i ƒë·ªì 22 23 24M·∫π b√© Thu mua k·∫πo 25M·∫π b√© Thu cho b√© Thu ƒÉn k·∫πo Ch√∫ng ta c√≥ c√¢u t·ª•c ng·ªØ: Chu·ªìn chu·ªìn bay th·∫•p th√¨ m∆∞a, bay cao th√¨ n·∫Øng, bay v·ª´a th√¨ r√¢m.\nC√¢u l·ªánh if else c·ªßa c√¢u t·ª•c ng·ªØ tr√™n l√†:\n1 2vi_tri_chuon_chuon = \u0026#39;bay_vua\u0026#39; 3 4if vi_tri_chuon_chuon == \u0026#39;bay_thap\u0026#39;: 5 print(\u0026#39;tr·ªùi s·∫Øp m∆∞a\u0026#39;) 6elif vi_tri_chuon_chuon == \u0026#39;bay_cao\u0026#39;: 7 print(\u0026#39;tr·ªùi n·∫Øng\u0026#39;) 8elif vi_tri_chuon_chuon == \u0026#39;bay_vua\u0026#39;: 9 print(\u0026#39;tr·ªùi r√¢m\u0026#39;) 10else: 11 print(\u0026#39;kh√¥ng x√°c ƒë·ªãnh\u0026#39;) 12 13# K·∫øt qu·∫£ 14 15tr·ªùi r√¢m C√¢u l·ªánh ƒëi·ªÅu khi·ªÉn for C√¢u l·ªánh for ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ duy·ªát c√°c ph·∫ßn t·ª≠ trong c√°c container nh∆∞ String, Tuple, List, Set ho·∫∑c Dictionary, Array.\nfor trong python t∆∞∆°ng ƒë∆∞∆°ng v·ªõi foreach trong c√°c ng√¥n ng·ªØ thu·ªôc h·ªç c. Python kh√¥ng c√≥ c√¢u l·ªánh for gi·ªëng for trong c/c++, c#, java \u0026hellip;\nC√∫ ph√°p c√¢u l·ªánh for\n1 2for item in container: 3 #statement V√≠ d·ª•\n1 2brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 3 4for item in brands: 5 print(item) 6 7#K·∫øt qu·∫£ 8 9iphone 10samsung 11xiaomi 12nokia H√†m range c√∫ ph√°p\n1 2range(start,stop,steep) H√†m range ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ tr·∫£ v·ªÅ m·ªôt chu·ªói c√°c s·ªë t·ª´ start (m·∫∑c ƒë·ªãnh l√† 0) ƒë·∫øn stop, v·ªõi b∆∞·ªõc nh·∫£y l√† steep (m·∫∑c ƒë·ªãnh l√† 1)\nV√≠ d·ª•:\nT·∫°o m·ªôt chu·ªói c√°c s·ªë t·ª´ 5 ƒë·∫øn 9, in ra c√°c s·ªë tr√™n\n1 2itemRange = range(5,10) 3 4for item in itemRange: 5 print(item) 6 7# K·∫øt qu·∫£ 8 95 106 117 128 139 H√†m range th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng v·ªõi h√†m len, ƒë·ªÉ duy·ªát index c·ªßa list\n1 2brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;] 3 4for x in range(len(brands)): 5 print(f\u0026#34;element at {x} in list is {brands[x]} \u0026#34;) 6 7# K·∫øt qu·∫£ 8 9element at 0 in list is iphone 10element at 1 in list is samsung 11element at 2 in list is xiaomi Ngo√†i ra, c√≤n tu·ª≥ v√†o b√†i to√°n, ch√∫ng ta s·ª≠ d·ª•ng h√†m range m·ªôt c√°ch th√¥ng minh ƒë·ªÉ code ƒë∆∞·ª£c trong s√°ng v√† s·∫°ch ƒë·∫πp h∆°n.\nK·∫øt h·ª£p c√¢u l·ªánh for v·ªõi if Ho√†ng ƒë·∫ø Julius Caesar l√† m·ªôt nh√† qu√¢n s·ª± t√†i ba. Trong l√∫c √¥ng l√£nh ƒë·∫°o qu√¢n ƒë·ªôi La M√£, ƒë·ªÉ tr√°nh b·ªã r√≤ r·ªâ n·ªôi dung th∆∞ t√≠n khi truy·ªÅn t·∫£i cho c√°c t∆∞·ªõng sƒ©, √¥ng ƒë√£ thi·∫øt l·∫≠p m·ªôt b·ªô m·∫≠t m√£ l√† d·ªãch t·ª´ng ch·ªØ trong th√¥ng tin qua 3 ch·ªØ c√°i trong b·∫£ng m√£ ascii. Nghƒ©a l√†, thay v√¨ vi·∫øt ch·ªØ a, √¥ng l·∫°i vi·∫øt th√†nh ch·ªØ d, thay v√¨ vi·∫øt ch·ªØ b, √¥ng l·∫°i vi·∫øt ch·ªØ e, \u0026hellip;., cho ƒë·∫øn thay z th√†nh c. Khi t∆∞·ªõng sƒ© c·ªßa √¥ng nh·∫≠n ƒë∆∞·ª£c th∆∞ t√≠n, ch·ªâ c·∫ßn d·ªãch ng∆∞·ª£c l·∫°i v·ªõi quy lu·∫≠t tr√™n l√† c√≥ ƒë∆∞·ª£c n·ªôi dung b·ª©c th∆∞.\nV√≠ d·ª• n·ªôi dung b·ª©c th∆∞ √¥ng g·ª≠i.\ngdqk Jdoold qjdb pxrl ed\nKhi t∆∞·ªõng sƒ© nh·∫≠n ƒë∆∞·ª£c ƒëo·∫°n l·ªánh tr√™n, h·ªç ti·∫øn h√†nh d·ªãch ng∆∞·ª£c l·∫°i. g t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ d (d+3 =g) \u0026hellip;, v√† gi·∫£i m√£ b·ª©c m·∫≠t th∆∞ c·ªßa ho√†ng ƒë·∫ø g·ª≠i l√†:\ndanh Gallia ngay muoi ba\nCh√∫ng ta vi·∫øt ch∆∞∆°ng tr√¨nh nh·ªè v·ªõi for v√† if ƒë·ªÉ m√£ ho√° n·ªôi dung th√¥ng tin gi√∫p Julius Caesar nh√©.\n1 2input = \u0026#39;danh Gallia ngay muoi ba\u0026#39; 3 4for c in input: 5 if c == \u0026#39;a\u0026#39;: 6 print(\u0026#39;d\u0026#39;,end=\u0026#39;\u0026#39;) 7 elif c == \u0026#39;b\u0026#39;: 8 print(\u0026#39;e\u0026#39;,end=\u0026#39;\u0026#39;) 9 elif c == \u0026#39;c\u0026#39;: 10 print(\u0026#39;f\u0026#39;,end=\u0026#39;\u0026#39;) 11 elif c == \u0026#39;d\u0026#39;: 12 print(\u0026#39;g\u0026#39;,end=\u0026#39;\u0026#39;) 13 elif c == \u0026#39;e\u0026#39;: 14 print(\u0026#39;h\u0026#39;,end=\u0026#39;\u0026#39;) 15 elif c == \u0026#39;f\u0026#39;: 16 print(\u0026#39;i\u0026#39;,end=\u0026#39;\u0026#39;) 17 elif c == \u0026#39;g\u0026#39;: 18 print(\u0026#39;j\u0026#39;,end=\u0026#39;\u0026#39;) 19 elif c == \u0026#39;h\u0026#39;: 20 print(\u0026#39;k\u0026#39;,end=\u0026#39;\u0026#39;) 21 elif c == \u0026#39;i\u0026#39;: 22 print(\u0026#39;l\u0026#39;,end=\u0026#39;\u0026#39;) 23 elif c == \u0026#39;j\u0026#39;: 24 print(\u0026#39;m\u0026#39;,end=\u0026#39;\u0026#39;) 25 elif c == \u0026#39;k\u0026#39;: 26 print(\u0026#39;n\u0026#39;,end=\u0026#39;\u0026#39;) 27 elif c == \u0026#39;l\u0026#39;: 28 print(\u0026#39;o\u0026#39;,end=\u0026#39;\u0026#39;) 29 elif c == \u0026#39;m\u0026#39;: 30 print(\u0026#39;p\u0026#39;,end=\u0026#39;\u0026#39;) 31 elif c == \u0026#39;n\u0026#39;: 32 print(\u0026#39;q\u0026#39;,end=\u0026#39;\u0026#39;) 33 elif c == \u0026#39;o\u0026#39;: 34 print(\u0026#39;r\u0026#39;,end=\u0026#39;\u0026#39;) 35 elif c == \u0026#39;p\u0026#39;: 36 print(\u0026#39;s\u0026#39;,end=\u0026#39;\u0026#39;) 37 elif c == \u0026#39;q\u0026#39;: 38 print(\u0026#39;t\u0026#39;,end=\u0026#39;\u0026#39;) 39 elif c == \u0026#39;r\u0026#39;: 40 print(\u0026#39;u\u0026#39;,end=\u0026#39;\u0026#39;) 41 elif c == \u0026#39;s\u0026#39;: 42 print(\u0026#39;v\u0026#39;,end=\u0026#39;\u0026#39;) 43 elif c == \u0026#39;t\u0026#39;: 44 print(\u0026#39;w\u0026#39;,end=\u0026#39;\u0026#39;) 45 elif c == \u0026#39;u\u0026#39;: 46 print(\u0026#39;x\u0026#39;,end=\u0026#39;\u0026#39;) 47 elif c == \u0026#39;v\u0026#39;: 48 print(\u0026#39;y\u0026#39;,end=\u0026#39;\u0026#39;) 49 elif c == \u0026#39;w\u0026#39;: 50 print(\u0026#39;z\u0026#39;,end=\u0026#39;\u0026#39;) 51 elif c == \u0026#39;x\u0026#39;: 52 print(\u0026#39;a\u0026#39;,end=\u0026#39;\u0026#39;) 53 elif c == \u0026#39;y\u0026#39;: 54 print(\u0026#39;b\u0026#39;,end=\u0026#39;\u0026#39;) 55 elif c == \u0026#39;z\u0026#39;: 56 print(\u0026#39;c\u0026#39;,end=\u0026#39;\u0026#39;) 57 else: 58 print(c,end=\u0026#39;\u0026#39;) 59print() 60 61# K·∫øt qu·∫£ 62 63gdqk Gdoold qjdb pxrl ed C√°ch vi·∫øt tr√™n kh√° c∆° b·∫Øp, tay to, d√†i d√≤ng, ch√∫ng ta h√£y vi·∫øt ƒëo·∫°n code tr√™n ng·∫Øn g·ªçn h∆°n b·∫±ng c√°ch.\nT·∫°o ra 2 chu·ªói, m·ªôt chu·ªói ch·ª©a c√°c k√Ω t·ª± alphabet, m·ªôt chu·ªói ch·ª©a b·∫£ng m√£ ho√°.\nT√¨m v·ªã tr√≠ c·ªßa t·ª´ c·∫ßn m√£ ho√° trong chu·ªói alphabet\nIn ra t·ª´ c·∫ßn l·∫•y trong b·∫£ng m√£ ho√°\n1 2input = \u0026#39;danh Gallia ngay muoi ba\u0026#39; 3 4alphabet = \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39; 5caesar_cipher = \u0026#39;defghijklmnopqrstuvwxyzabc\u0026#39; 6 7for c in input: 8 index = alphabet.find(c) 9 if index \u0026gt;-1: 10 print(caesar_cipher[index],end=\u0026#39;\u0026#39;) 11 else: 12 print(c,end=\u0026#39;\u0026#39;) 13 14print(\u0026#39;\u0026#39;) t·ª´ kho√° break, t·ª´ kho√° continue, t·ª´ kho√° pass ƒê·ªÉ tho√°t kh·ªèi v√≤ng l·∫∑p for, ch√∫ng ta s·ª≠ d·ª•ng t·ª´ kho√° break\nƒê·ªÉ b·ªè qua kh·ªëi l·ªánh b√™n d∆∞·ªõi, ti·∫øp t·ª•c l·ªánh for, ch√∫ng ta s·ª≠ d·ª•ng t·ª´ kho√° continue.\nƒê·ªÉ gi·ªØ ch·ªó cho t√≠nh nƒÉng t∆∞∆°ng lai s·∫Ω ph√°t tri·ªÉn, ch√∫ng ta s·ª≠ d·ª•ng t·ª´ kho√° pass ƒë·ªÉ ƒë√°nh d·∫•u, v√† c≈©ng ƒë·ªÉ cho ch∆∞∆°ng tr√¨nh c√≥ th·ªÉ ho·∫°t ƒë·ªông ƒë∆∞·ª£c.\nV√≠ d·ª• v·ªÅ break\nT√¨m l√† in ra 5 s·ªë l·∫ª nguy√™n d∆∞∆°ng ƒë·∫ßu ti√™n b√© h∆°n 100\n1 2count = 0 3 4for x in range(100): 5 if x % 2 != 0: 6 print(x) 7 count = count + 1 8 if count \u0026gt;=5: 9 break 10 11# K·∫øt qu·∫£ 12 131 143 155 167 179 V√≠ d·ª• v·ªÅ continue\nIn ra c√°c s·ªë l·∫ª b√© h∆°n 10\n1 2for x in range(10): 3 if x % 2 == 0: 4 continue 5 print(x) 6 7# K·∫øt qu·∫£ 8 91 103 115 127 139 V√≠ d·ª• v·ªÅ pass\nVi·∫øt m·ªôt v√≤ng l·∫∑p for l·∫∑p 10 l·∫ßn, ƒë·ªÉ gi√†nh ƒë√≥ mai m·ªët code ti·∫øp\n1 2for x in range(10): 3 pass 4 5# K·∫øt qu·∫£ V√≤ng l·∫∑p while √ù nghƒ©a: Trong khi ƒëi·ªÅu ki·ªán c√≤n ƒë√∫ng, th√¨ th·ª±c hi·ªán c√¢u l·ªánh.\nK·∫øt th√∫c v√≤ng l·∫∑p khi ƒëi·ªÅu ki·ªán sai\nC√∫ ph√°p\n1 2while \u0026lt;condition\u0026gt;: 3 # statement V√≠ d·ª•:\nIn ra c√°c s·ªë nguy√™n b√© h∆°n 10\n1 2 3i = 1 4while i \u0026lt; 10: 5 print(i) 6 i += 1 v√≤ng l·∫∑p while c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c t·ª´ kho√° pass, continue, break gi·ªëng nh∆∞ for\nK·ªπ thu·∫≠t duy·ªát container trong python Python h·ªó tr·ª£ nhi·ªÅu h√†m d·ª±ng s·∫µn, gi√∫p ch√∫ng ta c√≥ th·ªÉ duy·ªát c√°c container m·ªôt c√°ch d·ªÖ d√†ng.\nVi·ªác s·ª≠ d·ª•ng c√°c h√†m duy·ªát b√™n d∆∞·ªõi, gi√∫p cho coder:\nS·ª≠ d·ª•ng nhanh ch√≥ng, gi·∫£m th·ªùi gian coding.\nT√™n h√†m ch√≠nh l√† t·ª´ kho√°, m√¥ t·∫£ ch√≠nh x√°c m·ª•c ƒë√≠ch s·ª≠ d·ª•ng h√†m. Gi√∫p gi·∫£m th·ªùi gian ƒë·ªçc code, khi so v·ªõi vi·ªác s·ª≠ d·ª•ng for/while.\nCode ng·∫Øng g·ªçn h∆°n, r√µ r√†ng h∆°n, so v·ªõi for \u0026amp; while.\nDuy·ªát container s·ª≠ d·ª•ng h√†m enumerate H√†m enumerate h·ªó tr·ª£ tr·∫£ v·ªÅ index v√† value c·ªßa container\nV√≠ d·ª•:\n1 2 3brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 4 5for index,item in enumerate(brands): 6 print(f\u0026#34;element at index {index} in list is {item} \u0026#34;) 7 8 9# K·∫øt qu·∫£ 10 11element at index 0 in list is iphone 12element at index 1 in list is samsung 13element at index 2 in list is xiaomi 14element at index 3 in list is nokia Duy·ªát container s·ª≠ d·ª•ng h√†m zip H√†m d·ª±ng s·∫µn zip h·ªó tr·ª£ ch√∫ng ta k·∫øt h·ª£p 2 container c√πng lo·∫°i (list v·ªõi list, dict v·ªõi dict, string v·ªõi string) v·ªõi nhau\nV√≠ d·ª•:\n1 2alphabet = \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39; 3caesar_cipher = \u0026#39;defghijklmnopqrstuvwxyzabc\u0026#39; 4 5 6for decode, encode in zip(alphabet,caesar_cipher): 7 print(f\u0026#34;Caesar send {encode}, we have {decode}\u0026#34;) 8 9# K·∫øt qu·∫£ 10 11Caesar send d, we have a 12Caesar send e, we have b 13Caesar send f, we have c 14Caesar send g, we have d 15Caesar send h, we have e 16Caesar send i, we have f 17Caesar send j, we have g 18Caesar send k, we have h 19Caesar send l, we have i 20Caesar send m, we have j 21Caesar send n, we have k 22Caesar send o, we have l 23Caesar send p, we have m 24Caesar send q, we have n 25Caesar send r, we have o 26Caesar send s, we have p 27Caesar send t, we have q 28Caesar send u, we have r 29Caesar send v, we have s 30Caesar send w, we have t 31Caesar send x, we have u 32Caesar send y, we have v 33Caesar send z, we have w 34Caesar send a, we have x 35Caesar send b, we have y 36Caesar send c, we have z Duy·ªát dic s·ª≠ d·ª•ng h√†m items V√≠ d·ª•:\n1 2profile = {\u0026#39;name\u0026#39;:\u0026#39;alex\u0026#39;,\u0026#39;age\u0026#39;:18,\u0026#39;location\u0026#39;:\u0026#39;vietnam\u0026#39;} 3 4for key, value in profile.items(): 5 print(key,value) 6 7# K·∫øt qu·∫£ 8 9name alex 10age 18 11location vietnam Duy·ªát container s·ª≠ d·ª•ng h√†m sorted H√†m sorted s·∫Ω x·∫Øp x·∫øp l·∫°i ph·∫ßn t·ª≠ trong container theo th·ª© t·ª± (v·ªõi s·ªë th√¨ t·ª´ nh·ªè ƒë·∫øn l·ªõn, v·ªõi ch·ªØ th√¨ theo th·ª© t·ª± t·ª´ ƒëi·ªÉn), v√† tr·∫£ v·ªÅ t·ª´ng ph·∫ßn t·ª≠ trong container ƒë√£ ƒë∆∞·ª£c sort.\nV√≠ d·ª•:\n1 2 3brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 4 5for item in sorted(brands): 6 print(item) 7 8# K·∫øt qu·∫£ 9 10iphone 11nokia 12samsung 13xiaomi Duy·ªát container s·ª≠ d·ª•ng h√†m reversed H√†m reversed s·∫Ω duy·ªát ng∆∞·ª£c ph·∫ßn t·ª≠ trong container. H√†m n√†y kh√¥ng l√†m ·∫£nh h∆∞·ªüng th·ª© t·ª± c·ªßa c√°c ph·∫ßn t·ª≠ trong container\nV√≠ d·ª•:\n1 2 3brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 4 5for item in reversed(brands): 6 print(item) 7 8# K·∫øt qu·∫£ 9 10iphone 11nokia 12samsung 13xiaomi List Comprehension List comprehension cung c·∫•p cho ch√∫ng ta m·ªôt c√∫ ph√°p ng·∫Øn g·ªçn, s√∫c t√≠ch, gi√∫p ch√∫ng ta t·∫°o m·ªôt list, l√† t·∫≠p con t·ª´ m·ªôt list l·ªõn.\nC√∫ ph√°p chung c·ªßa list comprehension l√†:\n1 2newlist = [expression for item in iterable if condition == True] V·ªõi condition l√† ƒëi·ªÅu ki·ªán l·ªçc ƒë·ªÉ gi·∫£m s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ tr·∫£ v·ªÅ.\nexpression: c√≥ th·ªÉ l√† m·ªôt bi·ªÉu th·ª©c if\nV√≠ d·ª•:\n1 2brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 3filter_brands = [] 4 5for item in brands: 6 if \u0026#39;i\u0026#39; in item: 7 filter_brands.append(item) 8 9print(filter_brands) 10 11# K·∫øt qu·∫£ 12\u0026gt;\u0026gt;\u0026gt; print(filter_brands) 13[\u0026#39;iphone\u0026#39;, \u0026#39;xiaomi\u0026#39;, \u0026#39;nokia\u0026#39;] ƒêo·∫°n m√£ tr√™n th·ª±c hi·ªán vi·ªác in ra c√°c h√£ng c√≥ ch·ª©a k√Ω t·ª± i trong t√™n. Ch√∫ng ta t·ªën 3 d√≤ng code (1 v√≤ng for, 1 v√≤ng if, 1 v√≤ng append). Gi·ªù ch√∫ng ta s·∫Ω vi·∫øt l·∫°i b·∫±ng list comprehension\n1 2 3brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 4 5filter_brands = [item for item in brands if \u0026#39;i\u0026#39; in item] 6 7print(filter_brands) 8 9#K·∫øt qu·∫£ 10 11\u0026gt;\u0026gt;\u0026gt; print(filter_brands) 12[\u0026#39;iphone\u0026#39;, \u0026#39;xiaomi\u0026#39;, \u0026#39;nokia\u0026#39;] V√≠ d·ª• 2\nVi·∫øt hoa to√†n b·ªô t√™n h√£ng\n1 2# M·∫´u v√≤ng l·∫∑p for 3 4brands = [\u0026#39;iphone\u0026#39;,\u0026#39;samsung\u0026#39;,\u0026#39;xiaomi\u0026#39;,\u0026#39;nokia\u0026#39;] 5 6old_upper_brands = [] 7for brand in brands: 8 old_upper_brands.append(brand.upper()) 9 10# M·∫´u list comprehension 11 12new_upper_brands = [brand.upper() for brand in brands] V√≠ d·ª• 3:\nCho m·ªôt list c√≥ 10 ph·∫ßn t·ª≠, l·∫•y ra c√°c ph·∫ßn t·ª≠ \u0026gt; 5, thay c√°c ph·∫ßn t·ª≠ l·ªõn h∆°n 10 b·∫±ng 0\n1 2# M·∫´u c≈© 3items = [100,5,8,2,9,7,1,20,89,99] 4old_items = [] 5for item in items: 6 if item \u0026gt; 5: # ch·ªâ x√©t nh·ªØng ph·∫ßn t·ª≠ \u0026gt;5 7 if item\u0026gt;10: # thay nh·ªØng ph·∫ßn t·ª≠ \u0026gt; 10 th√†nh 0 8 old_items.append(0) 9 else: 10 old_items.append(item) 11 12print(old_items) 13 14new_items = [item if item \u0026lt;=10 else 0 for item in items if item\u0026gt;5] 15 16print(new_items) 17 18# K·∫øt qu·∫£ 19 20\u0026gt;\u0026gt;\u0026gt; print(old_items) 21[0, 8, 9, 7, 0, 0, 0] 22 23\u0026gt;\u0026gt;\u0026gt; print(new_items) 24[0, 8, 9, 7, 0, 0, 0] C·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt.\n","date":"Jul 16, 2022","img":"","permalink":"/courses/python/4_python_conditional_loop/","series":["Kh√≥a h·ªçc python cƒÉn b·∫£n"],"tags":["python"],"title":"B√†i 3: C√¢u L·ªánh ƒêi·ªÅu Khi·ªÉn Trong Python"},{"categories":"python","content":"Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu c√°c ki·ªÉu d·ªØ li·ªáu d·∫°ng container trong python\nKi·ªÉu d·ªØ li·ªáu string M·ªôt v√†i ph∆∞∆°ng th·ª©c c∆° b·∫£n c·ªßa string Ph∆∞∆°ng th·ª©c isdecimal, isdigit, isnumeric Ph∆∞∆°ng th·ª©c isascii, isalpha, isalnum, isspace, isupper Ph∆∞∆°ng th·ª©c lstrip, rstrip, strip Ph∆∞∆°ng th·ª©c find, index Ph∆∞∆°ng th·ª©c format f string Ki·ªÉu d·ªØ li·ªáu tuple Packing v√† Unpacking So s√°nh c√°c bi·∫øn c√≥ ki·ªÉu d·ªØ li·ªáu tuple Slicing trong Tuple C√°c h√†m d·ª±ng s·∫µn c·ªßa Tuple Ki·ªÉu d·ªØ li·ªáu t·ª´ ƒëi·ªÉn - dictionary Thu·ªôc t√≠nh c·ªßa keys trong t·ª´ ƒëi·ªÉn. M·ªôt v√†i ph∆∞∆°ng th·ª©c c·ªßa dictionary copy update del item len Merge T·ªïng k·∫øt: Ki·ªÉu d·ªØ li·ªáu list Truy xu·∫•t d·ªØ li·ªáu trong list slicing C√°c ph∆∞∆°ng th·ª©c ƒë∆∞·ª£c h·ªó tr·ª£ append pop remove reverse C√°c h√†m ƒë∆∞·ª£c h·ªó tr·ª£ len max min Ki·ªÉu d·ªØ li·ªáu set M·ªôt v√†i ph∆∞∆°ng th·ª©c c∆° b·∫£n c·ªßa Set Ph∆∞∆°ng th·ª©c Add Ph∆∞∆°ng th·ª©c Remove, Discard Ph∆∞∆°ng th·ª©c Pop Ph∆∞∆°ng th·ª©c Clear Ki·ªÉu d·ªØ li·ªáu array M·ªôt v√†i ph∆∞∆°ng th·ª©c c∆° b·∫£n c·ªßa array Ph∆∞∆°ng th·ª©c insert, ph∆∞∆°ng th·ª©c append Ph∆∞∆°ng th·ª©c truy xu·∫•t ph·∫ßn t·ª≠ theo index Ph∆∞∆°ng th·ª©c remove, ph∆∞∆°ng th·ª©c pop Ph∆∞∆°ng th·ª©c index Ki·ªÉu d·ªØ li·ªáu string string l√† t·∫≠p h·ª£p c√°c bytes ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng k√Ω t·ª± unicode\nV√≠ d·ª•\n1 2hello = \u0026#34;hi, i am alex\u0026#34; 3 4print(hello) 5 6greating = \u0026#34;i am from vi·ªát Nam\u0026#34; 7 8print(greating) 9 10 11#K·∫øt qu·∫£ 12 13\u0026gt;\u0026gt;\u0026gt; print(hello) 14hi, i am alex 15 16\u0026gt;\u0026gt;\u0026gt; print(greating) 17i am from vi·ªát Nam M·ªôt v√†i ph∆∞∆°ng th·ª©c c∆° b·∫£n c·ªßa string Ph∆∞∆°ng th·ª©c isdecimal, isdigit, isnumeric isdecimal: Tr·∫£ v·ªÅ true n·∫øu to√†n b·ªô c√°c k√Ω t·ª± l√† decimal (0-9)\nisdigit: Tr·∫£ v·ªÅ true n·∫øu to√†n b·ªô k√Ω t·ª± l√† digit. Bao g·ªìm c√°c s·ªë (0-9), s·ªë m≈© tr√™n (v√≠ d·ª•: x2), s·ªë m≈© d∆∞·ªõi (v√≠ d·ª•: x2).\nisnumeric: Tr·∫£ v·ªÅ true n·∫øu to√†n b·ªô k√Ω t·ª± l√† numeric. Bao g·ªìm c√°c s·ªë (0-9), s·ªë m≈© tr√™n (v√≠ d·ª•: x2), s·ªë m≈© d∆∞·ªõi (v√≠ d·ª•: x2) , ph√¢n s·ªë ( v√≠ d·ª•: 1‚ÅÑ2)\nV√≠ d·ª•:\n1 2# s·ªë 18 l√†: 3print(\u0026#39;18\u0026#39;.isdecimal()) 4print(\u0026#39;18\u0026#39;.isdigit()) 5print(\u0026#39;18\u0026#39;.isnumeric()) 6 7# K·∫øt qu·∫£ 8 9\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;18\u0026#39;.isdecimal()) 10True 11\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;18\u0026#39;.isdigit()) 12True 13\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;18\u0026#39;.isnumeric()) 14True 1 2# s·ªë 2 m≈© 3 l√†: 3print(\u0026#39;2\\u00b3\u0026#39;) 4print(\u0026#39;2\\u00b3\u0026#39;.isdecimal()) 5print(\u0026#39;2\\u00b3\u0026#39;.isdigit()) 6print(\u0026#39;2\\u00b3\u0026#39;.isnumeric()) 7 8# K·∫øt qu·∫£ 9 10\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;) 112¬≥ 12\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;.isdecimal()) 13False 14\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;.isdigit()) 15True 16\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;2\\u00b3\u0026#39;.isnumeric()) 17True 1 2# s·ªë ‚Öì l√†: 3print(\u0026#39;\\u2153\u0026#39;) 4print(\u0026#39;\\u2153\u0026#39;.isdecimal()) 5print(\u0026#39;\\u2153\u0026#39;.isdigit()) 6print(\u0026#39;\\u2153\u0026#39;.isnumeric()) 7 8# K·∫øt qu·∫£ 9 10\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\\u2153\u0026#39;.isdecimal()) 11False 12\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\\u2153\u0026#39;.isdigit()) 13False 14\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\\u2153\u0026#39;.isnumeric()) 15True Ph∆∞∆°ng th·ª©c isascii, isalpha, isalnum, isspace, isupper isalpha: Tr·∫£ v·ªÅ true n·∫øu to√†n b·ªô k√Ω t·ª± trong b·∫£ng alphabet(a-z). Kh√¥ng ch·ª©a k√Ω t·ª± kho·∫£ng tr·∫Øng, # @ $ \u0026hellip;\nisalnum: Tr·∫£ v·ªÅ true n·∫øu to√†n b·ªô k√Ω t·ª± l√† alphanumeric (a-z,0-9)\nisascii: Tr·∫£ v·ªÅ true n·∫øu to√†n b·ªô l√† k√Ω t·ª± ascii (a-z)\nisspace: Tr·∫£ v·ªÅ true n·∫øu to√†n b·ªô k√Ω t·ª± l√† kho·∫£ng tr·∫Øng\nisupper: Tr·∫£ v·ªÅ true n·∫øu to√†n b·ªô k√Ω t·ª± ƒë·ªÅu in hoa.\nV√≠ d·ª•:\n1 2\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex\u0026#34;.isalpha()) 3True 4 5\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100\u0026#34;.isalpha()) 6False 7 8\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100\u0026#34;.isalnum()) 9True 10 11\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100 $%\u0026#34;.isalnum()) 12False 13 14\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100 $%\u0026#34;.isascii()) 15True 16 17 18\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex100\u0026#34;.isspace()) 19False 20\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;\u0026#34;.isspace()) 21False 22\u0026gt;\u0026gt;\u0026gt; print(\u0026#34; \u0026#34;.isspace()) 23True 24 25 26\u0026gt;\u0026gt;\u0026gt; print(\u0026#34; \u0026#34;.isupper()) 27False 28\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;abc\u0026#34;.isupper()) 29False 30\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;AA\u0026#34;.isupper()) 31True Ph∆∞∆°ng th·ª©c lstrip, rstrip, strip Ph∆∞∆°ng th·ª©c lstrip: Xo√° chu·ªói d∆∞ th·ª´a ·ªü b√™n tr√°i, m·∫∑c ƒë·ªãnh chu·ªói d∆∞ th·ª´a l√† kho·∫£ng tr·∫Øng Ph∆∞∆°ng th·ª©c rstrip: Xo√° chu·ªói d∆∞ th·ª´a ·ªü b√™n ph·∫£i, m·∫∑c ƒë·ªãnh chu·ªói d∆∞ th·ª´a l√† kho·∫£ng tr·∫Øng Ph∆∞∆°ng th·ª©c strip: Xo√° chu·ªói d∆∞ th·ª´a ·ªü hai b√™n, m·∫∑c ƒë·ªãnh chu·ªói d∆∞ th·ª´a l√† kho·∫£ng tr·∫Øng V√≠ d·ª•\n1 2\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;.... alex black ..\u0026#34;.lstrip(\u0026#34;.\u0026#34;)) # ch·ªâ xo√° . b√™n tr√°i 3 alex black .. 4 5\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;.... alex black ..\u0026#34;.rstrip(\u0026#34;.\u0026#34;)) # ch·ªâ xo√° . b√™n ph·∫£i 6.... alex black 7 8\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;....alex black..\u0026#34;.strip(\u0026#34;.\u0026#34;)) # xo√° . ·ªü hai b√™n 9alex black 10 11 12\u0026gt;\u0026gt;\u0026gt; print(\u0026#34; ....alex black..\u0026#34;.strip()) # xo√° kho·∫£ng tr·∫Øng ·ªü hai b√™n 13....alex black.. Ph∆∞∆°ng th·ª©c find, index C·∫£ hai ph∆∞∆°ng th·ª©c find v√† index ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√¨m v·ªã tr√≠ ƒë·∫ßu ti√™n c·ªßa ph·∫ßn t·ª≠ c·∫ßn t√¨m\nPh∆∞∆°ng th·ª©c find: Tr·∫£ v·ªÅ -1 n·∫øu ph·∫ßn t·ª≠ kh√¥ng t√¨m th·∫•y\nPh∆∞∆°ng th·ª©c index: Tr·∫£ v·ªÅ l·ªói n·∫øu ph·∫ßn t·ª≠ kh√¥ng t√¨m th·∫•y\nV√≠ d·ª•:\n1 2\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.find(\u0026#34;b\u0026#34;)) 35 4 5\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.index(\u0026#34;b\u0026#34;)) 65 7 8\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.find(\u0026#34;a\u0026#34;,5)) 97 10 11\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.index(\u0026#34;a\u0026#34;,5)) 127 13 14\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.find(\u0026#34;z\u0026#34;)) 15-1 16 17\u0026gt;\u0026gt;\u0026gt; print(\u0026#34;alex black 18\u0026#34;.index(\u0026#34;z\u0026#34;)) 18Traceback (most recent call last): 19 File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; 20ValueError: substring not found Ph∆∞∆°ng th·ª©c format Ph∆∞∆°ng th·ª©c format ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë·ªãnh d·∫°ng chu·ªói.\nV√≠ d·ª•:\n1 2greetings = \u0026#34;Hello everyone, my name {name}, i am {age} year old. I come from {location}\u0026#34; 3 4name = \u0026#34;alex Black\u0026#34; 5age = 18 6location = \u0026#34;the moon\u0026#34; 7print(greetings.format(name=name, age=age, location=location)) 8 9#K·∫øt qu·∫£ 10 11\u0026gt;\u0026gt;\u0026gt; print(greetings.format(name=name, age=age, location=location)) 12Hello everyone, my name alex Black, i am 18 year old. I come from the moon C√°ch vi·∫øt n√†y kh√° d√†i d√≤ng l√™ th√™, m·ªôt c√°ch kh√°c l√† ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng f string.\nf string python 3 h·ªó tr·ª£ f string, gi√∫p format chu·ªói, tr√¥ng ƒë·∫πp h∆°n so v·ªõi ph∆∞∆°ng th·ª©c format ·ªü tr√™n.\n1 2\u0026gt;\u0026gt;\u0026gt; age =18 3\u0026gt;\u0026gt;\u0026gt; name= \u0026#39;Alex Black\u0026#39; 4\u0026gt;\u0026gt;\u0026gt; location=\u0026#39;the moon\u0026#39; 5 6\u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;hello, my name {name}. I am {age} years old. I come from {location}\u0026#34;) 7hello, my name Alex Black. I am 18 years old. I come from the moon Ki·ªÉu d·ªØ li·ªáu tuple Tuple l√† t·∫≠p cho ph√©p ch√∫ng ta g√°n nhi·ªÅu bi·∫øn v√†o m·ªôt bi·∫øn. V√≠ d·ª•:\n1tupinfo = (\u0026#39;Alex\u0026#39;, \u0026#39;Black\u0026#39;,\u0026#39;1978\u0026#39;,\u0026#39;Emprise\u0026#39;, \u0026#39;Engineer\u0026#39;,\u0026#39;Ho Chi Minh\u0026#39;); 2tupinfo = (1,3,5,7,9,9); 3print(tupinfo[0]) 4print(tupinfo[1:4]) 5 6#k·∫øt qu·∫£ 7\u0026gt;\u0026gt;\u0026gt; print(tupinfo[0]) 81 9\u0026gt;\u0026gt;\u0026gt; print(tupinfo[1:4]) 10(3, 5, 7) 11\u0026gt;\u0026gt;\u0026gt; Packing v√† Unpacking Thu·∫≠t ng·ªØ packing √°m ch·ªâ vi·ªác ta th√™m gi√° tr·ªã v√†o tuple.\nThu·∫≠t ng·ªØ unpacking √°m ch·ªâ vi·ªác ta ph√¢n gi·∫£i c√°c gi√° tr·ªã c·ªßa tuple ra nhi·ªÅu bi·∫øn.\nCh√∫ng ta c√πng xem v√≠ d·ª•:\n1 2a = (\u0026#34;alex\u0026#34; , 18, \u0026#34;Staff\u0026#34;) # tuple packing 3 4(name, age, position) = a # unpacking tuple 5 6print(name) 7print(age) 8print(position) 9 10# K·∫øt qu·∫£ 11 12\u0026gt;\u0026gt;\u0026gt; print(name) 13alex 14\u0026gt;\u0026gt;\u0026gt; print(age) 1518 16\u0026gt;\u0026gt;\u0026gt; print(position) 17Staff So s√°nh c√°c bi·∫øn c√≥ ki·ªÉu d·ªØ li·ªáu tuple Python cho ph√©p so s√°nh c√°c bi·∫øn thu·ªôc ki·ªÉu d·ªØ li·ªáu tuple v·ªõi nhau. Ch√∫ng ta c√≥ th·ªÉ th·ª±c hi·ªán c√°c ph√©p so s√°nh b·∫±ng, so s√°nh l·ªõn h∆°n, so s√°nh b√© h∆°n. Vi·ªác so s√°nh ƒë∆∞·ª£c th·ª±c hi·ªán l·∫ßn l∆∞·ª£t b·∫±ng c√°ch so s√°nh gi√° tr·ªã c·ªßa t·ª´ng ph·∫ßn t·ª≠ v·ªõi nhau theo th·ª© t·ª±. Ph·∫ßn t·ª≠ th·ª© nh·∫•t s·∫Ω so s√°nh v·ªõi ph·∫ßn t·ª≠ th·ª© nh·∫•t, ph·∫ßn t·ª≠ th·ª© hai s·∫Ω so s√°nh v·ªõi ph·∫ßn t·ª≠ th·ª© hai\u0026hellip;.\nV√≠ d·ª•:\n1 2num1 = (3,5,7) 3 4num2 = (3,6,4) 5 6print(num1\u0026gt;num2) 7print(num1==num2) 8print(num1\u0026lt;num2) 9 10K·∫øt qu·∫£: 11 12\u0026gt;\u0026gt;\u0026gt; print(num1\u0026gt;num2) 13False 14\u0026gt;\u0026gt;\u0026gt; print(num1==num2) 15False 16\u0026gt;\u0026gt;\u0026gt; print(num1\u0026lt;num2) # do 6 l·ªõn h∆°n 5, n√™n num2 l·ªõn h∆°n num1 17True M·ªôt l∆∞u √Ω nh·ªè l√† ·ªü python, ph√©p so s√°nh b·∫±ng s·∫Ω l√† hai d·∫•u b·∫±ng (==), kh√¥ng ph·∫£i m·ªôt d·∫•u =. D·∫•u = ƒë·∫°i di·ªán cho ph√©p g√°n gi√° tr·ªã cho bi·∫øn.\nSlicing trong Tuple ƒê·ªÉ l·∫•y ra m·ªôt nh√≥m c√°c ph·∫ßn t·ª≠ li·ªÅn k·ªÅ nhau trong tuple, ch√∫ng ta s·ª≠ d·ª•ng m·ªôt h√†m c√≥ t√™n l√† slicing. Slicing c√≥ th·ªÉ √°p d·ª•ng cho tuple, array, list.\nV√≠ d·ª•:\n1 2ages = (18,16,15,18,15,17,19,18,17) 3print(ages[2:4]) 4\u0026gt;\u0026gt;\u0026gt; print(ages[2:4]) 5(15, 18) C√°c h√†m d·ª±ng s·∫µn c·ªßa Tuple ƒê·ªÉ th·ª±c hi·ªán c√°c c√¥ng vi·ªác kh√°c nhau, ki·ªÉu d·ªØ li·ªáu tuple c√≥ x√¢y d·ª±ng m·ªôt s·ªë h√†m ƒë·ªÉ ch√∫ng ta s·ª≠ d·ª•ng, nh∆∞ l√† all(), any(), enumerate(), max(), min(), sorted(), len(), tuple(), etc.\nKi·ªÉu d·ªØ li·ªáu t·ª´ ƒëi·ªÉn - dictionary Trong python, ki·ªÉu t·ª´ ƒëi·ªÉn l√† t·∫≠p h·ª£p c√°c d·ªØ li·ªáu c√≥ d·∫°ng key-value. Trong ƒë√≥, Key l√† duy nh·∫•t trong t·ª´ ƒëi·ªÉn. Value c√≥ th·ªÉ l√† list, tuple, dictionary, s·ªë, chu·ªói, t√∫m l·∫°i l√† value kh√¥ng b·ªã gi·ªõi h·∫°n v·ªÅ ki·ªÉu d·ªØ li·ªáu, th√≠ch l∆∞u ki·ªÉu g√¨ c≈©ng ƒë∆∞·ª£c. C√≥ hai c√°ch ƒë·ªÉ t·∫°o bi·∫øn c√≥ ki·ªÉu d·ªØ li·ªáu t·ª´ ƒëi·ªÉn, m·ªôt l√† d√πng t·ª´ kho√° dict(), hai l√† d√πng d·∫•u ƒë√≥ng m·ªü ngo·∫∑c nh·ªçn {}.\nV√≠ d·ª•\n1 2info = {\u0026#39;name\u0026#39;: \u0026#34;alex\u0026#34;, age:18, \u0026#39;position\u0026#39;: \u0026#34;Staff\u0026#34; } 3print(info) 4 5K·∫øt qu·∫£: 6 7\u0026gt;\u0026gt;\u0026gt; print(info) 8{\u0026#39;alex\u0026#39;: \u0026#39;alex\u0026#39;, 18: 18, \u0026#39;position\u0026#39;: \u0026#39;Staff\u0026#39;} Qua 10 tri·ªáu l·∫ßn test tr√™n con m√°y apple m1 c·ªßa m√¨nh, m√¨nh th·∫•y r·∫±ng khai b√°o bi·∫øn dictionary b·∫±ng d·∫•u {} s·∫Ω ch·∫°y nhanh h∆°n so v·ªõi khai b√°o s·ª≠ d·ª•ng dict()\nThu·ªôc t√≠nh c·ªßa keys trong t·ª´ ƒëi·ªÉn. C√≥ ba ƒëi·ªÉm quan tr·ªçng v·ªÅ key c·ªßa dictionary ch√∫ng ta c·∫ßn ph·∫£i nh·ªõ:\nM·ªôt l√† key kh√¥ng cho ph√©p tr√πng nhau.\nKey ph·∫£i l√† thu·ªôc nh√≥m b·∫•t bi·∫øn - immutable, nh∆∞ number, tuple , string.\nKey c√≥ ph√¢n bi·ªát hoa th∆∞·ªùng.\nV√≠ d·ª•:\n1 2 3item = {\u0026#34;name\u0026#34;:\u0026#34; iPhone 13 Pro Max 512GB\u0026#34;,\u0026#34;Price\u0026#34;:\u0026#34;34.690.000\u0026#34;,\u0026#34;Brand\u0026#34;:\u0026#34;Apple\u0026#34;,\u0026#34;BRAND\u0026#34;:\u0026#34;Apple\u0026#34;} 4 5print(item[\u0026#34;Brand\u0026#34;]) 6 7\u0026gt;\u0026gt;\u0026gt; print(item[\u0026#34;Brand\u0026#34;]) 8Apple M·ªôt v√†i ph∆∞∆°ng th·ª©c c·ªßa dictionary copy Ph∆∞∆°ng th·ª©c n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ copy ph·∫ßn t·ª≠ c·ªßa bi·∫øn n√†y sang bi·∫øn kh√°c.\nV√≠ d·ª•:\n1 2item = {\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.690.000\u0026#34;,\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 3 4item_new = item.copy() 5 6print(item_new) 7 8\u0026gt;\u0026gt;\u0026gt; print(item_new) 9{\u0026#39;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.690.000\u0026#39;, \u0026#39;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;} update Ph∆∞∆°ng th·ª©c update ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ c·∫≠p nh·∫≠t d·ªØ li·ªáu n·∫øu key ƒë√£ c√≥, n·∫øu key ch∆∞a c√≥ th√¨ th√™m c·∫∑p key-value v√†o t·ª´ ƒëi·ªÉn.\nV√≠ d·ª•:\n1 2item = {\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 3 4item_new = item.copy() 5item_new.update({\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.690.000\u0026#34;}) # c·∫≠p nh·∫≠t gi√° tr·ªã, v√¨ key ƒë√£ t·ªìn t·∫°i 6 7item_new.update({\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 128GB\u0026#34; :\u0026#34;28.390.000\u0026#34;}) # th√™m c·∫∑p key-value v√†o bi·∫øn item_new 8 9print(item) 10print(item_new) 11 12#K·∫øt qu·∫£ 13 14\u0026gt;\u0026gt;\u0026gt; print(item) 15{\u0026#39;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.790.000\u0026#39;, \u0026#39;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;} 16\u0026gt;\u0026gt;\u0026gt; print(item_new) 17{\u0026#39;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.690.000\u0026#39;, \u0026#39;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;, \u0026#39;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 128GB\u0026#39;: \u0026#39;28.390.000\u0026#39;} del ƒê·ªÉ xo√° m·ªôt key ra kh·ªèi t·ª´ ƒëi·ªÉn, ch√∫ng ta d√πng t·ª´ kho√° del\n1 2item = {\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 3 4del item[\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 512GB\u0026#34;] 5 6print(item) 7 8#K·∫øt qu·∫£ 9 10\u0026gt;\u0026gt;\u0026gt; print(item) 11{\u0026#39;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;} item Ph∆∞∆°ng th·ª©c items tr·∫£ v·ªÅ gi√° tr·ªã c·ªßa t·ª´ ƒëi·ªÉn d∆∞·ªõi d·∫°ng list tuple (key,value)\n1 2info = {\u0026#34;name\u0026#34;:\u0026#34;Alex\u0026#34;,\u0026#34;age\u0026#34;:18,\u0026#34;position\u0026#34;:\u0026#34;staff\u0026#34;} 3print(info.items()) 4 5# K·∫øt qu·∫£ 6 7\u0026gt;\u0026gt;\u0026gt; print(info.items()) 8dict_items([(\u0026#39;name\u0026#39;, \u0026#39;Alex\u0026#39;), (\u0026#39;age\u0026#39;, 18), (\u0026#39;position\u0026#39;, \u0026#39;staff\u0026#39;)]) len Ph∆∞∆°ng th·ª©c len tr·∫£ v·ªÅ s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ trong t·ª´ ƒëi·ªÉn\n1 2item = {\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 3 4print(len(item)) 5 6#K·∫øt qu·∫£ 7 8\u0026gt;\u0026gt;\u0026gt; print(len(item)) 92 Merge ƒê·ªÉ n·ªëi hai hay nhi·ªÅu t·ª´ ƒëi·ªÉn v√†o l√†m m·ªôt, c√≥ m·ªôt s·ªë c√°ch sau:\nS·ª≠ d·ª•ng h√†m update, h√†m n√†y ƒë√£ ƒë∆∞·ª£c m√¨nh n√≥i r√µ ·ªü tr√™n, m√¨nh kh√¥ng nh·∫Øc l·∫°i n·ªØa\nS·ª≠ d·ª•ng Kwargs **.\nT·ª´ phi√™n b·∫£n 3.5 tr·ªü l√™n, python h·ªó tr·ª£ \u0026ldquo;ƒë·ªëi s·ªë t·ª´ kh√≥a\u0026rdquo; - Kwargs - keyword arguments l√† **, v√† l√∫c n√†y, ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng ** ·ªü tr∆∞·ªõc t√™n bi·∫øn.\nV√≠ d·ª•\n1 2itemApple = {\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 512GB\u0026#34; :\u0026#34;34.790.000\u0026#34;,\u0026#34;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 1TB\u0026#34;:\u0026#34;40.990.000\u0026#34;} 3 4 5itemSamsung = {\u0026#34;ƒêi·ªán tho·∫°i Samsung Galaxy S22 Ultra 5G 128GB \u0026#34;:\u0026#34;27.990.000\u0026#34;,\u0026#34;ƒêi·ªán tho·∫°i Samsung Galaxy S22 Ultra 5G 512GB\u0026#34;:\u0026#34;33.990.000\u0026#34;} 6 7itemPhone = {**itemApple,**itemSamsung} 8 9print(itemPhone) 10 11 12\u0026gt;\u0026gt;\u0026gt; print(itemPhone) 13{\u0026#39;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 512GB\u0026#39;: \u0026#39;34.790.000\u0026#39;, \u0026#39;ƒêi·ªán tho·∫°i iPhone 13 Pro Max 1TB\u0026#39;: \u0026#39;40.990.000\u0026#39;, \u0026#39;ƒêi·ªán tho·∫°i Samsung Galaxy S22 Ultra 5G 128GB \u0026#39;: \u0026#39;27.990.000\u0026#39;, \u0026#39;ƒêi·ªán tho·∫°i Samsung Galaxy S22 Ultra 5G 512GB\u0026#39;: \u0026#39;33.990.000\u0026#39;} T·ªïng k·∫øt: Ki·ªÉu d·ªØ li·ªáu t·ª´ ƒëi·ªÉn l∆∞u d·ªØ li·ªáu d∆∞·ªõi d·∫°ng key-value\nKey-value ƒë∆∞·ª£c ngƒÉn c√°ch v·ªõi nhau b·ªüi d·∫•u hai ch·∫•m (:)\nC·∫∑p key-value ƒë∆∞·ª£c ngƒÉn c√°ch v·ªõi c·∫∑p kh√°c b·ªüi d·∫•u ph·∫©y\nKey trong ki·ªÉu d·ªØ li·ªáu t·ª´ ƒëi·ªÉn l√† duy nh·∫•t\nKi·ªÉu t·ª´ ƒëi·ªÉn kh√¥ng l∆∞u th√¥ng tin theo m·ªôt th·ª© t·ª± c·ª• th·ªÉ, th√¥ng tin khi l·∫•y ra c√≥ th·ªÉ kh√°c th·ª© t·ª± v·ªõi th√¥ng tin khi nh·∫≠p v√†o. Tuy nhi√™n, t·ª´ phi√™n b·∫£n python3.7 tr·ªü ƒëi, ki·ªÉu t·ª´ ƒëi·ªÉn ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp theo th·ª© t·ª± c·ªßa key\nKi·ªÉu d·ªØ li·ªáu list List l√† c√°i th√πng ch·ª©a, ƒë·ªÉ ch·ª©a t·∫≠p c√°c d·ªØ li·ªáu. ƒê·ªÉ khai b√°o ki·ªÉu d·ªØ li·ªáu list, ta c√≥ th·ªÉ d·ª•ng d·∫•u ƒë√≥ng m·ªü ngo·∫∑c vu√¥ng ([]), ho·∫∑c d√πng t·ª´ kho√° list()\n1 2lsta = [1,2,3,4,5] # ƒë√¢y l√† khai b√°o list ch√≠nh th·ªëng c·ªßa python 3 4lstb = list((1,2,3,4,5)) # ƒë√¢y l√† s·ª≠ d·ª•ng h√†m ƒë·ªÉ t·∫°o list 5 6print(lsta) 7 8print(lstb) Truy xu·∫•t d·ªØ li·ªáu trong list D·ªØ li·ªáu trong list c√≥ th·ªÉ ƒë∆∞·ª£c truy xu·∫•t th√¥ng qua index. Index l√† v·ªã tr√≠ ƒë·ª©ng c·ªßa ph·∫ßn t·ª≠ trong list.\nV√≠ d·ª•, n·∫øu ta mu·ªën l·∫•y ra gi√° tr·ªã ·ªü v·ªã tr√≠ 0 c·ªßa list c√≥ t√™n l√† lsta, ta th·ª±c hi·ªán nh∆∞ sau: lst[0]\n1 2lsta = [5,3,6,9] 3 4print(lsta[0]) 5print(lsta[2]) 6 7\u0026gt;\u0026gt;\u0026gt; print(lsta[0]) 85 9\u0026gt;\u0026gt;\u0026gt; print(lsta[2]) 106 slicing slicing l√† l·∫•y m·ªôt nh√≥m c√°c ph·∫ßn t·ª≠ trong list ra, c√°ch th·ª±c hi·ªán gi·ªëng nh∆∞ tuple\n1lsta = [5,3,6,9,3,5,1,2,9,6] 2 3print(lsta[1:5]) 4 5\u0026gt;\u0026gt;\u0026gt; print(lsta[1:5]) 6[3, 6, 9, 3] Tuy nhi√™n, kh√¥ng gi·ªëng nh∆∞ tuple, gi√° tr·ªã c·ªßa tuple kh√¥ng th·ªÉ thay ƒë·ªïi ƒë∆∞·ª£c, gi√° tr·ªã c·ªßa list c√≥ th·ªÉ thay ƒë·ªïi ƒë∆∞·ª£c, n√™n ch√∫ng ta c√≥ th·ªÉ c·∫≠p nh·∫≠t gi√° tr·ªã cho list s·ª≠ d·ª•ng slicing\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4print(lsta) 5 6print(lsta[2:4]) 7 8lsta[2:4] = [8,8] 9 10print(lsta) 11 12print(lsta[2:4]) 13 14 15#K·∫øt qu·∫£ 16 17\u0026gt;\u0026gt;\u0026gt; print(lsta[2:4]) 18[6, 9] 19\u0026gt;\u0026gt;\u0026gt; 20\u0026gt;\u0026gt;\u0026gt; lsta[2:4] = [8,8] 21\u0026gt;\u0026gt;\u0026gt; 22\u0026gt;\u0026gt;\u0026gt; print(lsta) 23[5, 3, 8, 8, 3, 5, 1, 2, 9, 6] 24\u0026gt;\u0026gt;\u0026gt; 25\u0026gt;\u0026gt;\u0026gt; print(lsta[2:4]) 26[8, 8] M·ªôt ƒëi·ªÅu kh√° th√∫ v·ªã, l√† list h·ªó tr·ª£ index ng∆∞·ª£c, v√≠ d·ª•, n·∫øu ch√∫ng ta mu·ªën l·∫•y ph·∫ßn t·ª≠ cu·ªëi c√πng, ta c√≥ th·ªÉ s·ª≠ d·ª•ng index [-1], d√πng [-2] n·∫øu mu·ªën l·∫•y ph·∫ßn t·ª≠ k·∫ø cu·ªëi .\nv√≠ d·ª•\n1 2 3lsta = [5,3,6,9,3,5,1,2,9,6] 4 5print(lsta[-1]) 6 7print(lsta[-2]) 8 9#K·∫øt qu·∫£ 10 11\u0026gt;\u0026gt;\u0026gt; print(lsta[-1]) 126 13\u0026gt;\u0026gt;\u0026gt; 14\u0026gt;\u0026gt;\u0026gt; print(lsta[-2]) 159 H·ªá qu·∫£ c·ªßa index ng∆∞·ª£c, l√† ch√∫ng ta c√≥ slicing v·ªõi s·ªë √¢m\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4print(lsta[5:-1]) 5 6print(lsta[5:-2]) 7 8#K·∫øt qu·∫£ 9 10\u0026gt;\u0026gt;\u0026gt; print(lsta[5:-1]) 11[5, 1, 2, 9] 12\u0026gt;\u0026gt;\u0026gt; 13\u0026gt;\u0026gt;\u0026gt; print(lsta[5:-2]) 14[5, 1, 2] C√°c ph∆∞∆°ng th·ª©c ƒë∆∞·ª£c h·ªó tr·ª£ append Ph∆∞∆°ng th·ª©c append d√πng ƒë·ªÉ th√™m ph·∫ßn t·ª≠ v√†o list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4lsta.append(1) 5 6lsta.append([11,12]) 7 8print(lsta) 9 10 11# K·∫øt qu·∫£ 12 13\u0026gt;\u0026gt;\u0026gt; print(lsta) 14[5, 3, 6, 9, 3, 5, 1, 2, 9, 6, 1, [11, 12]] pop Ph∆∞∆°ng th·ª©c pop d√πng ƒë·ªÉ xo√° ph·∫ßn t·ª≠ ·ªü v·ªã tr√≠ index ra kh·ªèi list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4lsta.pop(0) 5 6print(lsta) 7 8# K·∫øt qu·∫£ 9 10\u0026gt;\u0026gt;\u0026gt; print(lsta) 11[3, 6, 9, 3, 5, 1, 2, 9, 6] remove Ph∆∞∆°ng th·ª©c remove d√πng ƒë·ªÉ xo√° ph·∫ßn t·ª≠ ra kh·ªèi list, n·∫øu c√≥ nhi·ªÅu ph·∫ßn t·ª≠ c√≥ c√πng gi√° tr·ªã v·ªõi ph·∫ßn t·ª≠ c·∫ßn xo√°, th√¨ ch·ªâ xo√° th·∫±ng ƒë·∫ßu ti√™n\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4lsta.remove(9) 5 6print(lsta) 7 8 9# K·∫øt qu·∫£ 10 11\u0026gt;\u0026gt;\u0026gt; print(lsta) 12[5, 3, 6, 3, 5, 1, 2, 9, 6] reverse Ph∆∞∆°ng th·ª©c reverse ƒë∆∞·ª£c d√πng ƒë·ªÉ ƒë·∫£o ng∆∞·ª£c list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4lsta.reverse() 5 6print(lsta) 7 8 9# K·∫øt qu·∫£ 10 11\u0026gt;\u0026gt;\u0026gt; print(lsta) 12[6, 9, 2, 1, 5, 3, 9, 6, 3, 5] C√°c h√†m ƒë∆∞·ª£c h·ªó tr·ª£ len H√†m len tr·∫£ v·ªÅ s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ trong list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4print(len(lsta)) 5 6 7# K·∫øt qu·∫£ 8 9\u0026gt;\u0026gt;\u0026gt; print(len(lsta)) 1010 max H√†m max tr·∫£ v·ªÅ ph·∫ßn t·ª≠ c√≥ gi√° tr·ªã l·ªõn nh·∫•t trong list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4print(max(lsta)) 5 6 7# K·∫øt qu·∫£ 8 9\u0026gt;\u0026gt;\u0026gt; print(max(lsta)) 109 min H√†m min tr·∫£ v·ªÅ ph·∫ßn t·ª≠ c√≥ gi√° tr·ªã nh·ªè nh·∫•t trong list\n1 2lsta = [5,3,6,9,3,5,1,2,9,6] 3 4print(min(lsta)) 5 6 7# K·∫øt qu·∫£ 8 9\u0026gt;\u0026gt;\u0026gt; print(min(lsta)) 101 Ki·ªÉu d·ªØ li·ªáu set Trong python, set l√† t·∫≠p h·ª£p kh√¥ng c√≥ th·ª© t·ª± c√°c d·ªØ li·ªáu. D·ªØ li·ªáu trong set l√† duy nh·∫•t.\nƒê·ªÉ t·∫°o m·ªôt set, ch√∫ng ta s·ª≠ d·ª•ng h√†m set(), ho·∫∑c d√πng d·∫•u ƒë√≥ng m·ªü ngo·∫∑c nh·ªçn {}\nV√≠ d·ª•:\n1 2item_samsung = set([\u0026#34;Samsung Galaxy S22 Ultra 5G\u0026#34;,\u0026#34;Samsung Galaxy A13\u0026#34;]) 3 4item_iphone = {\u0026#34;Iphone 12\u0026#34;,\u0026#34;Iphone 13\u0026#34;} 5 6print(item_samsung) 7 8print(item_iphone) 9 10#K·∫øt qu·∫£ 11 12\u0026gt;\u0026gt;\u0026gt; print(item_samsung) 13{\u0026#39;Samsung Galaxy S22 Ultra 5G\u0026#39;, \u0026#39;Samsung Galaxy A13\u0026#39;} 14\u0026gt;\u0026gt;\u0026gt; 15\u0026gt;\u0026gt;\u0026gt; print(item_iphone) 16{\u0026#39;Iphone 13\u0026#39;, \u0026#39;Iphone 12\u0026#39;} M·ªôt v√†i ph∆∞∆°ng th·ª©c c∆° b·∫£n c·ªßa Set Ph∆∞∆°ng th·ª©c Add Ph∆∞∆°ng th·ª©c n√†y c√≥ nhi·ªám v·ª• th√™m ph·∫ßn t·ª≠ v√† Set\nV√≠ d·ª•:\n1 2item = set() 3 4item.add(\u0026#34;Iphone\u0026#34;) 5 6item.add(\u0026#34;Samsung\u0026#34;) 7 8print(item) 9 10 11# K·∫øt qu·∫£ 12 13\u0026gt;\u0026gt;\u0026gt; print(item) 14{\u0026#39;Samsung\u0026#39;, \u0026#39;Iphone\u0026#39;} Ph∆∞∆°ng th·ª©c Remove, Discard Ph∆∞∆°ng th·ª©c n√†y d√πng ƒë·ªÉ xo√° ph·∫ßn t·ª≠ ra kh·ªèi set. ƒêi·ªÉm kh√°c nhau c·ªßa hai ph∆∞∆°ng th·ª©c n√†y l√†:\nPh∆∞∆°ng th·ª©c remove: Xo√° ph·∫ßn t·ª≠ ra kh·ªèi set, n·∫øu kh√¥ng t·ªìn t·∫°i ph·∫ßn t·ª≠ c·∫ßn xo√° trong set, ch∆∞∆°ng tr√¨nh s·∫Ω tr·∫£ v·ªÅ l·ªói KeyError\nPh∆∞∆°ng th·ª©c discard: Xo√° ph·∫ßn t·ª≠ ra kh·ªèi set, n·∫øu kh√¥ng t·ªìn t·∫°i ph·∫ßn t·ª≠ c·∫ßn xo√° trong set, ch∆∞∆°ng tr√¨nh v·∫´n ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng.\nV√≠ d·ª•:\n1 2 3item = set() 4 5item.add(\u0026#34;Iphone\u0026#34;) 6 7item.add(\u0026#34;Samsung\u0026#34;) 8 9print(item) 10 11item.discard(\u0026#34;Samsung\u0026#34;) 12 13item.discard(\u0026#34;Xiaomi\u0026#34;) 14 15item.remove(\u0026#34;Oppo\u0026#34;) 16 17# K·∫øt qu·∫£ 18 19\u0026gt;\u0026gt;\u0026gt; print(item) 20{\u0026#39;Samsung\u0026#39;, \u0026#39;Iphone\u0026#39;} 21\u0026gt;\u0026gt;\u0026gt; 22\u0026gt;\u0026gt;\u0026gt; item.discard(\u0026#34;Samsung\u0026#34;) # xo√° b√¨nh th∆∞·ªùng 23\u0026gt;\u0026gt;\u0026gt; 24\u0026gt;\u0026gt;\u0026gt; item.discard(\u0026#34;Xiaomi\u0026#34;) # Xiaomi kh√¥ng t·ªìn t·∫°i trong set item, ch∆∞∆°ng tr√¨nh v·∫´n kh√¥ng b√∫ng ra l·ªói 25\u0026gt;\u0026gt;\u0026gt; 26\u0026gt;\u0026gt;\u0026gt; item.remove(\u0026#34;Oppo\u0026#34;) # Oppo kh√¥ng t·ªìn t·∫°i trong set item, ch∆∞∆°ng tr√¨nh b√°o l·ªói KeyError 27Traceback (most recent call last): 28 File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; 29KeyError: \u0026#39;Oppo\u0026#39; Ph∆∞∆°ng th·ª©c Pop Ph∆∞∆°ng th·ª©c pop ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n c·ªßa set ra, v√† lo·∫°i ph·∫ßn t·ª≠ cu·ªëi ƒë√≥ ra kh·ªèi set.\nV√≠ d·ª•:\n1 2 3item = {1,5,6,4,3,8,10} 4 5print(item) 6 7print(item.pop()) 8 9print(item) 10 11 12# K·∫øt qu·∫£ 13 14\u0026gt;\u0026gt;\u0026gt; item = {1,5,6,4,3,8,10} 15\u0026gt;\u0026gt;\u0026gt; 16\u0026gt;\u0026gt;\u0026gt; print(item) 17{1, 3, 4, 5, 6, 8, 10} 18\u0026gt;\u0026gt;\u0026gt; 19\u0026gt;\u0026gt;\u0026gt; print(item.pop()) 201 21\u0026gt;\u0026gt;\u0026gt; 22\u0026gt;\u0026gt;\u0026gt; print(item) 23{3, 4, 5, 6, 8, 10} Ph∆∞∆°ng th·ª©c Clear Ph∆∞∆°ng th·ª©c clear ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ xo√° m·ªçi ph·∫ßn t·ª≠ trong set. K·∫øt qu·∫£ l√† ch√∫ng ta ƒë∆∞·ª£c m·ªôt set r·ªóng\n1 2 3item_iphone = {\u0026#34;Iphone 12\u0026#34;,\u0026#34;Iphone 13\u0026#34;} 4 5item_iphone.clear() 6 7print(item_iphone) 8 9 10# K·∫øt qu·∫£ 11 12\u0026gt;\u0026gt;\u0026gt; print(item_iphone) 13set() Ki·ªÉu d·ªØ li·ªáu array Array l√† t·∫≠p c√°c ph·∫ßn t·ª≠ ƒë∆∞·ª£c l∆∞u tr·ªØ c√≥ th·ª© t·ª± trong b·ªô nh·ªõ. C√°c ph·∫ßn t·ª≠ trong array ph·∫£i c√≥ c√πng ki·ªÉu d·ªØ li·ªáu. Ki·ªÉu d·ªØ li·ªáu array gi·ªëng ki·ªÉu array trong c++.\nV√≠ d·ª•:\n1 2import array as arr 3 4item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5]) 5 6print(item_number) 7 8 9item_number_decimal = arr.array(\u0026#39;d\u0026#39;,[5.391,6.626,1.054,1.616]) 10 11 12print(item_number_decimal) 13 14 15 16#K·∫øt qu·∫£ 17 18\u0026gt;\u0026gt;\u0026gt; print(item_number) 19array(\u0026#39;i\u0026#39;, [1, 2, 3, 5]) 20 21\u0026gt;\u0026gt;\u0026gt; print(item_number_decimal) 22array(\u0026#39;d\u0026#39;, [5.391, 6.626, 1.054, 1.616]) M·ªôt v√†i ph∆∞∆°ng th·ª©c c∆° b·∫£n c·ªßa array Ph∆∞∆°ng th·ª©c insert, ph∆∞∆°ng th·ª©c append Ph∆∞∆°ng th·ª©c insert v√† append ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ th√™m ph·∫ßn t·ª≠ v√†o array, ƒëi·ªÉm kh√°c bi·ªát c·ªßa hai ph∆∞∆°ng th·ª©c l√†:\nPh∆∞∆°ng th·ª©c insert: ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ch√®n ph·∫ßn t·ª≠ v√†o v·ªã tr√≠ tu·ª≥ √Ω.\nPh∆∞∆°ng th·ª©c append: Ch√®n v√†o cu·ªëi array.\nV√≠ d·ª•:\n1 2import array as arr 3 4item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5]) 5 6item_number.insert(2,4) 7 8print(item_number) 9 10item_number.append(1) 11 12print(item_number) 13 14#K·∫øt qu·∫£ 15\u0026gt;\u0026gt;\u0026gt; item_number.insert(2,4) 16\u0026gt;\u0026gt;\u0026gt; print(item_number) 17array(\u0026#39;i\u0026#39;, [1, 2, 4, 3, 5]) 18 19\u0026gt;\u0026gt;\u0026gt; item_number.append(1) 20\u0026gt;\u0026gt;\u0026gt; print(item_number) 21array(\u0026#39;i\u0026#39;, [1, 2, 4, 3, 5, 1]) Ph∆∞∆°ng th·ª©c truy xu·∫•t ph·∫ßn t·ª≠ theo index ƒê·ªÉ truy xu·∫•t ph·∫ßn t·ª≠ theo index, ch√∫ng ta s·ª≠ d·ª•ng d·∫•u ngo·∫∑c vu√¥ng [], k√®m theo v·ªã tr√≠ c·ªßa ph·∫ßn t·ª≠ c·∫ßn truy xu·∫•t.\n1 2 3 4import array as arr 5 6item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5]) 7 8print(item_number[2]) 9 10 11#K·∫øt qu·∫£ 12 13\u0026gt;\u0026gt;\u0026gt; print(item_number[2]) 143 Ph∆∞∆°ng th·ª©c remove, ph∆∞∆°ng th·ª©c pop Ph∆∞∆°ng th·ª©c remove v√† pop ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ xo√° ph·∫ßn t·ª≠ ra kh·ªèi array.\nPh∆∞∆°ng th·ª©c remove: Xo√° ph·∫ßn t·ª≠ ra kh·ªèi m·∫£ng, n·∫øu m·∫£ng c√≥ nhi·ªÅu ph·∫ßn t·ª≠ tr√πng v·ªõi ph·∫ßn t·ª≠ c·∫ßn xo√° th√¨ ch·ªâ xo√° ph·∫ßn t·ª≠ xu·∫•t hi·ªán ƒë·∫ßu ti√™n. N·∫øu ph·∫ßn t·ª≠ kh√¥ng c√≥ trong m·∫£ng, ch∆∞∆°ng tr√¨nh s·∫Ω b√∫ng ra l·ªói.\nPh∆∞∆°ng th·ª©c pop: Xo√° ph·∫ßn t·ª≠ ·ªü v·ªã tr√≠ index ra kh·ªèi m·∫£ng, tr·∫£ v·ªÅ l√† gi√° tr·ªã c·ªßa ph·∫ßn t·ª≠ b·ªã remove. N·∫øu kh√¥ng truy·ªÅn v√†o v·ªã tr√≠ c·∫ßn xo√°, th√¨ s·∫Ω xo√° ph·∫ßn t·ª≠ cu·ªëi c√πng trong m·∫£ng.\n1 2 3import array as arr 4 5item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5,2]) 6 7print(item_number) 8 9item_number.remove(2) 10 11print(item_number) 12 13print(item_number.pop(2)) 14 15print(item_number) 16 17 18#K·∫øt qu·∫£ 19 20\u0026gt;\u0026gt;\u0026gt; print(item_number) 21array(\u0026#39;i\u0026#39;, [1, 2, 3, 5, 2]) 22\u0026gt;\u0026gt;\u0026gt; item_number.remove(2) # xo√° s·ªë 2 ƒëi 23\u0026gt;\u0026gt;\u0026gt; 24\u0026gt;\u0026gt;\u0026gt; print(item_number) 25array(\u0026#39;i\u0026#39;, [1, 3, 5, 2]) # Ch·ªâ s·ªë 2 ƒë·∫ßu ti√™n b·ªã xo√° 26\u0026gt;\u0026gt;\u0026gt; 27\u0026gt;\u0026gt;\u0026gt; print(item_number.pop(2)) # xo√° ph·∫ßn t·ª≠ ·ªü v·ªã tr√≠ s·ªë 2 285 # Ph·∫ßn t·ª≠ ·ªü v·ªã tr√≠ s·ªë 2 l√† 5, ph·∫ßn t·ª≠ 5 ƒë√£ b·ªã xo√° 29\u0026gt;\u0026gt;\u0026gt; 30\u0026gt;\u0026gt;\u0026gt; print(item_number) 31array(\u0026#39;i\u0026#39;, [1, 3, 2]) Ph∆∞∆°ng th·ª©c index Ph∆∞∆°ng th·ª©c n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√¨m v·ªã tr√≠ c·ªßa ph·∫ßn t·ª≠ trong array\n1 2import array as arr 3 4item_number = arr.array(\u0026#39;i\u0026#39;,[1,2,3,5,2]) 5 6print(item_number.index(2)) 7 8 9print(item_number.index(2,2)) 10 11 12 13#K·∫øt qu·∫£ 14 15\u0026gt;\u0026gt;\u0026gt; print(item_number.index(2)) #T√¨m v·ªã tr√≠ c·ªßa s·ªë 2 161 17\u0026gt;\u0026gt;\u0026gt; 18\u0026gt;\u0026gt;\u0026gt; print(item_number.index(2,2))# T√¨m v·ªã tr√≠ c·ªßa s·ªë 2, b·∫Øt ƒë·∫ßu t·ª´ v·ªã tr√≠ 2 194 Ch√∫c c√°c b·∫°n h·ªçc th·∫≠t t·ªët.\n","date":"Jul 10, 2022","img":"","permalink":"/courses/python/3_python_data_struct/","series":["Kh√≥a h·ªçc python cƒÉn b·∫£n"],"tags":["python"],"title":"B√†i 2: Ki·ªÉu D·ªØ Li·ªáu Trong Python"},{"categories":"python","content":"Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu c√°c m·ª•c sau\nC√†i ƒë·∫∑t python C√†i ƒë·∫∑t ph·∫ßn m·ªÅm ƒë·ªÉ l·∫≠p tr√¨nh python (IDE) Ch∆∞∆°ng tr√¨nh python ƒë·∫ßu ti√™n - Hello word Bi·∫øn trong python Ki·ªÉu d·ªØ li·ªáu Khai b√°o v√† s·ª≠ d·ª•ng bi·∫øn trong python √âp ki·ªÉu d·ªØ li·ªáu Xem ki·ªÉu d·ªØ li·ªáu C√†i ƒë·∫∑t python ƒê·ªÉ c√†i ƒë·∫∑t python, c√°c b·∫°n truy c·∫≠p v√†o ƒë∆∞·ªùng d·∫´n https://www.python.org/downloads/ v√† download phi√™n b·∫£n python m·ªõi nh·∫•t, ph√π h·ª£p v·ªõi h·ªá ƒëi·ªÅu h√†nh c·ªßa b·∫°n. T·∫°i th·ªùi ƒëi·ªÉm m√¨nh vi·∫øt b√†i vi·∫øt n√†y, phi√™n b·∫£n python m·ªõi nh·∫•t l√† 3.10.4. N·∫øu c√°c b·∫°n s·ª≠ d·ª•ng h·ªá ƒëi·ªÅu h√†nh window, c√¥ng vi·ªác s·∫Ω h·∫øt s·ª©c ƒë∆°n gi·∫£n, c√°c b·∫°n ch·ªâ c·∫ßn download file c√†i ƒë·∫∑t python v·ªÅ, ·∫•n next -\u0026gt; next -\u0026gt; next \u0026hellip; finish. Xong\nƒê·ªëi v·ªõi h·ªá ƒëi·ªÅu h√†nh macos ho·∫∑c linux, th√¥ng th∆∞·ªùng th√¨ ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t s·∫µn python, n√™n c√°c b·∫°n c√≥ th·ªÉ b·ªè qua b∆∞·ªõc n√†y.\nH√£y li√™n h·ªá m√¨nh qua chat message n·∫øu c√°c b·∫°n g·∫∑p b·∫•t k·ª≥ kh√≥ khƒÉn ho·∫∑c l·ªói g√¨ khi c√†i ƒë·∫∑t python nh√©.\nC√†i ƒë·∫∑t ph·∫ßn m·ªÅm ƒë·ªÉ l·∫≠p tr√¨nh python (IDE) ·ªû ƒë√¢y, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng Visual studio code, m·ªôt IDE nh·∫π nh√†ng, h·ªó tr·ª£ nhi·ªÅu t√≠nh nƒÉng, h·ªó tr·ª£ nhi·ªÅu m√¥i tr∆∞·ªùng. C√°c b·∫°n h√£y truy c·∫≠p v√†o ƒë∆∞·ªùng d·∫´n https://code.visualstudio.com/download v√† download file c√†i ƒë·∫∑t v·ªÅ. V·ªõi h·ªá ƒëi·ªÅu h√†nh window th√¨ ch√∫ng ta ch·ªâ c·∫ßn next -\u0026gt; next \u0026hellip; finish.\nCh∆∞∆°ng tr√¨nh python ƒë·∫ßu ti√™n - Hello word Ch√∫ng ta h√£y m·ªü ch∆∞∆°ng tr√¨nh visual studio code l√™n, ch·ªçn File -\u0026gt; New File -\u0026gt; ƒë·∫∑t t√™n file l√† hello_word.py\nG√µ v√†o d√≤ng l·ªánh\n1print (\u0026#34;Hello World!\u0026#34;) Ch·ªçn File -\u0026gt; Save ho·∫∑c ·∫•n t·ªï h·ª£p ph√≠m ctr + s (window - ubuntu) ho·∫∑c command + s (macos)\nCh·ªçn Terminal -\u0026gt; New Terminal\nG√µ v√†o trong terminal d√≤ng l·ªánh\n1python3 hello_word.py C·ª≠a s·ªï terminal s·∫Ω hi·ªán ra nh∆∞ sau:\n1python3 hello_word.py 2\u0026gt;\u0026gt;\u0026gt;Hello World! Bi·∫øn trong python Bi·∫øn l√† n∆°i l∆∞u tr·ªØ c√°c gi√° tr·ªã. Gi√° tr·ªã ƒë∆∞·ª£c g√°n v√†o bi·∫øn th√¥ng qua d·∫•u =\nV√≠ d·ª•:\n1 2name = \u0026#39;alex\u0026#39; # name l√† t√™n bi·∫øn, gi√° tr·ªã c·ªßa name l√† alex 3 4age = 18 # age l√† t√™n bi·∫øn, gi√° tr·ªã c·ªßa age l√† 18 Ki·ªÉu d·ªØ li·ªáu M·ªói gi√° tr·ªã trong python ƒë·ªÅu thu·ªôc m·ªôt ki·ªÉu d·ªØ li·ªáu n√†o ƒë√≥. C√°c ki·ªÉu d·ªØ li·ªáu ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a s·∫µn trong python l√† string, number, list, dictionary, set. Ngo√†i ra, ch√∫ng ta c√≥ th·ªÉ t·ª± ƒë·ªãnh nghƒ©a c√°c ki·ªÉu d·ªØ li·ªáu ƒë·ªÉ ƒë√°p ·ª©ng nhu c·∫ßu trong b√†i to√°n c·ªßa m√¨nh. V√≠ d·ª• ki·ªÉu d·ªØ li·ªáu con m√®o, con ch√≥, ƒë·ªông v·∫≠t, c√¢y, xe ƒë·∫°p, xe h∆°i \u0026hellip;\nKhai b√°o v√† s·ª≠ d·ª•ng bi·∫øn trong python Python kh√¥ng c√≥ c√¢u l·ªánh khai b√°o bi·∫øn. Bi·∫øn ƒë∆∞·ª£c t·∫°o ra t·∫°i th·ªùi ƒëi·ªÉm ch√∫ng ƒë∆∞·ª£c g√°n gi√° tr·ªã.\nV√≠ d·ª•:\n1x = 5 # bi·∫øn x ƒë∆∞·ª£c t·∫°o ra, c√≥ gi√° tr·ªã l√† 5, ki·ªÉu d·ªØ li·ªáu l√† int 2 3x = \u0026#34;Alex\u0026#34; # bi·∫øn x ƒë∆∞·ª£c g√°n gi√° tr·ªã l√† Alex, ki·ªÉu d·ªØ li·ªáu l√† string √âp ki·ªÉu d·ªØ li·ªáu √âp ki·ªÉu, nghƒ©a l√† bi·∫øn ƒëang c√≥ ki·ªÉu d·ªØ li·ªáu n√†y, ch√∫ng ta mu·ªën bi·∫øn n√≥ th√†nh ki·ªÉu d·ªØ li·ªáu n·ªç. V√≠ d·ª•, m·ªôt bi·∫øn ƒëang c√≥ ki·ªÉu d·ªØ li·ªáu l√† int, b√†i to√°n y√™u c·∫ßu chuy·ªÉn sang ki·ªÉu d·ªØ li·ªáu float r·ªìi t√≠nh to√°n\n1 2 3x = 5 # ki·ªÉu d·ªØ li·ªáu c·ªßa x l√† int 4 5x = float(x) # ki·ªÉu d·ªØ li·ªáu c·ªßa x l√† float 6 7x = str(x) # ki·ªÉu d·ªØ li·ªáu c·ªßa x gi·ªù l√† string Xem ki·ªÉu d·ªØ li·ªáu ƒê·ªÉ xem ki·ªÉu d·ªØ li·ªáu c·ªßa m·ªôt bi·∫øn, ch√∫ng ta s·ª≠ d·ª•ng h√†m type\n1 2x = 9 3 4y = \u0026#39;alex\u0026#39; 5 6 7print(type(x)) 8 9\u0026gt;\u0026gt;\u0026gt; \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; 10 11print(type(y)) 12 13\u0026gt;\u0026gt;\u0026gt; \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; ","date":"Jun 5, 2022","img":"","permalink":"/courses/python/2_python_basic/","series":["Kh√≥a h·ªçc python cƒÉn b·∫£n"],"tags":["python"],"title":"B√†i 1: CƒÉn B·∫£n V·ªÅ Python"},{"categories":null,"content":" Ch·ªâ s·ªë MACD, l√† t√™n g·ªçi t·∫Øt c·ªßa moving average convergence/divergence, l√† m·ªôt ch·ªâ s·ªë giao d·ªãch ƒë∆∞·ª£c s·ª≠ d·ª•ng trong ph√¢n t√≠ch k·ªπ thu·∫≠t tr√™n gi√° c·ªï phi·∫øu. Ch·ªâ s·ªë ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Gerald Appel v√†o nh·ªØng nƒÉm cu·ªëi th·∫≠p ni√™n 70 c·ªßa th·∫ø k·ª∑ 20.\nCh·ªâ s·ªë MACD gi√∫p ch√∫ng ta x√°c ƒë·ªãnh s·ª± thay ƒë·ªïi c·ªßa s·ª©c m·∫°nh, h∆∞·ªõng, ƒë·ªông l∆∞·ª£ng ( momentum), v√† kho·∫£ng th·ªùi gian c·ªßa xu h∆∞·ªõng gi√° c·ªï phi·∫øu. ƒê·ªÉ l√†m ƒë∆∞·ª£c ƒëi·ªÅu n√†y, MACD s·ª≠ d·ª•ng 3 chu·ªói th·ªùi gian EMA kh√°c nhau, theo s√°ch v·ªü kinh ƒëi·ªÉn l√† EMA12, EMA26 v√† EMA9. Ch·ªâ s·ªë MACD d√πng 3 chu·ªói EMA tr√™n, ƒë∆∞·ª£c k√Ω hi·ªáu l√† MACD(12,26,9). Do ch·ªâ s·ª≠ d·ª•ng l·ªãch s·ª≠ gi√° c·ªßa qu√° kh·ª©, n√™n ch·ªâ s·ªë MACD ƒë∆∞·ª£c x·∫øp v√†o nh√≥m ch·ªâ s·ªë d·ª± b√°o mu·ªôn.\nM√¥ h√¨nh MACD ƒê∆∞·ªùng MACD $$ MACD = EMA_{12} - EMA_{26} $$\nMACD ƒë∆∞·ª£c c·∫•u t·∫°o b·∫±ng c√°ch l·∫•y chu k·ª≥ ng·∫Øn h·∫°n tr·ª´ chu k·ª≥ d√†i h·∫°n (EMA12 - EMA26). Th·ªã tr∆∞·ªùng tƒÉng gi√° l√† t·∫°i th·ªùi ƒëi·ªÉm MACD chuy·ªÉn tr·∫°ng th√°i gi√° tr·ªã t·ª´ √¢m sang d∆∞∆°ng. Ng∆∞·ª£c l·∫°i, th·ªã tr∆∞·ªùng gi·∫£m gi√° l√† t·∫°i th·ªùi ƒëi·ªÉm MACD chuy·ªÉn tr·∫°ng th√°i t·ª´ d∆∞∆°ng sang √¢m\n$$ signal = EMA_9 $$\nƒê∆∞·ªùng t√≠n hi·ªáu ƒëi song song v·ªõi ƒë∆∞·ªùng MACD, v√† x·∫£y ra c√°c tr∆∞·ªùng h·ª£p sau\nXu h∆∞·ªõng tƒÉng gi√°: ƒê∆∞·ªùng MACD c·∫Øt ƒë∆∞·ªùng t√≠n hi·ªáu, MACD ƒëi t·ª´ d∆∞·ªõi l√™n\nXu h∆∞·ªõng gi·∫£m gi√°: ƒê∆∞·ªùng MACD c·∫Øt ƒë∆∞·ªùng t√≠n hi·ªáu, MADC ƒëi t·ª´ tr√™n xu·ªëng\n$$ histogram = MACD - signal $$\nƒê∆∞·ªùng histogram: ƒëo kho·∫£ng c√°ch ch√™n l·ªách gi·ªØa MACD v√† signal. Nh∆∞ h√¨nh 1 ph√≠a tr√™n, gi√° tr·ªã c·ªßa histotram ƒë∆∞·ª£c bi·ªÉu di·ªÖn l√† c√°c ƒë∆∞·ªùng tr·ª• h√¨nh vu√¥ng, c√≥ gi√° tr·ªã d√†i ng·∫Øn kh√°c nhau. Gi√° tr·ªã histogram ph·∫£n √°nh gi√° tr·ªã ƒë·ªông l∆∞·ª£ng (momemtum) v·ªÅ gi√°. N·∫øu MACD l·ªõn h∆°n ƒë∆∞·ªùng t√≠n hi·ªáu th√¨ ch√∫ng ta s·∫Ω c√≥ v√πng ƒë·ªìi d∆∞∆°ng.\nN·∫øu ƒë·ªÉ √Ω k·ªπ, ch√∫ng ta c√≥ th·ªÉ th·∫•y r·∫±ng, n·∫øu l·ª±c mua v·∫´n d∆∞∆°ng, ƒë·ªìi v·∫´n d∆∞∆°ng, nh∆∞ng gi√° tr·ªã histogram ng·∫Øn l·∫°i, g·∫ßn 0, ƒë√≥ c√≥ th·ªÉ l√† t√≠n hi·ªáu c·ªßa vi·ªác gi√° c√≥ th·ªÉ gi·∫£m.\nVi·∫øt bot mua ch·ª©ng kho√°n m√£ MWG, t·ª± ƒë·ªông, d·ª±a tr√™n MACD, ki·ªÉm th·ª≠ l·ª£i nhu·∫≠n D∆∞·ªõi t∆∞ c√°ch l√† l·∫≠p tr√¨nh vi√™n, m√¨nh s·∫Ω coding m·ªôt con bot nh·ªè, ch·ªâ s·ª≠ d·ª•ng MACD, v√† xem th·ª≠ l·ª£i nhu·∫≠n nh∆∞ th·∫ø n√†o.\nB√†i to√°n gi·∫£ ƒë·ªãnh:\nCho d∆∞ 100 tri·ªáu VND trong tay\nƒê·∫ßu t∆∞ c·ªï phi·∫øu c·ªßa t·∫≠p ƒëo√†n th·∫ø gi·ªõi Di ƒë·ªông, m√£ c·ªï phi·∫øu MWG\nTh·ªùi gian: T·ª´ ng√†y 1/1/2021 ƒë·∫øn 31/12/2021\nƒê·∫ßu t∆∞ to√†n b·ªô trong m·ªôt l·∫ßn, kh√¥ng DCA, kh√¥ng x√©t y·∫øu t·ªë T+3, gi√° mua v√† gi√° ch·ªët l·ªùi l√† gi√° t·∫°i th·ªùi ƒëi·ªÉm close.\nL·∫•y d·ªØ li·ªáu: M√¨nh s·ª≠ d·ª•ng th∆∞ vi·ªán vnquant c·ªßa anh Ph·∫°m Kh√°nh ƒê√¨nh. M√£ ngu·ªìn c·ªßa th∆∞ vi·ªán ·ªü ƒë·ªãa ch·ªâ https://github.com/phamdinhkhanh/vnquant. DataSource ƒë∆∞·ª£c d√πng l√† c·ªßa vndirect. Th∆∞ vi·ªán c·ªßa anh Kh√°nh t·∫°i th·ªùi ƒëi·ªÉm m√¨nh s·ª≠ d·ª•ng b·ªã l·ªói khi load data vndirect, m√¨nh c√≥ rewrite l·∫°i.\nƒê·ªÉ t√≠nh EMA, m√¨nh x√†i h√†m ewm c√≥ s·∫µn c·ªßa pandas.\nK·∫øt qu·∫£: Nh∆∞ h√¨nh 1 m√¨nh ƒë√£ show ph√≠a tr√™n, hi hi.\n1Profit gained from the MACD strategy by investing $100M in MWG : 15619726.64 2Profit percentage of the MACD strategy : 15% N·∫øu m√¨nh ƒë·∫ßu t∆∞ 100 tri·ªáu ·ªü ƒë·∫ßu nƒÉm 2021, s·ª≠ d·ª•ng MACD v·ªõi c√°c tham s·ªë (12, 26, 9), ƒë·∫øn cu·ªëi nƒÉm m√¨nh thu ƒë∆∞·ª£c th√™m 15 tri·ªáu 6 trƒÉm 19 ng√†n 7 trƒÉm 26 ƒë·ªìng. L·ª£i nh·∫≠n h∆°n 15%, cao h∆°n ti·ªÅn l·ªùi g·ª≠i ng√¢n h√†ng.\nTham s·ªë 12,16,9 theo s√°ch v·ªü, m√¨nh kh√¥ng ∆∞ng l·∫Øm, th·∫ø l√† m√¨nh ƒë√£ cho ch·∫°y grid search t√¨m tham s·ªë t·ªët nh·∫•t, k·∫øt qu·∫£ ·ªü h√¨nh 2. Cu·ªëi c√πng m√¨nh ƒë√£ t√¨m ƒë∆∞·ª£c v√†i t·ªï h·ª£p nh∆∞ (9,25,6) ho·∫∑c (10,26,5) cho ra l·ª£i nhu·∫≠n ƒë·∫°t 40%.\nH√¨nh 2: MWG grid search\nCho d√π c√°c t·ªï h·ª£p ·ªü tr√™n kh√° cao, nh∆∞ng m√¨nh quy·∫øt ƒë·ªãnh ch·ªçn c·∫∑p t·ªï h·ª£p (11,31,5) cho c√°c b√†i to√°n trong t∆∞∆°ng lai. L√Ω do l√† l·ª£i nhu·∫≠n c·ªßa t·∫≠p t·ªï h·ª£p c≈©ng kh√° cao, ƒë·∫°t 39%, th·ª© hai l√† t·∫≠p t·ªï h·ª£p tr√™n ch·ª©a to√†n s·ªë nguy√™n t·ªë.\nBOT mua ch·ª©ng kho√°n, r·ªó VN30 T∆∞∆°ng t·ª± nh∆∞ mua c·ªï phi·∫øu MWG. M√¨nh s·∫Ω th·ª±c hi·ªán test mua c·ªï phi·∫øu trong r·ªó VN30, g·ªìm c√°c m√£ c·ªï phi·∫øu VPB, HPG, MBB, POW, STB, TCB, SSI, CTG, VRE, TCH, VHM, NVL, PDR, BID, FPT, HDB, TPB, SBT, MWG, VIC, BVH, VNM, PLX, MSN, PNJ, VCB, VJC, KDH, REE, GAS nh∆∞ sau:\nM·ªói lo·∫°i c·ªï phi·∫øu ƒë∆∞·ª£c c·∫•p v·ªën 100 tri·ªáu, t·ªïng c·ªông 30 m√£ c·ªï phi·∫øu, c√≥ 3 t·ª∑\nS·ª≠ d·ª•ng t·ªï h·ª£p MACD(11,31,5)\nTh·ªëng k√™ l·ª£i nhu·∫≠n cu·ªëi nƒÉm\nK·∫øt qu·∫£\nStock code Profit Profit Percent VPB 59531568.83 59 HPG 47797426.41 47 MBB 43655931.7 43 POW 11334630.9 11 STB 68945860.5 68 TCB 30909090.6 30 SSI 88181694.47 88 CTG 16023538.94 16 VRE 13112161.55 13 TCH 61063208.12 61 VHM 5633657.62 5 NVL 83612690.71 83 PDR 73030645.91 73 BID -10671169.9 -11 FPT 16548330.46 16 HDB 42686713.83 42 TPB 30960123.75 30 SBT 25536989.15 25 MWG 39039335.94 39 VIC 30392688.88 30 BVH -3770737.5 -4 VNM -13891787.01 -14 PLX 5485716.75 5 MSN 8503902.24 8 PNJ -6325266.73 -7 VCB -7289353.31 -8 VJC -2464227.2 -3 KDH 44801727.18 44 REE 26242537.2 26 GAS 41354753.12 41 C√≥ √¥ng l·ªùi, c√≥ √¥ng l·ªó. T·ªïng l·ªùi l√† 869.972.383 tri·ªáu, tr√™n t·ª∑ l·ªá ƒë·∫ßu t∆∞ l√† 3 t·ª∑. ƒê·∫°t t·ª∑ l·ªá l·ª£i nhu·∫≠n 28%.\n·ªû tr√™n, m√¨nh ch·ªâ s·ª≠ d·ª•ng ƒë∆∞·ªùng xu h∆∞·ªõng ƒë·ªÉ quy·∫øt ƒë·ªãnh mua / b√°n, ch∆∞a h·ªÅ s·ª≠ d·ª•ng gi√° tr·ªã ƒë·ªông l∆∞·ª£ng c·ªßa histogram ƒë·ªÉ x√©t vi·ªác ch·ªët l·ªùi hi·ªáu qu·∫£. N√™n hi·ªáu qu·∫£ ƒë·∫ßu t∆∞ v·∫´n c√≤n nh·ªè.\nM√¨nh ƒëi·ªÅu ch·ªânh l·∫°i m·ªôt ch√∫t, n·∫øu gi√° tr·ªã histogram gi·∫£m b√© h∆°n 10% so v·ªõi th·ªùi ƒëi·ªÉm cao nh·∫•t ·ªü th·ªùi ƒëi·ªÉm ƒë·ªìi d∆∞∆°ng, m√¨nh s·∫Ω ch·ªët l·ªùi ngay. Ngo√†i ra, ch√∫ng ta s·∫Ω k·∫øt h·ª£p v·ªõi m√¢y Ichimoku ƒë·ªÉ l·ªçc l·∫°i c√°c th·ªùi ƒëi·ªÉm mua cho h·ª£p l√Ω h∆°n.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p l·∫°i ·ªü b√†i ti·∫øp theo.\n","date":"Apr 11, 2022","img":"","permalink":"/courses/stocks/1_macd/","series":["Ch·ª©ng kho√°n cƒÉn b·∫£n"],"tags":["stock"],"title":"Ch·ªâ S·ªë D·ª± B√°o MACD"},{"categories":null,"content":" T·∫°i sao ch√∫ng ta c·∫ßn chu·∫©n h√≥a layer Batch Normalization Batch Normalization ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o Khuy·∫øt ƒëi·ªÉm c·ªßa Batch Normalization Weight Normalization Layer Normalization Instance Normalization Group Normalization Ngu·ªìn tham kh·∫£o T·∫°i sao ch√∫ng ta c·∫ßn chu·∫©n h√≥a layer M√¨nh nghƒ©, c√¢u tr·∫£ l·ªùi th·ªèa ƒë√°ng nh·∫•t l√† b·ªüi v√¨ n√≥ l√†m tƒÉng ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh. Trong qu√° tr√¨nh th·ª±c nghi·ªám, c√°c nh√† nghi√™n c·ª©u nh·∫≠n th·∫•y r·∫±ng vi·ªác th√™m Layer Normalization cho k·∫øt qu·∫£ test t·ªët h∆°n/ ch·∫°y nhanh h∆°n, h·ªôi t·ª• s·ªõm h∆°n \u0026hellip; V√† t·ª´ ƒë√≥, c√°c nh√† nghi√™n c·ª©u ƒë·ªï h·∫øt t√¢m s·ª©c khai ph√°, ƒë√†o b·ªõi n√≥ ra th·ª≠ sai , c·∫£i ti·∫øn, ƒë·ªÅ xu·∫•t c√°c m√¥ h√¨nh chu·∫©n h√≥a li√™n l·ª•c, t·∫°o n√™n c√°c m√¥ h√¨nh m√† m√¨nh s·∫Ω li·ªát k√™ ·ªü d∆∞·ªõi.\nTh·∫≠t ra, m·ªôt √Ω t∆∞·ªüng n√†o hay th√¨ c≈©ng c√≥ nhi·ªÅu nh√† nghi√™n c·ª©u ƒë·ªï h·∫øt t√¢m huy·∫øt v√†o nghi√™n c·ª©u, ƒë√†o s√¢u t·∫≠n c√πng n√≥ ra, ƒë·ªÉ c·ªëng hi·∫øn cho nh√¢n lo·∫°i.\nBatch Normalization ƒê√¢y l√† m·ªôt trong c√°c ph∆∞∆°ng ph√°p chu·∫©n h√≥a l√¢u ƒë·ªùi v√† ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i nh·∫•t. Ngay c·∫£ m√¨nh khi test c√°c data m·ªõi c≈©ng x√†i n√≥ v√¨ s·ª± ti·ªán l·ª£i v√† nhanh ch√≥ng c·ªßa n√≥. C√°c b·∫°n c√≥ th·ªÉ t√¨m ƒë·ªçc paper c√≥ t·ª±a ƒë·ªÅ Batch normalization: Accelerating deep network training by reducing internal covariate shift. Nh·ªØng ph·∫ßn b√™n d∆∞·ªõi, m√¨nh s·∫Ω thay ch·ªØ Batch Normalization th√†nh BN ƒë·ªÉ cho c√¢u ch·ªØ ƒë∆∞·ª£c ng·∫Øng g·ªçn v√† t·∫≠p trung v√†o √Ω ch√≠nh h∆°n.\nBatch Normalization (BN) ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác chu·∫©n h√≥a gi√° tr·ªã input c·ªßa layer b·∫•t k·ª≥. Chu·∫©n h√≥a c√≥ nghƒ©a l√† ƒë∆∞a ph√¢n ph·ªëi c·ªßa layer v·ªÅ x·∫•p x·ªâ ph√¢n ph·ªëi chu·∫©n v·ªõi trung b√¨nh x·∫•p x·ªâ 0 v√† ph∆∞∆°ng sai x·∫•p x·ªâ 1. V·ªÅ m·∫∑c to√°n h·ªçc, Batch Normalization (BN) th·ª±c hi·ªán nh∆∞ sau: v·ªõi m·ªói layer, BN t√≠nh gi√° tr·ªã trung b√¨nh v√† ph∆∞∆°ng sai c·ªßa n√≥. Sau ƒë√≥ s·∫Ω l·∫•y gi√° tr·ªã ƒë·∫∑c tr∆∞ng tr·ª´ gi√° tr·ªã trung b√¨nh , sau ƒë√≥ chia cho ƒë·ªô l·ªách chu·∫©n. Th·ª±c t·∫ø, ch√∫ng ta hay chia t·∫≠p train th√†nh t·ª´ng batch v·ªõi k√≠ch th∆∞·ªõc l√† 16,32,64 ,128 \u0026hellip; h√¨nh, hay c√≤n g·ªçi l√† 1 mini-batch size 16,32,64,128 \u0026hellip;. BN ƒë∆∞·ª£c t√≠nh to√°n tr√™n c√°c mini-batch ƒë√≥.\nC√¥ng th·ª©c t√≠nh trung b√¨nh c·ªßa mini-batch\n$$ \\mu_B \\leftarrow \\frac{1}{m}\\sum^{m}_{i=1}x_i $$\nC√¥ng th·ª©c t√≠nh ph∆∞∆°ng sai c·ªßa mini-batch\n$$ \\sigma^2_\\beta \\leftarrow \\frac{1}{m}\\sum^{m}_{i=1}(x_i-\\mu_B)^2 $$\nChu·∫©n h√≥a\n$$ \\hat{x}_i \\frac{x_i - \\mu_B}{\\sqrt{\\sigma^2_B + \\epsilon}} $$\nPh√≠a tr√™n m√† m√¥ t·∫£ to√°n h·ªçc ph√©p bi·∫øn ƒë·ªïi Batch Normalizing , s·ª≠ d·ª•ng cho h√†m k√≠ch ho·∫°t x tr√™n mini-batch.\nTh·ª±c t·∫ø, ƒë√¥i khi m√¥ h√¨nh l·∫°i ho·∫°t ƒë·ªông hi·ªáu qu·∫£ v·ªõi m·ªôt gi√° tr·ªã trung b√¨nh v√† ph∆∞∆°ng sai kh√°c, n√™n t√°c gi·∫£ th√™m 2 si√™u tham s·ªë l√† gamma - scale v√† beta - shift ƒë·ªÉ c√≥ t√≠nh t·ªïng qu√°t.\n$$ y_i \\leftarrow \\gamma\\hat{x}_i + \\beta $$\nBatch Normalization ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o V·ªÅ m·∫∑c tr·ª±c quan, ch√∫ng ta bi·∫øt r·∫±ng, trong gradient descent, m·∫°ng NN t√≠nh gi√° tr·ªã ƒë·∫°o h√†m v√† gi·∫£m tr·ªçng s·ªë c·ªßa n√≥ d·ª±a v√†o h∆∞·ªõng ƒëi c·ªßa ƒë·∫°o h√†m. Nh∆∞ng do c√°c layer ƒë∆∞·ª£c x·∫øp ch·ªìng l√™n nhau, ph√¢n ph·ªëi c·ªßa d·ªØ li·ªáu ƒë·∫ßu v√†o s·∫Ω b·ªã thay ƒë·ªïi d·∫ßn do vi·ªác c·∫≠p nh·∫≠t tr·ªçng s·ªë c·ªßa c√°c layer tr∆∞·ªõc ƒë√≥, l√†m cho ph√¢n ph·ªëi c·ªßa ƒë·∫ßu v√†o c·ªßa c√°c layer ph√≠a sau s·∫Ω kh√°c xa so v·ªõi ph√¢n ph·ªëi c·ªßa data input. BN gi√∫p c·ªë ƒë·ªãnh ph√¢n ph·ªëi c·ªßa d·ªØ li·ªáu v·ªÅ ph√¢n ph·ªëi chu·∫©n, qua t·∫•t c·∫£ c√°c l·ªõp, d·∫´n t·ªõi t√≠nh ch·∫•t ph√¢n ph·ªëi c·ªßa d·ªØ li·ªáu kh√¥ng thay ƒë·ªïi qua c√°c l·ªõp.\nKhuy·∫øt ƒëi·ªÉm c·ªßa Batch Normalization BN th·ª±c hi·ªán l·∫°i c√°c ph√©p t√≠nh tr√¨nh b√†y ph√≠a tr√™n qua c√°c l·∫ßn l·∫∑p, cho n√™n, v·ªÅ l√Ω thuy·∫øt, ch√∫ng ta c·∫ßn batch size ƒë·ªß l·ªõn ƒë·ªÉ ph√¢n ph·ªëi c·ªßa mini-batch x·∫•p x·ªâ ph√¢n ph·ªëi c·ªßa d·ªØ li·ªáu. ƒêi·ªÅu n√†y g√¢y kh√≥ khƒÉn cho c√°c m√¥ h√¨nh ƒë√≤i h·ªèi ·∫£nh ƒë·∫ßu v√†o c√≥ ch·∫•t l∆∞·ª£ng cao (1920x1080) nh∆∞ object detection, semantic segmentation, \u0026hellip; Vi·ªác hu·∫•n luy·ªán v·ªõi batch size l·ªõn l√†m m√¥ h√¨nh ph·∫£i t√≠nh to√°n nhi·ªÅu v√† ch·∫≠m.\nV·ªõi Batch size = 1, gi√° tr·ªã ph∆∞∆°ng sai s·∫Ω l√† 0. Do ƒë√≥ BN s·∫Ω kh√¥ng ho·∫°t ƒë·ªông hi·ªáu qu·∫£.\nBN kh√¥ng ho·∫°t ƒë·ªông t·ªët v·ªõi RNN. L√Ω do l√† RNN c√≥ c√°c k·∫øt n·ªëi l·∫∑p l·∫°i v·ªõi c√°c timestamps tr∆∞·ªõc ƒë√≥, v√† y√™u c·∫ßu c√°c gi√° tr·ªã beta v√† gamma kh√°c nhau cho m·ªói timestep, d·∫´n ƒë·∫øn ƒë·ªô ph·ª©c t·∫°p tƒÉng l√™n g·∫•p nhi·ªÅu l·∫ßn, v√† g√¢y kh√≥ khƒÉn cho vi·ªác s·ª≠ d·ª•ng BN trong RNN.\nTrong qu√° tr√¨nh test, BN kh√¥ng t√≠nh to√°n l·∫°i gi√° tr·ªã trung b√¨nh v√† ph∆∞∆°ng sai c·ªßa t·∫≠p test. M√† s·ª≠ d·ª•ng gi√° tr·ªã trung b√¨nh v√† ph∆∞∆°ng sai ƒë∆∞·ª£c t√≠nh to√°n t·ª´ t·∫≠p train. ƒêi·ªÅu n√†y l√†m cho vi·ªác t√≠nh to√°n tƒÉng th√™m. ·ªé pytorch, h√†m model.eval() gi√∫p ch√∫ng ta thi·∫øt l·∫≠p m√¥ h√¨nh ·ªü ch·∫ø ƒë·ªô evaluation. ·ªû ch·∫ø ƒë·ªô n√†y, BN layer s·∫Ω s·ª≠ d·ª•ng c√°c gi√° tr·ªã trung b√¨nh v√† ph∆∞∆°ng sai ƒë∆∞·ª£c t√≠nh to√°n t·ª´ tr∆∞·ªõc trong d·ªØ li·ªáu hu·∫•n luy·ªán. Gi√∫p cho ch√∫ng ta kh√¥ng ph·∫£i t√≠nh ƒëi t√≠nh l·∫°i gi√° tr·ªã n√†y.\nWeight Normalization Tham kh·∫£o https://arxiv.org/pdf/1602.07868.pdf Do c√°c b·∫•t l·ª£i c·ªßa BN, T. Saliman v√† P. Kingma ƒë·ªÅ xu·∫•t c√°ch t√≠nh kh√°c, v√† ƒë·∫∑t t√™n l√† Weight Normalization. √ù t∆∞·ªüng c·ªßa t√°c gi·∫£ l√† t√°ch tr·ªçng s·ªë th√†nh 2 th√†nh ph·∫ßn l√† gi√° tr·ªã c·ªßa tr·ªçng s·ªë v√† h∆∞·ªõng c·ªßa tr·ªçng s·ªë. Nh·∫±m m·ª•c ƒë√≠ch tƒÉng t·ªëc t·ªëc ƒë·ªô train.\nT√°c gi·∫£ ƒë·ªÅ xu·∫•t s·ª≠ d·ª•ng hai gi√° tr·ªã g( cho gi√° tr·ªã tr·ªçng s·ªë ) v√† v cho h∆∞·ªõng c·ªßa tr·ªçng s·ªë thay v√¨ s·ª≠ d·ª•ng 1 gi√° tr·ªã w nguy√™n th·ªßy.\n$$ w = \\frac{g}{||v||}v $$\nV·ªõi g l√† gi√° tr·ªã scala, v l√† vector. C√¥ng th·ª©c n√†y nhanh do ch√∫ng ta ƒë√£ fixed ƒë∆∞·ª£c gi√° tr·ªã chu·∫©n c·ªßa w. Do chu·∫©n c·ªßa w l√∫c n√†y b·∫±ng g.\nKh√¥ng gi·ªëng nh∆∞ BN, WN ho·∫°t ƒë·ªông ƒë∆∞·ª£c trong m√¥ h√¨nh RNN. Tuy nhi√™n, v·ªÅ th·ª±c nghi·ªám cho th·∫•y m√¥ h√¨nh v·ªõi WN th∆∞·ªùng kh√¥ng ·ªïn ƒë·ªãnh, n√™n √≠t khi ƒë∆∞·ª£c s·ª≠ d·ª•ng trong th·ª±c t·∫ø\nLayer Normalization Tham kh·∫£o https://arxiv.org/pdf/1607.06450.pdf\nL·∫•y c·∫£m h·ª©ng t·ª´ BN, Geoffrey Hinton v√† c√°c ƒë·ªìng s·ª± ƒë√£ ƒë·ªÅ xu·∫•t Layer Normalization. Ph√©p chu·∫©n h√≥a ƒë∆∞·ª£c s·ª≠ d·ª•ng tr√™n t·ª´ng layer nh∆∞ sau\n$$ \\mu^l =\\frac{1}{H}\\sum^{H}_{i=1}\\alpha^l_i $$\n$$ \\sigma^l = \\sqrt{\\frac{1}{H}\\sum^{H}_{i=1}(\\alpha^l_i-\\mu^l)^2} $$\nV·ªõi H l√† s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ trong m·ªôt hidden layer.\nC√°i kh√°c nhau ch√≠nh gi·ªØa BN v√† LN l√† LN s·ª≠ d·ª•ng chung m·ªôt gi√° tr·ªã trung b√¨nh v√† ph∆∞∆°ng sai trong 1 hidden layer. LN kh√¥ng ph·ª• thu·ªôc v√†o mini-batch, n√™n c√≥ th·ªÉ train ƒë∆∞·ª£c v·ªõi batch-size = 1 m√† kh√¥ng g·∫∑p v·∫•n ƒë·ªÅ g√¨ c·∫£.\nNgo√†i ra LN c≈©ng c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong RNN m√† kh√¥ng g·∫∑p tr·ªü ng·∫°i n√†o nh∆∞ BN.\nInstance Normalization Instance Normalization c√≤n c√≥ t√™n g·ªçi kh√°c l√† contrast normalization\n√ù t∆∞·ªüng ·ªü ƒë√¢y l√† ch√∫ng ta s·∫Ω chu·∫©n ho√° tr√™n t·ª´ng channel c·ªßa t·ª´ng batch.\nGroup Normalization Tham kh·∫£o https://arxiv.org/pdf/1803.08494.pdf\nƒê∆∞·ª£c ƒë·ªÅ xu·∫•t b·ªüi Kaiming He v√† c·ªông s·ª± , Group Normalization c√≥ c√°ch th·ª©c ho·∫°t ƒë·ªông t∆∞∆°ng t·ª± LN, ch·ªâ m·ªôt kh√°c bi·ªát duy nh·∫•t l√† thu·∫≠t to√°n s·∫Ω chia c√°c layer th√†nh t·ª´ng nh√≥m v√† th·ª±c hi·ªán chu·∫©n h√≥a tr√™n c√°c nh√≥m ƒë√≥. Ch√∫ng ta ph·∫£i turning tham s·ªë num_groups ƒë·ªÉ t√¨m s·ªë l∆∞·ª£ng nh√≥m cho k·∫øt qu·∫£ t·ªët nh·∫•t.\nHai c√°i chu·∫©n ho√° cu·ªëi kh√° ƒë∆°n gi·∫£n, m√¨nh kh√¥ng ƒë·ªÅ c·∫≠p chi ti·∫øt nhi·ªÅu. N·∫øu c√≥ b·∫°n n√†o quan t√¢m th√¨ vui l√≤ng ƒë·ªÉ l·∫°i l·ªùi nh·∫Øn, m√¨nh s·∫Ω update th√¥ng tin c√°c b·∫°n c·∫ßn.\nNgu·ªìn ·∫£nh : https://medium.com/syncedreview/facebook-ai-proposes-group-normalization-alternative-to-batch-normalization-fb0699bffae7\nJournalist: Tony Peng| Editor: Michael Sarazen\nNgu·ªìn tham kh·∫£o @inproceedings{ioffe2015batch, title={Batch normalization: Accelerating deep network training by reducing internal covariate shift}, author={Ioffe, Sergey and Szegedy, Christian}, booktitle={International conference on machine learning}, pages={448\u0026ndash;456}, year={2015}, organization={PMLR} }\nhttps://analyticsindiamag.com/understanding-normalization-methods-in-deep-learning/\nhttps://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8\nhttps://towardsdatascience.com/different-normalization-layers-in-deep-learning-1a7214ff71d6\nhttps://arxiv.org/pdf/1602.07868.pdf\nhttps://arxiv.org/pdf/1607.06450.pdf\nhttps://arxiv.org/pdf/1803.08494.pdf\nhttps://medium.com/syncedreview/facebook-ai-proposes-group-normalization-alternative-to-batch-normalization-fb0699bffae7\n","date":"Feb 25, 2022","img":"https://unsplash.it/1920/1080?image=30","permalink":"/blog/2022-02-25-normalization/","series":null,"tags":["Machine Learning","Normalization","Deep Learning"],"title":"C√°c K·ªπ Thu·∫≠t Chu·∫©n H√≥a Trong Deep Learning"},{"categories":"dataset","content":"1. CASIA-WebFace Dataset c√≥ k√≠ch th∆∞·ªõc t·∫ßm 4.1G, bao g·ªìm 494,414 h√¨nh khu√¥n m·∫∑t c·ªßa 10,575 ng∆∞·ªùi th·∫≠t ƒë∆∞·ª£c thu th·∫≠p tr√™n web v√† ƒë√£ g√°n nh√£n ƒë·∫ßy ƒë·ªß. Dataset n√†y ph·ª•c v·ª• cho b√†i to√°n face verification v√† face identification .\nhttps://archive.org/download/NudeNet_classifier_dataset_v1/NudeNet_Classifier_train_data_x320.zip\nƒê·ªëi v·ªõi c√°c b·∫°n mu·ªën m√¨ ƒÉn li·ªÅn, th√¨ c√≥ th·ªÉ t·∫£i pretrain model NudeNet tr√™n pip v·ªÅ r·ªìi th·ª≠.\n2. MS-Celeb-1M T·∫≠p dataset khu√¥n m·∫∑t g·ªëc ƒë∆∞·ª£c microsoft c√¥ng b·ªë nƒÉm 2016 ph·ª•c v·ª• cho b√†i to√°n nh·∫≠n di·ªán khu√¥n m·∫∑t. T·∫≠p n√†y ch·ª©a t·∫ßm 10 tri·ªáu ·∫£nh c·ªßa 100,000 c√° nh√¢n kh√°c nhau, ƒëa s·ªë l√† c√°c di·ªÖn vi√™n Hollywood (n√™n c√≥ th√™m t·ª´ Celeb - vi·∫øt t·∫Øt c·ªßa celebrity).\nNgu·ªìn microsoft.com\nHi·ªán nay dataset n√†y ƒë√£ b·ªã x√≥a b·ªè kh·ªèi website g·ªëc msceleb.org v√† d·ª± √°n n√†y c·ªßa microsoft ƒë√£ b·ªã k·∫øt th√∫c v√¨ m·ªôt l√Ω do n√†o ƒë√≥.\nLink download: https://academictorrents.com/details/9e67eb7cc23c9417f39778a8e06cca5e26196a97\nC√°c b·∫°n c√¢n nh·∫Øc k·ªπ tr∆∞·ªõc khi download. Do kh√¥ng ph·∫£i l√† link ch√≠nh ch·ªß\nM√£ l·ªánh convert tsv file sang h√¨nh ·∫£nh\n1import argparse 2import base64 3import csv 4import os 5# import magic # Detect image type from buffer contents (disabled, all are jpg) 6 7parser = argparse.ArgumentParser() 8parser.add_argument(\u0026#39;--croppedTSV\u0026#39;, type=str) 9parser.add_argument(\u0026#39;--outputDir\u0026#39;, type=str, default=\u0026#39;raw\u0026#39;) 10args = parser.parse_args() 11 12with open(args.croppedTSV, \u0026#39;r\u0026#39;) as tsvF: 13 reader = csv.reader(tsvF, delimiter=\u0026#39;\\t\u0026#39;) 14 i = 0 15 for row in reader: 16 MID, imgSearchRank, faceID, data = row[0], row[1], row[4], base64.b64decode(row[-1]) 17 18 saveDir = os.path.join(args.outputDir, MID) 19 savePath = os.path.join(saveDir, \u0026#34;{}-{}.jpg\u0026#34;.format(imgSearchRank, faceID)) 20 21 # assert(magic.from_buffer(data) == \u0026#39;JPEG image data, JFIF standard 1.01\u0026#39;) 22 23 os.makedirs(saveDir, exist_ok=True) 24 with open(savePath, \u0026#39;wb\u0026#39;) as f: 25 f.write(data) 26 27 i += 1 28 29 if i % 1000 == 0: 30 print(\u0026#34;Extracted {} images.\u0026#34;.format(i)) 31 32# Ngu·ªìn https://github.com/EB-Dodo/C-MS-Celeb/issues/1#issuecomment-844894295 D·ªØ li·ªáu g·ªëc c·ªßa MS-Celeb-1M c√≥ nhi·ªÅu h√¨nh ·∫£nh tr√πng, g√°n sai. C√≥ nhi·ªÅu task ƒë√£ ƒë∆∞·ª£c implement ƒë·ªÉ l√†m s·∫°ch dataset tr√™n. M·ªôt trong nh·ªØng task m√¨nh th·∫•y kh√° ·ªïn l√†\nhttps://github.com/EB-Dodo/C-MS-Celeb\nT√°c gi·∫£ ƒë√£ x·ª≠ l√Ω, r√∫t tr√≠ch, gi·ªØ l·∫°i t·∫ßm 6.5 tri·ªáu h√¨nh c·ªßa 94,682 ng∆∞·ªùi n·ªïi ti·∫øng\n3. VGG Face v√† VGG Face2 Dataset bao g·ªìm 494,414 h√¨nh khu√¥n m·∫∑t c·ªßa 10,575 ng∆∞·ªùi. C√°c b·∫°n c√≥ th·ªÉ download t·∫°i link ch√≠nh ch·ªß\nhttps://www.robots.ox.ac.uk/~vgg/data/vgg_face/vgg_face_dataset.tar.gz\nt·∫≠p VGG Face2 ƒë√£ b·ªã x√≥a tr√™n trang ch·ªß do vi ph·∫°m b·∫£n quy·ªÅn. N√™n hi·ªán th·ªùi kh√¥ng c√≥ link ch√≠nh ch·ªß\n","date":"Feb 25, 2022","img":"","permalink":"/courses/ml_dataset/web_face/","series":["Machine learning dataset"],"tags":["dataset"],"title":"Dataset Nh·∫≠n D·∫°ng Khu√¥ng M·∫∑t"},{"categories":"dataset","content":"C√≥ ƒë√¥i khi, m√¨nh mu·ªën test m·ªôt model n√†o ƒë√≥, nh∆∞ng m√† m√¨nh l·∫°i t·ªën r·∫•t nhi·ªÅu th·ªùi gian ƒë·ªÉ t√¨m ki·∫øm test data. V√¨ v·∫≠y, m√¨nh t·∫°o c√°i tut n√†y ƒë·ªÉ l∆∞u l·∫°i nh·ªØng data m√¨nh l∆∞·ª£m l·∫∑t ƒë∆∞·ª£c, ph·ª•c v·ª• cho vi·ªác t√¨m ki·∫øm sau n√†y d·ªÖ d√†ng h∆°n.\nDataset n√†y cung c·∫•p t·∫ßm 19G h√¨nh ·∫£nh nh·∫°y c·∫£m. Ph·ª•c v·ª• cho c√°c b√†i to√°n ph√¢n lo·∫°i, nh·∫≠n d·∫°ng v√† ki·ªÉm duy·ªát n·ªôi dung h√¨nh ·∫£nh/ video.\nhttps://archive.org/download/NudeNet_classifier_dataset_v1/NudeNet_Classifier_train_data_x320.zip\nƒê·ªëi v·ªõi c√°c b·∫°n mu·ªën m√¨ ƒÉn li·ªÅn, th√¨ c√≥ th·ªÉ t·∫£i pretrain model NudeNet tr√™n pip v·ªÅ r·ªìi th·ª≠.\n","date":"Feb 25, 2022","img":"","permalink":"/courses/ml_dataset/nunet/","series":["Machine learning dataset"],"tags":["dataset"],"title":"NudeNet Dataset [Dataset Nh·∫°y C·∫£m, 18+ Only]"},{"categories":"c++","content":"L·ªãch s·ª≠ h√¨nh th√†nh, ph√°t tri·ªÉn ng√¥n ng·ªØ c++ C++ l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh \u0026ldquo;b·∫≠c trung\u0026rdquo; ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Bjarne Stroustrup v√†o nƒÉm 1979 t·∫°i ph√≤ng th√≠ nghi·ªám Bell Labs. C++ ho·∫°t ƒë·ªông ƒë∆∞·ª£c tr√™n nhi·ªÅu n·ªÅn t·∫£ng kh√°c nhau nh∆∞ Windows, Mac OS, v√† c√°c phi√™n b·∫£n c·ªßa UNIX. Series b√†i h·ªçc n√†y h∆∞·ªõng t·ªõi m·ªôt kh√≥a h·ªçc ƒë∆°n gi·∫£n, v·ªõi ƒë·∫ßy ƒë·ªß c√°c ki·∫øn th·ª©c n·ªÅn t·∫£ng c·ªßa C++ cho ng∆∞·ªùi b·∫Øt ƒë·∫ßu h·ªçc.\nL√Ω do n√™n h·ªçc ng√¥n ng·ªØ C++ C++ l√† m·ªôt trong nh·ªØng ng√¥n ng·ªØ l·∫≠p tr√¨nh ph·ªï bi·∫øn tr√™n th·∫ø gi·ªõi.\nC++ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ph√°t tri·ªÉn nhi·ªÅu ·ª©ng d·ª•ng kh√°c nhau, v√≠ d·ª• nh∆∞ l·∫≠p tr√¨nh game, l·∫≠p tr√¨nh h·ªá ƒëi·ªÅu h√†nh, ph√°t tri·ªÉn c√°c ·ª©ng d·ª•ng nh√∫ng, l√†m website \u0026hellip;\nC++ ph√°t tri·ªÉn ph·∫ßn m·ªÅm ch·∫°y tr√™n nhi·ªÅu n·ªÅn t·∫£ng.\nC++ c√≥ c·ªông ƒë·ªìng developer m·∫°nh m·∫Ω\nC++ ch·∫°y nhanh\nH√†ng t·ª∑ l√Ω do kh√°c n·ªØa, m√¨nh li·ªát k√™ kh√¥ng n·ªïi.\nC ++ l√† m·ªôt ng√¥n ng·ªØ l·∫≠p tr√¨nh tuy·ªát v·ªùi v√† n√≥ gi·∫£i quy·∫øt ƒë∆∞·ª£c nhi·ªÅu nhu c·∫ßu c·ª• th·ªÉ. Ng√¥n ng·ªØ l·∫≠p tr√¨nh n√†y ƒë√£ t·ªìn t·∫°i ƒë∆∞·ª£c g·∫ßn 40 nƒÉm, n√™n h·∫ßu h·∫øt c√°c v·∫•n ƒë·ªÅ trong vi·ªác ph√°t tri·ªÉn ph·∫ßn m·ªÅm c√≥ th·ªÉ ƒë∆∞·ª£c gi·∫£i quy·∫øt b·∫±ng c√°c th∆∞ vi·ªán open-source v√† c√°c frameworks. Hi·ªán nay, ƒëi·ªÉm n·ªïi b·∫≠t c·ªßa C ++ l√† n√≥ ƒë∆∞·ª£c t·∫°o ra ƒë·ªÉ c√≥ t·ªëc ƒë·ªô c·ª±c nhanh, nh∆∞ng n√≥ c≈©ng ph·ª• thu·ªôc v√†o t·ªëc ƒë·ªô ch·∫°y c·ªßa b·ªô x·ª≠ l√Ω. M·ªôt trong nh·ªØng ƒëi·ªÉm n·ªïi b·∫≠t kh√°c l√† C ++ l√† m·ªôt ng√¥n ng·ªØ bi√™n d·ªãch, cho ph√©p n√≥ ƒë∆∞·ª£c th·ª±c thi m·ªôt c√°ch hi·ªáu qu·∫£. ƒêi·ªÅu n√†y l√† do ng√¥n ng·ªØ bi√™n d·ªãch ƒë∆∞·ª£c th·ª±c thi tr·ª±c ti·∫øp, ho√†n to√†n ng∆∞·ª£c l·∫°i v·ªõi m·ªôt ng√¥n ng·ªØ th√¥ng d·ªãch. C ++ d·ªãch t·ª´ m·ªôt ngu·ªìn sang m√£ m√°y, trong khi m·ªôt ng√¥n ng·ªØ th√¥ng d·ªãch nh∆∞ JavaScript ho·∫∑c Python ƒë∆∞·ª£c d·ªãch khi tr√¨nh th√¥ng d·ªãch x·ª≠ l√Ω m√£ ngu·ªìn.\nC ++ cung c·∫•p c√°c c∆° ch·∫ø tr·ª´u t∆∞·ª£ng, cho ph√©p c√°c thu·∫≠t to√°n c√¥ng nghi·ªáp ph·ª©c t·∫°p ƒë∆∞·ª£c ƒë√≥ng g√≥i trong c√°c th∆∞ vi·ªán b·ªï sung, t·ªën √≠t chi ph√≠ h∆°n so v·ªõi vi·ªác ph√°t tri·ªÉn t·ª´ ƒë·∫ßu. C√≥ h√†ng ng√†n th∆∞ vi·ªán nh∆∞ n√†y ƒë√£ ƒë∆∞·ª£c xu·∫•t b·∫£n trong nhi·ªÅu nƒÉm v√† c√°c ·ª©ng d·ª•ng th∆∞·ªùng c√≥ th·ªÉ nhanh ch√≥ng tri·ªÉn khai c√°c thu·∫≠t to√°n ƒëi·ªÅu ch·ªânh n√†y ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c c√°c hi·ªáu qu·∫£ mong mu·ªën v·ªõi hi·ªáu su·∫•t m√°y g·∫ßn nh∆∞ t·ªëi ∆∞u. ƒê√¢y l√† m·ªôt y·∫øu t·ªë ph√°t huy t√°c d·ª•ng l√†m cho vi·ªác ph√°t tri·ªÉn ph·∫ßn m·ªÅm tr√™n C ++ tr·ªü n√™n nhanh ch√≥ng.\nT·ªëc ƒë·ªô c·ªßa C ++ c≈©ng khi·∫øn n√≥ tr·ªü th√†nh s·ª± l·ª±a ch·ªçn tuy·ªát v·ªùi cho c√°c h·ªá th·ªëng nh√∫ng nh∆∞ NASA, robot v√† th·∫≠m ch√≠ l√† c√°c tr√≤ ch∆°i quy m√¥ l·ªõn ƒë∆∞·ª£c x·∫øp h·∫°ng h√†ng ƒë·∫ßu nh∆∞ b·∫°n c√≥, ch·∫≥ng h·∫°n nh∆∞ Assassin\u0026rsquo;s Creed, Battlefield, Call of Duty v√† Doom. V√† n·∫øu b·∫°n nghƒ© v·ªÅ ƒëi·ªÅu ƒë√≥, c√°c tr√≤ ch∆°i n√†y c·∫ßn ph·∫£i v·∫Øt ki·ªát t·ª´ng ph·∫ßn hi·ªáu su·∫•t v√† th·ª±c hi·ªán c√°c ph√©p t√≠nh nhanh v√† t√≠nh to√°n l·∫°i nhanh ch√≥ng, ƒëi·ªÅu m√† C ++ ƒë√£ l√†m cho ƒëi·ªÅu ƒë√≥ x·∫£y ra.\nL√Ω do kh√¥ng n√™n h·ªçc C++ M·∫∑t kh√°c, C ++ l√† m·ªôt ng√¥n ng·ªØ r·∫•t nghi√™m ng·∫∑t, r·∫•t m·∫°nh v√† r·∫•t ph·ª©c t·∫°p. V√† ƒëi·ªÅu n√†y l√†m cho C ++ tr·ªü n√™n c·ª±c k·ª≥ kh√≥ h·ªçc, ngay c·∫£ ƒë·ªëi v·ªõi c√°c nh√† ph√°t tri·ªÉn d√†y d·∫°n kinh nghi·ªám. N·∫øu b·∫°n th·ª±c hi·ªán t√¨m ki·∫øm tr√™n Google cho ‚Äúng√¥n ng·ªØ l·∫≠p tr√¨nh kh√≥ nh·∫•t‚Äù, b·∫°n s·∫Ω nhanh ch√≥ng th·∫•y r·∫±ng C ++ ƒë∆∞·ª£c li·ªát k√™ l√† ·ª©ng c·ª≠ vi√™n h√†ng ƒë·∫ßu.\nTr√™n h·∫øt, C ++ kh√¥ng ph·∫£i l√† l·ª±a ch·ªçn ph√π h·ª£p cho nhi·ªÅu d·ª± √°n v√† ·ª©ng d·ª•ng. N·∫øu b·∫°n ƒëang xem x√©t C ++ ƒë·ªÉ x√¢y d·ª±ng c√°c API web, ·ª©ng d·ª•ng m√°y t√≠nh ƒë·ªÉ b√†n, ·ª©ng d·ª•ng iPhone, v.v., th√¨ C ++ kh√¥ng n√™n l√† l·ª±a ch·ªçn c·ªßa b·∫°n tr·ª´ khi b·∫°n c√≥ k·∫ø ho·∫°ch cho c√°c ·ª©ng d·ª•ng c·ªßa m√¨nh nh·∫≠n ƒë∆∞·ª£c h√†ng trƒÉm ngh√¨n l∆∞·ª£t truy c·∫≠p m·ªói gi√¢y. H·∫ßu h·∫øt c√°c ·ª©ng d·ª•ng kh√¥ng c·∫ßn nh·ªØng m·ª©c tƒÉng hi·ªáu su·∫•t n√†y. M·∫∑c d√π, trong ph·∫ßn tr√™n, t√¥i c≈©ng ƒë√£ n√≥i v·ªÅ vi·ªác C ++ l√† m·ªôt l·ª±a ch·ªçn tuy·ªát v·ªùi cho c√°c h·ªá th·ªëng nh√∫ng, m·ªôt kh√≠a c·∫°nh kh√°c ƒë·ªÉ ph√°t tri·ªÉn nh√∫ng l√† tƒÉng hi·ªáu su·∫•t b·ªô x·ª≠ l√Ω, dung l∆∞·ª£ng b·ªô nh·ªõ kh·∫£ d·ª•ng v√† ti√™u chu·∫©n h√≥a tr√™n n·ªÅn t·∫£ng 32 v√† 64-bit. V√† ƒëi·ªÅu n√†y cho ph√©p c√°c ng√¥n ng·ªØ nh∆∞ Java, Lua v√† Python ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c h·ªá th·ªëng nh√∫ng s√¢u v√† ƒë√¢y l√† nh·ªØng ng√¥n ng·ªØ d·ªÖ s·ª≠ d·ª•ng h∆°n.\nNgay c·∫£ c√°c h·ªá th·ªëng tr√≤ ch∆°i ƒëi·ªán t·ª≠ c≈©ng ph√°t tri·ªÉn nhanh ƒë·∫øn m·ª©c nh·ªØng tr√≤ ch∆°i quy m√¥ l·ªõn n√†y hi·ªán ƒëang s·ª≠ d·ª•ng Unity ho·∫∑c C #. V√¨ v·∫≠y, m·ªçi ng∆∞·ªùi ƒëang ch·ªçn nh·ªØng ng√¥n ng·ªØ n√†y v√¨ ch√∫ng cung c·∫•p kh·∫£ nƒÉng t∆∞∆°ng th√≠ch ƒëa n·ªÅn t·∫£ng gi·ªëng nh∆∞ C ++, nh∆∞ng ch√∫ng d·ªÖ l√†m vi·ªác h∆°n nhi·ªÅu. B·∫°n c√≥ th·ªÉ v√†o c√°c trang t√¨m vi·ªác ·ªü Vi·ªát Nam nh∆∞ ItViec, ho·∫∑c c√°c trang freelacer nh∆∞ Upwork ƒë·ªÉ t√¨m hi·ªÉu s·ªë l∆∞·ª£ng vi·ªác l√†m C++ so v·ªõi python , javascrip , C# ƒë·ªÉ ki·ªÉm ch·ª©ng. T·∫°i th·ªùi ƒëi·ªÉm vi·∫øt b√†i vi·∫øt n√†y, m√¨nh search tr√™n trang itviec v√† v·ªõi t·ª´ kh√≥a .NET, m√¨nh t√¨m th·∫•y 238 jobs , c++ l√† 78 jobs, python l√† 264 jobs, javascrip l√† 484 jobs. C√°c b·∫°n c√≥ th·ªÉ t·ª± ƒë∆∞a ra k·∫øt lu·∫≠n cho ri√™ng m√¨nh d·ª±a v√†o c√°c con s·ªë tr√™n.\nK·∫øt lu·∫≠n M√¨nh hi v·ªçng c√≥ th·ªÉ cung c·∫•p ƒë·ªß th√¥ng tin ƒë·ªÉ gi√∫p b·∫°n quy·∫øt ƒë·ªãnh xem vi·ªác h·ªçc C ++ c√≥ x·ª©ng ƒë√°ng v·ªõi b·∫°n hay kh√¥ng. C ++ l√† m·ªôt trong nh·ªØng ng√¥n ng·ªØ l·∫≠p tr√¨nh h√†ng ƒë·∫ßu, v√¨ v·∫≠y h√£y y√™n t√¢m r·∫±ng ng√¥n ng·ªØ l·∫≠p tr√¨nh n√†y s·∫Ω kh√¥ng bi·∫øn m·∫•t kh·ªèi ng√†nh c√¥ng ngh·ªá. Nh∆∞ng b·∫°n ch·ªâ n√™n h·ªçc C ++ n·∫øu n√≥ ƒë∆∞·ª£c y√™u c·∫ßu trong vai tr√≤ c√¥ng vi·ªác c·ªßa b·∫°n ho·∫∑c trong lƒ©nh v·ª±c m√† n√≥ ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i. Ng∆∞·ª£c l·∫°i, b·∫°n h√£y quay xe ƒë√∫ng l√∫c. M√¨nh s·∫Ω bi√™n so·∫°n th√™m nhi·ªÅu b·ªô gi√°o tr√¨nh h·ªçc c√°c ng√¥n ng·ªØ l·∫≠p tr√¨nh kh√°c n·ªØa. See Ya\n","date":"Feb 20, 2022","img":"","permalink":"/courses/cplusplus/1_introduction/","series":["Kh√≥a h·ªçc c++ cƒÉn b·∫£n"],"tags":["c++"],"title":"B√†i 1: Gi·ªõi Thi·ªáu V·ªÅ C++"},{"categories":"c++","content":"L·ªùi gi·ªõi thi·ªáu Ch√∫ng ta c·∫ßn m·ªôt ph·∫ßn m·ªÅm c√≥ ch·∫•t l∆∞·ª£ng t·ªët t·ªët m·ªôt ch√∫t ƒë·ªÉ h·ªó tr·ª£ coding nhanh, g·ªçn, l·∫π. C√°c b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c ph·∫ßn m·ªÅm mi·ªÖn ph√≠ nh∆∞ Eclipse, NetBean, CodeBlock, Notepad++ \u0026hellip;.\nTrong b√†i vi·∫øt n√†y, m√¨nh ƒë·ªÅ ngh·ªã c√°c b·∫°n c√†i visual studio ho·∫∑c visual studio code. Visual stuido l√† m·ªôt ph·∫ßn kh√° b√° ƒë·∫°o, h·ªó tr·ª£ m·∫°nh m·∫Ω, gi√∫p c√°c b·∫°n l·∫≠p tr√¨nh vi√™n coding m·ªôt c√°ch tho·∫£i m√°i m√† kh√¥ng ph·∫£i v∆∞·ªõng b·∫≠n c√°c v·∫•n ƒë·ªÅ c·∫•u h√¨nh b√™n ngo√†i. N·∫øu c√≥ ƒëi·ªÅu ki·ªán, c√°c b·∫°n n√™n s·ª≠ d·ª•ng phi√™n b·∫£n visual studio enterpise, ƒë∆∞·ª£c m·ªü kh√≥a t·∫•t c·∫£ c√°c t√≠nh nƒÉng gi√∫p ch√∫ng ta ch·ªâ c·∫ßn t·∫≠p trung v√†o coding.\nC√†i ƒë·∫∑t tr√™n Windows T·∫°i th·ªùi ƒëi·ªÉm m√¨nh vi·∫øt b√†i vi·∫øt n√†y, Visual Studio 2022 l√† phi√™n b·∫£n m·ªõi nh·∫•t. C√°c b·∫°n c√≥ th·ªÉ c√†i phi√™n b·∫£n Visual Studio 2019 v·∫´n ƒë∆∞·ª£c. H√£y download b·ªô c√†i visual studio t·∫°i link https://visualstudio.microsoft.com/downloads/ v√† c√†i ƒë·∫∑t b√¨nh th∆∞·ªùng.\nTr√™n MacOS C√†i Visual studio code b·∫£n m·ªõi nh·∫•t t·ª´ trang ch·ªß microsoft\nC√†i extentsion c/c++\nC√†i Clang\nC√¢u l·ªánh ƒë·ªÉ ki·ªÉm tra clang ƒë√£ ƒë∆∞·ª£c c√†i hay ch∆∞a\n1clang --version N·∫øu ch∆∞a , m·ªü terminal l√™n v√† paste ƒëo·∫°n l·ªánh n√†y v√†o ƒë·ªÉ c√†i\n1xcode-select --install Online Compilers Th·ª≠ t∆∞·ªüng t∆∞·ª£ng b·∫°n ƒëang ng·ªìi tr√™n xe bu√Ωt, tr√™n tay c√≥ 1 chi·∫øc ƒëi·ªán tho·∫°i trang b·ªã 4G ƒë·∫ßy ƒë·ªß, b·∫°n c√≥ 1 √Ω t∆∞·ªüng l√≥e l√™n v·ªÅ m·ªôt h√†m n√†o ƒë·∫•y. B·∫°n ph·∫£i l√†m sao ???\nC√°c ƒë∆°n gi·∫£n nh·∫•t l√† truy c·∫≠p v√†o m·ªôt website compiler c++ online, dev ngay c√°i √Ω t∆∞·ªüng c·ªßa b·∫°n v√† ch·∫°y th·ª≠ xem nh∆∞ th·∫ø n√†o. Hi·ªán nay, c√≥ r·∫•t nhi·ªÅu trang web h·ªó tr·ª£ ch√∫ng ta bi√™n d·ªãch m√£ ngu·ªìn c++ online v√† xem k·∫øt qu·∫£ t·ª©c th√¨. Trong b√†i vi·∫øt n√†y, m√¨nh gi·ªõi thi·ªáu c√°c b·∫°n trang http://cpp.sh/. L√Ω do l√† trang n√†y kh√¥ng c√≥ ch·ª©a qu·∫£ng c√°o, nh·ªØng trang kh√°c √≠t nhi·ªÅu c√≥ ch√®n qu·∫£ng c√°o, m√¨nh kh√¥ng th√≠ch.\ntrang web cpp.sh\nTrang n√†y h·ªó tr·ª£ 3 tr√¨nh bi√™n d·ªãch l√† c++98, c++11 v√† c++ 14. Ngo√†i ra, trang web c√≤n h·ªó tr·ª£ ch√∫ng ta sinh ra shot link ƒë·ªÉ g·ª≠i m√£ ngu·ªìn √Ω t∆∞·ªüng c·ªßa ch√∫ng ta cho b·∫°n b√®, kh√° ti·ªán l·ª£i.\n","date":"Feb 20, 2022","img":"","permalink":"/courses/cplusplus/2_ide/","series":["Kh√≥a h·ªçc c++ cƒÉn b·∫£n"],"tags":["c++"],"title":"B√†i 2: C√†i ƒê·∫∑t C√¥ng C·ª• H·ªó Tr·ª£"},{"categories":"c++","content":"Ch∆∞∆°ng tr√¨nh ƒë·∫ßu ti√™n, Hello World M√£ ngu·ªìn\n1#include \u0026lt;iostream\u0026gt; 2using namespace std; 3 4// main() is where program execution begins. 5int main() { 6 cout \u0026lt;\u0026lt; \u0026#34;Hello World. My name AlexBlack.\u0026#34;; // prints Hello World. My name AlexBlack. 7 return 0; 8} C√°c b·∫°n h√£y th·ª±c hi·ªán c√°c b∆∞·ªõc m√¨nh m√¥ t·∫£ k·ªπ ·ªü b√™n d∆∞·ªõi\nM·ªü text editor b·∫•t k·ª≥, v√≠ d·ª• visual studio code.\nT·∫°o 1 file text, ƒë·∫∑t t√™n l√† main.cpp\nCopy ƒëo·∫°n m√£ l·ªánh b√™n d∆∞·ªõi, quƒÉng v√†o file main.cpp v·ª´a t·∫°o\nM·ªü terminal (cmd tr√™n windown), cd v√†o th∆∞ m·ª•c ch∆∞a file main.cpp b·∫°n v·ª´a t·∫°o.\nG√µ \u0026lsquo;g++ hello.cpp\u0026rsquo; v√† ·∫•n n√∫t enter. N·∫øu kh√¥ng c√≥ b·∫•t k·ª≥ l·ªói n√†o x·∫£y ra, sau khi th·ª±c thi xong ƒëo·∫°n l·ªánh tr√™n, ch∆∞∆°ng tr√¨nh s·∫Ω sinh ra 1 file c√≥ t√™n l√† a.out\ng√µ \u0026lsquo;a.out\u0026rsquo; ƒë·ªÉ ch·∫°y ch∆∞∆°ng tr√¨nh\nB·∫°n s·∫Ω nh√¨n th·∫•y d√≤ng ch·ªØ \u0026ldquo;Hello World. My name AlexBlack.\u0026rdquo; tr√™n m√†n h√¨nh terminal c·ªßa b·∫°n\n1g++ main.cpp 2./a.out 3Hello World. My name AlexBlack. Gi·∫£i th√≠ch:\nM·ªôt ch∆∞∆°ng tr√¨nh c++ l√† m·ªôt t·ªï h·ª£p bao g·ªìm nhi·ªÅu c√¢u l·ªánh, m·ªói c√¢u l·ªánh c√≥ nhi·ªám v·ª• v√† ch·ª©c nƒÉng kh√°c nhau, v·ªõi ƒëo·∫°n code helloworld ph√≠a tr√™n, ch∆∞∆°ng tr√¨nh c√≥ ch·ª©a c√°c th√†nh ph·∫ßn.\nD√≤ng ƒë·∫ßu ti√™n, khai b√°o header th∆∞ vi·ªán m√† ch√∫ng ta s·ª≠ d·ª•ng. ·ªû ƒë√¢y, ch√∫ng ta s·ª≠ d·ª•ng th∆∞ vi·ªán iostream. ƒê√¢y l√† th∆∞ vi·ªán c∆° b·∫£n, n·∫±m trong b·ªô th∆∞ vi·ªán chu·∫©n c·ªßa c++.\nD√≤ng ti·∫øp theo using namespace std; b√°o cho tr√¨nh bi√™n d·ªãch bi·∫øt s·ª≠ d·ª•ng namespace std. Kh√°i ni·ªám namespace m√¨nh s·∫Ω ƒë·ªÅ c·∫≠p ·ªü c√°c ch∆∞∆°ng ti·∫øp theo, ƒë·∫øn ch∆∞∆°ng ƒë√≥, c√°c b·∫°n s·∫Ω hi·ªÉu l√Ω do d√πng n√≥, c√≥ n√™n x√≥a n√≥ ƒëi hay kh√¥ng. ·ªû b∆∞·ªõc c∆° b·∫£n n√†y, c√°c b·∫°n ch·ªâ vi·ªác copy ƒëo·∫°n l·ªánh n√†y r·ªìi quƒÉng v√†o x√†i, ƒë·ª´ng th·∫Øc m·∫Øc, ph√¢n t√¢m.\nD√≤ng ti·∫øp theo // main() is where program execution begins. ƒê√¢y l√† ƒëo·∫°n comment 1 d√≤ng trong c++. Tr√¨nh bi√™n d·ªãch g·∫∑p // th√¨ s·∫Ω b·ªè qua, kh√¥ng bi√™n d·ªãch n·ªôi dung ·ªü sau ƒëo·∫°n //. Comment 1 d√≤ng ƒë∆∞·ª£c b·∫Øt ƒë·∫ßu b·ªüi d·∫•u //, v√† k·∫øt th√∫c b·ªüi k√Ω t·ª± xu·ªëng d√≤ng.\nD√≤ng *int main() * l√† t√™n h√†m ch√≠nh. B·∫•t k·ª≥ m·ªôt ch∆∞∆°ng tr√¨nh c++ n√†o, ƒë·ªÅu c√≥ h√†m b·∫Øt ƒë·∫ßu l√† main. Tr√¨nh bi√™n d·ªãch s·∫Ω t√¨m h√†m main ƒë·ªÉ b·∫Øt ƒë·∫ßu ch·∫°y th·ª±c thi.\nD√≤ng cout \u0026laquo; \u0026ldquo;Hello World. My name AlexBlack.\u0026rdquo;; // prints Hello World. My name AlexBlack. in ra d√≤ng ch·ªØ Hello World. My name AlexBlack. l√™n m√†n h√¨nh\nD√≤ng *return 0; * k·∫øt th√∫c ch∆∞∆°ng tr√¨nh, tr·∫£ v·ªÅ gi√° tr·ªã 0 cho ch∆∞∆°ng tr√¨nh cha g·ªçi ch∆∞∆°ng tr√¨nh c·ªßa m√¨nh ƒëang vi·∫øt.\n·ªû ti·∫øng vi·ªát, ch√∫ng ta k·∫øt th√∫c c√¢u b·ªüi d·∫•u \u0026lsquo;ch·∫•m(.)\u0026rsquo;. Ng√¥n ng·ªØ C/C++ k·∫øt th√∫c c√¢u b·ªüi d·∫•u ch·∫•m ph·∫©y \u0026lsquo;;\u0026rsquo;. ·ªû v√≠ d·ª• tr√™n, c√¢u \u0026lsquo;cout \u0026laquo; \u0026ldquo;Hello World. My name AlexBlack.\u0026rdquo;;\u0026rsquo; ƒë∆∞·ª£c k·∫øt th√∫c b·ªüi d·∫•u ch·∫•m ph·∫©y. N·∫øu thi·∫øu d·∫•u ch·∫•m ph·∫©y, tr√¨nh bi√™n d·ªãch s·∫Ω b√°o l·ªói c√∫ ph√°p (c√≥ ƒë·ªÅ c·∫≠p ·ªü m·ª•c l·ªói, b√™n d∆∞·ªõi)\nComment trong c++ C++ h·ªó tr·ª£ hai lo·∫°i comment. Comment m·ªôt d√≤ng v√† comment nhi·ªÅu d√≤ng\nComment m·ªôt d√≤ng, b·∫Øt ƒë·∫ßu b·∫±ng d·∫•u // k·∫øt th√∫c b·∫±ng k√Ω t·ª± xu·ªëng d√≤ng. V√≠ d·ª• nh∆∞ ƒëo·∫°n m√£ l·ªánh hello world ·ªü tr√™n, c√≥ 2 c√°i comment 1 d√≤ng.\nV√≠ d·ª•:\n1tr·ªùi n·∫Øng, ƒë∆∞·ªùng v·∫Øng Comment nhi·ªÅu d√≤ng, b·∫Øt ƒë·∫ßu b·∫±ng d·∫•u /*, k·∫øt th√∫c b·∫±ng ƒë·∫•u */. Khi b·∫°n mu·ªën vi·∫øt 1 ƒëo·∫°n ch√∫ th√≠ch d√†i, n√™u n·ªïi b·∫≠t v·∫•n ƒë·ªÅ ƒëang g·∫∑p ph·∫£i, ho·∫∑c c√°ch x·ª≠ l√Ω hay c·ªßa b·∫°n, ho·∫∑c b·∫•t k·ª≥ v·∫•n ƒë·ªÅ g√¨ m√† b·∫°n mu·ªën note l·∫°i ƒë·ªÉ sau n√†y ƒë·ªçc r√µ h∆°n.\n1/* h√¥m nay tr·ªùi n·∫Øng chang chang 2m√®o con ƒëi h·ªçc ch·∫≥ng mang th·ª© g√¨ */ M·ªôt c√¢u h·ªèi th∆∞·ªùng ƒë∆∞·ª£c ƒë·∫∑t ra l√† c√≥ n√™n comment hay kh√¥ng. Theo √Ω ki·∫øn ri√™ng c·ªßa m√¨nh l√† n√™n. Comment c√†ng nhi·ªÅu c√†ng t·ªët, c√†ng chi ti·∫øt c√†ng t·ªët. T·∫•t nhi√™n l√† ch√∫ng ta ph·∫£i comment tr·ªçng t√¢m c·ªßa v·∫•n ƒë·ªÅ, tr√°nh comment lang mang.\nTh·ª≠ ƒë·∫∑t tr∆∞·ªùng h·ª£p, b·∫°n vi·∫øt 1 h√†m t√¨m ƒëi·ªÉm r∆°i c·ªßa vi√™n bi s·∫Øt c√≥ kh·ªëi l∆∞·ª£ng x khi n√©m b·∫±ng tay ph·∫£i v·ªõi g√≥c n√©m y v√† l·ª±c n√©m z. 1 tu·∫ßn sau b·∫°n ƒë·ªçc l·∫°i ƒëo·∫°n m√£ ngu·ªìn ƒë√≥, b·∫°n t·ª± tin r·∫±ng m√¨nh s·∫Ω hi·ªÉu bao nhi√™u ph·∫ßn?\nErrors and Warnings L·ªói l√† m·ªôt ho·∫°t ƒë·ªông b·∫•t h·ª£p ph√°p ƒë∆∞·ª£c th·ª±c hi·ªán b·ªüi ng∆∞·ªùi d√πng d·∫´n ƒë·∫øn ho·∫°t ƒë·ªông b·∫•t th∆∞·ªùng c·ªßa ch∆∞∆°ng tr√¨nh.\nC√°c l·ªói l·∫≠p tr√¨nh th∆∞·ªùng kh√¥ng b·ªã ph√°t hi·ªán cho ƒë·∫øn khi ch∆∞∆°ng tr√¨nh ƒë∆∞·ª£c bi√™n d·ªãch ho·∫∑c th·ª±c thi. M·ªôt s·ªë l·ªói ngƒÉn c·∫£n ch∆∞∆°ng tr√¨nh ƒë∆∞·ª£c bi√™n d·ªãch ho·∫∑c th·ª±c thi. V√¨ v·∫≠y, c√°c l·ªói c·∫ßn ƒë∆∞·ª£c lo·∫°i b·ªè tr∆∞·ªõc khi bi√™n d·ªãch v√† th·ª±c thi.\nC√°c l·ªói ph·ªï bi·∫øn nh·∫•t c√≥ th·ªÉ ƒë∆∞·ª£c ph√¢n lo·∫°i nh∆∞ sau.\nL·ªói trong C++ Syntax errors Run-time Errors Linker Errors Logical Errors 1. Syntax errors (l·ªói c√∫ ph√°p) L√† l·ªói khi m√¨nh vi ph·∫°m c√°c lu·∫≠t c·ªßa vi·ªác vi·∫øt code c++. C√°c l·ªói d·∫°ng n√†y th∆∞·ªùng ƒë∆∞·ª£c ph√°t hi·ªán b·ªüi tr√¨nh bi√™n d·ªãch, n√™n n√≥ c√≤n c√≥ t√™n g·ªçi kh√°c l√† compile-time errors. Khi g·∫∑p l·ªói n√†y, ch√∫ng ta s·∫Ω kh√¥ng bi√™n d·ªãch th√†nh c√¥ng m√£ ngu·ªìn c·ªßa ch∆∞∆°ng tr√¨nh.\nM·ªôt s·ªë l·ªói c√∫ ph√°p ph·ªï bi·∫øn:\nVi·∫øt thi·∫øu d·∫•u ;\nVi·∫øt thi·∫øu d·∫•u ƒë√≥ng ngo·∫∑c/m·ªü ngo·∫∑c.\nS·ª≠ d·ª•ng bi·∫øn ch∆∞a ƒë∆∞·ª£c khai b√°o.\n1 // C++ program to illustrate syntax error 2 3#include \u0026lt;iostream\u0026gt; 4 5int main() 6{ 7 int x = 10; 8 int y = 15; 9 10 std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x\u0026lt;\u0026lt; z \u0026lt;\u0026lt;std::endl // semicolon missed 11 12 return 0; 13} 14 15//M√£ ngu·ªìn n√†y ƒë∆∞·ª£c vi·∫øt v√† chia s·∫ª b·ªüi Ph·∫°m Duy T√πng. Khi ch·∫°y d√≤ng code l√™n, ta s·∫Ω g·∫∑p th√¥ng b√°o l·ªói:\n1main.cpp:11:41: error: expected \u0026#39;;\u0026#39; after expression 2 std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x\u0026lt;\u0026lt; z \u0026lt;\u0026lt;std::endl // semicolon missed 3 ^ 4 ; 5main.cpp:11:28: error: use of undeclared identifier \u0026#39;z\u0026#39; 6 std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x\u0026lt;\u0026lt; z \u0026lt;\u0026lt;std::endl // semicolon missed 7 ^ 82 errors generated. ƒêo·∫°n b√°o l·ªói tr√™n nh·∫Øc l√† ch√∫ng ta thi·∫øu ƒë·∫•u ; sau bi·ªÉu th∆∞·ªõc ·ªü d√≤ng 11 c·ªôt 41. V√† s·ª≠ d·ª•ng bi·∫øn z ch∆∞a ƒë∆∞·ª£c khai b√°o.\n2. Run-time Errors L·ªói x·∫£y ra trong qu√° tr√¨nh ch·∫°y ch∆∞∆°ng tr√¨nh, khi ch∆∞∆°ng tr√¨nh ƒë√£ build th√†nh c√¥ng. M·ªôt l·ªói ph·ªï bi·∫øn trong nh√≥m l·ªói n√†y l√† l·ªói chia cho 0.\n1// C++ program to illustrate Run-time error 2 3#include \u0026lt;iostream\u0026gt; 4 5int main() 6{ 7 int x = 10; 8 int x = 0; 9 std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt; x/ z \u0026lt;\u0026lt;std::endl; // run-time error 10 11 return 0; 12} 13 14//M√£ ngu·ªìn n√†y ƒë∆∞·ª£c vi·∫øt v√† chia s·∫ª b·ªüi Ph·∫°m Duy T√πng. 3. Linker Errors L·ªói n√†y x·∫£y ra khi ta vi·∫øt ch∆∞∆°ng tr√¨nh c√≥ s·ª≠ d·ª•ng th√™m th∆∞ vi·ªán ngo√†i, ho·∫∑c th∆∞ vi·ªán do ch√≠nh ch√∫ng ta vi·∫øt. Trong qu√° tr√¨nh bi√™n d·ªãch, tr√¨nh bi√™n d·ªãch ƒë√£ bi√™n d·ªãch th√†nh c√¥ng c√°c file, nh∆∞ng kh√¥ng th·ªÉ li√™n k·∫øt c√°c file l·∫°i v·ªõi nhau.\n1// C++ program to illustrate Linker error 2#include \u0026lt;iostream\u0026gt; 3int Main() 4{ 5 return 0; 6} 7 8//M√£ ngu·ªìn n√†y ƒë∆∞·ª£c vi·∫øt v√† chia s·∫ª b·ªüi Ph·∫°m Duy T√πng. Trong C/C++ quy ƒë·ªãnh h√†m main ph·∫£i l√† ch·ªØ main (vi·∫øt th∆∞·ªùng), ·ªü ƒë√¢y ch∆∞∆°ng tr√¨nh kh√¥ng t√¨m ƒë∆∞·ª£c h√†m main ƒë·ªÉ b·∫Øt ƒë·∫ßu th·ª±c thi, n√™n b√°o l·ªói nh∆∞ b√™n d∆∞·ªõi.\n1Undefined symbols for architecture arm64: 2 \u0026#34;_main\u0026#34;, referenced from: 3 implicit entry/start for main executable 4ld: symbol(s) not found for architecture arm64 5clang: error: linker command failed with exit code 1 (use -v to see invocation) 4. Logical Errors L·ªói n√†y x·∫£y ra khi ch√∫ng ta nh·ª° tay g√µ m·ªôt c√°i g√¨ ƒë√≥ sai tr√°i l√†m cho ƒëo·∫°n ch∆∞∆°ng tr√¨nh kh√¥ng l√†m ƒë√∫ng theo logic ƒë√£ ƒë∆∞·ª£c thi·∫øt k·∫ø t·ª´ tr∆∞·ªõc.\n1// C++ program to illustrate Logical error 2#include\u0026lt;iostream\u0026gt; 3using namespace std; 4 5int main(){ 6 // logical error : a semicolon after loop 7 int i=1; 8 while (true); 9 { 10 i++; 11 if(i\u0026gt;10)return i; 12 } 13 14 return 0; 15} 16//M√£ ngu·ªìn n√†y ƒë∆∞·ª£c vi·∫øt v√† chia s·∫ª b·ªüi Ph·∫°m Duy T√πng. V√≠ d·ª• tr√™n, m√¨nh ƒë√£ nh·ª° tay g√µ th√™m k√Ω t·ª± ; sau v√≤ng l·∫∑p while, l√†m ch∆∞∆°ng tr√¨nh l·∫∑p v√¥ t·∫≠n v√† kh√¥ng c√≥ l·ªëi tho√°t.\n1main.cpp:7:17: warning: while loop has empty body [-Wempty-body] 2 while (true); 3 ^ 4main.cpp:7:17: note: put the semicolon on a separate line to silence this warning 51 warning generated. Trong tr∆∞·ªùng h·ª£p m√¨nh m·∫Øc c√°c l·ªói ph·ªï bi·∫øn, tr√¨nh bi√™n d·ªãch c√≥ th·ªÉ ƒë∆∞a ra c·∫£nh b√°o v√† ƒë∆∞a ra nh·∫Øc nh·ªü cho ch√∫ng ta.\nC√¢u l·ªánh v√† h√†m C√¢u l·ªánh C√¢u l·ªánh l√† m·ªôt ph·∫ßn ch∆∞∆°ng tr√¨nh c/c++, ƒë∆∞·ª£c th·ª±c thi m·ªôt c√°ch tu·∫ßn t·ª±.\nV√≠ d·ª•\n1// C++ program to illustrate statement 2#include\u0026lt;iostream\u0026gt; 3using namespace std; 4 5int main(){ 6 // logical error : a semicolon after loop 7 int i=1; // c√¢u l·ªánh khai b√°o declaration statement 8 while (true) //C√¢u l·ªánh ƒëi·ªÅu ki·ªán 9 { 10 i++; //C√¢u l·ªánh bi·ªÉu th·ª©c 11 if(i\u0026gt;10) //C√¢u l·ªánh ƒëi·ªÅu ki·ªán 12 return i; //C√¢u l·ªánh return 13 } 14 15 return 0; //C√¢u l·ªánh return. 16} 17//M√£ ngu·ªìn n√†y ƒë∆∞·ª£c vi·∫øt v√† chia s·∫ª b·ªüi Ph·∫°m Duy T√πng. H√†m H√†m l√† nh√≥m c√°c c√¢u l·ªánh l·∫°i v·ªõi nhau, ƒë·ªÉ th·ª±c hi·ªán m·ªôt nhi·ªám v·ª•. M·ªôt ch∆∞∆°ng tr√¨nh c++ c√≥ √≠t nh·∫•t 1 h√†m main.\nB·∫°n c√≥ th·ªÉ t√πy √Ω t√°ch c√°c ƒëo·∫°n code nh·ªè ra th√†nh nhi·ªÅu h√†m kh√°c nhau. Ph·ª• thu·ªôc v√†o phong c√°ch code c·ªßa b·∫°n. Kh√¥ng ai quy ƒë·ªãnh ph·∫£i t√°ch h√†m nh∆∞ th·∫ø n√†o c·∫£. Th√¥ng th∆∞·ªùng, c√°c l·∫≠p tr√¨nh vi√™n s·∫Ω t√°ch h√†m theo ch·ª©c nƒÉng, c√¥ng d·ª•ng c·ªßa h√†m.\nC·∫•u tr√∫c m·ªôt h√†m bao g·ªìm :\n1return_type function_name( parameter list ){ 2 body ; 3} Trong th∆∞ vi·ªán c++ chu·∫©n c√≥ cung c·∫•p cho ch√∫ng ta kha kh√° c√°c h√†m ƒë∆∞·ª£c x√¢y d·ª±ng s·∫µn, v√≠ d·ª• h√†m l√†m tr√≤n l√™n ceil, h√†m l√†m tr√≤n xu·ªëng floor. C√°c b·∫°n c√≥ tham kh·∫£o trong https://en.cppreference.com/w/cpp/header.\nNh·∫≠p, xu·∫•t d·ªØ li·ªáu Th∆∞ vi·ªán C++ h·ªó tr·ª£ ch√∫ng ta nhi·ªÅu th∆∞ vi·ªán nh·∫≠p xu·∫•t. Trong C++, d·ªØ li·ªáu ƒë∆∞·ª£c th·ª±c hi·ªán l√† m·ªôt chu·ªói tu·∫ßn t·ª± c√°c byte. T·ª´ chuy√™n ng√†nh l√† streams. V√¨ v√¢y, n√™n chia l√†m 2 d·∫°ng.\nInput stream: Chu·ªói c√°c byte ƒë∆∞·ª£c ƒë∆∞a t·ª´ b√™n ngo√†i (b√†n ph√≠m, m·∫°ng lan, file \u0026hellip;) v√†o trong b·ªô nh·ªõ -\u0026gt; g·ªçi l√† chu·ªói d·ªØ li·ªáu nh·∫≠p , hay g·ªçi l√† nh·∫≠p li·ªáu.\nOutput stream: chu·ªói c√°c byte t·ª´ b·ªô nh·ªõ ch√≠nh ƒëi ra (hi·ªÉn th·ªã l√™n m√†n h√¨nh, , qua m·∫°ng lan, ra ƒë√®n led \u0026hellip; ) -\u0026gt; g·ªçi l√† chu·ªói d·ªØ li·ªáu xu·∫•t.\n·ªû ƒë√¢y, m√¨nh s·∫Ω s·ª≠ d·ª•ng iostream c√≥ trong th∆∞ vi·ªán c∆° s·ªü c·ªßa C++ l√†m v√≠ d·ª• minh h·ªça, ngo√†i ra, c++ c√≤n c√≥ iomanip v√† fstream, c√°c b·∫°n c√≥ th·ªÉ t√¨m hi·ªÉu th√™m\n1 2// C++ program to illustrate data stream 3#include\u0026lt;iostream\u0026gt; 4using namespace std; 5 6int main(){ 7 int age; 8 9 cout \u0026lt;\u0026lt; \u0026#34;nhap vao so tuoi cua ban: \u0026#34;; 10 cin \u0026gt;\u0026gt; age; 11 cout \u0026lt;\u0026lt; endl\u0026lt;\u0026lt;\u0026#34;Tuoi cua ban la: \u0026#34; \u0026lt;\u0026lt; age\u0026lt;\u0026lt;endl; 12 13 return 0; 14} 15 16//M√£ ngu·ªìn n√†y ƒë∆∞·ª£c vi·∫øt v√† chia s·∫ª b·ªüi Ph·∫°m Duy T√πng. Trong v√≠ d·ª• tr√™n, m√¨nh s·ª≠ d·ª•ng h√†m nh·∫≠p li·ªáu l√† cin ( ƒë·ªçc l√† xi in), c√≥ s·∫µn trong iostream. H√†m s·∫Ω nh·∫≠n c√°c k√Ω t·ª± m√¨nh g√µ tr√™n b√†n ph√≠m, k·∫øt th√∫c b·ªüi d·∫•u enter ( gi·∫£ s·ª≠ m√¨nh nh·∫≠p s·ªë 5 r·ªìi ·∫•n enter). B·∫£n ch·∫•t b√™n trong l√† c√°c k√Ω t·ª± m√¨nh g√µ tr√™n b√†n ph√≠m s·∫Ω bi·∫øn th√†nh m·ªói chu·ªói tu·∫ßn t·ª± c√°c byte (stream) v√† ƒë·∫©y v√†o trong b·ªô nh·ªõ ram.\nƒê·ªÉ hi·ªÉn th·ªã l√™n m√†n h√¨nh, ch√∫ng ta d√πng h√†m cout ( ƒë·ªçc l√† xi ao). B·∫£n ch·∫•t b√™n trong l√† d·ªØ li·ªáu ch√∫ng ta mu·ªën hi·ªÉn th·ªã l√™n m√†n h√¨nh s·∫Ω m√£ h√≥a th√†nh chu·ªói tu·∫ßn t·ª± byte v√† ƒë·∫©y ra c√°c thi·∫øt b·ªã ngo·∫°i vi.\n1nhap vao so tuoi cua ban: 5 2 3Tuoi cua ban la: 5 Ph√¢n bi·ªát C++ Standard library v√† STL STL v√† C++ Standard library l√† 2 √¥ng kh√°c bi·ªát ho√†n to√†n, ph√¢n bi·ªát nh∆∞ sau.\nC++ Standard library C++ Standard library l√† t·∫≠p c√°c th∆∞ vi·ªán chu·∫©n c·ªßa C Standard Library, ƒë∆∞·ª£c vi·∫øt l·∫°i d∆∞·ªõi d·∫°ng t√™n kh√°c, th√¥ng th∆∞·ªùng l√† b·ªã x√≥a .h ƒëi v√† th√™m ch·ªØ c ·ªü ƒë·∫ßu. V√≠ d·ª• th∆∞ vi·ªán time.h trong c s·∫Ω ƒë∆∞·ª£c x√†o n·∫•u th√†nh ctime\nSTL STL l√† t·ª´ vi·∫øt t·∫Øt c·ªßa Standard Template Library , l√† th∆∞ vi·ªán bao g·ªìm 4 th√†nh ph·∫ßn ch√≠nh l√† algorithms, containers, Numeric, v√† iterators. Gi√∫p tƒÉng s·ª± linh ho·∫°t v√† m·ªÅm d·∫ªo c·ªßa C++. C·ª• th·ªÉ\nContainer Containers - ti·∫øng vi·ªát d·ªãch ra l√† th√πng ch·ª©a, l√† ƒë·ªëi t∆∞·ª£ng d√πng ƒë·ªÉ ch·ª©a c√°c ƒë·ªëi t∆∞·ª£ng kh√°c. Container l∆∞u tr·ªØ v√† qu·∫£n l√Ω c√°c ƒë·ªëi t∆∞·ª£ng, cung c·∫•p c√°c h√†m ƒë·ªÉ truy xu·∫•t ƒë·∫øn c√°c ƒë·ªëi t∆∞·ª£ng.\nContainer ƒë∆∞·ª£c ph√¢n lo·∫°i nh∆∞ sau:\nSequence containers\nvector deque list Associative containers\nset multiset map multimap hash_set hash_map hash_multiset hash_multimap Containers adpators\nStack Queue Priority_queue Ph·ª• thu·ªôc v√†o b√†i to√°n m√† ch√∫ng ta s·∫Ω l·ª±a ch·ªçn container ph√π h·ª£p ƒë·ªÉ ƒë√°p ·ª©ng ƒë·ªô ph·ª©c t·∫°p v√† th·ªùi gian th·ª±c thi. Kh√¥ng n√™n x√†i ƒë·∫°i 1 lo·∫°i container n√†o ƒë√≥.\nIterators Iterators l√† ƒë·ªëi t∆∞·ª£ng gi√∫p l·∫≠p tr√¨nh vi√™n duy·ªát containers. Ch·ªâ c√≥ 2 lo·∫°i nh√≥m container l√† Sequence container v√† Associative container m·ªõi c√≥ iterator\nC√≥ 5 lo·∫°i iterators ƒë∆∞·ª£c h·ªó tr·ª£ trong c++ l√†:\ninput (d√πng ƒë·ªÉ ƒë·ªçc chu·ªói gi√° tr·ªã) output (d√πng ƒë·ªÉ ghi chu·ªói gi√° tr·ªã) forward ( ƒë·ªçc, ghi, di chuy·ªÉn l√™n ƒë·∫øn 1 v√πng kh√°c) bidirectional (ƒë·ªçc, ghi , di chuy·ªÉn l√™n, di chuy·ªÉn xu·ªëng) random access (nh·∫£y t·ª± do ƒë·∫øn 1 b∆∞·ªõc kh√°c) Algorithms Algorithms ch·ª©a t·∫≠p c√°c h√†m gi√∫p x·ª≠ l√Ω nhi·ªÅu ph·∫ßn t·ª≠. V√≠ d·ª• sort d√πng ƒë·ªÉ x·∫Øp x·∫øp c√°c ph·∫ßn t·ª≠ theo th·ª© t·ª±. binary_search gi√∫p t√¨m ki·∫øm d·ªØ li·ªáu d·∫°ng nh·ªã ph√¢n, cho t·ªëc ƒë·ªô t√¨m ki·∫øm cao h∆°n\u0026hellip;.\nNumeric L√† t·∫≠p c√°c th∆∞ vi·ªán h·ªó tr·ª£ l·∫≠p tr√¨nh vi√™n th·ª±c hi·ªán c√°c ph√©p to√°n tr√™n s·ªë. V√≠ d·ª• complex h·ªó tr·ª£ c√°c template v√† c√°c h√†m t√≠nh to√°n s·ªë ph·ª©c.\n","date":"Feb 20, 2022","img":"","permalink":"/courses/cplusplus/3_steep/","series":["Kh√≥a h·ªçc c++ cƒÉn b·∫£n"],"tags":["c++"],"title":"B√†i 3: L√†m Quen V·ªõi C++"},{"categories":null,"content":"Tools sinh m·∫≠t kh·∫©u th√¥ng minh, t·ª± ƒë·ªông, tr√°nh l√†m l·ªô m·∫≠t kh·∫©u\nChi·ªÅu d√†i: Generate Password K√Ω t·ª± th∆∞·ªùng: abcd K√Ω t·ª± hoa: ABCD K√Ω s·ªë: 1234 K√Ω t·ª± ƒë·∫∑c bi·ªát @#$! Pass c·ªßa b·∫°n: copy \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; M·ªôt s·ªë l∆∞u √Ω khi ƒë·∫∑t m·∫≠t kh·∫©u ƒê·ªÉ tr√°nh cho m·∫≠t kh·∫©u b·ªã t·∫•n c√¥ng b·ªüi y·∫øu hacker b·∫±ng k·ªπ thu·∫≠t t·∫•n c√¥ng t·ª´ ƒëi·ªÉn, t·∫•n c√¥ng t·ª´ ƒëi·ªÉn, t·∫•n c√¥ng b·∫±ng social engineering, v√† gi·ªØ cho t√†i kho·∫£ng online c·ªßa b·∫°n ƒë∆∞·ª£c an to√†n, b·∫°n n√™n th·ª±c hi·ªán nh·ªØng ƒëi·ªÅu sau:\nKh√¥ng n√™n s·ª≠ d·ª•ng chung m·∫≠t kh·∫©u, c√¢u h·ªèi b·∫£o m·∫≠t, c√¢u tr·∫£ l·ªùi b·∫£o nh·∫≠t cho c√πng c√°c t√†i kho·∫£ng quang tr·ªçng nh∆∞ ng√¢n h√†ng, email, facebook\u0026hellip; S·ª≠ d·ª•ng m·∫≠t kh·∫©u c√≥ chi·ªÅu d√†i √≠t nh·∫•t l√† 16 k√Ω t·ª±, trong ƒë√≥ √≠t nh·∫•t ph·∫£i ch·ª©a 1 k√Ω s·ªë, 1 k√Ω t·ª± vi·∫øt hoa v√† 1 k√Ω t·ª± ƒë·∫∑c bi·ªát. Kh√¥ng n√™n s·ª≠ d·ª•ng h·ªç/t√™n c·ªßa m√¨nh ho·∫∑c nh·ªØng ng∆∞·ªùi trong gia ƒë√¨nh, t√™n th√∫ c∆∞ng, ng√†y th√°ng nƒÉm sinh c·ªßa m√¨nh/gia ƒë√¨nh m√¨nh ƒë·ªÉ ƒë·∫∑t m·∫≠t kh·∫©u Kh√¥ng n√™n s·ª≠ d·ª•ng m√£ b∆∞u ch√≠nh, s·ªë nh√†, t√™n ƒë∆∞·ªùng, s·ªë ƒëi·ªán tho·∫°i, ng√†y sinh nh·∫≠t, s·ªë ch·ª©ng minh nh√¢n d√¢n / cƒÉn c∆∞·ªõc c√¥ng d√¢n, s·ªë b·∫£o hi·ªÉm x√£ h·ªôi, s·ªë b·∫£o hi·ªÉm y t·∫ø, b·∫•t k·ª≥ s·ªë g√¨ m√† c√≥ th·ªÉ ƒë·ªãnh danh l√† b·∫°n l√†m m·∫≠t kh·∫©u. Kh√¥ng n√™n s·ª≠ d·ª•ng nh·ªØng m·∫≠t kh·∫©u ƒë√£ b·ªã c√¥ng b·ªë t√™n internet l√†m m·∫≠t kh·∫©u. V√≠ d·ª• nh∆∞ 123456, iloveyou, qwerty\u0026hellip; Kh√¥ng n√™n s·ª≠ d·ª•ng m·∫≠t kh·∫©u c√≥ ƒëo·∫°n k√Ω t·ª± tr√πng nhau, v√≠ d·ª• iloveyoupacpac, cualolocua, \u0026hellip; Kh√¥ng n√™n s·ª≠ d·ª•ng nh·ªØng th·ª© c√≥ th·ªÉ b·ªã copy (m√† b·∫°n kh√¥ng th·ªÉ thay ƒë·ªïi) l√†m m·∫≠t kh·∫©u. v√≠ d·ª• nh∆∞ l√† x√°c th·ª±c b·∫±ng v√¢n tay, khu√¥n m·∫∑t (Trong ƒëi·ªÅu ki·ªán b·∫°n mu·ªën an to√†n tuy·ªát ƒë·ªëi, th√¨ kh√¥ng n√™n b·∫≠t x√°c th·ª±c v√¢n tay v√† x√°c th·ª±c khu√¥n m·∫∑t tr√™n iphone , hi hi). Kh√¥ng n√™n cho ph√©p tr√¨nh duy·ªát l∆∞u to√†n b·ªô m·∫≠t kh·∫©u (c√°c tr√¨nh duy·ªát h·ªó tr·ª£ l∆∞u m·∫≠t kh·∫©u nh∆∞ FireFox, Chrome, Safari, Opera, IE, Microsoft Edge ). b·ªüi v√¨ ch√∫ng ta c√≥ th·ªÉ d·ªÖ d√†ng l·∫•y l·∫°i m·∫≠t kh·∫©u t·ª´ tr√¨nh duy·ªát. Kh√¥ng n√™n ƒëƒÉng nh·∫≠p v√†o t√†i kho·∫£ng quang tr·ªçng tr√™n m√°y ng∆∞·ªùi l·∫°. Kh√¥ng n√™n ƒëƒÉng nh·∫≠p v√†o t√†i kho·∫£ng quang tr·ªçng khi s·ª≠ d·ª•ng wifi c√¥ng c·ªông, free VPN, free web proxy, tor\u0026hellip; Kh√¥ng n√™n g·ª≠i c√°c th√¥ng tin quang tr·ªçng qua c√°c giao th·ª©c ch∆∞a ƒë∆∞·ª£c m√£ h√≥a( v√≠ d·ª• HTTP, FTP ), b·ªüi v√¨ c√°c th√¥ng tin ƒë√≥ c√≥ th·ªÉ ƒë∆∞·ª£c ƒë√°nh c·∫Øp m·ªôt c√°ch d·ªÖ d√†ng qua k·ªπ thu·∫≠t sniffed. B·∫°n n√™n s·ª≠ d·ª•ng c√°c giao th·ª©c ƒë√£ ƒë∆∞·ª£c m√£ h√≥a nh∆∞ l√† HTTPS, SFTP, FTPS, SMTPS, IPSec b·∫•t c·ª© khi n√†o c√≥ th·ªÉ. Khi ƒëi du l·ªãch, v√† s·ª≠ d·ª•ng m·∫°ng internet / wifi mi·ªÖn ph√≠, n·∫øu c√≥ th·ªÉ, h√£y m√£ h√≥a th√¥ng tin c·ªßa b·∫°n tr∆∞·ªõc khi g·ª≠i ƒëi. V√≠ d·ª•, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng ph·∫ßn m·ªÅm h·ªó tr·ª£ t·∫°o VPN c√° nh√¢n h·ªó tr·ª£ giao th·ª©c WireGuard( ho·∫∑c IKEv2, OpenVPN, SSTP, L2TP over IPSec ) v√†o server c√° nh√¢n c·ªßa b·∫°n( m√°y t√≠nh ·ªü nh√†, server b·∫°n d·ª±ng tr√™n AWS, VPS\u0026hellip;). Ho·∫∑c b·∫°n c√≥ th·ªÉ thi·∫øt l·∫≠p m√£ h√≥a k·∫øt n·ªëi SSH gi·ªØa m√°y b·∫°n v√† server c·ªßa b·∫°n, v√† sau ƒë√≥ c·∫•u h√¨nh cho Chrome ho·∫∑c FireFox s·ª≠ d·ª•ng socks proxy c·ªßa b·∫°n. Do ƒë√≥, ngay c·∫£ khi ng∆∞·ªùi x·∫•u ƒë√£ sniff ƒë∆∞·ª£c m·∫£nh d·ªØ li·ªáu th√¥ng tin c·ªßa b·∫°n, h·ªç c≈©ng kh√¥ng th·ªÉ xem ƒë∆∞·ª£c n√≥, b·ªüi v√¨ d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c m√£ h√≥a. Th√¥ng th∆∞·ªùng, ng∆∞·ªùi d√πng s·∫Ω r·∫•t t·ª± tin r·∫±ng m·∫≠t kh·∫©u h·ªç ƒë·∫∑t r·∫•t m·∫°nh v√† kh√≥ b·ªã hack. Nh∆∞ng trong th·ª±c t·∫ø, kh√¥ng c√≥ g√¨ c√≥ th·ªÉ b·∫£o ƒë·∫£m ƒë∆∞·ª£c ƒëi·ªÅu ƒë√≥. M·ªôt trong nh·ªØng c√°ch c√≥ th·ªÉ ki·ªÉm tra l√† b·∫°n s·ª≠ d·ª•ng m·ªôt ch∆∞∆°ng tr√¨nh hash md5 m·∫≠t kh·∫©u c·ªßa b·∫°n l·∫°i, ki·ªÉm tra tr√™n c√°c tr·∫°ng MD5 decryption website, v√† ki·ªÉm tra xem ƒëo·∫°n md5 c·ªßa b·∫°n s·∫Ω b·ªã crack trong v√≤ng bao l√¢u. Khuy·∫øn c√°o l√† n√™n ƒë·ªïi m·∫≠t kh·∫©u m·ªói 10 tu·∫ßn 1 l·∫ßn, ƒë·ªëi v·ªõi c√°c t√†i kho·∫£ng quang tr·ªçng. M·ªôt s·ªë t·ªï ch·ª©c ng√¢n h√†ng nh∆∞ techcombank ·ªü Vi·ªát Nam c√≥ th·ª±c hi·ªán theo khuy·∫øn ngh·ªã n√†y, nh∆∞ng v·ªõi s·ªë tu·∫ßn d√†i h∆°n. Th√¥ng th∆∞·ªùng, ch√∫ng ta kh√¥ng th·ªÉ nh·ªõ h·∫øt t·∫•t c·∫£ to√†n b·ªô m·∫≠t kh·∫©u c·ªßa ch√∫ng ta d√£ ƒë·∫∑t ra. V√¨ v·∫≠y, c√≥ m·ªôt c√°ch kh√°c ƒë·ªÉ th·ª±c hi·ªán l√† ch·ªâ nh·ªõ m·∫≠t kh·∫©u c·ªßa nh·ªØng t√†i kho·∫£ng quang tr·ªçng. ƒê·ªëi v·ªõi nh·ªØng t√†i kho·∫£ng √≠t quang tr·ªçng h∆°n, ch√∫ng ta c√≥ th·ªÉ l∆∞u d∆∞·ªõi d·∫°ng text file v√† m√£ h√≥a file text n√†y b·∫±ng c√°c ph·∫ßn m·ªÅm nh∆∞ 7-zip, GPG ho·∫∑c BitLocker. N√™n sao l∆∞u b·∫£n m√£ h√≥a file text m·∫≠t kh·∫©u ·ªü m·ªôt v√†i n∆°i, v√≠ d·ª• ƒë·∫©y l√™n email, l∆∞u ·ªü ·ªï ph·ª•. ƒê·ªÉ nh·ª° xui r·ªßi, v√¨ m·ªôt l√Ω do n√†o ƒë√≥, b·∫°n kh√¥ng th·ªÉ truy xu·∫•t v√†o m√°y t√≠nh c·ªßa b·∫°n v√† l·∫•y l·∫°i m·∫≠t kh·∫©u. Th√¨ b·∫°n c√≥ th·ªÉ d·ªÖ d√†ng xem v√† l·∫•y l·∫°i m·∫≠t kh·∫©u c·ªßa nh·ªØng t√†i kho·∫£ng kh√°c. B·∫≠t x√°c minh hai b∆∞·ªõc b·∫•t c·ª© khi n√†o c√≥ th·ªÉ. Kh√¥ng n√™n l∆∞u m·∫≠t kh·∫©u quang tr·ªçng tr√™n m√¢y Truy c·∫≠p nh·ªØng trang web quan tr·ªçng nh∆∞ paypal, ng√¢n h√†ng, mail\u0026hellip; t·ª´ bookmark. N·∫øu truy c·∫≠p t·ª´ link l·∫°i, n√™n check k·ªπ domain xem ƒë√£ ch√≠nh x√°c hay ch∆∞a. M·ªôt m·∫πo nh·ªè l√† ch√∫ng ta c√≥ th·ªÉ ki·ªÉm tra ƒë·ªô ph·ªï bi·∫øn c·ªßa website b·∫±ng c√¥ng c·ª• Alexa toolbar ƒë·ªÉ ch·∫Øc ch·∫Øn r·∫±ng domail b·∫°n ƒëang truy c·∫≠p kh√¥ng ph·∫£i l√† h√†ng gi·∫£ B·∫£o v·ªá m√°y t√≠nh b·∫°n b·∫±ng t∆∞·ªùng l·ª≠a v√† ch∆∞∆°ng tr√¨nh di·ªát virus. Ch·∫∑n t·∫•t c·∫£ c√°c k·∫øt n·ªëi v√†o v√† t·∫•t c·∫£ c√°c k·∫øt n·ªëi ra kh√¥ng c·∫ßn thi·∫øt b·∫±ng t∆∞·ªùng l·ª≠a. T·∫£i c√°c ph·∫ßn m·ªÅm t·ª´ c√°c site ch√≠nh th·ªëng. Check m√£ MD5 / SHA1 / SHA256 checksum ho·∫∑c GPG signature c·ªßa ph·∫ßn m·ªÅm n·∫øu c√≥ th·ªÉ. C·∫≠p nh·∫≠t h·ªá ƒëi·ªÅu h√†nh, c√°c ph·∫ßn m·ªÅm duy·ªát web trong m√°y t√≠nh c·ªßa b·∫°n l√™n phi√™n b·∫£n m·ªõi nh·∫•t ƒë·ªÉ fix c√°c l·ªói b·∫£o m·∫≠t N·∫øu trong m√°y c·ªßa b·∫°n c√≥ l∆∞u nh·ªØng file c·ª±c k·ª≥ quang tr·ªçng, v√≠ d·ª• nh∆∞ b·∫£ng l∆∞∆°ng c·ªßa c√¥ng ty, tin nh·∫Øn private v·ªõi tr√† xanh \u0026hellip; , th√¨ n√£y ki·ªÉm tra k·ªπ xem trong m√°y c√≥ ch·ª©a ph·∫ßn m·ªÅm keyloggers, ho·∫∑c ph·∫ßn c·ª©ng keyloggers( vd wireless keyboard sniffer ), ho·∫∑c camera ·∫©n. Nh·ªØng th·ª© v√≠ d·ª• ·ªü tr√™n l√† m·ªôt m·ªëi nguy h·∫°i r·∫•t l·ªõn. B·∫≠t t√≠nh nƒÉng kh√≥a m√†n h√¨nh m√°y t√≠nh / m√°y t√≠nh b·∫£ng/ ƒëi·ªán tho·∫°i ngay khi b·∫°n kh√¥ng s·ª≠ d·ª•ng ch√∫ng M√£ h√≥a to√†n b·ªô ·ªï ƒëƒ©a c·ª©ng b·∫±ng c√°c ph·∫ßn m·ªÅm m√£ h√≥a nh∆∞ VeraCrypt, FileVault, LUKS, \u0026hellip; ƒë·ªÉ b·∫£o v·ªá c√°c file quan tr·ªçng trong m√°y. H√£y h·ªßy v·∫≠t l√Ω ·ªï c·ª©ng c≈© c√≥ ch·ª©a th√¥ng tin quan tr·ªçng c·ªßa b·∫°n (thay v√¨ n√©m v√†o s·ªçt r√°c, b√°n ve chai) N·∫øu ƒë∆∞·ª£c, h√£y d√πng √≠t nh·∫•t 3 email ƒë·ªÉ nh·∫≠n mail. M·ªôt mail ƒë·ªÉ nh·∫≠n c√°c th√¥ng tin quang tr·ªçng t·ª´ ng√¢n h√†ng, paypal ho·∫∑c nh·ªØng g√¨ c√≥ y·∫øu t·ªë ·∫£nh h∆∞·ªüng ƒë·∫øn t√∫i ti·ªÅn c·ªßa b·∫°n. Mail th·ª© hai d√πng ƒë·ªÉ x√°c th·ª±c/ nh·∫≠n mail t·ª´ nh·ªØng site kh√¥ng quan tr·ªçng. Mail th·ª© 3 nh·∫≠n pasword - reset mail khi mail s·ªë 1 b·ªã hack. M·ªôt l∆∞u √Ω l√† mail th·ª© 3 n√™n d√πng m·ªôt n·ªÅn t·∫£ng mail kh√°c mail 1. V√≠ d·ª• mail 1 d√πng gmail th√¨ mail 3 d√πng outlook. N·∫øu ƒë∆∞·ª£c, h√£y s·ª≠ d·ª•ng √≠t nh·∫•t 2 s·ªë ƒëi·ªán tho·∫°i. S·ªë ƒëi·ªán tho·∫°i ƒë·∫ßu ti√™n ƒë·ªÉ x√°c th·ª±c 2 b∆∞·ªõc v·ªõi c√°c site quang tr·ªçng nh∆∞ ng√¢n h√†ng. Kh√¥ng cho gia ƒë√¨nh, ng∆∞·ªùi th√¢n, b·∫°n b√®, ƒë·ªìng nghi·ªáp bi·∫øt s·ªë ƒëi·ªán tho·∫°i s·ªë 1. S·ªë ƒëi·ªán tho·∫°i 2 l√† s·ªë ƒëi·ªán tho·∫°i public, cho b·∫°n b√® ng∆∞·ªùi th√¢n li√™n l·∫°c, ƒëƒÉng k√Ω c√°c app/ web √≠t quang tr·ªçng h∆°n, vd l√† s·ªë ƒëi·ªán tho·∫°i ƒë·∫∑t h√†ng tiki, shopee, b√°ch h√≥a xanh, ƒëi·ªán m√°y xanh, mua tr√† s·ª≠a, t√°n anh h√†ng x√≥m\u0026hellip;. ƒê·ª´ng click v√†o link trong email/SMS, h√£y ki·ªÉm tra ƒë∆∞·ªùng d·∫´n th·∫≠t k·ªπ, v√† copy paste v√†o new tab n·∫øu link ch√≠nh x√°c, kh√¥ng ph·∫£i gi·∫£ m·∫°o. N·∫øu b·∫°n x√°c ƒë·ªãnh n√≥ gi·∫£ m·∫°o, n√£y x√≥a n√≥ ƒëi, ho·∫∑c ƒë√°nh d·∫•u spam r·ªìi x√≥a n√≥ ƒëi. Kh√¥ng g·ª≠i m·∫≠t kh·∫©u c·ªßa b·∫°n cho ng∆∞·ªùi kh√°c qua email. C·∫©n th·∫≠n v·ªõi c√°c ch∆∞∆°ng tr√¨nh online paste tools v√† ch∆∞∆°ng tr√¨nh ch·ª•p ·∫£nh m√†n h√¨nh download ·ªü tr√™n m·∫°ng. N·∫øu b·∫°n dev web, h√£y l√†m c√≥ t√¢m m·ªôt ch√∫t, ƒë·ª´ng l∆∞u m·∫≠t kh·∫©u c·ªßa ng∆∞·ªùi d√πng d·∫°ng plain text v√†o database. B·∫°n n√™n l∆∞u b·∫£n m√£ h√≥a SHA1, SHA256 ho·∫∑c SHA512, k√®m th√™m m·ªôt ch√∫t mu·ªëi, ti√™u, ƒë·ªÉ b·∫£o v·ªá ng∆∞·ªùi d√πng. M·ªôt √Ω t∆∞·ªüng hay l√† l∆∞u th√™m m√£ hash ƒë·ªãnh danh thi·∫øt b·ªã ng∆∞·ªùi d√πng ƒëang s·ª≠ d·ª•ng (vd h·ªá ƒëi·ªÅu h√†nh, k√≠ch th∆∞·ªõc m√†n h√¨nh, s·ªë cpu/ram \u0026hellip;). Khi ng∆∞·ªùi d√πng ƒëƒÉng nh·∫≠p sai m·∫≠t kh·∫©u, v√† thi·∫øt b·ªã ng∆∞·ªùi d√πng s·ª≠ d·ª•ng kh√¥ng gi·ªëng v·ªõi thi·∫øt b·ªã ƒë√£ s·ª≠ d·ª•ng tr∆∞·ªõc ƒë√≥. Th√¨ h√£y b·∫≠t x√°c th·ª±c 2 b∆∞·ªõc qua s·ªë ƒëi·ªán tho·∫°i/ email sau khi ng∆∞·ªùi d√πng ƒë√£ ƒëƒÉng nh·∫≠p ƒë∆∞·ª£c. N·∫øu b·∫°n l√† nh√† ph√°t tri·ªÉn ph·∫ßn m·ªÅm, h√£y c·ªë g·∫Øng cung c·∫•p m√£ private key s·ª≠ d·ª•ng GnuPG ho·∫∑c SHA-256 file ·ª©ng d·ª•ng c·ªßa b·∫°n ƒë·ªÉ ng∆∞·ªùi d√πng c√≥ th·ªÉ ki·ªÉm tra xem file ƒë√£ b·ªã ch·ªânh s·ª≠a hay ch∆∞a. N·∫øu b·∫°n kinh doanh online, h√£y ƒëƒÉng k√Ω m·ªôt domain, thi·∫øt l·∫≠p t√†i kho·∫£ng email t∆∞∆°ng ·ª©ng v·ªõi domain. ƒêi·ªÅu n√†y l√† c·∫ßn thi·∫øt b·ªüi v√¨ b·∫°n s·∫Ω kh√¥ng ƒë√°nh m·∫•t c√°c th√¥ng tin li√™n l·∫°c, v√† t√†i kho·∫£ng email c·ªßa b·∫°n s·∫Ω kh√¥ng b·ªã nh√† cung c·∫•p n√†o c√≥ th·ªÉ x√≥a ƒëi c·∫£. ","date":"Feb 20, 2022","img":"","permalink":"/utils/gen_paswords/","series":null,"tags":["password","random password","password generator"],"title":"Ch∆∞∆°ng Tr√¨nh Sinh Pasword Ng·∫´u Nhi√™n"},{"categories":"python","content":"N·ªôi dung kh√≥a h·ªçc B√†i 1: Gi·ªõi thi·ªáu v·ªÅ C++\nT·ªïng quan ng√¥n ng·ªØ C++ T·∫°i sao n√™n h·ªçc ng√¥n ng·ªØ C++ B√†i 2: C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng ph√°t tri·ªÉn (IDE) Visual studio 2015\nGi·ªõi thi·ªáu Microsoft Visual Studio H∆∞·ªõng d·∫´n download v√† c√†i ƒë·∫∑t visual studio B√†i 3: X√¢y d·ª±ng ch∆∞∆°ng tr√¨nh C++ ƒë·∫ßu ti√™n v·ªõi Visual Studio 2015\nM·ªôt s·ªë ki·∫øn th·ª©c c·∫ßn l∆∞u √Ω C√°ch t·∫°o v√† bi√™n d·ªãch ch∆∞∆°ng tr√¨nh C++ ƒë·∫ßu ti√™n tr√™n Visual Studio M·ªôt s·ªë v·∫•n ƒë·ªÅ th∆∞·ªùng g·∫∑p ƒë·ªëi v·ªõi l·∫≠p tr√¨nh vi√™n m·ªõi B√†i 4: C·∫•u tr√∫c m·ªôt ch∆∞∆°ng tr√¨nh C++ (Structure of a program)\nC·∫•u tr√∫c c·ªßa m·ªôt ch∆∞∆°ng tr√¨nh C++ C√∫ ph√°p v√† l·ªói c√∫ ph√°p trong C++ (Syntax and syntax errors) B√†i 5: Ghi ch√∫ trong C++ (Comments in C++)\nC√∫ ph√°p comment trong C++ M·ªôt s·ªë kinh nghi·ªám khi comment trong l·∫≠p tr√¨nh B√†i 6: Bi·∫øn trong C++ (Variables in C++)\nBi·∫øn trong C++ Kh·ªüi t·∫°o bi·∫øn trong C++ (Defining a variable) ƒê·ªãnh nghƒ©a bi·∫øn ·ªü ƒë√¢u (Where to define variables) B√†i 7: S·ªë t·ª± nhi√™n v√† S·ªë ch·∫•m ƒë·ªông trong C++ (Integer, Floating point)\nT·ªïng quan v·ªÅ ki·ªÉu d·ªØ li·ªáu c∆° b·∫£n trong C++ Ki·ªÉu s·ªë nguy√™n (Integer) S·ªë ch·∫•m ƒë·ªông (Floating point numbers) B√†i 8: Ki·ªÉu k√Ω t·ª± trong C++ (Character)\nT·ªïng quan v·ªÅ ki·ªÉu k√Ω t·ª± (Character) Khai b√°o, kh·ªüi t·∫°o v√† g√°n gi√° tr·ªã m·ªôt bi·∫øn k√Ω t·ª± In k√Ω t·ª± ra m√†n h√¨nh In k√Ω t·ª± t·ª´ s·ªë nguy√™n v√† ng∆∞·ª£c l·∫°i (Casting) Escape sequences Newline ‚Äò\\n‚Äô v√† std::endl D·∫•u nh√°y ƒë∆°n ‚ÄòK‚Äô v√† d·∫•u nh√°y k√©p ‚ÄúKteam‚Äù B√†i 9: Ki·ªÉu lu·∫≠n l√Ω v√† c∆° b·∫£n v·ªÅ C√¢u ƒëi·ªÅu ki·ªán If (Boolean and If statements)\nT·ªïng quan v·ªÅ ki·ªÉu lu·∫≠n l√Ω (Boolean) C∆° b·∫£n v·ªÅ c√¢u ƒëi·ªÅu ki·ªán If v√† Boolean B√†i 10: Nh·∫≠p, Xu·∫•t v√† ƒê·ªãnh d·∫°ng d·ªØ li·ªáu trong C++ (Input and Output)\nXu·∫•t d·ªØ li·ªáu v·ªõi std::cout trong C++ Nh·∫≠p d·ªØ li·ªáu v·ªõi std::cin trong C++ ƒê·ªãnh d·∫°ng d·ªØ li·ªáu nh·∫≠p xu·∫•t trong C++ B√†i 11: H·∫±ng s·ªë trong C++ (Constants)\nT·ªïng quan h·∫±ng s·ªë (Constants) H·∫±ng s·ªë v·ªõi t·ª´ kh√≥a const H·∫±ng s·ªë v·ªõi ch·ªâ th·ªã ti·ªÅn x·ª≠ l√Ω #define N√™n ƒë·ªãnh nghƒ©a h·∫±ng s·ªë ·ªü ƒë√¢u B√†i 12: To√°n t·ª≠ s·ªë h·ªçc, to√°n t·ª≠ tƒÉng gi·∫£m, to√°n t·ª≠ g√°n s·ªë h·ªçc trong C++ (Operators)\nT·ªïng quan v·ªÅ to√°n t·ª≠ To√°n t·ª≠ s·ªë h·ªçc trong C++ (Arithmetic operators) To√°n t·ª≠ g√°n s·ªë h·ªçc trong C++ (Arithmetic assignment operators) B√†i 13: To√°n t·ª≠ quan h·ªá, logic, bitwise, misc v√† ƒë·ªô ∆∞u ti√™n to√°n t·ª≠ trong C++\nTo√°n t·ª≠ quan h·ªá trong C++ (Relational operators) To√°n t·ª≠ logic trong C++ (Logical operators) To√°n t·ª≠ tr√™n bit trong C++ (Bitwise operators) C√°c to√°n t·ª≠ h·ªón h·ª£p trong C++ (Misc Operators) ƒê·ªô ∆∞u ti√™n v√† quy t·∫Øc k·∫øt h·ª£p to√°n t·ª≠ trong C++ B√†i 14: C∆° b·∫£n v·ªÅ chu·ªói k√Ω t·ª± trong C++ (An introduction to std::string)\nT·ªïng quan v·ªÅ chu·ªói k√Ω t·ª± (std::string) Khai b√°o, kh·ªüi t·∫°o v√† g√°n gi√° tr·ªã m·ªôt chu·ªói k√Ω t·ª± Xu·∫•t m·ªôt chu·ªói k√Ω t·ª± (string output): Nh·∫≠p m·ªôt chu·ªói k√Ω t·ª± (string input) M·ªôt s·ªë thao t√°c c∆° b·∫£n v·ªõi chu·ªói k√Ω t·ª± B√†i 15: Bi·∫øn c·ª•c b·ªô trong C++ (Local variables in C++)\nT·ªïng quan v·ªÅ t·∫ßm v·ª±c c·ªßa bi·∫øn Bi·∫øn c·ª•c b·ªô (Local variables) B√†i 16: Bi·∫øn to√†n c·ª•c trong C++ (Global variables in C++)\nT·ªïng quan v·ªÅ t·∫ßm v·ª±c c·ªßa bi·∫øn Bi·∫øn to√†n c·ª•c (Global variables) S·ª≠ d·ª•ng bi·∫øn to√†n c·ª•c l√† nguy hi·ªÉm Khi n√†o c·∫ßn s·ª≠ d·ª•ng bi·∫øn to√†n c·ª•c (non-const) B√†i 17: Bi·∫øn tƒ©nh trong C++ (Static variables in C++)\nT·ªïng quan v·ªÅ bi·∫øn tƒ©nh (static variables) Khi n√†o n√™n s·ª≠ d·ª•ng bi·∫øn tƒ©nh B√†i 18: √âp ki·ªÉu ng·∫ßm ƒë·ªãnh trong C++ (Implicit type conversion in C++)\nT·ªïng quan v·ªÅ √©p ki·ªÉu d·ªØ li·ªáu √âp ki·ªÉu ng·∫ßm ƒë·ªãnh trong C++ (Implicit type conversion) B√†i 19: √âp ki·ªÉu t∆∞·ªùng minh trong C++ (Explicit type conversion in C++)\n√âp ki·ªÉu t∆∞·ªùng minh trong C++ (Explicit type conversion) B√†i 20: C∆° b·∫£n v·ªÅ H√†m v√† Gi√° tr·ªã tr·∫£ v·ªÅ (Basic of functions and return values)\nT·ªïng quan v·ªÅ h√†m (functions overview) Gi√° tr·ªã tr·∫£ v·ªÅ (return values) Gi√° tr·ªã tr·∫£ v·ªÅ c·ªßa ki·ªÉu void (return values of type void) B√†i 21: Truy·ªÅn Gi√° Tr·ªã cho H√†m (Passing Arguments by Value)\nTham s·ªë v√† ƒë·ªëi s·ªë c·ªßa h√†m (Function parameters and arguments) Truy·ªÅn gi√° tr·ªã cho h√†m (Passing arguments by value) T·ªïng k·∫øt v·ªÅ ph∆∞∆°ng ph√°p truy·ªÅn gi√° tr·ªã cho h√†m (Passing argument by value) B√†i 22: Truy·ªÅn Tham Chi·∫øu cho H√†m (Passing Arguments by Reference)\nTruy·ªÅn tham chi·∫øu cho h√†m (Passing arguments by reference) Truy·ªÅn tham chi·∫øu h·∫±ng (Pass by const reference) T·ªïng k·∫øt v·ªÅ ph∆∞∆°ng ph√°p truy·ªÅn tham chi·∫øu cho h√†m (Passing arguments by reference) B√†i 23: Ti·ªÅn khai b√°o v√† ƒê·ªãnh nghƒ©a H√†m (Forward declarations and Definitions of Functions)\nL·ªói ‚Äúidentifier not found‚Äù Ti·ªÅn khai b√°o v√† nguy√™n m·∫´u h√†m (Forward declaration and function prototypes) Khai b√°o v√† ƒë·ªãnh nghƒ©a trong C++ (Declarations and definitions in C++) B√†i 24: Gi·ªõi thi·ªáu v·ªÅ c·∫•u tr√∫c ƒëi·ªÅu khi·ªÉn (Control flow introduction)\nT·ªïng quan v·ªÅ c·∫•u tr√∫c ƒëi·ªÅu khi·ªÉn trong C++ C√¢u l·ªánh d·ª´ng (halt) C√¢u l·ªánh nh·∫£y (Jumps) C·∫•u tr√∫c r·∫Ω nh√°nh c√≥ ƒëi·ªÅu ki·ªán (Conditional branches) C·∫•u tr√∫c v√≤ng l·∫∑p (Loops) X·ª≠ l√Ω ngo·∫°i l·ªá (Exceptions handling) B√†i 25: C√¢u ƒëi·ªÅu ki·ªán If v√† To√°n t·ª≠ ƒëi·ªÅu ki·ªán (If statements and Conditional operator)\nC√¢u ƒëi·ªÅu ki·ªán If To√°n t·ª≠ ƒëi·ªÅu ki·ªán (Conditional operator) B√†i 26: C√¢u ƒëi·ªÅu ki·ªán Switch trong C++ (Switch statements)\nC√¢u ƒëi·ªÅu ki·ªán Switch (Switch statements) Khai b√°o v√† kh·ªüi t·∫°o bi·∫øn b√™n trong case statement B√†i 27: C√¢u l·ªánh Goto trong C++ (Goto statements)\nT·ªïng quan v·ªÅ c√¢u l·ªánh Goto trong C++ M·ªôt s·ªë v·∫•n ƒë·ªÅ c·ªßa c√¢u l·ªánh Goto B√†i 28: V√≤ng l·∫∑p While trong C++ (While statements)\nT·ªïng quan v·ªÅ c·∫•u tr√∫c v√≤ng l·∫∑p V√≤ng l·∫∑p while (while statements) B√†i 29: V√≤ng l·∫∑p Do while trong C++ (Do while statements)\nV√≤ng l·∫∑p do while (do while statements) B√†i 30: V√≤ng l·∫∑p For trong C++ (For statements)\nV√≤ng l·∫∑p for (for statements) B√†i 31: T·ª´ kh√≥a Break and continue trong C++\nT·ª´ kh√≥a break T·ª´ kh√≥a continue B√†i 32: Ph√°t sinh s·ªë ng·∫´u nhi√™n trong C++ (Random number generation)\nT·ªïng quan v·ªÅ ph√°t sinh s·ªë ng·∫´u nhi√™n Ph√°t sinh s·ªë ng·∫´u nhi√™n trong C++ Ph√°t sinh s·ªë ng·∫´u nhi√™n trong C++ 11 B√†i 33: M·∫£ng 1 chi·ªÅu trong C++ (Arrays)\nT·∫°i sao l·∫°i s·ª≠ d·ª•ng m·∫£ng? T·ªïng quan v·ªÅ m·∫£ng 1 chi·ªÅu Khai b√°o v√† kh·ªüi t·∫°o m·∫£ng 1 chi·ªÅu Xu·∫•t c√°c ph·∫ßn t·ª≠ m·∫£ng 1 chi·ªÅu Nh·∫≠p d·ªØ li·ªáu cho m·∫£ng 1 chi·ªÅu Ph√°t sinh d·ªØ li·ªáu ng·∫´u nhi√™n cho m·∫£ng 1 chi·ªÅu B√†i 34: C√°c thao t√°c tr√™n M·∫£ng m·ªôt chi·ªÅu\nTruy·ªÅn m·∫£ng v√†o h√†m (passing arrays to functions) Nh·∫≠p v√† xu·∫•t m·∫£ng 1 chi·ªÅu Sao ch√©p m·∫£ng 1 chi·ªÅu T√¨m ki·∫øm ph·∫ßn t·ª≠ trong m·∫£ng S·∫Øp x·∫øp m·∫£ng 1 chi·ªÅu Th√™m v√† x√≥a m·ªôt ph·∫ßn t·ª≠ trong m·∫£ng B√†i 35: M·∫£ng 2 chi·ªÅu trong C++ (Two-dimensional arrays)\nM·∫£ng 2 chi·ªÅu l√† g√¨? Khai b√°o v√† kh·ªüi t·∫°o m·∫£ng 2 chi·ªÅu Xu·∫•t c√°c ph·∫ßn t·ª≠ m·∫£ng 2 chi·ªÅu Nh·∫≠p c√°c ph·∫ßn t·ª≠ m·∫£ng 2 chi·ªÅu B√†i 36: C√°c thao t√°c tr√™n M·∫£ng 2 chi·ªÅu\nTruy·ªÅn m·∫£ng v√†o h√†m (passing arrays to functions) Nh·∫≠p v√† xu·∫•t m·∫£ng 2 chi·ªÅu T√≠nh t·ªïng c√°c ph·∫ßn t·ª≠ trong m·∫£ng T√¨m gi√° tr·ªã l·ªõn nh·∫•t c·ªßa m·∫£ng 2 chi·ªÅu B√†i 37: M·∫£ng k√Ω t·ª± trong C++ (C-style strings)\nM·∫£ng k√Ω t·ª± (C-style strings) l√† g√¨? Khai b√°o v√† kh·ªüi t·∫°o m·∫£ng k√Ω t·ª± (C-style strings) Xu·∫•t m·∫£ng k√Ω t·ª± (C-style strings) v·ªõi std::cout Nh·∫≠p m·∫£ng k√Ω t·ª± (C-style strings) v·ªõi std::cin B√†i 38: C√°c thao t√°c tr√™n M·∫£ng k√Ω t·ª± (C-style strings)\nM·ªôt s·ªë thao t√°c v·ªõi m·∫£ng k√Ω t·ª± (C-style strings)\nhttps://www.freecodecamp.org/news/learn-c-with-free-31-hour-course/\n‚å®Ô∏è (0:00:00) Introduction to data structures ‚å®Ô∏è (0:06:33) Data Structures: List as abstract data type ‚å®Ô∏è (0:19:40) Introduction to linked list ‚å®Ô∏è (0:36:50) Arrays vs Linked Lists ‚å®Ô∏è (0:49:05) Linked List - Implementation in C/C++ ‚å®Ô∏è (1:03:02) Linked List in C/C++ - Inserting a node at beginning ‚å®Ô∏è (1:15:50) Linked List in C/C++ - Insert a node at nth position ‚å®Ô∏è (1:31:04) Linked List in C/C++ - Delete a node at nth position ‚å®Ô∏è (1:43:32) Reverse a linked list - Iterative method ‚å®Ô∏è (1:57:21) Print elements of a linked list in forward and reverse order using recursion ‚å®Ô∏è (2:11:43) Reverse a linked list using recursion ‚å®Ô∏è (2:20:38) Introduction to Doubly Linked List ‚å®Ô∏è (2:27:50) Doubly Linked List - Implementation in C/C++ ‚å®Ô∏è (2:43:09) Introduction to stack ‚å®Ô∏è (2:51:34) Array implementation of stacks ‚å®Ô∏è (3:04:42) Linked List implementation of stacks ‚å®Ô∏è (3:15:39) Reverse a string or linked list using stack. ‚å®Ô∏è (3:32:03) Check for balanced parentheses using stack ‚å®Ô∏è (3:46:14) Infix, Prefix and Postfix ‚å®Ô∏è (3:59:14) Evaluation of Prefix and Postfix expressions using stack ‚å®Ô∏è (4:14:00) Infix to Postfix using stack ‚å®Ô∏è (4:32:17) Introduction to Queues ‚å®Ô∏è (4:41:35) Array implementation of Queue ‚å®Ô∏è (4:56:33) Linked List implementation of Queue ‚å®Ô∏è (5:10:48) Introduction to Trees ‚å®Ô∏è (5:26:37) Binary Tree ‚å®Ô∏è (5:42:51) Binary Search Tree ‚å®Ô∏è (6:02:17) Binary search tree - Implementation in C/C++ ‚å®Ô∏è (6:20:52) BST implementation - memory allocation in stack and heap ‚å®Ô∏è (6:33:55) Find min and max element in a binary search tree ‚å®Ô∏è (6:39:41) Find height of a binary tree ‚å®Ô∏è (6:46:50) Binary tree traversal - breadth-first and depth-first strategies ‚å®Ô∏è (6:58:43) Binary tree: Level Order Traversal ‚å®Ô∏è (7:10:05) Binary tree traversal: Preorder, Inorder, Postorder ‚å®Ô∏è (7:24:33) Check if a binary tree is binary search tree or not ‚å®Ô∏è (7:41:01) Delete a node from Binary Search Tree ‚å®Ô∏è (7:59:27) Inorder Successor in a binary search tree ‚å®Ô∏è (8:17:23) Introduction to graphs ‚å®Ô∏è (8:34:05) Properties of Graphs ‚å®Ô∏è (8:49:19) Graph Representation part 01 - Edge List ‚å®Ô∏è (9:03:03) Graph Representation part 02 - Adjacency Matrix ‚å®Ô∏è (9:17:46) Graph Representation part 03 - Adjacency List\n","date":"Feb 20, 2022","img":"","permalink":"/courses/python/1_introduction/introduction/","series":["Kh√≥a h·ªçc python cƒÉn b·∫£n"],"tags":["c++"],"title":"Gi·ªõi Thi·ªáu V·ªÅ Python"},{"categories":null,"content":"Tools sinh s·ªë ng·∫´u nhi√™n Vi·ªác ph√°t sinh m·ªôt con s·ªë ƒë∆∞·ª£c g·ªçi l√† ng·∫´u nhi√™n ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i v√¨ nhi·ªÅu th·ª© trong th·∫ø gi·ªõi th·ª±c ƒë∆∞·ª£c xem l√† ƒë∆∞·ª£c xu·∫•t hi·ªán m·ªôt c√°ch ng·∫´u nhi√™n. V√¨ v·∫≠y, ƒë·ªÉ m√¥ ph·ªèng nh·ªØng qu√° tr√¨nh x·∫£y ra nh∆∞ ·ªü th·∫ø gi·ªõi th·ª±c, ch√∫ng ta c·∫ßn sinh c√°c con s·ªë m·ªôt c√°ch ng·∫´u nhi√™n. V√≠ d·ª•, h√¨nh d·∫°ng c·ªßa ƒë√°m m√¢y, h√¨nh d·∫°ng c·ªßa c√°c d√£y n√∫i, r·ª´ng c√¢y, kh·ªëi ƒë√°, qu√° tr√¨nh ph√°t tri·ªÉn t·∫ø b√†o, qu√° tr√¨nh ti·∫øn h√≥a, v√¢n v√¢n v√† m√¢y m√¢y.\nhttps://en.wikipedia.org/wiki/Randomized_algorithm C√°c b·∫°n c√≥ th·ªÉ t√¨m ƒë·ªçc ƒë·ªÉ hi·ªÉu th√™m v·ªÅ c√°c thu·∫≠t to√°n random/gi·∫£ random.\nQuay \u0026nbsp; ","date":"Feb 20, 2022","img":"","permalink":"/utils/random/","series":null,"tags":["tools"],"title":"Sinh S·ªë Ng·∫´u Nhi√™n"},{"categories":null,"content":" Gi·ªõi thi·ªáu B∆∞·ªõc 1: T·∫°o b√†n c·ªù v√† sinh n∆∞·ªõc ƒëi B∆∞·ªõc 2: H√†m l∆∞·ª£ng gi√° B∆∞·ªõc 3. T√¨m ki·∫øm c√¢y s·ª≠ d·ª•ng minimax B∆∞·ªõc 4: C·∫Øt t·ªâa Alpha - Beta Gi·ªõi thi·ªáu C·ªù t∆∞·ªõng l√† m·ªôt m√¥n th·ªÉ thao kh√° ph·ªï bi·∫øn ·ªü Vi·ªát Nam. C√°c b·∫°n c√≥ th·ªÉ b·∫Øt g·∫∑p c√°c b√†n c·ªù ·ªü c√°c con h·∫ªm c·ªßa m·ªói g√≥c ph·ªë. Ho·∫∑c l√† khi c√°c b·ªô b√†n gh·∫ø ƒë√° th√¨ ng∆∞·ªùi mua c≈©ng th∆∞·ªùng nh·ªù th·ª£ kh·∫Øc l√™n b√†n c·ªù t∆∞·ªõng ƒë·ªÉ h√†ng x√≥m l√°ng gi·ªÅng gi·∫£i tr√≠ ng√†y cu·ªëi tu·∫ßn. Trong b√†i vi·∫øt n√†y, m√¨nh s·∫Ω h∆∞·ªõng d·∫´n step by step ·ª©ng d·ª•ng ch∆°i game c·ªù t∆∞·ªõng ƒë∆°n gi·∫£n v·ªõi m·ªôt ch√∫t AI. Hi v·ªçng s·∫Ω gi√∫p ƒë∆∞·ª£c c√°c b·∫°n tr√™n con ƒë∆∞·ªùng th·ª±c h√†nh m√°y h·ªçc.\nC√°c vi·ªác c·∫ßn l√†m:\nT·∫°o b√†n c·ªù v√† sinh n∆∞·ªõc ƒëi\nL∆∞·ª£ng gi√° b√†n c·ªù\n√Åp d·ª•ng minimax\n√Åp d·ª•ng c·∫Øt t·ªâa alpha, beta\nB·∫°n c√≥ th·ªÉ ch∆°i th·ª≠ game c·ªù t∆∞·ªõng m√¨nh c√≥ post ·ªü ƒë√¢y: https://www.phamduytung.com/games/china_chess/\nB∆∞·ªõc 1: T·∫°o b√†n c·ªù v√† sinh n∆∞·ªõc ƒëi M√¨nh kh√¥ng c√≥ g·ªèi l·∫Øm trong vi·ªác thi·∫øt k·∫ø m·∫•y icon cho m·∫•y con t∆∞·ªõng, sƒ©, t∆∞·ª£ng. Ngo√†i ra, c√¥ng vi·ªác ch√≠nh c·ªßa ch√∫ng ta l√† ph·∫ßn l√†m sao cho m√°y t·ª± ƒë√°nh ƒë∆∞·ª£c, n√™n ph·∫ßn n√†y m√¨nh s·∫Ω x√†i c√°c open source c√≥ s·∫µn, l∆∞·ª£n l·ªù m·ªôt ch√∫t tr√™n m·∫°ng th√¨ m√¨nh ƒë√£ l·ª•m ƒë∆∞·ª£c c√°i b√†n c·ªù ·ªü link https://github.com/lengyanyu258/xiangqiboardjs v√† th∆∞ vi·ªán sinh n∆∞·ªõc ƒëi xiangqi.js. Th∆∞ vi·ªán xiangqi.js ƒë√£ c√≥ s·∫µn c√°c h√†m ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa n∆∞·ªõc ƒëi, n√™n m√¨nh ch·ªâ vi·ªác l·∫•y ra r·ªìi d√πng th√¥i, kh·ªèi m·∫•t c√¥ng ph·∫£i vi·∫øt l·∫°i.\nB√†n c·ªù ƒë∆∞·ª£c chia l√†m 2 ƒë·ªôi, l√† ƒë·ªôi ƒëen (black, k√Ω hi·ªáu b) v√† ƒë·ªôi ƒë·ªè (red , k√Ω hi·ªáu r), m·ªói ƒë·ªôi g·ªìm 16 qu√¢n, bao g·ªìm 1 con t∆∞·ªõng (General ho·∫∑c king , k√Ω hi·ªáu k), 2 con s·ªπ (Advisor ho·∫∑c guards, ministers, k√Ω hi·ªáu l√† a), 2 con t∆∞·ª£ng (Elephants ho·∫∑c bishops - k√Ω hi·ªáu l√† b), 2 con m√£ (Horses ho·∫∑c knights - k√Ω hi·ªáu l√† n, do ch·ªØ k tr√πng v·ªõi king l√† con t∆∞·ªõng, n√™n ng∆∞·ªùi ta x√†i ch·ªØ n), 2 con xe (Chariot ho·∫∑c rooks - k√Ω hi·ªáu l√† r), 2 con ph√°o (canons, k√Ω hi·ªáu l√† c ), 5 con ch·ªët (Soldiers , k√Ω hi·ªáu l√† p ( do con ch·ªët ·ªü c·ªù ƒëen v√† c·ªù ƒë·ªè c√≥ phi√™n √¢m ti·∫øng trung kh√°c nhau, ch·ªët c·ªù ƒëen ƒë·ªçc g·∫ßn gi·ªëng ch·ªØ \u0026ldquo;z√∫\u0026rdquo; (\u0026ldquo;pawn\u0026rdquo; ho·∫∑c \u0026ldquo;private\u0026rdquo; - ti·∫øng anh), c√≤n ch·ªët c·ªù ƒë·ªè ƒë·ªçc l√† bing (\u0026ldquo;soldier\u0026rdquo; - ti·∫øng anh) )).\nT·ªïng c·ªông, ta c√≥ t∆∞·ªõng, s·ªπ, t∆∞·ª£ng, m√£, xe, ph√°o, ch·ªët, 7 lo·∫°i qu√¢n, t∆∞∆°ng ƒë∆∞∆°ng v·ªõi 7 k√Ω hi·ªáu, t·ªï h·ª£p v·ªõi 2 ƒë·ªôi l√† ƒë·ªè v√† ƒëen, t·ªï h·ª£p v·ªõi nhau, ta x√°c ƒë·ªãnh ƒë∆∞·ª£c\nƒê·ªÉ b·∫Øt ƒë·∫ßu, ch√∫ng ta s·∫Ω code m·ªôt h√†m random b∆∞·ªõc ƒëi ƒë∆°n gi·∫£n. H√†m c√≥ nhi·ªám v·ª• l·∫•y ng·∫´u nhi√™n m·ªôt b∆∞·ªõc ƒëi trong danh s√°ch c√°c b∆∞·ªõc c√≥ th·ªÉ ƒëi, sau ƒë√≥ m√°y s·∫Ω ƒë√°nh b∆∞·ªõc ƒëi ƒë√≥.\n1 2 3function makeRandomMove () { 4 let possibleMoves = game.moves(); 5 6 // game over 7 if (possibleMoves.length === 0) return; // Kh√¥ng c√≤n n∆∞·ªõc n√†o c√≥ th·ªÉ ƒëi, end game 8 9 let randomIdx = Math.floor(Math.random() * possibleMoves.length); // b·ªëc ƒë·∫°i 1 n∆∞·ªõc ƒëi trong danh s√°ch c√°c b∆∞·ªõc c√≥ th·ªÉ ƒëi 10 game.move(possibleMoves[randomIdx]); 11 board.position(game.fen()); 12} Do thu·∫≠t to√°n ch√∫ng ta cho m√°y ch·∫°y kh√° l√† ng·ªëc, n√™n n√≥ ƒë√°nh c≈©ng h∆°i ng·ªëc. :)\nB∆∞·ªõc 2: H√†m l∆∞·ª£ng gi√° D·ª±a v√†o m·ª©c ƒë·ªô c∆° ƒë·ªông, t·∫ßm quang tr·ªçng c·ªßa m·ªói qu√¢n l√≠nh tr√™n b√†n c·ªù, ch√∫ng ta s·∫Ω g√°n cho m·ªói qu√¢n c·ªù m·ªôt tr·ªçng s·ªë kh√°c nhau th·ªÉ hi·ªán ƒëi·ªÅu ƒë√≥.\nV√≠ d·ª•, ch√∫ng ta set c√°c tr·ªçng s·ªë nh∆∞ sau:\nt∆∞·ªõng c·ªßa ta l√† 900 ƒëi·ªÉm, t∆∞·ªõng c·ªßa ƒë·ªëi th·ªß l√† -900 ƒëi·ªÉm\ns·ªπ c·ªßa ta l√† 20 ƒëi·ªÉm, s·ªπ c·ªßa ƒë·ªëi th·ªß l√† -20 ƒëi·ªÉm\nt∆∞·ª£ng c·ªßa ta l√† 20 ƒëi·ªÉm, t∆∞·ª£ng c·ªßa ƒë·ªëi th·ªß l√† -20 ƒëi·ªÉm\nm√£ c·ªßa ta l√† 40 ƒëi·ªÉm, m√£ c·ªßa ƒë·ªëi th·ªß l√† -40 ƒëi·ªÉm\nxe c·ªßa ta l√† 90 ƒëi·ªÉm, xe c·ªßa ƒë·ªëi th·ªß l√† -90 ƒëi·ªÉm\nph√°o c·ªßa ta l√† 45 ƒëi·ªÉm, ph√°o c·ªßa ƒë·ªëi th·ªß l√† -45 ƒëi·ªÉm\nch·ªët c·ªßa ta l√† 15 ƒëi·ªÉm, ch·ªët c·ªßa ƒë·ªëi th·ªß l√† -15 ƒëi·ªÉm\nH√†m l∆∞·ª£ng gi√° ·ªü tr√™n kh√° ng√¢y th∆°, m·ªçi qu√¢n c·ªù ƒë·ªÅu c√≥ ƒëi·ªÉm ngang nhau, kh√¥ng quan t√¢m v·ªã tr√≠ ƒë·ª©ng c·ªßa n√≥.\nTr√™n th·ª±c t·∫ø, ch√∫ng ta th·∫•y r·∫±ng, con t∆∞·ªõng ·ªü v·ªã tr√≠ trung t√¢m th∆∞·ªùng l√† an to√†n nh·∫•t, m·ªôt khi t∆∞·ªõng leo l√™n l·∫ßu 1 ho·∫∑c leo l·∫ßu 2, nghƒ©a l√† con t∆∞·ªõng c√≥ kh·∫£ nƒÉng b·ªã ƒë·ªôt t·ª≠ cao h∆°n, n√™n ch√∫ng ta ph·∫£i tinh ch·ªânh l·∫°i ƒëi·ªÉm c·ªßa con t∆∞·ªõng trong tr∆∞·ªùng h·ª£p n√†y.\nM·ªôt v√≠ d·ª• n·ªØa l√† v·ªã tr√≠ con m√£, m√£ g·∫ßn v·ªõi th√†nh c·ªßa t∆∞·ªõng ƒë·ªãch h∆°n th√¨ kh·∫£ nƒÉng con xe chi·∫øu b√≠ t∆∞·ªõng ƒë·ªãch s·∫Ω cao h∆°n con m√£ ch∆∞a qua s√¥ng.\nGi√° tr·ªã l∆∞·ª£ng gi√° cho c·ªù t∆∞·ªõng, c√°c b·∫°n c√≥ th·ªÉ tham kh·∫£o ·ªü link https://github.com/markdirish/xiangqi/blob/master/evaluate.js\nCh√∫ng ta s·∫Ω duy·ªát l·∫ßn l∆∞·ª£t t·ª´ tr√°i qua ph·∫£i, t·ª´ tr√™n xu·ªëng d∆∞·ªõi, t√≠nh ƒëi·ªÉm c·ªßa b√†n c·ªù hi·ªán t·∫°i.\nH√†m l∆∞·ª£ng gi√° c·ªßa b√†n c·ªù x√©t nh∆∞ sau:\n1 2 3 4function evaluateBoard(board) { 5 var totalEvaluation = 0; 6 for (var i = 0; i \u0026lt; 10; i++) { 7 for (var j = 0; j \u0026lt; 9; j++) { 8 totalEvaluation = totalEvaluation + getPieceValue(board[i][j], i ,j); 9 } 10 } 11 return totalEvaluation; 12} 13 14 15 16function getPieceValue(piece, x, y) { 17 if (piece === null) { 18 return 0; 19 } 20 var getAbsoluteValue = function (piece, isRed, x ,y) { 21 if (piece.type === \u0026#39;p\u0026#39;) { //ch·ªët 22 return 15 + ( isRed ? pEvalRed[x][y] : pEvalBlack[x][y] ); 23 } else if (piece.type === \u0026#39;r\u0026#39;) { //Xe 24 return 90 +( isRed ? rEvalRed[x][y] : rEvalBlack[x][y] ); 25 } else if (piece.type === \u0026#39;c\u0026#39;) { //ph√°o 26 return 45 +( isRed ? cEvalRed[x][y] : cEvalBlack[x][y] ); 27 } else if (piece.type === \u0026#39;n\u0026#39;) { // m√£ 28 return 40 +( isRed ? nEvalRed[x][y] : nEvalBlack[x][y] ); 29 } else if (piece.type === \u0026#39;b\u0026#39;) { // t∆∞·ª£ng 30 return 20 +( isRed ? bEvalRed[x][y] : bEvalBlack[x][y] ); 31 } else if (piece.type === \u0026#39;a\u0026#39;) { // s·ªπ 32 return 20 +( isRed ? aEvalRed[x][y] : aEvalBlack[x][y] ); 33 } else if (piece.type === \u0026#39;k\u0026#39;) { // t∆∞·ªõng 34 return 900 +( isRed ? kEvalRed[x][y] : kEvalBlack[x][y] ); 35 } 36 throw \u0026#34;Unknown piece type: \u0026#34; + piece.type; 37 }; 38 39 var absoluteValue = getAbsoluteValue(piece, piece.color === \u0026#39;r\u0026#39;, x ,y); 40 return piece.color === \u0026#39;r\u0026#39; ? absoluteValue : -absoluteValue; 41} B√¢y gi·ªù, ch√∫ng ta ch·ªâ c·∫ßn duy·ªát qua to√†n b·ªô c√°c n∆∞·ªõc c√≥ th·ªÉ ƒëi, t√≠nh xem n∆∞·ªõc ƒëi n√†o c√≥ ƒëi·ªÉm s·ªë l√† l·ªõn nh·∫•t, th√¨ m√°y s·∫Ω ƒëi theo n∆∞·ªõc ƒëi ƒë√≥.\n1 2 3function getBestMove(game) { 4 5var newGameMoves = game.moves(); 6var bestMove = null; 7// set ƒë·∫°i m·ªôt s·ªë √¢m v√¥ h·∫°n 8var bestValue = -9999; 9 10for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 11 var newGameMove = newGameMoves[i]; 12 game.move(newGameMove); 13 14 var boardValue = -evaluateBoard(game.board()) 15 game.undo(); 16 if (boardValue \u0026gt; bestValue) { 17 bestValue = boardValue; 18 bestMove = newGameMove 19 } 20} 21 22return bestMove; 23 24}; V√¨ v·∫≠y, ngo√†i vi·ªác x√©t ƒëi·ªÉm cho c√°c lo·∫°i qu√¢n, ch√∫ng ta s·∫Ω c√≥ m·ªôt b·∫£ng x√©t ƒëi·ªÉm cho c√°c con\nK·∫øt qu·∫£ c√≥ v·∫ª t·ªët h∆°n so v·ªõi vi·ªác random b∆∞·ªõc ƒëi tr∆∞·ªõc ƒë√≥, nh∆∞ng thu·∫≠t to√°n v·∫´n c√≤n h∆°i d·ªët d·ªët x√≠u, do m√°y ch·ªâ t√≠nh 1 n∆∞·ªõc ƒëi v√† ch·ªçn ra n∆∞·ªõc ƒëi t·ªët nh·∫•t. N√™n m√°y ch∆∞a c√≥ c√°i nh√¨n d√†i h∆°n. C√≥ nhi·ªÅu c√°ch ƒë·ªÉ cho m√°y c√≥ th·ªÉ c√≥ g√≥c nh√¨n xa h∆°n v·ªÅ th·∫ø c·ª•c c·ªßa b√†n c·ªù, m·ªôt trong c√°c c√°ch ƒë∆∞·ª£c gi·ªõi thi·ªáu ·ªü ƒë√¢y l√† s·ª≠ d·ª•ng minimax\nB∆∞·ªõc 3. T√¨m ki·∫øm c√¢y s·ª≠ d·ª•ng minimax Thu·∫≠t to√°n minimax thu·ªôc nh√≥m duy·ªát theo chi·ªÅu s√¢u (depth first search). Hai ng∆∞·ªùi ch∆°i, m·ªôt ng∆∞·ªùi ƒë∆∞·ª£c g·ªçi l√† MAX, ng∆∞·ªùi c√≤n l·∫°i g·ªçi l√† MIN. Thu·∫≠t to√°n ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ t√¨m n∆∞·ªõc ƒëi t·ªëi ∆∞u cho ng∆∞·ªùi MAX. Ng∆∞·ªùi MAX s·∫Ω gi·ªØ node g·ªëc, l·∫ßn l∆∞·ª£t duy·ªát ƒë·ªá quy qua t·∫•t c·∫£ c√°c node con theo chi·ªÅu s√¢u nh·∫•t ƒë·ªãnh ƒë·∫øn khi duy·ªát qua t·∫•t c·∫£ c√°c node ho·∫∑c l√† t√¨m ƒë∆∞·ª£c m·ªôt ƒë∆∞·ªùng ƒëi m√† ƒë·∫°t MAX.\nChi ti·∫øt h∆°n, ng∆∞·ªùi MAX s·∫Ω ƒëi ƒë·∫ßu ti√™n. Nhi·ªám v·ª• c·ªßa MAX l√† t√¨m n∆∞·ªõc ƒëi sao cho ƒëi·ªÉm s·ªë c·ªßa m√¨nh l√† cao nh·∫•t, nhi·ªám v·ª• c·ªßa MIN l√† t√¨m n∆∞·ªõc ƒëi ƒë·ªÉ c·ª±c ti·ªÉu ho√° ƒëi·ªÉm s·ªë c·ªßa MAX.\nC√°c b·∫°n c√≥ th·ªÉ ƒë·ªçc th√™m ·ªü link https://en.wikipedia.org/wiki/Minimax.\nƒê·ªÉ tri·ªÉn khai minimax, ƒë·∫ßu ti√™n, ch√∫ng ta s·∫Ω s·ª≠a l·∫°i h√†m getBestMove ·ªü tr√™n, thay v√¨ g·ªçi l∆∞·ª£ng gi√° b√†n c·ªù evaluateBoard, ch√∫ng ta s·∫Ω g·ªçi h√†m minimax\n1 2 3function minimaxRoot(depth, game, isMaximisingPlayer) { 4 var newGameMoves = game.moves(); 5 var bestMove = -9999; 6 var bestMoveFound; 7 8 for(var i = 0; i \u0026lt; newGameMoves.length; i++) { 9 var newGameMove = newGameMoves[i] 10 game.move(newGameMove); 11 var value = minimax(depth - 1, game, !isMaximisingPlayer); 12 game.undo(); 13 if(value \u0026gt;= bestMove) { 14 bestMove = value; 15 bestMoveFound = newGameMove; 16 } 17 } 18 return bestMoveFound; 19} v·ªõi h√†m minimax c≈©ng c√πng √Ω t∆∞·ªüng v·ªõi h√†m getBestMove ·ªü tr√™n, nh∆∞ng ta s·∫Ω g·ªçi ƒë·ªá quy, lu√¢n phi√™n t√≠nh ƒëi·ªÉm m√°y, sau ƒë√≥ t√≠nh ƒëi·ªÉm ng∆∞·ªùi \u0026hellip; theo ƒë·ªô s√¢u ta ƒë√£ thi·∫øt l·∫≠p, ƒë·ªÉ t√¨m ra ƒë∆∞·ªùng ƒëi c√≥ s·ªë ƒëi·ªÉm l√† l·ªõn nh·∫•t.\n1 2function minimax (depth, game, isMaximisingPlayer) { 3 if (depth === 0) { 4 return -evaluateBoard(game.board()); 5 } 6 var newGameMoves = game.moves(); 7 if (isMaximisingPlayer) { 8 var bestMove = -9999; 9 for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 10 game.move(newGameMoves[i]); 11 bestMove = Math.max(bestMove, minimax(depth - 1, game, !isMaximisingPlayer)); 12 game.undo(); 13 } 14 return bestMove; 15 } else { 16 var bestMove = 9999; 17 for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 18 game.move(newGameMoves[i]); 19 bestMove = Math.min(bestMove, minimax(depth - 1, game, !isMaximisingPlayer)); 20 game.undo(); 21 } 22 return bestMove; 23 } 24}; Thu·∫≠t to√°n n√†y ho·∫°t ƒë·ªông kh√° hi·ªáu qu·∫£, nh∆∞ng c√≥ m·ªôt ƒëi·ªÉm y·∫øu l√† n√≥ s·∫Ω v√©t c·∫°n to√†n b·ªô c√°c tr∆∞·ªùng h·ª£p ƒë·ªÉ t√¨m ra ƒë∆∞·ªùng ƒëi t·ªëi ∆∞u nh·∫•t. V√¨ v·∫≠y, v·ªõi gi√° tr·ªã ƒë·ªô s√¢u c√†ng l·ªõn th√¨ thu·∫≠t to√°n ch·∫°y c√†ng ch·∫≠m.\nB∆∞·ªõc 4: C·∫Øt t·ªâa Alpha - Beta C·∫Øt t·ªâa Alpha - Beta l√† m·ªôt ph∆∞∆°ng ph√°p t·ªëi ∆∞u ho√° c·ªßa thu·∫≠t to√°n minimax, ph∆∞∆°ng ph√°p n√†y gi√∫p ch√∫ng ta b·ªè qua m·ªôt v√†i nh√°nh trong qu√° tr√¨nh t√¨m ki·∫øm, l√†m gi·ªõi h·∫°n ph·∫°m vi t√¨m ki·∫øm, gi√∫p m√¥ h√¨nh ho·∫°t ƒë·ªông nhanh h∆°n.\nThu·∫≠t to√°n s·∫Ω ho·∫°t ƒë·ªông hi·ªáu qu·∫£ h∆°n n·∫øu nh·ªØng b∆∞·ªõc t√¨m ki·∫øm ƒë·∫ßu ti√™n l√† nh·ªØng n∆∞·ªõc ƒëi t·ªët nh·∫•t :)\nH√†m minimax v·ªõi alpla, beta ƒë∆∞·ª£c vi·∫øt l·∫°i nh∆∞ sau\n1 2 3 4function minimax(depth, game, alpha, beta, isMaximisingPlayer) { 5 positionCount++; 6 if (depth === 0) { 7 return -evaluateBoard(game.board()); 8 } 9 10 var newGameMoves = game.moves(); 11 12 if (isMaximisingPlayer) { 13 var bestMove = -9999; 14 for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 15 game.moves(newGameMoves[i]); 16 bestMove = Math.max(bestMove, minimax(depth - 1, game, alpha, beta, !isMaximisingPlayer)); 17 game.undo(); 18 alpha = Math.max(alpha, bestMove); 19 if (beta \u0026lt;= alpha) { 20 return bestMove; 21 } 22 } 23 return bestMove; 24 } else { 25 var bestMove = 9999; 26 for (var i = 0; i \u0026lt; newGameMoves.length; i++) { 27 game.moves(newGameMoves[i]); 28 bestMove = Math.min(bestMove, minimax(depth - 1, game, alpha, beta, !isMaximisingPlayer)); 29 game.undo(); 30 beta = Math.min(beta, bestMove); 31 if (beta \u0026lt;= alpha) { 32 return bestMove; 33 } 34 } 35 return bestMove; 36 } 37} C·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt. Xin ch√†o v√† h·∫πn g·∫∑p l·∫°i c√°c b·∫°n ·ªü b√†i vi·∫øt k·∫ø ti·∫øp.\nC√°c b·∫°n c√≥ th·ªÉ ch∆°i game ·ªü ƒë√¢y nha , link https://www.phamduytung.com/games/china_chess/\nM√¨nh s·∫Ω update d·∫ßn giao di·ªán ƒë·ªÉ cho game tr·ªü n√™n ƒë·∫πp ƒë·∫πp h∆°n.\n","date":"Aug 12, 2021","img":"https://unsplash.it/1920/1080?image=30","permalink":"/blog/2021-08-12-china_chess_alpha_beta_ai/","series":null,"tags":["Machine Learning","Normalization","Deep Learning","China Chess","C·ªù T∆∞·ªõng","MiniMax","Alpha Beta Pruning"],"title":"X√¢y D·ª±ng Ch∆∞∆°ng Tr√¨nh AI ƒê∆°n Gi·∫£n Cho Game C·ªù T∆∞·ªõng"},{"categories":null,"content":" Gi·ªõi thi·ªáu V√≤ng ƒë·ªùi khi x√¢y d·ª±ng ch∆∞∆°ng tr√¨nh m√°y h·ªçc MLOps l√† g√¨ V√≠ d·ª• s·ª≠ d·ª•ng Pycaret Business Problem Exploratory Data Analysis Data Preparation Model Training \u0026amp; Selection Deployment \u0026amp; Monitoring Gi·ªõi thi·ªáu PyCaret l√† th∆∞ vi·ªán open-source machinelearning trong python, Th∆∞ vi·ªán t√≠ch h·ª£p s·∫µn c√°c m√¥ h√¨nh c·∫ßn thi·∫øt, gi√∫p ch√∫ng ta train m√¥ h√¨nh m·ªôt l·∫ßn tr√™n nhi·ªÅu thu·∫≠t to√°n m√°y h·ªçc kh√°c nhau. Th∆∞ vi·ªán c√≥ h·ªó tr·ª£ train tr√™n GPU. Phi√™n b·∫£n hi·ªán t·∫°i l√∫c m√¨nh vi·∫øt b√†i vi·∫øt n√†y l√† 2.3.3. C√°c b·∫°n c√≥ th·ªÉ tham kh·∫£o th√¥ng tin th√™m c·ªßa th∆∞ vi·ªán ·ªü link github https://github.com/pycaret/pycaret\nƒê·ªÉ c√†i ƒë·∫∑t pycaret, c√°c b·∫°n s·ª≠ d·ª•ng l·ªánh sau\n1 2pip install pycaret 3 4pip install pycaret[full] B·∫£n full c√≥ c√†i th√™m nhi·ªÅu g√≥i th∆∞ vi·ªán kh√°c, c√°c b·∫°n c√≥ th·ªÉ tham kh·∫£o c√°c g√≥i th∆∞ vi·ªán ƒë∆∞·ª£c c√†i th√™m ·ªü b·∫£n full qua link https://github.com/pycaret/pycaret/blob/master/requirements-optional.txt\nM√¨nh quan s√°t s∆° qua th√¨ b√†n full c√≥ c√†i th√™m m·∫•y c√°i th∆∞ vi·ªán k·∫øt n·ªëi aws v√† gcs kh√° d∆∞ th·ª´a, m√¨nh kh√¥ng x√†i t·ªõi, v·ªõi ·ªï c·ª©ng m√°y m√¨nh c≈©ng c√≥ h·∫°n. N√™n m√¨nh ch·ªâ c√†i b·∫£n c∆° b·∫£n v√† c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt nh∆∞ scikit-optimize, tune-sklearn, xgboost \u0026hellip;\nV√≤ng ƒë·ªùi khi x√¢y d·ª±ng ch∆∞∆°ng tr√¨nh m√°y h·ªçc Business Problem : Nh∆∞ nh·ªØng ·ª©ng d·ª•ng kh√°c, m·ªôt ·ª©ng d·ª•ng m√°y h·ªçc c≈©ng ƒë∆∞·ª£c b·∫Øt ƒë·∫ßu b·∫±ng m·ªôt v·∫•n ƒë·ªÅ th·ª±c t·∫ø trong cu·ªôc s·ªëng, trong c√¥ng vi·ªác. Ph·ª• thu·ªôc v√†o s·ª± ph·ª©c t·∫°p c·ªßa v·∫•n ƒë·ªÅ, v√† c√°c chi ph√≠ li√™n quan v·ªÅ m·∫∑t kinh doanh, ch√∫ng ta s·∫Ω ph√¢n t√≠ch c√°c y·∫øu t·ªë li√™n quan ƒë·ªÉ xem x√©t c√≥ c·∫ßn thi·∫øt ph·∫£i ph√°t tri·ªÉn ch∆∞∆°ng tr√¨nh s·ª≠ d·ª•ng m√°y h·ªçc ho·∫∑c t√¨m m·ªôt gi·∫£i ph√°p thay th·∫ø t·ªët h∆°n theo to√†n b·ªô ti√™u ch√≠ (thuy·∫øt v·ªã l·ª£i).\nData Sourcing \u0026amp; ETL : Sau khi hi·ªÉu b√†i to√°n, ch√∫ng ta s·∫Ω thu th·∫≠p c√°c d·ªØ li·ªáu c·∫ßn thi·∫øt.\nExploratory Data Analysis (EDA) : D·ªØ li·ªáu ·ªü tr√™n l√† d·ªØ li·ªáu th√¥, ch∆∞a qua x·ª≠ l√Ω, n√™n c√≥ th·ªÉ s·∫Ω b·ªã thu th·∫≠p kh√¥ng ƒë·ªß, thu th·∫≠p thi·∫øu. Ch√∫ng ta c·∫ßn ph·∫£i n·∫Øm r√µ d·ªØ li·ªáu, ph√¢n t√≠ch s·ª± c√¢n b·∫±ng/ ƒë·ªô l·ªách c·ªßa d·ªØ li·ªáu, x·ª≠ l√Ω nhi·ªÖu, xem ph√¢n b·ªë c·ªßa d·ªØ li·ªáu, xem ƒë·ªô t∆∞∆°ng quan gi·ªØa c√°c ƒë·∫∑c tr∆∞ng, \u0026hellip;\nData Preparation : Sau khi ph√¢n t√≠ch, x√†o n·∫•u d·ªØ li·ªáu ƒë·∫πp ƒë·∫Ω, tr∆°n tru, ch√∫ng ta s·∫Ω b·∫Øt ƒë·∫ßu chu·∫©n b·ªã d·ªØ li·ªáu cho m√¥ h√¨nh train, v√≠ d·ª• chia d·ªØ li·ªáu th√†nh t·∫≠p train,test,validation, one-hot encoding, feature engineering, feature selection \u0026hellip;\nModel Training \u0026amp; Selection : ƒê√¢y l√† ph·∫ßn nh√†m ch√°n nh·∫•t, th·ª≠ nghi·ªám d·ªØ li·ªáu v·ªõi c√°c m√¥ h√¨nh v√† tham s·ªë kh√°c nhau, l·ª±a ch·ªçn m√¥ h√¨nh c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t tr√™n t·∫≠p validation. ch·ªù m√¥ h√¨nh train xong\nDeployment \u0026amp; Monitoring : Sau khi c√≥ ƒë∆∞·ª£c m√¥ h√¨nh t·ªët nh·∫•t, ch√∫ng ta s·∫Ω deploy ·ª©ng d·ª•ng, v√† theo d√µi, t∆∞∆°ng t·ª± nh∆∞ nh·ªØng ·ª©ng d·ª•ng kh√°c th√¥i.\nTrong vi·ªác ph√°t tri·ªÉn ph·∫ßn m·ªÅm, c√≥ m·ªôt kh√°i ni·ªám ƒëang n·ªïi g·∫ßn ƒë√¢y (l√∫c m√¨nh ƒëang vi·∫øt b√†i vi·∫øt n√†y) l√† devops. Gi√∫p cho m·ªôt s·ªë c√¥ng vi·ªác nh√†m ch√°m ƒë∆∞·ª£c th·ª±c hi·ªán m·ªôt c√°ch t·ª± ƒë·ªông. Trong m√°y h·ªçc, ch√∫ng ta s·∫Ω c√≥ kh√°i ni·ªám MLOps.\nMLOps l√† g√¨ ƒê·ªãnh nghƒ©a theo wikipedia:\n1 2MLOps or ML Ops is a set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently M·ªôt b·ª©c h√¨nh b·∫±ng v·∫°n c√¢u ch·ªØ, xem b·ª©c h√¨nh tr√™n, c√°c b·∫°n ch·∫Øc v·ªÅ c∆° b·∫£n c≈©ng hi·ªÉu c√¥ng vi·ªác c·ªßa MLOps l√† g√¨ r·ªìi hen.\n√Ä, ƒë·ªçc ƒë·∫øn ƒë√¢y, c√°c b·∫°n c√≥ l·∫Ω s·∫Ω th·∫Øc m·∫Øc l√† sao ƒëang gi·ªõi thi·ªáu Pycaret, m√† sao l·∫°i lang mang qua MLOps l√†m g√¨? Th√¨ m√¨nh c≈©ng tr·∫£ l·ªùi lu√¥n l√† Pycaret l√† m·ªôt trong nh·ªØng package gi√∫p ch√∫ng ta MLOps ==\u0026gt; b·ªõt nh√†m ch√°n khi ph√°t tri·ªÉn ·ª©ng d·ª•ng machine learning r·ªìi ƒë√≥.\nV√≠ d·ª• s·ª≠ d·ª•ng Pycaret M√¨nh s·∫Ω tr√¨nh b√†y ph·∫ßn n√†y ƒë√∫ng theo machine learning life cycle, ƒë·ªÉ ƒë·∫£m b·∫£o vi·ªác gi·∫£ l·∫≠p s√°t v·ªõi th·ª±c t·∫ø.\nBusiness Problem B√†i to√°n Sarah Gets a Diamond, link chi ti·∫øt c·ªßa b√†i to√°n ·ªü https://hbsp.harvard.edu/product/UV0869-PDF-ENG. B√†i to√°n n√†y gi√∫p ng∆∞·ªùi h·ªçc kho√° ƒë√≥ hi·ªÉu ƒë∆∞·ª£c s·ª± kh√°c nhau c·ªßa linear-model, log-liner model, log-log mode. N·∫øu c√°c b·∫°n c√≥ nhu c·∫ßu t√¨m hi·ªÉu c√°c model tr√™n, c√≥ th·ªÉ ƒëƒÉng k√Ω kho√° h·ªçc tr√™n hen. ·ªû ƒë√¢y, m√¨nh ch·ªâ l·∫•y m√¥ t·∫£ chi ti·∫øt v√† data c·ªßa kho√° h·ªçc.\nB·ªëi c·∫£nh c·ªßa b√†i to√°n di·ªÖn ra nh∆∞ sau. Grey mu·ªën mua m·ªôt chi·∫øc nh·∫´n ƒë·ªÉ c·∫ßu h√¥n Sarah. Sau m·ªôt h·ªìi tham kh·∫£o m·∫•y th·∫±ng b·∫°n t·ª´ th·ªùi n·ªëi kh·ªë, Grey quy·∫øt ƒë·ªãnh s·∫Ω mua nh·∫´n kim c∆∞∆°ng. Grey ti·∫øn h√†nh ƒëi thu th·∫≠p th√¥ng tin c·ªßa 6000 chi·∫øc nh·∫´n kim c∆∞∆°ng kh√°c nhau v·ªÅ gi√°, m√†u s·∫Øc, h√¨nh d·∫°ng \u0026hellip;\nMay m·∫Øn thay Grey c√≥ share d·ªØ li·ªáu n√†y cho Pycaret, v√† ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng d·ªØ li·ªáu tr√™n b·∫±ng c√°ch load t·ª´ dataset c·ªßa Pycaret\n1 2# load the dataset from pycaret 3from pycaret.datasets import get_data 4data = get_data(\u0026#39;diamond\u0026#39;) V√† top 5 d·ªØ li·ªáu m·∫´u m√† Grey thu th·∫≠p l√†:\n1 2Carat Weight\tCut\tColor\tClarity\tPolish\tSymmetry\tReport\tPrice 30\t1.10\tIdeal\tH\tSI1\tVG\tEX\tGIA\t5169 41\t0.83\tIdeal\tH\tVS1\tID\tID\tAGSL\t3470 52\t0.85\tIdeal\tH\tSI1\tEX\tEX\tGIA\t3183 63\t0.91\tIdeal\tE\tSI1\tVG\tVG\tGIA\t4370 74\t0.83\tIdeal\tG\tSI1\tEX\tEX\tGIA\t3171 Exploratory Data Analysis B∆∞·ªõc n√†y s·∫Ω ph·ª• thu·ªôc v√†o kinh nghi·ªám c·ªßa ng∆∞·ªùi l√†m data. Kinh nghi·ªám c·ªßa m√¨nh th√¨ ƒë·∫ßu ti√™n s·∫Ω ph√¢n t√≠ch ph√¢n b·ªë d·ªØ li·ªáu v√† ph√¢n t√≠ch m·ªëi t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn li√™n t·ª•c tr∆∞·ªõc ƒë√£, sau ƒë√≥ s·∫Ω ph√¢n t√≠ch c√°c y·∫øu t·ªë chuy√™n s√¢u h∆°n d·ª±a v√†o c·∫£m quan nh·∫≠n ƒë∆∞·ª£c t·ª´ hai c√°i tr√™n.\nQuan s√°t d·ªØ li·ªáu, ch√∫ng ta th·∫•y r·∫±ng ch·ªâ c√≥ hai thu·ªôc t√≠nh Carat Weight v√† Price thu·ªôc nh√≥m numerical variable, c√°c thu·ªôc t√≠nh c√≤n l·∫°i thu·ªôc nh√≥m categorical variable, n√™n m√¨nh kh√¥ng c·∫ßn t√≠nh ƒë·ªô t∆∞∆°ng quan l√†m g√¨ h·∫øt.\nM√¨nh c√≥ h·ªçc t·ª´ link ·ªü t√†i li·ªáu tham kh·∫£o ph√≠a d∆∞·ªõi, th∆∞ vi·ªán plotly.express, m√¨nh tham kh·∫£o th·ª≠ th√¨ th·∫•y h√†m v·∫Ω scatter c·ªßa th∆∞ vi·ªán c√≥ nhi·ªÅu thu·ªôc t√≠nh kh√° hay. V√≠ d·ª• m√¨nh th·ª≠ ph√¢n t√≠ch k√≠ch th∆∞·ªõc vi√™n ƒë√° kim c∆∞∆°ng v·ªõi gi√° c·ªßa chi·∫øc nh·∫´n, chia theo m√†u s·∫Øc th√¨ nh∆∞ th·∫ø n√†o\n1fig = px.scatter(data,x=\u0026#39;Carat Weight\u0026#39;, y=\u0026#39;Price\u0026#39;, animation_group=\u0026#39;Color\u0026#39;, 2 facet_col = \u0026#39;Color\u0026#39;, opacity = 0.25, template = \u0026#39;plotly_dark\u0026#39;, trendline=\u0026#39;ols\u0026#39;, 3 color=\u0026#34;Color\u0026#34;, trendline_color_override = \u0026#39;red\u0026#39;, title = \u0026#39;SARAH GETS A DIAMOND - A CASE STUDY\u0026#39;) 4fig.show() Nh√¨n h√¨nh tr√™n, m√¨nh th·∫•y r·∫±ng c√πng 1 k√≠ch th∆∞·ªõc, m√†u H v√† m√†u I c√≥ gi√° x√™m x√™m nhau, m√†u E v√† F c≈©ng t∆∞∆°ng t·ª±, m√†u D c√≥ m·ª©c gi√° cao nh·∫•t. v·ªõi k√≠ch th∆∞·ªõc 2.74, gi√° c·ªßa chi·∫øc nh·∫´n kim c∆∞∆°ng m√†u D cao h∆°n g·∫•p ƒë√¥i so v·ªõi gi√° c·ªßa nh·∫´n kim c∆∞∆°ng c√≥ m√†u H ho·∫∑c m√†u I\nC√°c b·∫°n c√≥ th·ªÉ thay thu·ªôc t√≠nh facet_col = \u0026lsquo;Color\u0026rsquo; c·ªßa h√†m scatter b·∫±ng c√°c t√™n c·ªôt nh∆∞ Cut\tho·∫∑c Clarity\tho·∫∑c\tSymmetry, s·∫Ω c√≥ v√†i th·ª© hay ho c√≥ th·ªÉ r√∫t ra ƒë√≥.\nSau khi ph√¢n t√≠ch d·ªØ li·ªáu, c√≥ c√°i nh√¨n s∆° l∆∞·ª£c v·ªÅ c√°c thu·ªôc t√≠nh c≈©ng nh∆∞ m·ªëi t∆∞∆°ng quang gi·ªØa ch√∫ng, ch√∫ng ta th∆∞·ªùng s·∫Ω th∆∞·ªùng th·ª±c hi·ªán c√°c ph√©p bi·∫øn ƒë·ªïi ƒë·ªÉ chu·∫©n ho√° d·ªØ li·ªáu. C√°c ph√©p bi·∫øn ƒë·ªïi th∆∞·ªùng ƒë∆∞·ª£c x√†i l√†:\nChu·∫©n ho√° d·ªØ li·ªáu: Scale d·ªØ li·ªáu v·ªÅ c√πng m·ªôt ƒëo·∫°n, v√≠ d·ª• [-1,1] ho·∫∑c [0-1], 2 ph∆∞∆°ng ph√°p ph·ªï bi·∫øn hay ƒë∆∞·ª£c s·ª≠ d·ª•ng:\nMin-Max Z score X·ª≠ l√Ω d·ªØ li·ªáu l·ªách: C√°c c·ªôt thu·ªôc t√≠nh numberric s·∫Ω ƒë∆∞·ª£c chu·∫©n ho√° v·ªÅ ph√¢n ph·ªëi chu·∫©n.\nT·ªïng h·ª£p d·ªØ li·ªáu: S·ª≠ d·ª•ng c√°c thu·ªôc t√≠nh c√≥ s·∫µn, k·∫øt h·ª£p l·∫°i ƒë·ªÉ t·∫°o n√™n c√°c thu·ªôc t√≠nh m·ªõi.\nTr∆∞·ªõc h·∫øt, ch√∫ng ta s·∫Ω xem histogram c·ªßa bi·∫øn Price\nTa th·∫•y r·∫±ng, ph√¢n ph·ªëi c√≥ √≠t quan s√°t h∆°n ·ªü ph√≠a b√™n ph·∫£i =\u0026gt; m√¥ h√¨nh b·ªã l·ªách ph·∫£i (right-skewed ho·∫∑c skewed right, positively skewed distribution). V·ªõi d·ªØ li·ªáu b·ªã b·ªãnh n√†y th√¨ ch√∫ng ta s·∫Ω d√πng thu·ªëc ch·ªØa l√† cƒÉn b·∫≠c hai, cƒÉn b·∫≠c ba ho·∫∑c l√† log.\nM√¨nh s·∫Ω x√†i thu·ªëc log. S·ª≠ d·ª•ng h√†m log trong th∆∞ vi·ªán numpy\n1 2import numpy as np 3# create a copy of data 4data_copy = data.copy() 5# create a new feature Log_Price 6data_copy[\u0026#39;Log_Price\u0026#39;] = np.log(data[\u0026#39;Price\u0026#39;]) 7# plot histogram 8fig = px.histogram(data_copy, x=[\u0026#34;Log_Price\u0026#34;], title = \u0026#39;Histgram of Log Price\u0026#39;, template = \u0026#39;plotly_dark\u0026#39;) 9fig.show() D·ªØ li·ªáu ƒë∆∞·ª£c ƒë∆∞a v·ªÅ d·∫°ng gi·ªëng gi·ªëng c√°i chu√¥ng √∫p, h√¨nh d·∫°ng c·ªßa ph√¢n ph·ªëi chu·∫©n.\nData Preparation X√†i th∆∞ vi·ªán PyCaret kh√° s∆∞·ªõng, ch√∫ng ta ch·ªâ c·∫ßn g·ªçi h√†m setup c·ªßa th∆∞ vi·ªán l√† ƒë·ªß\n1 2# initialize setup 3from pycaret.regression import * 4s = setup(data, target = \u0026#39;Price\u0026#39;, transform_target = True,transform_target_method=\u0026#34;yeo-johnson\u0026#34;, log_experiment = True, experiment_name = \u0026#39;diamond\u0026#39;) B√†i to√°n thu·ªôc d·∫°ng h·ªìi quy, n√™n m√¨nh s·∫Ω load to√†n b·ªô c√°c h√†m thu·ªôc regression v√†o.\nM·ªçi vi·ªác c√≤n l·∫°i, t·ª´ vi·ªác t√≠nh log c·ªßa c·ªôt Price, ƒë·∫øn vi·ªác ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu , \u0026hellip; ƒë√£ ƒë∆∞·ª£c PyCaret lo h·∫øt. Ch√∫ng ta ch·ªâ c·∫ßn ch·ªãu kh√≥ ƒë·ªçc doc c·ªßa th∆∞ vi·ªán ƒë·ªÉ hi·ªÉu c√°c tham s·ªë v√† ·ª©ng d·ª•ng n√≥ v√†o l√† ·ªïn.\nM·ªôt l∆∞u √Ω l√† h√†m transform m·∫∑c ƒë·ªãnh x√†i box-cox, v√† pycaret ·ªü th·ªùi ƒëi·ªÉm hi·ªán t·∫°i ch·ªâ h·ªó tr·ª£ \u0026ldquo;box-cox\u0026rdquo; ho·∫∑c \u0026ldquo;yeo-johnson\u0026rdquo;. N·∫øu c√°c b·∫°n mu·ªën x√†i log cho c·ªôt Price, th√¨ ph·∫£i th√™m c·ªôt m·ªõi. M√¨nh s·∫Ω x√†i yeo-johnson thay cho m·∫∑c ƒë·ªãnh box-cox.\nModel Training \u0026 Selection Ti·∫øp ƒë·∫øn vi·ªác train model v√† l·ª±a ch·ªçn model c≈©ng h·∫øt s·ª©c ƒë∆°n gi·∫£n, ch√∫ng ta ch·ªâ c·∫ßn g·ªçi 1 d√≤ng l·ªánh duy nh·∫•t\n1 2# compare all models 3best = compare_models() Xong. Th∆∞ vi·ªán t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh tham s·ªë, l·ª±a ch·ªçn tham s·ªë t·ªët nh·∫•t v√† m√¥ h√¨nh t·ªët nh·∫•t cho ch√∫ng ta. Ch√∫ng ta ch·ªâ c·∫ßn ng·ªìi, ƒë·ª£i m√°y ch·∫°y, xem k·∫øt qu·∫£.\nM·ªôt l∆∞u √Ω l√† c√°c b·∫°n n·∫øu kh√¥ng c√†i b·∫£n full th√¨ n√™n xem file log ƒë·ªÉ xem c√≥ b√°o l·ªói thi·∫øu th∆∞ vi·ªán hay kh√¥ng hen.\nSau khi c√≥ ƒë∆∞·ª£c thu·∫≠t to√°n v·ªõi m√¥ h√¨nh t·ªët nh·∫•t , v√† c√°c tr·ªçng s·ªë t·ªët nh·∫•t, ch√∫ng ta s·∫Ω l∆∞u m√¥ h√¨nh l·∫°i v√†o file ƒë·ªÉ sau n√†y s·ª≠ d·ª•ng.\n1 2# finalize the model 3final_best = finalize_model(best) 4# save model to disk 5save_model(final_best, \u0026#39;diamond-pipeline\u0026#39;) Deployment \u0026 Monitoring ƒê·∫øn ph·∫ßn n√†y th√¨ ƒë∆°n gi·∫£n r·ªìi, c√°c b·∫°n c√≥ th·ªÉ vi·∫øt webapi nh∆∞ flask ho·∫∑c fastapi ƒë·ªÉ s·ª≠ d·ª•ng.\nPycaret c√≥ h·ªó tr·ª£ mlflow, d√πng ƒë·ªÉ xem ƒë∆∞·ªùng d·∫´n c√°c model ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán, c≈©ng nh∆∞ chi ti·∫øt c√°c th√¥ng tin tham s·ªë, ƒë·ªô l·ªói. C√°c b·∫°n h√£y g√µ l·ªánh\n1!mlflow ui N·∫øu b·∫°n ch·∫°y b·∫±ng terminal , th√¨ ch·ªâ c·∫ßn g√µ mlflow ui th√¥i, kh√¥ng c·∫ßn d·∫•u ! ƒë√¢u, do m√¨nh ch·∫°y tr√™n jupiter notebook n√™n ph·∫£i th√™m d·∫•u ! c√¢u l·ªánh m·ªõi ho·∫°t ƒë·ªông.\nSau khi ch·∫°y l·ªán tr√™n, b·∫°n h√£y m·ªü tr√¨nh duy·ªát web l√™n v√† nh·∫≠p v√† ƒë·ªãa ch·ªâ http://localhost:5000, c√°i n√†y c≈©ng kh√¥ng c√≥ g√¨ nhi·ªÅu ƒë·ªÉ ƒë·ªÅ c·∫≠p, n√™n m√¨nh kh√¥ng show chi ti·∫øt ·ªü ƒë√¢y, c√°c b·∫°n c·ª© v√†o ƒë√≥ v·ªçc v·∫°ch, qu·∫≠y ph√° hen.\nC√°c b·∫°n c√≥ th·ªÉ testing best model b·∫±ng c√¢u l·ªánh sau\n1 2# create a copy of data and drop Price 3data1 = data.copy() 4# data1.drop(\u0026#39;Price\u0026#39;, axis=1, inplace=True) 5# generate predictions 6from pycaret.regression import predict_model 7predictions = predict_model(final_best, data=data1) 8predictions.head() C·ªôt Label ch√≠nh l√† c·ªôt gi√° c·ªßa m√¥ h√¨nh. M√¨nh gi·ªØ l·∫°i c·ªôt gi√° ƒë·ªÉ ti·ªán so s√°nh.\n1 2\tCarat Weight\tCut\tColor\tClarity\tPolish\tSymmetry\tReport\tPrice\tLabel 30\t1.10\tIdeal\tH\tSI1\tVG\tEX\tGIA\t5169\t5365.265635 41\t0.83\tIdeal\tH\tVS1\tID\tID\tAGSL\t3470\t3525.863059 52\t0.85\tIdeal\tH\tSI1\tEX\tEX\tGIA\t3183\t3352.882096 63\t0.91\tIdeal\tE\tSI1\tVG\tVG\tGIA\t4370\t4485.753572 74\t0.83\tIdeal\tG\tSI1\tEX\tEX\tGIA\t3171\t3327.363225 Top 5 ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n hi·ªán ra cho m√¨nh th·∫•y r·∫±ng, c√≥ v·∫ª m√¥ h√¨nh d·ª± ƒëo√°n gi√° cao h∆°n m·ªôt ch√∫t so v·ªõi gi√° g·ªëc.\nC·∫£m ∆°n c√°c b·∫°n nhi·ªÅu. H·∫πn g·∫∑p l·∫°i trong c√°c b√†i vi·∫øt ti·∫øp theo\nTham kh·∫£o\nhttps://github.com/pycaret/pycaret\nhttps://towardsdatascience.com/build-with-pycaret-deploy-with-fastapi-333c710dc786\nhttps://towardsdatascience.com/easy-mlops-with-pycaret-mlflow-7fbcbf1e38c6\n","date":"Jul 28, 2021","img":"https://unsplash.it/1920/1080?image=32","permalink":"/blog/2021-07-28-pycaret-flaskapi/","series":null,"tags":["Machine Learning","Deep Learning","PyCaret"],"title":"T√¨m Hi·ªÉu Package PyCaret Trong Python"},{"categories":null,"content":" Gi·ªõi thi·ªáu Danh s√°ch ƒëi·ªÅu khi·ªÉn truy c·∫≠p - Access Control List (ACL) ƒêi·ªÅu khi·ªÉn truy c·∫≠p b·∫Øt bu·ªôc - Mandatory Access Control (MAC) ƒêi·ªÅu khi·ªÉn truy c·∫≠p t√πy quy·ªÅn - Discretionary Access Control (DAC) ƒêi·ªÅu khi·ªÉn truy c·∫≠p theo vai - Role Based Access Control (RBAC) ƒêi·ªÅu khi·ªÉn truy c·∫≠p theo thu·ªôc t√≠nh - Attribute Based Access Control (ABAC) Gi·ªõi thi·ªáu Danh s√°ch ƒëi·ªÅu khi·ªÉn truy c·∫≠p - Access Control List ƒêi·ªÅu khi·ªÉn truy c·∫≠p b·∫Øt bu·ªôc - Mandatory Access Control ƒêi·ªÅu khi·ªÉn truy c·∫≠p t√πy quy·ªÅn - Discretionary Access Control (DAC) ƒêi·ªÅu khi·ªÉn truy c·∫≠p theo vai - Role Based Access Control (RBAC) ƒêi·ªÅu khi·ªÉn truy c·∫≠p theo thu·ªôc t√≠nh - Attribute Based Access Control (ABAC) Danh s√°ch ƒëi·ªÅu khi·ªÉn truy c·∫≠p - Access Control List (ACL) L√† m√¥ h√¨nh c·∫•p quy·ªÅn truy c·∫≠p d·ª±a v√†o danh s√°ch c√°c quy·ªÅn\nM√¥ h√¨nh:\nSubject ƒë∆∞·ª£c quy·ªÅn ( action ) tr√™n object\rTu·ª≥ t·ª´ng b√†i to√°n kh√°c nhau m√† subject, action, object l√† kh√°c nhau\rV√≠ d·ª•:\rTrong m√¥i tr∆∞·ªùng ph√¢n quy·ªÅn t·∫≠p tin linux, subject l√† user, thread, action l√† READ/WRITE/ EXECUTE object l√† file, directory, tcp/udp port, thi·∫øt b·ªã nh·∫≠p xu·∫•t ...\rV√≠ d·ª•:\nTrong h·ªá th·ªëng ph√¢n quy·ªÅn c·ªßa linux\rUser Alice ƒë∆∞·ª£c quy·ªÅn ƒë·ªçc/ghi/th·ª±c thi tr√™n file alice.sh\rUser Bob ƒë∆∞·ª£c quy·ªÅn ƒë·ªçc tr√™n file alice.sh\r·ª®ng d·ª•ng:\nM√¥ h√¨nh ƒë∆∞·ª£c ·ª©ng d·ª•ng trong Filesystem ACLs, POSIX ACL, NFSv4 ACL, Active Directory ACLs, Networking ACLs, SQL implementations.\rTham kh·∫£o:\nhttps://en.wikipedia.org/wiki/Access-control_list ƒêi·ªÅu khi·ªÉn truy c·∫≠p b·∫Øt bu·ªôc - Mandatory Access Control (MAC) V·ªÅ c∆° b·∫£n th√¨ m√¥ h√¨nh n√†y c≈©ng \u0026quot; l√† m√¥ h√¨nh c·∫•p quy·ªÅn truy c·∫≠p d·ª±a v√†o danh s√°ch c√°c quy·ªÅn\u0026quot;. Tuy nhi√™n, m√¥ h√¨nh n√†y s·∫Ω ki·ªÉm so√°t quy·ªÅn truy c·∫≠p ƒë·∫øn t·ª´ng object c·ªßa subject\nM√¥ h√¨nh:\nSubject ƒë∆∞·ª£c quy·ªÅn ( action ) tr√™n object\rObject ƒë∆∞·ª£c quy·ªÅn (action) b·ªüi object\rV√¨ r√†ng ·ªü m·ª©c 2 ƒë·∫ßu, n√™n m√¥ h√¨nh n√†y ƒë∆∞·ª£c r√†ng ch·∫∑c ch·∫Ω h∆°n\rV√≠ d·ª•:\nV√≠ d·ª•: ·ªû m·ªôt s·ªë t·ªï ch·ª©c, user c√≥ quy·ªÅn ƒë·ªçc ghi file (subject - action - object), tuy nhi√™n, c√≥ m·ªôt s·ªë file tuy·ªát m·∫≠t ƒë∆∞·ª£c ph√¢n quy·ªÅn ƒë·ªçc/ ghi cho gi√°m ƒë·ªëc (object - action - subject), n√™n user b√¨nh th∆∞·ªùng kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c.\rC√°c b·∫°n c√≥ th·ªÉ ƒë·ªçc th√™m 3 v√≠ d·ª• trong link c·ªßa cornell m√¨nh c√≥ ƒë·ªÉ b√™n d∆∞·ªõi\r·ª®ng d·ª•ng:\nSELinux\rWindows Vista v√† Windows Server 2008\r...\rTham kh·∫£o:\nhttps://en.wikipedia.org/wiki/Mandatory_access_control\rhttp://www.cs.cornell.edu/courses/cs5430/2015sp/notes/mac.php\rƒêi·ªÅu khi·ªÉn truy c·∫≠p t√πy quy·ªÅn - Discretionary Access Control (DAC) L√† m√¥ h√¨nh c·∫•p quy·ªÅn truy c·∫≠p d·ª±a v√†o danh s√°ch c√°c quy·ªÅn. M√¥ h√¨nh n√†y gi·ªëng v·ªõi ACL, ch·ªâ c√≥ 1 ƒëi·ªÉm kh√°c l√† subject c√≥ th·ªÉ chuy·ªÉn quy·ªÅn m√¨nh ƒëang c√≥ cho m·ªôt subject kh√°c\nM√¥ h√¨nh:\nSubject ƒë∆∞·ª£c quy·ªÅn ( action ) tr√™n object\rSubject g√°n quy·ªÅn (grant : action - object) cho Subject kh√°c\rV√≠ d·ª•: Alice c√≥ quy·ªÅn ƒë·ªçc, ghi, th·ª±c thi file Alice.sh\nAlice g√°n quy·ªÅn ƒë·ªçc file Alice.sh cho Bob\r·ª®ng d·ª•ng:\nPh√¢n quy·ªÅn file trong h·ªá ƒëi·ªÅu h√†nh\r...\rƒêi·ªÅu khi·ªÉn truy c·∫≠p theo vai - Role Based Access Control (RBAC) M√¥ h√¨nh c√≤n c√≥ t√™n g·ªçi kh√°c l√† Role Based Security, l√† m√¥ h√¨nh c·∫•p quy·ªÅn truy c·∫≠p d·ª±a v√†o danh s√°ch c√°c quy·ªÅn. Tuy nhi√™n, c√°c subject s·∫Ω ƒë∆∞·ª£c g√°n v√†o trong c√°c Role v√† ch√∫ng ta s·∫Ω c·∫•p quy·ªÅn cho c√°c role.\nM√¥ h√¨nh n√†y c√≥ th·ªÉ k·∫øt h·ª£p v·ªõi m√¥ h√¨nh DAC (ƒë·ªÉ tƒÉng kh·∫£ nƒÉng c·∫•p quy·ªÅn), ho·∫∑c MAC (ƒë·ªÉ tƒÉng t√≠nh b·∫£o m·∫≠t) m√† kh√¥ng xung ƒë·ªôt v·ªõi 2 m√¥ h√¨nh tr√™n.\nM√¥ h√¨nh:\nSubject thu·ªôc Roles\rRoles ƒë∆∞·ª£c quy·ªÅn ( action ) tr√™n object\r=\u0026gt; c√°c subject thu·ªôc Roles ƒë∆∞·ª£c quy·ªÅn (action) tr√™n object\rV√≠ d·ª•:\nAlice thu·ªôc Role NhanVienTuyenDung, NhanVienIT\nRole NhanVienTuyenDung c√≥ quy·ªÅn read, execute file\nRole NhanVienIT c√≥ quy·ªÅn write file\n=\u0026gt; Alice c√≥ quy·ªÅn read, write, execute file\n·ª®ng d·ª•ng:\nC√≥ r·∫•t nhi·ªÅu ·ª©ng d·ª•ng c·ªßa m√¥ h√¨nh n√†y, v√≠ d·ª• c√°c forum m√£ ngu·ªìn m·ªü, c·∫•p quy·ªÅn trong h·ªá ƒëi·ªÅu h√†nh ....\rƒê·ªÉ t√¨m hi·ªÉu k·ªπ h∆°n v·ªÅ m√¥ h√¨nh RBAC, c√°c b·∫°n c√≥ th·ªÉ ƒë·ªçc quy·ªÉn s√°ch tham kh·∫£o ·ªü d∆∞·ªõi\nTham kh·∫£o :\nDavid F. Ferraiolo; D. Richard Kuhn; Ramaswamy Chandramouli (2007). Role-based Access Control (2nd ed.). Artech House. ISBN 978-1-59693-113-8.\rhttps://en.wikipedia.org/wiki/Role-based_access_control\rƒêi·ªÅu khi·ªÉn truy c·∫≠p theo thu·ªôc t√≠nh - Attribute Based Access Control (ABAC) M√¥ h√¨nh c√≤n c√≥ t√™n g·ªçi kh√°c l√† Policy Based Access Control ho·∫∑c Claims Based Access Control (CBAC), l√† m√¥ h√¨nh c·∫•p quy·ªÅn truy c·∫≠p d·ª±a v√†o danh s√°ch c√°c quy·ªÅn k·∫øt h·ª£p v·ªõi c√°c thu·ªôc t√≠nh.\nKi·∫øn tr√∫c: Theo NIST ƒë·ªÅ xu·∫•t, ki·∫øn tr√∫c c·ªßa ABAC n√™n c√≥ c√°c th√†nh ph·∫ßn sau:\n- Policy Enforcement Point PEP: ch·ªãu tr√°ch nhi·ªám ph√¢n t√≠ch c√°c y√™u c·∫ßu truy xu·∫•t v√† g·ª≠i ƒë·∫øn PDP ƒë·ªÉ ch·ª©ng th·ª±c.\r- Policy Decision Point PDP: nh·∫≠n th√¥ng tin t·ª´ PEP v√† ch·ªãu tr√°ch nhi·ªám ch·ª©ng th·ª±c y√™u c·∫ßu c√≥ quy·ªÅn truy xu·∫•t t·ªõi c√°c t√†i nguy√™n hay kh√¥ng, tr·∫£ v·ªÅ ƒë·ªìng √Ω ho·∫∑c t·ª´ ch·ªëi. N·∫øu thi·∫øu t√¥ng tin th√¨\r- Policy Information Point PIP: tr·∫£ v·ªÅ c√°c attribute m√† PDP y√™u c·∫ßu.\rThu·ªôc t√≠nh: B·∫•t k·ªÉ th·ª© g√¨ tr√™n ƒë·ªùi n√†y ƒë·ªÅu c√≥ th·ªÉ l√† thu·ªôc t√≠nh. Tuy nhi√™n, ch√∫ng s·∫Ω th∆∞·ªùng ƒë∆∞·ª£c ph√¢n l√†m 4 nh√≥m ch√≠nh sau:\n- Subject attributes: C√°c thu·ªôc t√≠nh v·ªÅ th√¥ng tin ng∆∞·ªùi d√πng, v√≠ d·ª• h·ªç t√™n, ng√†y th√°ng nƒÉm sinh, qu√™ qu√°n, qu·ªëc t·ªãch, ƒë·ªãa ch·ªâ, ph√≤ng ban, ch·ª©c v·ª•, t√™n c√¥ng vi·ªác, s·ªë cmnd, ....\r- Action attributes: C√°c thu·ªôc t√≠nh v·ªÅ h√†nh ƒë·ªông nh∆∞ ch·∫°y , n·∫£y, xo√°, th√™m, ƒë·ªçc, ghi ...\r- Object attributes: C√°c thu·ªôc t√≠nh v·ªÅ th√¥ng tin c·ªßa ƒë·ªëi t∆∞·ª£ng mu·ªën truy xu·∫•t, v√≠ d·ª• nh∆∞ lo·∫°i file, ph·∫ßn ƒëu√¥i m·ªü r·ªông, v·ªã tr√≠, ....\r- Contextual (environment) attributes: C√°c thu·ªôc t√≠nh li√™n quan ƒë·∫øn k·ªãch b·∫£n di·ªÖn ra. V√≠ d·ª• h·ªá ƒëi·ªÅu h√†nh, ram, cpu, th·ªùi gian, m√∫i gi·ªù, ...\rV√≠ d·ª•:\nTo√†n b·ªô nh√¢n vi√™n kh√¥ng ƒë∆∞·ª£c truy xu·∫•t database sau 21h ƒë√™m\rNh√¢n vi√™n Nguy·ªÖn Th·ªã L·ª•a c·ªßa GHN ƒë∆∞·ª£c quy·ªÅn ƒë·ªï danh s√°ch freelancer ·ªü H√† N·ªôi, H·∫£i Ph√≤ng, H∆∞ng Y√™n\r·ª®ng d·ª•ng:\nC√≥ th·ªÉ ·ª©ng d·ª•ng ABAC v√†o r·∫•t nhi·ªÅu ·ª©ng d·ª•ng kh√°c nhau ƒë·ªÉ ki·ªÉm so√°t lu·ªìng truy c·∫≠p t√†i nguy√™n c·ªßa h·ªá th·ªëng. Tuy nhi√™n, vi·ªác x√¢y d·ª±ng m√¥ h√¨nh ACBA kh√° t·ªën k√©m v·ªÅ t√†i nguy√™n v√† ƒë√≤i h·ªèi ng∆∞·ªùi qu·∫£n l√Ω ph·∫£i c√≥ t∆∞ duy h·ªá th·ªëng v·ªØng ch·∫Øc\rƒê·ªÉ t√¨m hi·ªÉu k·ªπ h∆°n v·ªÅ m√¥ h√¨nh ABAC, c√°c b·∫°n c√≥ th·ªÉ ƒë·ªçc quy·ªÉn s√°ch tham kh·∫£o ·ªü d∆∞·ªõi\nTham kh·∫£o :\nhttps://nvlpubs.nist.gov/nistpubs/specialpublications/NIST.SP.800-162.pdf\rhttps://arxiv.org/pdf/1306.2401.pdf\rhttps://en.wikipedia.org/wiki/Attribute-based_access_control\rC·∫£m ∆°n c√°c b·∫°n ƒë√£ ch√∫ √Ω quan t√¢m theo d√µi. Xin ch√†o v√† h·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Jul 2, 2021","img":"https://unsplash.it/1920/1080?image=33","permalink":"/blog/2021-07-02-mo-hinh-phan-quyen/","series":null,"tags":["ACL","mac","dac","rbac","abac"],"title":"M√¥ H√¨nh Ph√¢n Quy·ªÅn - Access Control"},{"categories":null,"content":" Gi·ªõi thi·ªáu Y√™u c·∫ßu Gi·ªõi thi·ªáu Microsoft ƒë√£ tr√¨nh l√†ng phi√™n b·∫£n WLS 2 v·ªõi nhi·ªÅu ƒëi·ªÉm c·∫£i ti·∫øn n·ªïi tr·ªôi. Trong b√†i vi·∫øt n√†y, m√¨nh s·∫Ω h∆∞·ªõng d·∫´n c√°c b·∫°n c√†i ƒë·∫∑t wls 2 v√† upgrade c√°c distro linux c·ªßa m√¨nh x√†i WLS 2. M√¨nh c√≥ m·ªôt l∆∞u √Ω nh·ªè l√† n·∫øu c√°c distro linux c·ªßa b·∫°n kh√¥ng b·ªã r√†ng g√¨ th√¨ c√°c b·∫°n n√™n x√≥a c√°c linux distro hi·ªán t·∫°i v√† c√†i m·ªõi l·∫°i linux. V√¨ qu√° tr√¨nh upgrade ch·∫°y r·∫•t l√† l√¢u.\nY√™u c·∫ßu ƒê·ªÉ c√†i ƒë·∫∑t WLS 2, C√°c b·∫°n b·∫Øc bu·ªôc ph·∫£i n√¢ng c·∫•p l√™n c√°c phi√™n b·∫£n \u0026ldquo;Windows 10 May 2020 (2004), Windows 10 May 2019 (1903), or Windows 10 November 2019 (1909)\u0026rdquo; ho·∫∑c c√°c b·∫£n c·∫≠p nh·∫≠t sau ƒë√≥.\nƒê·ªÇ x√°c ƒë·ªãnh xem m√°y b·∫°n ƒëang x√†i phi√™n b·∫£n bao nhi√™u, b·∫°n n√£y g√µ m·ªü cmd l√™n v√† g√µ l·ªánh\n1systeminfo | findstr \u0026#34;OS\u0026#34; 2 3------ 4 5OS Name: Microsoft Windows 10 Home Single Language 6OS Version: 10.0.19043 N/A Build 19043 7OS Manufacturer: Microsoft Corporation 8OS Configuration: Standalone Workstation 9OS Build Type: Multiprocessor Free 10BIOS Version: American Megatrends Inc. S551LN.209, 7/8/2014 N·∫øu th·ªèa m√£n c√°c ƒëi·ªÅu ki·ªán tr√™n, th√¨ c√°c b∆∞·ªõc ch√∫ng ta ph·∫£i l√†m l√†:\n1dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 2 3------ 4 5Deployment Image Servicing and Management tool 6Version: 10.0.19041.844 7 8Image Version: 10.0.19043.1023 9 10Enabling feature(s) 11[==========================100.0%==========================] 12The operation completed successfully. Ti·∫øp theo, ch√∫ng ta ch·∫°y l·ªánh\n1 2 3dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 4 5---------- 6 7Deployment Image Servicing and Management tool 8Version: 10.0.19041.844 9 10Image Version: 10.0.19043.1023 11 12Enabling feature(s) 13[==========================100.0%==========================] 14The operation completed successfully. Sau ƒë√≥, b·∫°n ph·∫£i kh·ªüi ƒë·ªông l·∫°i m√°y ƒë·ªÉ window ti·∫øn h√†nh c·∫≠p nh·∫≠t c√°c g√≥i th∆∞ vi·ªán c·∫ßn thi·∫øt.\nSau khi kh·ªüi ƒë·ªông l·∫°i m√°y xong, ch√∫ng ta s·∫Ω g·ªçi l·ªánh set phi√™n b·∫£n m·∫∑c ƒë·ªãnh c·ªßa wsl l√† b·∫£n 2 b·∫±ng l·ªánh:\n1 2wsl --set-default-version 2 Sau khi ch·∫°y l·ªánh n√†y, s·∫Ω c√≥ 1 trong 2 tr∆∞·ªùng h·ª£p x·∫£y ra. Tr∆∞·ªùng h·ª£p 1\n1For information on key differences with WSL 2 please visit https://aka.ms/wsl2 Th√¨ ch√∫c m·ª´ng b·∫°n, b·∫°n ƒë√£ enable th√†nh c√¥ng WSL 2\nTr∆∞·ªùng h·ª£p th·ª© 2, b·∫°n s·∫Ω g·∫∑p output nh∆∞ th·∫ø n√†y:\n1WSL 2 requires an update to its kernel component. For information please visit https://aka.ms/wsl2kernel. Th√¨ b·∫°n n√†y v√†o trang https://aka.ms/wsl2kernel nh∆∞ h∆∞·ªõng d·∫´n, ƒë·ªçc k·ªπ file, down v·ªÅ file msi ƒë·ªÉ c√†i Linux kernel v√†o. Sau ƒë√≥ ch·∫°y l·∫°i l·ªánh \u0026ldquo;wsl \u0026ndash;set-default-version 2\u0026rdquo;\nSau ƒë√≥, c√°c b·∫°n ti·∫øn h√†nh check l·∫°i phi√™n b·∫£n linux m√¨nh ƒëang s·ª≠ d·ª•ng\n1 2 wsl --list --verbose 3 4 ----- 5 6 NAME STATE VERSION 7* Ubuntu-18.04 Running 1 8 kali-linux Stopped 1 Nh∆∞ c√°c b·∫°n th·∫•y ·ªü tr√™n, b·∫£n ubuntu 18.4 m√¨nh ƒëang s·ª≠ d·ª•ng ƒëang ·ªü version 1. M√¨nh s·∫Ω convert qua version 2 b·∫±ng l·ªánh\n1 2wsl --set-version Ubuntu-18.04 2 3 4------- 5Conversion in progress, this may take a few minutes... 6For information on key differences with WSL 2 please visit https://aka.ms/wsl2 Sau khi ch·∫°y d√≤ng l·ªánh tr√™n, c√°c b·∫°n ch·ªãu kh√≥ ng·ªìi ch·ªù m·ªôt x√≠u, n√≥ ph·ª• thu·ªôc v√†o c·∫•u h√¨nh m√°y c·ªßa c√°c b·∫°n. Kinh nghi·ªám c·ªßa m√¨nh khi upgrade v√†i m√°y l√† n√™n t·∫Øt ch∆∞∆°ng tr√¨nh di·ªát virus nh∆∞ kaspersky, norton, BKAV, bit \u0026hellip;. ƒëi. T·∫Øt nh·ªØng ·ª©ng d·ª•ng s·ª≠ d·ª•ng nhi·ªÅu ram th√¨ vi·ªác convert s·∫Ω ch·∫°y nhanh h∆°n m·ªôt ch√∫t.\nK·∫øt qu·∫£ sau khi m√¨nh convert.\n1 2 NAME STATE VERSION 3* Ubuntu-18.04 Stopped 2 4 kali-linux Stopped 1 C·∫£m ∆°n c√°c b·∫°n ƒë√£ ch√∫ √Ω theo d√µi. H·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\nLink h∆∞·ªõng d·∫´n g·ªëc t·ª´ trang ch·ªß microsoft\nhttps://docs.microsoft.com/en-us/windows/wsl/install-win10\n","date":"May 30, 2021","img":"https://unsplash.it/1920/1080?image=34","permalink":"/blog/2021-05-30-upgrade-wls-to-wls2/","series":null,"tags":["wls2"],"title":"N√¢ng C·∫•p WSL L√™n B·∫£n WSL 2 Tr√™n Window 10"},{"categories":null,"content":" Gi·ªõi thi·ªáu B·∫Øt ƒë·∫ßu Ti·∫øn h√†nh turning Gi·ªõi thi·ªáu Trong qu√° tr√¨nh gi·∫£i c√°c b√†i to√°n c√≥ s·ª≠ d·ª•ng machine learning, v√¨ ƒë·ªÉ l√†m nhanh n√™n ƒë√¥i khi m√¨nh s·∫Ω s·ª≠ d·ª•ng c√°c tham s·ªë m·∫∑c ƒë·ªãnh c·ªßa m√¥ h√¨nh ƒë·ªÉ train. M·ªôt ph·∫ßn v√¨ l√Ω do ch√∫ng ta kh√¥ng bi·∫øt c√°ch ch·ªânh c√°c tham s√≥ nh∆∞ th·∫ø n√†o, so v·ªõi c√°i g√¨ ƒë·ªÉ c√≥ m√¥ h√¨nh hu·∫•n luy·ªán l√† t·ªët nh·∫•t. ·ªû b√†i vi·∫øt n√†y, m√¨nh s·∫Ω s·ª≠ d·ª•ng Learning Curves ƒë·ªÉ t·ªëi ∆∞u h√≥a c√°c tham s·ªë c·ªßa XGBoost. C√°c m√¥ h√¨nh kh√°c c≈©ng l√†m t∆∞∆°ng t·ª± th√¥i. M√¨nh ch·ªçn XGBoost v√¨ m√¥ h√¨nh n√†y th∆∞·ªùng cho k·∫øt qu·∫£ kh√° t·ªët tr√™n c√°c cu·ªôc thi ·ªü Kaggle.\nB·∫Øt ƒë·∫ßu ƒê·ªÉ b·∫Øt ƒë·∫ßu th√≠ nghi·ªám, ch√∫ng ta s·∫Ω sinh ng·∫´u nhi√™n 60 ng√†n d·ªØ li·ªáu c√≥ 1 ng√†n thu·ªôc t√≠nh b·∫±ng c√°ch s·ª≠ d·ª•ng h√†m make_classification, sau ƒë√≥ s·∫Ω chia d·ªØ li·ªáu th√†nh 2 t·∫≠p train v√† test v·ªõi t·ª∑ l·ªá 10% l√† t·∫≠p test\n1X, y = make_classification(n_samples=60000, n_features=1000, n_informative=50, n_redundant=0, random_state=1) 2# split data into train and test sets 3X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1) Load m√¥ h√¨nh XGBClassifier v·ªõi c√°c tham s·ªë l√† m·∫∑c ƒë·ªãnh. M√¥ h√¨nh n√†y ƒë∆∞·ª£c xem nh∆∞ l√† baseline v√† c√°c c·∫£i ti·∫øn tham s·ªë ·ªü sau s·∫Ω so s√°nh k·∫øt qu·∫£ tr√™n m√¥ h√¨nh n√†y.\n1 2 3model = XGBClassifier() 4 5evalset = [(X_train, y_train), (X_test, y_test)] 6 7model.fit(X_train, y_train, eval_metric=\u0026#39;logloss\u0026#39;, eval_set=evalset) 8# evaluate performance 9yhat = model.predict(X_test) 10score = accuracy_score(y_test, yhat) 11print(\u0026#39;Accuracy: %.3f\u0026#39; % score) 12# retrieve performance metrics 13results = model.evals_result() 14# plot learning curves 15pyplot.plot(results[\u0026#39;validation_0\u0026#39;][\u0026#39;logloss\u0026#39;], label=\u0026#39;train\u0026#39;) 16pyplot.plot(results[\u0026#39;validation_1\u0026#39;][\u0026#39;logloss\u0026#39;], label=\u0026#39;test\u0026#39;) 17# show the legend 18pyplot.legend() 19# show the plot 20pyplot.show() ƒê·ªô ch√≠nh x√°c: Accuracy: 0.962. L∆∞u √Ω r√†ng ƒë·ªô ch√≠nh x√°c khi th·ª±c nghi·ªám c·ªßa m·ªói l·∫ßn ch·∫°y s·∫Ω kh√°c nhau, do data sinh ng·∫´u nhi√™n v√† m·ªôt ph·∫ßn do s·ª± ng·∫´u nhi√™n trong XGBoost.\nNh√¨n v√†o h√¨nh tr√™n, ch√∫ng ta th·∫•y r·∫±ng ƒë∆∞·ªùng cong c·ªßa t·∫≠p train (ƒë∆∞·ªùng m√†u xanh) c√≥ ƒë·ªô l·ªói t·ªët h∆°n so v·ªõi ƒë∆∞·ªùng cong c·ªßa t·∫≠p test( ƒë∆∞·ªùng m√†u ƒë·ªè)\nTi·∫øn h√†nh turning ƒê·∫ßu ti√™n, nh√¨n v√†o ƒë·ªì th·ªã, ta th·∫•y r·∫±ng ƒë∆∞·ªùng cong v·∫´n c√≤n c√≥ ƒë·ªô d·ªëc, n√™n vi·ªác tƒÉng s·ªë l·∫ßn l·∫∑p c√≥ th·ªÉ s·∫Ω l√†m tƒÉng th√™m ƒë·ªô ch√≠nh x√°c, th·ª≠ thay ƒë·ªïi s·ªë l·∫ßn l·∫∑p l√™n 500 xem sao.\nTrong XGBoost s·ªë l·∫ßn l·∫∑p ƒë∆∞·ª£c tham s·ªë h√≥a b·ªüi tham s·ªë n_estimators, ch·ªânh l·∫°i ƒëo·∫°n m√£ l·ªánh ·ªü tr√™n v·ªõi m·ªôt thay ƒë·ªïi nh·ªè r·ªìi ch·∫°y l·∫°i\n1 2model = XGBClassifier(n_estimators=500) ƒê·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh tƒÉng l√™n 1 ch√∫t, ƒë·ªëi v·ªõi th·ª±c nghi·ªám c·ªßa m√¨nh l√† Accuracy: 0.981\nQuan s√°t ƒë∆∞·ªùng cong c·ªßa h√¨nh tr√™n, ta th·∫•y ph·∫ßn ƒëu√¥i ƒëo·∫°n s·ªë l·∫ßn l·∫∑p t·ª´ 270 ƒë·∫øn 500 c√≥ ƒë·ªô d·ªëc nh·ªè, h·∫ßu nh∆∞ l√† b·∫±ng ph·∫≥ng, c√≥ th·ªÉ k·∫øt lu·∫≠n l√† vi·ªác hu·∫•n luy·ªán ·ªü ƒëo·∫°n n√†y h·∫ßu nh∆∞ kh√¥ng c·∫£i ti·∫øn g√¨ nhi·ªÅu.\nM·ªôt nh·∫≠n x√©t n·ªØa l√† ƒëo·∫°n tr∆∞·ªõc 150 c√≥ ƒë·ªô d·ªëc kh√° l·ªõn, c√≥ kh·∫£ nƒÉng l√† h·ªá s·ªë h·ªçc (learning reate) qu√° l·ªõn, l√†m cho m√¥ h√¨nh ch∆∞a ƒë·∫°t ƒë∆∞·ª£c c·ª±c ti·ªÉu, th·ª≠ ƒëi·ªÅu ch·ªânh h·ªá s·ªë h·ªçc n√†y nh·ªè h∆°n l√† 0.01, thay v√¨ 0.3 nh∆∞ gi√° tr·ªã m·∫∑c ƒë·ªãnh xem sao.\nM·ªôt l∆∞u √Ω l√† h·ªá s·ªë h·ªçc nh·ªè th√¨ s·∫Ω l√¢u h·ªôi t·ª•, n√™n ch√∫ng ta ph·∫£i tƒÉng s·ªë l·∫ßn l·∫∑p l√™n. ·ªû ƒë√¢y ƒë·ªìng th·ªùi v·ªõi vi·ªác gi·∫£m h·ªá s·ªë h·ªçc xu·ªëng 0.01, m√¨nh c√≤n tƒÉng s·ªë l·∫ßn l·∫∑p l√™n 1000.\nTrong XGBoost h·ªá s·ªë h·ªçc ƒë∆∞·ª£c tham s·ªë h√≥a b·ªüi tham s·ªë eta\n1 2model = XGBClassifier(n_estimators=1000, eta=0.01) ƒê·ªô ch√≠nh x√°c ƒë·∫°t ƒë∆∞·ª£c: Accuracy: 0.954\nTuy m√¥ h√¨nh c√≥ ƒë·ªô ch√≠nh x√°c gi·∫£m, nh∆∞ng nh√¨n v√†o ƒë·ªì th·ªã th√¨ ta th·∫•y m√¥ h√¨nh v·∫´n c√≤n ƒë·ªô d·ªëc, nghƒ©a l√† m√¥ h√¨nh s·∫Ω cho k·∫øt qu·∫£ t·ªët h∆°n n·ªØa n·∫øu ta tƒÉng s·ªë v√≤ng l·∫∑p.\nM·ªôt c√°ch kh√°ch l√† thay ƒë·ªïi c√°c chu·∫©n h√≥a (regularization ) b·∫±ng c√°ch gi·∫£m c√°c tham s·ªë s·ªë m·∫´u ( samples) v√† s·ªë ƒë·∫∑c tr∆∞ng (features) ƒë∆∞·ª£c d√πng ƒë·ªÉ x√¢y d·ª±ng c√¢y trong t·∫≠p h·ª£p. Hai tham s·ªë n√†y ƒë∆∞·ª£c tham s·ªë h√≥a b·ªüi tham s·ªë subsample v√† colsample_bytree. Gi√° tr·ªã m·∫∑c ƒë·ªãnh c·ªßa ch√∫ng l√† 1. Ch√∫ng ta s·∫Ω thay ƒë·ªïi th√†nh 0.35 xem sao nh√©\n1 2model = XGBClassifier(n_estimators=5000, eta=0.01, subsample=0.35, colsample_bytree=0.35) K·∫øt qu·∫£ Accuracy: 0.970 ·ªû hai l·∫ßn th√≠ nghi·ªám tr√™n, m√¨nh c√≥ c√°c h∆∞·ªõng x·ª≠ l√Ω c√≥ th·ªÉ ƒëi ti·∫øp, m·ªôt l√† tƒÉng s·ªë l·∫ßn l·∫∑p l√™n, v√¨ ƒë·ªô d·ªëc c·ªßa m√¥ h√¨nh v·∫´n c√≤n, n√™n ch√∫ng ta ho√†n to√†n c√≥ th·ªÉ thu ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªët h∆°n. M·ªôt c√°ch kh√°c l√† tƒÉng learning rate l√™n ƒë·ªÉ qu√° tr√¨nh h·ªôi t·ª• ƒë∆∞·ª£c x·∫£y ra nhanh h∆°n, v√≠ d·ª• ƒë·ªÉ eta = 0.05 ho·∫∑c 0.75 ch·∫≥n h·∫°n.\nQu√° tr√¨nh n√†y c√≥ th·ªÉ ti·∫øp t·ª•c, d·ª±a v√†o quan s√°t c·ªßa c√°c b·∫°n tr√™n ƒë∆∞·ªùng cong v√† h∆°n h·∫øt l√† s·ª± hi·ªáu bi·∫øt th·∫•u ƒë√°o c·ªßa c√°c b·∫°n tr√™n c√°c tham s·ªë m√† m√¥ h√¨nh c·ªßa b·∫°n ƒëang s·ª≠ d·ª•ng. Ch√∫c c√°c b·∫°n s·∫Ω c√≥ m·ªôt h∆∞·ªõng ƒëi t·ªët ƒë·ªÉ gi·∫£m thi·ªÉu th·ªùi gian m√≤ m·∫´m.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ ch√∫ √Ω theo d√µi. H·∫πn g·∫∑p l·∫°i ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\nNgu·ªìn tham kh·∫£o\nhttps://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\nhttps://machinelearningmastery.com/tune-xgboost-performance-with-learning-curves/\nhttps://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\n","date":"Apr 11, 2021","img":"https://unsplash.it/1920/1080?image=35","permalink":"/blog/2021-04-11-xgboost_learning_curves/","series":null,"tags":["Machine Learning","XGBoost"],"title":"Tinh Ch·ªânh Thu·∫≠t To√°n XGBoost  V·ªõi Learning Curves"},{"categories":null,"content":" Gi·ªõi thi·ªáu SGD - Stochastic Gradient Descent Adam - Adaptive Moment Estimation AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients K·∫øt lu·∫≠n Gi·ªõi thi·ªáu Hi c√°c b·∫°n, l·∫°i l√† m√¨nh ƒë√¢y, h√¥m nay m√¨nh s·∫Ω c√πng c√°c b·∫°n t√¨m hi·ªÉu thu·∫≠t to√°n t·ªëi ∆∞u h√≥a AdaBelief. Thu·∫≠t to√°n n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ thay cho thu·∫≠t to√°n Adam optimizer m√† c√°c b·∫°n hi·ªán ƒëang x√†i ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh Deep learning. N√†o, ch√∫ng ta c√πng b·∫Øt ƒë·∫ßu t√¨m hi·ªÉu nh√©.\n·∫®n s√¢u b√™n trong c√°c thu·∫≠t to√°n s·ª≠ d·ª•ng Neural Network v√† m·ªôt v√†i thu·∫≠t to√°n machine learning ƒë·ªÅu s·ª≠ d·ª•ng c√°c h√†m t·ªëi ∆∞u h√≥a. Ch√∫ng ta c√≥ th·ªÉ li·ªát k√™ ra m·ªôt v√†i c√°i t√™n nh∆∞ RMSprop, SGD (Stochastic Gradient Descent), Adam (Adaptive Moment Estimation).\nM·ªôt v√†i c√°c y·∫øu t·ªë hay ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° m·ªôt thu·∫≠t to√°n optimizer:\nH·ªôi t·ª• nhanh (trong qu√° tr√¨nh train)\nS·ª± t·ªïng qu√°t h√≥a cao (v·∫´n nh·∫≠n d·∫°ng ƒë∆∞·ª£c nh·ªØng m·∫´u ch∆∞a t·ª´ng ƒë∆∞·ª£c hu·∫•n luy·ªán)\nƒê·ªô ch√≠nh x√°c cao\nC√°c thu·∫≠t to√°n t·ªëi ∆∞u thu·ªôc h·ªç Adaptive th∆∞·ªùng c√≥ t·ªëc ƒë·ªô h·ªôi t·ª• nhanh. Trong khi ƒë√≥, c√°c thu·∫≠t to√°n thu·ªôc h·ªç SGD th∆∞·ªùng c√≥ s·ª± t·ªïng qu√°t h√≥a cao. G·∫ßn ƒë√¢y, Juntang Zhuang v√† c√°c c·ªông s·ª± thu·ªôc ƒë·∫°i h·ªçc Yale ƒë√£ nghi√™n c·ª©u v√† t·∫°o ra thu·∫≠t to√°n AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients. Thu·∫≠t to√°n n√†y theo l·ªùi t√°c gi·∫£, h·ªôi t·ª• c·∫£ hai ∆∞u ƒëi·ªÉm c·ªßa h·ªç Adaptive v√† SGD, l√† v·ª´a c√≥ t·ªëc ƒë·ªô h·ªôi t·ª• nhanh, v·ª´a c√≥ t√≠nh t·ªïng qu√°t h√≥a cao M√£ ngu·ªìn ƒë∆∞·ª£c t√°c gi·∫£ c√¥ng b·ªë ·ªü link https://github.com/juntang-zhuang/Adabelief-Optimizer.\nL·ªùi c·ªßa t√°c gi·∫£:\nWe propose the AdaBelief optimizer, which adaptively scales the stepsize by the difference betweenpredicted gradient and observed gradient. To our knowledge, AdaBelief is the first optimizer toachieve three goals simultaneously: fast convergence as in adaptive methods, good generalization asin SGD, and training stability in complex settings such as GANs. Furthermore, Adabelief has the same parameters as Adam, hence is easy to tune. We validate the benefits of AdaBelief with intuitive examples, theoretical convergence analysis in both convex and non-convex cases, and extensiveexperiments on real-world datasets\nƒê·ªÉ hi·ªÉu v·ªÅ AdaBelief, tr∆∞·ªõc ti√™n, ch√∫ng ta ph·∫£i c√≥ m·ªôt √≠t ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ SGD v√† Adam, n√™n ch√∫ng ta s·∫Ω b·∫Øt ƒë·∫ßu n√≥i v·ªÅ SGD tr∆∞·ªõc\nSGD - Stochastic Gradient Descent Thu·∫≠t to√°n SGD l√† thu·∫≠t to√°n t·ªëi ∆∞u h√≥a c∆° b·∫£n theo h·ªç gradient. Thu·∫≠t to√°n n√†y r·∫•t tri·ªÉn khai, c√≥ n·ªÅn t·∫£ng l√Ω thuy·∫øt v·ªØng ch·∫Øc, c·ª±c k·ª≥ ·ªïn ƒë·ªãnh trong qu√° tr√¨nh hu·∫•n luy·ªán, k·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c c√≥ th·ªÉ so s√°nh v·ªõi c√°c thu·∫≠t to√°n kh√°c. √ù t∆∞·ªüng c·ªßa thu·∫≠t to√°n kh√° ƒë∆°n gi·∫£n, ƒë√≥ l√† \u0026ldquo;t√≠nh gi√° tr·ªã gradient c·ªßa m·ªói tham s·ªë, v√† ƒëi m·ªôt b∆∞·ªõc nh·ªè theo chi·ªÅu c·ªßa gradient\u0026rdquo;. N·∫øu ch√∫ng ta l·∫∑p ƒëi l·∫∑p l·∫°i qu√° tr√¨nh n√†y, v√† ng·∫´u nhi√™n ch·ªçn (stochastic) m·ªôt t·∫≠p batch trong t·∫≠p hu·∫•n luy·ªán, m√¥ h√¨nh ch√∫ng ta s·∫Ω ƒë∆∞·ª£c c·∫£i ti·∫øn d·∫ßn ƒë·∫øn ƒë·ªÉm h·ªôi t·ª•.\nTrong qu√° kh·ª©, ph·∫ßn kh√≥ nh·∫•t c·ªßa SGD l√† vi·ªác t√≠nh l·∫°i gi√° tr·ªã gradient cho to√†n b·ªô c√°c tham s·ªë trong m√¥ h√¨nh. Nh∆∞ng hi·ªán nay, c√°c framwork m√°y h·ªçc nh∆∞ Tensorflow, PyTouch, Caffee, Theano, \u0026hellip;. ƒë√£ gi√∫p ch√∫ng ta t√≠nh c√°c gi√° tr·ªã gradient m·ªôt c√°ch t·ª± ƒë·ªông. Do ƒë√≥, c√¥ng vi·ªác c·ªßa ch√∫ng ta hi·ªán th·ªùi ƒë∆°n gi·∫£n h∆°n\n$$for \\text{ } i \\text{ } in \\text{ } range (m): $$ $$\\theta_i = \\theta_i - \\alpha ( \\hat y^{i} - y^i) x^i_j$$\nM·ªôt v·∫•n ƒë·ªÅ ch√∫ng ta g·∫∑p ph·∫£i trong qu√° tr√¨nh hu·∫•n luy·ªán DL v·ªõi SGD l√† ch·∫≠m, si√™u ch·∫≠m. Do thu·∫≠t to√°n ph·∫£i c·∫≠p nh·∫≠t to√†n b·ªô c√°c tham s·ªë, n√™n s·ªë l∆∞·ª£ng ph√©p t√≠nh v√† l∆∞·ª£ng t√†i nguy√™n ph·∫ßn c·ª©ng ƒë∆∞·ª£c s·ª≠ d·ª•ng r·∫•t l√† nhi·ªÅu. R·∫•t nhi·ªÅu c√°c bi·∫øn th·ªÉ c·ªßa SGD ƒë√£ ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ tr√™n.\nAdam - Adaptive Moment Estimation Adam optimizer l√† m·ªôt thu·∫≠t to√°n k·∫øt h·ª£p k·ªπ thu·∫≠t c·ªßa RMS prop v√† momentum. Thu·∫≠t to√°n s·ª≠ d·ª•ng hai internal states momentum (m) v√† squared momentum (v) c·ªßa gradient cho c√°c tham s·ªë. Sau m·ªói batch hu·∫•n luy·ªán, gi√° tr·ªã c·ªßa m v√† v ƒë∆∞·ª£c c·∫≠p nh·∫≠t l·∫°i s·ª≠ d·ª•ng exponential weighted averaging.\nM√£ gi·∫£i c·ªßa vi·ªác c·∫≠p nh·∫≠t m v√† v\n$$m_t = \\beta_1m_t-_1 + (1-\\beta_1)g_t $$ $$v_t = \\beta_2v_t-_1 + (1-\\beta_2)g^2_t$$\ntrong ƒë√≥, beta ƒë∆∞·ª£c xem nh∆∞ l√† m·ªôt si√™u tham s·ªë. C√¥ng th·ª©c c·∫≠p nh·∫≠t theta nh∆∞ sau:\n$$\\theta_t = \\theta_t-_1 - \\alpha\\frac{m_t}{\\sqrt{v_t}+ \\epsilon }$$\ntrong ƒë√≥, alpha l√† learning rate, epsion l√† gi√° tr·ªã ƒë∆∞·ª£c th√™m v√†o ƒë·ªÉ ngƒÉng vi·ªác chia cho 0\nƒê·ªÉ vi·ªác descent ƒë∆∞·ª£c th·ª±c hi·ªán nhanh h∆°n, thu·∫≠t to√°n ƒë√£ s·ª≠ d·ª•ng hai k·ªπ thu·∫≠t:\nT√≠nh exponential moving average c·ªßa gi√° tr·ªã ƒë·∫°o h√†m l∆∞u v√†o bi·∫øn m v√† s·ª≠ d·ª•ng n√≥ l√† t·ª≠ s·ªë c·ªßa vi·ªác c·∫≠p nh·∫≠t h∆∞·ªõng. V·ªõi √Ω nghƒ©a l√† n·∫øu m c√≥ gi√° tr·ªã l·ªõn, th√¨ vi·ªác descent ƒëang ƒëi ƒë√∫ng h∆∞·ªõng v√† ch√∫ng ta c·∫ßn b∆∞·ªõc nh·∫£y l·ªõn h∆°n ƒë·ªÉ ƒëi nhanh h∆°n. T∆∞∆°ng t·ª±, n·∫øu gi√° tr·ªã m nh·ªè, ph·∫ßn descent c√≥ th·ªÉ kh√¥ng ƒëi v·ªÅ h∆∞·ªõng t·ªëi ti·ªÉu v√† ch√∫ng ta n√™n ƒëi 1 b∆∞·ªõc nh·ªè ƒë·ªÉ thƒÉm d√≤. ƒê√¢y l√† ph·∫ßn momentum c·ªßa thu·∫≠t to√°n.\nT√≠nh exponential moving average c·ªßa b√¨nh ph∆∞∆°ng g√≠a tr·ªã ƒë·∫°o h√†m l∆∞u v√†o bi·∫øn v v√† s·ª≠ d·ª•ng n√≥ l√† ph·∫ßn m·∫´u s·ªë c·ªßa vi·ªác c·∫≠p nh·∫≠t h∆∞·ªõng. V·ªõi √Ω nghƒ©a nh∆∞ sau: Gi·∫£ s·ª≠ gradient mang c√°c gi√° tr·ªã d∆∞∆°ng, √¢m l·∫´n l·ªôn, th√¨ khi c·ªông c√°c gi√° tr·ªã l·∫°i theo c√¥ng th·ª©c t√≠nh m ta s·∫Ω ƒë∆∞·ª£c gi√° tr·ªã m g·∫ßn s·ªë 0. Do √¢m d∆∞∆°ng l·∫´n l·ªôn n√™n n√≥ b·ªã tri·ªát ti√™u l·∫´n nhau. Nh∆∞ng trong tr∆∞·ªùng h·ª£p n√†y th√¨ v s·∫Ω mang gi√° tr·ªã l·ªõn. Do ƒë√≥, trong tr∆∞·ªùng h·ª£p n√†y, ch√∫ng ta s·∫Ω kh√¥ng h∆∞·ªõng t·ªõi c·ª±c ti·ªÉu, ch√∫ng ta s·∫Ω kh√¥ng mu·ªën ƒëi theo h∆∞·ªõng ƒë·∫°o h√†m trong tr∆∞·ªùng h·ª£p n√†y. Ch√∫ng ta ƒë·ªÉ v ·ªü ph·∫ßn m·∫´u v√¨ khi chia cho m·ªôt gi√° tr·ªã cao, gi√° tr·ªã c·ªßa c√°c ph·∫ßn c·∫≠p nh·∫≠t s·∫Ω nh·ªè, v√† khi v c√≥ gi√° tr·ªã th·∫•p, ph·∫ßn c·∫≠p nh·∫≠t s·∫Ω l·ªõn. ƒê√¢y ch√≠nh l√† ph·∫ßn t·ªëi ∆∞u RMSProp c·ªßa thu·∫≠t to√°n.\n·ªû ƒë√¢y, m ƒë∆∞·ª£c xem nh∆∞ l√† moment th·ª© nh·∫•t, v xem nh∆∞ l√† moment th·ª© hai, n√™n thu·∫≠t to√°n c√≥ t√™n l√† \u0026ldquo;Adaptive moment estimation\u0026rdquo;.\nƒê·ªÉ l√Ω gi·∫£i v√¨ sao Adam l·∫°i h·ªôi t·ª• nhanh h∆°n so v·ªõi SGD, ch√∫ng ta c√≥ th·ªÉ gi·∫£i th√≠ch nh∆∞ sau: Exponential weighted averaging cho ch√∫ng ta gi√° tr·ªã x·∫•p x·ªâ gradient m∆∞·ª£t h∆°n qua m·ªói l·∫ßn l·∫∑p, d·∫´n t·ªõi tƒÉng t√≠nhs d·ª´ng. Sau ƒë√≥, vi·ªác chia cho cƒÉng b·∫≠c 2 c·ªßa gi√° tr·ªã v l√†m s·ªë l∆∞·ªõc c·ªßa ch√∫ng ta gi·∫£m m·∫°nh khi ph∆∞∆°ng sai c·ªßa gi√° tr·ªã gradient tƒÉng l√™n. ƒêi·ªÅu n√†y , nh∆∞ gi·∫£i th√≠ch ·ªü tr√™n, c√≥ nghƒ©a l√†, khi h∆∞·ªõng ƒëi c·ªßa m√¥ h√¨nh ch·ªâ ra kh√¥ng r√µ r√†ng, thu·∫≠t to√°n Adam th·ª±c hi·ªán c√°c b∆∞·ªõc ƒëi nh·ªè coi nh∆∞ l√† thƒÉm d√≤ th√¥i. V√† s·∫Ω th·ª±c hi·ªán c√°c b∆∞·ªõc ƒëi l·ªõn, nhanh khi h∆∞·ªõng ƒëi r√µ r√†ng.\nThu·∫≠t to√°n Adam ho·∫°t ƒë·ªông kh√° hi·ªáu qu·∫£, nh∆∞ng b·∫£n th√¢n n√≥ c≈©ng c√≥ nh·ªØng v·∫•n ƒë·ªÅ. T√°c gi·∫£ c·ªßa AdaBelief ƒë√£ ch·ªâ ra m·ªôt v√†i ƒëi·ªÉm kh√¥ng hi·ªáu qu·∫£ c·ªßa thu·∫≠t to√°n\nAdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients ![H√¨nh ·∫£nh AdaBelief - Ngu·ªìn https://arxiv.org/pdf/2010.07468v5.pdf ] (adam_error.jpg)\nH√£y nh√¨n v√†o h√¨nh tr√™n, ·ªü m·ª•c ƒë√°nh d·∫•u l√† s·ªë 3, gi√° tr·ªã G l·ªõn v√¨ ƒë∆∞·ªùng cong ·ªü ƒëo·∫°n ƒë√≥ d·ªëc. Gi√° tr·ªã v c≈©ng l·ªõn. Do ƒë√≥, n·∫øu s·ª≠ d·ª•ng thu·∫≠t to√°n Adam ·ªü ƒë√¢y, b∆∞·ªõc ƒëi s·∫Ω r·∫•t nh·ªè. Vi·ªác di chuy·ªÉn m·ªôt b∆∞·ªõc ƒëi nh·ªè ·ªü ƒë√¢y s·∫Ω l√†m ch·∫≠m qu√° tr√¨nh h·ªôi t·ª• v√† kh√¥ng c·∫ßn thi·∫øt. B·ªüi v√¨ ch√∫ng ta tin t∆∞·ªüng r·∫±ng ch√∫ng ta ƒëang ƒëi ƒë√∫ng h∆∞·ªõng, v√† ch√∫ng ta c·∫ßn m·ªôt b∆∞·ªõc ƒëi d√†i h∆°n.\nAdaBelief s·ª≠a l·ªói n√†y b·∫±ng m·ªôt thay ƒë·ªïi nh·ªè trong thu·∫≠t to√°n c·ªßa adam. Thay v√¨ t√≠nh b√¨nh ph∆∞∆°ng c·ªßa gradient, AdaBelief s·∫Ω t√≠nh ph∆∞∆°ng sai c·ªßa gradient. M·ªôt s·ª± thay ƒë·ªïi nh·ªè nh∆∞ng mang l·∫°i gi√° tr·ªã to l·ªõn.\n$$v_t = \\beta_2v_t-_1 + (1-\\beta_2)g^2_t $$ $$s_t = \\beta_2v_t-_1 + (1-\\beta_2)(g_t-m_t)^2$$\nT√°c gi·∫£ kh√¥ng d√πng bi·∫øn v n·ªØa, m√† thay b·∫±ng bi·∫øn s.\nV·ªõi vi·ªác d√πng bi·∫øn s. Trong tr∆∞·ªùng h·ª£p tr√™n, g l·ªõn v√† m l·ªõn, th√¨ s s·∫Ω nh·ªè. V√† khi s ·ªü ph·∫ßn m·∫´u nh·ªè, ch√∫ng ta s·∫Ω c√≥ b∆∞·ªõc ƒëi xa h∆°n. ·ªû ƒë√¢y, AdaBelief ƒë√£ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ\nQua ƒë√¢y, ch√∫ng ta c≈©ng c√≥ th·ªÉ gi·∫£i th√≠ch v√¨ sao c√≥ ch·ªØ \u0026ldquo;belief\u0026rdquo; trong t·ª´ AdaBelief. Gi√° tr·ªã ph∆∞∆°ng sai ƒë∆∞·ª£c t√≠nh d·ª±a v√†o k·ª≥ v·ªçng c·ªßa gi√° tr·ªã gradient.\nM·ªôt ch√∫ √Ω nh·ªè ·ªü ƒë√¢y l√† m·ª•c s·ªë 1 v√† m·ª•c s·ªë 3 ƒë∆∞·ª£c coi l√† c·∫£i ti·∫øn c·ªßa Adam so v·ªõi momentum v√† SGD. T·∫•t nhi√™n, AdaBelief c≈©ng k·∫ø th·ª´a m·∫•y c√°i n√†y.\n·ªû m·ª•c ƒë√°nh d·∫•u s·ªë 1 tr√™n h√¨nh, ƒë∆∞·ªùng cong kh√° ph·∫≥ng v√† gi√° tr·ªã ƒë·∫°o h√†m g·∫ßn nh∆∞ b·∫±ng 0. N·∫øu s·ª≠ d·ª•ng SGD, ch√∫ng ta s·∫Ω c√≥ m·ªôt b∆∞·ªõc ƒëi nh·ªè. Trong khi ƒë√≥, h·ªç Adam s·∫Ω cho ch√∫ng ta b∆∞·ªõc ƒëi l·ªõn h∆°n v√¨ gi√° tr·ªã cƒÉng b·∫≠c hai c·ªßa s ho·∫∑c v ·ªü m·∫´u s·ªë s·∫Ω cho ra m·ªôt k·∫øt qu·∫£ r·∫•t nh·ªè.\n·ªû m·ª•c ƒë√°nh d·∫•u s·ªë 2, ƒë∆∞·ªùng cong ·ªü ƒë√¢y r·∫•t d·ªëc v√† h·∫πp, g v√† delta g ·ªü ƒë√¢y r·∫•t l·ªõn, cho n√™n ·ªü ƒë√¢y ch√∫ng ta c·∫ßn m·ªôt b∆∞·ªõc di chuy·ªÉn nh·ªè. N·∫øu s·ª≠ d·ª•ng SGD ho·∫∑c momentum th√¨ s·∫Ω ƒëi m·ªôt b∆∞·ªõc ƒëi r·∫•t l·ªõn do nh√¢n v·ªõi m·ªôt l∆∞·ª£ng moving averages l·ªõn. Trong khi ƒë√≥, v·ªõi Adam ho·∫∑c AdaBelief, ch√∫ng ta s·∫Ω c√≥ gi√° tr·ªã cƒÉng b·∫≠c hai c·ªßa s ho·∫∑c v ·ªü m·∫´u s·ªë l·ªõn n√™n b∆∞·ªõc ƒëi s·∫Ω nh·ªè h∆°n.\nV·ªÅ t·ªëc ƒë·ªô h·ªôi t·ª•, t√°c gi·∫£ c√≥ ƒë·ªÅ c·∫≠p r√µ v√† chi ti·∫øt trong b√†i b√°o, m√¨nh kh√¥ng ƒë·ªÅ c·∫≠p l·∫°i n√≥ n·ªØa ·ªü ƒë√¢y. C√°c b·∫°n t·ª± xem nh√©.\nK·∫øt lu·∫≠n AdaBelief l√† thu·∫≠t to√°n t·ªëi ∆∞u h√≥a c√≥ ngu·ªìn g·ªëc t·ª´ thu·∫≠t to√°n Adam, kh√¥ng c√≥ th√™m tham s·ªë ngo√†i, ch·ªâ thay ƒë·ªïi 1 d√≤ng code.\nThu·∫≠t to√°n ƒë√£ tƒÉng t·ªëc ƒë·ªô h·ªôi t·ª• c≈©ng nh∆∞ m·ª©c t·ªïng qu√°t h√≥a.\nThu·∫≠t to√°n th·ª±c hi·ªán c√°c b∆∞·ªõc ƒëi d·ª±a v√†o \u0026ldquo;belief\u0026rdquo; c·ªßa h∆∞·ªõng gradient ·ªü th·ªùi ƒëi·ªÉm hi·ªán t·∫°i.\nThu·∫≠t to√°n gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ \u0026ldquo;Large gradient, small curvature\u0026rdquo; b·∫±ng c√°ch xem x√©t bi√™n ƒë·ªô v√† d·∫•u c·ªßa gradient.\nNgu·ªìn:\nhttps://arxiv.org/abs/2010.07468\nhttps://medium.com/the-dl/understanding-the-new-adabelief-optimizer-2db70ef6de1e\nhttps://towardsdatascience.com/adabelief-optimizer-fast-as-adam-generalizes-as-good-as-sgd-71a919597af\n","date":"Jan 15, 2021","img":"https://unsplash.it/1920/1080?image=36","permalink":"/blog/2021-01-15---adabelief-optimizer/","series":null,"tags":["Machine Learning","Optimizer","SGD","Opencv"],"title":"T√¨m Hi·ªÉu Thu·∫≠t To√°n T·ªëi ∆Øu H√≥a Adabelief Optimizer"},{"categories":null,"content":" Advantages of Reinforcement Learning Thi·∫øt l·∫≠p b√†n c·ªù Kh·ªüi t·∫°o b√†n c·ªù Ki·ªÉm tra Reward Thi·∫øt l·∫≠p ng∆∞·ªùi ch∆°i Kh·ªüi t·∫°o Ch·ªçn n∆∞·ªõc ƒëi C·∫≠p nh·∫≠t tr·∫°ng th√°i Hu·∫•n luy·ªán m√¥ h√¨nh Advantages of Reinforcement Learning Trong khi trong c√°c ph∆∞∆°ng ph√°p l√Ω thuy·∫øt tr√≤ ch∆°i n√≥i chung, v√≠ d·ª• thu·∫≠t to√°n min-max, thu·∫≠t to√°n lu√¥n gi·∫£ ƒë·ªãnh ch√∫ng ta c√≥ m·ªôt ƒë·ªëi th·ªß ho√†n h·∫£o, c√¥ng vi·ªác ph·∫£i th·ª±c hi·ªán l√† t·ªëi ƒëa h√≥a ph·∫ßn th∆∞·ªüng c·ªßa m√¨nh v√† gi·∫£m thi·ªÉu ph·∫ßn th∆∞·ªüng c·ªßa ƒë·ªëi th·ªß ( t·ªëi ƒëa h√≥a ƒëi·ªÉm c·ªßa m√¨nh v√† t·ªëi thi·ªÉu h√≥a ƒëi·ªÉm c·ªßa ƒë·ªëi th·ªß), trong h·ªçc c·ªßng c·ªë, ch√∫ng ta kh√¥ng c·∫ßn gi·∫£ ƒë·ªãnh ƒë·ªëi th·ªß c·ªßa ch√∫ng ta l√† 1 thi√™n t√†i xu·∫•t ch√∫ng, nh∆∞ng chung ta v·∫´n thu ƒë∆∞·ª£c m√¥ h√¨nh v·ªõi k·∫øt qu·∫£ r·∫•t t·ªët.\nB·∫±ng c√°ch coi ƒë·ªëi th·ªß l√† m·ªôt ph·∫ßn c·ªßa m√¥i tr∆∞·ªùng m√† ch√∫ng ta c√≥ th·ªÉ t∆∞∆°ng t√°c, sau m·ªôt s·ªë l·∫ßn l·∫∑p l·∫°i nh·∫•t ƒë·ªãnh, ƒë·ªëi th·ªß c√≥ th·ªÉ l·∫≠p k·∫ø ho·∫°ch tr∆∞·ªõc m√† kh√¥ng c·∫ßn ch√∫ng ta ph·∫£i l√†m g√¨ c·∫£. ∆Øu ƒëi·ªÉm c·ªßa ph∆∞∆°ng ph√°p n√†y l√† gi·∫£m s·ªë l∆∞·ª£ng kh√¥ng gian t√¨m ki·∫øm v√† gi·∫£m s·ªë ph√©p to√°n suy lu·∫≠n ph·∫£i th·ª±c hi·ªán, nh∆∞ng n√≥ c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c k·ªπ nƒÉng hi·ªán ƒë·∫°i ch·ªâ b·∫±ng c√°ch th·ª≠ v√† h·ªçc.\nTrong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω l√†m c√°c c√¥ng vi·ªác sau:\nTh·ª© nh·∫•t, hu·∫•n luy·ªán m√¥ h√¨nh cho 2 m√°y ƒë·∫•u v·ªõi nhau m√† thu ƒë∆∞·ª£c c√°c tr·ªçng s·ªë c·∫ßn thi·∫øt.\nTh·ª© hai, cho ng∆∞·ªùi ƒë√°nh v·ªõi m√°y\nƒê·ªÉ h√¨nh th√†nh b√†i to√°n h·ªçc c·ªßng c·ªë Reinforcement Learning , ch√∫ng ta c·∫ßn ph·∫£i x√°c ƒë·ªãnh r√µ 3 th√†nh ph·∫ßn ch√≠nh:\nState\nAction\nReward\nV·ªõi:\nState ch√≠nh l√† b√†n c·ªù v·ªõi c√°c n∆∞·ªõc ƒëi c·ªßa c√°c ng∆∞·ªùi ch∆°i. Ch√∫ng ta s·∫Ω t·∫°o m·ªôt b√†n c·ªù c√≥ k√≠ch th∆∞·ªõc 3x3, gi√° tr·ªã c·ªßa m·ªói √¥ c·ªù ƒë·ªÅu l√† 0. V·ªã tr√≠ ng∆∞·ªùi ch∆°i 1 ƒë·∫∑t qu√¢n s·∫Ω ƒë∆∞·ª£c g√°n l√† 1. V·ªã tr√≠ ng∆∞·ªùi ch∆°i 2 ƒë·∫∑t qu√¢n s·∫Ω ƒë∆∞·ª£c g√°n l√† -1.\nAction l√† v·ªã tr√≠ ng∆∞·ªùi ch∆°i s·∫Ω ƒëi qu√¢n khi bi·∫øt state hi·ªán t·∫°i (nghƒ©a l√† bi·∫øt ƒë·ªëi th·ªß ƒëi n∆∞·ªõc n√†o, v√† c√≥ nh·ªØng n∆∞·ªõc n√†o hi·ªán ƒëang tr√™n b√†n c·ªù).\nReward: mang gi√° tr·ªã 0 ho·∫∑c 1. Khi k·∫øt th√∫c game s·∫Ω tr·∫£ v·ªÅ gi√° tr·ªã cho reward.\n·ªû ph·∫ßn d∆∞·ªõi ƒë√¢y, m√¨nh s·∫Ω note l·∫°i code v√† s·∫Ω comment trong code ƒë·ªÉ cho r√µ √Ω\nThi·∫øt l·∫≠p b√†n c·ªù Kh·ªüi t·∫°o b√†n c·ªù 1 2def __init__(self, p1, p2): 3 self.board = np.zeros((BOARD_ROWS, BOARD_COLS)) 4 self.p1 = p1 5 self.p2 = p2 6 self.isEnd = False 7 self.boardHash = None 8 # init p1 plays first 9 self.playerSymbol = 1 Ch√∫ng ta s·∫Ω t·∫°o m·ªôt b√†n c·ªù c√≥ k√≠ch th∆∞·ªõc 3x3, 2 bi·∫øn ng∆∞·ªùi ch∆°i. Ng∆∞·ªùi 1 l√† ng∆∞·ªùi ch∆°i ƒë·∫ßu ti√™n.\n1 2# Tr·∫£ v·ªÅ danh s√°ch c√°c n∆∞·ªõc c√≥ th·ªÉ ƒëi 3def availablePositions(self): 4 positions = [] 5 for i in range(BOARD_ROWS): 6 for j in range(BOARD_COLS): 7 if self.board[i, j] == 0: 8 positions.append((i, j)) # need to be tuple 9 return positions 10 11# C·∫≠p nh·∫≠t l·∫°i l√™n b√†n c·ªù v·ªã tr√≠ c·ªßa ng∆∞·ªùi ch∆°i ƒë·∫∑t qu√¢n 12 13def updateState(self, position): 14 self.board[position] = self.playerSymbol 15 # switch to another player 16 self.playerSymbol = -1 if self.playerSymbol == 1 else 1 Ki·ªÉm tra Reward Sau m·ªói n∆∞·ªõc ƒëi c·ªßa c√°c k·ª≥ th·ªß, ch√∫ng ta c·∫ßn 1 h√†m ƒë·ªÉ ki·ªÉm tra xem k·ª≥ th·ªß th·∫Øng hay thua v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ cho reward nh∆∞ ƒë·ªÅ c·∫≠p ·ªü tr√™n\n1 2def winner(self): 3 4\t# Ki·ªÉm tra theo d√≤ng 5 6\tfor i in range(BOARD_ROWS): 7\tif sum(self.board[i, :]) == 3: 8\tself.isEnd = True 9\treturn 1 10\tif sum(self.board[i, :]) == -3: 11\tself.isEnd = True 12\treturn -1 13\t# ki·ªÉm tra theo c·ªôt 14 15\tfor i in range(BOARD_COLS): 16\tif sum(self.board[:, i]) == 3: 17\tself.isEnd = True 18\treturn 1 19\tif sum(self.board[:, i]) == -3: 20\tself.isEnd = True 21\treturn -1 22 23\t# ki·ªÉm tra theo ƒë∆∞·ªùng ch√©o ch√≠nh v√† theo ƒë∆∞·ªùng ch√©o ph·ª• 24 25\tdiag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)]) # ƒë∆∞·ªùng ch√©o ch√≠nh 26 27\tdiag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)]) # ƒë∆∞·ªùng ch√©o ph·ª• 28 29\tdiag_sum = max(abs(diag_sum1), abs(diag_sum2)) # l·∫•y tr·ªã tuy·ªát ƒë·ªëi c·ªßa c√°c n∆∞·ªõc ƒëi, n·∫øu b·∫±ng 3 nghƒ©a l√† c√≥ ng∆∞·ªùi ch∆°i chi·∫øn th·∫Øng 30 31\tif diag_sum == 3: 32\tself.isEnd = True 33\tif diag_sum1 == 3 or diag_sum2 == 3: 34\treturn 1 35\telse: 36\treturn -1 37 38\t# Ki·ªÉm tra xem c√≤n n∆∞·ªõc ƒëi hay kh√¥ng 39\tif len(self.availablePositions()) == 0: 40\tself.isEnd = True 41\treturn 0 42 43\t# not end 44\tself.isEnd = False 45\treturn None 46 47# only when game ends 48def giveReward(self): 49\tresult = self.winner() 50\t# backpropagate reward 51\tif result == 1: 52\tself.p1.feedReward(1) 53\tself.p2.feedReward(0) 54\telif result == -1: 55\tself.p1.feedReward(0) 56\tself.p2.feedReward(1) 57\telse: 58\tself.p1.feedReward(0.1) 59\tself.p2.feedReward(0.5) ·ªû ƒë√¢y c√≥ m·ªôt l∆∞u √Ω. Khi c·ªù h√≤a th√¨ ch√∫ng ta c≈©ng xem r·∫±ng ng∆∞·ªùi ƒëi tr∆∞·ªõc thua, n√™n h·ªá s·ªë l√∫c c·ªù h√≤a s·∫Ω l√† 0.1-0.5. C√°c b·∫°n c√≥ th·ªÉ thi·∫øt l·∫≠p m·ªôt gi√° tr·ªã kh√°c, v√≠ d·ª• 0.2-0.5 ho·∫∑c 0.5-0.5 t√πy th√≠ch.\nThi·∫øt l·∫≠p ng∆∞·ªùi ch∆°i Ng∆∞·ªùi ch∆°i c·∫ßn c√≥ c√°c ph∆∞∆°ng th·ª©c sau:\nCh·ªçn n∆∞·ªõc ƒëi d·ª±a tr√™n tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa b√†n c·ªù.\nL∆∞u l·∫°i tr·∫°ng th√°i c·ªßa v√°n c·ªù.\nC·∫≠p nh·∫≠t l·∫°i gi√° tr·ªã tr·∫°ng th√°i sau m·ªói v√°n.\nL∆∞u v√† load c√°c tr·ªçng s·ªë l√™n.\nKh·ªüi t·∫°o 1 2def __init__(self, name, exp_rate=0.2): 3 self.name = name 4 self.states = [] # record all positions taken 5 self.lr = 0.2 6 self.exp_rate = exp_rate 7 self.decay_gamma = 0.9 8 self.states_value = {} # state -\u0026gt; value Ch·ªçn n∆∞·ªõc ƒëi 1 2def chooseAction(self, positions, current_board, symbol): 3\trandValue = np.random.uniform(0, 1) 4\tvalue_max = value = -999 5\tif randValue\u0026gt; self.exp_rate: 6 7\tfor p in positions: 8\tnext_board = current_board.copy() 9\tnext_board[p] = symbol 10\tnext_boardHash = self.getHash(next_board) 11\tvalue = -999 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash) 12\t# print(\u0026#34;value\u0026#34;, value) 13\tif value \u0026gt;= value_max: 14\tvalue_max = value 15\taction = p 16 17\tif value_max == -999 : 18\t# take random action 19\tidx = np.random.choice(len(positions)) 20\taction = positions[idx] 21 22\t# print(\u0026#34;{} takes action {}\u0026#34;.format(self.name, action)) 23\treturn action C·∫≠p nh·∫≠t tr·∫°ng th√°i Ch√∫ng ta s·∫Ω c·∫≠p nh·∫≠t tr·∫°ng th√°i v·ªõi c√¥ng th·ª©c sau\n$$ V(S_t) = V(S_t) + \\alpha [V(S_{t+1}) - V(S_t)] $$\nDi·ªÖn gi·∫£i ra ti·∫øng vi·ªát, gi√° tr·ªã c·ªßa tr·∫°ng th√°i t·∫°i th·ªùi ƒëi·ªÉm t b·∫±ng gi√° tr·ªã t·∫°i th·ªùi ƒëi·ªÉm hi·ªán t·∫°i c·ªông v·ªõi ƒë·ªô l·ªách c·ªßa tr·∫°ng th√°i hi·ªán t·∫°i v√† tr·∫°ng th√°i ti·∫øp theo nh√¢n v·ªõi m·ªôt h·ªá s·ªë h·ªçc alpha.\n1 2# at the end of game, backpropagate and update states value 3def feedReward(self, reward): 4 for st in reversed(self.states): 5 if self.states_value.get(st) is None: 6 self.states_value[st] = 0 7 self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st]) 8 reward = self.states_value[st] Hu·∫•n luy·ªán m√¥ h√¨nh Ph·∫ßn n√†y n·∫±m trong l·ªõp State. Ch√∫ng ta s·∫Ω l·∫ßn l∆∞·ª£t ƒëi qua c√°c qu√° tr√¨nh lu√¢n phi√™n nhau gi·ªØa ng∆∞·ªùi ch∆°i 1 v√† ng∆∞·ªùi ch∆°i 2\nng∆∞·ªùi ch∆°i ch·ªçn n∆∞·ªõc c√≥ th·ªÉ ƒëi -\u0026gt; c·∫≠p nh·∫≠t tr·∫°ng th√°i -\u0026gt; ki·ªÉm tra th·∫Øng/thua -\u0026gt; ng∆∞·ªùi ch∆°i ch·ªçn n∆∞·ªõc c√≥ th·ªÉ ƒëi \u0026hellip;\n1 2def play(self, rounds=100): 3\tfor i in range(rounds): 4\tif i % 1000 == 0: 5\tprint(\u0026#34;Rounds {}\u0026#34;.format(i)) 6\twhile not self.isEnd: 7\t# Player 1 8\tpositions = self.availablePositions() 9\tp1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 10\t# take action and upate board state 11\tself.updateState(p1_action) 12\tboard_hash = self.getHash() 13\tself.p1.addState(board_hash) 14\t# check board status if it is end 15 16\twin = self.winner() 17\tif win is not None: 18\t# self.showBoard() 19\t# ended with p1 either win or draw 20\tself.giveReward() 21\tself.p1.reset() 22\tself.p2.reset() 23\tself.reset() 24\tbreak 25 26\telse: 27\t# Player 2 28\tpositions = self.availablePositions() 29\tp2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol) 30\tself.updateState(p2_action) 31\tboard_hash = self.getHash() 32\tself.p2.addState(board_hash) 33 34\twin = self.winner() 35\tif win is not None: 36\t# self.showBoard() 37\t# ended with p2 either win or draw 38\tself.giveReward() 39\tself.p1.reset() 40\tself.p2.reset() 41\tself.reset() 42\tbreak Sau khi hu·∫•n luy·ªán 100 ng√†n l·∫ßn, ch√∫ng ta s·∫Ω ch∆°i v·ªõi m√°y, ch·ªâ l√† 1 thay ƒë·ªïi nh·ªè trong h√†m chooseAction l√† thay v√¨ l·∫•y n∆∞·ªõc ƒëi c√≥ tr·ªçng s·ªë l·ªõn nh·∫•t, ch√∫ng ta s·∫Ω cho ng∆∞·ªùi d√πng nh·∫≠p t·ª´ b√†n ph√≠m d√≤ng v√† c·ªôt v√†o\n1 2 3def chooseAction(self, positions): 4 while True: 5 row = int(input(\u0026#34;Input your action row:\u0026#34;)) 6 col = int(input(\u0026#34;Input your action col:\u0026#34;)) 7 action = (row, col) 8 if action in positions: 9 return action V√† s·ª≠a l·∫°i h√†m play m·ªôt ch√∫t, b·ªè loop 100k l·∫ßn ƒëi, b·ªè g·ªçi h√†m c·∫≠p nh·∫≠t th∆∞·ªüng v√† b·ªè c√°c h√†m reset ƒëi\n1 2 3# play with human 4def play2(self): 5\twhile not self.isEnd: 6\t# Player 1 7\tpositions = self.availablePositions() 8\tp1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 9\t# take action and upate board state 10\tself.updateState(p1_action) 11\tself.showBoard() 12\t# check board status if it is end 13\twin = self.winner() 14\tif win is not None: 15\tif win == 1: 16\tprint(self.p1.name, \u0026#34;wins!\u0026#34;) 17\telse: 18\tprint(\u0026#34;tie!\u0026#34;) 19\tself.reset() 20\tbreak 21 22\telse: 23\t# Player 2 24\tpositions = self.availablePositions() 25\tp2_action = self.p2.chooseAction(positions) 26 27\tself.updateState(p2_action) 28\tself.showBoard() 29\twin = self.winner() 30\tif win is not None: 31\tif win == -1: 32\tprint(self.p2.name, \u0026#34;wins!\u0026#34;) 33\telse: 34\tprint(\u0026#34;tie!\u0026#34;) 35\tself.reset() 36\tbreak M√£ ngu·ªìn ho√†n ch·ªânh c·ªßa ch∆∞∆°ng tr√¨nh\n1 2import numpy as np 3import pickle 4 5BOARD_ROWS = 3 6BOARD_COLS = 3 7 8 9class State: 10 def __init__(self, p1, p2): 11 self.board = np.zeros((BOARD_ROWS, BOARD_COLS)) 12 self.p1 = p1 13 self.p2 = p2 14 self.isEnd = False 15 self.boardHash = None 16 # init p1 plays first 17 self.playerSymbol = 1 18 19 # get unique hash of current board state 20 def getHash(self): 21 self.boardHash = str(self.board.reshape(BOARD_COLS * BOARD_ROWS)) 22 return self.boardHash 23 24 def winner(self): 25 # row 26 for i in range(BOARD_ROWS): 27 if sum(self.board[i, :]) == 3: 28 self.isEnd = True 29 return 1 30 if sum(self.board[i, :]) == -3: 31 self.isEnd = True 32 return -1 33 # col 34 for i in range(BOARD_COLS): 35 if sum(self.board[:, i]) == 3: 36 self.isEnd = True 37 return 1 38 if sum(self.board[:, i]) == -3: 39 self.isEnd = True 40 return -1 41 # diagonal 42 diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)]) 43 diag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)]) 44 diag_sum = max(abs(diag_sum1), abs(diag_sum2)) 45 if diag_sum == 3: 46 self.isEnd = True 47 if diag_sum1 == 3 or diag_sum2 == 3: 48 return 1 49 else: 50 return -1 51 52 # tie 53 # no available positions 54 if len(self.availablePositions()) == 0: 55 self.isEnd = True 56 return 0 57 # not end 58 self.isEnd = False 59 return None 60 61 def availablePositions(self): 62 positions = [] 63 for i in range(BOARD_ROWS): 64 for j in range(BOARD_COLS): 65 if self.board[i, j] == 0: 66 positions.append((i, j)) # need to be tuple 67 return positions 68 69 def updateState(self, position): 70 self.board[position] = self.playerSymbol 71 # switch to another player 72 self.playerSymbol = -1 if self.playerSymbol == 1 else 1 73 74 # only when game ends 75 def giveReward(self): 76 result = self.winner() 77 # backpropagate reward 78 if result == 1: 79 self.p1.feedReward(1) 80 self.p2.feedReward(0) 81 elif result == -1: 82 self.p1.feedReward(0) 83 self.p2.feedReward(1) 84 else: 85 self.p1.feedReward(0.1) 86 self.p2.feedReward(0.5) 87 88 # board reset 89 def reset(self): 90 self.board = np.zeros((BOARD_ROWS, BOARD_COLS)) 91 self.boardHash = None 92 self.isEnd = False 93 self.playerSymbol = 1 94 95 def play(self, rounds=100): 96 for i in range(rounds): 97 if i % 1000 == 0: 98 print(\u0026#34;Rounds {}\u0026#34;.format(i)) 99 while not self.isEnd: 100 # Player 1 101 positions = self.availablePositions() 102 p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 103 # take action and upate board state 104 self.updateState(p1_action) 105 board_hash = self.getHash() 106 self.p1.addState(board_hash) 107 # check board status if it is end 108 109 win = self.winner() 110 if win is not None: 111 # self.showBoard() 112 # ended with p1 either win or draw 113 self.giveReward() 114 self.p1.reset() 115 self.p2.reset() 116 self.reset() 117 break 118 119 else: 120 # Player 2 121 positions = self.availablePositions() 122 p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol) 123 self.updateState(p2_action) 124 board_hash = self.getHash() 125 self.p2.addState(board_hash) 126 127 win = self.winner() 128 if win is not None: 129 # self.showBoard() 130 # ended with p2 either win or draw 131 self.giveReward() 132 self.p1.reset() 133 self.p2.reset() 134 self.reset() 135 break 136 137 138 # play with human 139 def play2(self): 140 while not self.isEnd: 141 # Player 1 142 positions = self.availablePositions() 143 p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol) 144 # take action and upate board state 145 self.updateState(p1_action) 146 self.showBoard() 147 # check board status if it is end 148 win = self.winner() 149 if win is not None: 150 if win == 1: 151 print(self.p1.name, \u0026#34;wins!\u0026#34;) 152 else: 153 print(\u0026#34;tie!\u0026#34;) 154 self.reset() 155 break 156 157 else: 158 # Player 2 159 positions = self.availablePositions() 160 p2_action = self.p2.chooseAction(positions) 161 162 self.updateState(p2_action) 163 self.showBoard() 164 win = self.winner() 165 if win is not None: 166 if win == -1: 167 print(self.p2.name, \u0026#34;wins!\u0026#34;) 168 else: 169 print(\u0026#34;tie!\u0026#34;) 170 self.reset() 171 break 172 173 174 def showBoard(self): 175 # p1: x p2: o 176 for i in range(0, BOARD_ROWS): 177 print(\u0026#39;-------------\u0026#39;) 178 out = \u0026#39;| \u0026#39; 179 for j in range(0, BOARD_COLS): 180 token = \u0026#34;\u0026#34; 181 if self.board[i, j] == 1: 182 token = \u0026#39;x\u0026#39; 183 if self.board[i, j] == -1: 184 token = \u0026#39;o\u0026#39; 185 if self.board[i, j] == 0: 186 token = \u0026#39; \u0026#39; 187 out += token + \u0026#39; | \u0026#39; 188 print(out) 189 print(\u0026#39;-------------\u0026#39;) 190 191 192class Player: 193 def __init__(self, name, exp_rate=0.3): 194 self.name = name 195 self.states = [] # record all positions taken 196 self.lr = 0.3 197 self.exp_rate = exp_rate 198 self.decay_gamma = 0.9 199 self.states_value = {} # state -\u0026gt; value 200 201 def getHash(self, board): 202 boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS)) 203 return boardHash 204 205 def chooseAction(self, positions, current_board, symbol): 206 randValue = np.random.uniform(0, 1) 207 value_max = value = -999 208 if randValue\u0026gt; self.exp_rate: 209 210 for p in positions: 211 next_board = current_board.copy() 212 next_board[p] = symbol 213 next_boardHash = self.getHash(next_board) 214 value = -999 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash) 215 # print(\u0026#34;value\u0026#34;, value) 216 if value \u0026gt;= value_max: 217 value_max = value 218 action = p 219 220 if value_max == -999 : 221 # take random action 222 idx = np.random.choice(len(positions)) 223 action = positions[idx] 224 225 # print(\u0026#34;{} takes action {}\u0026#34;.format(self.name, action)) 226 return action 227 228 # append a hash state 229 def addState(self, state): 230 self.states.append(state) 231 232 # at the end of game, backpropagate and update states value 233 def feedReward(self, reward): 234 for st in reversed(self.states): 235 if self.states_value.get(st) is None: 236 self.states_value[st] = 0 237 self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st]) 238 reward = self.states_value[st] 239 240 def reset(self): 241 self.states = [] 242 243 def savePolicy(self): 244 fw = open(\u0026#39;policy_\u0026#39; + str(self.name), \u0026#39;wb\u0026#39;) 245 pickle.dump(self.states_value, fw) 246 fw.close() 247 248 def loadPolicy(self, file): 249 fr = open(file, \u0026#39;rb\u0026#39;) 250 self.states_value = pickle.load(fr) 251 fr.close() 252 253 254class HumanPlayer: 255 def __init__(self, name): 256 self.name = name 257 258 def chooseAction(self, positions): 259 while True: 260 row = int(input(\u0026#34;Input your action row:\u0026#34;)) 261 col = int(input(\u0026#34;Input your action col:\u0026#34;)) 262 action = (row, col) 263 if action in positions: 264 return action 265 266 # append a hash state 267 def addState(self, state): 268 pass 269 270 # at the end of game, backpropagate and update states value 271 def feedReward(self, reward): 272 pass 273 274 def reset(self): 275 pass 276 277 278if __name__ == \u0026#34;__main__\u0026#34;: 279 # training 280 p1 = Player(\u0026#34;p1\u0026#34;) 281 p2 = Player(\u0026#34;p2\u0026#34;) 282 283 st = State(p1, p2) 284 print(\u0026#34;training...\u0026#34;) 285 st.play(100000) 286 287 p1.savePolicy() 288 289 # play with human 290 p1 = Player(\u0026#34;computer\u0026#34;, exp_rate=0) 291 p1.loadPolicy(\u0026#34;policy_p1\u0026#34;) 292 293 p2 = HumanPlayer(\u0026#34;human\u0026#34;) 294 295 st = State(p1, p2) 296 st.play2() Ngu·ªìn\nReinforcement Learning: An Introduction phi√™n b·∫£n 2 c·ªßa Richard S. Sutton and Andrew G. Barto\nhttps://towardsdatascience.com/reinforcement-learning-implement-tictactoe-189582bea542\n","date":"Dec 27, 2020","img":"https://unsplash.it/1920/1080?image=39","permalink":"/blog/2020-12-26---tic-tac-toe/","series":null,"tags":["Reinforcement Learning","TicTacToe","Opencv"],"title":"Reinforcement Learning V√† Tictactoe"},{"categories":null,"content":" M√£ ngu·ªìn M√£ ngu·ªìn 1 2import cv2 3import numpy as np 4from random import choice 5 6def getColor(): 7\tlstColor = [[255,64,64],[255,165,0],[255,244,79],[102,255,0],[172,229,238],[148,87,235],[148,87,235],[241,156,187]] 8\treturn choice(lstColor) 9 10def getInfo(piece): 11\tif piece == \u0026#34;\u0026#34;: 12\tcoords = np.array([[0, 0]]) 13\telif piece == \u0026#34;I\u0026#34;: 14\tcoords = np.array([[0, 3], [0, 4], [0, 5], [0, 6]]) 15\telif piece == \u0026#34;T\u0026#34;: 16\tcoords = np.array([[1, 3], [1, 4], [1, 5], [0, 4]]) 17\telif piece == \u0026#34;L\u0026#34;: 18\tcoords = np.array([[1, 3], [1, 4], [1, 5], [0, 5]]) 19\telif piece == \u0026#34;J\u0026#34;: 20\tcoords = np.array([[1, 3], [1, 4], [1, 5], [0, 3]]) 21\telif piece == \u0026#34;S\u0026#34;: 22\tcoords = np.array([[1, 5], [1, 4], [0, 3], [0, 4]]) 23\telif piece == \u0026#34;Z\u0026#34;: 24\tcoords = np.array([[1, 3], [1, 4], [0, 4], [0, 5]]) 25\telse: 26\tcoords = np.array([[0, 4], [0, 5], [1, 4], [1, 5]]) 27 28\treturn coords, getColor() 29 30def display(board, coords, color, next_info, held_info, score, SPEED): 31\t# Generates the display 32 33\tborder = np.uint8(127 - np.zeros([20, 1, 3])) 34\tborder_ = np.uint8(127 - np.zeros([1, 23, 3])) 35 36\tdummy = board.copy() 37\tdummy[coords[:,0], coords[:,1]] = color 38 39\tright = np.uint8(np.zeros([20, 10, 3])) 40\tright[next_info[0][:,0] + 2, next_info[0][:,1]] = next_info[1] 41 42\tdummy = np.concatenate(( border, dummy, border, right, border), 1) 43\tdummy = np.concatenate((border_, dummy, border_), 0) 44\tdummy = dummy.repeat(20, 0).repeat(20, 1) 45\tdummy = cv2.putText(dummy, str(score), (325, 150), cv2.FONT_HERSHEY_DUPLEX, 1, [0, 0, 255], 2) 46 47\t# Instructions for the player 48\tindex_pos = 300 49\tx_index_pos = 300 50\tdummy = cv2.putText(dummy, \u0026#34;A - left\u0026#34;, (x_index_pos, index_pos), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 51\tdummy = cv2.putText(dummy, \u0026#34;D - right\u0026#34;, (x_index_pos, index_pos+25), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 52\tdummy = cv2.putText(dummy, \u0026#34;S - drain\u0026#34;, (x_index_pos, index_pos+50), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 53\tdummy = cv2.putText(dummy, \u0026#34;W - rotate\u0026#34;, (x_index_pos, index_pos+75), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 234]) 54\t# dummy = cv2.putText(dummy, \u0026#34;J - rotate left\u0026#34;, (45, 300), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 255]) 55\t# dummy = cv2.putText(dummy, \u0026#34;L - rotate right\u0026#34;, (45, 325), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 255]) 56\t# dummy = cv2.putText(dummy, \u0026#34;I - hold\u0026#34;, (45, 350), cv2.FONT_HERSHEY_DUPLEX, 0.6, [0, 0, 255]) 57 58\tcv2.imshow(\u0026#34;Tetris\u0026#34;, dummy) 59\tkey = cv2.waitKey(int(1000/SPEED)) 60 61\treturn key 62 63def getNextPiece(): 64\tnext_piece = choice([\u0026#34;O\u0026#34;, \u0026#34;I\u0026#34;, \u0026#34;S\u0026#34;, \u0026#34;Z\u0026#34;, \u0026#34;L\u0026#34;, \u0026#34;J\u0026#34;, \u0026#34;T\u0026#34;]) 65 66\treturn next_piece 67 68SPEED = 1 # Controls the speed of the tetris pieces 69 70# Make a board 71 72board = np.uint8(np.zeros([20, 10, 3])) 73 74# Initialize some variables 75 76quit = False 77place = False 78drop = False 79switch = False 80held_piece = \u0026#34;\u0026#34; 81flag = 0 82score = 0 83next_piece =\u0026#34;\u0026#34; 84current_piece = \u0026#34;\u0026#34; 85# All the tetris pieces 86 87 88 89if __name__ == \u0026#34;__main__\u0026#34;: 90\tnext_piece = getNextPiece() 91\twhile not quit: 92\t# Check if user wants to swap held and current pieces 93\tif switch: 94\t# swap held_piece and current_piece 95\theld_piece, current_piece = current_piece, held_piece 96\tswitch = False 97\telse: 98\t# Generates the next piece and updates the current piece 99\tcurrent_piece = next_piece 100\tnext_piece = getNextPiece() 101 102\tif flag \u0026gt; 0: 103\tflag -= 1 104 105\t# Determines the color and position of the current, next, and held pieces 106 107\theld_info = getInfo(held_piece) 108 109\tnext_info = getInfo(next_piece) 110 111\tcoords, color = getInfo(current_piece) 112\tif current_piece == \u0026#34;I\u0026#34;: 113\ttop_left = [-2, 3] 114 115\tif not np.all(board[coords[:,0], coords[:,1]] == 0): 116\tbreak 117 118\twhile True: 119\t# Shows the board and gets the key press 120\tkey = display(board, coords, color, next_info, held_info, score, SPEED) 121\t# Create a copy of the position 122\tdummy = coords.copy() 123\tprint(\u0026#34;speed \u0026#34;,SPEED, \u0026#34;key \u0026#34;,key,\u0026#34; \u0026#34;, ord(\u0026#34;s\u0026#34;)) 124 125\tif key == ord(\u0026#34;s\u0026#34;): 126\tdrop = True 127 128\telif key == ord(\u0026#34;a\u0026#34;): 129\t# Moves the piece left if it isn\u0026#39;t against the left wall 130\tif np.min(coords[:,1]) \u0026gt; 0: 131\tcoords[:,1] -= 1 132\tif current_piece == \u0026#34;I\u0026#34;: 133\ttop_left[1] -= 1 134\telif key == ord(\u0026#34;d\u0026#34;): 135\t# Moves the piece right if it isn\u0026#39;t against the right wall 136\tif np.max(coords[:,1]) \u0026lt; 9: 137\tcoords[:,1] += 1 138\tif current_piece == \u0026#34;I\u0026#34;: 139\ttop_left[1] += 1 140\t# elif key == ord(\u0026#34;j\u0026#34;) or key == ord(\u0026#34;l\u0026#34;): 141\t# # Rotation mechanism 142\t# # arr is the array of nearby points which get rotated and pov is the indexes of the blocks within arr 143 144\t# if current_piece != \u0026#34;I\u0026#34; and current_piece != \u0026#34;O\u0026#34;: 145\t# if coords[1,1] \u0026gt; 0 and coords[1,1] \u0026lt; 9: 146\t# arr = coords[1] - 1 + np.array([[[x, y] for y in range(3)] for x in range(3)]) 147\t# pov = coords - coords[1] + 1 148 149\t# elif current_piece == \u0026#34;I\u0026#34;: 150\t# # The straight piece has a 4x4 array, so it needs seperate code 151 152\t# arr = top_left + np.array([[[x, y] for y in range(4)] for x in range(4)]) 153\t# pov = np.array([np.where(np.logical_and(arr[:,:,0] == pos[0], arr[:,:,1] == pos[1])) for pos in coords]) 154\t# pov = np.array([k[0] for k in np.swapaxes(pov, 1, 2)]) 155 156\t# # Rotates the array and repositions the piece to where it is now 157 158\t# if current_piece != \u0026#34;O\u0026#34;: 159\t# if key == ord(\u0026#34;j\u0026#34;): 160\t# arr = np.rot90(arr, -1) 161\t# else: 162\t# arr = np.rot90(arr) 163\t# coords = arr[pov[:,0], pov[:,1]] 164 165\telif key == ord(\u0026#34;w\u0026#34;): 166\t# Rotation mechanism 167\t# arr is the array of nearby points which get rotated and pov is the indexes of the blocks within arr 168 169\tif current_piece != \u0026#34;I\u0026#34; and current_piece != \u0026#34;O\u0026#34;: 170\tif coords[1,1] \u0026gt; 0 and coords[1,1] \u0026lt; 9: 171\tarr = coords[1] - 1 + np.array([[[x, y] for y in range(3)] for x in range(3)]) 172\tpov = coords - coords[1] + 1 173 174\telif current_piece == \u0026#34;I\u0026#34;: 175\t# The straight piece has a 4x4 array, so it needs seperate code 176 177\tarr = top_left + np.array([[[x, y] for y in range(4)] for x in range(4)]) 178\tpov = np.array([np.where(np.logical_and(arr[:,:,0] == pos[0], arr[:,:,1] == pos[1])) for pos in coords]) 179\tpov = np.array([k[0] for k in np.swapaxes(pov, 1, 2)]) 180 181\t# Rotates the array and repositions the piece to where it is now 182 183\tif current_piece != \u0026#34;O\u0026#34;: 184\tif key == ord(\u0026#34;j\u0026#34;): 185\tarr = np.rot90(arr, -1) 186\telse: 187\tarr = np.rot90(arr) 188\tcoords = arr[pov[:,0], pov[:,1]] 189\t# Hard drop set to true 190\t# drop = True 191\t# elif key == ord(\u0026#34;i\u0026#34;): 192\t# # Goes out of the loop and tells the program to switch held and current pieces 193\t# if flag == 0: 194\t# if held_piece == \u0026#34;\u0026#34;: 195\t# held_piece = current_piece 196\t# else: 197\t# switch = True 198\t# flag = 2 199\t# break 200\telif key == 8 or key == 27: 201\tquit = True 202\tbreak 203 204\t# Checks if the piece is overlapping with other pieces or if it\u0026#39;s outside the board, and if so, changes the position to the position before anything happened 205 206\tif np.max(coords[:,0]) \u0026lt; 20 and np.min(coords[:,0]) \u0026gt;= 0: 207\tif not (current_piece == \u0026#34;I\u0026#34; and (np.max(coords[:,1]) \u0026gt;= 10 or np.min(coords[:,1]) \u0026lt; 0)): 208\tif not np.all(board[coords[:,0], coords[:,1]] == 0): 209\tcoords = dummy.copy() 210\telse: 211\tcoords = dummy.copy() 212\telse: 213\tcoords = dummy.copy() 214 215\tif drop: 216\t# Every iteration of the loop moves the piece down by 1 and if the piece is resting on the ground or another piece, then it stops and places it 217 218\twhile not place: 219\tif np.max(coords[:,0]) != 19: 220\t# Checks if the piece is resting on something 221\tfor pos in coords: 222\tif not np.array_equal(board[pos[0] + 1, pos[1]], [0, 0, 0]): 223\tplace = True 224\tbreak 225\telse: 226\t# If the position of the piece is at the ground level, then it places 227\tplace = True 228 229\tif place: 230\tbreak 231 232\t# Keeps going down and checking when the piece needs to be placed 233 234\tcoords[:,0] += 1 235 236\tif current_piece == \u0026#34;I\u0026#34;: 237\ttop_left[0] += 1 238 239\tdrop = False 240 241\telse: 242\t# Checks if the piece needs to be placed 243\tif np.max(coords[:,0]) != 19: 244\tfor pos in coords: 245\tif not np.array_equal(board[pos[0] + 1, pos[1]], [0, 0, 0]): 246\tplace = True 247\tbreak 248\telse: 249\tplace = True 250 251\tif place: 252\t# Places the piece where it is on the board 253\tfor pos in coords: 254\tboard[tuple(pos)] = color 255 256\t# Resets place to False 257\tplace = False 258\tbreak 259 260\t# Moves down by 1 261 262\tcoords[:,0] += 1 263\tif current_piece == \u0026#34;I\u0026#34;: 264\ttop_left[0] += 1 265 266\t# Clears lines and also counts how many lines have been cleared and updates the score 267 268\tlines = 0 269 270\tfor line in range(20): 271\tif np.all([np.any(pos != 0) for pos in board[line]]): 272\tlines += 1 273\tboard[1:line+1] = board[:line] 274 275 276\tscore += lines*10 M√£ ngu·ªìn n√†y ƒë∆∞·ª£c k·∫ø th·ª´a t·ª´ b√†i vi·∫øt https://www.learnopencv.com/tetris-with-opencv-python/ v√† m√¨nh c√≥ modify l·∫°i theo s·ªü th√≠ch c√° nh√¢n c·ªßa m√¨nh. C√≤n m·ªôt s·ªë bug m√† m√¨nh ch∆∞a fix h·∫øt. B·∫°n ƒë·ªçc n√†o gh√© ngang c√≥ ƒë√≥ng g√≥p g√¨ th√¨ ƒë·ªÉ l·∫°i comment gi√∫p m√¨nh hen.\n","date":"Dec 26, 2020","img":"https://unsplash.it/1920/1080?image=40","permalink":"/blog/2020-12-25---tetric/","series":null,"tags":["Python","Tetris","Opencv"],"title":"X√¢y D·ª±ng Game X·∫øp G·∫°ch B·∫±ng Opencv V√† Python"},{"categories":null,"content":" Gi√° tr·ªã ng∆∞·ª°ng: Thu·∫≠t to√°n Simple Thresholding Adaptive Thresholding Gi√° tr·ªã ng∆∞·ª°ng: N√≥i theo ki·ªÉu l√∫a h√≥a, trong opencv, ng∆∞·ª°ng l√† m·ªôt s·ªë n·∫±m trong ƒëo·∫°n t·ª´ 0 ƒë·∫øn 255. Gi√° tr·ªã ng∆∞·ª°ng s·∫Ω chia t√°ch gi√° tr·ªã ƒë·ªô x√°m c·ªßa ·∫£nh th√†nh 2 mi·ªÅn ri√™ng bi·ªát. Mi·ªÅn th·ª© nh·∫•t l√† t·∫≠p h·ª£p c√°c ƒëi·ªÉm ·∫£nh c√≥ gi√° tr·ªã nh·ªè h∆°n gi√° tr·ªã ng∆∞·ª°ng. Mi·ªÅn th·ª© hai l√† t·∫≠p h·ª£p c√°c c√°c ƒëi·ªÉm ·∫£nh c√≥ gi√° tr·ªã l·ªõn h∆°n ho·∫∑c b·∫±ng gi√° tr·ªã ng∆∞·ª°ng.\nƒê·∫ßu v√†o c·ªßa m·ªôt thu·∫≠t to√°n ph√¢n ng∆∞·ª°ng trong opencv th∆∞·ªùng c√≥ input l√† ·∫£nh ngu·ªìn (source image) v√† gi√° tr·ªã ng∆∞·ª°ng. ƒê·∫ßu ra l√† ·∫£nh ƒë√≠ch ƒë√£ ƒë∆∞·ª£c ph√¢n ng∆∞·ª°ng (destination image). M·ªôt s·ªë thu·∫≠t to√°n ph√¢n ng∆∞·ª°ng s·∫Ω k√®m th√™m v√†i gi√° tr·ªã r√¢u ria kh√°c n·ªØa, ch√∫ng ta s·∫Ω kh√¥ng quan t√¢m ƒë·∫øn ch√∫ng\nM√£ gi·∫£i c·ªßa thu·∫≠t to√°n ph√¢n ng∆∞·ª°ng:\n1if src[i] \u0026gt;= T: 2\tdest[i] = MAXVAL 3else: 4\tdest [i] = 0 C√≥ r·∫•t nhi·ªÅu thu·∫≠t to√°n ph√¢n ng∆∞·ª°ng d·ª±a tr√™n c√°ch ch√∫ng ta x√°c ƒë·ªãnh ng∆∞·ª°ng. Ch√∫ng ta s·∫Ω t√¨m hi·ªÉu l·∫ßn l∆∞·ª£t c√°c thu·∫≠t to√°n tr√™n.\nThu·∫≠t to√°n Simple Thresholding Simple Thresholding th·ª±c hi·ªán ph√¢n ng∆∞·ª°ng b·∫±ng c√°ch thay th·∫ø gi√° tr·ªã l·ªõn h∆°n ho·∫∑c b·∫±ng v√† gi√° tr·ªã b√© h∆°n gi√° tr·ªã ng∆∞·ª°ng b·∫±ng m·ªôt gi√° tr·ªã m·ªõi. C·ª• th·ªÉ ch√∫ng ta c√≥ th·ªÉ xem m√£ ngu·ªìn b√™n d∆∞·ªõi\n1 2import cv2 3import numpy as np 4from matplotlib import pyplot as plt 5 6img = cv2.imread(\u0026#39;gradient.png\u0026#39;,0) 7ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY) 8ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV) 9ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC) 10ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO) 11ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV) 12 13titles = [\u0026#39;Original Image\u0026#39;,\u0026#39;BINARY\u0026#39;,\u0026#39;BINARY_INV\u0026#39;,\u0026#39;TRUNC\u0026#39;,\u0026#39;TOZERO\u0026#39;,\u0026#39;TOZERO_INV\u0026#39;] 14images = [img, thresh1, thresh2, thresh3, thresh4, thresh5] 15 16for i in xrange(6): 17 plt.subplot(2,3,i+1),plt.imshow(images[i],\u0026#39;gray\u0026#39;) 18 plt.title(titles[i]) 19 plt.xticks([]),plt.yticks([]) 20 21plt.show() H√¨nh ·∫£nh v√† thu·∫≠t to√°n c·ªßa m√¥ h√¨nh ƒë∆∞·ª£c l·∫•y t·ª´ trang opencv-python-tutroals.readthedocs.io\n·ªû ƒëo·∫°n code tr√™n, ch√∫ng ta thi·∫øt l·∫≠p gi√° tr·ªã ng∆∞·ª°ng l√† 127, v·ªõi c√°c ƒëi·ªÉm ·∫£nh c√≥ gi√° tr·ªã l·ªõn h∆°n ho·∫∑c b·∫±ng 127, ch√∫ng ta s·∫Ω g√°n l·∫°i gi√° tr·ªã c·ªßa n√≥ th√†nh 255. V√† c√°c ƒëi·ªÉm ·∫£nh c√≥ gi√° tr·ªã b√© h∆°n 127 s·∫Ω ƒë∆∞·ª£c g√°n b·∫±ng 0 (m·∫∑c ƒë·ªãnh).\n1 2 3double cv::threshold\t(\tInputArray src, 4OutputArray dst, 5double thresh, 6double maxval, 7int type 8) Thu·∫≠t to√°n sample thresholding c·ªßa opencv c√≤n c√≥ 1 tham s·ªë n·ªØa kh√° quan tr·ªçng n·ªØa l√† lo·∫°i ng∆∞·ª°ng (type). Hi·ªán t·∫°i l√∫c m√¨nh vi·∫øt b√†i vi·∫øt n√†y th√¨ opencv h·ªó tr·ª£ 8 lo·∫°i l√†: THRESH_BINARY, THRESH_BINARY_INV, THRESH_TRUNC, THRESH_TOZERO, THRESH_TOZERO_INV, THRESH_MASK, THRESH_OTSU, THRESH_TRIANGLE. √ù nghƒ©a c·ªßa t·ª´ng lo·∫°i nh∆∞ sau:\nTHRESH_BINARY: C√≥ th·ªÉ d·ªãch l√† ng∆∞·ª°ng nh·ªã ph√¢n. √ù nghƒ©a y h·ªát nh·ªØng g√¨ m√¨nh ƒë·ªÅ c·∫≠p ·ªü tr√™n.\nTHRESH_BINARY_INV: Ng∆∞·ª°ng nh·ªã ph√¢n ƒë·∫£o ng∆∞·ª£c. C√≥ th·ªÉ hi·ªÉu l√† n√≥ s·∫Ω ƒë·∫£o ng∆∞·ª£c l·∫°i k·∫øt qu·∫£ c·ªßa THRESH_BINARY.\nTHRESH_TRUNC: Nh·ªØng gi√° tr·ªã ƒëi·ªÉm ·∫£nh b√© h∆°n ng∆∞·ª°ng s·∫Ω gi·ªØ nguy√™n gi√° tr·ªã, nh·ªØng ƒëi·ªÉm ·∫£nh l·ªõn h∆°n ho·∫∑c ng∆∞·ª°ng s·∫Ω ƒë∆∞·ª£c g√°n l·∫°i l√† maxvalue.\nTHRESH_TOZERO: Nh·ªØng ƒëi·ªÉm ·∫£nh b√© h∆°n ng∆∞·ª°ng s·∫Ω b·ªã g√°n th√†nh 0, nh·ªØng ƒëi·ªÉm c√≤n l·∫°i gi·ªØ nguy√™n.\nTHRESH_TOZERO_INV: Nh·ªØng ƒëi·ªÉm ·∫£nh nh·ªè h∆°n gi√° tr·ªã ng∆∞·ª°ng s·∫Ω ƒë∆∞·ª£c gi·ªØ nguy√™n, nh·ªØng ƒëi·ªÉm ·∫£nh c√≤n l·∫°i s·∫Ω b·ªã g√°n th√†nh 0.\nTHRESH_MASK: ·ªû b·∫°n opencv4, h·∫ßu nh∆∞ kh√¥ng ƒë∆∞·ª£c x√†i.\nTHRESH_OTSU: S·ª≠ d·ª•ng thu·∫≠t to√°n Otsu ƒë·ªÉ x√°c ƒë·ªãnh gi√° tr·ªã ng∆∞·ª°ng.\nTHRESH_TRIANGLE: S·ª≠ d·ª•ng thu·∫≠t to√°n Triangle ƒë·ªÉ x√°c ƒë·ªãnh gi√° tr·ªã ng∆∞·ª°ng.\nGi√° tr·ªã 127 l√† gi√° tr·ªã trung b√¨nh c·ªông c·ªßa 0 v√† 255 l√†m tr√≤n xu·ªëng. Gi√° tr·ªã ng∆∞·ª°ng c·ªßa thu·∫≠t to√°n n√†y ƒë√≤i h·ªèi ng∆∞·ªùi s·ª≠ d·ª•ng ph·∫£i c√≥ m·ª©c ƒë·ªô hi·ªÉu bi·∫øt nh·∫•t ƒë·ªãnh v·ªÅ c√°c lo·∫°i ·∫£nh m√¨nh ƒëang x·ª≠ l√Ω ƒë·ªÉ ch·ªçn ng∆∞·ª°ng cho ph√π h·ª£p.\nAdaptive Thresholding Thu·∫≠t to√°n simple thresholding ho·∫°t ƒë·ªông kh√° t·ªët. Tuy nhi√™n, n√≥ c√≥ 1 nh∆∞·ª£c ƒëi·ªÉm l√† gi√° tr·ªã ng∆∞·ª°ng b·ªã/ƒë∆∞·ª£c g√°n to√†n c·ª•c. Th·ª±c t·∫ø khi ch·ª•p, h√¨nh ·∫£nh ch√∫ng ta nh·∫≠n ƒë∆∞·ª£c th∆∞·ªùng b·ªã ·∫£nh h∆∞·ªüng c·ªßa nhi·ªÖu, v√≠ d·ª• nh∆∞ l√† b·ªã ph∆°i s√°ng, b·ªã ƒë√®n flask, \u0026hellip;\nM·ªôt trong nh·ªØng c√°ch ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ tr√™n l√† chia nh·ªè b·ª©c ·∫£nh th√†nh nh·ªØng v√πng nh·ªè (region), v√† ƒë·∫∑t gi√° tr·ªã ng∆∞·ª°ng tr√™n nh·ªØng v√πng nh·ªè ƒë√≥ -\u0026gt; adaptive thresholding ra ƒë·ªùi. Opencv cung c·∫•p cho ch√∫ng ta hai c√°ch x√°c ƒë·ªãnh nh·ªØng v√πng nh·ªè\n1import cv2 as cv 2import numpy as np 3from matplotlib import pyplot as plt 4img = cv.imread(\u0026#39;sudoku.png\u0026#39;,0) 5img = cv.medianBlur(img,5) 6ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY) 7th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\ 8 cv.THRESH_BINARY,11,2) 9th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\ 10 cv.THRESH_BINARY,11,2) 11titles = [\u0026#39;Original Image\u0026#39;, \u0026#39;Global Thresholding (v = 127)\u0026#39;, 12 \u0026#39;Adaptive Mean Thresholding\u0026#39;, \u0026#39;Adaptive Gaussian Thresholding\u0026#39;] 13images = [img, th1, th2, th3] 14for i in xrange(4): 15 plt.subplot(2,2,i+1),plt.imshow(images[i],\u0026#39;gray\u0026#39;) 16 plt.title(titles[i]) 17 plt.xticks([]),plt.yticks([]) 18plt.show() H√¨nh ·∫£nh v√† thu·∫≠t to√°n c·ªßa m√¥ h√¨nh ƒë∆∞·ª£c l·∫•y t·ª´ trang docs.opencv.org\n1 2 3void cv::adaptiveThreshold\t(\tInputArray src, 4OutputArray dst, 5double maxValue, 6int adaptiveMethod, 7int thresholdType, 8int blockSize, 9double C 10) ·ªû ƒë√¢y:\nblockSize: K√≠ch th∆∞·ªõc c·ªßa v√πng, b·∫Øt bu·ªôc ph·∫£i l√† m·ªôt s·ªë l·∫ª l·ªõn h∆°n 0.\nC: h·∫±ng s·ªë, gi√° tr·ªã t·ª´ -255 ƒë·∫øn 255. C√≥ th·ªÉ g√°n C b·∫±ng 0 ƒë·ªÉ ƒë·ª° r·ªëi.\nadaptiveMethod nh·∫≠n v√†o m·ªôt trong hai gi√° tr·ªã l√† cv.ADAPTIVE_THRESH_MEAN_C v√† cv.ADAPTIVE_THRESH_GAUSSIAN_C, ƒë√≥ l√† c√°c ph∆∞∆°ng ph√°p t√≠nh ng∆∞·ª°ng.\nADAPTIVE_THRESH_MEAN_C: T√≠nh trung b√¨nh c√°c l√°ng gi·ªÅng xung quanh ƒëi·ªÉm c·∫ßn x√©t trong v√πng blockSize * blockSize tr·ª´ ƒëi gi√° tr·ªã h·∫±ng s·ªë C.\nADAPTIVE_THRESH_GAUSSIAN_C: Nh√¢n gi√° tr·ªã xung quanh ƒëi·ªÉm c·∫ßn x√©t v·ªõi tr·ªçng s·ªë gauss r·ªìi t√≠nh trung b√¨nh c·ªßa n√≥, sau ƒë√≥ tr·ª´ ƒëi gi√° tr·ªã h·∫±ng s·ªë C.\nthresholdType: T∆∞∆°ng t·ª± nh∆∞ Simple Thresholding ƒë√£ tr√¨nh b√†y ·ªü tr√™n.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ quan t√¢m v√† theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\nTham kh·∫£o\nhttps://www.geeksforgeeks.org/python-thresholding-techniques-using-opencv-set-1-simple-thresholding/\nhttps://www.learnopencv.com/opencv-threshold-python-cpp/\nhttps://medium.com/@anupriyam/basic-image-thresholding-in-opencv-5af9020f2472\n","date":"Dec 25, 2020","img":"","permalink":"/blog/2020-12-24-thresholding/","series":null,"tags":["python","thresholding","contour","opencv"],"title":"Ng∆∞·ª°ng (Thresholding) Trong Opencv"},{"categories":null,"content":" X√°c ƒë·ªãnh bias v√† variance Bias Unavoidable bias Avoidable bias Variance Tradeoff gi·ªØa bias v√† variance C√°ch gi·∫£m bias v√† variance C√°ch gi·∫£m bias Gi·∫£m variance B·ª©c tranh t·ªïng qu√°t T·ªïng k·∫øt Vi·ªác hu·∫•n luy√™n m√¥ h√¨nh m√°y h·ªçc c√≥ th·ªÉ s·∫Ω g√¢y ra cho b·∫°n m·ªôt ch√∫t kh√≥ khƒÉn n·∫øu b·∫°n kh√¥ng hi·ªÉu nh·ªØng th·ª© b·∫°n dang l√†m l√† ƒë√∫ng hay sai. Trong h·∫ßu h·∫øt c√°c tr∆∞·ªùng h·ª£p, c√°c m√¥ h√¨nh h·ªçc m√°y l√† c√°c \u0026ldquo;h·ªôp ƒëen\u0026rdquo;, ch√∫ng ta ch·ªâ c√≥ th·ªÉ \u0026ldquo;nh√¨n th·∫•y\u0026rdquo; d·ªØ li·ªáu ƒë·∫ßu v√†o v√† ƒë·ªô ch√≠nh x√°c m√† m√¥ h√¨nh tr·∫£ ra. Ch√∫ng ta kh√¥ng bi·∫øt b√™n trong n√≥ ƒëang l√†m c√°i g√¨. Vi·ªác hi·ªÉu l√Ω do t·∫°i sao m√¥ h√¨nh cho ra k·∫øt qu·∫£ t·ªá h·∫°i l√† ch√¨a kh√≥a cho c√°i \u0026ldquo;c√°ch\u0026rdquo; m√† b·∫°n c·∫£i ti·∫øn n√≥.\nT√¨m hi·ªÉu l√Ω do \u0026ldquo;t·∫°i sao\u0026rdquo; m√¥ h√¨nh cho ra k·∫øt qu·∫£ t·ªá h·∫°i b·∫±ng c√°ch \u0026ldquo;x√°c ƒë·ªãnh bias v√† variance\u0026rdquo;.\nT√¨m hi·ªÉu \u0026ldquo;c√°ch\u0026rdquo; c·∫£i ti·∫øn m√¥ h√¨nh b·∫±ng vi·ªác th·ª±c hi·ªán \u0026ldquo;gi·∫£m bias v√† variance\u0026rdquo;.\nX√°c ƒë·ªãnh bias v√† variance Tr∆∞·ªõc h·∫øt, ch√∫ng ta h√£y b·∫Øt ƒë·∫ßu n√≥i v·ªÅ l·ªói. L·ªói l√† ph·∫ßn kh√¥ng ch√≠nh x√°c c·ªßa m√¥ h√¨nh tr√™n t·∫≠p test.\n$$ error = 1 - testing accuracy $$\nN·∫øu m√¥ h√¨nh ƒë·∫°t ƒë·ªô ch√≠nh x√°c l√† 86% tr√™n t·∫≠p test, ƒëi·ªÅu ƒë√≥ ƒë·ªìng nghƒ©a v·ªõi ƒë·ªô l·ªói l√† 14%. Trong 14% ƒë√≥ bao g·ªìm bias v√† variance.\nBi·ªÉu ƒë·ªì bias - variance. Ngu·ªìn towardsdatascience.com\nHai √Ω ch√≠nh c·ªßa h√¨nh tr√™n c·∫ßn l√†m r√µ ·ªü ƒë√¢y:\nBias l√† l·ªói tr√™n t·∫≠p hu·∫•n luy·ªán.\nVariance l√† gap gi·ªØa ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p train v√† ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p test.\nB·∫°n h√£y h√¨nh th·∫≠t k·ªπ v√†o h√¨nh ·ªü tr√™n, nh√¨n ƒëi nh√¨n l·∫°i 2, 3 l·∫ßn. Nh·∫Øm m·∫Øt l·∫°i v√† nghi·ªÅn ng·∫´m th·∫≠t k·ªπ hai √Ω ch√≠nh m√¨nh v·ª´a ƒë·ªÅ c·∫≠p ·ªü tr√™n.\nBias Bias m√¥ t·∫£ kh·∫£ nƒÉng h·ªçc c·ªßa m√¥ h√¨nh. Gi√° tr·ªã bias l·ªõn ƒë·ªìng nghƒ©a v·ªõi vi·ªác m√¥ h√¨nh c·∫ßn ph·∫£i h·ªçc nhi·ªÅu h∆°n n·ªØa t·ª´ t·∫≠p hu·∫•n luy·ªán.\nN·∫øu m√¥ h√¨nh c√≥ ƒë·ªô ch√≠nh x√°c 90% tr√™n t·∫≠p train, ƒëi·ªÅu ƒë√≥ ƒë·ªìng nghƒ©a v·ªõi vi·ªác b·∫°n c√≥ 10% bias. Bias c≈©ng ƒë∆∞·ª£c chia l√†m 2 nh√≥m, nh√≥m bias c√≥ th·ªÉ tr√°nh ƒë∆∞·ª£c (avoidable bias) v√† nh√≥m bias kh√¥ng th·ªÉ tr√°nh ƒë∆∞·ª£c (unavoidable bias).\n$$ bias = 1 - trainning accuracy $$\nUnavoidable bias Unavoidable bias hay c√≤n ƒë∆∞·ª£c s·ª≠ d·ª•ng d∆∞·ªõi t√™n l√† optimal error rate. ƒê√¢y l√† gi·ªõi h·∫°n tr√™n c·ªßa m√¥ h√¨nh. Trong m·ªôt s·ªë b√†i to√°n, v√≠ d·ª• nh∆∞ l√† b√†i to√°n d·ª± ƒëo√°n gi√° ch·ª©ng kho√°n, ch√∫ng ta - con ng∆∞·ªùi - kh√¥ng th·ªÉ d·ª± ƒëo√°n ch√≠nh x√°c 100%. Do ƒë√≥, trong ƒëi·ªÅu ki·ªán l√Ω t∆∞·ªüng nh·∫•t, t·∫°i m·ªôt th·ªùi ƒëi·ªÉm n√†o ƒë√≥, m√¥ h√¨nh c·ªßa ch√∫ng ta v·∫´n c·ª© tr·∫£ ra k·∫øt qu·∫£ sai.\nN·∫øu b·∫°n quy·∫øt ƒë·ªãnh r·∫±ng m√¥ h√¨nh c√≥ ƒë·ªô sai √≠t nh·∫•t l√† 4%. Nghƒ©a l√† ch√∫ng ta c√≥ 4% unavoidable bias.\nAvoidable bias Kh√°c v·ªõi optimal error rate v√† trainning error. ƒê·ªô l·ªói n√†y x·∫£y ra khi m√¥ h√¨nh ch√∫ng ta ch∆∞a ƒë·ªß ƒë·ªô t·ªõi. Ch√∫ng ta ho√†n to√†n c√≥ th·ªÉ c√°i ti·∫øn m√¥ h√¨nh n√†y ƒë·ªÉ gi·∫£m ƒë·ªô l·ªói n√†y v·ªÅ m·ª©c 0, v\nBi·ªÉu ƒë·ªì bias - variance. Ngu·ªìn towardsdatascience.com\nB·∫°n h√£y ƒë·ªÉ √Ω k·ªπ ph·∫ßn bias ·ªü h√¨nh tr√™n. Bias ƒë∆∞·ª£c chia l√†m 2 ph·∫ßn. ·ªû tr√™n ph·∫ßn n√©t ƒë·ª©t l√† Unavoidable bias. N√≥ l√† ƒëi·ªÉm t·ªõi h·∫°n c·ªßa m√¥ h√¨nh. Vi·ªác c·∫ßn l√†m c·ªßa ch√∫ng ta l√† hu·∫•n luy·ªán, c·∫£i ti·∫øn m√¥ h√¨nh, ƒë·ªÉ cho ƒë∆∞·ªùng trainning accuracy m√†u ƒë·ªè ti·∫øn s√°t v·ªõi ƒë∆∞·ªùng n√©t ƒë·ª©t.\nVariance Variance √Ω nghƒ©a c·ªßa n√≥ l√† m√¥ t·∫£ m·ª©c ƒë·ªô t·ªïng qu√°t h√≥a c·ªßa m√¥ h√¨nh c·ªßa b·∫°n ƒë·ªëi v·ªõi d·ªØ li·ªáu m√† n√≥ ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. V√† ƒë·ªãnh nghƒ©a c·ªßa n√≥ l√† ph·∫ßn sai l·ªách gi·ªØa ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p hu·∫•n luy·ªán v√† ƒë·ªô ch√≠nh x√°c t√™n t·∫≠p test.\n$$ Variance = trainning accuracy - testing accuracy $$\nBi·ªÉu ƒë·ªì variance. Ngu·ªìn towardsdatascience.com\nTradeoff gi·ªØa bias v√† variance S·ª± ƒë√°nh ƒë·ªïi gi·ªØa bias v√† variace. Ngu·ªìn towardsdatascience.com\nM√¨nh nghƒ© h√¨nh tr√™n ƒë·ªß n√≥i l√™n t·∫•t c·∫£ √Ω m√¨nh mu·ªën n√≥i. Khi m√¥ h√¨nh c·∫£ng tr·ªü n√™n ph·ª©c t·∫°p, th√¨ bias s·∫Ω gi·∫£m, nh∆∞ng m·ª©c ƒë·ªô t·ªïng qu√°t h√≥a c≈©ng gi·∫£m theo (ƒë·ªìng nghƒ©a v·ªõi vi·ªác variace s·∫Ω tƒÉng).\nC√°ch gi·∫£m bias v√† variance C√°ch gi·∫£m bias Nh∆∞ ƒë√£ n√≥i ·ªü ph·∫ßn tr√™n, bias ƒë∆∞·ª£c chia th√†nh 2 nh√≥m l√† Avoidable bias v√† unavoidable bias. Ch√∫ng ta kh√¥ng th·ªÉ n√†o gi·∫£m Avoidable bias, nh∆∞ng ch√∫ng ta c√≥ th·ªÉ gi·∫£m unavoidable bias b·∫±ng m·ªôt trong c√°c c√°ch sau.\nTƒÉng k√≠ch th∆∞·ªõc m√¥ h√¨nh Vi·ªác tƒÉng k√≠ch th∆∞·ªõc m√¥ h√¨nh l√† m·ªôt trong nh·ªØng c√°ch l√†m gi·∫£m avoidable bias. M√¥ h√¨nh c√†ng l·ªõn th√¨ c√≥ c√†ng nhi·ªÅu tham s·ªë ph·∫£i ƒëi·ªÅu ch·ªânh. C√≥ nhi·ªÅu tham sos ƒë·ªìng nghƒ©a v·ªõi vi·ªác m√¥ h√¨nh s·∫Ω h·ªçc ƒë∆∞·ª£c nhi·ªÅu m·ªëi quan h·ªá ph·ª©c t·∫°p h∆°n. Ch√∫ng ta c√≥ th·ªÉ tƒÉng k√≠ch th∆∞·ªõc m√¥ h√¨nh b·∫±ng c√°ch th√™m nhi·ªÅu layer h∆°n n·ªØa, ho·∫∑c th√™m nhi·ªÅu node h∆°n n·ªØa cho m·ªói layer.\nGi·∫£m Regulation Vi·ªác gi·∫£m regulation c≈©ng gi√∫p m√¥ h√¨nh tƒÉng ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p hu·∫•n luy√™n. Tuy nhi√™n, n·∫øu ch√∫ng ta gi·∫£m regularization qu√° ƒë√†, m√¥ h√¨nh s·∫Ω kh√¥ng ƒë·∫°t ƒë∆∞·ª£c m·ª©c ƒë·ªô t·ªïng qu√°t h√≥a, v√† l√†m tƒÉng variance. ƒê√¢y l√† v√≠ d·ª• d·ªÖ th·∫•y nh·∫•t nh·∫•t v·ªÅ s·ª± ƒë√°nh ƒë·ªïi gi·ªØa bias v√† variance.\nGi·∫£m Regulation . Ngu·ªìn towardsdatascience.com\nThay ƒë·ªïi ki·∫øn tr√∫c m√¥ h√¨nh Vi·ªác thay ƒë·ªïi ki·∫øn tr√∫c m√¥ h√¨nh c≈©ng c√≥ th·ªÉ gi√∫p ch√∫ng ta ƒë·∫°t ƒë∆∞·ª£c ƒë·ªô ch√≠nh x√°c cao h∆°n.\nM·ªôt s·ªë m·ª•c c√≥ th·ªÉ thay ƒë·ªïi:\nThay ƒë·ªïi activation function ( v√≠ d·ª• tanh, ReLU, sigmoid, LeakyReLU)\nThay ƒë·ªïi lo·∫°i m√¥ h√¨nh (ANN, CNN, RNN, KNNKNN, \u0026hellip;)\nThay ƒë·ªïi c√°c tham s·ªë (learning rate, image size, \u0026hellip;)\nThay ƒë·ªïi thu·∫≠t to√°n t·ªëi ∆∞u (Adam, SGD, RMSprop, ‚Ä¶)\nTh√™m ƒë·∫∑c tr∆∞ng m·ªõi Vi·ªác th√™m ƒë·∫∑c tr∆∞ng m·ªõi gi√∫p ch√∫ng ta cung c·∫•p cho m√¥ h√¨nh nhi·ªÅu th√¥ng tin h∆°n. Ch√∫ng ta c√≥ th·ªÉ th·ª±c hi·ªán ƒëi·ªÅu n√†y th√¥ng qua k·ªπ thu·∫≠t feature engineering.\nGi·∫£m variance Th√™m nhi·ªÅu d·ªØ li·ªáu Th√™m d·ªØ li·ªáu l√† c√°ch ƒë∆°n gi·∫£n nh·∫•t, th∆∞·ªùng g·∫∑p nh·∫•t ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh trong tr∆∞·ªùng h·ª£p m√¥ h√¨nh hu·∫•n luy·ªán c·ªßa ch√∫ng ta b·ªã hight variance. Hi·ªáu qu·∫£ c·ªßa vi·ªác th√™m nhi·ªÅu d·ªØ li·ªáu v√†o m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p ·ªü b√†i b√°o c√≥ t·ª±a ƒë·ªÅ l√† The Unreasonable Effectiveness of Recurrent Neural Networks c·ªßa Andrej Karpathy (link: http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Vi·ªác th√™m d·ªØ li·ªáu th∆∞·ªùng kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn ƒë·ªô l·ªói bias, gi√∫p l√†m gi·∫£m variance, n√™n ƒë√¢y l√† c√°ch th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng nh·∫•t.\nTƒÉng Regularization Vi·ªác tƒÉng Regularization gi√∫p m√¥ h√¨nh ch·ªëng overfitting. Qua ƒë√≥ gi√∫p gi·∫£m variance, v√† tƒÉng bias :(. M·ªôt s√≥ c√°ch Regularization hot ·ªü th·ªùi ƒëi·ªÉm hi·ªán l·∫°i l√† dropout ( v·ªõi bi·∫øn th·ªÉ l√† Monte Carlo Dropout), BatchNorm\u0026hellip;\nGi·∫£m k√≠ch th∆∞·ªõc m√¥ h√¨nh Vi·ªác gi·∫£m k√≠ch th∆∞·ªõc m√¥ h√¨nh gi√∫p cho ch√∫ng ta gi·∫£m overfitting tr√™n t·∫≠p train. M·ª•c ti√™u c·ªßa Vi·ªác n√†y l√†m gi·∫£m kh·∫£ nƒÉng li√™n k·∫øt nh·ªØng pattern c·ªßa d·ªØ li·ªáu. B·ªüi v·∫≠y, m·ª•c ti√™u c·ªßa n√≥ ho√†n to√†n t∆∞∆°ng t·ª± nh∆∞ tƒÉng Regularization. Trong th·ª±c t·∫ø, ch√∫ng ta th∆∞·ªùng s·ª≠ d·ª•ng tƒÉng th√™m Regularization h∆°n l√† gi·∫£m k√≠ch th∆∞·ªõc m√¥ h√¨nh ƒë·ªÉ ch·ªëng variace.\nL·ª±a ch·ªçn ƒë·∫∑c tr∆∞ng (feature selection) Gi·∫£m chi·ªÅu d·ªØ li·ªáu, b·∫±ng c√°ch b·ªè ƒëi c√°c ƒë·∫∑c tr∆∞ng th·ª´a, gi√∫p gi·∫£m nhi·ªÖu, l√† c√°ch th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ gi·∫£m variace. Ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng PCA (Principal Component Analysis) ƒë·ªÉ l·ªçc ra c√°c ƒë·∫∑c tr∆∞ng t·ªët ho·∫∑c k·∫øt h·ª£p ch√∫ng v·ªõi nhau ƒë·ªÉ t·∫°o c√°c ƒë·∫∑c tr∆∞ng t·ªët h∆°n.\nB·ª©c tranh t·ªïng qu√°t Sau t·∫•t c·∫£, ch√∫ng ta s·∫Ω x√¢y d·ª±ng ƒë∆∞·ª£c m·ªôt b·ª©c tranh t·ªïng quan v·ªÅ l·ªói ch√∫ng ta ƒëang m·∫Øc ph·∫£i l√† g√¨ v√† ch√∫ng ta n√™n l√†m g√¨ ƒë·ªÉ gi·∫£m ƒë·ªô l·ªói ƒë√≥.\nT·ªïng quan . Ngu·ªìn towardsdatascience.com\nT·ªïng k·∫øt Reducing Bias\nIncrease model size\nReduce regularization\nChange model architecture\nAdd features\nReducing Variance\nAdd More data\nDecrease model size\nAdd regularization\nFeature selection\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ quan t√¢m v√† theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\nB√†i vi·∫øt ƒë∆∞·ª£c l∆∞·ª£c d·ªãch t·ª´ link https://towardsdatascience.com/two-important-machine-learning-concepts-to-improve-every-model-62fd058916b\nNgu·ªìn t·ª± li·ªáu t·ª´ b√†i vi·∫øt ƒë∆∞·ª£c s·ª≠ d·ª•ng trong cu·ªën s√°ch Machine Learning Yearning c·ªßa Andrew Ng. C√°c b·∫°n c√≥ th·ªÉ search theo t·ª´ kh√≥a tr√™n ho·∫∑c ƒëƒÉng k√Ω tr√™n site http://deeplearning.net/\n","date":"Apr 16, 2020","img":"","permalink":"/blog/2020-04-16-two-important-machine-learning-concepts-to-improve-every-model/","series":null,"tags":["machine learning","deep learning","bias","variance"],"title":"Hai Kh√°i Ni·ªám Quan Tr·ªçng Gi√∫p TƒÉng ƒê·ªô Ch√≠nh X√°c C·ªßa C√°c M√¥ H√¨nh Trong Machine Learning"},{"categories":null,"content":" ƒê·∫∑t v·∫•n ƒë·ªÅ B√†i to√°n t√¨m ki·∫øm vƒÉn b·∫£n t∆∞∆°ng ƒë·ªìng V√¨ sao ph·∫£i d√πng Min-Hashing Thu·∫≠t to√°n MinHash ƒê·∫∑t v·∫•n ƒë·ªÅ Gi·∫£ s·ª≠ b·∫°n v√† t√¥i ƒë·ªÅu th√≠ch nghe nh·∫°c tr√™n trang mp3.zing.vn. M·ªói ng∆∞·ªùi ƒë·ªÅu nghe kho·∫£ng 100 b√†i nh·∫°c kh√°c nhau. ƒê·ªÉ ƒëo s·ª± gi·ªëng nhau gi·ªØa danh s√°ch b√†i h√°t b·∫°n nghe v√† danh s√°ch b√†i h√°t t√¥i nghe, th√¥ng th∆∞·ªùng ch√∫ng ta s·∫Ω d√πng ƒë·ªô ƒëo Jaccard Similarity, ƒë∆∞·ª£c ƒëo b·∫±ng c√°ch l·∫•y ph·∫ßn giao (intersection ) chia cho ph·∫ßn h·ª£p (union). Nghƒ©a l√† ƒë·∫øm s·ªë l∆∞·ª£ng b√†i h√°t c·∫£ hai c√πng nghe (ph·∫ßn giao) chia cho t·ªïng s·ªë b√†i h√°t kh√¥ng l·∫∑p c·ªßa c·∫£ hai.\nTrong tr∆∞·ªùng h·ª£p b·∫°n v√† t√¥i ƒë·ªÅu nghe 100 b√†i, trong ƒë√≥ c√≥ 30 b√†i gi·ªëng nhau, v·∫≠y ph·∫ßn giao l√† 30, ph·∫ßn h·ª£p l√† 170, gi√° tr·ªã Jaccard Similarity s·∫Ω l√† 30/170.\nƒê·ªô ƒëo Jaccard Similarity ƒë∆∞·ª£c s·ª≠ d·ª•ng ·ªü ph∆∞∆°ng ph√°p apriori , FP Growth, \u0026hellip; m√† c√°c b·∫°n ƒë√£ c√≥ d·ªãp h·ªçc trong m√¥n khai ph√° d·ªØ li·ªáu ·ªü ƒê·∫°i h·ªçc.\nB√†i to√°n t√¨m ki·∫øm vƒÉn b·∫£n t∆∞∆°ng ƒë·ªìng Gi·∫£ s·ª≠ b·∫°n qu·∫£n l√Ω m·ªôt s·ªë l∆∞·ª£ng l·ªõn vƒÉn b·∫£n (N= 1 t·ª∑), v√† x·∫øp c·ªßa b·∫°n c√≥ nhu c·∫ßu nh√≥m nh·ªØng b√†i vi·∫øt gi·ªëng nhau th√†nh t·ª´ng c·ª•m. ƒê·ªÉ:\nLo·∫°i b·ªè b·ªõt nh·ªØng k·∫øt qu·∫£ tr√πng trong khung search.\nNh√≥m nh·ªØng b√†i vi·∫øt v√†o t·ª´ng nh√≥m s·ª± ki·ªán theo d√≤ng th·ªùi gian, v√≠ d·ª• s·ª± ki·ªán \u0026lsquo;c√¥ g√°i giao g√†\u0026rsquo;, s·ª± ki·ªán \u0026lsquo;d·ªãch c√∫m corona\u0026rsquo;, \u0026hellip;\nV√¨ m·ªôt b·∫•t k·ªÉ l√Ω do n√†o ƒë√≥ m√† trong l√∫c vi·∫øt b√†i n√†y t√°c gi·∫£ ch∆∞a nghƒ© ra.\nKhi ƒë√≥, c√°c v·∫•n ƒë·ªÅu sau c√≥ th·ªÉ s·∫Ω ph√°t sinh:\nNhi·ªÅu ph·∫ßn nh·ªè c·ªßa vƒÉn b·∫£n n√†y xu·∫•t hi·ªán ·ªü m·ªôt v·ªã tr√≠ l·ªôn x·ªôn n√†o ·ªü m·ªôt ho·∫∑c nhi·ªÅu vƒÉn b·∫£n kh√°c.\nVƒÉn b·∫£n qu√° d√†i n√™n kh√¥ng th·ªÉ l∆∞u tr·ªØ h·∫øt l√™n b·ªô nh·ªõ ch√≠nh (RAM).\nC√≥ qu√° nhi·ªÅu c·∫∑p vƒÉn b·∫£n c·∫ßn ph·∫£i so s√°nh.\nƒê·ªÉ gi·∫£i quy·∫øt b√†i to√°n tr√™n, ch√∫ng ta s·∫Ω ti·∫øp c·∫≠n theo h∆∞·ªõng sau:\nShingling: Chuy·ªÉn vƒÉn b·∫£n th√†nh t·∫≠p k√Ω t·ª±, t·∫≠p t·ª´ \u0026hellip;.\nMin-Hashing: Chuy·ªÉn t·∫≠p k√Ω t·ª± th√†nh 1 chu·ªói s·ªë hash ƒë·ªãnh danh.\nLocality-Sensitive Hashing: T√¨m c√°c vƒÉn b·∫£n t∆∞∆°ng ƒë·ªìng d·ª±a v√†o chu·ªói s·ªë ƒë·ªãnh danh.\n·ªû b√†i vi·∫øt n√†y, m√¨nh ch·ªâ ƒë·ªÅ c·∫≠p b∆∞·ªõc th·ª© 2 l√† Min-Hashing. B∆∞·ªõc 1 v√† b∆∞·ªõc 3 b·∫°n c√≥ th·ªÉ tham kh·∫£o th√™m trong kh√≥a h·ªçc, m√¨nh c√≥ ƒë·ªÉ link b√™n d∆∞·ªõi.\nV√¨ sao ph·∫£i d√πng Min-Hashing Nh∆∞ b√†i to√°n ƒë·∫∑t ra ·ªü tr√™n, ch√∫ng ta c√≥ 1 t·ª∑ vƒÉn b·∫£n, ch√∫ng ta c·∫ßn N(N-1)/2 = 5*10^17 ph√©p t√≠nh Jaccard Similarity. Ch√∫ng ta c√≥ m·ªôt server c√≥ th·ªÉ th·ª±c hi·ªán 5x10^6 ph√©p so s√°nh, th√¨ ch√∫ng ta ph·∫£i m·∫•t 10^11 gi√¢y t∆∞∆°ng ƒë∆∞∆°ng 31,710 nƒÉm ƒë·ªÉ th·ª±c hi·ªán xong.\nThu·∫≠t to√°n MinHash s·∫Ω gi√∫p ch√∫ng ta m·ªôt gi√° tr·ªã x·∫•p x·ªâ gi√° tr·ªã c·ªßa Jaccard Similarity c·ªßa hai t·∫≠p d·ªØ li·ªáu. ∆Øu ƒëi·ªÉm c·ªßa MinHash:\nC√≥ chi·ªÅu d√†i ƒë·∫ßu ra c·ªë ƒë·ªãnh\nKh√¥ng ph·ª• thu·ªôc v√†o chi·ªÅu d√†i ƒë·∫ßu v√†o.\nƒê·ªÉ t√≠nh gi√° tr·ªã x·∫•p x·ªâ Jaccard Similarity (MinHash signatures), ƒë·∫ßu ti√™n ta s·∫Ω t√≠nh MinHash c·ªßa hai t·∫≠p data, ƒë∆∞·ª£c 2 gi√° tr·ªã hash, sau ƒë√≥ ƒë·∫øm gi√° tr·ªã tr√πng nhau c·ªßa 2 chu·ªói hash v√† chia chi·ªÅu d√†i g√≠a tr·ªã hash, ch√∫ng ta s·∫Ω ƒë∆∞·ª£c m·ªôt gi√° tr·ªã x·∫•p x·ªâ gi√° tr·ªã Jaccard Similarity.\nV√≠ d·ª• ta c√≥ hai t·∫≠p t·∫≠p d·ªØ li·ªáu {a,x,c,d} v√† {a,x,d,e} hai gi√° tr·ªã hash ta c√≥ t∆∞∆°ng ·ª©ng l√† 1234 v√† 1235, s·ªë k√Ω t·ª± tr√πng nhau l√† 3 (1,2,3), chi·ªÅu d√†i l√† 4, v·∫≠y ta c√≥ gi√° tr·ªã Jaccard Similarity l√† 3/4.\nPh√©p t√≠nh n√†y s·∫Ω h∆°n vi·ªác t√≠nh Jaccard Similarity truy·ªÅn th·ªëng, l√Ω do l√† ch√∫ng ta kh√¥ng c·∫ßn ph·∫£i t√≠nh ph·∫ßn giao v√† ph·∫ßn h·ª£p c·ªßa hai t·∫≠p d·ªØ li·ªáu ( trong tr∆∞·ªùng h·ª£p hai t·∫≠p c√≥ nhi·ªÅu gi√° tr·ªã th√¨ vi·ªác t√≠nh c√†ng l√¢u), v√† gi√° tr·ªã hash th∆∞·ªùng c√≥ chi·ªÅu d√†i ng·∫Øn h∆°n so v·ªõi s·ªë l∆∞·ª£ng ph·∫ßn tr·ª≠ trong t·∫≠p d·ªØ li·ªáu, ngo√†i ra ph√©p so s√°nh c≈©ng ƒë∆°n gi·∫£n h∆°n nhi·ªÅu.\nThu·∫≠t to√°n MinHash √ù t∆∞·ªüng c·ªßa thu·∫≠t to√°n kh√° ƒë∆°n gi·∫£n:\nta c√≥ h√†m hash:\n$$ h(x) = (ax+b)%c $$\nTrong ƒë√≥:\nx l√† s·ªë nguy√™n ƒë·∫ßu v√†o, a v√† b l√† hai s·ªë ƒë∆∞·ª£c ch·ªçn ng·∫´u nhi√™n v·ªõi ƒëi·ªÅu ki·ªán a v√† b \u0026lt; x\nc l√† s·ªë nguy√™n t·ªë ƒë∆∞·ª£c ch·ªçn ng·∫´u nhi√™n, v·ªõi ƒëi·ªÅu ki·ªán c l·ªõn h∆°n x.\nC√°ch thu·∫≠t to√°n th·ª±c hi·ªán nh∆∞ sau:\nV·ªõi 1 vƒÉn b·∫£n, ch·∫°y thu·∫≠t to√°n hash 10 l·∫ßn, do ta c√≥ s·ªë a v√† b l√† ng·∫´u nhi√™n n√™n 10 l·∫ßn ch·∫°y s·∫Ω cho ra c√°c k·∫øt qu·∫£ kh√°c nhau, l·∫•y gi√° tr·ªã hash nh·ªè nh·∫•t (do ƒë√≥ thu·∫≠t to√°n c√≥ t√™n l√† min hash) l√†m th√†nh ph·∫ßn ƒë·∫ßu ti√™n c·ªßa MinHash signature. L·∫∑p l·∫°i qu√° tr√¨nh tr√™n 10 l·∫ßn, ch√∫ng ta c√≥ MinHash signature v·ªõi 10 gi√° tr·ªã.\nXong thu·∫≠t to√°n, qu√° d·ªÖ.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ quan t√¢m v√† theo d√µi b√†i vi·∫øt, h·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\nTham kh·∫£o\nKh√≥a h·ªçc Mining of Massive Datasets ch∆∞∆°ng 3 http://www.mmds.org/\nhttps://mccormickml.com/2015/06/12/minhash-tutorial-with-python-code/\n","date":"Jan 26, 2020","img":"","permalink":"/blog/2020-01-26-simhash/","series":null,"tags":["python","hash"],"title":"Simhash"},{"categories":null,"content":" Built-In Hashing Checksums Secure Hashing MD5‚Äì 16 bytes/128 bit SHA1‚Äì20 bytes/160 bits SHA256‚Äì32 bytes/256 bit v√† SHA512‚Äì64 bytes/512 bit Near-Duplicate Detection Perceptual Hashing K·∫øt lu·∫≠n Built-In Hashing Python c√≥ x√¢y d·ª±ng s·∫µn cho ch√∫ng ta m·ªôt h√†m hash, ch√∫ng ta c·ª© vi·ªác g·ªçi ra v√† s·ª≠ d·ª•ng.\n1hash(\u0026#34;pham duy tung\u0026#34;) 2-7141560399917772220 M·ªôt l∆∞u √Ω nh·ªè l√† gi√° tr·ªã c·ªßa h√†m hash s·∫Ω kh√°c nhau gi·ªØa c√°c phi√™n b·∫£n python. V√≠ d·ª• ·ªü tr√™n m√¨nh x√†i python 3.8, v·ªõi b·∫£n 3.6 s·∫Ω l√†\n1hash(\u0026#34;pham duy tung\u0026#34;) 21568935795476364190 Checksums Ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng checksums ƒë·ªÉ hash d·ªØ li·ªáu. Checksum ƒë∆∞·ª£c s·ª≠ d·ª•ng trong thu·∫≠t to√°n n√©n file ZIP ƒë·ªÉ ƒë·∫£m b·∫£o to√†n v·∫πn d·ªØ li·ªáu sau khi n√©n. Th∆∞ vi·ªán zlib c·ªßa python h·ªó tr·ª£ 2 h√†m t√≠nh checksum l√† adler32 v√† crc32. ƒê·ªÉ ƒë·∫£m b·∫£o t·ªëc ƒë·ªô ch∆∞∆°ng tr√¨nh v√† ch·ªâ c·∫ßn l·∫•y hash ƒë∆°n gi·∫£n, ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m Adler32. Tuy nhi√™n, n·∫øu b·∫°n mu·ªën ch∆∞∆°ng tr√¨nh c√≥ ƒë·ªô tin c·∫≠y cao ho·∫∑c ƒë∆°n gi·∫£n l√† checksums, h√£y s·ª≠ d·ª•ng crc32. C√°c b·∫°n c√≥ th·ªÉ ƒë·ªçc b√†i vi·∫øt ·ªü ƒë√¢y https://www.leviathansecurity.com/blog/analysis-of-adler32 ƒë·ªÉ hi·ªÉu h∆°n.\n1\u0026gt;\u0026gt;\u0026gt; import zlib 2\u0026gt;\u0026gt;\u0026gt; zlib.adler32(b\u0026#34;Pham Duy Tung\u0026#34;) 3524616855 4\u0026gt;\u0026gt;\u0026gt; zlib.crc32(b\u0026#34;Pham Duy Tung\u0026#34;) 53750031252 Secure Hashing M√£ h√≥a an to√†n (Secure Hashing) v√† b·∫£o m·∫≠t d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c nghi√™n c·ª©u v√† ·ª©ng d·ª•ng t·ª´ nhi·ªÅu nƒÉm v·ªÅ tr∆∞·ªõc. Ti·ªÅn th√¢n l√† thu·∫≠t to√°n MD5 ƒë·∫øn SHA1, SHA256, SHA512\u0026hellip;. M·ªói thu·∫≠t to√°n ra ƒë·ªùi sau s·∫Ω c·∫£i ti·∫øn ƒë·ªô b·∫£o m·∫≠t v√† gi·∫£m ƒë·ª•ng ƒë·ªô c·ªßa c√°c thu·∫≠t to√°n tr∆∞·ªõc ƒë√≥.\nM·ªôt s·ªë h√†m hash ph·ªï bi·∫øn:\nMD5‚Äì 16 bytes/128 bit Chu·ªói ƒë·∫ßu ra c·ªßa MD5 c√≥ k√≠ch th∆∞·ªõc 16 bytes hay 16*8 = 128 bits. ·ªû th·ªùi ƒëi·ªÉm hi·ªán t·∫°i MD5 kh√¥ng c√≤n l√† thu·∫≠t to√°n ph·ªï bi·∫øn v√† kh√¥ng ƒë∆∞·ª£c khuy·∫øn kh√≠ch d√πng b·ªüi c√°c t·ªï ch·ª©c b·∫£o m·∫≠t.\n1\u0026gt;\u0026gt;\u0026gt; import hashlib 2\u0026gt;\u0026gt;\u0026gt; hashlib.md5(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 3\u0026#39;58067430b9caa44f5ac1220b171f45c8\u0026#39; 4\u0026gt;\u0026gt;\u0026gt; len(hashlib.md5(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) # Chi·ªÅu d√†i c·ªßa ƒë·∫ßu ra l√† 16 bytes 516 Ch√∫ √Ω: H√†m hexdigest bi·ªÉu di·ªÖn m·ªôt byte th√†nh m·ªôt k√Ω t·ª± hex (2 k√Ω t·ª± ƒë·∫ßu 58 c·ªßa v√≠ d·ª• tr√™n l√† gi√° tr·ªã hex c·ªßa s·ªë 88 trong h·ªá th·∫≠p ph√¢n)\nSHA1‚Äì20 bytes/160 bits ƒê·∫ßu ra c·ªßa SHA1 c√≥ chi·ªÅu d√†i l√† 20 bytes t∆∞∆°ng ·ª©ng v·ªõi 160 bit. C≈©ng gi·ªëng nh∆∞ MD5, SHA1 c≈©ng kh√¥ng ƒë∆∞·ª£c khuy·∫øn kh√≠ch s·ª≠ d·ª•ng ·ªü trong c√°c ·ª©ng d·ª•ng b·∫£o m·∫≠t.\n1\u0026gt;\u0026gt;\u0026gt; import hashlib 2\u0026gt;\u0026gt;\u0026gt; hashlib.sha1(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 3\u0026#39;b95b8716f15d89b6db67e2e788dea42d3fba5ee8\u0026#39; 4\u0026gt;\u0026gt;\u0026gt; len(hashlib.sha1(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) 520 SHA256‚Äì32 bytes/256 bit v√† SHA512‚Äì64 bytes/512 bit ƒê√¢y l√† hai h√†m hash ƒë∆∞·ª£c khuy√™n l√† n√™n d√πng ·ªü th·ªùi ƒëi·ªÉm hi·ªán t·∫°i\n1\u0026gt;\u0026gt;\u0026gt; hashlib.sha256(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 2\u0026#39;611b322b6b8ee570831c6061408ac5aa77fcdb572206d5d443855f5d3c1383c6\u0026#39; 3\u0026gt;\u0026gt;\u0026gt; len(hashlib.sha256(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) 432 5\u0026gt;\u0026gt;\u0026gt; hashlib.sha512(b\u0026#34;Pham Duy Tung\u0026#34;).hexdigest() 6\u0026#39;ac1f6a2dd234bc15c1fa2be1db4e55ad4af8c476abb8e3d9ac3d4c74d3e151c23314e20925616e90a0bcb13a38b5531e064c586d65fed54504d713fdabee03f9\u0026#39; 7\u0026gt;\u0026gt;\u0026gt; len(hashlib.sha512(b\u0026#34;Pham Duy Tung\u0026#34;).digest()) 864 Near-Duplicate Detection C√°c thu·∫≠t to√°n ƒë∆∞·ª£c gi·ªõi thi·ªáu ·ªü tr√™n, khi ch√∫ng ta thay ƒë·ªïi gi√° tr·ªã ƒë·∫ßu v√†o, d√π ch·ªâ m·ªôt gi√° tr·ªã nh·ªè th√¥i ·ªü m·ªôt v√†i v·ªã tr√≠ n√†o ƒë√≥, th√¨ k·∫øt qu·∫£ tr·∫£ ra l·∫°i kh√°c nhau kh√° l·ªõn. Tuy nhi√™n, ƒë√¥i khi ch√∫ng ta g·∫∑p nh·ªØng b√†i to√°n t√¨m n·ªôi dung t∆∞∆°ng t·ª± nhau ho·∫∑c g·∫ßn nh∆∞ t∆∞∆°ng t·ª± nhau. V√≠ d·ª• gi·ªëng nh∆∞ google crawler d·ªØ li·ªáu x√°c ƒë·ªãnh nh·ªØng b√†i vƒÉn copy paste t·ª´ nh·ªØng trang web kh√°c nhau, ho·∫∑c ph√°t hi·ªán ƒë·∫°o vƒÉn, ph√°t hi·ªán ƒë·∫°o nh·∫°c \u0026hellip;\nM·ªôt thu·∫≠t to√°n kh√° ph·ªï bi·∫øn n·∫±m trong nh√≥m n√†y l√† SimHash. Thu·∫≠t to√°n ƒë∆∞·ª£c google s·ª≠ d·ª•ng ƒë·ªÉ t√¨m ra c√°c trang g·∫ßn tr√πng nhau (theo wiki https://en.wikipedia.org/wiki/SimHash). T√°c gi·∫£ c·ªßa thu·∫≠t to√°n l√† Moses Charikar.\nƒê·ªÉ d√πng Simhash, ch√∫ng ta ph·∫£i c√†i ƒë·∫∑t package t·ª´ kho c·ªßa python\n1from simhash import Simhash 2 3\u0026gt;\u0026gt;\u0026gt; Simhash(\u0026#34;Pham Duy Tung\u0026#34;).value 417022061268703429674 5\u0026gt;\u0026gt;\u0026gt; Simhash(\u0026#34;Pham Duy Tung1\u0026#34;).value 617184261516160517290 M·ªôt trong nh·ªØng l∆∞u √Ω quan tr·ªçng khi s·ª≠ d·ª•ng SimHash ( tham kh·∫£o https://stackoverflow.com/questions/49820228/how-to-compare-the-similarity-of-documents-with-simhash-algorithm/49831194#49831194)\nSimHash th·∫≠t s·ª± h·ªØu √≠ch trong b√†i to√°n ph√°t hi·ªán vƒÉn b·∫£n tr√πng l·∫Øp.\nƒê·ªÉ t√¨m vƒÉn b·∫£n tr√πng l·∫Øp ch√≠nh x√°c, d√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c thu·∫≠t to√°n ƒë∆°n gi·∫£n m√† hi·ªáu qu·∫£ nh∆∞ md5, sha1sha1.\nThu·∫≠t to√°n ph√π h·ª£p c√°c vƒÉn b·∫£n l·ªõn, kh√¥ng ph√π h·ª£p cho c√°c c√¢u vƒÉn nh·ªè.\nƒêo·∫°n code b√™n d∆∞·ªõi l√† m·ªôt v√≠ d·ª• ƒë∆∞·ª£c d√πng ƒë·ªÉ t√¨m c√°c vƒÉn b·∫£n c√≥ ƒë·∫°o n·ªôi dung.\n1 #assuming that you have a dictionary with document id as the key and the document as the value: 2# documents = { doc_id: doc } you can do: 3 4from simhash import simhash 5 6def split_hash(str, num): 7 return [ str[start:start+num] for start in range(0, len(str), num) ] 8 9hashes = {} 10for doc_id, doc in documents.items(): 11 hash = simhash(doc) 12 13 # you can either use the whole hash for higher precision or split into chunks for higher recall 14 hash_chunks = split_hash(hash, 4) 15 16 for chunk in hash_chunks: 17 if chunk not in hashes: 18 hashes[chunk] = [] 19 hashes[chunk].append(doc_id) 20 21# now you can print the duplicate documents: 22for hash, doc_list in hashes: 23 if doc_list \u0026gt; 1: 24 print(\u0026#34;Duplicates documents: \u0026#34;, doc_list) Ngo√†i SimHash, c√≤n m·ªôt thu·∫≠t to√°n hash kh√° n·ªïi ti·∫øng n·ªØa c≈©ng ƒë∆∞·ª£c google s·ª≠ d·ª•ng trong vi·ªác c√° nh√¢n h√≥a ng∆∞·ªùi d√πng, ƒë√≥ l√† MinHash. ·ªû c√°c b√†i vi·∫øt ti·∫øp theo m√¨nh s·∫Ω vi·∫øt v·ªÅ thu·∫≠t to√°n n√†y.\nPerceptual Hashing Lo·∫°i hash cu·ªëi c√πng ch√∫ng ta ƒë·ªÅ c·∫≠p ·ªü ƒë√¢y l√† perceptual hashing. Lo·∫°i hash n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ph√°t hi·ªán s·ª± kh√°c nhau trong t·∫≠p h√¨nh ·∫£nh ho·∫∑c trong video.\nM·ªôt v√≠ d·ª• c·ªßa c√°c thu·∫≠t to√°n thu·ªôc nh√≥m l√† l√† ƒë∆∞·ª£c d√πng ƒë·ªÉ ph√°t hi·ªán c√°c frame ·∫£nh tr√πng l·∫Øp trong video. Thu·∫≠t to√°n ƒë∆∞·ª£c d√πng ƒë·ªÉ lo·∫°i b·ªè nh·ªØng n·ªôi dung tr√πng l·∫Øp, gi√∫p ti·∫øt ki·ªám l∆∞u tr·ªØ. Ho·∫∑c d√πng trong c√°c thu·∫≠t to√°n t√≥m t·∫Øt video.\n·∫¢nh 1 ·∫¢nh 2\n1\u0026gt;\u0026gt;\u0026gt; import hashlib 2\u0026gt;\u0026gt;\u0026gt; from PIL import Image 3\u0026gt;\u0026gt;\u0026gt; image1 = Image.open(\u0026#34;google_free_ds1.png\u0026#34;) 4\u0026gt;\u0026gt;\u0026gt; image1 = Image.open(\u0026#34;google_free_ds_1.png\u0026#34;) 5\u0026gt;\u0026gt;\u0026gt; image2 = Image.open(\u0026#34;google_free_ds_2.png\u0026#34;) 6\u0026gt;\u0026gt;\u0026gt; hashlib.sha256(image1.tobytes()).hexdigest() 7\u0026#39;c57d0b5b1ca64077b45bdb65f817497834675232a2fc2ed76d6b8aa7955126b9\u0026#39; 8\u0026gt;\u0026gt;\u0026gt; hashlib.sha256(image2.tobytes()).hexdigest() 9\u0026#39;02ea5e51b19cf3748f91f9bbe26976e9e14dca4b47e0aaff88ab20030a695f44\u0026#39; Gi√° tr·ªã hash kh√°c xa nhau, c√≥ v·∫ª ch√∫ng ta kh√¥ng th·ªÉ n√†o s·ª≠ d·ª•ng SHA256 trong b√†i to√°n n√†y ƒë∆∞·ª£c. L√∫c n√†y, ch√∫ng ta s·∫Ω t√¨m t·ªõi c√°c th∆∞ vi·ªán thu·ªôc nh√≥m Perceptual Hashing, m·ªôt trong s·ªë ch√∫ng l√† ImageHash.\n1\u0026gt;\u0026gt;\u0026gt; import imagehash 2\u0026gt;\u0026gt;\u0026gt; hash1 = imagehash.average_hash(image1) 3\u0026gt;\u0026gt;\u0026gt; hash2 = imagehash.average_hash(image2) 4\u0026gt;\u0026gt;\u0026gt; hash1-hash2 524 Gi√° tr·ªã hash c·ªßa hai ·∫£nh tr√™n l√† kh√°c nhau, nh∆∞ng s·ª± kh√°c nhau l√† r·∫•t √≠t. Ch·ª©ng t·ªè hai ·∫£nh tr√™n c√≥ th·ªÉ l√† b·∫£n sao c·ªßa nhau.\nK·∫øt lu·∫≠n Trong b√†i vi·∫øt n√†y, ch√∫ng ta ƒë√£ ƒë·ªÅ c·∫≠p qua c√°c c√°ch kh√°c nhau ƒë·ªÉ hash d·ªØ li·ªáu trong Python. Ph·ª• thu·ªôc v√†o b√†i to√°n, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng c√°c thu·∫≠t to√°n v·ªõi c√°c tham s·ªë ph√π h·ª£p. Hi v·ªçng b√†i vi·∫øt n√†y s·∫Ω √≠t nhi·ªÅu gi√∫p √≠ch ƒë∆∞·ª£c cho c√°c b·∫°n.\nCh√∫ th√≠ch:\n·∫¢nh cover c·ªßa b√†i vi·∫øt l√† ·∫£nh c·ªßa ch√πm sao th·∫•t tinh b·∫Øc ƒë·∫©u m√¨nh ch·ª•p t·ª´ trang https://stellarium-web.org/.\nhash collision : Khi cho 2 input kh√°c nhau v√†o h√†m hash m√† c√πng ra m·ªôt output -\u0026gt; collision.\nNgu·ªìn b√†i vi·∫øt:\nhttps://medium.com/better-programming/how-to-hash-in-python-8bf181806141\n","date":"Jan 25, 2020","img":"","permalink":"/blog/2020-01-13-hash-in-python/","series":null,"tags":["python","hash"],"title":"C√°c H√†m Hash C√≥ S·∫µn Trong Python"},{"categories":null,"content":" ƒê·∫∑t v·∫•n ƒë·ªÅ Thu·∫≠t to√°n NMS ƒê·∫∑t v·∫•n ƒë·ªÅ Sau khi th·ª±c hi·ªán object detection feed m·ªôt ·∫£nh qua m·∫°ng neural, ch√∫ng ta s·∫Ω thu ƒë∆∞·ª£c r·∫•t nhi·ªÅu proposals (nh∆∞ h√¨nh ·ªü d∆∞·ªõi). ·ªû tr·∫°ng th√°i n√†y, c√≥ r·∫•t nhi·ªÅu proposals l√† boding box cho m·ªôt object duy nh·∫•t, ƒëi·ªÅu n√†y d·∫´n t·ªõi vi·ªác d∆∞ th·ª´a. Ch√∫ng ta s·ª≠ d·ª•ng thu·∫≠t to√°n Non-maximum suppression (NMS) ƒë·ªÉ gi·∫£i quy·∫øt b√†i to√°n n√†y.\nH√¨nh 1: Proposals box, h√¨nh ƒë∆∞·ª£c c·∫Øt t·ª´ b√†i b√°o\nThu·∫≠t to√°n NMS ƒê·∫ßu v√†o:\nT·∫≠p danh s√°ch c√°c proposals box k√Ω hi·ªáu l√† B v·ªõi B ={b1,b2,\u0026hellip;,bn}, v·ªõi bi l√† proposal th·ª© i.\nT·∫≠p ƒëi·ªÉm c·ªßa m·ªói proposal box k√Ω hi·ªáu l√† S v·ªõi S={s1,s2,\u0026hellip;,sn}, si l√† ƒëi·ªÉm confidence c·ªßa box bi\nGi√° tr·ªã ng∆∞·ª°ng overlap threshold N.\nC·∫£ hai gi√° tr·ªã bi v√† si ƒë·ªÅu l√† output c·ªßa m·∫°ng neural network.\nƒê·∫ßu ra:\nM·ªôt t·∫≠p c√°c proposals box D l√† t·∫≠p c√°c proposals ƒë√£ lo·∫°i b·ªè d∆∞ th·ª´a t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng object trong h√¨nh.\nThu·∫≠t to√°n:\nB∆∞·ªõc 1: Kh·ªüi t·∫°o t·∫≠p output D = {}\nB∆∞·ªõc 2: Ch·ªçn ra proposal box c√≥ ƒëi·ªÉm confidence cao nh·∫•t trong t·∫≠p S, lo·∫°i box ƒë√≥ ra kh·ªèi t·∫≠p S, B v√† th√™m n√≥ v√†o t·∫≠p D.\nB∆∞·ªõc 3: T√≠nh gi√° tr·ªã IOU gi·ªØa proposal box m·ªõi v·ª´a lo·∫°i ra ·ªü b∆∞·ªõc 2 v·ªõi to√†n b·ªô proposal box trong t·∫≠p B. N·∫øu c√≥ b·∫•t k·ª≥ box n√†o ƒë√≥ c√≥ gi√° tr·ªã IOU l·ªõn h∆°n gi√° tr·ªã ng∆∞·ª°ng N th√¨ lo·∫°i box ƒë√≥ ra kh·ªèi B, S.\nB∆∞·ªõc 4: L·∫∑p l·∫°i b∆∞·ªõc 2 ƒë·∫øn khi n√†o kh√¥ng c√≤n box n√†o c√≥ trong t·∫≠p B.\nƒêi·ªÉm y·∫øu c·ªßa thu·∫≠t to√°n:\nN·∫øu b·∫°n ƒë·ªçc k·ªπ thu·∫≠t to√°n, b·∫°n s·∫Ω th·∫•y r·∫±ng to√†n b·ªô qu√° tr√¨nh loai b·ªè nh·ªØng box d∆∞ th·ª´a ƒë·ªÅu ph·ª• thu·ªôc v√†o gi√° tr·ªã ng∆∞·ª°ng N. Vi·ªác ch·ªçn l·ª±a gi√° tr·ªã N ch√≠nh l√† ch√¨a kh√≥a th√†nh c√¥ng c·ªßa m√¥ h√¨nh. Tuy nhi√™n, vi·ªác ch·ªçn gi√° tr·ªã ng∆∞·ª°ng n√†y trong c√°c b√†i to√°n kh√° kh√≥. V√† v·ªõi vi·ªác ch·ªâ s·ª≠ d·ª•ng gi√° tr·ªã N, ch√∫ng ta s·∫Ω g·∫∑p tr∆∞·ªùng h·ª£p d∆∞·ªõi ƒë√¢y.\nGi·∫£ s·ª≠a gi√° tr·ªã ng∆∞·ª°ng N b·∫°n ch·ªçn l√† 0.5. C√≥ nghƒ©a l√† n·∫øu box c√≥ gi√° tr·ªã l·ªõn IOU ƒë·ªÅu b·ªã lo·∫°i b·ªè, ngay c·∫£ v·ªõi tr∆∞·ªùng h·ª£p ƒëi·ªÉm score si c·ªßa n√≥ c√≥ gi√° tr·ªã cao. Ng∆∞·ª£c l·∫°i, gi·∫£ s·ª≠ box c√≥ ƒëi·ªÉm score si th·∫•p nh∆∞ng IOU c·ªßa n√≥ nh·ªè h∆°n 0.5, v√≠ d·ª• o.49, th√¨ n√≥ l·∫°i ƒë∆∞·ª£c nh·∫≠n.\nV√† ƒë·ªÉ gi·∫£i quy·∫øt b√†i to√°n n√†y Navaneeth Bodla ƒë√£ ƒë·ªÅ xu·∫•t m·ªôt c·∫£i ti·∫øn nh·ªè v√† ƒë·∫∑t t√™n thu·∫≠t to√°n l√† Soft-NMS. √Ω t∆∞·ªüng ƒë∆∞·ª£c ƒë·ªÅ ra nh∆∞ sau: Thay v√¨ ph·∫£i lo·∫°i b·ªè ho√†n to√†n proposal, ch√∫ng ta s·∫Ω gi·∫£m gi√° tr·ªã confidence c·ªßa box ƒëi.\nsoft-nms, h√¨nh ƒë∆∞·ª£c c·∫Øt t·ª´ b√†i b√°o\nV·ªõi gi√° tr·ªã si ƒë∆∞·ª£c c·∫≠p nh·∫≠t l·∫°i nh∆∞ sau:\nsoft-nms, h√¨nh ƒë∆∞·ª£c c·∫Øt t·ª´ b√†i b√°o\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt. H·∫πn g·∫∑p l·∫°i c√°c b·∫°n ·ªü nh·ªØng b√†i vi·∫øt ti·∫øp theo.\nTham kh·∫£o\nhttps://medium.com/@yusuken/object-detction-1-nms-ed00d16fdcf9\nhttps://towardsdatascience.com/non-maximum-suppression-nms-93ce178e177c\nhttps://arxiv.org/pdf/1704.04503.pdf\nhttps://arxiv.org/pdf/1705.02950.pdf\n","date":"Dec 25, 2019","img":"","permalink":"/blog/2019-12-25-nms/","series":null,"tags":["Machine learning","Deeplearning","AlexNet"],"title":"T√¨m Hi·ªÉu Non-Maximum Suppression (NMS)"},{"categories":null,"content":" Ki·∫øn tr√∫c m·∫°ng AlexNet C·∫£i ti·∫øn c·ªßa m√¥ h√¨nh ƒë·ªÉ gi·∫£m error rate S·ª≠ d·ª•ng ReLU thay cho TanH Local Response Normalization Overlapping Pooling S·ª≠ d·ª•ng Data Augmentation Dropout S·ª≠ d·ª•ng nhi·ªÅu GPU M·ªôt s·ªë chi ti·∫øt kh√°c v·ªÅ c√°c learning param K·∫øt qu·∫£ M·∫°ng CaffeNet Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu m√¥ h√¨nh AlexNet t·ª´ nh√≥m c·ªßa gi√°o s∆∞ Hinton. T·ªõi th·ªùi ƒëi·ªÉm hi·ªán t·∫°i (2019-05-27), b√†i vi·∫øt c·ªßa gi√°o s∆∞ ƒë√£ c√≥ h∆°n 40316 l∆∞·ª£t tr√≠ch d·∫´n. B√†i b√°o n√†y c√≥ b∆∞·ªõc ƒë√≥ng g√≥p c·ª±c k·ª≥ quan tr·ªçng, l√† m·ªôt ƒë·ªôt ph√° l·ªõn trong lƒ©nh v·ª±c deep learning, m·ªü ƒë·∫ßu cho s·ª± quay l·∫°i c·ªßa m·∫°ng neural network v√† ƒë√≥ng g√≥p tr·ª±c ti·∫øp v√†o th√†nh c√¥ng c·ªßa nh·ªØng ch∆∞∆°ng tr√¨nh tr√≠ tu·ªá nh√¢n t·∫°o t·∫°i th·ªùi ƒëi·ªÉm hi·ªán t·∫°i.\nV·ªÅ b√†i b√°o g·ªëc c·ªßa t√°c gi·∫£, m√¨nh c√≥ ƒë·ªÉ ·ªü ph·∫ßn tr√≠ch d·∫´n b√™n d∆∞·ªõi. C√°c b·∫°n c√≥ nhu c·∫ßu t√¨m hi·ªÉu c√≥ th·ªÉ t√¨m v√† ƒë·ªçc. Theo √Ω ki·∫øn ri√™ng c·ªßa m√¨nh, ƒë√¢y l√† m·ªôt b√†i b√°o r·∫•t n√™n ƒë·ªçc v√† ph·∫£i ƒë·ªçc. Tr∆∞·ªõc ƒë√¢y m√¨nh ƒë√£ c√≥ vi·∫øt 1 b√†i v·ªÅ t·∫≠p AlexNet nh∆∞ng ch∆∞a ƒë·∫ßy ƒë·ªß, b√†i ƒë√≥ m√¨nh ch·ªâ gi·ªõi thi·ªáu ph·ªõt ph·ªõt qua m·∫°ng AlexNet. Trong b√†i vi·∫øt n√†y, m√¨nh s·∫Ω tr√¨nh b√†y k·ªπ h∆°n.\nS∆° l∆∞·ª£c m·ªôt ch√∫t, t·∫≠p d·ªØ li·ªáu ImageNet l√† t·∫≠p dataset c√≥ kho·∫£ng 15 tri·ªáu h√¨nh ·∫£nh c√≥ ƒë·ªô ph√¢n gi·∫£i cao ƒë√£ ƒë∆∞·ª£c g√°n nh√£n (c√≥ kho·∫£ng 22000 nh√£n). Cu·ªôc thi ILSVRC s·ª≠ d·ª•ng m·ªôt ph·∫ßn nh·ªè c·ªßa t·∫≠p ImageNet v·ªõi kho·∫£ng 1.2 tri·ªáu ·∫£nh c·ªßa 1000 nh√£n (trung b√¨nh m·ªói nh√£n c√≥ kho·∫£ng 1.2 ng√†n h√¨nh ·∫£nh) l√†m t·∫≠p train, 50000 ·∫£nh l√†m t·∫≠p validation v√† 150000 ·∫£nh l√†m t·∫≠p test (t·∫≠p validation v√† t·∫≠p test ƒë·ªÅu c√≥ 1000 nh√£n thu·ªôc t·∫≠p train).\nKi·∫øn tr√∫c m·∫°ng AlexNet Ki·∫øn tr√∫c m√¥ h√¨nh AlexNet\nM·∫°ng AlexNet bao g·ªìm 8 l·ªõp (t√≠nh lu√¥n l·ªõp input l√† 9), bao g·ªìm:\nInput: c√≥ k√≠ch th∆∞·ªõc 224x224x3 (Scale ·∫£nh ƒë·∫ßu v√†o v·ªÅ d·∫°ng 224x224x3, th·ª±c ch·∫•t ·∫£nh c·ªßa t·∫≠p ImageNet c√≥ size t√πy √Ω)\nL·ªõp th·ª© nh·∫•t:\nConvolution Layer c√≥ k√≠ch th∆∞·ªõc 11x11x3 v·ªõi stride size = 4 v√† pad = 0. K·∫øt qu·∫£ sau b∆∞·ªõc n√†y ta ƒë∆∞·ª£c t·∫≠p feature map c√≥ k√≠ch th∆∞·ªõc 55x55x96 (m√¨nh nghƒ© l√† c√°c b·∫°n s·∫Ω bi·∫øt c√°ch t√≠nh sao cho ra s·ªë 55, m√¨nh c≈©ng ƒë√£ ƒë·ªÅ c·∫≠p v·∫•n ƒë·ªÅ c√°ch t√≠nh n√†y ·ªü 1 b√†i vi·∫øt tr∆∞·ªõc ƒë√¢y).\rTi·∫øp theo l√† m·ªôt Overlapping Max Pooling 3x3 c√≥ stride =2 =\u0026gt; feature maps = 27x27x96.\rTi·∫øp theo l√† Local Response Normalization =\u0026gt; feature maps = 27x27x96.\rXong l·ªõp th·ª© nh·∫•t\rL·ªõp th·ª© hai:\nConvolutional Layer: 256 kernels c√≥ k√≠ch th∆∞·ªõc 5x5x48 (stride size = 1, pad = 2) =\u0026gt; 27x27x256 feature maps.\rOverlapping Max Pooling 3x3 c√≥ stride =2 =\u0026gt; feature maps = 13x13x256.\rTi·∫øp theo l√† Local Response Normalization =\u0026gt; feature maps = 13x13x256.\rL·ªõp th·ª© ba:\nConvolutional Layer: 384 kernels c√≥ k√≠ch th∆∞·ªõc 3x3x256 (stride size = 1, pad = 1) =\u0026gt; 13x13x384 feature maps.\rL·ªõp th·ª© b·ªën: 384 kernels c√≥ k√≠ch th∆∞·ªõc 3x3x192 (stride size = 1, pad = 1) =\u0026gt; 13x13x384 feature maps.\nL·ªõp th·ª© nƒÉm:\nConvolutional Layer: 256 kernels c√≥ k√≠ch th∆∞·ªõc 3x3x192 (stride size = 1, pad = 1) =\u0026gt; 13x13x256 feature maps.\rOverlapping Max Pooling 3x3 c√≥ stride =2 =\u0026gt; feature maps = 6x6x256.\rL·ªõp th·ª© s√°u:\nFull connected (hay c√≤n g·ªçi l√† Dense layer) v·ªõi 4096 neurals\rL·ªõp th·ª© b·∫£y:\nFull connected v·ªõi 4096 neurals\rL·ªõp th·ª© t√°m:\nFull connected ra output 1000 neural (do c√≥ 1000 l·ªõp)\rH√†m ƒë·ªô l·ªói ƒë∆∞·ª£c s·ª≠ d·ª•ng l√† Softmax.\nT·ªïng c·ªông, ch√∫ng ta c√≥ 60 tri·ªáu tham s·ªë ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ hu·∫•n luy·ªán.\nC·∫£i ti·∫øn c·ªßa m√¥ h√¨nh ƒë·ªÉ gi·∫£m error rate S·ª≠ d·ª•ng ReLU thay cho TanH H√†m k√≠ch ho·∫°t ReLU v√† TanH\nC√°c m√¥ h√¨nh neural network tr∆∞·ªõc khi b√†i b√°o ra ƒë·ªùi th∆∞·ªùng s·ª≠ d·ª•ng h√†m Tanh l√†m h√†m k√≠ch ho·∫°t. M√¥ h√¨nh AlexNet kh√¥ng s·ª≠ d·ª•ng h√†m TanH m√† gi·ªõi thi·ªáu m·ªôt h√†m k√≠ch ho·∫°t m·ªõi l√† ReLU. ReLU gi√∫p cho qu√° tr√¨nh hu·∫•n luy·ªán ch·∫°y nhanh h∆°n g·∫•p 6 l·∫ßn so v·ªõi ki·∫øn tr√∫c t∆∞∆°ng t·ª± s·ª≠ d·ª•ng TanH, g√≥p m·ªôt ph·∫ßn v√†o vi·ªác ƒë·ªô l·ªói tr√™n t·∫≠p hu·∫•n luy·ªán l√† 25%.\nLocal Response Normalization Local Response Normalization v√† Batch Normalization\nTrong m·∫°ng AlexNet, nh√≥m t√°c gi·∫£ s·ª≠ d·ª•ng h√†m chu·∫©n h√≥a l√† Local Response Normalization. H√†m n√†y kh√¥ng ph·∫£i l√† Batch Normalization m√† c√°c b·∫°n hay s·ª≠ d·ª•ng ·ªü th·ªùi ƒëi·ªÉm hi·ªán t·∫°i (xem h√¨nh ·ªü tr√™n, hai h√†m c√≥ c√¥ng th·ª©c t√≠nh to√°n ho√†n to√†n kh√°c nhau). Vi·ªác s·ª≠ d·ª•ng chu·∫©n h√≥a (Normalization) gi√∫p tƒÉng t·ªëc ƒë·ªô h·ªôi t·ª•. Ng√†y nay, ch√∫ng ta kh√¥ng c√≤n s·ª≠ d·ª•ng Local Response Normalization n·ªØa. Thay v√†o ƒë√≥, ch√∫ng ta s·ª≠ d·ª•ng Batch Normalization l√†m h√†m chu·∫©n h√≥a.\nV·ªõi vi·ªác s·ª≠ d·ª•ng h√†m chu·∫©n h√≥a Local Response Normalization, ƒë·ªô l·ªói top-1 error rate gi·∫£m 1.4%, top-5 gi·∫£m 1.2%.\nOverlapping Pooling Overlapping Pooling l√† pooling v·ªõi stride nh·ªè h∆°n kernel size. M·ªôt kh√°i ni·ªám ng∆∞·ª£c v·ªõi Overlapping Pooling l√† Non-Overlapping Pooling v·ªõi stride l·ªõn hoƒÉn ho·∫∑c b·∫±ng kernel.\nM·∫°ng AlexNet s·ª≠ d·ª•ng Overlapping Pooling ·ªü hidden layer th·ª© 1, 2 v√† 5 (Kernel size = 3x3, stride =2).\nV·ªõi vi·ªác s·ª≠ d·ª•ng overlapping pooling, top-1 error rates gi·∫£m 0.4%, top-5 error rate gi·∫£m 0.3%.\nS·ª≠ d·ª•ng Data Augmentation D·ªØ li·ªáu c·ªßa t·∫≠p hu·∫•n luy·ªán kh√° nhi·ªÅu, 1.2 tri·ªáu m·∫´u. Nh∆∞ng chia ra cho 1000 l·ªõp th√¨ m·ªói l·ªõp c√≥ kho·∫£ng 1200, kh√° khi√™m t·ªën ph·∫£i kh√¥ng. Cho n√™n, t√°c gi·∫£ ƒë√£ nghƒ© ra m·ªôt c√°ch kh√° hay ƒë·ªÉ tƒÉng s·ªë l∆∞·ª£ng h√¨nh ·∫£nh m√† v·∫´n gi·ªØ ƒë∆∞·ª£c t√≠nh IID c·ªßa d·ªØ li·ªáu, ƒë√≥ l√† s·ª≠ d·ª•ng c√°c ph√©p bi·∫øn ƒë·ªïi affine tr√™n d·ªØ li·ªáu ·∫£nh g·ªëc ƒë·ªÉ thu th√™m nhi·ªÅu ·∫£nh h∆°n.\nC√≥ hai d·∫°ng Data Augentation ƒë∆∞·ª£c t√°c gi·∫£ s·ª≠ d·ª•ng\nD·∫°ng th·ª© nh·∫•t: Image translation v√† horizontal reflection (mirroring)\nImage translation ƒë∆∞·ª£c hi·ªÉu nh∆∞ sau: ·∫£nh ImageNet g·ªëc c√≥ k√≠ch th∆∞·ªõc 256x256 pixel, t√°c gi·∫£ r√∫t ra m·ªôt ·∫£nh con c√≥ k√≠ch th∆∞·ªõc 224x224 pixel, sau ƒë√≥ d·ªãch qua tr√°i 1 pixel v√† l·∫•y 1 ·∫£nh con ti·∫øp theo c√≥ k√≠ch th∆∞·ªõc 224x224. L√†m nh∆∞ v·∫≠y theo h√†ng, h·∫øt h√†ng l√†m theo c·ªôt. Cu·ªëi c√πng t√°c gi·∫£ c√≥ th·ªÉ t·ª´ m·ªôt b·ª©c h√¨nh 256x256 ban ƒë·∫ßu r√∫t tr√≠ch th√†nh 1024 h√¨nh c√≥ k√≠ch th∆∞·ªõc 224x224\nhorizontal reflection (mirroring) ƒë∆∞·ª£c hi·ªÉu l√† l·∫•y ·∫£nh ph·∫£n chi·∫øu c·ªßa √°nh g·ªëc qua ƒë∆∞·ªùng ch√©o ch√≠nh. V√≠ d·ª• con b√°o dang c√≥ h∆∞·ªõng tai c·ªßa n√≥ t·ª´ tr√°i qua ph·∫£i, ta l·∫•y horizontal reflection c·ªßa ·∫£nh ƒë√≥ th√¨ s·∫Ω ƒë∆∞·ª£c con b√°o h∆∞·ªõng tai t·ª´ ph·∫£i qua tr√°i.\nV·ªõi vi·ªác k·∫øt h·ª£p Image translation v√† horizontal reflection (mirroring), t√°c gi·∫£ c√≥ th·ªÉ r√∫t t·ªëi ƒëa 2048 b·ª©c ·∫£nh kh√°c nhau ch·ªâ t·ª´ 1 b·ª©c ·∫£nh g·ªëc =\u0026gt; v·ªõi h∆°n 1000 b·ª©c ·∫£nh c·ªßa 1 nh√£n c√≥ th·ªÉ sinh ra t·ªëi ƒëa l√† 2048000 b·ª©c ·∫£nh, m·ªôt con s·ªë kh√° l·ªõn ph·∫£i kh√¥ng c√°c b·∫°n.\n·ªû t·∫≠p test, t√°c gi·∫£ s·ª≠ d·ª•ng 4 h√¨nh 224x224 ·ªü b·ªën g√≥c c·ªông v·ªõi 1 h√¨nh 224x224 ·ªü trung t√¢m =\u0026gt; ƒë∆∞·ª£c 5 h√¨nh, ƒëem 5 h√¨nh ƒë√≥ s·ª≠ d·ª•ng horizontal reflection th√¨ thu ƒë∆∞·ª£c 10 h√¨nh cho m·ªói file test.\nD·∫°ng th·ª© hai: Thay ƒë·ªïi ƒë·ªô s√°ng\nTh·ª±c hi·ªán t√≠nh PCA tr√™n t·∫≠p train. V·ªõi m·ªói h√¨nh tr√™n t·∫≠p train, thay ƒë·ªïi gi√° tr·ªã ƒë·ªô s√°ng\n$$[p_1, p_2, p_3][\\alpha_1 \\gamma_1, \\alpha_2 \\gamma_2, \\alpha_3 \\gamma_3]^T$$\nv·ªõi pi v√† gammai l√† gi√° tr·ªã tr·ªã ri√™ng v√† vector ri√™ng th·ª© i c·ªßa ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai 3x3 c·ªßa ·∫£nh, v√† alpha i l√† m·ªôt gi√° tr·ªã ng·∫´u nhi√™n thu·ªôc ƒëo·∫°n 1 v√† ƒë·ªô l·ªách chu·∫©n 0.1..\nV·ªõi vi·ªác s·ª≠ d·ª•ng data augmentation, top-1 error rate gi·∫£m 1% ƒë·ªô l·ªói.\nDropout Dropout\nV·ªõi m·ªói layer s·ª≠ d·ª•ng dropout, m·ªói neural s·∫Ω c√≥ c∆° h·ªôi kh√¥ng ƒë√≥ng g√≥p v√†o feed forward v√† backpropagation. Do ƒë√≥, m·ªói neural ƒë·ªÅu c√≥ c∆° h·ªôi r·∫•t l·ªõn ƒë√≥ng g√≥p v√†o thu·∫≠t to√°n, v√† ch√∫ng ta s·∫Ω gi·∫£m thi·ªÉu t√¨nh tr·∫°ng ph·ª• thu·ªôc v√†o m·ªôt v√†i neural.\nKh√¥ng s·ª≠ d·ª•ng dropout trong t·∫≠p qu√° tr√¨nh test.\nM·∫°ng AlexNet s·ª≠ d·ª•ng gi√° tr·ªã x√°c xu·∫•t c·ªßa dropout l√† 0.5 ·ªü hai fully-connected layer. Dopout ƒë∆∞·ª£c xem nh∆∞ l√† m·ªôt k·ªπ thu·∫≠t chu·∫©n h√≥a nh·∫±m m·ª•c ƒë√≠ch gi·∫£m overfitting.\nS·ª≠ d·ª•ng nhi·ªÅu GPU T·∫°i nƒÉm 2012, nh√≥m t√°c gi·∫£ s·ª≠ d·ª•ng card ƒë·ªì h·ªça NIVIDIA GTX 580 c√≥ 3GB b·ªô nh·ªõ RAM. Cho n√™n, ƒë·ªÉ c√≥ th·ªÉ hu·∫•n luy·ªán ƒë∆∞·ª£c m√¥ h√¨nh AlexNet tr√™n GPU, m√¥ h√¨nh c·∫ßn s·ª≠ d·ª•ng 2 GPU.\nv√¨ v·∫≠y vi·ªác s·ª≠ d·ª•ng 2 ho·∫∑c nhi·ªÅu GPU l√† do v·∫•n ƒë·ªÅ thi·∫øu b·ªô nh·ªõ, ch·ª© kh√¥ng ph·∫£i l√† v·∫•n ƒë·ªÅ tƒÉng t·ªëc qu√° tr√¨nh train h∆°n so v·ªõi 1 GPU\nNgo√†i ra, do gi·ªõi h·∫°n c·ªßa GPU, n√™n m√¥ h√¨nh AlexNet ƒë∆∞·ª£c t√°ch ra l√†m 2 ph·∫ßn, m·ªói ph·∫ßn ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n 1 GPU. Phi√™n b·∫£n 1 GPU c·ªßa m√¥ h√¨nh c√≥ t√™n l√† CaffeNet, v√† ƒë√≤i h·ªèi ch√∫ng ta ph·∫£i s·ª≠ d·ª•ng GPU c√≥ b·ªô nh·ªõ RAM l·ªõn h∆°n ho·∫∑c b·∫±ng 6GB.\nM·ªôt s·ªë chi ti·∫øt kh√°c v·ªÅ c√°c learning param Batch size: 128\nMomemtum: 0.9\nWeight Decay: 0.0005\nLearning rate: 0.01, gi√° tr·ªã learning rate s·∫Ω gi·∫£m ƒëi 10 l·∫ßn n·∫øu validation error rate kh√¥ng thay ƒë·ªïi trong 1 kho·∫£ng th·ªùi gian. S·ªë l·∫ßn gi·∫£m l√† 3.\nEpoch: 90\nNh√≥m t√°c gi·∫£ ƒë√£ s·ª≠ d·ª•ng 2 GPU 580 c√≥ 3GB GPU RAM v√† t·ªën 6 ng√†y ƒë·ªÉ hu·∫•n luy·ªán.\nK·∫øt qu·∫£ ƒê·ªô l·ªói c·ªßa AlexNet tr√™n ILSVRC 2010\nTrong cu·ªôc thi ILSVRC 2010, AlexNet ƒë·∫°t ƒë·ªô ch√≠nh x√°c top-1 error 37.5% v√† top-5 error l√† 17.0%, k·∫øt qu·∫£ n√†y t·ªët h∆°n v∆∞·ª£t tr·ªôi so v·ªõi c√°c c√°ch ti·∫øp c·∫≠n kh√°c.\nƒê·ªô l·ªói c·ªßa AlexNet tr√™n ILSVRC 2012\nƒê·∫øn cu·ªôc thi ILSVRC 2012, ƒë·ªô l·ªói c·ªßa AlexNet tr√™n t·∫≠p validation gi·∫£m c√≤n 18.2%.\nN·∫øu l·∫•y trung b√¨nh c·ªßa d·ª± ƒëo√°n tr√™n 5 m·∫°ng AlexNet ƒë∆∞·ª£c hu·∫•n luy·ªán kh√°c nhau, ƒë·ªô l·ªói gi·∫£m c√≤n 16.4%. C√°c l·∫•y trung b√¨nh tr√™n nhi·ªÅu h∆°n 1 m·∫°ng CNN l√† m·ªôt k·ªπ thu·∫≠t boosting v√† ƒë∆∞·ª£c s·ª≠ d·ª•ng tr∆∞·ªõc ƒë√≥ ·ªü b√†i to√°n ph√¢n lo·∫°i s·ªë c·ªßa m·∫°ng LeNet.\n·ªû d√≤ng s·ªë 3 l√† m·∫°ng AlexNet nh∆∞ng ƒë∆∞·ª£c th√™m 1 convolution layer n·ªØa (n√™n ƒë∆∞·ª£c k√Ω hi·ªáu l√† 1CNN*), ƒë·ªô l·ªói tr√™n t·∫≠p validation gi·∫£m c√≤n 16.4%.\nN·∫øu l·∫•y k·∫øt qu·∫£ trung b√¨nh c·ªßa 2 m·∫°ng neural net ƒë∆∞·ª£c ch·ªânh s·ª≠a (th√™m 1 convolution layer) v√† 5 m·∫°ng AlexNet g·ªëc (=\u0026gt; ch√∫ng ta c√≥ 7CNN*), ƒë·ªô l·ªói tr√™n t·∫≠p validation gi·∫£m xu·ªëng 15.4%\nDemo k·∫øt qu·∫£ top-5 c·ªßa m·∫°ng AlexNet\nM·∫°ng CaffeNet M·∫°ng n√†y l√† phi√™n b·∫£n ki·∫øn tr√∫c 1-GPU c·ªßa AlexNet. Ki·∫øn tr√∫c c·ªßa m·∫°ng caffeNet nh∆∞ h√¨nh b√™n d∆∞·ªõi:\nM·∫°ng caffeNet\nB·∫°n th·∫•y ƒë√≥, thay v√¨ c√≥ 2 ph·∫ßn tr√™n v√† d∆∞·ªõi nh∆∞ m√¥ √¨nh AlexNet ·ªü tr√™n, m√¥ h√¨nh CaffeNet ch·ªâ c√≥ 1 ph·∫ßn. V√≠ d·ª• l·ªõp hidden layer th·ª© 7 m·∫°ng AlexNet g·ªìm 2 ph·∫ßn, m·ªói ph·∫ßn c√≥ k√≠ch th∆∞·ªõc 2048, c√≤n ·ªü phi√™n b·∫£n CaffeNet th√¨ ƒë√£ g·ªôp l·∫°i th√†nh 1 ph·∫ßn.\nT√†i li·ªáu tham kh·∫£o\nhttps://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\nhttp://www.image-net.org/challenges/LSVRC/\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, c√≥ ch·ªó n√†o b·∫°n ch∆∞a r√µ ho·∫∑c m√¨nh vi·∫øt b·ªã sai, c√°c b·∫°n vui l√≤ng ƒë·ªÉ l·∫°i comment ƒë·ªÉ m√¨nh s·ª≠a l·∫°i cho ƒë√∫ng.\n","date":"May 27, 2019","img":"","permalink":"/blog/2019-05-27-alexnet/","series":null,"tags":["machine learning","deep learning","AlexNet","ILSVRC","dropout"],"title":"T√¨m Hi·ªÉu M·∫°ng AlexNet, M√¥ H√¨nh Gi√†nh Chi·∫øn Th·∫Øng T·∫°i Cu·ªôc Thi ILSVRC 2012"},{"categories":null,"content":" Contour l√† g√¨ S·ª≠ d·ª•ng contour trong opencv V√≠ d·ª•: ƒê·∫øm s·ªë l∆∞·ª£ng qu·∫£ b√≥ng bay trong h√¨nh Contour l√† g√¨ C√°c b·∫°n c√≥ th·ªÉ hi·ªÉu contour l√† \u0026ldquo;t·∫≠p c√°c ƒëi·ªÉm-li√™n-t·ª•c t·∫°o th√†nh m·ªôt ƒë∆∞·ªùng cong (curve) (boundary), v√† kh√¥ng c√≥ kho·∫£ng h·ªü trong ƒë∆∞·ªùng cong ƒë√≥, ƒë·∫∑c ƒëi·ªÉm chung trong m·ªôt contour l√† c√°c c√°c ƒëi·ªÉm c√≥ c√πng /g·∫ßn x·∫•u x·ªâ m·ªôt gi√° tr·ªã m√†u, ho·∫∑c c√πng m·∫≠t ƒë·ªô. Contour l√† m·ªôt c√¥ng c·ª• h·ªØu √≠ch ƒë∆∞·ª£c d√πng ƒë·ªÉ ph√¢n t√≠ch h√¨nh d·∫°ng ƒë·ªëi t∆∞·ª£ng, ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng v√† nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng\u0026rdquo;.\nƒê·ªÉ t√¨m contour ch√≠nh x√°c, ch√∫ng ta c·∫ßn ph·∫£i nh·ªã ph√¢n h√≥a b·ª©c ·∫£nh (nh·ªõ l√† ·∫£nh nh·ªã ph√¢n nha c√°c b·∫°n, kh√¥ng ph·∫£i ·∫£nh grayscale ƒë√¢u). C√°c k·ªπ thu·∫≠t nh·ªã ph√¢n h√≥a ·∫£nh ·ªü x·ª≠ l√Ω ·∫£nh c∆° b·∫£n c√≥ th·ªÉ li·ªát k√™ ƒë·∫øn l√† ƒë·∫∑t ng∆∞·ª°ng, ho·∫∑c candy edge detection. Ch√∫ng ta s·∫Ω kh√¥ng b√†n k·ªπ v·ªÅ c√°c c√°ch ƒë·∫∑t ng∆∞·ª°ng ( m·∫∑c d√π c√≥ kh√° nhi·ªÅu c√°ch ƒë·∫∑t ng∆∞·ª°ng, v√† trong opencv c≈©ng c√≥ implement m·ªôt v√†i ph∆∞∆°ng ph√°p, nh∆∞ng n√≥ kh√¥ng ph·∫£i l√† m·ª•c ti√™u c·ªßa b√†i n√†y, n√™n m√¨nh kh√¥ng ƒë·ªÅ c·∫≠p ·ªü ƒë√¢y) ho·∫∑c edge detection ·ªü b√†i vi·∫øt n√†y, m√† ch√∫ng ta s·∫Ω ƒëi v√†o c√°c t√¨m contours b·∫±ng c√°c s·ª≠ d·ª•ng opencv lu√¥n.\nTrong opencv, vi·ªác t√¨m m·ªôt contour l√† vi·ªác t√¨m m·ªôt ƒë·ªëi t∆∞·ª£ng c√≥ m√†u tr·∫Øng tr√™n n·ªÅn ƒëen. Cho n√™n, c√°c b·∫°n h√£y nh·ªõ r·∫±ng h√£y set ƒë·ªëi t∆∞·ª£ng th√†nh m√†u tr·∫Øng v√† ƒë·ªÉ n·ªÅn l√† m√†u ƒëen, ƒë·ª´ng l√†m ng∆∞·ª£c l·∫°i nha.\nM·ªôt l∆∞u √Ω nh·ªè l√† t·∫°i th·ªùi ƒëi·ªÉm m√¨nh vi·∫øt b√†i vi·∫øt n√†y, m√¨nh s·ª≠ d·ª•ng phi√™n b·∫£n opencv3.6. C√°c b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng phi√™n b·∫£n opencv m·ªõi h∆°n, nh∆∞ng c√≥ th·ªÉ nh·ªØng sample code m√¨nh ƒë·ªÉ b√™n d∆∞·ªõi s·∫Ω kh√¥ng work, do kh√¥ng t∆∞∆°ng th√≠ch.\nS·ª≠ d·ª•ng contour trong opencv Opencv h·ªó tr·ª£ cho ch√∫ng ta h√†m ƒë·ªÉ t√¨m contour c·ªßa m·ªôt b·ª©c ·∫£nh\n1modifiedImage, contours, hierarchy = cv2.findContours(binaryImage, typeofContour, methodofContour) Trong ƒë√≥:\ncontours: Danh s√°ch c√°c contour c√≥ trong b·ª©c ·∫£nh nh·ªã ph√¢n. M·ªói m·ªôt contour ƒë∆∞·ª£c l∆∞u tr·ªØ d∆∞·ªõi d·∫°ng vector c√°c ƒëi·ªÉm\nhierarchy: Danh s√°ch c√°c vector, ch·ª©a m·ªëi quan h·ªá gi·ªØa c√°c contour.\nmodifiedImage: ·∫¢nh sau khi s·ª≠ d·ª•ng contour, th∆∞·ªùng ch√∫ng ta kh√¥ng x√†i ƒë·ªëi s·ªë n√†y\nbinaryImage: ·∫¢nh nh·ªã ph√¢n g·ªëc. M·ªôt ch√∫ √Ω quan tr·ªçng ·ªü ƒë√¢y l√† sau khi s·ª≠ d·ª•ng h√†m findContours th√¨ gi√° tr·ªã c·ªßa binaryImage c≈©ng thay ƒë·ªïi theo, n√™n khi s·ª≠ d·ª•ng b·∫°n c√≥ th·ªÉ √°p d·ª•ng binaryImage.copy() ƒë·ªÉ kh√¥ng l√†m thay ƒë·ªïi gi√° tr·ªã c·ªßa binaryImage\ntypeofContour: c√≥ c√°c d·∫°ng sau: RETR_EXTERNAL, RETR_LIST, RETR_CCOMP, RETR_TREE, RETR_FLOODFILL.\nmethodofContour: C√≥ c√°c ph∆∞∆°ng th·ª©c sau: CHAIN_APPROX_NONE, CHAIN_APPROX_SIMPLE, CHAIN_APPROX_TC89_L1, CHAIN_APPROX_TC89_KCOS.\nV√≠ d·ª• v·ªÅ c√°c s·ª≠ d·ª•ng h√†m\n1 2import numpy as np 3import cv2 4 5im = cv2.imread(\u0026#39;test.jpg\u0026#39;) # ƒë·ªçc ·∫£nh m√†u 6imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) # chuy·ªÉn ·∫£nh m√†u sang d·∫°ng grayscale 7ret,thresh = cv2.threshold(imgray,127,255,0) # nh·ªã ph√¢n h√≥a b·ª©c ·∫£nh b·∫±ng c√°ch ƒë·∫∑t ng∆∞·ª°ng, v·ªõi gi√° tr·ªã c·ªßa ng∆∞·ª°ng l√† 127 8im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) # t√¨m contour Opencv h·ªó tr·ª£ ch√∫ng ta h√†m ƒë·ªÉ v·∫Ω contor l√™n b·ª©c ·∫£nh, gi√∫p ch√∫ng ta nh√¨n r√µ r√†ng h∆°n\n1cv2.drawContours(image, contours, contourIndex, colorCode, thickness) V·ªõi:\nimgage: ·∫£nh, c√≥ th·ªÉ l√† ·∫£nh grayscale ho·∫∑c ·∫£nh m√†u.\ncontours: danh s√°ch c√°c contour, l√† vector, n·∫øu b·∫°n mu·ªën v·∫Ω m·ªôt contour, th√¨ b·∫°n ph·∫£i cho n√≥ v√†o trong m·ªôt list.\ncontourIndex V·ªã tr√≠ c·ªßa contor, th√¥ng th∆∞·ªùng ch√∫ng ta ƒë·ªÉ -1\ncolorCode: Gi√° tr·ªã m√†u c·ªßa contour ch√∫ng ta mu·ªën v·∫Ω, ·ªü d·∫°ng BGR, n·∫øu b·∫°n mu·ªën v·∫Ω contour m√†u xanh l√° c√¢y th√¨ set l√† (0,255,0).\nthickness : ƒë·ªô d√†y c·ªßa ƒë∆∞·ªùng contour c·∫ßn v·∫Ω, gi√° tr·ªã thickness c√†ng l·ªõn th√¨ ƒë∆∞·ªùng contor v·∫Ω c√†ng b·ª±\nV√≠ d·ª•: ƒê·∫øm s·ªë l∆∞·ª£ng qu·∫£ b√≥ng bay trong h√¨nh Gi·∫£ s·ª≠ ch√∫ng ta c√≥ b·ª©c ·∫£nh Bong b√≥ng bay\nCh√∫ng ta th·ª±c hi·ªán t√¨m contour c·ªßa ·∫£nh tr√™n b·∫±ng c√°ch\n1 2import numpy as np 3import cv2 4 5im = cv2.imread(\u0026#39;colorfull_ballon.jpg\u0026#39;) 6imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) # chuy·ªÉn ·∫£nh x√°m th√†nh ·∫£nh grayscale 7thresh = cv2.Canny(imgray, 127, 255) # nh·ªã ph√¢n h√≥a ·∫£nh 8_, contours, _ = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) 9 10cv2.drawContours(im, contours, -1, (0, 255, 0), 2) # v·∫Ω l·∫°i ·∫£nh contour v√†o ·∫£nh g·ªëc 11 12# show ·∫£nh l√™n 13cv2.imshow(\u0026#34;ballons\u0026#34;, im) 14cv2.waitKey(0) K·∫øt qu·∫£:\nContour m√†u xanh l√† ƒë∆∞·ªùng curve bao quanh d·ªØ li·ªáu ƒë∆∞·ª£c r√∫t tr√≠ch ƒë∆∞·ª£c\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü nh·ªØng b√†i vi·∫øt ti·∫øp theo.\n","date":"May 26, 2019","img":"","permalink":"/blog/2019-05-26-contours/","series":null,"tags":["Machine Learning","Deep Learning","Opencv","Image Processing"],"title":"Contour"},{"categories":null,"content":" Chi ti·∫øt v·ªÅ m·∫°ng MobileNet M√¥ h√¨nh ki·∫øn tr√∫c Depthwise Separable Convolution L√†m m√¥ h√¨nh g·ªçn nh·∫π h∆°n n·ªØa So s√°nh MobileNet v·ªõi c√°c State-of-the-art ƒë∆∞∆°ng th·ªùi K·∫øt lu·∫≠n Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu m√¥ h√¨nh MobileNetV1 t·ª´ nh√≥m t√°c gi·∫£ ƒë·∫øn t·ª´ Google. ƒêi·ªÉm c·∫£i ti·∫øn (ch·∫Øc l√† c·∫£i ti·∫øn :) c·ªßa m√¥ h√¨nh l√† s·ª≠ d·ª•ng m·ªôt c√°ch t√≠nh t√≠ch ch·∫≠p c√≥ t√™n l√† Depthwise Separable Convolution ƒë·ªÉ gi·∫£m k√≠ch th∆∞·ªõc m√¥ h√¨nh v√† gi·∫£m ƒë·ªô ph·ª©c t·∫°p t√≠nh to√°n. Do ƒë√≥, m√¥ h√¨nh s·∫Ω h·ªØu √≠ch khi ch·∫°y c√°c ·ª©ng d·ª•ng tr√™n di ƒë·ªông v√† c√°c thi·∫øt b·ªã nh√∫ng.\nL√Ω do:\nM√¥ h√¨nh c√≥ √≠t tham s·ªë h∆°n -\u0026gt; k√≠ch th∆∞·ªõc model s·∫Ω nh·ªè h∆°n.\nM√¥ h√¨nh c√≥ √≠t ph√©p t√≠nh c·ªông tr·ª´ nh√¢n chia h∆°n -\u0026gt; ƒë·ªô ph·ª©c t·∫°p s·∫Ω nh·ªè h∆°n.\nHi·ªán t·∫°i (2019-05-26), t·∫°i th·ªùi ƒëi·ªÉm vi·∫øt b√†i, b√†i vi·∫øt g·ªëc c·ªßa t√°c gi·∫£ ƒë√£ ƒë∆∞·ª£c 1594 l∆∞·ª£t tr√≠ch d·∫´n. C√°c b·∫°n c√≥ th·ªÉ t√¨m ƒë·ªçc b√†i b√°o g·ªëc c·ªßa t√°c gi·∫£ t·∫°i trang https://arxiv.org/abs/1704.04861\nS·ªë l∆∞·ª£t tr√≠ch d·∫´n b√†i b√°o MobileNets Efficient Convolutional Neural Networks for Mobile Vision Applications\nChi ti·∫øt v·ªÅ m·∫°ng MobileNet M√¥ h√¨nh ki·∫øn tr√∫c Ki·∫øn tr√∫c m·∫°ng MobileNet ƒë∆∞·ª£c tr√¨nh b√†y b√™n d∆∞·ªõi. H√¨nh b√™n d∆∞·ªõi ƒë∆∞·ª£c tr√≠ch t·ª´ b√†i b√°o g·ªëc c·ªßa t√°c gi·∫£\nM√¥ h√¨nh ki·∫øn tr√∫c m·∫°ng MobileNet\nDi·ªÖn d·ªãch ra ng√¥n ng·ªØ t·ª± nhi√™n, ch√∫ng ta th·∫•y r·∫±ng m√¥ h√¨nh c√≥ 30 l·ªõp v·ªõi c√°c ƒë·∫∑c ƒëi·ªÉm sau:\nL·ªõp 1: Convolution layer v·ªõi stride b·∫±ng 2\nL·ªõp 2: Depthwise layer\nL·ªõp 3: Pointwise layer\nL·ªõp 4: Depthwise layer v·ªõi stride b·∫±ng 2 (kh√°c v·ªõi b∆∞·ªõc 2, dw l·ªõp 2 c√≥ stride size b·∫±ng 1)\nL·ªõp 5: Pointwise layer\nL·ªõp 30: Softmax, d√πng ƒë·ªÉ ph√¢n l·ªõp.\nDepthwise Separable Convolution Depthwise separable convolution l√† m·ªôt depthwise convolution theo sau b·ªüi m·ªôt pointwise convolution nh∆∞ h√¨nh b√™n d∆∞·ªõi:\nC·∫•u tr√∫c c·ªßa m·ªôt Depthwise Separable Convolution\nDepthwise convolution: l√† m·ªôt channel-wise DK√óDK spatial convolution. V√≠ d·ª• ·ªü h√¨nh tr√™n, ta c√≥ 5 channels (c√°c b·∫°n ƒë·ªÉ √Ω c·ª•c ƒë·∫ßu ti√™n c√≥ 5 kh·ªëi h·ªôp, c·ª•c th·ª© 2 l√† ph√¢n t√°ch 5 kh·ªëi h·ªôp ra th√†nh ma tr·∫≠n mxn, c·ª•c th·ª© 3 l√† spatial convolution c√≥ k√≠ch th∆∞·ªõc kxk, c·ª•c th·ª© 4 l√† k·∫øt qu·∫£ sau khi convolution, c·ª•c th·ª© 5 l√† r√°p 5 c√°i k·∫øt qu·∫£ c·ªßa convolution l·∫°i ), do ƒë√≥ ch√∫ng ta s·∫Ω c√≥ 5 DK√óDK spatial convolution t∆∞∆°ng ·ª©ng v·ªõi 5 channel tr√™n.\nPointwise convolution: ƒë∆°n gi·∫£n l√† m·ªôt convolution c√≥ k√≠ch th∆∞·ªõc 1x1 (nh∆∞ h√¨nh ·ªü tr√™n).\nV·ªõi M l√† s·ªë l∆∞·ª£ng input channel, N l√† s·ªë l∆∞·ª£ng output channel, Dk l√† kernel size, Df l√† feature map size (v·ªõi dataset ImageNet th√¨ input c√≥ k√≠ch th∆∞·ªõc l√† 224, do ƒë√≥ feature map ban ƒë·∫ßu c√≥ Df = 224), ch√∫ng ta c√≥ th·ªÉ t√≠nh ƒë∆∞·ª£c:\nChi ph√≠ t√≠nh to√°n c·ªßa Depthwise convolution l√† :\n$$D_k \\cdot D_k \\cdot M \\cdot D_f \\cdot D_f$$\nChi ph√≠ t√≠nh to√°n c·ªßa Pointwise convolution l√† :\n$$M \\cdot N \\cdot D_f \\cdot D_f$$\nT·ªïng chi ph√≠ t√≠nh to√°n c·ªßa Depthwise Separable Convolution l√†:\n$$D_k \\cdot D_k \\cdot M \\cdot D_f \\cdot D_f + M \\cdot N \\cdot D_f \\cdot D_f$$\nN·∫øu ch√∫ng ta kh√¥ng s·ª≠ d·ª•ng Depthwise Separable Convolution m√† s·ª≠ d·ª•ng ph√©p convolution nh∆∞ b√¨nh th∆∞·ªùng, chi ph√≠ t√≠nh to√°n l√†\n$$ D_k \\cdot D_k \\cdot M \\cdot N \\cdot D_f \\cdot D_f$$\nDo ƒë√≥, chi ph√≠ t√≠nh to√°n s·∫Ω gi·∫£m:\n$$\\frac{D_k \\cdot D_k \\cdot M \\cdot D_f \\cdot D_f + M \\cdot N \\dot D_f \\cdot D_f}{D_k \\cdot D_k \\cdot M \\cdot N \\cdot D_f \\cdot D_f} = \\frac{1}{N} + \\frac{1}{D^2_k}$$\nGi·∫£ s·ª≠, ch√∫ng ta ch·ªçn kernel size Dk = 3, ch√∫ng ta s·∫Ω gi·∫£m t·ª´ 8 ƒë·∫øn 9 l·∫ßn ph√©p t√≠nh nh√¢n =\u0026gt; gi·∫£m chi ph√≠ t√≠nh to√°n ƒëi r·∫•t nhi·ªÅu.\nM·ªôt ch√∫ √Ω nh·ªè v·ªÅ ki·∫øn tr√∫c ·ªü ƒë√¢y, l√† sau m·ªói convolution MobileNet s·∫Ω s·ª≠ d·ª•ng Batch Normalization (BN) v√† ReLU nh∆∞ h√¨nh b√™n d∆∞·ªõi:\nStandard Convolution b√™n tr√°i, Depthwise separable convolution v·ªõi BN v√† ReLU b√™n ph·∫£i\nSo s√°nh k·∫øt qu·∫£ c·ªßa vi·ªác s·ª≠ d·ª•ng m·∫°ng 30 layer s·ª≠ d·ª•ng thu·∫ßn Convolution v√† m·∫°ng 30 layer s·ª≠ d·ª•ng Depthwise Separable Convolution (MobileNet) tr√™n t·∫≠p d·ªØ li·ªáu ImageNet, ch√∫ng ta c√≥ b·∫£ng k·∫øt qu·∫£ b√™n d∆∞·ªõi\nStandard Convolution b√™n tr√°i, Depthwise separable convolution v·ªõi BN v√† ReLU b√™n ph·∫£i\nMobileNet gi·∫£m 1% ƒë·ªô ch√≠nh x√°c, nh∆∞ng s·ªë l∆∞·ª£ng tham s·ªë c·ªßa m√¥ h√¨nh v√† s·ªë l∆∞·ª£ng ph√©p t√≠nh to√°n gi·∫£m ƒëi r·∫•t r·∫•t nhi·ªÅu, g·∫ßn x·∫•p x·ªâ 90%. M·ªôt con s·ªë ƒë√°ng kinh ng·∫°c.\nL√†m m√¥ h√¨nh g·ªçn nh·∫π h∆°n n·ªØa V·ªõi mong mu·ªën l√†m m√¥ h√¨nh g·ªçn nh·∫π h∆°n n·ªØa, nh√≥m t√°c gi·∫£ ƒë√£ th√™m v√†o hai tham s·ªë alpha v√† rho.\nTham s·ªë alpha: ƒêi·ªÅu khi·ªÉn s·ªë l∆∞·ª£ng channel (M v√† N).\nChi ph√≠ t√≠nh to√°n c·ªßa depthwise separable convolution khi s·ª≠ d·ª•ng th√™m tham s·ªë alpha.\n$$D_k \\cdot D_k \\cdot \\alpha M \\cdot D_f \\cdot D_f + \\alpha M \\cdot \\alpha N \\cdot D_f \\cdot D_f$$\nGi√° tr·ªã alpha n·∫±m trong ƒëo·∫°n [0,1], nh√≥m t√°c gi·∫£ set gi√° tr·ªã alpha c√≥ b∆∞·ªõc nh·∫£y l√† 0.25, c√°c gi√° tr·ªã c·∫ßn x√©t l√† 0.25, 0.5, 0.75, 1. Tr∆∞·ªùng h·ª£p alpha = 1 ch√≠nh l√† m·∫°ng MobileNet baseline c·ªßa m√¨nh. Trong tr∆∞·ªùng h·ª£p thay ƒë·ªïi alpha, s·ªë ph√©p t√≠nh to√°n, s·ªë tham s·ªë, c≈©ng gi·∫£m ƒëi r·∫•t nhi·ªÅu, v√† t·∫•t nhi√™n, ƒë·ªô ch√≠nh x√°c c≈©ng gi·∫£m ƒëi t∆∞∆°ng ·ª©ng.\nM·∫°ng MobileNet v·ªõi alpha thay ƒë·ªïi\nPh√¢n t√≠ch k·ªπ h√¨nh ·ªü tr√™n, ta th·∫•y r·∫±ng v·ªõi alpha b·∫±ng 0.75 v√† 0.5 gi√° tr·ªã ƒë·ªô ch√≠nh x√°c c√≤n n·∫±m ·ªü m·ª©c mi·ªÖn c∆∞·ª°ng c√≥ th·ªÉ ch·∫•p nh·∫≠n ƒë∆∞·ª£c. Nh∆∞ng v·ªõi alpha b·∫±ng 0.25 th√¨ kh√≥ m√† c√≥ th·ªÉ ch·∫•p nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ ƒë√≥. Vi·ªác gi·∫£m ph√©p t√≠nh to√°n v√† s·ªë l∆∞·ª£ng tham s·ªë d·∫´n ƒë·∫øn k·∫øt qu·∫£ t·ªá nh∆∞ tr√™n qu·∫£ l√† m·ªôt ƒëi·ªÅu kh√¥ng n√™n. M√¨nh nghƒ© ·ªü ƒë√¢y nh√≥m t√°c gi·∫£ ƒë·ªÉ con s·ªë ƒë·ªÉ c√≥ √Ω nghƒ©a so s√°nh.\nTham s·ªë rho: Tham s·ªë n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒëi·ªÅu khi·ªÉn ƒë·ªô ph√¢n gi·∫£i c·ªßa ·∫£nh input.\nChi ph√≠ t√≠nh to√°n c·ªßa depthwise separable convolution khi s·ª≠ d·ª•ng th√™m tham s·ªë rho.\n$$D_k \\cdot D_k \\cdot \\alpha M \\cdot \\rho D_f \\cdot \\rho D_f + \\alpha M \\cdot \\alpha N \\cdot \\rho D_f \\cdot \\rho D_f$$\nGi√° tr·ªã rho c≈©ng n·∫±m trong ƒëo·∫°n [0,1]. Nh√≥m t√°c gi·∫£ s·ª≠ d·ª•ng c√°c gi√° tr·ªã ƒë·ªô ph√¢n gi·∫£i l√† 224 (ƒë·ªô ph√¢n gi·∫£i g·ªëc, t∆∞∆°ng ·ª©ng v·ªõi rho =1), 192, 160, 128.\nM·∫°ng MobileNet v·ªõi rho thay ƒë·ªïi\nGi√° tr·ªã ƒë·ªô ch√≠nh x√°c thay ƒë·ªïi theo h∆∞·ªõng gi·∫£m kh√° m∆∞·ª£t. Vi·ªác thay ƒë·ªïi rho ch·ªâ l√†m gi·∫£m s·ªë l∆∞·ª£ng ph√©p t√≠nh to√°n, kh√¥ng l√†m gi·∫£m s·ªë l∆∞·ª£ng tham s·ªë. Vi·ªác gi·∫£m ƒë·ªô ch√≠nh x√°c c√≥ th·ªÉ l√Ω gi·∫£i l√Ω do l√† c√≥ m·ªôt s·ªë h√¨nh c√≥ k√≠ch th∆∞·ªõc nh·ªè n√™n khi gi·∫£m k√≠ch th∆∞·ªõc s·∫Ω l√†m m·∫•t nh·ªØng ƒë·∫∑c tr∆∞ng c·∫ßn thi·∫øt c·ªßa ƒë·ªëi t∆∞·ª£ng c·∫ßn x√©t.\nSo s√°nh MobileNet v·ªõi c√°c State-of-the-art ƒë∆∞∆°ng th·ªùi Khi so s√°nh 1.0 MobileNet-224 v·ªõi GoogleNet v√† VGG 16 (h√¨nh b√™n d∆∞·ªõi), ch√∫ng ta th·∫•y r·∫±ng ƒë·ªô ch√≠nh x√°c c·ªßa c·∫£ 3 thu·∫≠t to√°n l√† h·∫ßu nh∆∞ t∆∞∆°ng ƒë∆∞∆°ng nhau. Nh∆∞ng 1.0 MobileNet-224 c√≥ s·ªë l∆∞·ª£ng tham s·ªë √≠t (75% so v·ªõi GoogleNet) v√† s·ªë l∆∞·ª£ng ph√©p to√°n nh·ªè h∆°n r·∫•t nhi·ªÅu =\u0026gt; ch·∫°y nhanh h∆°n.\nSo s√°nh 1.0 MobileNet-224 v·ªõi GoogleNet v√† VGG 16 tr√™n t·∫≠p ImageNet\nV·ªõi m√¥ h√¨nh 0.50 MobileNet-160, ch√∫ng ta c√≥ th·ªÉ so s√°nh v·ªõi m√¥ h√¨nh Squeezenet v√† AlexNet (m√¥ h√¨nh th·∫Øng gi·∫£i nh·∫•t cu·ªôc thi ILSVRC 2012). M·ªôt l·∫ßn n·ªØa, m√¥ h√¨nh 0.50 MobileNet-160 cho k·∫øt qu·∫£ t·ªët h∆°n, nh∆∞ng c√≥ s·ªë l∆∞·ª£ng ph√©p t√≠nh to√°n √≠t h∆°n r·∫•t nhi·ªÅu (h∆°i ƒë√°ng bu·ªìn l√† s·ªë l∆∞·ª£ng tham s·ªë c·ªßa m√¥ h√¨nh 0.50 MobileNet-160 kh√° cao, s·ªë l∆∞·ª£ng tham s·ªë g·∫•p ƒë√¥i so v·ªõi AlexNet v√† g·∫ßn b·∫±ng Squeezenet) =\u0026gt; 0.50 MobileNet-160 train nhanh h∆°n, predict c≈©ng nhanh h∆°n so v·ªõi Squeezenet v√† AlexNet, nh∆∞ng t·ªën b·ªô nh·ªõ RAM h∆°n.\nSo s√°nh 0.50 MobileNet-160 v·ªõi Squeezenet v√† AlexNet tr√™n t·∫≠p ImageNet\nSo v·ªõi m√¥ h√¨nh Inception-v3 (m√¥ h√¨nh th·∫Øng gi·∫£i nh·∫•t cu·ªôc thi ILSVRC 2015), MobileNet cho k·∫øt qu·∫£ kh√° t·ªët, nh∆∞ng s·ªë tham s·ªë v√† s·ªë l∆∞·ª£ng ph√©p t√≠nh to√°n nh·ªè h∆°n r·∫•t nhi·ªÅu\nSo s√°nh Mobile net v√† Inception-v3 tr√™n t·∫≠p Stanford Dog\nC√°c th√≠ nghi·ªám ·ªü d∆∞·ªõi tr√™n c√°c t·∫≠p dataset kh√°c nhau ch·ª©ng minh m·ª©c ƒë·ªô hi·ªáu qu·∫£ c·ªßa MobileNet GPS Localization Via Photos\nFace Attribute Classification\nMMicrosoft COCO Object Detection Dataset\nFace Recognition\nK·∫øt lu·∫≠n MobileNet cho k·∫øt qu·∫£ t·ªët ngang ng·ªØa c√°c state-of-the-art th·∫Øng gi·∫£i nh·∫•t ·ªü qu√° kh·ª©, nh∆∞ng v·ªõi m√¥ h√¨nh c√≥ s·ªë l∆∞·ª£ng tham s·ªë nh·ªè h∆°n v√† s·ªë ph√©p t√≠nh to√°n √≠t h∆°n. ƒêi·ªÅu n√†y ƒë·∫°t ƒë∆∞·ª£c l√† nh·ªù v√†o vi·ªác s·ª≠ d·ª•ng Depthwise Separable Convolution.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt, c√≥ ch·ªó n√†o b·∫°n ch∆∞a r√µ ho·∫∑c m√¨nh vi·∫øt b·ªã sai, c√°c b·∫°n vui l√≤ng ƒë·ªÉ l·∫°i comment ƒë·ªÉ m√¨nh s·ª≠a l·∫°i cho ƒë√∫ng.\n","date":"May 25, 2019","img":"","permalink":"/blog/2019-05-26-mobilenetv1/","series":null,"tags":["machine learning","deep learning","MobileNetV1","Depthwise Separable Convolution","Light Weight Model","Width Multiplier","Resolution Multiplier"],"title":"T√¨m Hi·ªÉu M·∫°ng MobileNetV1"},{"categories":null,"content":" 1. T·∫°o ch∆∞∆°ng tr√¨nh ƒë·∫ßu ti√™n b·∫±ng PredictionIO 1. T·∫°o ch∆∞∆°ng tr√¨nh ƒë·∫ßu ti√™n b·∫±ng PredictionIO ƒê·∫ßu ti√™n, c√°c b·∫°n h√£y t·∫°o th∆∞ m·ª•c template ·ªü ƒë√¢u ƒë√≥. M√¨nh s·∫Ω t·∫°o ·ªü trong th∆∞ m·ª•c /data/pio. ƒê∆∞·ªùng d·∫´n c·ªßa m√¨nh s·∫Ω l√† /data/pio/template\n1mdkir /data/pio/template Ti·∫øp theo, ch√∫ng ta s·∫Ω clone templte tr√™n github v·ªÅ, c√°c b·∫°n th·ª±c hi·ªán l·ªánh sau\n1git clone https://github.com/apache/predictionio-template-recommender.git 2cd predictionio-template-recommender Ti·∫øp theo, ch√∫ng ta s·∫Ω t·∫°o m·ªôt app ƒë·∫ßu ti√™n, m√¨nh ƒë·∫∑t t√™n l√† ourrecommendation, c√°c b·∫°n th√≠ch ƒë·∫∑t t√™n g√¨ th√¨ ƒë·∫∑t nha.\n1pio app new ourrecommendation ƒê·ªÉ li·ªát k√™ danh s√°ch app ƒëang c√≥ trong h·ªá th·ªëng, c√°c b·∫°n d√πng l·ªánh\n1pio app list K·∫øt qu·∫£ trong m√°y m√¨nh t·∫°i th·ªùi ƒëi·ªÉm vi·∫øt b√†i l√†\n1[INFO] [Pio$] Name | ID | Access Key | Allowed Event(s) 2[INFO] [Pio$] ourrecommendation | 1 | Z93rJZ7Xq2pXiQwVC6B5nRK6jRykcfyMI5huOijKbdDJeUeKEnVT-ph5nabptIX1 | (all) 3[INFO] [Pio$] Finished listing 1 app(s). M√¨nh m·ªõi t·∫°o app ƒë·∫ßu ti√™n t√™n l√† ourrecommendation n√™n ch·ªâ c√≥ 1 app trong h·ªá th·ªëng. Sau n√†y s·∫Ω c√≥ nhi·ªÅu h∆°n. √Ä, sau khi t·∫°o app, th√¨ h·ªá th·ªëng s·∫Ω generate t·ª± ƒë·ªông cho app v·ªõi m·ªôt Access Key, v√≠ d·ª• access key c·ªßa app ourrecommendateion c·ªßa m√¨nh l√† Z93rJZ7Xq2pXiQwVC6B5nRK6jRykcfyMI5huOijKbdDJeUeKEnVT-ph5nabptIX1. C√°c b·∫°n s·∫Ω c√≥ access key kh√°c v·ªõi access key c·ªßa m√¨nh, n√™n ƒë·ª´ng copy c·ªßa m√¨nh v·ªÅ l√†m g√¨ h·∫øt :).\nSau khi kh·ªüi t·∫°o app xong, ch√∫ng ta s·∫Ω import data v√†o h·ªá th·ªëng. ·ªû ƒë√¢y, m√¨nh s·∫Ω download d·ªØ li·ªáu m·∫´u t·ª´ ngu·ªìn https://gist.githubusercontent.com/vaghawan/0a5fb8ddb85e03631dd500d7c8f0677d/raw/17487437dd8269588d9dd1ac859b129a43842ba5/data-sample.json. Sau khi download v·ªÅ c√°c b·∫°n import d·ªØ li·ªáu v√†o h·ªá th·ªëng b·∫±ng l·ªánh\n1pio import ‚Äî appid 1 ‚Äî input data-sample.json V·ªõi appod 1 l√† id c·ªßa ourrecommendation ch√∫ng ta v·ª´a m·ªõi t·∫°o. N·∫øu qu√™n appid, c√°c b·∫°n c√≥ th·ªÉ xem l·∫°i b·∫±ng l·ªánh pio app list.\nSau khi import th√†nh c√¥ng, ch√∫ng ta s·∫Ω thay ƒë·ªïi gi√° tr·ªã c·ªßa tr∆∞·ªùng appname trong file engine.json th√†nh t√™n c·ªßa app m√¨nh, l√† ourrecommendation\n1nano engine.json 2 3{ 4 \u0026#34;id\u0026#34;: \u0026#34;default\u0026#34;, 5 \u0026#34;description\u0026#34;: \u0026#34;Default settings\u0026#34;, 6 \u0026#34;engineFactory\u0026#34;: \u0026#34;org.example.recommendation.RecommendationEngine\u0026#34;, 7 \u0026#34;datasource\u0026#34;: { 8 \u0026#34;params\u0026#34; : { 9 \u0026#34;appName\u0026#34;: \u0026#34;ourrecommendation\u0026#34; 10 } 11 }, 12 \u0026#34;algorithms\u0026#34;: [ 13 { 14 \u0026#34;name\u0026#34;: \u0026#34;als\u0026#34;, 15 \u0026#34;params\u0026#34;: { 16 \u0026#34;rank\u0026#34;: 10, 17 \u0026#34;numIterations\u0026#34;: 20, 18 \u0026#34;lambda\u0026#34;: 0.01, 19 \u0026#34;seed\u0026#34;: 3 20 } 21 } 22 ] 23} M·ªôt l∆∞u √Ω quang tr·ªçng l√† gi√° tr·ªã \u0026ldquo;org.example.recommendation.RecommendationEngine\u0026rdquo; trong \u0026ldquo;engineFactory\u0026rdquo; l√† c·ªßa h·ªá th·ªëng. V√† b·∫°n ƒë·ª´ng s·ª≠a, thay ƒë·ªïi ch√∫ng. N√≥i chung l√† ngo√†i gi√° tr·ªã c·ªßa \u0026ldquo;appName\u0026rdquo; ra, b·∫°n kh√¥ng n√™n thay ƒë·ªïi b·∫•t k·ª≥ th·ª©c g√¨ kh√°c trong file engine.json.\nSau khi import file th√†nh c√¥ng. Ch√∫ng ta s·∫Ω build app. L·ªánh build c√≥ t√°c d·ª•ng ki·ªÉm tra l·∫°i h·ªá th·ªëng ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng v√† ƒë·ªß ch∆∞a.\n1pio build N·∫øu build th√†nh c√¥ng, ch√∫ng ta s·∫Ω th·∫•y d√≤ng ch·ªØ n√†y.\n1 2[INFO] [Engine$] Build finished successfully. 3[INFO] [Pio$] Your engine is ready for training. Sau khi build th√†nh c√¥ng, ch√∫ng ta s·∫Ω ti·∫øn h√†nh hu·∫•n luy·ªán m√¥ h√¨nh\n1pio build V√† ch·ªù ƒë·ª£i d√≤ng n√†y xu·∫•t hi·ªán\n1 2[INFO] [CoreWorkflow$] Training completed successfully. C·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü nh·ªØng b√†i vi·∫øt ti·∫øp theo.\n","date":"May 7, 2019","img":"","permalink":"/blog/2019-05-07-predictio-mini-demo/","series":null,"tags":["Machine Learning","Deep Learning","PredictionIO","Forecast"],"title":"PredictionIO Ph·∫ßn 2 - C√†i ƒê·∫∑t Ch∆∞∆°ng Tr√¨nh Demo"},{"categories":null,"content":" 1. Dropout l√† g√¨, n√≥ c√≥ √Ω nghƒ©a g√¨ trong m·∫°ng neural network 2. T·∫°o sao ch√∫ng ta c·∫ßn dropout 3. Dropout 4. M·ªôt s·ªë ƒë·∫∑c ƒëi·ªÉm r√∫t ra ƒë∆∞·ª£c khi hu·∫•n luy·ªán nhi·ªÅu m√¥ h√¨nh kh√°c nhau s·ª≠ d·ª•ng dropout 5. Th·ª±c nghi·ªám trong keras 1. Dropout l√† g√¨, n√≥ c√≥ √Ω nghƒ©a g√¨ trong m·∫°ng neural network Theo Wikipedia, thu·∫≠t ng·ªØ \u0026ldquo;dropout\u0026rdquo; ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác b·ªè qua c√°c ƒë∆°n v·ªã (unit) (c·∫£ hai hidden unit v√† visible unit) trong m·∫°ng neural network.\nHi·ªÉu ƒë∆°n gi·∫£n l√†, trong m·∫°ng neural network, k·ªπ thu·∫≠t dropout l√† vi·ªác ch√∫ng ta s·∫Ω b·ªè qua m·ªôt v√†i unit trong su·ªët qu√° tr√¨nh train trong m√¥ h√¨nh, nh·ªØng unit b·ªã b·ªè qua ƒë∆∞·ª£c l·ª±a ch·ªçn ng·∫´u nhi√™n. ·ªû ƒë√¢y, ch√∫ng ta hi·ªÉu \u0026ldquo;b·ªè qua - ignoring\u0026rdquo; l√† unit ƒë√≥ s·∫Ω kh√¥ng tham gia v√† ƒë√≥ng g√≥p v√†o qu√° tr√¨nh hu·∫•n luy·ªán (lan truy·ªÅn ti·∫øn v√† lan truy·ªÅn ng∆∞·ª£c).\nV·ªÅ m·∫∑t k·ªπ thu·∫≠t, t·∫°i m·ªói giai ƒëo·∫°n hu·∫•n luy·ªán, m·ªói node c√≥ x√°c su·∫•t b·ªã b·ªè qua l√† 1-p v√† x√°c su·∫•t ƒë∆∞·ª£c ch·ªçn l√† p\n2. T·∫°o sao ch√∫ng ta c·∫ßn dropout Gi·∫£ s·ª≠ r·∫±ng b·∫°n hi·ªÉu ho√†n to√†n nh·ªØng g√¨ ƒë√£ n√≥i ·ªü ph·∫ßn 1, c√¢u h·ªèi ƒë·∫∑t ra l√† t·∫°i sao ch√∫ng ta c·∫ßn ƒë·∫øn dropout, t·∫°i sao ch√∫ng ta c·∫ßn ph·∫£i lo·∫°i b·ªè m·ªôt v√†i c√°c unit n√†o ƒë√≥ trong m·∫°ng neural network?\nC√¢u tr·∫£ l·ªùi cho c√¢u h·ªèi n√†y l√† ƒë·ªÉ ch·ªëng over-fitting\nKhi ch√∫ng ta s·ª≠ d·ª•ng full connected layer, c√°c neural s·∫Ω ph·ª• thu·ªôc \u0026ldquo;m·∫°nh\u0026rdquo; l·∫´n nhau trong su·ªët qu√° tr√¨nh hu·∫•n luy·ªán, ƒëi·ªÅu n√†y l√†m gi·∫£m s·ª©c m·∫°ng cho m·ªói neural v√† d·∫´n ƒë·∫øn b·ªã over-fitting t·∫≠p train.\n3. Dropout ƒê·ªçc ƒë·∫øn ƒë√¢y, b·∫°n ƒë√£ c√≥ m·ªôt kh√°i ni·ªám c∆° b·∫£n v·ªÅ dropout v√† ƒë·ªông l·ª±c - ƒë·ªông c∆° ƒë·ªÉ ch√∫ng ta s·ª≠ d·ª•ng n√≥. N·∫øu b·∫°n ch·ªâ mu·ªën c√≥ c√°i nh√¨n t·ªïng quan v·ªÅ dropout trong neural network, hai sections tr√™n ƒë√£ cung c·∫•p ƒë·∫ßy ƒë·ªß th√¥ng tin cho b·∫°n, b·∫°n c√≥ th·ªÉ d·ª´ng t·∫°i ƒë√¢y. Ph·∫ßn ti·∫øp theo, ch√∫ng ta s·∫Ω n√≥i k·ªπ h∆°n v·ªÅ m·∫∑t k·ªπ thu·∫≠t c·ªßa dropout.\nTr∆∞·ªõc ƒë√¢y, trong machine learning, ng∆∞·ªùi ta th∆∞·ªùng s·ª≠ d·ª•ng regularization ƒë·ªÉ ngƒÉng ch·∫∑n over-fititng. Regularization l√†m gi·∫£m over-fitting b·∫±ng c√°ch th√™m y·∫øu t·ªë \u0026ldquo;ph·∫°t\u0026rdquo; v√†o h√†m ƒë·ªô l·ªói (loss function). B·∫±ng vi·ªác th√™m v√†o ƒëi·ªÉm ph·∫°t n√†y, m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán s·∫Ω gi√∫p c√°c features weights gi·∫£m ƒëi s·ª± ph·ª• thu·ªôc l·∫´n nhau. ƒê·ªëi v·ªõi nh·ªØng ai ƒë√£ s·ª≠ d·ª•ng Logistic Regression r·ªìi th√¨ s·∫Ω kh√¥ng xa l·∫° v·ªõi thu·∫≠t ng·ªØ ph·∫°t L1(Laplacian) v√† L2 (Gaussian).\nDropout l√† m·ªôt k·ªπ thu·∫≠t kh√°c, m·ªôt c√°ch ti·∫øp c·∫≠n kh√°c ƒë·ªÉ regularization trong m·∫°ng neural netwoks.\nK·ªπ thu·∫≠t dropout ƒë∆∞·ª£c th·ª±c hi·ªán nh∆∞ sau:\nTrong pha train: v·ªõi m·ªói hidden layer, v·ªõi m·ªói trainning sample, v·ªõi m·ªói l·∫ßn l·∫∑p, ch·ªçn ng·∫´u nhi√™n p ph·∫ßn trƒÉm s·ªë node v√† b·ªè qua n√≥ (b·ªè qua lu√¥n h√†m k√≠ch ho·∫°t cho c√°c node b·ªã b·ªè qua).\nTrong pha test: S·ª≠ d·ª•ng to√†n b·ªô activations, nh∆∞ng gi·∫£m ch√∫ng v·ªõi t·ª∑ l·ªá p (do ch√∫ng ta b·ªã miss p% h√†m activation trong qu√° tr√¨nh train).\nM√¥ t·∫£ v·ªÅ ki·∫øn tr√∫c m·∫°ng c√≥ v√† kh√¥ng c√≥ dropout\n4. M·ªôt s·ªë ƒë·∫∑c ƒëi·ªÉm r√∫t ra ƒë∆∞·ª£c khi hu·∫•n luy·ªán nhi·ªÅu m√¥ h√¨nh kh√°c nhau s·ª≠ d·ª•ng dropout Dropout √©p m·∫°ng neural ph·∫£i t√¨m ra nhi·ªÅu robust features h∆°n, v·ªõi ƒë·∫∑c ƒëi·ªÉm l√† ch√∫ng ph·∫£i h·ªØu √≠ch h∆°n, t·ªët h∆°n, ngon h∆°n khi k·∫øt h·ª£p v·ªõi nhi·ªÅu neuron kh√°c.\nDropout ƒë√≤i h·ªèi ph·∫£i g·∫•p ƒë√¥i qu√° tr√¨nh hu·∫•n luy·ªán ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c s·ª± h·ªôi t·ª•. Tuy nhi√™n, th·ªùi gian hu·∫•n luy·ªán cho m·ªói epoch s·∫Ω √≠t h∆°n.\nV·ªõi H unit trong m√¥ h√¨nh, m·ªói unit ƒë·ªÅu c√≥ x√°c xu·∫•t b·ªã b·ªè qua ho·∫∑c ƒë∆∞·ª£c ch·ªçn, ch√∫ng ta s·∫Ω c√≥ 2^H m√¥ h√¨nh c√≥ th·ªÉ c√≥. Trong pha test, to√†n b·ªô network ƒë∆∞·ª£c s·ª≠ d·ª•ng v√† m·ªói h√†m activation ƒë∆∞·ª£c gi·∫£m ƒëi v·ªõi h·ªá s·ªë p.\nM·ªôt s·ªë nghi√™n c·ª©u ch·ªâ ra r·∫±ng, khi s·ª≠ d·ª•ng Dropout v√† Batch Normalization (BN) c√πng nhau th√¨ k·∫øt qu·∫£ r·∫•t t·ªá, trong c·∫£ l√Ω thuy·∫øt v√† th·ª±c nghi·ªám, v√≠ d·ª• nghi√™n c·ª©u ·ªü papper \u0026ldquo;Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift\u0026rdquo;, ngu·ªìn https://arxiv.org/abs/1801.05134, nh√≥m t√°c gi·∫£ gi·∫£i th√≠ch v·ªÅ m·∫∑t l√Ω thuy·∫øt r·∫±ng: \u0026ldquo;ƒë·ªëi v·ªõi m·ªôt neural, Dropout s·∫Ω thay ƒë·ªïi ph∆∞∆°ng sai c·ªßa n√≥ khi ch√∫ng ta chuy·ªÉn tr·∫°ng th√°i t·ª´ trian sang test. C√≤n BN th√¨ kh√¥ng, BN v·∫´n t√≠ch lu·ªπ ƒë·∫ßy ƒë·ªß th√¥ng tin trong qu√° tr√¨nh hu·∫•n luy·ªán. Do Dropout l√†m thay ƒë·ªïi ph∆∞∆°ng sai n√™n s·∫Ω x·∫£y ra hi·ªán t∆∞·ª£ng kh√¥ng ƒë·ªìng nh·∫•t v·ªÅ ph∆∞∆°ng sai, d·∫´n ƒë·∫øn h√†nh vi suy lu·∫≠n kh√¥ng ch·∫Øc ch·∫Øn d·∫´n ƒë·∫øn suy lu·∫≠n b·ªã sai nhi·ªÅu. ƒê·∫∑c bi·ªát l√† khi k·∫øt h·ª£p dropout v√† BN th√¨ khi·∫øn cho suy lu·∫≠n c√†ng sai l·∫ßm tr·∫ßm tr·ªçng. \u0026ldquo;. Cho n√™n, trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p/b√†i to√°n ch√∫ng ta c√≥ th·ªÉ d√πng Dropout, trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p/ b√†i to√°n, ng∆∞·ªùi ta s·ª≠ d·ª•ng BN v√† kh√¥ng s·ª≠ d·ª•ng dropout.\nNg∆∞·ªùi ta th∆∞·ªùng d√πng h·ªá s·ªë dropout l√† 0.5. L√Ω gi·∫£i cho vi·ªác n√†y, b·∫°n c√≥ th·ªÉ ƒë·ªçc b√†i b√°o http://papers.nips.cc/paper/4878-understanding-dropout.pdf. N√≥i n√¥m l√† vi·ªác s·ª≠ d·ª•ng gi·∫£m 50% c·ªßa dropout gi√∫p k·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c l√† t·ªët nh·∫•t so v·ªõi c√°c ph∆∞∆°ng ph√°p chu·∫©n ho√° kh√°c.\n5. Th·ª±c nghi·ªám trong keras Nh·ªØng v·∫•n ƒë·ªÅ n√≥i ·ªü tr√™n ch·ªâ l√† l√Ω thuy·∫øt. B√¢y gi·ªù ch√∫ng ta s·∫Ω b·∫Øt tay v√†o l√†m th·ª±c t·∫ø. ƒê·ªÉ xem th·ª≠ dropout ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o, ch√∫ng ta s·∫Ω x√¢y d·ª±ng m√¥ h√¨nh deep net s·ª≠ d·ª•ng keras v√† s·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu cifar-10. M√¥ h√¨nh ch√∫ng ta x√¢y d·ª±ng c√≥ 3 hidden layer v·ªõi k√≠ch th∆∞·ªõc l·∫ßn l∆∞·ª£t l√† 64, 128, 256 v√† 1 full connected layer c√≥ k√≠ch th∆∞·ªõc 512 v√† output layer c√≥ k√≠ch th∆∞·ªõc 10 (do m√¨nh c√≥ 10 l·ªõp).\nCh√∫ng ta s·ª≠ d·ª•ng h√†m k√≠ch ho·∫°t l√† ReLU tr√™n c√°c hidden layer v√† s·ª≠ d·ª•ng h√†m sigmoid tr√™n output layer. S·ª≠ d·ª•ng h√†m l·ªói categorical cross-entropy.\nTrong tr∆∞·ªùng h·ª£p m√¥ h√¨nh c√≥ s·ª≠ d·ª•ng dropout, ch√∫ng ta s·∫Ω set dropout ·ªü t·∫•t c·∫£ c√°c layer v√† thay ƒë·ªïi t·ª∑ l·ªá dropout n·∫±m trong kho·∫£ng t·ª´ 0.0 ƒë·∫øn 0.9 v·ªõi b∆∞·ªõc nh·∫£y l√† 0.1.\nM√¥ h√¨nh setup v·ªõi s·ªë epochs l√† 20. B·∫Øt ƒë·∫ßu xem n√†o.\nƒê·∫ßu ti√™n, ch√∫ng ta s·∫Ω load m·ªôt v√†i th∆∞ vi·ªán c·∫ßn thi·∫øt\n1import numpy as np 2import os 3 4import keras 5 6from keras.datasets import cifar10 7from keras.models import Sequential 8from keras.layers import Dense, Dropout, Activation, Flatten 9from keras.layers import Convolution2D, MaxPooling2D 10from keras.optimizers import SGD 11from keras.utils import np_utils 12from keras.preprocessing.image import ImageDataGenerator 13import matplotlib.pyplot as plt 14 15from pylab import rcParams 16rcParams[\u0026#39;figure.figsize\u0026#39;] = 20, 20 17 18from keras.datasets import cifar10 19 20(X_train, y_train), (X_test, y_test) = cifar10.load_data() 21 22 23print(\u0026#34;Training data:\u0026#34;) 24print(\u0026#34;Number of examples: \u0026#34;, X_train.shape[0]) 25print(\u0026#34;Number of channels:\u0026#34;,X_train.shape[3]) 26print(\u0026#34;Image size:\u0026#34;,X_train.shape[1], X_train.shape[2], X_train.shape[3]) 27 28print(\u0026#34;Test data:\u0026#34;) 29print(\u0026#34;Number of examples:\u0026#34;, X_test.shape[0]) 30print(\u0026#34;Number of channels:\u0026#34;, X_test.shape[3]) 31print(\u0026#34;Image size:\u0026#34;,X_test.shape[1], X_test.shape[2], X_test.shape[3]) K·∫øt qu·∫£\n1Training data: 2Number of examples: 50000 3Number of channels: 3 4Image size: 32 32 3 5Test data: 6Number of examples: 10000 7Number of channels: 3 8Image size: 32 32 3 Ch√∫ng ta c√≥ 50000 h√¨nh train, v√† 10000 h√¨nh test. M·ªói h√¨nh l√† m·ªôt ·∫£nh RGB c√≥ k√≠ch th∆∞·ªõc 33x32x3 pixel.\ndataset cifar 10\nTi·∫øp theo, ch√∫ng ta s·∫Ω chu·∫©n ho√° d·ªØ li·ªáu. ƒê√¢y l√† 1 b∆∞·ªõc quan tr·ªçng tr∆∞·ªõc khi hu·∫•n luy·ªán m√¥ h√¨nh\n1print( \u0026#34;mean before normalization:\u0026#34;, np.mean(X_train)) 2print( \u0026#34;std before normalization:\u0026#34;, np.std(X_train)) 3 4mean=[0,0,0] 5std=[0,0,0] 6newX_train = np.ones(X_train.shape) 7newX_test = np.ones(X_test.shape) 8for i in range(3): 9 mean[i] = np.mean(X_train[:,i,:,:]) 10 std[i] = np.std(X_train[:,i,:,:]) 11 12for i in range(3): 13 newX_train[:,i,:,:] = X_train[:,i,:,:] - mean[i] 14 newX_train[:,i,:,:] = newX_train[:,i,:,:] / std[i] 15 newX_test[:,i,:,:] = X_test[:,i,:,:] - mean[i] 16 newX_test[:,i,:,:] = newX_test[:,i,:,:] / std[i] 17 18 19X_train = newX_train 20X_test = newX_test 21 22print(\u0026#34;mean after normalization:\u0026#34;, np.mean(X_train)) 23print(\u0026#34;std after normalization:\u0026#34;, np.std(X_train)) 1mean before normalization: 120.70756512369792 2std before normalization: 64.1500758911213 3mean after normalization: 0.9062499999999979 4std after normalization: 0.4227421643271468 Full code ƒëo·∫°n hu·∫•n luy·ªán\n1 2 3# In[3]:Specify Training Parameters 4 5batchSize = 512 #-- Training Batch Size 6num_classes = 10 #-- Number of classes in CIFAR-10 dataset 7num_epochs = 100 #-- Number of epochs for training 8learningRate= 0.001 #-- Learning rate for the network 9lr_weight_decay = 0.95 #-- Learning weight decay. Reduce the learn rate by 0.95 after epoch 10 11 12img_rows, img_cols = 32, 32 #-- input image dimensions 13 14Y_train = np_utils.to_categorical(y_train, num_classes) 15Y_test = np_utils.to_categorical(y_test, num_classes) 16 17 18 19batchSize = 512 #-- Training Batch Size 20num_classes = 10 #-- Number of classes in CIFAR-10 dataset 21num_epochs = 100 #-- Number of epochs for training 22learningRate= 0.001 #-- Learning rate for the network 23lr_weight_decay = 0.95 #-- Learning weight decay. Reduce the learn rate by 0.95 after epoch 24 25 26img_rows, img_cols = 32, 32 #-- input image dimensions 27 28Y_train = np_utils.to_categorical(y_train, num_classes) 29Y_test = np_utils.to_categorical(y_test, num_classes) 30 31 32# In[4]:VGGnet-10 33 34 35from keras.layers import Conv2D 36import copy 37result = {} 38y = {} 39loss = [] 40acc = [] 41dropouts = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] 42for dropout in dropouts: 43 print(\u0026#34;Dropout: \u0026#34;, (dropout)) 44 model = Sequential() 45 46 #-- layer 1 47 model.add(Conv2D(64, (3, 3), 48 border_mode=\u0026#39;valid\u0026#39;, 49 input_shape=( img_rows, img_cols,3))) 50 model.add(Dropout(dropout)) 51 model.add(Conv2D(64, (3, 3))) 52 model.add(Dropout(dropout)) 53 model.add(Activation(\u0026#39;relu\u0026#39;)) 54 model.add(MaxPooling2D(pool_size=(2, 2))) 55 56 ##--layer 2 57 model.add(Conv2D(128, (3, 3))) 58 model.add(Dropout(dropout)) 59 model.add(Activation(\u0026#39;relu\u0026#39;)) 60 model.add(MaxPooling2D(pool_size=(2, 2))) 61 62 ##--layer 3 63 model.add(Conv2D(256, (3, 3))) 64 model.add(Dropout(dropout)) 65 model.add(Activation(\u0026#39;relu\u0026#39;)) 66 model.add(MaxPooling2D(pool_size=(2, 2))) 67 68 ##-- layer 4 69 model.add(Flatten()) 70 model.add(Dense(512)) 71 model.add(Activation(\u0026#39;relu\u0026#39;)) 72 73 #-- layer 5 74 model.add(Dense(num_classes)) 75 76 #-- loss 77 model.add(Activation(\u0026#39;softmax\u0026#39;)) 78 79 sgd = SGD(lr=learningRate, decay = lr_weight_decay) 80 model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, 81 optimizer=\u0026#39;sgd\u0026#39;, 82 metrics=[\u0026#39;accuracy\u0026#39;]) 83 84 model_cce = model.fit(X_train, Y_train, batch_size=batchSize, epochs=20, verbose=1, shuffle=True, validation_data=(X_test, Y_test)) 85 score = model.evaluate(X_test, Y_test, verbose=0) 86 y[dropout] = model.predict(X_test) 87 print(\u0026#39;Test score:\u0026#39;, score[0]) 88 print(\u0026#39;Test accuracy:\u0026#39;, score[1]) 89 result[dropout] = copy.deepcopy(model_cce.history) 90 loss.append(score[0]) 91 acc.append(score[1]) 92 93 94 95# In[5]: plot dropout 96import numpy as np 97import matplotlib.pyplot as plt 98 99width = 0.1 100 101plt.bar(dropouts, acc, width, align=\u0026#39;center\u0026#39;) 102 103plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;major\u0026#39;, labelsize=35) 104plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;minor\u0026#39;, labelsize=35) 105 106plt.ylabel(\u0026#39;Accuracy\u0026#39;,size = 30) 107plt.xlabel(\u0026#39;Dropout\u0026#39;, size = 30) 108plt.show() 109 110 111# In[6]: plot non drop out 112 113import numpy as np 114import matplotlib.pyplot as plt 115 116width = 0.1 117 118plt.bar(dropouts, loss, width, align=\u0026#39;center\u0026#39;,color = \u0026#39;green\u0026#39;) 119 120plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;major\u0026#39;, labelsize=35) 121plt.tick_params(axis=\u0026#39;both\u0026#39;, which=\u0026#39;minor\u0026#39;, labelsize=35) 122 123plt.ylabel(\u0026#39;Loss\u0026#39;,size = 30) 124plt.xlabel(\u0026#39;Dropout\u0026#39;, size = 30) 125plt.show() K·∫øt qu·∫£\nNh√¨n h√¨nh k·∫øt qu·∫£ ·ªü tr√™n, ch√∫ng ta c√≥ m·ªôt s·ªë k·∫øt lu·∫≠n nh·ªè nh∆∞ sau:\nGi√° tr·ªã dropout t·ªët nh·∫•t l√† 0.2, kho·∫£ng dropout cho gi√° tr·ªã ch·∫•p nh·∫≠n ƒë∆∞·ª£c l√† n·∫±m trong ƒëo·∫°n t·ª´ 0 ƒë·∫øn 0.5. N·∫øu dropout l·ªõn h∆°n 0.5 th√¨ k·∫øt qu·∫£ h√†m hu·∫•n luy·ªán tr·∫£ v·ªÅ kh√° t·ªá.\nGi√° tr·ªã ƒë·ªô ch√≠nh x√°c c√≤n kh√° th·∫•p =\u0026gt; 20 epochs l√† ch∆∞a ƒë·ªß, c·∫ßn hu·∫•n luy·ªán nhi·ªÅu h∆°n n·ªØa.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü nh·ªØng b√†i vi·∫øt ti·∫øp theo.\n","date":"May 5, 2019","img":"","permalink":"/blog/2019-05-05-deep-learning-dropout/","series":null,"tags":["machine learning","deep learning","dropout","deep net"],"title":"T√¨m Hi·ªÉu V·ªÅ Dropout Trong Deep Learning, Machine Learning"},{"categories":null,"content":" 1. Gi·ªõi thi·ªáu v·ªÅ PredictionIO 2. C∆° ch·∫ø ho·∫°t ƒë·ªông c·ªßa PredictionIO Event Server Engine 3. C√†i ƒë·∫∑t PredictionIO tr√™n m√¥i tr∆∞·ªùng Ubuntu Download v√† build Apache Prediction IO Bi√™n d·ªãch Prediction IO Download v√† gi·∫£i n√©n c√°c Dependencies C·∫•u h√¨nh ch∆∞∆°ng tr√¨nh 4.Kh·ªüi ch·∫°y h·ªá th·ªëng 1. Gi·ªõi thi·ªáu v·ªÅ PredictionIO PredictionIO l√† m·ªôt \u0026ldquo;open source Machine Learning Server built on top of a state-of-the-art open source stack\u0026rdquo; gi√∫p cho c√°c developers v√† c√°c data scientists t·∫°o ra c√°c engine d·ª± ƒëo√°n trong h·ªçc m√°y. PredictionIO gi√∫p ch√∫ng ta\nX√¢y d·ª±ng v√† tri·ªÉn khai c√°c ·ª©ng d·ª•ng, d·ªãch v·ª• m·ªôt c√°ch nhanh ch√≥ng b·∫±ng c√°ch tu·ª≥ ch·ªânh l·∫°i c√°c template ƒë√£ s·∫µn c√≥.\nTr·∫£ l·ªùi c√°c c√¢u truy v·∫•n ƒë·ªông trong th·ªùi gian th·ª±c.\nhu·∫•n luy·ªán v√† so s√°nh/ƒë√°nh gi√° nhi·ªÅu m√¥ h√¨nh kh√°c nhau d·ªÖ d√†ng.\nH·ª£p nh·∫•t ho√° d·ªØ li·ªáu t·ª´ nhi·ªÅu n·ªÅn t·∫£ng kh√°c nhau ho·∫∑c trong th·ªùi gian th·ª±c ƒë·ªÉ th·ª±c hi·ªán ph√¢n t√≠ch d·ª± ƒëo√°n.\nH·ªó tr·ª£ c√°c th∆∞ vi·ªán m√°y h·ªçc v√† x·ª≠ l√Ω d·ªØ li·ªáu nh∆∞ Spark MLLib v√† OpenNLP\nT·ª± x√¢y d·ª±ng, tri·ªÉn khai, customize m·ªôt m√¥ h√¨nh machine learning\n2. C∆° ch·∫ø ho·∫°t ƒë·ªông c·ªßa PredictionIO PredictionIO bao g·ªìm c√°c th√†nh ph·∫ßn sau:\nPredictionIO platform: l√† n·ªÅn t·∫£ng open source ƒë∆∞·ª£c apache x√¢y d·ª±ng s·∫µn gi√∫p ch√∫ng ta tri·ªÉn khai, x√¢y d·ª±ng, ƒë√°nh gi√° c√°c m√¥ h√¨nh m√°y h·ªçc.\nEvent Server: l√† n∆°i gi√∫p ch√∫ng ta chu·∫©n ho√° c√°c s·ª± ki·ªán t·ª´ nhi·ªÅu ngu·ªìn kh√°c nhau\nTemplate Gallery: l√† n∆°i ch√∫ng ta download c√°c engine template m√°y h·ªçc v·ªÅ. PredictionIO h·ªó tr·ª£ cho ch√∫ng ta r·∫•t nhi·ªÅu template m·∫´u kh√°c nhau. Ch√∫ng ta s·∫Ω l·∫ßn l∆∞·ª£t t√¨m hi·ªÉu v√† implement ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\nEvent Server PredictionIO Event Server ch·ªãu tr√°ch nhi·ªáu thu th·∫≠p d·ªØ li·ªáu t·ª´ c√°c ·ª©ng d·ª•ng c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ nh√¨n k·ªπ h∆°n ·ªü h√¨nh b√™n d∆∞·ªõi, c√°c ·ª©ng d·ª•ng web, mobile app \u0026hellip; khi ng∆∞·ªùi d√πng t∆∞∆°ng t√°c s·∫Ω ph√°t sinh c√°c s·ª± ki·ªán (Event Data), v√≠ d·ª• s·ª± ki·ªán ng∆∞·ªùi d√πng th√™m 1 ƒë∆°n h√†ng v√†o gi·ªè h√†ng, ng∆∞·ªùi d√πng xem s·∫£n ph·∫©n A, ng∆∞·ªùi d√πng xem s·∫£n ph·∫©m C sau khi xem s·∫£n ph·∫©m A\u0026hellip; Event Server s·∫Ω ghi nh·∫≠n l·∫°i ƒë·ªëng d·ªØ li·ªáu n√†y, chu·∫©n ho√° l·∫°i. PredictionIO engine sau ƒë√≥ s·∫Ω x√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n d·ª±a tr√™n c√°c d·ªØ li·ªáu ch√∫ng ta thu th·∫≠p ƒë∆∞·ª£c. Sau khi b·∫°n c√≥ ƒë∆∞·ª£c m√¥ h√¨nh t·ªëi ∆∞u, ch√∫ng ta s·∫Ω deploy c√°c predict webservice, l·∫Øng nghe c√°c truy v·∫•n t·ª´ c√°c ·ª©ng d·ª•ng v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ trong th·ªùi gian th·ª±c.\nH√¨nh 1: Event server trong predictionio\nEvent Server s·∫Ω thu th·∫≠p d·ªØ li·ªáu c·ªßa b·∫°n trong th·ªùi gian th·ª±c ho·∫∑c theo chu k·ª≥. Sau ƒë√≥, n√≥ s·∫Ω chu·∫©n ho√° d·ªØ li·ªáu h·ªón ƒë·ªôn c·ªßa b·∫°n t·ª´ nhi·ªÅu ngu·ªìn kh√°c nhau th√†nh m·ªôt d·∫°ng chu·∫©n chung. Event Server ch·ªß y·∫øu ph·ª•c v·ª• hai m·ª•c ƒë√≠nh ch√≠nh:\nCung c·∫•p d·ªØ li·ªáu cho c√°c engine ƒë·ªÉ hu·∫•n luy·ªán v√† ƒë√°nh gi√°\nCung c·∫•p d·ªØ li·ªáu d·∫°ng chu·∫©n ƒë·ªÉ data analysis\nC≈©ng gi·ªëng nh∆∞ m·ªôt database server, Event Server c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ph·ª•c v·ª• cho nhi·ªÅu ·ª©ng d·ª•ng kh√°c nhau. D·ªØ li·ªáu ƒë∆∞·ª£c ph√¢n t√°ch cho c√°c ·ª©ng d·ª•ng b·∫±ng \u0026ldquo;app_name\u0026rdquo; duy nh·∫•t. C√°i n√†y s·∫Ω n√≥i l·∫°i l√∫c x√¢y d·ª±ng ·ª©ng d·ª•ng ·ªü b√™n d∆∞·ªõi.\nKhi m·ªôt Event Server ƒë∆∞·ª£c tri·ªÉn khai, b·∫°n c√≥ th·ªÉ g·ª≠i d·ªØ li·ªáu cho m·ªôt \u0026lsquo;app_name\u0026rsquo; c·ª• th·ªÉ n√†o ƒë√≥, app-name ƒë∆∞·ª£c ƒë·ªãnh danh b·∫±ng access key. D·ªØ li·ªáu ƒë∆∞·ª£c g·ª≠i ƒë·∫øn Event Server s·ª≠ d·ª•ng EventAPI s·ª≠ d·ª•ng giao th·ª©c http (tham kh·∫£o th√™m ·ªü https://predictionio.apache.org/datacollection/eventapi/) ho·∫∑c s·ª≠ d·ª•ng c√°c PredictionIO SDK. Tham kh·∫£o th√™m c√°c SDK ·ªü https://predictionio.apache.org/sdk/.\nTrong m·ªôt s·ªë tr∆∞·ªùng h·ª£p, b·∫°n mu·ªën engine ƒë·ªçc d·ªØ li·ªáu t·ª´ m·ªôt datastore n√†o ƒë√≥ thay v√¨ Event Server. B·∫°n c√≥ th·ªÉ th·ª±c hi·ªán th√¥ng qua h∆∞·ªõng d·∫´n ·ªü https://predictionio.apache.org/start/customize/\nEngine Engine l√† n∆°i ch·ªãu tr√°ch nhi·ªáu ƒë∆∞a ra c√°c quy·∫øt ƒë·ªãnh. N√≥ g·ªìm m·ªôt ho·∫∑c nhi·ªÅu thu·∫≠t to√°n h·ªçc m√°y h·ªçc kh√°c nhau. C√°c Engine s·∫Ω hu·∫•n luy·ªán d·ªØ li·ªáu v√† x√¢y d·ª±ng c√°c m√¥ h√¨nh d·ª± ƒëo√°n. Sau ƒë√≥ s·∫Ω ph√°t tri·ªÉn th√†nh c√°c webservice. C√°c webservice s·∫Ω nh·∫≠n c√°c truy v·∫•n t·ª´ ·ª©ng d·ª•ng, d·ª± ƒëo√°n v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ cho ·ª©ng d·ª•ng.\nPredictionIO\u0026rsquo;s cung c·∫•p cho ch√∫ng ta r·∫•t nhi·ªÅu c√°c template kh√°c nhau ƒë√°p ·ª©ng g·∫ßn nh∆∞ l√† ƒë·∫©y ƒë·ªß c√°c m√¥ h√¨nh m√°y h·ªçc m√† ch√∫ng ta c·∫ßn. B·∫°n c√≥ th·ªÉ d·ªÖ d√†ng t·∫°o m·ªôt m√¥ h√¨nh m√°y h·ªçc t·ª´ c√°c template. C√°c th√†nh ph·∫ßn c·ªßa m·ªôt template d∆∞·ª£c ƒë·∫∑t t√™n l√† Data Source, Data Preparator, Algorithm(s), Serving, c√°c b·∫°n c√≥ th·ªÉ d·ªÖ d√†ng customize l·∫°i tu·ª≥ thu·ªôc nhu c·∫ßu c·ªßa b·∫°n.\n3. C√†i ƒë·∫∑t PredictionIO tr√™n m√¥i tr∆∞·ªùng Ubuntu Trong th·ªùi ƒë·∫°i docker, c√°c b·∫°n c√≥ th·ªÉ c√†i ƒë·∫∑t PredictionIO d·ª±a v√†o c√°c docker ƒë∆∞·ª£c x√¢y d·ª±ng s·∫µn ƒë·∫ßy r·∫´y tr√™n m·∫°ng, ch√∫ng gi√∫p b·∫°n ƒë·ª° t·ªën c√¥ng s·ª©c h∆°n. Tuy nhi√™n, trong b√†i vi·∫øt n√†y, m√¨nh s·∫Ω c√†i ƒë·∫∑t t·ª´ng th√†nh ph·∫ßn PredictiIO tr√™n ubuntu, kh√¥ng s·ª≠ d·ª•ng docker.\nDownload v√† build Apache Prediction IO Ch√∫ng ta s·∫Ω download Prediction IO t·ª´ trang github ch√≠nh ch·ªß. Phi√™n b·∫£n hi·ªán t·∫°i l√† 0.14.0. C√°c b·∫°n c√≥ th·ªÉ l∆∞u d·ªØ li·ªáu ·ªü ƒë√¢u tu·ª≥ √Ω c√°c b·∫°n. M√¨nh l∆∞u ·ªü th∆∞ m·ª•c /data/pio. V√† trong su·ªët b√†i vi·∫øt n√†y, m√¨nh s·∫Ω l∆∞u c√°c th·ª© li√™n quan trong th∆∞ m·ª•c /data/pio. C√°c b·∫°n c√≥ c√†i ƒë·∫∑t theo h∆∞·ªõng d·∫´n c·ªßa m√¨nh th√¨ nh·ªõ s·ª≠a l·∫°i cho ƒë√∫ng ƒë∆∞·ªùng d·∫´n c·ªßa c√°c b·∫°n. Ch√∫ng ta s·∫Ω clone ngu·ªìn t·ª´ trang github predictionio. v√† s·∫Ω switch qua branch release. ƒê√¢y l√† branch ch√≠nh th√†nh ph·∫©m, c√°c branch kh√°c ƒëang trong giai ƒëo·∫°n ph√°t tri·ªÉn n√™n c√≥ th·ªÉ build kh√¥ng ƒë∆∞·ª£c. L√∫c c√°c b·∫°n l√†m c√≥ th·ªÉ n√≥ ƒë√£ ph√°t tri·ªÉn l√™n b·∫£n 15, 16 ho·∫∑c 1.0 g√¨ ƒë√≥ r·ªìi. C√°c b·∫°n c·ª© t·ª± tin s·ª≠ d·ª•ng phi√™n b·∫£n m·ªõi nh·∫•t.\n1git clone https://github.com/apache/predictionio.git 2git checkout release/0.14.0 Bi√™n d·ªãch Prediction IO Sau khi t·∫£i v·ªÅ b·ªô ngu·ªìn c·ªßa Prediction IO, ch√∫ng ta s·∫Ω ti·ªÅn h√†nh bi√™n d·ªãch. Qu√° tr√¨nh bi√™n d·ªãch s·∫Ω x·∫£y ra kh√° l√¢u, c√°c b·∫°n ki√™n nh·∫´n ch·ªù ƒë·ª£i\n1cd predictionio 2./make-distribution.sh K·∫øt th√∫c qu√° tr√¨nh bi√™n d·ªãch, c√°c b·∫°n s·∫Ω th·∫•y d√≤ng ch·ªØ\n1PredictionIO binary distribution created at PredictionIO-0.14.0.tar.gz V·∫≠y l√† ch√∫ng ta ƒë√£ th√†nh c√¥ng. Vi·ªác ti·∫øp theo l√† gi·∫£i n√©n file PredictionIO-0.14.0.tar.gz ƒë·ªÉ s·ª≠ d·ª•ng\n1tar xvzf PredictionIO-0.14.0.tar.gz -C /data/pio Nh·∫Øc l·∫°i 1 l·∫ßn n·ªØa l√† do th·ªùi ƒëi·ªÉm hi·ªán t·∫°i m√¨nh vi·∫øt b√†i vi·∫øt n√†y, PredictionIO m·ªõi release b·∫£n 0.14.0 n√™n file t·∫≠p tin s·∫Ω l√† PredictionIO-0.14.0.tar.gz. C√°c b·∫°n nh·ªõ gi·∫£i n√©n ƒë√∫ng v·ªõi t√™n file ·ª©ng v·ªõi phi√™n b·∫£n PredictionIO t∆∞∆°ng ·ª©ng nh√©.\nDownload v√† gi·∫£i n√©n c√°c Dependencies M√¨nh s·∫Ω s·ª≠ d·ª•ng Spark, ElasticSearch, Hbase v√† zookeeper, n√™n m√¨nh download h·∫øt v·ªÅ. M√¨nh c√≥ th√≥i quen s·ª≠ d·ª•ng phi√™n b·∫£n m·ªõi nh·∫•t. N√™n m√¨nh l√™n trang ch·ªß v√† l·∫•y link download m·ªõi nh·∫•t c·ªßa ch√∫ng th√¥i. T·∫•t c·∫£ c√°c Dependencies m√¨nh d√πng ƒë·ªÅu ƒë∆∞·ª£c b·ªè v√†o trong th∆∞ m·ª•c vendors\n1 2cd PredictionIO-0.14.0 3mkdir vendors 4cd vendors 5wget https://archive.apache.org/dist/spark/spark-2.4.2/spark-2.4.2-bin-hadoop2.7.tgz 6 7wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.9.tar.gz 8 9wget https://www.apache.org/dyn/closer.lua/hbase/2.1.4/hbase-2.1.4-bin.tar.gz 10 11wget https://www-us.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz 12 13tar xvzf spark-2.4.2-bin-hadoop2.7.tgz 14 15tar xvzf elasticsearch-5.6.9.tar.gz 16 17tar xvzf hbase-2.1.4-bin.tar.gz 18 19tar xvzf zookeeper-3.4.14/zookeeper-3.4.14.tar.gz C·∫•u h√¨nh ch∆∞∆°ng tr√¨nh C·∫•u h√¨nh dependency Ch√∫ng ta s·∫Ω c·∫•u h√¨nh m·ªôt ch√∫t ƒë·ªÉ PredictionIO nh·∫≠n ra c√°c dependency c·ªßa m√¨nh v√† c·∫•u h√¨nh c√°c dependency\nƒê·∫ßu ti√™n, ch√∫ng ta s·∫Ω ch·ªânh s·ª≠a file hbase-site.xml c·ªßa HBase\n1nano /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/conf/hbase-site.xml Thay ƒëo·∫°n\n1\u0026lt;configuration\u0026gt; 2\u0026lt;/configuration\u0026gt; b·∫±ng ƒëo·∫°n\n1\u0026lt;configuration\u0026gt; 2 \u0026lt;property\u0026gt; 3 \u0026lt;name\u0026gt;hbase.rootdir\u0026lt;/name\u0026gt; 4 \u0026lt;value\u0026gt;file:///data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4\u0026lt;/value\u0026gt; 5 \u0026lt;/property\u0026gt; 6 \u0026lt;property\u0026gt; 7 \u0026lt;name\u0026gt;hbase.zookeeper.property.dataDir\u0026lt;/name\u0026gt; 8 \u0026lt;value\u0026gt;/data/pio/PredictionIO-0.14.0/vendors/zookeeper-3.4.14\u0026lt;/value\u0026gt; 9 \u0026lt;/property\u0026gt; 10\u0026lt;/configuration\u0026gt; Ti·∫øp theo, ch√∫ng ta s·∫Ω add ƒë∆∞·ªùng d·∫´n java cho hbase\n1nano /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/conf/hbase-env.sh Th√™m ƒëo·∫°n\n1 export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre/ c√°c b·∫°n h√£y thay ƒë∆∞·ªùng d·∫´n java t∆∞∆°ng ·ª©ng v·ªõi ƒë∆∞·ªùng d·∫´n trong m√°y b·∫°n. N·∫øu ch∆∞a c√≥ java th√¨ c√°c b·∫°n h√£y c√†i v√†o, n·∫øu c√°c b·∫°n ƒë√£ c√†i java m√† kh√¥ng bi·∫øt n√≥ n·∫±m ·ªü ƒë√¢u, c√°c b·∫°n c√≥ th·ªÉ g·ªçi l·ªánh b√™n d∆∞·ªõi ƒë·ªÉ xem ƒë∆∞·ªùng d·∫´n\n1update-alternatives --config java ƒê·ªÉ ch·∫Øc ch·∫Øn r·∫±ng trong m√°y c·ªßa b·∫°n c√≥ c√†i java b·∫°n h√£y g·ªçi l·ªán java -version\nV√≠ d·ª• trong m√°y m√¨nh\n1$java -version 2openjdk version \u0026#34;1.8.0_191\u0026#34; 3OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-2ubuntu0.16.04.1-b12) 4OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode) C√°c b·∫°n c·ªë g·∫Øng s·ª≠ d·ª•ng phi√™n b·∫£n java m·ªõi nh·∫•t. N√≥ s·∫Ω t∆∞∆°ng th√≠ch t·ªët h∆°n v·ªõi phi√™n b·∫£n m·ªõi nh·∫•t c·ªßa HBase, ho·∫∑c ƒë·ªçc phi√™n b·∫£n java ƒë·ªÅ ngh·ªã trong trang ch·ªß HBase. Tr√°nh tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng phi√™n b·∫£n java qu√° c≈© HBase kh√¥ng h·ªó tr·ª£.\nC·∫•u h√¨nh Prediction IO Ch·ªânh s·ª≠a file pio-env.sh.\n1 2nano /data/pio/PredictionIO-0.14.0/conf/pio-env.sh M·∫∑c ƒë·ªãnh PredictionIO s·ª≠ d·ª•ng PosgresSQl l√†m event server. M√¨nh kh√¥ng d√πng n√≥ m√† thay th·∫ø b·∫±ng HBASE v√† ELASTICSEARCH.\nM·ªôt s·ªë thay ƒë·ªïi m√¨nh s·∫Ω li·ªát k√™ b√™n d∆∞·ªõi\n1SPARK_HOME=$PIO_HOME/vendors/spark-2.3.2-bin-hadoop2.7 2 3HBASE_CONF_DIR=$PIO_HOME/vendors/hbase-2.1.4/conf 4 5PIO_STORAGE_REPOSITORIES_METADATA_NAME=pio_meta 6PIO_STORAGE_REPOSITORIES_METADATA_SOURCE=ELASTICSEARCH 7 8PIO_STORAGE_REPOSITORIES_EVENTDATA_NAME=pio_event 9PIO_STORAGE_REPOSITORIES_EVENTDATA_SOURCE=HBASE 10 11PIO_STORAGE_REPOSITORIES_MODELDATA_NAME=pio_model 12PIO_STORAGE_REPOSITORIES_MODELDATA_SOURCE=LOCALFS 13 14#Comment c√°c d√≤ng n√†y l·∫°i, do kh√¥ng d√πng postgres 15# PIO_STORAGE_SOURCES_PGSQL_PASSWORD accordingly 16# PIO_STORAGE_SOURCES_PGSQL_TYPE=jdbc 17# PIO_STORAGE_SOURCES_PGSQL_URL=jdbc:postgresql://localhost/pio 18# PIO_STORAGE_SOURCES_PGSQL_USERNAME=pio 19# PIO_STORAGE_SOURCES_PGSQL_PASSWORD=pio 20 21PIO_STORAGE_SOURCES_ELASTICSEARCH_HOME=$PIO_HOME/vendors/elasticsearch-5.6.9 22PIO_STORAGE_SOURCES_HBASE_HOME=$PIO_HOME/vendors/hbase-2.1.4 4.Kh·ªüi ch·∫°y h·ªá th·ªëng Ch√∫ng ta s·∫Ω add path c·ªßa PredictIO v√†o bi·∫øn m√¥i tr∆∞·ªùng ƒë·ªÉ s·ª≠ d·ª•ng cho c√°c l·∫ßn sau\n1 2nano ~/.bashrc 3erport PATH=/data/pio/PredictionIO-0.14.0/bin:$PATH Ho·∫∑c c√≥ th·ªÉ add path trong m·ªói session\n1PATH=$PATH:/data/pio/PredictionIO-0.14.0/bin; export PATH Ti·∫øp theo, ch√∫ng ta s·∫Ω c·∫•p quy·ªÅn cho th∆∞ m·ª•c PredictionIO\n1sudo chmod -R 775 /data/pio N·∫øu kh√¥ng c·∫•p quy·ªÅn write cho th∆∞ m·ª•c th√¨ PredictionIO kh√¥ng th·ªÉ write log file ƒë∆∞·ª£c.\nCh·∫°y PredictionIO Server b·∫±ng c√°ch g·ªçi c√¢u l·ªánh\n1pio-start-all K·∫øt qu·∫£\n1Stopping PredictionIO Event Server... 2Stopping HBase... 3stopping hbase............. 4Stopping Elasticsearch... 5tgdd@U1604:/data/pio/PredictionIO-0.14.0/bin$ pio-start-all 6Starting Elasticsearch... 7Starting HBase... 8running master, logging to /data/pio/PredictionIO-0.14.0/vendors/hbase-2.1.4/bin/../logs/hbase-tgdd-master-U1604.out 9Waiting 10 seconds for Storage Repositories to fully initialize... 10Starting PredictionIO Event Server... ƒê·ªÉ ki·ªÉm tra h·ªá th·ªëng khi start c√≥ l·ªói l·∫ßm g√¨ kh√¥ng, ch√∫ng ta s·ª≠ d·ª•ng l·ªánh\n1pio status K·∫øt qu·∫£\n1[INFO] [Management$] Inspecting PredictionIO... 2[INFO] [Management$] PredictionIO 0.14.0 is installed at /data/pio/PredictionIO-0.14.0 3[INFO] [Management$] Inspecting Apache Spark... 4[INFO] [Management$] Apache Spark is installed at /data/spark-2.3.2-bin-hadoop2.7 5[INFO] [Management$] Apache Spark 2.3.2 detected (meets minimum requirement of 2.0.2) 6[INFO] [Management$] Inspecting storage backend connections... 7[INFO] [Storage$] Verifying Meta Data Backend (Source: ELASTICSEARCH)... 8[INFO] [Storage$] Verifying Model Data Backend (Source: LOCALFS)... 9[INFO] [Storage$] Verifying Event Data Backend (Source: HBASE)... 10[INFO] [Storage$] Test writing to Event Store (App Id 0)... 11[INFO] [HBLEvents] The table pio_event:events_0 doesn\u0026#39;t exist yet. Creating now... 12[INFO] [HBLEvents] Removing table pio_event:events_0... 13[INFO] [Management$] Your system is all ready to go. B·∫°n th·∫•y d√≤ng ch·ªØ [INFO] [Management$] Your system is all ready to go. th√¨ y√™n t√¢m, h·ªá th·ªëng ƒë√£ ch·∫°y th√†nh c√¥ng.\nƒê·ªÉ stop h·ªá th·ªëng, c√°c b·∫°n g·ªçi l·ªánh\n1pio-stop-all K·∫øt qu·∫£ khi stop\n1Stopping PredictionIO Event Server... 2Stopping HBase... 3stopping hbase............. 4Stopping Elasticsearch... V·∫≠y l√† ch√∫ng ta ƒë√£ ti·∫øn h√†nh c√†i ƒë·∫∑t th√†nh c√¥ng PredictionIO Server r·ªìi. H·∫πn g·∫∑p b·∫°n ·ªü b√†i th·ª© hai, c√†i ƒë·∫∑t c√°c template cho PredictionIO v√† ti·∫øn h√†nh d·ª± ƒëo√°n.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü nh·ªØng b√†i vi·∫øt ti·∫øp theo.\n","date":"May 4, 2019","img":"","permalink":"/blog/2019-05-04-setup-predictio/","series":null,"tags":["machine learning","deep learning","PredictionIO","forecast","d·ª± ƒëo√°n"],"title":"PredictionIO Ph·∫ßn 1 - H∆∞·ªõng D·∫´n C√†i ƒê·∫∑t"},{"categories":null,"content":" L·∫•y m·∫´u ng·∫´u nhi√™n L·∫•y m·∫´u phi ng·∫´u nhi√™n L·∫•y m·∫´u d·ªØ li·ªáu l√† m·ªôt k·ªπ thu·∫≠t r·∫•t quang tr·ªçng trong th·ªëng k√™, l√† y·∫øu t·ªë quan tr·ªçng g√≥p ph·∫ßn x√°c ƒë·ªãnh ƒë·ªô ch√≠nh x√°c c·ªßa research/ survey. N·∫øu c√≥ b·∫•t k·ª≥ sai s√≥t g√¨ trong qu√° tr√¨nh l·∫•y m·∫´u, n√≥ s·∫Ω ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn k·∫øt qu·∫£ cu·ªëi c√πng. C√≥ r·∫•t nhi·ªÅu k·ªπ thu·∫≠t gi√∫p ch√∫ng ta thu th·∫≠p m·∫´u d·ª±a tr√™n nhu c·∫ßu v√† t√¨nh hu·ªëng ch√∫ng ta c·∫ßn. B√†i vi·∫øt n√†y s·∫Ω gi·∫£i th√≠ch m·ªôt s·ªë k·ªπ thu·∫≠t ph·ªï bi·∫øn nh·∫•t.\nƒê·ªÉ b·∫Øt ƒë·∫ßu b√†i vi·∫øt, ch√∫ng ta s·∫Ω l√†m r√µ m·ªët s·ªë kh√°i ni·ªám c∆° b·∫£n l√† Qu·∫ßn th·ªÉ - Population,m·∫´u - Sample v√† l·∫•y m·∫´u - sampling\nQu·∫ßn th·ªÉ - population l√† t·∫≠p h·ª£p c·ªßa c√°c c√° th·ªÉ c√≥ m·ªôt ho·∫∑c m·ªôt s·ªë ƒë·∫∑c ƒëi·ªÉm chung. K√≠ch th∆∞·ªõc c·ªßa m·ªôt qu·∫ßn th·ªÉ l√† s·ªë l∆∞·ª£ng c√° th·ªÉ trong qu·∫ßn th·ªÉ ƒë√≥.\nM·∫´u - sample l√† m·ªôt t·∫≠p con c·ªßa qu·∫ßn th·ªÉ. Qu√° tr√¨nh ch·ªçn m·ªôt m·∫´u ƒë∆∞·ª£c g·ªçi l√† l·∫•y m·∫´u -sampling. K√≠ch th∆∞·ªõc m·∫´u l√† s·ªë l∆∞·ª£ng c√° th·ªÉ trong t·∫≠p m·∫´u.\nH√¨nh 1: V√≠ d·ª• v·ªÅ l·∫•y m·∫´u d·ªØ li·ªáu\nC√≥ r·∫•t nhi·ªÅu k·ªπ thu·∫≠t l·∫•y m·∫´u d·ªØ li·ªáu kh√°c nhau, nh∆∞ng ch√∫ng ta c√≥ th·ªÉ gom ch√∫ng v√†o 2 nh√≥m ch√≠nh:\nL·∫•y m·∫´u ng·∫´u nhi√™n - Probability Sampling\nL·∫•y m·∫´u phi ng·∫´u nhi√™n - non-probability sampling\nH√¨nh 2: V√≠ d·ª• so v·ªÅ l·∫•y m·∫´u ng·∫´u nhi√™n v√† l·∫•y m·∫´u phi ng·∫´u nhi√™n\nS·ª± kh√°c bi·ªát c·ªßa hai nh√≥m tr√™n l√† ph∆∞∆°ng ph√°p l·∫•y m·∫´u c√≥ s·ª≠ d·ª•ng \u0026ldquo;h√†m ng·∫´u nhi√™n\u0026rdquo; hay kh√¥ng. V·ªõi vi·ªác s·ª≠ d·ª•ng h√†m ng·∫´u nhi√™n, m·ªói c√° th·ªÉ ƒë·ªÅu c√≥ c∆° h·ªôi ƒë∆∞·ª£c l·ª±a ch·ªçn ngang nhau v√† ƒë·ªÅu c√≥ c∆° h·ªôi l√† m·ªôt c√° th·ªÉ trong t·∫≠p m·∫´u.\nL·∫•y m·∫´u ng·∫´u nhi√™n Nh·ªØng thu·∫≠t to√°n trong nh√≥m n√†y s·ª≠ d·ª•ng h√†m \u0026ldquo;ng·∫´u nhi√™n\u0026rdquo; ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng m·ªçi ph·∫ßn t·ª≠ ƒë·ªÅu c√≥ c∆° h·ªôi l·ª±a ch·ªçn ngang nhau. M·ªôt t√™n kh√°c c·ªßa ph∆∞∆°ng ph√°p n√†y l√† random sampling.\nM·ªôt s·ªë ph∆∞∆°ng ph√°p thu·ªôc nh√≥m n√†y\nSimple Random Sampling\nStratified sampling\nSystematic sampling\nCluster Sampling\nMulti stage Sampling\nSimple Random Sampling M·ªói c√° th·ªÉ ƒë·ªÅu c√≥ c∆° h·ªôi l·ª±a ch·ªçn ngang nhau v√†o t·∫≠p m·∫´u. Ph∆∞∆°ng ph√°p n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng khi ch√∫ng ta kh√¥ng c√≥ b·∫•t k·ª≥ th√¥ng tin g√¨ v·ªÅ t·∫≠p population.\nV√≠ d·ª•: Ch·ªçn ng·∫´u nhi√™n 20 sinh vi√™n trong l·ªõp h·ªçc 50 sinh vi√™n. M·ªói sinh vi√™n ƒë·ªÅu c√≥ c∆° h·ªôi ƒë∆∞·ª£c ch·ªçn ngang nhau l√† 1/50.\nStratified sampling K·ªπ thu·∫≠t n√†y ph√¢n chia m·ªói c√° th·ªÉ trong qu·∫ßn th·ªÉ th√†nh t·ª´ng nh√≥m nh·ªè d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng (similarity), nghƒ©a l√† c√°c c√° th·ªÉ trong c√πng 1 nh√≥m s·∫Ω ƒë·ªìng nh·∫•t v·ªõi nhau v·ªÅ m·ªôt kh√≠a c·∫°nh n√†o ƒë√≥, v√† s·∫Ω kh√¥ng gi·ªëng v·ªõi c√°c nh√≥m kh√°c v·ªÅ kh√≠a c·∫°nh ƒë√≥. V√† ch√∫ng ta s·∫Ω ch·ªçn ng·∫´u nhi√™n c√°c c√°c th·ªÉ trong m·ªói nh√≥m. ·ªû ph∆∞∆°ng ph√°p n√†y, ch√∫ng ta c·∫ßn th√¥ng tin cho tr∆∞·ªõc v·ªÅ t·∫≠p qu·∫ßn th·ªÉ ƒë·ªÉ t·∫°o c√°c nh√≥m con.\nH√¨nh 2: l·∫•y m·∫´u Stratified sampling\n·ªû v√≠ d·ª• tr√™n, ch√∫ng ta s·∫Ω chia t·∫≠p qu·∫ßn th·ªÉ th√†nh c√°c nh√≥m con m·∫∑c √°o ƒë·ªè, m·∫∑c √°o xanh, m·∫∑c √°o v√†ng (ph·∫£i bi·∫øt tr∆∞·ªõc ƒë∆∞·ª£c trong qu·∫ßn th·ªÉ th·∫±ng n√†o m·∫∑c √°o m√†u g√¨). Sau ƒë√≥ s·∫Ω l·ª±a ch·ªçn ng·∫´u nhi√™n 2 c√°c th·ªÉ trong m·ªói nh√≥m.\nCluster Sampling To√†n b·ªô t·∫≠p qu·∫ßn th·ªÉ s·∫Ω ƒë∆∞·ª£c chia th√†nh t·ª´ c·ª•m ho·∫∑c th√†nh t·ª´ng ph·∫ßn. Sau ƒë√≥ ch√∫ng ta s·∫Ω ch·ªçn ng·∫´u nhi√™n t·ª´ng c·ª•m. T·∫•t c·∫£ c√°c c√° th·ªÉ trong c·ª•m ƒë√≥ s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng l√†m t·∫≠p m·∫´u. C√°c c·ª•m ƒë∆∞·ª£c ƒë·ªãnh danh d·ª±a tr√™n c√°c y·∫øu t·ªë x√°c ƒë·ªãnh tr∆∞·ªõc. V√≠ d·ª• ·ªü trong h√¨nh ·ªü tr√™n, c√°c c·ª•m ƒë∆∞·ª£c ƒë·ªãnh danh d·ª±a v√†o m√†u s·∫Øc c·ªßa √°o m√† ng∆∞·ªùi ƒë√≥ m·∫∑c. ƒêi·ªÉm kh√°c bi·ªát ·ªü ph∆∞∆°ng ph√°p n√†y so v·ªõi ph∆∞∆°ng ph√°p ·ªü tr√™n l√† ph∆∞∆°ng ph√°p ·ªü tr√™n l·ª±a ch·ªçn ng·∫´u nhi√™n m·ªôt s·ªë c√°c c√° th·ªÉ trong m·ªói c·ª•m. C√≤n ph∆∞∆°ng ph√°p n√†y s·∫Ω l·ª±a ch·ªçn ng·∫´u nhi√™n c√°c c·ª•m, v√† ch·ªçn h·∫øt t·∫•t c·∫£ c√°c c√°c th·ªÉ trong c·ª•m ƒë√≥.\nM·ªôt s·ªë chi·∫øn l∆∞·ª£c ƒë·ªÉ l·ª±a ch·ªçn c·ª•m:\nSingle Stage Cluster Sampling: C√°c c·ª•m ƒë∆∞·ª£c l·ª±a ch·ªçn ng·∫´u nhi√™n\nH√¨nh 3: Single Stage Cluster Sampling\nTwo Stage Cluster Sampling: ·ªû ph∆∞∆°ng ph√°p n√†y, ch√∫ng ta s·∫Ω l·ª±a ch·ªçn ng·∫´u nhi√™n c√°c c·ª•m, sau ƒë√≥, trong m·ªói c·ª•m, ch√∫ng ta s·∫Ω l·ª±a ch·ªçn ng·∫´u nhi√™n c√°c c√° th·ªÉ trong m·ªói c·ª•m\nH√¨nh 4: Two Stage Cluster Sampling\nSystematic Clustering ·ªû ph∆∞∆°ng ph√°p n√†y, vi·ªác l·ª±a ch·ªçn c√° th·ªÉ l√† c√≥ quy lu·∫≠t v√† kh√¥ng ng·∫´u nhi√™n, t·ª´ c√° th·ªÉ ƒë·∫ßu ti√™n. C√°c c√° th·ªÉ c·ªßa t·∫≠p m·∫´u ƒë∆∞·ª£c ch·ªçn ra t·ª´ t·∫≠p qu·∫ßn th·ªÉ d·ª±a v√†o m·ªôt quy lu·∫≠t n√†o ƒë√≥. ƒê·∫ßu ti√™n, t·∫•t c·∫£ c√°c c√° th·ªÉ trong t·∫≠p qu·∫ßn th·ªÉ ph·∫£i ƒë∆∞·ª£c x·∫Øp x·∫øp c√≥ th·ª© t·ª±. Sau ƒë√≥ ch√∫ng ta s·∫Ω l·ª±a ch·ªçn ng·∫´u nhi√™n c√° th·ªÉ ƒë·∫ßu ti√™n (m·ªói c√° th·ªÉ ƒë·ªÅu c√≥ x√°c su·∫•t ngang nhau ·ªü ƒë√¢y), v√† s·ª≠ d·ª•ng quy lu·∫≠t n√†o ƒë√≥ ƒë·ªÉ r√∫t ra c√°c c√° th·ªÉ ti·∫øp theo.\nH√¨nh 5: Systematic Clustering\nNh∆∞ v√≠ d·ª• ·ªü tr√™n, ch√∫ng ta x·∫Øp x·∫øp c√°c nh√¢n v·∫≠t √°o v√†ng, xanh, ƒë·ªè ng·∫´u nhi√™n tu·ª≥ √Ω theo s·ª± l·ª±a ch·ªçn c·ªßa ng∆∞·ªùi ta. Quy lu·∫≠t l√† c·ª© 4 ng∆∞·ªùi s·∫Ω l·∫•y ng∆∞·ªùi cu·ªëi. ·∫§n n√∫t ng·∫´u nhi√™n \u0026hellip; ta ƒë∆∞·ª£c s·ªë 3. V·∫≠y l√† c√° th·ªÉ ƒë·∫ßu ti√™n l√† nh√¢n v·∫≠t ·ªü v·ªã tr√≠ s·ªë 3, ti·∫øp theo s·∫Ω l√† nh√¢n v·∫≠t ·ªü v·ªã tr√≠ 7, 11, 15,19, 5, \u0026hellip;\nMulti-Stage Sampling Ph∆∞∆°ng ph√°p n√†y l√† s·ª± k·∫øt h·ª£p c·ªßa m·ªôt ho·∫∑c nhi·ªÅu ph∆∞∆°ng ph√°p ƒë∆∞·ª£c m√¥ t·∫£ ·ªü tr√™n.\nQu·∫ßn th·ªÉ ƒë∆∞·ª£c chia th√†nh nhi·ªÅu c·ª•m (cluster) v√† m·ªói c·ª•m ƒë∆∞·ª£c chia v√†o t·ª´ng nh√≥m con (subgrop - strata) d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng =\u0026gt; ch√∫ng ta ƒë∆∞·ª£c m·ªôt t·∫≠p c√°c c·ª•m con ƒë∆∞·ª£c g·ªçi l√† stratum. Ch√∫ng ta s·∫Ω l·ª±a nh·ªçn m·ªôt ho·∫∑c m·ªôt v√†i strata trong stratum. Qu√° tr√¨nh n√†y s·∫Ω ƒë∆∞·ª£c l·∫∑p ƒëi l·∫∑p l·∫°i ƒë·∫øn khi kh√¥ng c√≤n c·ª•m n√†o c√≥ th·ªÉ ph√¢n chia ƒë∆∞·ª£c n·ªØa.\nV√≠ d·ª•, c√°c qu·ªëc gia c√≥ th·ªÉ ƒë∆∞·ª£c ph√¢n chia th√†nh t·ª´ng bang, th√†nh ph·ªë, th√†nh th·ªã, n√¥ng th√¥n. V√† t·∫•t c·∫£ c√°c khu v·ª±c c√≥ c√πng k√Ω t·ª± ƒë·∫ßu c√≥ th·ªÉ ƒë∆∞·ª£c gom l·∫°i th√†nh v·ªõi nhau t·∫°o th√†nh m·ªôt strata.\nH√¨nh 6: Multi-Stage Sampling\nL·∫•y m·∫´u phi ng·∫´u nhi√™n Nh·ªØng k·ªπ thu·∫≠t n·∫±m trong nh√≥m n√†y kh√¥ng s·ª≠ d·ª•ng h√†m ng·∫´u nhi√™n. K·ªπ thu·∫≠t n√†y ph·ª• thu·ªôc v√†o kh·∫£ nƒÉng hi·ªÉu bi·∫øt c·ªßa c√°c nh√† nghi√™n c·ª©u (researcher) tr√™n t·∫≠p qu·∫ßn th·ªÉ h·ªç ƒëang c√≥ ƒë·ªÉ ch·ªçn l·ª±a c√° th·ªÉ cho t·∫≠p m·∫´u. K·∫øt qu·∫£ c·ªßa vi·ªác l·∫•y m·∫´u c√≥ th·ªÉ b·ªã l·ªách.\nM·ªôt s·ªë ph∆∞∆°ng ph√°p thu·ªôc nh√≥m n√†y l√†:\nConvenience Sampling\nPurposive Sampling\nQuota Sampling\nReferral /Snowball Sampling\nConvenience Sampling C√°c c√° th·ªÉ ƒë∆∞·ª£c ch·ªçn d·ª±a tr√™n t√≠nh kh·∫£ d·ª•ng c·ªßa d·ªØ li·ªáu. Ph∆∞∆°ng ph√°p n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng khi t√≠nh kh·∫£ d·ª•ng c·ªßa d·ªØ li·ªáu l√† hi·∫øm v√† t·ªën k√©m. Do v·∫≠y, ch√∫ng ta s·∫Ω l·ª±a ch·ªçn m·∫´u d·ª±a tr√™n s·ª± ti·ªán l·ª£i.\nV√≠ d·ª•, C√°c nh√† nghi√™n c·ª©u th∆∞·ªùng hay s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p n√†y trong c√°c giai ƒëo·∫°n ƒë·∫ßu c·ªßa c√°c nghi√™n c·ª©u kh·∫£o s√°t, v√¨ n√≥ d·ªÖ d√†ng, nhanh ch√≥ng v√† cho ra k·∫øt qu·∫£ nhanh.\nPurposive Sampling Ph∆∞∆°ng ph√°p l·∫•y m·∫´u n√†y d·ª±a tr√™n m·ª•c ƒë√≠ch c·ªßa nghi√™n c·ª©u. Ch·ªâ ch·ªçn ra nh·ªØng c√° th·ªÉ trong qu·∫ßn th·ªÉ ph√π h·ª£p nh·∫•t v·ªõi m·ª•c ƒë√≠ch nghi√™n c·ª©u .\nV√≠ d·ª•: N·∫øu ch√∫ng ta mu·ªën hi·ªÉu ƒë∆∞·ª£c \u0026ldquo;suy nghƒ© c·ªßa nh·ªØng ng∆∞·ªùi quan t√¢m ƒë·∫øn b·∫±ng th·∫°c s·ªπ\u0026rdquo; th√¨ ti√™u ch√≠ l·ª±a ch·ªçn c√° th·ªÉ l√† nh·ªØng ng∆∞·ªùi say yes trong c√¢u h·ªèi \u0026ldquo;b·∫°n c√≥ h·ª©ng th√∫ v·ªõi b·∫≠c th·∫°c s·ªπ trong lƒ©nh v·ª±c \u0026hellip; kh√¥ng?\u0026rdquo;. Nh·ªØng ng∆∞·ªùi say \u0026ldquo;No\u0026rdquo; s·∫Ω b·ªã lo·∫°i kh·ªèi t·∫≠p m·∫´u c·ªßa ch√∫ng ta.\nQuota Sampling Ph∆∞∆°ng ph√°p l·∫•y m·∫´u n√†y ph·ª• thu·ªôc v√†o m·ªôt s·ªë ti√™u chu·∫©n thi·∫øt l·∫≠p t·ª´ tr∆∞·ªõc. T·ª∑ l·ªá c·ªßa c√°c nh√≥m c√° th·ªÉ trong t·∫≠p m·∫´u ph·∫£i gi·ªëng h·∫øt trong t·∫≠p qu·∫ßn th·ªÉ. C√°c c√° th·ªÉ ƒë∆∞·ª£c ch·ªçn cho ƒë·∫øn khi ch√∫ng ƒë·∫°t ƒë√∫ng t·ª∑ l·ªá c·ªßa m·ªôt lo·∫°i d·ªØ li·ªáu.\nV√≠ d·ª•: Gi·∫£ s·ª≠ ch√∫ng ta bi·∫øt r·∫±ng tr√™n tr√°i ƒë·∫•t n√†y c√≥ 6 t·ª∑ ng∆∞·ªùi, v√† 45% trong s·ªë ƒë√≥ l√† nam gi·ªõi v√† 55% l√† n·ªØ gi·ªõi. V·∫≠y th√¨ ch√∫ng ta s·∫Ω l·∫•y m·∫´u l√†m sao cho t·∫≠p m·∫´u ch√∫ng ta c≈©ng ph·∫£n √°nh s·ªë ƒë√≥, nghƒ©a l√† trong t·∫≠p m·∫´u c√≥ 1000 ng∆∞·ªùi th√¨ 45% trong s·ªë 1000 ng∆∞·ªùi ƒë√≥ ph·∫£i l√† nam v√† 55% trong s·ªë 1000 ng∆∞·ªùi ƒë√≥ l√† n·ªØ.\nReferral /Snowball Sampling K·ªπ thu·∫≠t n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng khi ch√∫ng ta kh√¥ng bi·∫øt g√¨ v·ªÅ t·∫≠p qu·∫ßn th·ªÉ ho·∫∑c t·∫≠p qu·∫ßn th·ªÉ hi·∫øm. L√∫c ƒë√≥ ch√∫ng ta s·∫Ω t√¨m ra c√° th·ªÉ ƒë·∫ßu ti√™n trong qu·∫ßn th·ªÉ, r·ªìi nh·ªù c√° th·ªÉ ƒë·∫ßu ti√™n ƒë√≥ g·ª£i √Ω c√°c c√° th·ªÉ ti·∫øp theo v·ªõi ƒëi·ªÅu ki·ªán tho·∫£ nhu c·∫´u l·∫•y m·∫´u c·ªßa nghi√™n c·ª©u. C·ª© ti·∫øp t·ª•c nh∆∞ v·∫≠y th√¨ k√≠ch th∆∞·ªõc c·ªßa t·∫≠p m·∫´u s·∫Ω tƒÉng l√™n theo c·∫•p nh√¢n nh∆∞ k√≠ch th∆∞·ªõc qu·∫£ qu·∫£ c·∫ßu tuy·∫øt, n√™n k·ªπ thu·∫≠t n√†y c√≤n c√≥ t√™n g·ªçi kh√°c l√† Snowball Sampling.\nH√¨nh 7: V√≠ d·ª• v·ªÅ Snowball Sampling\nV√≠ d·ª•: Trong t√¨nh hu·ªëng, ng·ªØ c·∫£nh l√† b·∫°n mu·ªën l√†m 1 b√†i kh·∫£o s√°t v·ªÅ nh·ªØng ng∆∞·ªùi b·ªã nhi·ªÖm HIV, nh·ªØng ng∆∞·ªùi n√†y th∆∞·ªùng c√≥ khuynh h∆∞·ªõng kh√¥ng c·ªüi m·ªü ·ªü m·ª©c ƒë·ªô c√¥ng c·ªông v√† kh√≥ cho ch√∫ng ta ti·∫øp c·∫≠n ƒë·ªÉ thu th·∫≠p th√¥ng tin tr·ª±c ti·∫øp t·ª´ h·ªç.\nNh√≥m kh·∫£o s√°t s·∫Ω ti·∫øn h√†nh li√™n h·ªá 1 ng∆∞·ªùi n√†o ƒë√≥ m√† h·ªç bi·∫øt ho·∫∑c ng∆∞·ªùi n√†o ƒë√≥ xung phong l√†m c·∫ßu n·ªëi v·ªõi c√°c ng∆∞·ªùi b·ªã nhi·ªÖm v√† thu th·∫≠p th√¥ng tin t·ª´ h·ªç (nh·ªØng ng∆∞·ªùi b·ªã nhi·ªÖn tin t∆∞·ªüng ng∆∞·ªùi ƒë∆∞·ª£c xung phong h∆°n nh√≥m kh·∫£o s√°t. V√¨ nh√≥m kh·∫£o s√°t l√† ng∆∞·ªùi l·∫°).\nHi v·ªçng sau b√†i vi·∫øt n√†y, c√°c b·∫°n c√≥ th√™m nhi·ªÅu √Ω t∆∞·ªüng h∆°n n·ªØa v·ªÅ vi·ªác l·∫•y m·∫´u v√† c√°c c√°ch ƒë·ªÉ l·∫•y m·∫´u trong ·ª©ng d·ª•ng th·ª±c t·∫ø.\nB√†i vi·∫øt ƒë∆∞·ª£c l∆∞·ª£c d·ªãch v√† m·ªôt s·ªë h√¨nh ·∫£nh ƒë∆∞·ª£c l·∫•y t·ª´ ngu·ªìn https://towardsdatascience.com/sampling-techniques-a4e34111d808\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü nh·ªØng b√†i vi·∫øt ti·∫øp theo.\n","date":"May 4, 2019","img":"","permalink":"/blog/2019-05-04-sampling-method/","series":null,"tags":["machine learning","deep learning","sampleing","Probability Sampling","non-probability sampling"],"title":"C√°c K·ªπ Thu·∫≠t L·∫•y M·∫´u"},{"categories":null,"content":" 1.\tPh√¢n nh√≥m d·ª±a tr√™n ph∆∞∆°ng th·ª©c h·ªçc a.\tH·ªçc c√≥ gi√°m s√°t Ph√¢n l·ªõp H·ªìi quy b. H·ªçc kh√¥ng gi√°m s√°t Ph√¢n c·ª•m Lu·∫≠t k·∫øt h·ª£p c.\tH·ªçc b√°n gi√°m s√°t d.\tH·ªçc tƒÉng c∆∞·ªùng 2.\tPh√¢n nh√≥m d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng a.\tC√°c thu·∫≠t to√°n h·ªìi quy (Regression Algorithms) b.\tThu·∫≠t to√°n d·ª±a tr√™n m·∫´u (Instance-based Algorithms) c.\tThu·∫≠t to√°n chu·∫©n ho√° (Regularization Algorithms) d.\tThu·∫≠t to√°n c√¢y quy·∫øt ƒë·ªãnh (Decision Tree Algorithms) e.\tThu·∫≠t to√°n Bayes (Bayesian Algorithms) f.\tThu·∫≠t to√°n ph√¢n c·ª•m (Clustering Algorithms) g.\tC√°c thu·∫≠t to√°n lu·∫≠t k·∫øt h·ª£p (Association Rule Learning Algorithms) h.\tThu·∫≠t to√°n m·∫°ng n∆°ron nh√¢n t·∫°o (Artificial Neural Network Algorithms) i.\tThu·∫≠t to√°n h·ªçc s√¢u (Deep Learning Algorithms) j.\tNh√≥m thu·∫≠t to√°n Gi·∫£m chi·ªÅu d·ªØ li·ªáu (Dimensionality Reduction Algorithms) k.\tThu·∫≠t to√°n t·∫≠p h·ª£p (Ensemble Algorithms) l.\tC√°c thu·∫≠t to√°n kh√°c ·ªû b√†i tr∆∞·ªõc m√¨nh ƒë√£ tr√¨nh b√†y ƒë·ªãnh nghƒ©a v√† m·ªôt s·ªë ·ª©ng d·ª•ng c·ªßa M√°y h·ªçc (Machine Learning ‚Äì ML), ph√¢n bi·ªát ML v·ªõi Tr√≠ tu·ªá nh√¢n t·∫°o (Artificial Intelligence ‚Äì AI) c≈©ng nh∆∞ m·ªëi quan h·ªá gi·ªØa AI, ML v√† Big Data. T·ª´ b√†i vi·∫øt n√†y tr·ªü ƒëi m√¨nh s·∫Ω t·∫≠p trung vi·∫øt v·ªÅ ML, c√°c thu·∫≠t to√°n, c√°ch s·ª≠ d·ª•ng c√¥ng c·ª• k√®m theo m·ªôt v√†i demo nh·ªè gi√∫p b·∫°n ƒë·ªçc d·ªÖ h√¨nh dung v√† √°p d·ª•ng. ƒê·ªÉ m·ªü ƒë·∫ßu cho chu·ªói b√†i vi·∫øt s·∫Øp t·ªõi, h√¥m nay m√¨nh s·∫Ω tr√¨nh b√†y c√°ch ph√¢n nh√≥m c√°c thu·∫≠t to√°n ML.\nV·ªõi ƒëa s·ªë m·ªçi ng∆∞·ªùi, tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu gi·∫£i quy·∫øt m·ªôt v·∫•n ƒë·ªÅ n√†o ƒë√≥, vi·ªác ƒë·∫ßu ti√™n l√† ch√∫ng ta s·∫Ω t√¨m hi·ªÉu xem li·ªáu c√≥ ai ƒë√£ g·∫∑p v·∫•n ƒë·ªÅ n√†y ho·∫∑c v·∫•n ƒë·ªÅ t∆∞∆°ng t·ª± nh∆∞ v·∫≠y hay kh√¥ng v√† c√°ch h·ªç gi·∫£i quy·∫øt th·∫ø n√†o. Sau khi n·∫Øm ƒë∆∞·ª£c th√¥ng tin kh√°i qu√°t, c√¥ng vi·ªác k·∫ø ti·∫øp l√† ch·ªçn l·ª±a v√† ƒëi·ªÅu ch·ªânh gi·∫£i ph√°p sao cho ph√π h·ª£p v·ªõi v·∫•n ƒë·ªÅ c·ªßa b·∫£n th√¢n. Trong tr∆∞·ªùng h·ª£p v·∫•n ƒë·ªÅ c√≤n qu√° m·ªõi m·∫ª th√¨ ch√∫ng ta m·ªõi ph·∫£i b·∫Øt tay l√†m t·ª´ ƒë·∫ßu, ƒëi·ªÅu n√†y h·∫ßu nh∆∞ r·∫•t hi·∫øm, ƒë·∫∑c bi·ªát l√† trong th·ªùi ƒë·∫°i c√¥ng ngh·ªá n√†y, khi m√† ch·ªâ b·∫±ng m·ªôt c√∫ nh·∫•p chu·ªôt, h√†ng ng√†n th√¥ng tin, t∆∞ li·ªáu v·ªÅ ƒë·ªÅ t√†i ch√∫ng ta quan t√¢m s·∫Ω xu·∫•t hi·ªán. C≈©ng gi·ªëng nh∆∞ th·∫ø, ML hi·ªán ƒë√£ ƒë∆∞·ª£c nghi√™n c·ª©u r·ªông kh·∫Øp, r·∫•t nhi·ªÅu c√¥ng tr√¨nh khoa h·ªçc, thu·∫≠t to√°n ƒë∆∞·ª£c cho ra ƒë·ªùi. V·ªõi ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu m√† n√≥i th√¨ ch√∫ng ta ch∆∞a c·∫ßn ph·∫£i l√†m g√¨ c·∫£ ngo√†i vi·ªác n·∫Øm ƒë∆∞·ª£c c√°c thu·∫≠t to√°n c∆° b·∫£n, ƒë·∫∑c ƒëi·ªÉm c·ªßa ch√∫ng ƒë·ªÉ khi ƒë·ªëi di·ªán v·ªõi m·ªôt b√†i to√°n c·ª• th·ªÉ trong th·ª±c t·∫ø ch√∫ng ta c√≥ th·ªÉ bi·∫øt ƒë∆∞·ª£c m√¨nh n√™n l·ª±a ch·ªçn thu·∫≠t to√°n n√†o cho ph√π h·ª£p ƒë√£ l√† ƒëi·ªÅu r·∫•t t·ªët r·ªìi.\nM·∫∑c d√π c√≥ r·∫•t nhi·ªÅu thu·∫≠t to√°n h·ªçc nh∆∞ng d·ª±a v√†o ph∆∞∆°ng th·ª©c h·ªçc (learning style) ho·∫∑c s·ª± t∆∞∆°ng ƒë·ªìng (similarity) v·ªÅ h√¨nh th·ª©c hay ch·ª©c nƒÉng m√† ch√∫ng c√≥ th·ªÉ ƒë∆∞·ª£c gom th√†nh t·ª´ng nh√≥m. Sau ƒë√¢y m√¨nh s·∫Ω tr√¨nh b√†y t·ªïng quan c·∫£ hai c√°ch ph√¢n nh√≥m thu·∫≠t to√°n h·ªçc n√†y.\n1.\tPh√¢n nh√≥m d·ª±a tr√™n ph∆∞∆°ng th·ª©c h·ªçc X√©t theo ph∆∞∆°ng th·ª©c h·ªçc, c√°c thu·∫≠t to√°n ML ƒë∆∞·ª£c chia l√†m b·ªën nh√≥m, bao g·ªìm ‚ÄúH·ªçc c√≥ gi√°m s√°t‚Äù (Supervised Learning), ‚ÄúH·ªçc kh√¥ng gi√°m s√°t‚Äù (Unsupervised Learning), ‚ÄúH·ªçc b√°n gi√°m s√°t‚Äù (hay h·ªçc k·∫øt h·ª£p - Semi-supervised Learning) v√† ‚ÄúH·ªçc tƒÉng c∆∞·ªùng‚Äù (Reinforcement Learning).\na.\tH·ªçc c√≥ gi√°m s√°t H·ªçc c√≥ gi√°m s√°t hay c√≤n g·ªçi l√† h·ªçc c√≥ th·∫ßy l√† thu·∫≠t to√°n d·ª± ƒëo√°n nh√£n (label)/ƒë·∫ßu ra (output) c·ªßa m·ªôt d·ªØ li·ªáu m·ªõi d·ª±a tr√™n t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán m√† trong ƒë√≥ m·ªói m·∫´u d·ªØ li·ªáu ƒë·ªÅu ƒë√£ ƒë∆∞·ª£c g√°n nh√£n nh∆∞ minh ho·∫° ·ªü H√¨nh 1. Khi ƒë√≥, th√¥ng qua m·ªôt qu√° tr√¨nh hu·∫•n luy·ªán, m·ªôt m√¥ h√¨nh s·∫Ω ƒë∆∞·ª£c x√¢y d·ª±ng ƒë·ªÉ cho ra c√°c d·ª± ƒëo√°n v√† khi c√°c d·ª± ƒëo√°n b·ªã sai th√¨ m√¥ h√¨nh n√†y s·∫Ω ƒë∆∞·ª£c tinh ch·ªânh l·∫°i. Vi·ªác hu·∫•n luy·ªán s·∫Ω ti·∫øp t·ª•c cho ƒë·∫øn khi m√¥ h√¨nh ƒë·∫°t ƒë∆∞·ª£c m·ª©c ƒë·ªô ch√≠nh x√°c mong mu·ªën tr√™n d·ªØ li·ªáu hu·∫•n luy·ªán. ƒêi·ªÅu n√†y c≈©ng gi·ªëng nh∆∞ khi ch√∫ng ta ƒëi h·ªçc tr√™n l·ªõp, ta bi·∫øt c√¢u tr·∫£ l·ªùi ch√≠nh x√°c t·ª´ gi√°o vi√™n (t·∫≠p d·ªØ li·ªáu c√≥ nh√£n) v√† t·ª´ ƒë√≥ ta s·∫Ω s·ª≠a ch·ªØa n·∫øu l√†m sai. H·ªçc c√≥ gi√°m s√°t l√† nh√≥m ph·ªï bi·∫øn nh·∫•t trong c√°c thu·∫≠t to√°n ML.\nH√¨nh 1: Supervised Learning Algorithms\nM·ªôt c√°ch to√°n h·ªçc, h·ªçc c√≥ gi√°m s√°t l√† khi ch√∫ng ra c√≥ m·ªôt t·∫≠p h·ª£p bi·∫øn ƒë·∫ßu v√†o $ X={x_1,x_2,‚Ä¶,x_N} $ v√† m·ªôt t·∫≠p h·ª£p nh√£n t∆∞∆°ng ·ª©ng $ Y={y_1,y_2,‚Ä¶,y_N} $, trong ƒë√≥ $ x_i$, $y_i $ l√† c√°c vector. C√°c c·∫∑p d·ªØ li·ªáu bi·∫øt tr∆∞·ªõc $( x_i, y_i ) \\in X \\times Y $ ƒë∆∞·ª£c g·ªçi l√† t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán (training data). T·ª´ t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán n√†y, ch√∫ng ta c·∫ßn t·∫°o ra m·ªôt h√†m s·ªë √°nh x·∫° m·ªói ph·∫ßn t·ª≠ t·ª´ t·∫≠p X sang m·ªôt ph·∫ßn t·ª≠ (x·∫•p x·ªâ) t∆∞∆°ng ·ª©ng c·ªßa t·∫≠p Y:\n$$ y_i \\approx f(x_i), \\forall i=1, 2, ‚Ä¶, N $$\nM·ª•c ƒë√≠ch l√† x·∫•p x·ªâ h√†m s·ªë $f$ th·∫≠t t·ªët ƒë·ªÉ khi c√≥ m·ªôt d·ªØ li·ªáu x m·ªõi, ch√∫ng ta c√≥ th·ªÉ t√≠nh ƒë∆∞·ª£c nh√£n t∆∞∆°ng ·ª©ng c·ªßa n√≥ $y=f(x)$.\nV√≠ d·ª•: Trong nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay, ta c√≥ ·∫£nh c·ªßa h√†ng ngh√¨n tr∆∞·ªùng h·ª£p ·ª©ng v·ªõi m·ªói ch·ªØ s·ªë ƒë∆∞·ª£c vi·∫øt b·ªüi nhi·ªÅu ng∆∞·ªùi kh√°c nhau. Ta ƒë∆∞a c√°c b·ª©c ·∫£nh n√†y v√†o m·ªôt thu·∫≠t to√°n h·ªçc v√† ch·ªâ cho n√≥ bi·∫øt ‚Äúm·ªói b·ª©c ·∫£nh t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë n√†o‚Äù. Sau khi thu·∫≠t to√°n t·∫°o ra m·ªôt m√¥ h√¨nh, t·ª©c l√† m·ªôt h√†m s·ªë nh·∫≠n ƒë·∫ßu v√†o l√† m·ªôt b·ª©c ·∫£nh v√† cho ra k·∫øt qu·∫£ l√† m·ªôt ch·ªØ s·ªë. Khi nh·∫≠n ƒë∆∞·ª£c m·ªôt b·ª©c ·∫£nh m·ªõi m√† m√¥ h√¨nh ‚Äúch∆∞a t·ª´ng g·∫∑p qua‚Äù v√† n√≥ s·∫Ω d·ª± ƒëo√°n xem b·ª©c ·∫£nh ƒë√≥ t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë n√†o.\nH√¨nh 2: ·∫¢nh minh ho·∫° cho t·∫≠p d·ªØ li·ªáu ch·ªØ s·ªë vi·∫øt tay - MNIST\nƒê·ªëi v·ªõi nh·ªØng ai s·ª≠ d·ª•ng m·∫°ng x√£ h·ªôi Facebook th√¨ kh√° quen thu·ªôc v·ªõi t√≠nh nƒÉng ph√°t hi·ªán khu√¥n m·∫∑t trong m·ªôt b·ª©c ·∫£nh, b·∫£n ch·∫•t c·ªßa thu·∫≠t to√°n d√≤ t√¨m c√°c khu√¥n m·∫∑t n√†y l√† m·ªôt thu·∫≠t to√°n h·ªçc c√≥ gi√°m s√°t v·ªõi t·∫≠p hu·∫•n luy·ªán l√† v√¥ s·ªë ·∫£nh ƒë√£ ƒë∆∞·ª£c g√°n nh√£n l√† m·∫∑t ng∆∞·ªùi hay kh√¥ng ph·∫£i m·∫∑t ng∆∞·ªùi.\nC√°c thu·∫≠t to√°n h·ªçc c√≥ gi√°m s√°t c√≤n ƒë∆∞·ª£c ph√¢n ra th√†nh hai lo·∫°i ch√≠nh l√† ph√¢n l·ªõp (Classification) v√† h·ªìi quy (Regression).\nPh√¢n l·ªõp M·ªôt b√†i to√°n ƒë∆∞·ª£c g·ªçi l√† ph√¢n l·ªõp n·∫øu c√°c nh√£n c·ªßa d·ªØ li·ªáu ƒë·∫ßu v√†o ƒë∆∞·ª£c chia th√†nh m·ªôt s·ªë h·ªØu h·∫°n l·ªõp (mi·ªÅn gi√° tr·ªã l√† r·ªùi r·∫°c). Ch·∫≥ng h·∫°n nh∆∞ t√≠nh nƒÉng x√°c ƒë·ªãnh xem m·ªôt email c√≥ ph·∫£i l√† spam hay kh√¥ng c·ªßa Gmail; x√°c ƒë·ªãnh xem h√¨nh ·∫£nh c·ªßa con v·∫≠t l√† ch√≥ hay m√®o. Ho·∫∑c v√≠ d·ª• nh·∫≠n d·∫°ng k√Ω s·ªë vi·∫øt tay ·ªü tr√™n c≈©ng thu·ªôc b√†i to√°n ph√¢n l·ªõp, bao g·ªìm m∆∞·ªùi l·ªõp ·ª©ng v·ªõi c√°c s·ªë t·ª´ 0 ƒë·∫øn 9. T∆∞∆°ng t·ª± cho v√≠ d·ª• nh·∫≠n d·∫°ng khu√¥n m·∫∑t v·ªõi hai l·ªõp l√† ph·∫£i v√† kh√¥ng ph·∫£i khu√¥n m·∫∑t, ‚Ä¶\nH·ªìi quy M·ªôt b√†i to√°n ƒë∆∞·ª£c xem l√† h·ªìi quy n·∫øu nh√£n kh√¥ng ƒë∆∞·ª£c chia th√†nh c√°c nh√≥m m√† l√† m·ªôt gi√° tr·ªã th·ª±c c·ª• th·ªÉ (mi·ªÅn gi√° tr·ªã l√† li√™n t·ª•c). H·∫ßu h·∫øt c√°c b√†i to√°n d·ª± b√°o (gi√° c·ªï phi·∫øu, gi√° nh√†, ‚Ä¶) th∆∞·ªùng ƒë∆∞·ª£c x·∫øp v√†o b√†i to√°n h·ªìi quy. V√≠ nh∆∞, n·∫øu m·ªôt cƒÉn nh√† r·ªông 150 m^2, c√≥ 7 ph√≤ng v√† c√°ch trung t√¢m th√†nh ph·ªë 10 km s·∫Ω c√≥ gi√° l√† bao nhi√™u? L√∫c n√†y k·∫øt qu·∫£ d·ª± ƒëo√°n s·∫Ω l√† m·ªôt s·ªë th·ª±c.\nN·∫øu nh∆∞ ph√°t hi·ªán khu√¥n m·∫∑t l√† b√†i to√°n ph√¢n l·ªõp th√¨ d·ª± ƒëo√°n tu·ªïi l√† b√†i to√°n h·ªìi quy. Tuy nhi√™n d·ª± ƒëo√°n tu·ªïi c≈©ng c√≥ th·ªÉ coi l√† ph√¢n l·ªõp n·∫øu ta cho tu·ªïi l√† m·ªôt s·ªë nguy√™n d∆∞∆°ng N v√† khi ƒë√≥ ta s·∫Ω c√≥ N l·ªõp kh√°c nhau t√≠nh t·ª´ 1. M·ªôt s·ªë thu·∫≠t to√°n n·ªïi ti·∫øng thu·ªôc v·ªÅ nh√≥m h·ªçc c√≥ gi√°m s√°t nh∆∞:\nPh√¢n l·ªõp: k-Nearest Neighbors, m·∫°ng n∆°ron nh√¢n t·∫°o, SVM, ‚Ä¶\nH·ªìi quy: Linear Regression, Logistic Regression, ‚Ä¶\nb. H·ªçc kh√¥ng gi√°m s√°t Tr√°i v·ªõi Supervised learning, h·ªçc kh√¥ng gi√°m s√°t hay h·ªçc kh√¥ng th·∫ßy l√† thu·∫≠t to√°n d·ª± ƒëo√°n nh√£n c·ªßa m·ªôt d·ªØ li·ªáu m·ªõi d·ª±a tr√™n t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán m√† trong ƒë√≥ t·∫•t c·∫£ c√°c m·∫´u d·ªØ li·ªáu ƒë·ªÅu ch∆∞a ƒë∆∞·ª£c g√°n nh√£n hay n√≥i c√°ch kh√°c l√† ta kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi ch√≠nh x√°c cho m·ªói d·ªØ li·ªáu ƒë·∫ßu v√†o nh∆∞ minh ho·∫° ·ªü H√¨nh 3. ƒêi·ªÅu n√†y c≈©ng gi·ªëng nh∆∞ khi ta h·ªçc m√† kh√¥ng c√≥ th·∫ßy c√¥, s·∫Ω kh√¥ng ai cho ta bi·∫øt ƒë√°p √°n ƒë√∫ng l√† g√¨.\nH√¨nh 3: Unsupervised Learning Algorithms\nKhi ƒë√≥, m·ª•c ti√™u c·ªßa thu·∫≠t to√°n unsupervised learning kh√¥ng ph·∫£i l√† t√¨m ƒë·∫ßu ra ch√≠nh x√°c m√† s·∫Ω h∆∞·ªõng t·ªõi vi·ªác t√¨m ra c·∫•u tr√∫c ho·∫∑c s·ª± li√™n h·ªá trong d·ªØ li·ªáu ƒë·ªÉ th·ª±c hi·ªán m·ªôt c√¥ng vi·ªác n√†o ƒë√≥, v√≠ nh∆∞ gom c·ª•m (clustering) ho·∫∑c gi·∫£m s·ªë chi·ªÅu c·ªßa d·ªØ li·ªáu (dimension reduction) ƒë·ªÉ thu·∫≠n ti·ªán trong vi·ªác l∆∞u tr·ªØ v√† t√≠nh to√°n.\nC√°c b√†i to√°n Unsupervised learning ti·∫øp t·ª•c ƒë∆∞·ª£c chia nh·ªè th√†nh hai lo·∫°i l√† ph√¢n c·ª•m (Clustering) v√† lu·∫≠t k·∫øt h·ª£p (Association Rule).\nPh√¢n c·ª•m M·ªôt b√†i to√°n ph√¢n c·ª•m / ph√¢n nh√≥m to√†n b·ªô d·ªØ li·ªáu X th√†nh c√°c nh√≥m/c·ª•m nh·ªè d·ª±a tr√™n s·ª± li√™n quan gi·ªØa c√°c d·ªØ li·ªáu trong m·ªói nh√≥m. Ch·∫≥ng h·∫°n nh∆∞ ph√¢n nh√≥m kh√°ch h√†ng d·ª±a v√†o ƒë·ªô tu·ªïi, gi·ªõi t√≠nh. ƒêi·ªÅu n√†y c≈©ng gi·ªëng nh∆∞ vi·ªác ta ƒë∆∞a cho m·ªôt ƒë·ª©a tr·∫ª r·∫•t nhi·ªÅu m·∫£nh gh√©p v·ªõi c√°c h√¨nh d·∫°ng v√† m√†u s·∫Øc kh√°c nhau, c√≥ th·ªÉ l√† tam gi√°c, vu√¥ng, tr√≤n v·ªõi m√†u xanh, ƒë·ªè, t√≠m, v√†ng, sau ƒë√≥ y√™u c·∫ßu tr·∫ª ph√¢n ch√∫ng th√†nh t·ª´ng nh√≥m. M·∫∑c d√π ta kh√¥ng d·∫°y tr·∫ª m·∫£nh n√†o t∆∞∆°ng ·ª©ng v·ªõi h√¨nh n√†o ho·∫∑c m√†u n√†o, nh∆∞ng nhi·ªÅu kh·∫£ nƒÉng tr·∫ª v·∫´n c√≥ th·ªÉ ph√¢n lo·∫°i c√°c m·∫£nh gh√©p theo m√†u s·∫Øc ho·∫∑c h√¨nh d·∫°ng.\nLu·∫≠t k·∫øt h·ª£p L√† b√†i to√°n m√† khi ch√∫ng ta mu·ªën kh√°m ph√° ra m·ªôt quy lu·∫≠t d·ª±a tr√™n nhi·ªÅu d·ªØ li·ªáu cho tr∆∞·ªõc. V√≠ nh∆∞ nh·ªØng kh√°ch h√†ng mua m·∫∑t h√†ng n√†y s·∫Ω mua th√™m m·∫∑t h√†ng kia; ho·∫∑c khan gi·∫£ xem phim n√†y s·∫Ω c√≥ xu h∆∞·ªõng th√≠ch xem phim kia, d·ª±a v√†o ƒë√≥ ta c√≥ th·ªÉ x√¢y d·ª±ng nh·ªØng h·ªá th·ªëng g·ª£i √Ω kh√°ch h√†ng (Recommendation System) nh·∫±m th√∫c ƒë·∫©y nhu c·∫ßu mua s·∫Øm ho·∫∑c xem phim\u0026hellip;.\nM·ªôt s·ªë thu·∫≠t to√°n thu·ªôc nh√≥m h·ªçc kh√¥ng gi√°m s√°t nh∆∞ Apriori (Association Rule), k-Means (Clustering), ‚Ä¶\nc.\tH·ªçc b√°n gi√°m s√°t L√† b√†i to√°n m√† khi t·∫≠p d·ªØ li·ªáu ƒë·∫ßu v√†o X l√† h·ªón h·ª£p c√°c m·∫´u c√≥ nh√£n v√† kh√¥ng c√≥ nh√£n, trong ƒë√≥ s·ªë l∆∞·ª£ng c√≥ nh√£n ch·ªâ chi·∫øm m·ªôt ph·∫ßn nh·ªè nh∆∞ minh ho·∫° ·ªü H√¨nh 4.\nPh·∫ßn l·ªõn c√°c b√†i to√°n th·ª±c t·∫ø c·ªßa ML thu·ªôc nh√≥m n√†y v√¨ vi·ªác thu th·∫≠p d·ªØ li·ªáu c√≥ nh√£n t·ªën r·∫•t nhi·ªÅu th·ªùi gian v√† c√≥ chi ph√≠ cao. R·∫•t nhi·ªÅu lo·∫°i d·ªØ li·ªáu th·∫≠m ch√≠ c·∫ßn ph·∫£i c√≥ chuy√™n gia m·ªõi g√°n nh√£n ƒë∆∞·ª£c, ch·∫≥ng h·∫°n nh∆∞ ·∫£nh y h·ªçc ho·∫∑c c√°c c·∫∑p c√¢u song ng·ªØ. Ng∆∞·ª£c l·∫°i, d·ªØ li·ªáu ch∆∞a c√≥ nh√£n c√≥ th·ªÉ ƒë∆∞·ª£c thu th·∫≠p v·ªõi chi ph√≠ th·∫•p t·ª´ internet.\nH√¨nh 4: Semi-supervised Learning Algorithms\nV·ªõi b√†i to√°n n√†y, m√¥ h√¨nh ph·∫£i t√¨m hi·ªÉu c√°c c·∫•u tr√∫c ƒë·ªÉ t·ªï ch·ª©c d·ªØ li·ªáu c≈©ng nh∆∞ ƒë∆∞a ra d·ª± ƒëo√°n. V√¨ ƒë·∫∑c ƒëi·ªÉm trung gian n√™n ta c√≥ th·ªÉ s·ª≠ d·ª•ng unsupervised learning ƒë·ªÉ kh√°m ph√° v√† t√¨m hi·ªÉu c·∫•u tr√∫c trong d·ªØ li·ªáu ƒë·∫ßu v√†o, ƒë·ªìng th·ªùi s·ª≠ d·ª•ng supervised learning ƒë·ªÉ d·ª± ƒëo√°n cho d·ªØ li·ªáu kh√¥ng ƒë∆∞·ª£c g√°n nh√£n. Sau ƒë√≥ ƒë∆∞a d·ªØ li·ªáu v·ª´a d·ª± ƒëo√°n tr·ªü l·∫°i l√†m d·ªØ li·ªáu hu·∫•n luy·ªán cho supervised learning v√† s·ª≠ d·ª•ng m√¥ h√¨nh sau khi hu·∫•n luy·ªán ƒë·ªÉ ƒë∆∞a ra d·ª± ƒëo√°n v·ªÅ d·ªØ li·ªáu m·ªõi.\nM·ªôt s·ªë thu·∫≠t to√°n h·ªçc tƒÉng c∆∞·ªùng nh∆∞: Self Training, Generative models, S3VMs, Graph-Based Algorithms, Multiview Algorithms, ‚Ä¶\nd.\tH·ªçc tƒÉng c∆∞·ªùng H·ªçc tƒÉng t∆∞·ªùng hay h·ªçc c·ªßng c·ªë l√† b√†i to√°n gi√∫p cho m·ªôt h·ªá th·ªëng t·ª± ƒë·ªông x√°c ƒë·ªãnh h√†nh vi d·ª±a tr√™n ho√†n c·∫£nh ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c l·ª£i √≠ch cao nh·∫•t. Hi·ªán t·∫°i, reinforcement learning ch·ªß y·∫øu ƒë∆∞·ª£c √°p d·ª•ng v√†o L√Ω Thuy·∫øt Tr√≤ Ch∆°i (Game Theory), c√°c thu·∫≠t to√°n c·∫ßn x√°c ƒë·ªãnh n∆∞·ªõc ƒëi ti·∫øp theo ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c ƒëi·ªÉm s·ªë cao nh·∫•t. H√¨nh 5 l√† m·ªôt v√≠ d·ª• ƒë∆°n gi·∫£n s·ª≠ d·ª•ng h·ªçc tƒÉng c∆∞·ªùng.\nH√¨nh 5: Minh ho·∫° cho h·ªçc tƒÉng c∆∞·ªùng ƒë∆∞·ª£c √°p d·ª•ng trong l√Ω thuy·∫øt tr√≤ ch∆°i.\nAlphaGo - m·ªôt ph·∫ßn m·ªÅm ch∆°i c·ªù v√¢y tr√™n m√°y t√≠nh ƒë∆∞·ª£c x√¢y d·ª±ng b·ªüi Google DeepMind hay ch∆∞∆°ng tr√¨nh d·∫°y m√°y t√≠nh ch∆°i game Mario l√† nh·ªØng ·ª©ng d·ª•ng s·ª≠ d·ª•ng h·ªçc tƒÉng c∆∞·ªùng.\nC·ªù v·∫≠y ƒë∆∞·ª£c xem l√† tr√≤ ch∆°i c√≥ ƒë·ªô ph·ª©c t·∫°p c·ª±c k·ª≥ cao v·ªõi t·ªïng s·ªë n∆∞·ªõc ƒëi l√† x·∫•p x·ªâ 1076110761, so v·ªõi c·ªù vua l√† 1012010120, v√¨ v·∫≠y thu·∫≠t to√°n ph·∫£i ch·ªçn ra m·ªôt n∆∞·ªõc ƒëi t·ªëi ∆∞u trong s·ªë h√†ng t·ªâ t·ªâ l·ª±a ch·ªçn. V·ªÅ c∆° b·∫£n, AlphaGo bao g·ªìm c√°c thu·∫≠t to√°n thu·ªôc c·∫£ Supervised learning v√† Reinforcement learning. Trong ph·∫ßn Supervised learning, d·ªØ li·ªáu t·ª´ c√°c v√°n c·ªù do con ng∆∞·ªùi ch∆°i v·ªõi nhau ƒë∆∞·ª£c ƒë∆∞a v√†o ƒë·ªÉ hu·∫•n luy·ªán. Tuy nhi√™n, m·ª•c ti√™u cu·ªëi c√πng c·ªßa AlphaGo kh√¥ng ph·∫£i l√† ch∆°i nh∆∞ con ng∆∞·ªùi m√† ph·∫£i th·∫Øng ƒë∆∞·ª£c con ng∆∞·ªùi. V√¨ v·∫≠y, sau khi h·ªçc xong c√°c v√°n c·ªù c·ªßa con ng∆∞·ªùi, AlphaGo t·ª± ch∆°i v·ªõi ch√≠nh n√≥ th√¥ng qua h√†ng tri·ªáu v√°n c·ªù ƒë·ªÉ t√¨m ra c√°c n∆∞·ªõc ƒëi m·ªõi t·ªëi ∆∞u h∆°n. Thu·∫≠t to√°n trong ph·∫ßn t·ª± ch∆°i n√†y ƒë∆∞·ª£c x·∫øp v√†o lo·∫°i Reinforcement learning.\nƒê∆°n gi·∫£n h∆°n c·ªù v√¢y, t·∫°i m·ªôt th·ªùi ƒëi·ªÉm c·ª• th·ªÉ, ng∆∞·ªùi ch∆°i game Mario ch·ªâ c·∫ßn b·∫•m m·ªôt s·ªë l∆∞·ª£ng nh·ªè c√°c n√∫t (di chuy·ªÉn, nh·∫£y, b·∫Øn ƒë·∫°n) ho·∫∑c kh√¥ng c·∫ßn b·∫•m n√∫t n√†o ·ª©ng v·ªõi m·ªôt ch∆∞·ªõng ng·∫°i v·∫≠t c·ªë ƒë·ªãnh ·ªü m·ªôt v·ªã tr√≠ c·ªë ƒë·ªãnh. Khi ƒë√≥ thu·∫≠t to√°n trong ·ª©ng d·ª•ng d·∫°y m√°y t√≠nh ch∆°i game Mario s·∫Ω nh·∫≠n ƒë·∫ßu v√†o l√† s∆° ƒë·ªì c·ªßa m√†n h√¨nh t·∫°i th·ªùi ƒëi·ªÉm hi·ªán h√†nh, nhi·ªám v·ª• c·ªßa thu·∫≠t to√°n l√† t√¨m ra t·ªï h·ª£p ph√≠m n√™n ƒë∆∞·ª£c b·∫•m ·ª©ng v·ªõi ƒë·∫ßu v√†o ƒë√≥. Vi·ªác hu·∫•n luy·ªán n√†y ƒë∆∞·ª£c d·ª±a tr√™n ƒëi·ªÉm s·ªë cho vi·ªác di chuy·ªÉn ƒë∆∞·ª£c bao xa v·ªõi th·ªùi gian bao l√¢u trong game, c√†ng xa v√† c√†ng nhanh th√¨ ƒëi·ªÉm th∆∞·ªüng ƒë·∫°t ƒë∆∞·ª£c c√†ng cao, t·∫•t nhi√™n ƒëi·ªÉm th∆∞·ªüng n√†y kh√¥ng ph·∫£i l√† ƒëi·ªÉm c·ªßa tr√≤ ch∆°i m√† l√† ƒëi·ªÉm do ch√≠nh ng∆∞·ªùi l·∫≠p tr√¨nh t·∫°o ra. Th√¥ng qua hu·∫•n luy·ªán, thu·∫≠t to√°n s·∫Ω t√¨m ra m·ªôt c√°ch t·ªëi ∆∞u ƒë·ªÉ t·ªëi ƒëa s·ªë ƒëi·ªÉm tr√™n, qua ƒë√≥ ƒë·∫°t ƒë∆∞·ª£c m·ª•c ƒë√≠ch cu·ªëi c√πng l√† c·ª©u c√¥ng ch√∫a.\nC√≥ nhi·ªÅu c√°ch kh√°c nhau ƒë·ªÉ thu·∫≠t to√°n c√≥ th·ªÉ m√¥ h√¨nh h√≥a m·ªôt v·∫•n ƒë·ªÅ d·ª±a tr√™n s·ª± t∆∞∆°ng t√°c c·ªßa n√≥ v·ªõi d·ªØ li·ªáu ƒë·∫ßu v√†o. Ph√¢n lo·∫°i ho·∫∑c c√°ch t·ªï ch·ª©c thu·∫≠t to√°n h·ªçc m√°y n√†y r·∫•t h·ªØu √≠ch v√¨ n√≥ bu·ªôc ch√∫ng ta ph·∫£i suy nghƒ© v·ªÅ vai tr√≤ c·ªßa d·ªØ li·ªáu ƒë·∫ßu v√†o v√† quy tr√¨nh chu·∫©n b·ªã m√¥ h√¨nh v√† ch·ªçn m·ªôt thu·∫≠t to√°n ph√π h·ª£p nh·∫•t cho v·∫•n ƒë·ªÅ c·ªßa ch√∫ng ta ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t.\n2.\tPh√¢n nh√≥m d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng D·ª±a v√†o s·ª± t∆∞∆°ng ƒë·ªìng v·ªÅ ch·ª©c nƒÉng hay c√°ch th·ª©c ho·∫°t ƒë·ªông m√† c√°c thu·∫≠t to√°n s·∫Ω ƒë∆∞·ª£c gom nh√≥m v·ªõi nhau. Sau ƒë√¢y l√† danh s√°ch c√°c nh√≥m v√† c√°c thu·∫≠t to√°n theo t·ª´ng nh√≥m.\na.\tC√°c thu·∫≠t to√°n h·ªìi quy (Regression Algorithms) H·ªìi quy l√† qu√° tr√¨nh t√¨m m·ªëi quan h·ªá ph·ª• thu·ªôc c·ªßa m·ªôt bi·∫øn (ƒë∆∞·ª£c g·ªçi l√† bi·∫øn ph·ª• thu·ªôc hay bi·∫øn ƒë∆∞·ª£c gi·∫£i th√≠ch, bi·∫øn ƒë∆∞·ª£c d·ª± b√°o, bi·∫øn ƒë∆∞·ª£c h·ªìi quy, bi·∫øn ph·∫£n ·ª©ng, bi·∫øn n·ªôi sinh) v√†o m·ªôt ho·∫∑c nhi·ªÅu bi·∫øn kh√°c (ƒë∆∞·ª£c g·ªçi l√† bi·∫øn ƒë·ªôc l·∫≠p, bi·∫øn gi·∫£i th√≠ch, bi·∫øn d·ª± b√°o, bi·∫øn h·ªìi quy, bi·∫øn t√°c nh√¢n hay bi·∫øn ki·ªÉm so√°t, bi·∫øn ngo·∫°i sinh) nh·∫±m m·ª•c ƒë√≠ch ∆∞·ªõc l∆∞·ª£ng ho·∫∑c ti√™n ƒëo√°n gi√° tr·ªã k·ª≥ v·ªçng c·ªßa bi·∫øn ph·ª• thu·ªôc khi bi·∫øt tr∆∞·ªõc gi√° tr·ªã c·ªßa bi·∫øn ƒë·ªôc l·∫≠p. H√¨nh 6 t∆∞·ª£ng tr∆∞ng cho √Ω t∆∞·ªüng c·ªßa c√°c thu·∫≠t to√°n h·ªìi quy.\nV√≠ d·ª• nh∆∞, d·ª± ƒëo√°n r·∫±ng n·∫øu tƒÉng l√£i su·∫•t ti·ªÅn g·ª≠i th√¨ s·∫Ω huy ƒë·ªông ƒë∆∞·ª£c l∆∞·ª£ng ti·ªÅn g·ª≠i nhi·ªÅu h∆°n, khi ƒë√≥ ng√¢n h√†ng A c·∫ßn bi·∫øt m·ªëi quan h·ªá gi·ªØa l∆∞·ª£ng ti·ªÅn g·ª≠i v√† l√£i su·∫•t ti·ªÅn g·ª≠i, c·ª• th·ªÉ h∆°n h·ªç mu·ªën bi·∫øt khi tƒÉng l√£i su·∫•t th√™m 0.1% th√¨ l∆∞·ª£ng ti·ªÅn g·ª≠i s·∫Ω tƒÉng trung b√¨nh l√† bao nhi√™u.\nC√°c thu·∫≠t to√°n h·ªìi quy ph·ªï bi·∫øn nh·∫•t l√†:\nLinear Regression\nLogistic Regression\nLocally Estimated Scatterplot Smoothing (LOESS)\nMultivariate Adaptive Regression Splines (MARS)\nOrdinary Least Squares Regression (OLSR)\nStepwise Regression\nH√¨nh 6: Regression Algorithms\nb.\tThu·∫≠t to√°n d·ª±a tr√™n m·∫´u (Instance-based Algorithms) M√¥ h√¨nh h·ªçc t·∫≠p d·ª±a tr√™n m·∫´u hay th·ª±c th·ªÉ l√† b√†i to√°n ra quy·∫øt ƒë·ªãnh d·ª±a v√†o c√°c tr∆∞·ªùng h·ª£p ho·∫∑c c√°c m·∫´u d·ªØ li·ªáu hu·∫•n luy·ªán ƒë∆∞·ª£c coi l√† quan tr·ªçng hay b·∫Øt bu·ªôc ƒë·ªëi v·ªõi m√¥ h√¨nh.\nNh√≥m thu·∫≠t to√°n n√†y th∆∞·ªùng x√¢y d·ª±ng c∆° s·ªü d·ªØ li·ªáu v·ªÅ d·ªØ li·ªáu m·∫´u v√† so s√°nh d·ªØ li·ªáu m·ªõi v·ªõi c∆° s·ªü d·ªØ li·ªáu b·∫±ng c√°ch s·ª≠ d·ª•ng th∆∞·ªõc ƒëo t∆∞∆°ng t·ª± ƒë·ªÉ t√¨m k·∫øt qu·∫£ ph√π h·ª£p nh·∫•t v√† ƒë∆∞a ra d·ª± ƒëo√°n. Khi ƒë√≥ tr·ªçng t√¢m ƒë∆∞·ª£c ƒë·∫∑t v√†o ƒë·∫°i di·ªán c·ªßa c√°c th·ªÉ hi·ªán ƒë∆∞·ª£c l∆∞u tr·ªØ nh∆∞ minh ho·∫° ·ªü H√¨nh 7.\nH√¨nh 7: Instance-based Algorithms\nC√°c thu·∫≠t to√°n d·ª±a tr√™n th·ª±c th·ªÉ ph·ªï bi·∫øn nh·∫•t l√†:\nk-Nearest Neighbor (kNN ‚Äì k l√°ng gi·ªÅng g·∫ßn nh·∫•t)\nLearning Vector Quantization (LVQ)\nLocally Weighted Learning (LWL)\nSelf-Organizing Map (SOM)\nc.\tThu·∫≠t to√°n chu·∫©n ho√° (Regularization Algorithms) C√°c thu·∫≠t to√°n chu·∫©n ho√° ra ƒë·ªùi t·ª´ s·ª± m·ªü r·ªông c√°c ph∆∞∆°ng ph√°p ƒë√£ c√≥ (ƒëi·ªÉn h√¨nh l√† c√°c ph∆∞∆°ng ph√°p h·ªìi quy) b·∫±ng c√°ch x·ª≠ ph·∫°t c√°c m√¥ h√¨nh d·ª±a tr√™n m·ª©c ƒë·ªô ph·ª©c t·∫°p c·ªßa ch√∫ng. Vi·ªác ∆∞u ti√™n c√°c m√¥ h√¨nh ƒë∆°n gi·∫£n h∆°n c≈©ng t·ªët h∆°n trong vi·ªác kh√°i qu√°t h√≥a. H√¨nh 8 t∆∞·ª£ng tr∆∞ng cho √Ω t∆∞·ªüng c·ªßa thu·∫≠t to√°n chu·∫©n ho√°.\nH√¨nh 8: Regularization Algorithms\nC√°c thu·∫≠t to√°n ch√≠nh quy ph·ªï bi·∫øn nh·∫•t l√†:\nElastic Net\nLeast Absolute Shrinkage and Selection Operator (LASSO)\nLeast-Angle Regression (LARS)\nRidge Regression\nd.\tThu·∫≠t to√°n c√¢y quy·∫øt ƒë·ªãnh (Decision Tree Algorithms) ƒê√¢y l√† ph∆∞∆°ng ph√°p x√¢y d·ª±ng m√¥ h√¨nh ra quy·∫øt ƒë·ªãnh d·ª±a tr√™n c√°c gi√° tr·ªã th·ª±c c·ªßa nh·ªØng thu·ªôc t√≠nh trong d·ªØ li·ªáu. S·ª± quy·∫øt ƒë·ªãnh ƒë∆∞·ª£c r·∫Ω nh√°nh trong c·∫•u tr√∫c c√¢y cho ƒë·∫øn khi quy·∫øt ƒë·ªãnh d·ª± ƒëo√°n ƒë∆∞·ª£c ƒë∆∞a ra cho m·ªôt m·∫´u nh·∫•t ƒë·ªãnh nh∆∞ minh ho·∫° ·ªü H√¨nh 9. Ph∆∞∆°ng ph√°p n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng trong vi·ªác hu·∫•n luy·ªán d·ªØ li·ªáu cho b√†i to√°n ph√¢n l·ªõp v√† h·ªìi quy. V√¨ s·ª± nhanh ch√≥ng, ch√≠nh x√°c n√™n ph∆∞∆°ng ph√°p n√†y r·∫•t ƒë∆∞·ª£c ∆∞a chu·ªông trong ML.\nH√¨nh 9: Decision Tree Algorithms\nC√°c thu·∫≠t to√°n c√¢y quy·∫øt ƒë·ªãnh ph·ªï bi·∫øn nh·∫•t bao g·ªìm:\nChi-squared Automatic Interaction Detection (CHAID)\nClassification v√† Regression Tree ‚Äì CART\nConditional Decision Trees\nC4.5 v√† C5.0\nDecision Stump\nIterative Dichotomiser 3 (ID3)\nM5\ne.\tThu·∫≠t to√°n Bayes (Bayesian Algorithms) ƒê√¢y l√† nh√≥m c√°c thu·∫≠t to√°n √°p d·ª•ng ƒê·ªãnh l√Ω Bayes cho b√†i to√°n ph√¢n lo·∫°i v√† h·ªìi quy.\nH√¨nh 10: Bayesian Algorithms\nC√°c thu·∫≠t to√°n ph·ªï bi·∫øn nh·∫•t l√†:\nAveraged One-Dependence Estimators (AODE)\nBayesian Belief Network (BBN)\nBayesian Network (BN)\nGaussian Naive Bayes\nMultinomial Naive Bayes\nNaive Bayes\nf.\tThu·∫≠t to√°n ph√¢n c·ª•m (Clustering Algorithms) T·∫•t c·∫£ c√°c ph∆∞∆°ng ph√°p ƒë·ªÅu s·ª≠ d·ª•ng c√°c c·∫•u tr√∫c v·ªën c√≥ trong d·ªØ li·ªáu ƒë·ªÉ t·ªï ch·ª©c t·ªët nh·∫•t d·ªØ li·ªáu th√†nh c√°c nh√≥m c√≥ m·ª©c ƒë·ªô ph·ªï bi·∫øn t·ªëi ƒëa d·ª±a v√†o tr·ªçng t√¢m (centroid) v√† th·ª© b·∫≠c (hierarchal) nh∆∞ th·ªÉ hi·ªán ·ªü H√¨nh 11.\nH√¨nh 11: Clustering Algorithms\nC√°c thu·∫≠t to√°n ph√¢n c·ª•m ph·ªï bi·∫øn nh·∫•t l√†:\nExpectation Maximisation (EM ‚Äì c·ª±c ƒë·∫°i ho√° k·ª≥ v·ªçng)\nHierarchical Clustering\nk-Means\nk-Medians\ng.\tC√°c thu·∫≠t to√°n lu·∫≠t k·∫øt h·ª£p (Association Rule Learning Algorithms) ƒê√¢y l√† nh·ªØng thu·∫≠t to√°n s·∫Ω r√∫t tr√≠ch ra c√°c quy t·∫Øc gi·∫£i th√≠ch t·ªët nh·∫•t m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn trong d·ªØ li·ªáu. C√°c quy t·∫Øc n√†y c√≥ th·ªÉ gi√∫p kh√°m ph√° ra c√°c t√≠nh ch·∫•t quan tr·ªçng v√† h·ªØu √≠ch trong c√°c t·∫≠p d·ªØ li·ªáu l·ªõn v√† cao chi·ªÅu trong th∆∞∆°ng m·∫°i c√πng c√°c lƒ©nh v·ª±c kh√°c. H√¨nh 12 minh ho·∫° cho √Ω t∆∞·ªüng c·ªßa thu·∫≠t to√°n lu·∫≠t k·∫øt h·ª£p.\nH√¨nh 12: Association Rule Learning Algorithms\nC√°c thu·∫≠t to√°n lu·∫≠t k·∫øt h·ª£p ph·ªï bi·∫øn nh·∫•t l√†:\nApriori algorithm\nEclat algorithm\nFP-Growth algorithm\nh.\tThu·∫≠t to√°n m·∫°ng n∆°ron nh√¢n t·∫°o (Artificial Neural Network Algorithms) M·∫°ng n∆°ron nh√¢n t·∫°o l√† c√°c m√¥ h√¨nh ƒë∆∞·ª£c l·∫•y c·∫£m h·ª©ng t·ª´ c·∫•u tr√∫c v√† ch·ª©c nƒÉng c·ªßa m·∫°ng l∆∞·ªõi th·∫ßn kinh sinh h·ªçc. H√¨nh 13 minh ho·∫° cho m·ªôt m·∫°ng truy·ªÅn th·∫≥ng. Nh√≥m thu·∫≠t to√°n n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng cho b√†i to√°n ph√¢n l·ªõp v√† h·ªìi quy v·ªõi r·∫•t nhi·ªÅu bi·∫øn th·ªÉ kh√°c nhau cho h·∫ßu h·∫øt c√°c v·∫•n ƒë·ªÅ. Tuy nhi√™n, trong b√†i vi·∫øt n√†y m√¨nh ch·ªâ tr√¨nh b√†y c√°c thu·∫≠t to√°n c·ªï ƒëi·ªÉn v√† ph·ªï bi·∫øn nh·∫•t:\nBack-Propagation (m·∫°ng lan truy·ªÅn ng∆∞·ª£c)\nPerceptron (M·∫°ng lan truy·ªÅn th·∫≥ng)\nMulti-layer perceptron (M·∫°ng truy·ªÅn th·∫≥ng ƒëa l·ªõp)\nHopfield Network\nRadial Basis Function Network (RBFN)\nH√¨nh 13: Artificial Neural Network Algorithms\ni.\tThu·∫≠t to√°n h·ªçc s√¢u (Deep Learning Algorithms) Th·ª±c ch·∫•t Deep Learning l√† m·ªôt b·∫£n c·∫≠p nh·∫≠t hi·ªán ƒë·∫°i cho Artificial Neural Networks nh·∫±m khai th√°c kh·∫£ nƒÉng t√≠nh to√°n c·ªßa m√°y t√≠nh, tuy nhi√™n v√¨ s·ª± ph√°t tri·ªÉn l·ªõn m·∫°nh c·ªßa ch√∫ng n√™n m√¨nh t√°ch ra th√†nh m·ªôt nh√≥m ri√™ng.\nDeep Learning quan t√¢m ƒë·∫øn vi·ªác x√¢y d·ª±ng c√°c m·∫°ng th·∫ßn kinh l·ªõn h∆°n, ph·ª©c t·∫°p h∆°n nhi·ªÅu, v√† l√†m sao ƒë·ªÉ khai th√°c hi·ªáu qu·∫£ c√°c b·ªô d·ªØ li·ªáu l·ªõn ch·ª©a r·∫•t √≠t d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c g√°n nh√£n. H√¨nh 14 minh ho·∫° cho √Ω t∆∞·ªüng c·ªßa Deep learning.\nH√¨nh 14: Deep Learning Algorithms\nC√°c thu·∫≠t to√°n h·ªçc s√¢u ph·ªï bi·∫øn nh·∫•t l√†:\nConvolutional Neural Network (CNN)\nDeep Belief Networks (DBN)\nDeep Boltzmann Machine (DBM)\nStacked Auto-Encoders\nj.\tNh√≥m thu·∫≠t to√°n Gi·∫£m chi·ªÅu d·ªØ li·ªáu (Dimensionality Reduction Algorithms) Gi·ªëng nh∆∞ c√°c ph∆∞∆°ng ph√°p ph√¢n c·ª•m, gi·∫£m kh√¥ng gian t√¨m ki·∫øm v√† khai th√°c c·∫•u tr√∫c v·ªën c√≥ trong d·ªØ li·ªáu nh∆∞ng theo c√°ch kh√¥ng gi√°m s√°t ho·∫∑c ƒë·ªÉ t√≥m t·∫Øt hay m√¥ t·∫£ d·ªØ li·ªáu s·ª≠ d·ª•ng √≠t th√¥ng tin h∆°n l√† m·ª•c ti√™u c·ªßa nh√≥m ph∆∞∆°ng ph√°p n√†y. H√¨nh 15 minh ho·∫° cho vi·ªác gi·∫£m chi·ªÅu d·ªØ li·ªáu.\nƒêi·ªÅu n√†y c√≥ th·ªÉ h·ªØu √≠ch ƒë·ªÉ tr·ª±c quan h√≥a d·ªØ li·ªáu ho·∫∑c ƒë∆°n gi·∫£n h√≥a d·ªØ li·ªáu m√† sau ƒë√≥ c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong ph∆∞∆°ng ph√°p h·ªçc c√≥ gi√°m s√°t. Nhi·ªÅu trong s·ªë c√°c ph∆∞∆°ng ph√°p n√†y c√≥ th·ªÉ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh ƒë·ªÉ s·ª≠ d·ª•ng trong ph√¢n l·ªõp v√† h·ªìi quy.\nH√¨nh 15: Dimensional Reduction Algorithms\nC√°c thu·∫≠t to√°n Gi·∫£m chi·ªÅu d·ªØ li·ªáu ph·ªï bi·∫øn nh∆∞:\nFlexible Discriminant Analysis (FDA)\nLinear Discriminant Analysis (LDA)\nMixture Discriminant Analysis (MDA)\nMultidimensional Scaling (MDS)\nPartial Least Squares Regression (PLSR)\nPrincipal Component Analysis (PCA)\nPrincipal Component Regression (PCR)\nProjection Pursuit\nQuadratic Discriminant Analysis (QDA)\nSammon Mapping\nk.\tThu·∫≠t to√°n t·∫≠p h·ª£p (Ensemble Algorithms) Ensemble methods l√† nh·ªØng ph∆∞∆°ng ph√°p k·∫øt h·ª£p c√°c m√¥ h√¨nh y·∫øu h∆°n ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªôc l·∫≠p v√† ph·∫ßn d·ª± ƒëo√°n c·ªßa ch√∫ng s·∫Ω ƒë∆∞·ª£c k·∫øt h·ª£p theo m·ªôt c√°ch n√†o ƒë√≥ ƒë·ªÉ ƒë∆∞a ra d·ª± ƒëo√°n t·ªïng th·ªÉ nh∆∞ minh h·ªça ·ªü H√¨nh 16.\nNh√≥m thu·∫≠t to√°n n√†y kh√° m·∫°nh v√† ƒë∆∞·ª£c nghi√™n c·ª©u nhi·ªÅu, ƒë·∫∑c bi·ªát l√† v·ªÅ c√°ch ƒë·ªÉ k·∫øt h·ª£p c√°c m√¥ h√¨nh v·ªõi nhau.\nH√¨nh 16: Ensemble Algorithms\nM·ªôt s·ªë thu·∫≠t to√°n ph·ªï bi·∫øn nh∆∞:\nAdaBoost\nBoosting\nBootstrapped Aggregation (Bagging)\nGradient Boosting Machines (GBM)\nGradient Boosted Regression Trees (GBRT)\nRandom Forest\nStacked Generalization (blending)\nl.\tC√°c thu·∫≠t to√°n kh√°c C√≤n r·∫•t nhi·ªÅu c√°c thu·∫≠t to√°n kh√°c kh√¥ng ƒë∆∞·ª£c li·ªát k√™ ·ªü ƒë√¢y, ch·∫≥ng h·∫°n nh∆∞ Support Vector Machines (SVM), m√¨nh ƒëang ph√¢n v√¢n r·∫±ng li·ªáu thu·∫≠t to√°n n√†y n√™n ƒë∆∞·ª£c ƒë∆∞a v√†o nh√≥m n√†o ƒë√≥ hay ƒë·ª©ng m·ªôt m√¨nh. N·∫øu d·ª±a v√†o danh s√°ch c√°c bi·∫øn th·ªÉ v√† m·ª©c ƒë·ªô ph√°t tri·ªÉn th√¨ SVM c√≥ th·ªÉ ƒë∆∞·ª£c t√°ch th√†nh m·ªôt nh√≥m ri√™ng ‚Äì nh√≥m thu·∫≠t to√°n s·ª≠ d·ª•ng v√©ct∆° h·ªó tr·ª£.\nTh√™m v√†o ƒë√≥, c√°c thu·∫≠t to√°n ƒë∆∞·ª£c h√¨nh th√†nh t·ª´ c√°c nhi·ªám v·ª• ƒë·∫∑c bi·ªát, hoƒÉc c√°c thu·∫≠t to√°n t·ª´ nh·ªØng nh√°nh con ƒë·∫∑c bi·ªát c·ªßa ML c≈©ng kh√¥ng ƒë∆∞·ª£c li·ªát k√™ v√†o c√°c nh√≥m, ch·∫≥ng h·∫°n nh∆∞:\nFeature selection algorithms\nAlgorithm accuracy evaluation\nPerformance measures\nC√≥ d·ªãp m√¨nh s·∫Ω b·ªï sung ho·∫∑c ƒë·ªÅ c·∫≠p ƒë·∫øn nh·ªØng thu·∫≠t to√°n n√†y ·ªü m·ªôt b√†i vi·∫øt kh√°c.\nM·∫∑c d√π r·∫•t h·ªØu √≠ch (d·ª±a v√†o nh√≥m, ng∆∞·ªùi d√πng s·∫Ω d·ªÖ d√†ng nh·ªõ ƒë∆∞·ª£c b·∫£n ch·∫•t c·ªßa thu·∫≠t to√°n) nh∆∞ng ph∆∞∆°ng ph√°p ph√¢n nh√≥m n√†y ch∆∞a ho√†n h·∫£o ·ªü ƒëi·ªÉm c√≥ nh·ªØng thu·∫≠t to√°n c√≥ th·ªÉ ph√π h·ª£p v·ªõi nhi·ªÅu danh m·ª•c nh∆∞ Learning Vector Quantization, v·ª´a l√† ph∆∞∆°ng ph√°p l·∫•y c·∫£m h·ª©ng t·ª´ m·∫°ng th·∫ßn kinh (neural network), v·ª´a l√† ph∆∞∆°ng ph√°p d·ª±a tr√™n c√° th·ªÉ (instance-based). Ho·∫∑c l√† thu·∫≠t to√°n c√≥ c√πng t√™n m√¥ t·∫£ b√†i to√°n v√† nh√≥m thu·∫≠t to√°n nh∆∞ H·ªìi quy (Regression) v√† Ph√¢n c·ª•m (Clustering). ƒê·ªëi v·ªõi nh·ªØng tr∆∞·ªùng h·ª£p n√†y ta c√≥ th·ªÉ gi·∫£i quy·∫øt b·∫±ng c√°ch li·ªát k√™ c√°c thu·∫≠t to√°n hai l·∫ßn ho·∫∑c b·∫±ng c√°ch ch·ªçn nh√≥m m·ªôt c√°ch ch·ªß quan. ƒê·ªÉ tr√°nh tr√πng l·∫∑p c√°c thu·∫≠t to√°n v√† gi·ªØ cho m·ªçi th·ª© ƒë∆°n gi·∫£n th√¨ c√≥ l·∫Ω ch·ªçn nh√≥m theo c√°ch ch·ªß quan s·∫Ω ph√π h·ª£p h∆°n.\nƒê·ªÉ gi√∫p c√°c b·∫°n d·ªÖ nh·ªõ c≈©ng nh∆∞ t·ªïng k·∫øt cho ph·∫ßn n√†y m√¨nh ƒë√£ v·∫Ω m·ªôt s∆° ƒë·ªì c√°c thu·∫≠t to√°n ph√¢n theo nh√≥m v√† s·∫Øp x·∫øp theo alphabet, c√°c b·∫°n c√≥ th·ªÉ xem th·ªÉm ·ªü H√¨nh 17 b√™n d∆∞·ªõi.\nH√¨nh 17: S∆° ƒë·ªì ph√¢n nh√≥m thu·∫≠t to√°n theo s·ª± t∆∞∆°ng ƒë·ªìng\nHy v·ªçng b√†i vi·∫øt n√†y s·∫Ω mang l·∫°i h·ªØu √≠ch cho b·∫°n ƒë·ªçc, nh·∫•t l√† gi√∫p b·∫°n c√≥ d∆∞·ª£c c√°i nh√¨n t·ªïng quan v·ªÅ nh·ªØng g√¨ hi·ªán c√≥ v√† m·ªôt s·ªë √Ω t∆∞·ªüng v·ªÅ c√°ch li√™n k·∫øt c√°c thu·∫≠t to√°n v·ªõi nhau.\nDanh s√°ch c√°c nh√≥m v√† thu·∫≠t to√°n ƒë∆∞·ª£c li·ªát k√™ trong b√†i vi·∫øt ch·ªâ ƒë·∫£m b·∫£o ƒë∆∞·ª£c y·∫øu t·ªë ph·ªï bi·∫øn tuy nhi√™n s·∫Ω kh√¥ng ƒë·∫ßy ƒë·ªß. V·∫≠y n√™n n·∫øu b·∫°n bi·∫øt th√™m thu·∫≠t to√°n ho·∫∑c nh√≥m n√†o ch∆∞a ƒë∆∞·ª£c li·ªát k√™ ·ªü ƒë√¢y ho·∫∑c k·ªÉ c·∫£ c√°ch ph√¢n nh√≥m thu·∫≠t to√°n kh√°c, c≈©ng nh∆∞ sau khi ƒë·ªçc m√† c√°c b·∫°n c√≥ b·∫•t k·ª≥ g√≥p √Ω, c√¢u h·ªèi gi√∫p c·∫£i thi·ªán b√†i vi·∫øt t·ªët h∆°n, c√°c b·∫°n c√≥ th·ªÉ ƒë·ªÉ l·∫°i b√¨nh lu·∫≠n nh·∫±m chia s·∫ª c√πng m√¨nh v√† nh·ªØng b·∫°n ƒë·ªçc kh√°c nh√©.\nT√†i li·ªáu tham kh·∫£o: A Tour of Machine Learning Algorithms by Jason Brownlee in Understand Machine Learning Algorithms\nSemi-Supervised Learning Tutorial by Xiaojin Zhu\nhttps://en.wikipedia.org/wiki/Outline_of_machine_learning#Machine_learning_algorithms\nTop 10 algorithms in data mining by Xindong Wu ¬∑ Vipin Kumar ¬∑ J. Ross Quinlan ¬∑ Joydeep Ghosh ¬∑ Qiang Yang ¬∑ Hiroshi Motoda ¬∑ Geoffrey J. McLachlan ¬∑ Angus Ng ¬∑ Bing Liu ¬∑ Philip S. Yu ¬∑ Zhi-Hua Zhou ¬∑ Michael Steinbach ¬∑ David J. Hand ¬∑ Dan Steinberg.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü nh·ªØng b√†i vi·∫øt ti·∫øp theo.\n","date":"Apr 19, 2019","img":"","permalink":"/blog/2019-04-19-deep-learning-view/","series":null,"tags":["machine learning","deep learning","h·ªçc c√≥ gi√°m s√°t","h·ªçc kh√¥ng gi√°m s√°t","h·ªçc tƒÉng c∆∞·ªùng"],"title":"Ph√¢n Nh√≥m C√°c Thu·∫≠t To√°n H·ªçc M√°y"},{"categories":null,"content":" Nghi√™n c·ª©u d·ªØ li·ªáu Ph√¢n t√≠ch d·ªØ li·ªáu L√†m s·∫°ch d·ªØ li·ªáu X·ª≠ l√Ω missing values T·∫°o ƒë·∫∑c tr∆∞ng Hu·∫•n luy·ªán m√¥ h√¨nh Nghi√™n c·ª©u d·ªØ li·ªáu Trong th·ª±c t·∫ø, Walmart ƒë√£ ch·∫°y c√°c ch∆∞∆°ng tr√¨nh khuy·∫øn m√£i trong c√°c ng√†y l·ªÖ l·ªõn trong nƒÉm. C√≥ 4 ng√†y l·ªÖ l·ªõn ƒë√≥ l√† Si√™u c√∫p b√≥ng b·∫ßu d·ª•c M·ªπ (Super Bowl - t·ªï ch·ª©c v√†o ch·ªß nh·∫≠t ƒë·∫ßu ti√™n c·ªßa th√°ng Hai. ƒê√¢y l√† m·ªôt s·ª± ki·ªán th·ªÉ thao l·ªõn v√† ng√†y t·ªï ch·ª©c Super Bowl ƒë∆∞·ª£c ng∆∞·ªùi M·ªπ coi l√† ng√†y l·ªÖ qu·ªëc gia c·ªßa Hoa K·ª≥ (theo wiki https://vi.wikipedia.org/wiki/Super_Bowl)), ng√†y l·ªÖ lao ƒë·ªông (Labor Day - ng√†y m·ªôt th√°ng 5), l·ªÖ t·∫° ∆°n (Thanksgiving, ng√†y l·ªÖ t·∫° ∆°n ·ªü M·ªπ ƒë∆∞·ª£c t·ªï ch·ª©c v√†o ng√†y th·ª© NƒÉm l·∫ßn th·ª© t∆∞ c·ªßa th√°ng 11, c√≤n ·ªü Canada ng√†y l·ªÖ t·∫° ∆°n ƒë∆∞·ª£c t·ªï ch·ª©c v√†o ng√†y th·ª© hai l·∫ßn th·ª© hai c·ªßa th√°ng 10, theo wiki https://en.wikipedia.org/wiki/Thanksgiving), l·ªÖ gi√°ng sinh (Christmas ng√†y 24 v√† 25 th√°ng 12 theo wiki https://en.wikipedia.org/wiki/Christmas ). Nh·ªØng tu·∫ßn c√≥ ch·ª©a nh·ªØng ng√†y l·ªÖ l·ªõn n√†y ƒë∆∞·ª£c ƒë√°nh tr·ªçng s·ªë g·∫•p 5 l·∫ßn nh·ªØng tu·∫ßn kh√°c. Ch√∫ng ta ph·∫£i x√¢y d·ª±ng m√¥ h√¨nh ƒë·ªÉ m√¥ h√¨nh ho√° c√°c t√°c ƒë·ªông c·ªßa vi·ªác gi·∫£m gi√° trong c√°c tu·∫ßn l·ªÖ n√†y khi kh√¥ng c√≥ d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·∫ßy ƒë·ªß.\nT·∫≠p d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p bao g·ªìm:\nT·∫≠p train: ch·ª©a d·ªØ li·ªáu s·ªë b√°n t·ª´ 05-02-2010 ƒë·∫øn 01-11-2012. C√°c tr∆∞·ªùng d·ªØ li·ªáu l√†: store number - m√£ c·ª≠a h√†ng, Dept number - m√£ s·∫£n ph·∫©m, Date - Tu·∫ßn, Weekly_Sales - s·ªë b√°n, IsHoliday - N·∫øu tu·∫ßn ƒë√≥ c√≥ ch·ª©a c√°c holidate th√¨ ƒë√°nh 1 ng∆∞·ª£c l·∫°i ƒë√°nh 0.\nT·∫≠p test: Ch·ª©a d·ªØ li·ªáu test, c√≥ c√°c c·ªôt thu·ªôc t√≠nh nh∆∞ t·∫≠p train\nT·∫≠p features: Ch·ª©a th√¥ng tin th√™m v·ªÅ c·ªßa h√†ng, bao g·ªìm store - m√£ c·ª≠a h√†ng, Date - ng√†y, Temperature - Nhi·ªát ƒë·ªô, Fuel_Price - gi√° d·∫ßu (·ªü m·ªπ, m·ªói khu v·ª±c kh√°c nhau s·∫Ω c√≥ gi√° nhi√™n li·ªáu kh√°c nhau), MarkDown1, MarkDown2,\u0026hellip; , MarkDown5 - m·ªôt ch·ªâ s·ªë g√¨ ƒë√≥ m√† t√°c gi·∫£ kh√¥ng cung c·∫•p ƒë·ªãnh nghƒ©a cho ch√∫ng ta, CPI - ch·ªâ s·ªë gi√° ti√™u d√πng, Unemployment - t√¨nh tr·∫°ng th·∫•t nghi·ªáp, IsHoliday - Tu·∫ßn c√≥ ch·ª©a ng√†y ngh·ªâ.\nPh√¢n t√≠ch d·ªØ li·ªáu M√¨nh s·∫Ω import m·ªôt s·ªë th∆∞ vi·ªán c·∫ßn thi·∫øt\n1import pandas as pd 2import numpy as np 3 4#Do some statistics 5from scipy.misc import imread 6from scipy import sparse 7import scipy.stats as ss 8import math 9 10#Nice graphing tools 11import matplotlib 12import matplotlib.pyplot as plt 13import seaborn as sns ƒê·ªçc c√°c file data l√™n, merge c√°c file l·∫°i v·ªõi nhau\n1 2 3train = pd.read_csv(\u0026#39;data/train.csv\u0026#39;) 4test = pd.read_csv(\u0026#39;data/test.csv\u0026#39;) 5feature = pd.read_csv(\u0026#39;data/features.csv\u0026#39;) 6 7train = train.merge(feature, how=\u0026#39;left\u0026#39;, on=[\u0026#39;Store\u0026#39;,\u0026#39;Date\u0026#39;]) 8test = test.merge(feature, how=\u0026#39;left\u0026#39;, on=[\u0026#39;Store\u0026#39;,\u0026#39;Date\u0026#39;]) 9 10 11# Merge in store info 12stores = pd.read_csv(\u0026#34;data/stores.csv\u0026#34;) 13train = train.merge(stores, how=\u0026#39;left\u0026#39;, on=\u0026#39;Store\u0026#39;) 14test = test.merge(stores, how=\u0026#39;left\u0026#39;, on=\u0026#39;Store\u0026#39;) 15print(train.head()) K·∫øt qu·∫£\n1 Store Dept Date Weekly_Sales IsHoliday_x Temperature Fuel_Price MarkDown1 MarkDown2 MarkDown3 MarkDown4 MarkDown5 CPI Unemployment IsHoliday_y Type Size Split 20 1 1 2010-02-05 24924.50 False 42.31 2.572 NaN NaN NaN NaN NaN 211.096358 8.106 False A 151315 Train 31 1 1 2010-02-12 46039.49 True 38.51 2.548 NaN NaN NaN NaN NaN 211.242170 8.106 True A 151315 Train 42 1 1 2010-02-19 41595.55 False 39.93 2.514 NaN NaN NaN NaN NaN 211.289143 8.106 False A 151315 Train 53 1 1 2010-02-26 19403.54 False 46.63 2.561 NaN NaN NaN NaN NaN 211.319643 8.106 False A 151315 Train 64 1 1 2010-03-05 21827.90 False 46.50 2.625 NaN NaN NaN NaN NaN 211.350143 8.106 False A 151315 Train M·ªõi c√≥ 5 d√≤ng ƒë·∫ßu ti√™n m√† th·∫•y c√°c ch·ªâ s·ªë markdown Nan r·ªìi.\nCh√∫ng ta ti·∫øn h√†nh m·ªôt s·ªë ph√¢n t√≠ch d·ªØ li·ªáu. √Ä, M√¨nh s·∫Ω merge d·ªØ li·ªáu train v√† test l·∫°i r·ªìi ph√¢n t√≠ch th·ªëng k√™\n1df = pd.concat([train,test],axis=0) # Join train and test 2 3print(df.describe()) K·∫øt qu·∫£\n1 CPI Dept Fuel_Price MarkDown1 MarkDown2 MarkDown3 MarkDown4 MarkDown5 Size Store Temperature Unemployment Weekly_Sales 2count 498472.000000 536634.000000 536634.000000 265596.000000 197685.000000 242326.000000 237143.000000 266496.000000 536634.00000 536634.000000 536634.000000 498472.000000 421570.000000 3mean 172.090481 44.277301 3.408310 7438.004144 3509.274827 1857.913525 3371.556866 4324.021158 136678.55096 22.208621 58.771762 7.791888 15981.258123 4std 39.542149 30.527358 0.430861 9411.341379 8992.047197 11616.143274 6872.281734 13549.262124 61007.71180 12.790580 18.678716 1.865076 22711.183519 5min 126.064000 1.000000 2.472000 -2781.450000 -265.760000 -179.260000 0.220000 -185.170000 34875.00000 1.000000 -7.290000 3.684000 -4988.940000 625% 132.521867 18.000000 3.041000 2114.640000 72.500000 7.220000 336.240000 1570.112500 93638.00000 11.000000 45.250000 6.623000 2079.650000 750% 182.442420 37.000000 3.523000 5126.540000 385.310000 40.760000 1239.040000 2870.910000 140167.00000 22.000000 60.060000 7.795000 7612.030000 875% 213.748126 74.000000 3.744000 9303.850000 2392.390000 174.260000 3397.080000 5012.220000 202505.00000 33.000000 73.230000 8.549000 20205.852500 9max 228.976456 99.000000 4.468000 103184.980000 104519.540000 149483.310000 67474.850000 771448.100000 219622.00000 45.000000 101.950000 14.313000 693099.360000 Ph√¢n t√≠ch m·ªôt ch√∫t:\nB·ªè qua c·ªôt Dept v√† Store v√¨ n√≥ l√† m√£ s·∫£n ph·∫©m v√† m√£ c·ªßa h√†ng, ng∆∞·ªùi ta th√≠ch ƒë·∫∑t s·ªë bao nhi√™u th√¨ ƒë·∫∑t.\nC√°c ch·ªâ s·ªë MarkDown c√≥ ƒë·ªô l·ªách chu·∫©n kh√° cao.\nNhi·ªát ƒë·ªô min l√† -7.29, max l√† 101.95, trung b√¨nh l√† 58, n√™n kh√¥ng th·ªÉ l√† ƒë·ªô C ƒë∆∞·ª£c, c√≥ th·ªÉ l√† ƒë·ªô F\nXem th·ª≠ h·ªá s·ªë t∆∞∆°ng quan gi·ªØa c√°c column nh∆∞ th·∫ø n√†o\n1sns.set(style=\u0026#34;white\u0026#34;) 2 3# Compute the correlation matrix 4corr = df.corr() 5 6# Generate a mask for the upper triangle 7mask = np.zeros_like(corr, dtype=np.bool) 8mask[np.triu_indices_from(mask)] = True 9 10# Set up the matplotlib figure 11f, ax = plt.subplots(figsize=(11, 9)) 12 13# Generate a custom diverging colormap 14cmap = sns.diverging_palette(220, 10, as_cmap=True) 15 16# Draw the heatmap with the mask and correct aspect ratio 17sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, 18 square=True, linewidths=.5, cbar_kws={\u0026#34;shrink\u0026#34;: .5}) 19 20plt.show() H·ªá s·ªë t∆∞∆°ng quan gi·ªØa c√°c c·ªôt trong d·ªØ li·ªáu\nPh√¢n t√≠ch m·ªôt ch√∫t, ch√∫ng ta th·∫•y r·∫±ng MarkDown5 h·∫ßu nh∆∞ kh√¥ng c√≥ li√™n quan g√¨ ƒë·∫øn c√°c column c√≤n l·∫°i. H·ªá s·ªë tr·∫£i t·ª´ -0.3 ƒë·∫øn 0.3 ch·ª©ng t·ªè m·ªïi quan h·ªá gi·ªØa c√°c c·ªôt l√† kh√° l·ªèng l·∫ªo. Ch·ªâ s·ªë gi√° ti√™u d√πng t∆∞∆°ng quan t·ª∑ l·ªá ngh·ªãch v·ªõi t√¨nh tr·∫°ng th·∫•t nghi·ªáp (h·ª£p l√Ω kh√¥ng nh·ªâ). K√≠ch th∆∞·ªõc c·ª≠a h√†ng c√†ng b·ª± th√¨ b√°n c√†ng nhi·ªÅu (ok hi·ªÉn nhi√™n), s·∫£n ph·∫©m c√≥ m√£ c√†ng l·ªõn th√¨ b√°n c√†ng nhi·ªÅu (? c√≥ l·∫Ω l√† s·∫£n ph·∫©m m·ªõi, ng∆∞·ªùi m·ªπ th√≠ch mua s·∫£n ph·∫©m m·ªõi chƒÉng). V√† m·ªôt v·∫•n ƒë·ªÅ quan tr·ªçng l√† gi√° nhi√™n li·ªáu, isHoliday, nhi·ªát ƒë·ªô kh√¥ng c√≥ m·ªëi t∆∞∆°ng quan v·ªõi weekly sales. Ch·ªâ s·ªë CPI v√† t√¨nh tr·∫°ng th·∫•t nghi·ªáp c≈©ng ·∫£nh h∆∞·ªüng kh√¥ng l·ªõn v·ªõi weekly sales.\nTh·ª≠ plot l√™n h√¨nh ·∫£nh v·ªÅ s·ªë l∆∞·ª£ng b√°n v√† k√≠ch th∆∞·ªõc c·ª≠a h√†ng xem sao\n1plt.scatter( df[\u0026#39;Size\u0026#39;],df[\u0026#39;Weekly_Sales\u0026#39;]) 2plt.show() T∆∞∆°ng quan gi·ªØa s·ªë b√°n v√† k√≠ch th∆∞·ªõc c·ª≠a h√†ng\nNh√¨n v√†o h√¨nh tr√™n, ch√∫ng ta th·∫•y r·∫±ng c·ª≠a h√†ng c√≥ k√≠ch th∆∞·ªõc nh·ªè s·ªë b√°n c≈©ng kh√¥ng tƒÉng ƒë·ªôt bi·∫øn khi g·∫∑p ng√†y l·ªÖ, c·ª≠a h√†ng k√≠ch th∆∞·ªõc si√™u b·ª± c√≥ t·ª∑ l·ªá ƒë·ªôt bi·∫øn th·∫•p, c·ª≠a h√†ng trung trung c√≥ ƒë·ªôt bi·∫øn, ·ªü kh√∫c size 125000 v√† s·ªë b√°n l√† 700000. Ch√∫ng ta h√£y xem nh·ªØng ng√†y c√≥ s·ªë b√°n l·ªõn r∆°i v√†o ng√†y n√†o. D·ª±a v√†o b·∫£ng desription ·ªü ph√≠a tr√™n ƒë√£ ph√¢n t√≠ch, trung b√¨nh c·ªßa s·ªë b√°n l√† 15981 v√† l·ªách chu·∫©n l√† 22711, c·ªông l·∫°i l√† 15981 + 22711 = 38692, nh√¨n tr√™n ƒë√¥ th·ªã th√¨ ph·∫ßn ƒë·ªôt bi·∫øn kh√° l·ªõn. Max l√† 700000, min l√† 0 (c√°i n√†y nh√¨n h√¨nh, kh√¥ng ph·∫£i s·ªë th·ª±c t·∫ø ·ªü b·∫£ng m√¥ t·∫£), m√¨nh s·∫Ω l·∫•y ra nh·ªØng ng√†y c√≥ s·ªë b√°n l·ªõn h∆°n 350000 (v∆∞·ª£t qua ng∆∞·ª°ng trung b√¨nh + ƒë·ªô l·ªách chu·∫©n r·∫•t nh·ªÅu -\u0026gt; ngo·∫°i l·ªá l√† ƒë√¢y) xem nh·ªØng ng√†y ƒë√≥ l√† ng√†y g√¨\n1 2print(df.loc[df[\u0026#39;Weekly_Sales\u0026#39;] \u0026gt;350000].head(10)) In ra top 10 th·∫±ng ƒë·∫ßu ti√™n\n1 2 CPI Date Dept Fuel_Price IsHoliday_x IsHoliday_y MarkDown1 MarkDown2 MarkDown3 MarkDown4 MarkDown5 Size Split Store Temperature Type Unemployment Weekly_Sales 337201 126.669267 2010-11-26 72 2.752 True True NaN NaN NaN NaN NaN 205863 Train 4 48.08 A 7.127 381072.11 437253 129.836400 2011-11-25 72 3.225 True True 561.45 137.88 83340.33 44.04 9239.23 205863 Train 4 47.96 A 5.143 385051.04 588428 126.983581 2010-12-24 7 3.236 False False NaN NaN NaN NaN NaN 126512 Train 10 57.06 B 9.003 406988.63 695373 126.669267 2010-11-26 72 3.162 True True NaN NaN NaN NaN NaN 126512 Train 10 55.33 B 9.003 693099.36 795377 126.983581 2010-12-24 72 3.236 False False NaN NaN NaN NaN NaN 126512 Train 10 57.06 B 9.003 404245.03 895425 129.836400 2011-11-25 72 3.760 True True 174.72 329.00 141630.61 79.00 1009.98 126512 Train 10 60.68 B 7.874 630999.19 9115222 126.669267 2010-11-26 72 3.162 True True NaN NaN NaN NaN NaN 112238 Train 12 47.66 B 14.313 359995.60 10115274 129.836400 2011-11-25 72 3.622 True True 5391.83 8.00 63143.29 49.27 2115.67 112238 Train 12 53.25 B 12.890 360140.66 11128984 182.544590 2010-12-24 7 3.141 False False NaN NaN NaN NaN NaN 200898 Train 14 30.59 A 8.724 356867.25 12135665 182.783277 2010-11-26 72 3.039 True True NaN NaN NaN NaN NaN 200898 Train 14 46.15 A 8.724 474330.10 Nh√¨n v√†o b·∫£ng tr√™n, ch√∫ng ta th·∫•y r·∫±ng 10 ng√†y ƒë·∫ßu ti√™n t·∫≠p trung ch·ªß y·∫øu ·ªü th√°ng 11 v√† th√°ng 12, th√°ng 12 l√† 24-25 th√°ng 12 -\u0026gt; ng√†y noel, c√≤n th√°ng 11 l√† 25-26 th√°ng 11 (ng√†y g√¨ v·∫≠y ta, trong m√¥ t·∫£ kh√¥ng th·∫•y) Tra l·ªãch th√¨ ng√†y 25 th√°ng 11 nƒÉm 2011 tr√∫ng th·ª© s√°u, tra tr√™n m·∫°ng m·ªôt th√¥ng tin kh√° quan trong l√† \u0026ldquo;Black Friday s·∫Ω r∆°i v√†o kho·∫£ng ng√†y 23-29 th√°ng 11\u0026rdquo; -\u0026gt; kh√¥ng nghi ng·ªù g√¨ n·ªØa c√≥ th·ªÉ l√† ng√†y n√†y ƒë√¢y. Th·ª≠ tra ti·∫øp ng√†y 26 th√°ng 11 nƒÉm 2010, c≈©ng l√† th·ª© s√°u lu√¥n -\u0026gt; ng√†y black friday v√† ng√†y noel c√≥ s·ª©c mua ƒëi√™n cu·ªìng qu√°.\nM√¨nh d√πng m·ªôt k·ªπ thu·∫≠t nh·ªè l√† gi·∫£m d·∫ßn s·ªë b√°n, ƒë·ªÉ ra s·ªë b√°n t·ªëi thi·ªÉu m√† ng√†y black friday v√† ng√†y nodel v·∫´n c√≤n gi·ªØ v·ªã tr√≠ th·ªëng tr·ªã. K·ªπ thu·∫≠t kh√° ƒë∆°n gi·∫£n th√¥i, t·ª´ gi√° tr·ªã 350000, m·ªói l·∫ßn m√¨nh s·∫Ω gi·∫£m ƒëi 10000, v√† ƒë·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa c√°c ng√†y, n·∫øu c√≥ ng√†y n√†o ƒë√≥ n·∫±m ngo√†i tu·∫ßn ch·ª©a black friday v√† nodel th√¨ m√¨nh d·ª´ng. Sau m·ªôt h·ªìi t√¨m ki·∫øm v√† s·ªë b√°n ƒë√£ xu·∫•t hi·ªán, ƒë√≥ l√† 290000\n1print(df.loc[df[\u0026#39;Weekly_Sales\u0026#39;] \u0026gt;290000,\u0026#34;Date\u0026#34;].value_counts()) 12010-11-26 16 22011-11-25 14 32010-12-24 8 42011-12-23 3 52010-02-05 1 L√†m s·∫°ch d·ªØ li·ªáu X·ª≠ l√Ω missing values M·ªôt v·∫•n ƒë·ªÅ kh√° quan tr·ªçng l√† trong t·∫≠p d·ªØ li·ªáu n√†y missing value kh√° nhi·ªÅu, th·ª≠ ƒë·∫øm s·ªë l∆∞·ª£ng null trong data cho ta bi·∫øt ƒë∆∞·ª£c r·∫±ng\n1CPI 38162 2Date 0 3Dept 0 4Fuel_Price 0 5IsHoliday_x 0 6IsHoliday_y 0 7MarkDown1 271038 8MarkDown2 338949 9MarkDown3 294308 10MarkDown4 299491 11MarkDown5 270138 12Size 0 13Split 0 14Store 0 15Temperature 0 16Type 0 17Unemployment 38162 18Weekly_Sales 115064 C√°c gi√° tr·ªã MarkDown b·ªã null kh√° nhi·ªÅu, c√°ch ƒë∆°n gi·∫£n nh·∫•t l√† set 0 cho t·∫•t c·∫£ c√°c gi√° tr·ªã null ( M√¨nh l∆∞u log l·∫°i nh·ªØng index null c·ªßa c√°c markdown).\n1df = df.assign(md1_present = df[\u0026#39;MarkDown1\u0026#39;]notnull()) 2df = df.assign(md2_present = df[\u0026#39;MarkDown2\u0026#39;]notnull()) 3df = df.assign(md3_present = df[\u0026#39;MarkDown3\u0026#39;]notnull()) 4df = df.assign(md4_present = df[\u0026#39;MarkDown4\u0026#39;]notnull()) 5df = df.assign(md5_present = df[\u0026#39;MarkDown5\u0026#39;].notnull()) 6 7df.fillna(0, inplace=True) T·∫°o ƒë·∫∑c tr∆∞ng ƒê·∫∑c tr∆∞ng holiday\n1df[\u0026#39;IsHoliday\u0026#39;] = \u0026#39;IsHoliday_\u0026#39; + df[\u0026#39;IsHoliday_x\u0026#39;].map(str) 2holiday_dummies = pd.get_dummies(df[\u0026#39;IsHoliday\u0026#39;]) ƒê·∫∑c tr∆∞ng ng√†y th√°ng\nR√∫t tr√≠ch th√°ng\n1df[\u0026#39;DateType\u0026#39;] = [datetime.strptime(date, \u0026#39;%Y-%m-%d\u0026#39;).date() for date in df[\u0026#39;Date\u0026#39;].astype(str).values.tolist()] 2df[\u0026#39;Month\u0026#39;] = [date.month for date in df[\u0026#39;DateType\u0026#39;]] 3df[\u0026#39;Month\u0026#39;] = \u0026#39;Month_\u0026#39; + df[\u0026#39;Month\u0026#39;].map(str) 4Month_dummies = pd.get_dummies(df[\u0026#39;Month\u0026#39;] ) R√∫t tr√≠ch ng√†y tr∆∞·ªõc gi√°ng sinh v√† black friday\n1df[\u0026#39;Black_Friday\u0026#39;] = np.where((df[\u0026#39;DateType\u0026#39;]==datetime(2010, 11, 26).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2011, 11, 25).date()), \u0026#39;yes\u0026#39;, \u0026#39;no\u0026#39;) 2df[\u0026#39;Pre_christmas\u0026#39;] = np.where((df[\u0026#39;DateType\u0026#39;]==datetime(2010, 12, 23).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2010, 12, 24).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2011, 12, 23).date()) | (df[\u0026#39;DateType\u0026#39;]==datetime(2011, 12, 24).date()), \u0026#39;yes\u0026#39;, \u0026#39;no\u0026#39;) 3df[\u0026#39;Black_Friday\u0026#39;] = \u0026#39;Black_Friday_\u0026#39; + df[\u0026#39;Black_Friday\u0026#39;].map(str) 4df[\u0026#39;Pre_christmas\u0026#39;] = \u0026#39;Pre_christmas_\u0026#39; + df[\u0026#39;Pre_christmas\u0026#39;].map(str) 5Black_Friday_dummies = pd.get_dummies(df[\u0026#39;Black_Friday\u0026#39;] ) 6Pre_christmas_dummies = pd.get_dummies(df[\u0026#39;Pre_christmas\u0026#39;] ) Th√™m c√°c ƒë·∫∑c tr∆∞ng v√†o trong d·ªØ li·ªáu\n1 2df = pd.concat([df,holiday_dummies,Pre_christmas_dummies,Black_Friday_dummies],axis=1) Th√™m ƒë·∫∑c tr∆∞ng trung v·ªã c·ªßa t·ª´ng lo·∫°i c·ª≠a h√†ng v√†o t·ª´ng th√°ng, do m·ªôt s·ªë c·ªßa h√†ng s·∫Ω b·ªã NA ·ªü c·ªôt s·ªë b√°n ·ªü m·ªôt th·ªùi ƒëi·ªÉm n√†o ƒë√≥, n√™n ch√∫ng ta replace s·ªë b√°n l√† 0 c√≥ v·∫ª kh√¥ng h·ª£p l√Ω l·∫Øm. M√¨nh ch·ªçn c√°ch l√† thay th·∫ø b·∫±ng trung b√¨nh c·ªßa s·ªë b√°n trong th√°ng c·ªßa c·ª≠a h√†ng c√πng lo·∫°i. Nh∆∞ng tr∆∞·ªõc ti√™n th√¨ t√≠nh trung b√¨nh s·ªë b√°n c·ªßa t·ª´ng lo·∫°i c·ª≠a h√†ng c√°i ƒë√£.\n1 2medians = pd.DataFrame({\u0026#39;Median Sales\u0026#39; :df.loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Train\u0026#39;].groupby(by=[\u0026#39;Type\u0026#39;,\u0026#39;Dept\u0026#39;,\u0026#39;Store\u0026#39;,\u0026#39;Month\u0026#39;,\u0026#39;IsHoliday\u0026#39;])[\u0026#39;Weekly_Sales\u0026#39;].median()}).reset_index() 3print(medians.head()) K·∫øt qu·∫£\n1 Type Dept Store Month IsHoliday Median Sales 20 Type_A Dept_1 Store_1 Month_1 IsHoliday_False 17350.585 31 Type_A Dept_1 Store_1 Month_10 IsHoliday_False 23388.030 42 Type_A Dept_1 Store_1 Month_11 IsHoliday_False 19551.115 53 Type_A Dept_1 Store_1 Month_11 IsHoliday_True 19865.770 64 Type_A Dept_1 Store_1 Month_12 IsHoliday_False 39109.390 th√™m d·ªØ li·ªáu v√†o trong data ch√≠nh, lo·∫°i b·ªè NA v√† t·∫°o key cho m·ªói d√≤ng ƒë·ªÉ d·ªÖ d√†ng truy xu·∫•t\n1df = df.merge(medians, how = \u0026#39;outer\u0026#39;, on = [\u0026#39;Type\u0026#39;,\u0026#39;Dept\u0026#39;,\u0026#39;Store\u0026#39;,\u0026#39;Month\u0026#39;,\u0026#39;IsHoliday\u0026#39;]) 2 3# Fill NA 4df[\u0026#39;Median Sales\u0026#39;].fillna(df[\u0026#39;Median Sales\u0026#39;].loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Train\u0026#39;].median(), inplace=True) 5 6# Create a key for easy access 7 8df[\u0026#39;Key\u0026#39;] = df[\u0026#39;Type\u0026#39;].map(str)+df[\u0026#39;Dept\u0026#39;].map(str)+df[\u0026#39;Store\u0026#39;].map(str)+df[\u0026#39;Date\u0026#39;].map(str)+df[\u0026#39;IsHoliday\u0026#39;].map(str) Ch√∫ng ta s·∫Ω d·ª± ƒëo√°n s·ªë b√°n c·ªßa tu·∫ßn k·∫ø ti·∫øp d·ª±a v√†o k·∫øt qu·∫£ s·ªë b√°n c·ªßa tu·∫ßn hi·ªán t·∫°i, n√™n trong d·ªØ li·ªáu s·∫Ω l∆∞u tr√™n ng√†y c·ªßa tu·∫ßn tr∆∞·ªõc ƒë√≥ ƒë·ªÉ d·ªÖ truy xu·∫•t. V√¨ 1 tu·∫ßn c√≥ 7 ng√†y, ch√∫ng ta s·∫Ω l∆∞u gi√° tr·ªã l√† ng√†y ·ªü c·ªôt hi·ªán t·∫°i - 7\n1df[\u0026#39;DateLagged\u0026#39;] = df[\u0026#39;DateType\u0026#39;]- timedelta(days=7) V√† gi·ªù ƒë√¢y, ch√∫ng ta s·∫Ω l·∫∑p qua to√†n b·ªô c√°c d√≤ng tr√™n t·∫≠p d·ªØ li·ªáu, ki·ªÉm tra xem c√≥ d√≤ng n√†o s·ªë b√°n nan h√¥ng, n·∫øu c√≥ th√¨ s·∫Ω thay b·∫±ng trung b√¨nh ƒë√£ t√≠nh ·ªü tr√™n. ·ªû ƒë√¢y m√¨nh t·∫°o m·ªôt sorted dataset ƒë·ªÉ truy xu·∫•t cho nhanh\n1 2#Make a sorted dataframe. This will allow us to find lagged variables much faster! 3sorted_df = df.sort_values([\u0026#39;Store\u0026#39;, \u0026#39;Dept\u0026#39;,\u0026#39;DateType\u0026#39;], ascending=[1, 1,1]) 4sorted_df = sorted_df.reset_index(drop=True) # Reinitialize the row indices for the loop to work 5 6sorted_df[\u0026#39;LaggedSales\u0026#39;] = np.nan # Initialize column 7sorted_df[\u0026#39;LaggedAvailable\u0026#39;] = np.nan # Initialize column 8last=df.loc[0] # intialize last row for first iteration. Doesn\u0026#39;t really matter what it is 9row_len = sorted_df.shape[0] 10for index, row in sorted_df.iterrows(): 11 lag_date = row[\u0026#34;DateLagged\u0026#34;] 12 # Check if it matches by comparing last weeks value to the compared date 13 # And if weekly sales aren\u0026#39;t 0 14 if((last[\u0026#39;DateType\u0026#39;]== lag_date) \u0026amp; (last[\u0026#39;Weekly_Sales\u0026#39;]\u0026gt;0)): 15 sorted_df.set_value(index, \u0026#39;LaggedSales\u0026#39;,last[\u0026#39;Weekly_Sales\u0026#39;]) 16 sorted_df.set_value(index, \u0026#39;LaggedAvailable\u0026#39;,1) 17 else: 18 sorted_df.set_value(index, \u0026#39;LaggedSales\u0026#39;,row[\u0026#39;Median Sales\u0026#39;]) # Fill with median 19 sorted_df.set_value(index, \u0026#39;LaggedAvailable\u0026#39;,0) 20 21 last = row #Remember last row for speed 22 if(index%int(row_len/10)==0): #See progress by printing every 10% interval 23 print(str(int(index*100/row_len))+\u0026#39;% loaded\u0026#39;) 24 25print(sorted_df[[\u0026#39;Dept\u0026#39;, \u0026#39;Store\u0026#39;,\u0026#39;DateType\u0026#39;,\u0026#39;LaggedSales\u0026#39;,\u0026#39;Weekly_Sales\u0026#39;,\u0026#39;Median Sales\u0026#39;]].head()) 19% loaded 219% loaded 329% loaded 439% loaded 549% loaded 659% loaded 769% loaded 879% loaded 989% loaded 1099% loaded 11 Dept Store DateType LaggedSales Weekly_Sales Median Sales 120 Dept_1 Store_1 2010-02-05 23510.49 24924.50 23510.49 131 Dept_1 Store_1 2010-02-12 24924.50 46039.49 37887.17 142 Dept_1 Store_1 2010-02-19 46039.49 41595.55 23510.49 153 Dept_1 Store_1 2010-02-26 41595.55 19403.54 23510.49 164 Dept_1 Store_1 2010-03-05 19403.54 21827.90 21280.40 C√¥ng vi·ªác ƒë∆°n gi·∫£n ti·∫øp theo l√† merge d·ªØ li·ªáu v√†o data ch√≠nh v√† t√≠nh ƒë·ªô l·ªách gi·ªØa 2 tu·∫ßn b√°n\n1# Merge by store and department 2df = df.merge(sorted_df[[\u0026#39;Dept\u0026#39;, \u0026#39;Store\u0026#39;,\u0026#39;DateType\u0026#39;,\u0026#39;LaggedSales\u0026#39;,\u0026#39;LaggedAvailable\u0026#39;]], how = \u0026#39;inner\u0026#39;, on = [\u0026#39;Dept\u0026#39;, \u0026#39;Store\u0026#39;,\u0026#39;DateType\u0026#39;]) 3df[\u0026#39;Sales_dif\u0026#39;] = df[\u0026#39;Median Sales\u0026#39;] - df[\u0026#39;LaggedSales\u0026#39;] V√† b√¢y gi·ªù , thay v√¨ ta ∆∞·ªõc l∆∞·ª£ng weekly sales, ch√∫ng ta s·∫Ω ∆∞·ªõc l∆∞·ª£ng ƒë·ªô l·ªách gi·ªØa week sales v√† median sales (ƒë√¢y l√† m·ªôt c√°ch trong nh·ªØng c√°ch ƒë·ªÉ t√≠nh ƒëi·ªÉm d·ª´ng c·ªßa d·ªØ li·ªáu time series)\n1df[\u0026#39;Difference\u0026#39;] = df[\u0026#39;Median Sales\u0026#39;] - df[\u0026#39;Weekly_Sales\u0026#39;] Hu·∫•n luy·ªán m√¥ h√¨nh L·ª±a ch·ªçn c√°c ƒë·∫∑c tr∆∞ng hu·∫•n luy·ªán\n1selector = [ 2 #\u0026#39;Month\u0026#39;, 3 \u0026#39;CPI\u0026#39;, 4 \u0026#39;Fuel_Price\u0026#39;, 5 \u0026#39;MarkDown1\u0026#39;, 6 \u0026#39;MarkDown2\u0026#39;, 7 \u0026#39;MarkDown3\u0026#39;, 8 \u0026#39;MarkDown4\u0026#39;, 9 \u0026#39;MarkDown5\u0026#39;, 10 \u0026#39;Size\u0026#39;, 11 \u0026#39;Temperature\u0026#39;, 12 \u0026#39;Unemployment\u0026#39;, 13 14 15 16 \u0026#39;md1_present\u0026#39;, 17 \u0026#39;md2_present\u0026#39;, 18 \u0026#39;md3_present\u0026#39;, 19 \u0026#39;md4_present\u0026#39;, 20 \u0026#39;md5_present\u0026#39;, 21 22 \u0026#39;IsHoliday_False\u0026#39;, 23 \u0026#39;IsHoliday_True\u0026#39;, 24 \u0026#39;Pre_christmas_no\u0026#39;, 25 \u0026#39;Pre_christmas_yes\u0026#39;, 26 \u0026#39;Black_Friday_no\u0026#39;, 27 \u0026#39;Black_Friday_yes\u0026#39;, 28 \u0026#39;LaggedSales\u0026#39;, 29 \u0026#39;Sales_dif\u0026#39;, 30 \u0026#39;LaggedAvailable\u0026#39; 31 ] T√°ch d·ªØ li·ªáu train v√† test ri√™ng ra\n1 2train = df.loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Train\u0026#39;] 3test = df.loc[df[\u0026#39;Split\u0026#39;]==\u0026#39;Test\u0026#39;] L·∫•y ng·∫´u nhi√™n 20% d·ªØ li·ªáu ·ªü t·∫≠p train ƒë·ªÉ validation\n1# Set seed for reproducability 2np.random.seed(42) 3X_train, X_val, y_train, y_val = train_test_split(train[selector], train[\u0026#39;Difference\u0026#39;], test_size=0.2, random_state=42) Hu·∫•n luy·ªán b·∫±ng neural network s·ª≠ d·ª•ng lstm\n1 2adam_regularized = Sequential() 3 4 # First hidden layer now regularized 5 model.add(Dense(32,activation=\u0026#39;relu\u0026#39;, 6 input_dim=X_train.shape[1], 7 kernel_regularizer = regularizers.l2(0.01))) 8 9 # Second hidden layer now regularized 10 adam_regularized.add(Dense(16,activation=\u0026#39;relu\u0026#39;, 11 kernel_regularizer = regularizers.l2(0.01))) 12 13 # Output layer stayed sigmoid 14 adam_regularized.add(Dense(1,activation=\u0026#39;linear\u0026#39;)) 15 16 # Setup adam optimizer 17 adam_optimizer=keras.optimizers.Adam(lr=0.01, 18 beta_1=0.9, 19 beta_2=0.999, 20 epsilon=1e-08) 21 22 # Compile the model 23 adam_regularized.compile(optimizer=adam_optimizer, 24 loss=\u0026#39;mean_absolute_error\u0026#39;, 25 metrics=[\u0026#39;acc\u0026#39;]) 26 27 # Train 28 history=adam_regularized.fit(X_train, y_train, # Train on training set 29 epochs=10, # We will train over 1,000 epochs 30 batch_size=2048, # Batch size 31 verbose=0) # Suppress Keras output 32 print(\u0026#39;eval\u0026#39;,model.evaluate(x=X_val,y=y_val)) 33 34 # Plot network 35 plt.plot(history.history[\u0026#39;loss\u0026#39;], label=\u0026#39;Adam Regularized\u0026#39;) 36 plt.xlabel(\u0026#39;Epochs\u0026#39;) 37 plt.ylabel(\u0026#39;loss\u0026#39;) 38 plt.legend() 39 plt.show() 1eval: [1457.0501796214685, 0.002312783168124545] ƒê·ªô l·ªói tr√™n t·∫≠p train\nƒê·ªô l·ªói tr√™n t·∫≠p train gi·∫£m xu·ªëng ƒë·∫øn g·∫ßn 1450 th√¨ ƒë·ª´ng h·∫≥n, kh√¥ng th·ªÉ gi·∫£m ƒë∆∞·ª£c n·ªØa\nGi√° tr·ªã ƒë·ªô l·ªách tr√™n t·∫≠p evaluation l√† 1457.0501796214685\nTh·ª≠ hu·∫•n luy·ªán b·∫±ng random forest\n1regr = RandomForestRegressor(n_estimators=20, criterion=\u0026#39;mse\u0026#39;, max_depth=None, 2 min_samples_split=2, min_samples_leaf=1, 3 min_weight_fraction_leaf=0.0, max_features=\u0026#39;auto\u0026#39;, 4 max_leaf_nodes=None, min_impurity_decrease=0.0, 5 min_impurity_split=None, bootstrap=True, 6 oob_score=False, n_jobs=1, random_state=None, 7 verbose=2, warm_start=False) 8 9 #Train on data 10 regr.fit(X_train, y_train.ravel()) 11 y_pred_random = regr.predict(X_val) 12 13 y_val = y_val.to_frame() 14 15 # Transform forest predictions to observe direction of change 16 direction_true1= y_val.values 17 direction_predict = y_pred_random 18 19 y_val[\u0026#39;Predicted\u0026#39;] = y_pred_random 20 df_out = pd.merge(train,y_val[[\u0026#39;Predicted\u0026#39;]],how = \u0026#39;left\u0026#39;,left_index = True, right_index = True,suffixes=[\u0026#39;_True\u0026#39;,\u0026#39;_Pred\u0026#39;]) 21 df_out = df_out[~pd.isnull(df_out[\u0026#39;Predicted\u0026#39;])] 22 23 df_out[\u0026#39;prediction\u0026#39;] = df_out[\u0026#39;Median Sales\u0026#39;]-df_out[\u0026#39;Predicted\u0026#39;] 24 25 print(\u0026#34;Medians: \u0026#34;+str(sum(abs(df_out[\u0026#39;Difference\u0026#39;]))/df_out.shape[0])) 26 print(\u0026#34;Random Forest: \u0026#34;+str(sum(abs(df_out[\u0026#39;Weekly_Sales\u0026#39;]-df_out[\u0026#39;prediction\u0026#39;]))/df_out.shape[0])) K·∫øt qu·∫£\n1 29% loaded 319% loaded 429% loaded 539% loaded 649% loaded 759% loaded 869% loaded 979% loaded 1089% loaded 1199% loaded 12 Dept Store DateType LaggedSales Weekly_Sales Median Sales 130 Dept_1 Store_1 2010-02-05 23510.49 24924.50 23510.49 141 Dept_1 Store_1 2010-02-12 24924.50 46039.49 37887.17 152 Dept_1 Store_1 2010-02-19 46039.49 41595.55 23510.49 163 Dept_1 Store_1 2010-02-26 41595.55 19403.54 23510.49 174 Dept_1 Store_1 2010-03-05 19403.54 21827.90 21280.40 18[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. 19building tree 1 of 20 20[Parallel(n_jobs=1)]: Done 1 out of 1 | elapsed: 6.5s remaining: 0.0s 21building tree 2 of 20 22building tree 3 of 20 23building tree 4 of 20 24building tree 5 of 20 25building tree 6 of 20 26building tree 7 of 20 27building tree 8 of 20 28building tree 9 of 20 29building tree 10 of 20 30building tree 11 of 20 31building tree 12 of 20 32building tree 13 of 20 33building tree 14 of 20 34building tree 15 of 20 35building tree 16 of 20 36building tree 17 of 20 37building tree 18 of 20 38building tree 19 of 20 39building tree 20 of 20 40[Parallel(n_jobs=1)]: Done 20 out of 20 | elapsed: 2.2min finished 41[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers. 42[Parallel(n_jobs=1)]: Done 1 out of 1 | elapsed: 0.0s remaining: 0.0s 43[Parallel(n_jobs=1)]: Done 20 out of 20 | elapsed: 1.1s finished 44Medians: 1545.7406070759525 45Random Forest: 1356.4670052620745 Trung b√¨nh l·ªách c·ªßa random forest l√† 1356, gi√° tr·ªã n√†y nh·ªè h∆°n so v·ªõi gi√° tr·ªã output c·ªßa lstm tr·∫£ v·ªÅ.\nTh·ª≠ hu·∫•n luy·ªán b·∫±ng XGBoost\n1 2param_dist = { \u0026#39;max_depth\u0026#39;:5} 3 4 model = XGBRegressor(**param_dist) 5 6 #Train on data 7 model.fit(X_train, y_train.ravel()) 8 y_pred_random = model.predict(X_val) 9 10 y_val = y_val.to_frame() 11 12 # Transform forest predictions to observe direction of change 13 direction_true1= y_val.values 14 direction_predict = y_pred_random 15 16 y_val[\u0026#39;Predicted\u0026#39;] = y_pred_random 17 df_out = pd.merge(train,y_val[[\u0026#39;Predicted\u0026#39;]],how = \u0026#39;left\u0026#39;,left_index = True, right_index = True,suffixes=[\u0026#39;_True\u0026#39;,\u0026#39;_Pred\u0026#39;]) 18 df_out = df_out[~pd.isnull(df_out[\u0026#39;Predicted\u0026#39;])] 19 20 df_out[\u0026#39;prediction\u0026#39;] = df_out[\u0026#39;Median Sales\u0026#39;]-df_out[\u0026#39;Predicted\u0026#39;] 21 22 print(\u0026#34;Medians: \u0026#34;+str(sum(abs(df_out[\u0026#39;Difference\u0026#39;]))/df_out.shape[0])) 23 print(\u0026#34;XGB Regressor: \u0026#34;+str(sum(abs(df_out[\u0026#39;Weekly_Sales\u0026#39;]-df_out[\u0026#39;prediction\u0026#39;]))/df_out.shape[0])) K·∫øt qu·∫£\n1 2Medians: 1545.7406070759525 3XGB Regressor: 1354.1976755192593 K·∫øt qu·∫£ c≈©ng g·∫ßn nh∆∞ b·∫±ng Random forest :).\nGi·ªù m√¨nh s·∫Ω d√πng random forest ƒë·ªÉ t·∫°o file submission\n1 2 3rf_model = RandomForestRegressor(n_estimators=80, criterion=\u0026#39;mse\u0026#39;, max_depth=None, 4 min_samples_split=2, min_samples_leaf=1, 5 min_weight_fraction_leaf=0.0, max_features=\u0026#39;auto\u0026#39;, 6 max_leaf_nodes=None, min_impurity_decrease=0.0, 7 min_impurity_split=None, bootstrap=True, 8 oob_score=False, n_jobs=1, random_state=None, 9 verbose=0, warm_start=False) 10 11#Train on data 12rf_model.fit(train[selector], train[\u0026#39;Difference\u0026#39;]) 13final_y_prediction = rf_model.predict(test[selector]) 14 15testfile = pd.concat([test.reset_index(drop=True), pd.DataFrame(final_y_prediction)], axis=1) 16testfile[\u0026#39;prediction\u0026#39;] = testfile[\u0026#39;Median Sales\u0026#39;]-testfile[0] 17 18submission = pd.DataFrame({\u0026#39;id\u0026#39;:pd.Series([\u0026#39;\u0026#39;.join(list(filter(str.isdigit, x))) for x in testfile[\u0026#39;Store\u0026#39;]]).map(str) + \u0026#39;_\u0026#39; + 19 pd.Series([\u0026#39;\u0026#39;.join(list(filter(str.isdigit, x))) for x in testfile[\u0026#39;Dept\u0026#39;]]).map(str) + \u0026#39;_\u0026#39; + 20 testfile[\u0026#39;Date\u0026#39;].map(str), 21 \u0026#39;Weekly_Sales\u0026#39;:testfile[\u0026#39;prediction\u0026#39;]}) 22 23submission.to_csv(\u0026#39;submission.csv\u0026#39;,index=False) Sau khi submit m√¥ h√¨nh, m√¨nh ƒë·∫°t ƒë∆∞·ª£c k·∫øt qu·∫£ l√† 4455.96312 tr√™n private board, v√† 4419.17292 tr√™n publish board. ƒê√¢y l√† m·ªôt k·∫øt qu·∫£ kh√° t·ªá (ƒë·ª©ng h·∫°ng kho·∫£ng top 300). Sau khi m√¨nh nh√¨n l·∫°i m√¥ h√¨nh th√¨ ph√°t hi·ªán m·ªôt s·ªë v·∫•n ƒë·ªÅ.\nC√°c ƒë·∫∑c tr∆∞ng trong file features.csv n√≥ kh√¥ng c√≥ m·ªëi t∆∞∆°ng quan g√¨ h·∫øt v·ªõi s·ªë b√°n nh∆∞ ph√¢n t√≠ch ·ªü tr√™n -\u0026gt; m√¨nh m·∫°nh d·∫°ng b·ªè lu√¥n file features.csv, kh√¥ng quan t√¢m ƒë·∫øn n√≥ n·ªØa, t·∫≠p trung v√†o file ch√≠nh.\nB·ªè m·∫•y c√°i lag lu√¥n, th·ª≠ forecast ch√≠nh v√†o c√°i s·ªë b√°n lu√¥n xem sao\nV·ªõi c·ª≠a h√†ng n√†o th√¨ x√¢y d·ª±ng m√¥ h√¨nh cho c·ª≠a h√†ng v√† s·∫£n ph·∫©m ƒë√≥, kh√¥ng x√¢y d·ª±ng m·ªôt m√¥ h√¨nh t·ªïng qu√°t √°p d·ª•ng cho to√†n c·ª≠a h√†ng. v·ªõi nh·ªØng c·ª≠a h√†ng kh√¥ng c√≥ trong t·∫≠p train ho·∫∑c nh·ªØng s·∫£n ph·∫©m m√† c·ª≠a h√†ng ƒë√≥ ch∆∞a b√°n tr∆∞·ªõc ƒë√¢y (n√≥i chung l√† kh√¥ng c√≥ trong t·∫≠p train) th√¨ m·ªõi √°p d·ª•ng m√¥ h√¨nh c·ªßa to√†n c·ª≠a h√†ng cho n√≥.\nK·∫øt qu·∫£ l√† m√¨nh ƒë·∫°t ƒë∆∞·ª£c 2736 tr√™n private board v√† 2657.40087 tr√™n publish board (top 30), k·∫øt qu·∫£ tr√™n v·∫´n l√†m cho m√¨nh ch∆∞a h√†i l√≤ng l·∫Øm.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Apr 17, 2019","img":"","permalink":"/blog/2019-04-17-walmart-store-sales-forecasting/","series":null,"tags":["walmart","forecast","d·ª± ƒëo√°n"],"title":"D·ª± ƒêo√°n Doanh S·ªë B√°n C·ªßa C√°c C·ª≠a H√†ng Walmart"},{"categories":null,"content":" Th·ª±c hi·ªán Thu th·∫≠p h√¨nh ·∫£nh v√† ti·ªÅn x·ª≠ l√Ω Th·ª±c hi·ªán ƒê√¢y l√† m·ªôt b√†i to√°n ti·∫øp c·∫≠n b·∫±ng Deep Learning, n√™n vi·ªác thu th·∫≠p nhi·ªÅu d·ªØ li·ªáu c√≥ √Ω nghƒ©a r·∫•t quang tr·ªçng trong vi·ªác ƒë√≥ng g√≥p v√†o ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh. ·ªû ƒë√¢y, ch√∫ng ta s·∫Ω download t·∫≠p d·ªØ li·ªáu ·∫£nh c·ªßa http://places2.csail.mit.edu/download.html v√† s·ª≠ d·ª•ng m·∫°ng UNet ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.\nThu th·∫≠p h√¨nh ·∫£nh v√† ti·ªÅn x·ª≠ l√Ω D·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c download t·∫°i ƒë·ªãa ch·ªâ http://data.csail.mit.edu/places/places365/train_256_places365challenge.tar. T·∫≠p tr√™n c√≥ k√≠ch th∆∞·ªõc 108 GB. ƒê√¢y l√† t·∫≠p ·∫£nh thu·ªôc h·ªá m√†u RGB. Ch√∫ng ta s·∫Ω chuy·ªÉn t·∫≠p ·∫£nh tr√™n v·ªÅ h·ªá m√†u grayscale l√†m ·∫£nh g·ªëc cho qu√° tr√¨nh hu·∫•n luy·ªán. C√≥ m·ªôt m·∫πo nh·ªè cho ch√∫ng ta r√∫t ng·∫Øn qu√° tr√¨nh hu·∫•n luy·ªán nh∆∞ng v·∫´n ƒë·∫£m b·∫£o ƒë∆∞·ª£c ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh l√† ngo√†i k√™nh m√†u RGB m√† ch√∫ng ta hay x√†i, tr√™n th·∫ø gi·ªõi c√≤n c√≥ k√™nh m√†u HSV, trong ƒë√≥ n·∫øu ch√∫ng ta chuy·ªÉn m·ªôt ·∫£nh ·ªü k√™nh m√†u RGB v·ªÅ h·ªá m√†u HSV, v√† b·ªè ƒëi c√°c gi√° tr·ªã H, S, ch·ªâ gi·ªØ l·∫°i gi√° tr·ªã V, th√¨ ch·∫•t l∆∞·ª£ng ·∫£nh x√°m c·ªßa n√≥ g·∫ßn nh∆∞ l√† t∆∞∆°ng ƒë∆∞∆°ng v·ªõi ·∫£nh grayscale s·ª≠ d·ª•ng c√¥ng th·ª©c \u0026ldquo;th·∫ßn th√°nh\u0026rdquo; m√† ch√∫ng ta ƒë∆∞·ª£c h·ªçc ·ªü m√¥n x·ª≠ l√Ω ·∫£nh grayscale =0.30*R + 0.59*G + 0.11*B\nV√¨ v·∫≠y, thay v√¨ vi·ªác input l√† gi√° tr·ªã x√°m c·ªßa ·∫£nh, output l√† gi√° tr·ªã c·ªßa c√°c k√™nh m√†u RGB, ch√∫ng ta s·∫Ω chuy·ªÉn ƒë·ªïi b√†i to√°n l·∫°i l√† input l√† gi√° tr·ªã x√°m, output l√† gi√° tr·ªã H v√† S.\nM√¥ h√¨nh m·∫°ng Unet\nM·∫°ng UNet l√† m·ªôt m·∫°ng neural network ƒë∆∞·ª£c d√πng kh√° ph·ªï bi·∫øn trong c√°c cu·ªôc thi ph√¢n ƒëo·∫°n ·∫£nh, ƒë·ªô ch√≠nh x√°c c·ªßa n√≥ so v·ªõi c√°c thu·∫≠t to√°n kh√°c l√† v∆∞·ª£t tr·ªôi ho√†n to√†n. ·ªû ƒë√¢y, ch√∫ng ta c√≥ 2 h∆∞·ªõng ti·∫øp c·∫≠n, m·ªôt l√† build m·ªôt m·∫°ng Unet v√† random init weight r·ªìi hu·∫•n luy·ªán n√≥, c√°ch th·ª© hai l√† build m·∫°ng unet s·ª≠ d·ª•ng pretrain model r·ªìi hu·∫•n luy·ªán. B·ªüi v√¨ ƒë·∫∑c tr∆∞ng c·ªßa c√°c pretrain model ho·∫°t ƒë·ªông kh√° t·ªët v√† ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n t·∫≠p dataset l·ªõn, n√™n m√¨nh s·∫ª s·ª≠ d·ª•ng n√≥ ·ªü b√†i vi·∫øt n√†y. Song song ƒë√≥, m√¨nh s·∫Ω cung c·∫•p m·ªôt gi·∫£i ph√°p k√®m theo s·ª≠ ƒë·ªÉ s·ª≠ d·ª•ng m·∫°ng m√† kh√¥ng d√πng pretrain model.\n√ö t∆∞·ªüng ch√≠nh c·ªßa m·∫°ng UNet t·ª±a t·ª±a nh∆∞ auto-encoder, t·ª´ ·∫£nh g·ªëc ban ƒë·∫ßu, ch√∫ng s·∫Ω ƒë∆∞·ª£c n√©n th√¥ng tin l·∫°i qua c√°c ph√©p bi·∫øn ƒë·ªïi Conv2D (nh∆∞ c√°c ch√∫ th√≠ch m√†u s·∫Øc c·ªßa m≈©i t√™n trong h√¨nh tr√™n), sau ƒë√≥ s·∫Ω ƒë∆∞·ª£c \u0026ldquo;gi·∫£i n√©n\u0026rdquo; v·ªÅ l·∫°i ·∫£nh g·ªëc ban ƒë·∫ßu. Vi·ªác hu·∫•n luy·ªán coi nh∆∞ l√† ho√†n t·∫•t 100% n·∫øu ·∫£nh g·ªëc v·ªõi ·∫£nh gi·∫£i n√©n l√† l√† gi·ªëng nhau ho√†n to√†n.\nB√†i vi·∫øt s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Apr 16, 2019","img":"","permalink":"/blog/2019-04-16-colorfull-grayscale-to-color/","series":null,"tags":["machine learning","deep learning","neural network","amazone","th·∫ø gi·ªõi di ƒë·ªông","mwg"],"title":"Th·ª≠ L√†m ·ª®ng D·ª•ng T√¥ M√†u ·∫¢nh X√°m Th√†nh ·∫¢nh M√†u S·ª≠ D·ª•ng Tensorflow"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu Th·ª±c hi·ªán L·ªùi m·ªü ƒë·∫ßu ·ªû trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu l√† t·∫≠p d·ªØ li·ªáu ·ªü ·ªü link https://www.kaggle.com/alxmamaev/flowers-recognition. T·∫≠p d·ªØ li·ªáu n√†y bao g·ªìm 4242 h√¨nh c·∫£nh c·ªßa 5 lo·∫°i hoa h·ªìng (rose), hoa m·∫∑t tr·ªùi (sunflower), hoa b·ªì c√¥ng anh (dandelion), hoa c√∫c (daisy) v√† hoa tulip. Nh√≥m t√°c gi·∫£ ƒë√£ thu th·∫≠p d·ªØ li·ªáu d·ª±a tr√™n c√°c trang web flicr, google images, yandex. T·∫≠p h√¨nh ·∫£nh ƒë∆∞·ª£c chia th√†nh 5 l·ªõp, m·ªói l·ªõp c√≥ kho·∫£ng 800 h√¨nh, c√≥ k√≠ch th∆∞·ªõc x·∫•p x·ªâ 320x320 pixel. C√°c h√¨nh ·∫£nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng ƒë·ªìng nh·∫•t v·ªõi nhau.\nTh·ª±c hi·ªán D·ªØ li·ªáu sau khi gi·∫£n n√©n c√≥ d·∫°ng\n1data_dir/classname1/*.* 2data_dir/classname2/*.* 3... C·∫•u tr√∫c l∆∞u tr≈© nh∆∞ n√†y ƒë√∫ng v·ªõi m√¥ h√¨nh c·ªßa m√¨nh n√™n ch√∫ng ta c·∫ßn n√™n ch√∫ng ta kh√¥ng thay ƒë·ªïi g√¨ v·ªÅ c√¢u tr√∫c n·ªØa, ti·∫øn h√†nh vi·∫øt code\nƒê·∫ßu ti√™n, ch√∫ng ta s·∫Ω load dataset l√™n v√† tranform n√≥ ƒë·ªÉ ƒë∆∞a v√†o hu·∫•n luy·ªán.\n1import sys 2import os 3from collections import defaultdict 4import numpy as np 5import scipy.misc 6 7 8def preprocess_input(x0): 9 x = x0 / 255. 10 x -= 0.5 11 x *= 2. 12 return x 13 14 15def reverse_preprocess_input(x0): 16 x = x0 / 2.0 17 x += 0.5 18 x *= 255. 19 return x 20 21 22def dataset(base_dir, n): 23 print(\u0026#34;base dir: \u0026#34;+base_dir) 24 print(\u0026#34;n: \u0026#34;+str(n)) 25 n = int(n) 26 d = defaultdict(list) 27 for root, subdirs, files in os.walk(base_dir): 28 for filename in files: 29 file_path = os.path.join(root, filename) 30 assert file_path.startswith(base_dir) 31 32 suffix = file_path[len(base_dir):] 33 34 suffix = suffix.lstrip(\u0026#34;/\u0026#34;) 35 suffix = suffix.lstrip(\u0026#34;\\\\\u0026#34;) 36 if(suffix.find(\u0026#39;/\u0026#39;)\u0026gt;-1): #linux 37 label = suffix.split(\u0026#34;/\u0026#34;)[0] 38 else: #window 39 label = suffix.split(\u0026#34;\\\\\u0026#34;)[0] 40 d[label].append(file_path) 41 print(\u0026#34;walk directory complete\u0026#34;) 42 tags = sorted(d.keys()) 43 44 processed_image_count = 0 45 useful_image_count = 0 46 47 X = [] 48 y = [] 49 50 for class_index, class_name in enumerate(tags): 51 filenames = d[class_name] 52 for filename in filenames: 53 processed_image_count += 1 54 if processed_image_count%100 ==0: 55 print(class_name+\u0026#34;\\tprocess: \u0026#34;+str(processed_image_count)+\u0026#34;\\t\u0026#34;+str(len(d[class_name]))) 56 img = scipy.misc.imread(filename) 57 height, width, chan = img.shape 58 assert chan == 3 59 aspect_ratio = float(max((height, width))) / min((height, width)) 60 if aspect_ratio \u0026gt; 2: 61 continue 62 # We pick the largest center square. 63 centery = height // 2 64 centerx = width // 2 65 radius = min((centerx, centery)) 66 img = img[centery-radius:centery+radius, centerx-radius:centerx+radius] 67 img = scipy.misc.imresize(img, size=(n, n), interp=\u0026#39;bilinear\u0026#39;) 68 X.append(img) 69 y.append(class_index) 70 useful_image_count += 1 71 print(\u0026#34;processed %d, used %d\u0026#34; % (processed_image_count, useful_image_count)) 72 73 X = np.array(X).astype(np.float32) 74 #X = X.transpose((0, 3, 1, 2)) 75 X = preprocess_input(X) 76 y = np.array(y) 77 78 perm = np.random.permutation(len(y)) 79 X = X[perm] 80 y = y[perm] 81 82 print(\u0026#34;classes:\u0026#34;,end=\u0026#34; \u0026#34;) 83 for class_index, class_name in enumerate(tags): 84 print(class_name, sum(y==class_index),end=\u0026#34; \u0026#34;) 85 print(\u0026#34;X shape: \u0026#34;,X.shape) 86 87 return X, y, tags ƒêo·∫°n code tr√™n kh√° ƒë∆°n gi·∫£n v√† d·ªÖ hi·ªÉu. L∆∞u √Ω ·ªü ƒë√¢y l√† v·ªõi nh·ªØng b·ª©c ·∫£nh c√≥ t·ª∑ l·ªá width v√† height \u0026gt; 2 th√¨ m√¨nh s·∫Ω lo·∫°i ch√∫ng ra kh·ªèi t·∫≠p d·ªØ li·ªáu.\nTi·∫øp theo, ch√∫ng ta s·∫Ω x√¢y d·ª±ng m√¥ h√¨nh d·ª±a tr√™n m√¥ h√¨nh Resnet50 c√≥ s·∫µn c·ªßa kares, do s·ª≠ d·ª•ng pretrain model, n√™n n-1 l·ªõp tr∆∞·ªõc ƒë√≥ s·∫Ω kh√¥ng ƒë∆∞·ª£c hu·∫•n luy·ªán v√† ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng d·ª•ng c√°c weight c√≥ s·∫µn ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n t·∫≠p ImageNet r√∫t ƒë·∫∑c tr∆∞ng cho m√¥ h√¨nh. Ch√∫ng ta ch·ªâ c·∫ßn th√™m m·ªôt l·ªõp full connected v√† softmax ƒë·ªÉ ph√¢n l·ªõp c√°c lo·∫°i hoa, c√¥ng vi·ªác c·ªßa ch√∫ng ta hi·ªán t·∫°i l√† t√¨m ra tr·ªçng s·ªë c·ªßa l·ªõp full connected cu·ªëi c√πng (thay v√¨ hu·∫•n luy·ªán l·∫°i h·∫øt to√†n b·ªô m√¥ h√¨nh).\n1 2# create the base pre-trained model 3def build_model(nb_classes): 4 base_model = ResNet50(weights=\u0026#39;imagenet\u0026#39;, include_top=False) 5 6 # add a global spatial average pooling layer 7 x = base_model.output 8 x = GlobalAveragePooling2D()(x) 9 # let\u0026#39;s add a fully-connected layer 10 x = Dense(1024, activation=\u0026#39;relu\u0026#39;)(x) 11 # and a logistic layer 12 predictions = Dense(nb_classes, activation=\u0026#39;softmax\u0026#39;)(x) 13 14 # this is the model we will train 15 model = Model(inputs=base_model.input, outputs=predictions) 16 17 # first: train only the top layers (which were randomly initialized) 18 # i.e. freeze all convolutional ResNet50 layers 19 for layer in base_model.layers: 20 layer.trainable = False 21 22 return model Visualize m·ªôt ch√∫t x√≠u v·ªÅ ki·∫øn tr√∫c inceptionV3 m√¨nh ƒëang d√πng.\n1__________________________________________________________________________________________________ 2Layer (type) Output Shape Param # Connected to 3================================================================================================== 4input_1 (InputLayer) (None, None, None, 3 0 5__________________________________________________________________________________________________ 6conv1_pad (ZeroPadding2D) (None, None, None, 3 0 input_1[0][0] 7__________________________________________________________________________________________________ 8conv1 (Conv2D) (None, None, None, 6 9472 conv1_pad[0][0] 9__________________________________________________________________________________________________ 10bn_conv1 (BatchNormalization) (None, None, None, 6 256 conv1[0][0] 11__________________________________________________________________________________________________ 12activation_1 (Activation) (None, None, None, 6 0 bn_conv1[0][0] 13__________________________________________________________________________________________________ 14pool1_pad (ZeroPadding2D) (None, None, None, 6 0 activation_1[0][0] 15__________________________________________________________________________________________________ 16max_pooling2d_1 (MaxPooling2D) (None, None, None, 6 0 pool1_pad[0][0] 17__________________________________________________________________________________________________ 18res2a_branch2a (Conv2D) (None, None, None, 6 4160 max_pooling2d_1[0][0] 19__________________________________________________________________________________________________ 20bn2a_branch2a (BatchNormalizati (None, None, None, 6 256 res2a_branch2a[0][0] 21__________________________________________________________________________________________________ 22activation_2 (Activation) (None, None, None, 6 0 bn2a_branch2a[0][0] 23__________________________________________________________________________________________________ 24res2a_branch2b (Conv2D) (None, None, None, 6 36928 activation_2[0][0] 25__________________________________________________________________________________________________ 26bn2a_branch2b (BatchNormalizati (None, None, None, 6 256 res2a_branch2b[0][0] 27__________________________________________________________________________________________________ 28activation_3 (Activation) (None, None, None, 6 0 bn2a_branch2b[0][0] 29__________________________________________________________________________________________________ 30res2a_branch2c (Conv2D) (None, None, None, 2 16640 activation_3[0][0] 31__________________________________________________________________________________________________ 32res2a_branch1 (Conv2D) (None, None, None, 2 16640 max_pooling2d_1[0][0] 33__________________________________________________________________________________________________ 34bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024 res2a_branch2c[0][0] 35__________________________________________________________________________________________________ 36bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024 res2a_branch1[0][0] 37__________________________________________________________________________________________________ 38add_1 (Add) (None, None, None, 2 0 bn2a_branch2c[0][0] 39 bn2a_branch1[0][0] 40__________________________________________________________________________________________________ 41activation_4 (Activation) (None, None, None, 2 0 add_1[0][0] 42__________________________________________________________________________________________________ 43res2b_branch2a (Conv2D) (None, None, None, 6 16448 activation_4[0][0] 44__________________________________________________________________________________________________ 45bn2b_branch2a (BatchNormalizati (None, None, None, 6 256 res2b_branch2a[0][0] 46__________________________________________________________________________________________________ 47activation_5 (Activation) (None, None, None, 6 0 bn2b_branch2a[0][0] 48__________________________________________________________________________________________________ 49res2b_branch2b (Conv2D) (None, None, None, 6 36928 activation_5[0][0] 50__________________________________________________________________________________________________ 51bn2b_branch2b (BatchNormalizati (None, None, None, 6 256 res2b_branch2b[0][0] 52__________________________________________________________________________________________________ 53activation_6 (Activation) (None, None, None, 6 0 bn2b_branch2b[0][0] 54__________________________________________________________________________________________________ 55res2b_branch2c (Conv2D) (None, None, None, 2 16640 activation_6[0][0] 56__________________________________________________________________________________________________ 57bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024 res2b_branch2c[0][0] 58__________________________________________________________________________________________________ 59add_2 (Add) (None, None, None, 2 0 bn2b_branch2c[0][0] 60 activation_4[0][0] 61__________________________________________________________________________________________________ 62activation_7 (Activation) (None, None, None, 2 0 add_2[0][0] 63__________________________________________________________________________________________________ 64res2c_branch2a (Conv2D) (None, None, None, 6 16448 activation_7[0][0] 65__________________________________________________________________________________________________ 66bn2c_branch2a (BatchNormalizati (None, None, None, 6 256 res2c_branch2a[0][0] 67__________________________________________________________________________________________________ 68activation_8 (Activation) (None, None, None, 6 0 bn2c_branch2a[0][0] 69__________________________________________________________________________________________________ 70res2c_branch2b (Conv2D) (None, None, None, 6 36928 activation_8[0][0] 71__________________________________________________________________________________________________ 72bn2c_branch2b (BatchNormalizati (None, None, None, 6 256 res2c_branch2b[0][0] 73__________________________________________________________________________________________________ 74activation_9 (Activation) (None, None, None, 6 0 bn2c_branch2b[0][0] 75__________________________________________________________________________________________________ 76res2c_branch2c (Conv2D) (None, None, None, 2 16640 activation_9[0][0] 77__________________________________________________________________________________________________ 78bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024 res2c_branch2c[0][0] 79__________________________________________________________________________________________________ 80add_3 (Add) (None, None, None, 2 0 bn2c_branch2c[0][0] 81 activation_7[0][0] 82__________________________________________________________________________________________________ 83activation_10 (Activation) (None, None, None, 2 0 add_3[0][0] 84__________________________________________________________________________________________________ 85res3a_branch2a (Conv2D) (None, None, None, 1 32896 activation_10[0][0] 86__________________________________________________________________________________________________ 87bn3a_branch2a (BatchNormalizati (None, None, None, 1 512 res3a_branch2a[0][0] 88__________________________________________________________________________________________________ 89activation_11 (Activation) (None, None, None, 1 0 bn3a_branch2a[0][0] 90__________________________________________________________________________________________________ 91res3a_branch2b (Conv2D) (None, None, None, 1 147584 activation_11[0][0] 92__________________________________________________________________________________________________ 93bn3a_branch2b (BatchNormalizati (None, None, None, 1 512 res3a_branch2b[0][0] 94__________________________________________________________________________________________________ 95activation_12 (Activation) (None, None, None, 1 0 bn3a_branch2b[0][0] 96__________________________________________________________________________________________________ 97res3a_branch2c (Conv2D) (None, None, None, 5 66048 activation_12[0][0] 98__________________________________________________________________________________________________ 99res3a_branch1 (Conv2D) (None, None, None, 5 131584 activation_10[0][0] 100__________________________________________________________________________________________________ 101bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048 res3a_branch2c[0][0] 102__________________________________________________________________________________________________ 103bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048 res3a_branch1[0][0] 104__________________________________________________________________________________________________ 105add_4 (Add) (None, None, None, 5 0 bn3a_branch2c[0][0] 106 bn3a_branch1[0][0] 107__________________________________________________________________________________________________ 108activation_13 (Activation) (None, None, None, 5 0 add_4[0][0] 109__________________________________________________________________________________________________ 110res3b_branch2a (Conv2D) (None, None, None, 1 65664 activation_13[0][0] 111__________________________________________________________________________________________________ 112bn3b_branch2a (BatchNormalizati (None, None, None, 1 512 res3b_branch2a[0][0] 113__________________________________________________________________________________________________ 114activation_14 (Activation) (None, None, None, 1 0 bn3b_branch2a[0][0] 115__________________________________________________________________________________________________ 116res3b_branch2b (Conv2D) (None, None, None, 1 147584 activation_14[0][0] 117__________________________________________________________________________________________________ 118bn3b_branch2b (BatchNormalizati (None, None, None, 1 512 res3b_branch2b[0][0] 119__________________________________________________________________________________________________ 120activation_15 (Activation) (None, None, None, 1 0 bn3b_branch2b[0][0] 121__________________________________________________________________________________________________ 122res3b_branch2c (Conv2D) (None, None, None, 5 66048 activation_15[0][0] 123__________________________________________________________________________________________________ 124bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048 res3b_branch2c[0][0] 125__________________________________________________________________________________________________ 126add_5 (Add) (None, None, None, 5 0 bn3b_branch2c[0][0] 127 activation_13[0][0] 128__________________________________________________________________________________________________ 129activation_16 (Activation) (None, None, None, 5 0 add_5[0][0] 130__________________________________________________________________________________________________ 131res3c_branch2a (Conv2D) (None, None, None, 1 65664 activation_16[0][0] 132__________________________________________________________________________________________________ 133bn3c_branch2a (BatchNormalizati (None, None, None, 1 512 res3c_branch2a[0][0] 134__________________________________________________________________________________________________ 135activation_17 (Activation) (None, None, None, 1 0 bn3c_branch2a[0][0] 136__________________________________________________________________________________________________ 137res3c_branch2b (Conv2D) (None, None, None, 1 147584 activation_17[0][0] 138__________________________________________________________________________________________________ 139bn3c_branch2b (BatchNormalizati (None, None, None, 1 512 res3c_branch2b[0][0] 140__________________________________________________________________________________________________ 141activation_18 (Activation) (None, None, None, 1 0 bn3c_branch2b[0][0] 142__________________________________________________________________________________________________ 143res3c_branch2c (Conv2D) (None, None, None, 5 66048 activation_18[0][0] 144__________________________________________________________________________________________________ 145bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048 res3c_branch2c[0][0] 146__________________________________________________________________________________________________ 147add_6 (Add) (None, None, None, 5 0 bn3c_branch2c[0][0] 148 activation_16[0][0] 149__________________________________________________________________________________________________ 150activation_19 (Activation) (None, None, None, 5 0 add_6[0][0] 151__________________________________________________________________________________________________ 152res3d_branch2a (Conv2D) (None, None, None, 1 65664 activation_19[0][0] 153__________________________________________________________________________________________________ 154bn3d_branch2a (BatchNormalizati (None, None, None, 1 512 res3d_branch2a[0][0] 155__________________________________________________________________________________________________ 156activation_20 (Activation) (None, None, None, 1 0 bn3d_branch2a[0][0] 157__________________________________________________________________________________________________ 158res3d_branch2b (Conv2D) (None, None, None, 1 147584 activation_20[0][0] 159__________________________________________________________________________________________________ 160bn3d_branch2b (BatchNormalizati (None, None, None, 1 512 res3d_branch2b[0][0] 161__________________________________________________________________________________________________ 162activation_21 (Activation) (None, None, None, 1 0 bn3d_branch2b[0][0] 163__________________________________________________________________________________________________ 164res3d_branch2c (Conv2D) (None, None, None, 5 66048 activation_21[0][0] 165__________________________________________________________________________________________________ 166bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048 res3d_branch2c[0][0] 167__________________________________________________________________________________________________ 168add_7 (Add) (None, None, None, 5 0 bn3d_branch2c[0][0] 169 activation_19[0][0] 170__________________________________________________________________________________________________ 171activation_22 (Activation) (None, None, None, 5 0 add_7[0][0] 172__________________________________________________________________________________________________ 173res4a_branch2a (Conv2D) (None, None, None, 2 131328 activation_22[0][0] 174__________________________________________________________________________________________________ 175bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024 res4a_branch2a[0][0] 176__________________________________________________________________________________________________ 177activation_23 (Activation) (None, None, None, 2 0 bn4a_branch2a[0][0] 178__________________________________________________________________________________________________ 179res4a_branch2b (Conv2D) (None, None, None, 2 590080 activation_23[0][0] 180__________________________________________________________________________________________________ 181bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024 res4a_branch2b[0][0] 182__________________________________________________________________________________________________ 183activation_24 (Activation) (None, None, None, 2 0 bn4a_branch2b[0][0] 184__________________________________________________________________________________________________ 185res4a_branch2c (Conv2D) (None, None, None, 1 263168 activation_24[0][0] 186__________________________________________________________________________________________________ 187res4a_branch1 (Conv2D) (None, None, None, 1 525312 activation_22[0][0] 188__________________________________________________________________________________________________ 189bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096 res4a_branch2c[0][0] 190__________________________________________________________________________________________________ 191bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096 res4a_branch1[0][0] 192__________________________________________________________________________________________________ 193add_8 (Add) (None, None, None, 1 0 bn4a_branch2c[0][0] 194 bn4a_branch1[0][0] 195__________________________________________________________________________________________________ 196activation_25 (Activation) (None, None, None, 1 0 add_8[0][0] 197__________________________________________________________________________________________________ 198res4b_branch2a (Conv2D) (None, None, None, 2 262400 activation_25[0][0] 199__________________________________________________________________________________________________ 200bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024 res4b_branch2a[0][0] 201__________________________________________________________________________________________________ 202activation_26 (Activation) (None, None, None, 2 0 bn4b_branch2a[0][0] 203__________________________________________________________________________________________________ 204res4b_branch2b (Conv2D) (None, None, None, 2 590080 activation_26[0][0] 205__________________________________________________________________________________________________ 206bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024 res4b_branch2b[0][0] 207__________________________________________________________________________________________________ 208activation_27 (Activation) (None, None, None, 2 0 bn4b_branch2b[0][0] 209__________________________________________________________________________________________________ 210res4b_branch2c (Conv2D) (None, None, None, 1 263168 activation_27[0][0] 211__________________________________________________________________________________________________ 212bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096 res4b_branch2c[0][0] 213__________________________________________________________________________________________________ 214add_9 (Add) (None, None, None, 1 0 bn4b_branch2c[0][0] 215 activation_25[0][0] 216__________________________________________________________________________________________________ 217activation_28 (Activation) (None, None, None, 1 0 add_9[0][0] 218__________________________________________________________________________________________________ 219res4c_branch2a (Conv2D) (None, None, None, 2 262400 activation_28[0][0] 220__________________________________________________________________________________________________ 221bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024 res4c_branch2a[0][0] 222__________________________________________________________________________________________________ 223activation_29 (Activation) (None, None, None, 2 0 bn4c_branch2a[0][0] 224__________________________________________________________________________________________________ 225res4c_branch2b (Conv2D) (None, None, None, 2 590080 activation_29[0][0] 226__________________________________________________________________________________________________ 227bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024 res4c_branch2b[0][0] 228__________________________________________________________________________________________________ 229activation_30 (Activation) (None, None, None, 2 0 bn4c_branch2b[0][0] 230__________________________________________________________________________________________________ 231res4c_branch2c (Conv2D) (None, None, None, 1 263168 activation_30[0][0] 232__________________________________________________________________________________________________ 233bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096 res4c_branch2c[0][0] 234__________________________________________________________________________________________________ 235add_10 (Add) (None, None, None, 1 0 bn4c_branch2c[0][0] 236 activation_28[0][0] 237__________________________________________________________________________________________________ 238activation_31 (Activation) (None, None, None, 1 0 add_10[0][0] 239__________________________________________________________________________________________________ 240res4d_branch2a (Conv2D) (None, None, None, 2 262400 activation_31[0][0] 241__________________________________________________________________________________________________ 242bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024 res4d_branch2a[0][0] 243__________________________________________________________________________________________________ 244activation_32 (Activation) (None, None, None, 2 0 bn4d_branch2a[0][0] 245__________________________________________________________________________________________________ 246res4d_branch2b (Conv2D) (None, None, None, 2 590080 activation_32[0][0] 247__________________________________________________________________________________________________ 248bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024 res4d_branch2b[0][0] 249__________________________________________________________________________________________________ 250activation_33 (Activation) (None, None, None, 2 0 bn4d_branch2b[0][0] 251__________________________________________________________________________________________________ 252res4d_branch2c (Conv2D) (None, None, None, 1 263168 activation_33[0][0] 253__________________________________________________________________________________________________ 254bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096 res4d_branch2c[0][0] 255__________________________________________________________________________________________________ 256add_11 (Add) (None, None, None, 1 0 bn4d_branch2c[0][0] 257 activation_31[0][0] 258__________________________________________________________________________________________________ 259activation_34 (Activation) (None, None, None, 1 0 add_11[0][0] 260__________________________________________________________________________________________________ 261res4e_branch2a (Conv2D) (None, None, None, 2 262400 activation_34[0][0] 262__________________________________________________________________________________________________ 263bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024 res4e_branch2a[0][0] 264__________________________________________________________________________________________________ 265activation_35 (Activation) (None, None, None, 2 0 bn4e_branch2a[0][0] 266__________________________________________________________________________________________________ 267res4e_branch2b (Conv2D) (None, None, None, 2 590080 activation_35[0][0] 268__________________________________________________________________________________________________ 269bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024 res4e_branch2b[0][0] 270__________________________________________________________________________________________________ 271activation_36 (Activation) (None, None, None, 2 0 bn4e_branch2b[0][0] 272__________________________________________________________________________________________________ 273res4e_branch2c (Conv2D) (None, None, None, 1 263168 activation_36[0][0] 274__________________________________________________________________________________________________ 275bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096 res4e_branch2c[0][0] 276__________________________________________________________________________________________________ 277add_12 (Add) (None, None, None, 1 0 bn4e_branch2c[0][0] 278 activation_34[0][0] 279__________________________________________________________________________________________________ 280activation_37 (Activation) (None, None, None, 1 0 add_12[0][0] 281__________________________________________________________________________________________________ 282res4f_branch2a (Conv2D) (None, None, None, 2 262400 activation_37[0][0] 283__________________________________________________________________________________________________ 284bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024 res4f_branch2a[0][0] 285__________________________________________________________________________________________________ 286activation_38 (Activation) (None, None, None, 2 0 bn4f_branch2a[0][0] 287__________________________________________________________________________________________________ 288res4f_branch2b (Conv2D) (None, None, None, 2 590080 activation_38[0][0] 289__________________________________________________________________________________________________ 290bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024 res4f_branch2b[0][0] 291__________________________________________________________________________________________________ 292activation_39 (Activation) (None, None, None, 2 0 bn4f_branch2b[0][0] 293__________________________________________________________________________________________________ 294res4f_branch2c (Conv2D) (None, None, None, 1 263168 activation_39[0][0] 295__________________________________________________________________________________________________ 296bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096 res4f_branch2c[0][0] 297__________________________________________________________________________________________________ 298add_13 (Add) (None, None, None, 1 0 bn4f_branch2c[0][0] 299 activation_37[0][0] 300__________________________________________________________________________________________________ 301activation_40 (Activation) (None, None, None, 1 0 add_13[0][0] 302__________________________________________________________________________________________________ 303res5a_branch2a (Conv2D) (None, None, None, 5 524800 activation_40[0][0] 304__________________________________________________________________________________________________ 305bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048 res5a_branch2a[0][0] 306__________________________________________________________________________________________________ 307activation_41 (Activation) (None, None, None, 5 0 bn5a_branch2a[0][0] 308__________________________________________________________________________________________________ 309res5a_branch2b (Conv2D) (None, None, None, 5 2359808 activation_41[0][0] 310__________________________________________________________________________________________________ 311bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048 res5a_branch2b[0][0] 312__________________________________________________________________________________________________ 313activation_42 (Activation) (None, None, None, 5 0 bn5a_branch2b[0][0] 314__________________________________________________________________________________________________ 315res5a_branch2c (Conv2D) (None, None, None, 2 1050624 activation_42[0][0] 316__________________________________________________________________________________________________ 317res5a_branch1 (Conv2D) (None, None, None, 2 2099200 activation_40[0][0] 318__________________________________________________________________________________________________ 319bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192 res5a_branch2c[0][0] 320__________________________________________________________________________________________________ 321bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192 res5a_branch1[0][0] 322__________________________________________________________________________________________________ 323add_14 (Add) (None, None, None, 2 0 bn5a_branch2c[0][0] 324 bn5a_branch1[0][0] 325__________________________________________________________________________________________________ 326activation_43 (Activation) (None, None, None, 2 0 add_14[0][0] 327__________________________________________________________________________________________________ 328res5b_branch2a (Conv2D) (None, None, None, 5 1049088 activation_43[0][0] 329__________________________________________________________________________________________________ 330bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048 res5b_branch2a[0][0] 331__________________________________________________________________________________________________ 332activation_44 (Activation) (None, None, None, 5 0 bn5b_branch2a[0][0] 333__________________________________________________________________________________________________ 334res5b_branch2b (Conv2D) (None, None, None, 5 2359808 activation_44[0][0] 335__________________________________________________________________________________________________ 336bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048 res5b_branch2b[0][0] 337__________________________________________________________________________________________________ 338activation_45 (Activation) (None, None, None, 5 0 bn5b_branch2b[0][0] 339__________________________________________________________________________________________________ 340res5b_branch2c (Conv2D) (None, None, None, 2 1050624 activation_45[0][0] 341__________________________________________________________________________________________________ 342bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192 res5b_branch2c[0][0] 343__________________________________________________________________________________________________ 344add_15 (Add) (None, None, None, 2 0 bn5b_branch2c[0][0] 345 activation_43[0][0] 346__________________________________________________________________________________________________ 347activation_46 (Activation) (None, None, None, 2 0 add_15[0][0] 348__________________________________________________________________________________________________ 349res5c_branch2a (Conv2D) (None, None, None, 5 1049088 activation_46[0][0] 350__________________________________________________________________________________________________ 351bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048 res5c_branch2a[0][0] 352__________________________________________________________________________________________________ 353activation_47 (Activation) (None, None, None, 5 0 bn5c_branch2a[0][0] 354__________________________________________________________________________________________________ 355res5c_branch2b (Conv2D) (None, None, None, 5 2359808 activation_47[0][0] 356__________________________________________________________________________________________________ 357bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048 res5c_branch2b[0][0] 358__________________________________________________________________________________________________ 359activation_48 (Activation) (None, None, None, 5 0 bn5c_branch2b[0][0] 360__________________________________________________________________________________________________ 361res5c_branch2c (Conv2D) (None, None, None, 2 1050624 activation_48[0][0] 362__________________________________________________________________________________________________ 363bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192 res5c_branch2c[0][0] 364__________________________________________________________________________________________________ 365add_16 (Add) (None, None, None, 2 0 bn5c_branch2c[0][0] 366 activation_46[0][0] 367__________________________________________________________________________________________________ 368activation_49 (Activation) (None, None, None, 2 0 add_16[0][0] 369__________________________________________________________________________________________________ 370global_average_pooling2d_1 (Glo (None, 2048) 0 activation_49[0][0] 371__________________________________________________________________________________________________ 372dense_1 (Dense) (None, 1024) 2098176 global_average_pooling2d_1[0][0] 373__________________________________________________________________________________________________ 374dense_2 (Dense) (None, 5) 5125 dense_1[0][0] 375================================================================================================== 376Total params: 25,691,013 377Trainable params: 2,103,301 378Non-trainable params: 23,587,712 379__________________________________________________________________________________________________ Ph·∫ßn train l·∫°i s·∫Ω c√≥ kho·∫£ng h∆°n 2 tri·ªáu tham s·ªë, ph·∫ßn layer ·ªü tr∆∞·ªõc ƒë√≥ kh√¥ng train l√† kho·∫£ng 23 tri·ªáu tham s·ªë.\nChia t·∫≠p d·ªØ li·ªáu ra th√†nh 5 ph·∫ßn, 4 ph·∫ßn l√†m t·∫≠p train, 1 ph·∫ßn l√†m t·∫≠p validation.\n1X, y, tags = dataset.dataset(data_directory, n) 2nb_classes = len(tags) 3 4 5sample_count = len(y) 6train_size = sample_count * 4 // 5 7X_train = X[:train_size] 8y_train = y[:train_size] 9Y_train = np_utils.to_categorical(y_train, nb_classes) 10X_test = X[train_size:] 11y_test = y[train_size:] 12Y_test = np_utils.to_categorical(y_test, nb_classes) ch√∫ng ta ti·∫øn h√†nh th·ª±c hi·ªán ImageDataGenerator ƒë·ªÉ c√≥ ƒë∆∞·ª£c nhi·ªÅu d·ªØ li·ªáu m·∫´u h∆°n v√† ch·ªëng overfit, trong keras ƒë√£ c√≥ s·∫µn h√†m\n1datagen = ImageDataGenerator( 2 featurewise_center=False, 3 samplewise_center=False, 4 featurewise_std_normalization=False, 5 samplewise_std_normalization=False, 6 zca_whitening=False, 7 rotation_range=45, 8 width_shift_range=0.25, 9 height_shift_range=0.25, 10 horizontal_flip=True, 11 vertical_flip=False, 12 channel_shift_range=0.5, 13 zoom_range=[0.5, 1.5], 14 brightness_range=[0.5, 1.5], 15 fill_mode=\u0026#39;reflect\u0026#39;) 16 17datagen.fit(X_train) Cu·ªëi c√πng, ch√∫ng ta s·∫Ω x√¢y d·ª±ng m√¥ h√¨nh v√† ti·∫øn h√†nh hu·∫•n luy·ªán, l∆∞u m√¥ h√¨nh. Qu√° tr√¨nh n√†y t·ªën h∆°i nhi·ªÅu th·ªùi gian.\n1 2model = net.build_model(nb_classes) 3model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#34;accuracy\u0026#34;]) 4 5# train the model on the new data for a few epochs 6 7print(\u0026#34;training the newly added dense layers\u0026#34;) 8 9samples_per_epoch = X_train.shape[0]//batch_size*batch_size 10steps_per_epoch = samples_per_epoch//batch_size 11validation_steps = X_test.shape[0]//batch_size*batch_size 12 13model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True), 14 samples_per_epoch=samples_per_epoch, 15 epochs=nb_epoch, 16 steps_per_epoch = steps_per_epoch, 17 validation_data=datagen.flow(X_test, Y_test, batch_size=batch_size), 18 validation_steps=validation_steps, 19 ) 20 21 22net.save(model, tags, model_file_prefix) Th·ª≠ download m·ªôt v√†i h√¨nh ·∫£nh tr√™n m·∫°ng v·ªÅ r·ªìi test th·ª≠ xem sao\n![H√¨nh ·∫£nh] (flower-classifition_demo.jpg)\nK·∫øt qu·∫£ kh√° t·ªët ph·∫£i kh√¥ng c√°c b·∫°n.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Apr 15, 2019","img":"","permalink":"/blog/2019-04-15-phan-loai-hoa/","series":null,"tags":["Machine learning","Deeplearning","hoa h·ªìng","hoa m·∫∑t tr·ªùi","hoa b·ªì c√¥ng anh","hoa c√∫c","hoa tulip"],"title":"Ph√¢n Lo·∫°i Hoa S·ª≠ D·ª•ng Pretrain Model"},{"categories":null,"content":" D·ª± ƒëo√°n chu·ªói th·ªùi gian C√°c thu·ªôc t√≠nh c·ªßa time series V√¨ sao ch√∫ng ta l·∫°i quan t√¢m ƒë·∫øn t√≠nh d·ª´ng c·ªßa d·ªØ li·ªáu C√°ch x√°c ƒë·ªãnh t√≠nh d·ª´ng c·ªßa d·ªØ li·ªáu Ph∆∞∆°ng ph√°p d·ª± ƒëo√°n chu·ªói th·ªùi gian c∆° b·∫£n Ph∆∞∆°ng ph√°p d·ª± ƒëo√°n d·ª±a v√†o m·∫°ng neural network S·ª≠ d·ª•ng m·∫°ng Echo State Networks D·ª± do√°n chu·ªói time series T·ªëi ∆∞u ho√° c√°c tham s·ªë Hyper parameters Trong cu·ªën The West Wing Script Book c·ªßa Aaron Sorkin, √¥ng ·∫•y ƒë√£ c√≥ m·ªôt c√¢u nh∆∞ th·∫ø n√†y \u0026ldquo;There (is) order and even great beauty in what looks like total chaos. If we look closely enough at the randomness around us, patterns will start to emerge.\u0026rdquo;. M√¨nh xin ph√©p kh√¥ng d·ªãch c√¢u n√≥i tr√™n ra, b·ªüi v√¨ m√¨nh d·ªãch kh√° t·ªá, v√† c√¢u n√≥i n√†y kh√° n·ªïi ti·∫øng (ƒë√£ ƒë∆∞·ª£c tr√≠ch d·∫´n kh√° nhi·ªÅu tr√™n c√°c b√†i vi·∫øt c·ªßa c√°c bloger kh√°c). Nh∆∞ng c√¢u n√≥i ƒë√≥ kh√° ph√π h·ª£p v·ªõi m√¥i tr∆∞·ªùng ch·ª©ng kho√°n, n∆°i m√† m·ªçi th·ª© ƒë·ªÅu kh√¥ng r√µ r√†ng v√† kh√° \u0026ldquo;h·ªón lo·∫°n\u0026rdquo;.\nD·ª± ƒëo√°n chu·ªói th·ªùi gian Gi√° c·ªï phi·∫øu tr√™n th·ªã tr∆∞·ªùng ch·ª©ng kho√°n th∆∞·ªùng ƒë∆∞·ª£c quy v√†o b√†i to√°n l√† time series. C√°c c√¥ng ty ƒë·∫ßu t∆∞ ho·∫∑c c√°c nh√† nghi√™n c·ª©u, c√°c nh√† ƒë·∫ßu t∆∞ hi·ªán nay th∆∞·ªùng s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p stochastic ho·∫∑c c√°c c·∫£i ti·∫øn c·ªßa ph∆∞∆°ng ph√°p stochastic (v√≠ d·ª• m√¥ h√¨nh ARIMA, RegARIMA,\u0026hellip;) ƒë·ªÉ ƒë∆∞a ra c√°c d·ª± ƒëo√°n h·ª£p l√Ω ph√π h·ª£p v·ªõi c√°c gi√° tr·ªã qu√° kh·ª©. M·ª•c ti√™u cu·ªëi c√πng l√† t√¨m ra m·ªôt m√¥ h√¨nh kh·∫£ dƒ© nh·∫•t ƒë·ªÉ ph·∫£n √°nh quy lu·∫≠t c·ªßa th·ªã tr∆∞·ªùng v√† s·ª≠ d·ª•ng n√≥ ƒë·ªÉ sinh ra l·ª£i nhu·∫≠n (tr·ªü n√™n gi√†u c√≥ h∆°n :)).\nC√°c thu·ªôc t√≠nh c·ªßa time series M·ªôt trong c√°c thu·ªôc t√≠nh c·ªßa chu·ªói th·ªùi gian l√† t√≠nh d·ª´ng (stationary). M·ªôt chu·ªói time series ƒë∆∞·ª£c g·ªçi l√† c√≥ t√≠nh d·ª´ng n·∫øu c√°c thu·ªôc t√≠nh c√≥ √Ω nghƒ©a th·ªëng k√™ c·ªßa n√≥ (v√≠ d·ª• nh∆∞ l√† trung b√¨nh, ƒë·ªô l·ªách chu·∫©n) kh√¥ng ƒë·ªïi theo th·ªùi gian. ·ªû ƒë√¢y, ch√∫ng ta lu·∫≠n b√†n nho nh·ªè m·ªôt ch√∫t v√¨ sao t√≠nh d·ª´ng r·∫•t quang tr·ªçng trong chu·ªói th·ªùi gian.\nTr∆∞·ªõc h·∫øt, h·∫ßu h·∫øt c√°c m√¥ h√¨nh v·ªÅ time series hi·ªán t·∫°i ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n m·ªôt gi·∫£ ƒë·ªãnh t√≠nh d·ª´ng c·ªßa chu·ªói th·ªùi gian. C√≥ nghƒ©a l√† n·∫øu chu·ªói th·ªùi gian ·ªü trong qu√° kh·ª© c√≥ m·ªôt h√†nh vi n√†o ƒë√≥, th√¨ kh·∫£ nƒÉng cao l√† n√≥ s·∫Ω l·∫∑p l·∫°i trong t∆∞∆°ng lai. Ngo√†i ra, c√°c l√Ω thuy·∫øt li√™n quan ƒë·∫øn t√≠nh d·ª´ng c·ªßa chu·ªói time series ƒë√£ ƒë∆∞·ª£c c√°c nh√† nghi√™n c·ª©u khai th√°c m·ªôt c√°ch tri·ªát ƒë·ªÉ v√† d·ªÖ r√†ng implement h∆°n l√† c√°c l√Ω thuy·∫øt v·ªÅ non-stationary trong time series.\nT√≠nh d·ª´ng ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a b·∫±ng c√°c ti√™u ch√≠ r√µ r√†ng v√† nghi√™m ng·∫∑t. Tuy nhi√™n, trong b√†i to√°n th·ª±c t·∫ø, ch√∫ng ta c√≥ th·ªÉ gi·∫£ ƒë·ªãnh r·∫±ng m·ªôt chu·ªói time series ƒë∆∞·ª£c coi l√† c√≥ t√≠nh d·ª´ng n·∫øu c√°c thu·ªôc t√≠nh th·ªëng k√™ kh√¥ng ƒë·ªïi theo th·ªùi gian, nghƒ©a l√†:\nGi√° tr·ªã trung b√¨nh kh√¥ng thay ƒë·ªïi. N·∫øu gi√° tr·ªã trung b√¨nh thay ƒë·ªïi, chu·ªói th·ªùi gian s·∫Ω c√≥ khuynh h∆∞·ªõng ƒëi l√™n ho·∫∑c ƒëi xu·ªëng. H√¨nh ·∫£nh b√™n d∆∞·ªõi, m√¥ t·∫£ tr·ª±c quan m·ªôt chu·ªói th·ªùi gian c√≥ t√≠nh d·ª´ng (trung b√¨nh kh√¥ng thay ƒë·ªïi), v√† m·ªôt chu·ªói th·ªùi gian kh√¥ng c√≥ t√≠nh d·ª´ng (trung b√¨nh thay ƒë·ªïi). Gi√° tr·ªã ph∆∞∆°ng sai kh√¥ng thay ƒë·ªïi. Thu·ªôc t√≠nh n√†y c√≤n ƒë∆∞·ª£c g·ªçi l√† ƒë·ªìng ƒë·∫≥ng (homoscedasticity). H√¨nh b√™n d∆∞·ªõi m√¥ t·∫£ m·ªôt chu·ªói c√≥ ph∆∞∆°ng sai thay ƒë·ªïi (kh√¥ng c√≥ t√≠nh d·ª´ng) v√† m·ªôt chu·ªói c√≥ ph∆∞∆°ng sai b·∫•t bi·∫øn (c√≥ t√≠nh d·ª´ng). T√≠nh t·ª± t∆∞∆°ng t·ª± kh√¥ng ph·ª• thu·ªôc v√†o th·ªùi gian V√¨ sao ch√∫ng ta l·∫°i quan t√¢m ƒë·∫øn t√≠nh d·ª´ng c·ªßa d·ªØ li·ªáu Ch√∫ng ta quan t√¢m ƒë·∫øn t√≠nh d·ª´ng c·ªßa d·ªØ li·ªáu, ƒë∆°n gi·∫£n l√† b·ªüi v√¨ n·∫øu d·ªØ li·ªáu kh√¥ng c√≥ t√≠nh d·ª´ng, ch√∫ng ta kh√¥ng th·ªÉ x√¢y d·ª±ng m√¥ h√¨nh chu·ªói th·ªùi gian (nh∆∞ ƒë√£ n√≥i ·ªü tr√™n, c√°c nghi√™n c·ª©u hi·ªán nay ƒë·ªÅu d·ª±a tr√™n m·ªôt c∆° s·ªü l√† d·ªØ li·ªáu c√≥ t√≠nh d·ª´ng). Trong tr∆∞·ªùng h·ª£p b·∫°n c√≥ trong tay d·ªØ li·ªáu thu·ªôc d·∫°ng time series, v√† m·ªôt ti√™u ch√≠ n√†o ƒë√≥ trong 3 ti√™u ch√≠ m√¨nh ƒë√£ li·ªáu k√™ ·ªü tr√™n b·ªã vi ph·∫°m, suy ra l√† d·ªØ li·ªáu c·ªßa b·∫°n kh√¥ng c√≥ t√≠nh d·ª´ng. B·∫°n ph·∫£i chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu b·∫°n ƒëang c√≥ ƒë·ªÉ cho n√≥ c√≥ t√≠nh d·ª´ng. May m·∫Øn r·∫±ng c≈©ng c√≥ nhi·ªÅu nghi√™n c·ª©u th·ª±c hi·ªán vi·ªác n√†y, v√≠ d·ª• nh∆∞ \u0026ldquo;kh·ª≠ xu h∆∞·ªõng (detrending)\u0026rdquo;, kh·ª≠ sai bi·ªát (differencing)\u0026hellip;\nN·∫øu b·∫°n m·ªõi ch·ªâ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch chu·ªói th·ªùi gian, b·∫°n s·∫Ω th·∫•y vi·ªác l√†m tr√™n kh√° l√† stupid. L√Ω thuy·∫øt t·ªët nh·∫•t hi·ªán nay cho chu·ªói th·ªùi gian l√† chia nh·ªè n√≥ ra th√†nh c√°c th√†nh ph·∫ßn nh∆∞ l√† xu h∆∞·ªõng (linear trend), m√πa v·ª• (seasonal), chu k·ª≥, v√† y·∫øu t·ªë ng·∫´u nhi√™n. D·ª± ƒëo√°n cho t·ª´ng ph·∫ßn m·ªôt, sau ƒë√≥ l·∫•y t·ªïng ch√∫ng l·∫°i.\nƒê·ªëi v·ªõi nh·ªØng ai ƒë√£ quen thu·ªôc v·ªõi bi·∫øn ƒë·ªïi Fourier, th√¨ s·∫Ω d·ªÖ d√†ng \u0026ldquo;c·∫£m\u0026rdquo; h∆°n c√°i m√¨nh v·ª´a n√≥i ·ªü tr√™n.\nC√°ch x√°c ƒë·ªãnh t√≠nh d·ª´ng c·ªßa d·ªØ li·ªáu Kh√° kh√≥ ƒë·ªÉ x√°c ƒë·ªãnh m·ªôt bi·ªÉu ƒë·ªì chu·ªói time series c√≥ t√≠nh d·ª´ng hay kh√¥ng (quan s√°t bi·ªÉu ƒë·ªì b·∫±ng m·∫Øt). Cho n√™n ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng ki·ªÉm ƒë·ªãnh Dickey-Fuller. ƒê√¢y l√† m·ªôt ki·ªÉm ƒë·ªãnh th·ªëng k√™ ƒë·ªÉ ki·ªÉm tra xem chu·ªói d·ªØ li·ªáu c√≥ t√≠nh d·ª´ng hay kh√¥ng. V·ªõi gi·∫£ thuy·∫øt null l√† chu·ªói time series l√† m·ªôt chu·ªói kh√¥ng c√≥ t√≠nh d·ª´ng. N·∫øu gi√° tr·ªã nh·ªè h∆°n m·ªôt ng∆∞·ª°ng p-value n√†o ƒë√≥ (th∆∞·ªùng l√† 0.05), ch√∫ng ta c√≥ quy·ªÅn b√°c b·ªè gi·∫£ ƒë·ªãnh null, v√† n√≥i r·∫±ng chu·ªói th·ªùi gian ƒëang c√≥ l√† c√≥ t√≠nh d·ª´ng. ·ªû b√†i vi·∫øt n√†y, m√¨nh kh√¥ng ƒë·ªÅ c·∫≠p ƒë·∫øn m√¥ h√¨nh ki·ªÉm ƒë·ªãnh - v·ªën ƒë∆∞·ª£c h·ªçc trong m√¥n x√°c xu·∫•t th·ªëng k√™. C√°c b·∫°n c√≥ nhu c·∫ßu t√¨m hi·ªÉu th√¨ c√≥ th·ªÉ search tr√™n google ho·∫∑c l√† xem l·∫°i s√°ch x√°c su·∫•t th·ªëng k√™.\nPh∆∞∆°ng ph√°p d·ª± ƒëo√°n chu·ªói th·ªùi gian c∆° b·∫£n Ph∆∞∆°ng ph√°p c∆° b·∫£n nh·∫•t, ƒë∆°n gi·∫£n nh·∫•t, v√† ƒë·ªÉ √°p d·ª•ng nh·∫•t d∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ d·ª± ƒëo√°n chu·ªói th·ªùi gian l√† moving average. M√¥ h√¨nh n√†y th·ª±c hi·ªán t√≠nh trung b√¨nh c·ªßa t gi√° tr·ªã cu·ªëi c√πng l√†m gi√° tr·ªã d·ª± ƒëo√°n c·ªßa ƒëi·ªÉm ti·∫øp theo. V√≠ d·ª• nh∆∞ ƒë·ªÉ d·ª± ƒëo√°n gi√° ch·ª©ng kho√°n c·ªßa ng√†y th·ª© 2 c·ªßa tu·∫ßn ti·∫øp theo, ch√∫ng ta s·∫Ω l·∫•y trung b√¨nh gi√° ƒë√≥ng c·ªßa c·ªßa 5 ng√†y tr∆∞·ªõc ƒë√≥ (gi√° t·ª´ th·ª© hai ƒë·∫øn th·ª© s√°u tu·∫ßn n√†y).\nƒê·∫øn ƒë√¢y, c√°c b·∫°n ƒë√£ c√≥ m·ªôt s·ªë hi·ªÉu bi·∫øt v·ªÅ time series. M·ªôt m√¥ h√¨nh kh√° n·ªïi ti·∫øng l√† ARIMA ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng nhi·ªÅu ƒë·ªÉ ph√¢n t√≠ch v√† d·ª± b√°o. C√°ch th·ª±c hi·ªán c·ªßa m√¥ h√¨nh tr√™n ƒë∆∞·ª£c tr√¨nh b√†y t√≥m g·ªçn trong h√¨nh m√¥ t·∫£ b√™n d∆∞·ªõi.\nPh∆∞∆°ng ph√°p d·ª± ƒëo√°n d·ª±a v√†o m·∫°ng neural network Th·ª±c t·∫ø, c√≥ r·∫•t nhi·ªÅu m·∫°ng neural network ƒë√£ ƒë∆∞·ª£c √°p d·ª•ng ƒë·ªÉ d·ª± ƒëo√°n m√¥ h√¨nh ch·ª©ng kho√°n. C√°c b·∫°n c√≥ th·ªÉ t√¨m ƒë·ªçc l·∫°i c√°c b√†i vi·∫øt tr∆∞·ªõc ƒë√¢y c·ªßa m√¨nh v·ªÅ s·ª≠ d·ª•ng LSTM trong d·ª± b√°o ch·ª©ng kho√°n. M√¥ h√¨nh ch·ª©ng kho√°n b·∫±ng m·∫°ng neural network n√≥i chung ph·∫£i ƒë·ªëi m·∫∑t v·ªõi m·ªôt v·∫•n ƒë·ªÅ kh√° \u0026ldquo;x∆∞∆°ng x·∫©u\u0026rdquo; l√† x·ª≠ l√Ω nhi·ªÖu v√† vanishing gradients. Trong ƒë√≥, vi·ªác x·ª≠ l√Ω vanishing gradients l√† quan tr·ªçng nh·∫•t. B·∫£n ch·∫•t c·ªßa m·∫°ng neural network l√† t·ªëi ∆∞u ho√° h√†m lan truy·ªÅn ng∆∞·ª£c b·∫±ng c√°ch s·ª≠ d·ª•ng ƒë·∫°o h√†m gi·ªØa c√°c l·ªõp layer ƒë·ªÉ ch√∫ng \u0026lsquo;h·ªçc\u0026rsquo;. Tr·∫£i qua nhi·ªÅu layer, gi√° tr·ªã c·ªßa ƒë·∫°o h√†m s·∫Ω c√†ng ng√†y nh·ªè d·∫ßn v√†o x·∫•p x·ªâ b·∫±ng 0. Gi·∫£ s·ª≠ ch√∫ng ta c√≥ m·ªôt m√¥ h√¨nh c√≥ 100 l·ªõp hidden layer, ch√∫ng ta nh√¢n 100 l·∫ßn s·ªë 0.1 v·ªõi nhau v√† boom, gi√° tr·ªã cu·ªëi c√πng chung ta nh·∫≠n ƒë∆∞·ª£c l√† 0, nghƒ©a l√† ch√∫ng ta ch·∫≥ng h·ªçc ƒë∆∞·ª£c c√°i g√¨ c·∫£.\nMay m·∫Øn thay, t·ªõi th·ªùi ƒëi·ªÉm hi·ªán t·∫°i, ch√∫ng ta c√≥ 3 c√°ch ƒë·ªÉ x·ª≠ l√Ω v·∫•n ƒë·ªÅ tr√™n:\nClipping gradients\nLSTM (Long Short Term Memory) ho·∫∑c GRU (Gate Recurrent Units)\nEcho states RNNs\nK·ªπ thu·∫≠t clipping gradients s·ª≠ d·ª•ng m·ªôt m·∫πo l√† khi gi√° tr·ªã ƒë·∫°o h√†m qu√° l·ªõn ho·∫∑c qu√° nh·ªè, ch√∫ng ta s·∫Ω kh√¥ng l·∫•y ƒë·∫°o h√†m n·ªØa. K·ªπ thu·∫≠t n√†y tho·∫°t nh√¨n c√≥ v·∫ª hay, nh∆∞ng n√≥ kh√¥ng th·ªÉ ngƒÉn ch√∫ng ta m·∫•t m√°t th√¥ng tin v√† ƒë√¢y l√† m·ªôt √Ω t∆∞·ªüng kh√° t·ªá.\nRNN (LSTM ho·∫∑c GRU) l√† m·ªôt k·ªπ thu·∫≠t kh√°c l√† ƒëi·ªÅu ch·ªânh c√°c k·∫øt n·ªëi theo m·ªôt v√†i quy lu·∫≠t nh·∫•t ƒë·ªãnh, v√≠ d·ª• output c·ªßa layer t·∫ßng 1 c√≥ th·ªÉ l√† input c·ªßa layer t·∫ßng 10, ch·ª© kh√¥ng nh·∫•t thi·∫øt l√† input c·ªßa layer t·∫ßng 2 nh∆∞ c√°ch th√¥ng th∆∞·ªùng. K·ªπ thu·∫≠t n√†y kh√° t·ªët v·ªÅ m·∫∑t l√Ω thuy·∫øt. Tuy nhi√™n, c√≥ m·ªôt v·∫•n ƒë·ªÅ kh√° l·ªõn khi s·ª≠ d·ª•ng l√† ch√∫ng ta ph·∫£i t√≠nh to√°n k·ªπ c√°c k·∫øt n·ªëi ƒë·ªÉ ƒë·∫£m b·∫£o h·ªá th·ªëng ho·∫°t ƒë·ªông ·ªïn ƒëinh. M√¥ h√¨nh ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n k·ªπ thu·∫≠t n√†y kh√° b·ª±, l√†m cho thu·∫≠t to√°n ch·∫°y ch·∫≠m. Ngo√†i ra, t√≠nh h·ªôi t·ª• c·ªßa thu·∫≠t to√°n kh√¥ng ƒë∆∞·ª£c ƒë·∫£m b·∫£o. M√¥ h√¨nh LSTM ƒë∆°n gi·∫£n m√¨nh c√≥ ƒë·ªÉ ·ªü h√¨nh b√™n d∆∞·ªõi.\nM·∫°ng echo states network, l√† m·ªôt m√¥ h√¨nh m·ªõi ƒë∆∞·ª£c nghi√™n c·ª©u g·∫ßn ƒë√¢y, b·∫£n ch·∫•t n√≥ l√† m·ªôt m·∫£ng recurrent neural network v·ªõi c√°c hidden layer li√™n k·∫øt \u0026ldquo;l·ªèng l·∫ªo\u0026rdquo; v·ªõi nhau. L·ªõp n√†y ƒë∆∞·ª£c g·ªçi l√† \u0026lsquo;reservoir\u0026rsquo; (nh∆∞ h√¨nh m√¥ t·∫£ b√™n d∆∞·ªõi).\nTrong m√¥ h√¨nh m·∫°ng echo state network, ch√∫ng ta ch·ªâ c·∫ßn hu·∫•n luy·ªán l·∫°i tr·ªçng s·ªë c·ªßa l·ªõp output, vi·ªác n√†y gi√∫p ch√∫ng ta r√∫t ng·∫Øn th·ªùi gian hu·∫•n luy·ªán m√¥ h√¨nh, v√† tƒÉng t·ªëc qusa tr√¨nh training.\nS·ª≠ d·ª•ng m·∫°ng Echo State Networks V·ªÅ nguy√™n l√Ω ho·∫°t ƒë·ªông c·ªßa m√¥ h√¨nh n√†y, m√¨nh s·∫Ω kh√¥ng ƒë·ªÅ c·∫≠p ·ªü ƒë√¢y. Ch·ªß ƒë·ªÅ v·ªÅ m·∫°ng Echo State Networks m√¨nh s·∫Ω nghi√™n c·ª©u k·ªπ l∆∞·ª°ng v√† ƒë·ªÅ c·∫≠p ·ªü trong b√†i vi·∫øt s·∫Øp t·ªõi. M·ª•c ti√™u c·ªßa b√†i vi·∫øt n√†y l√† s·ª≠ d·ª•ng m√¥ h√¨nh Echo State Networks trong b√†i to√°n time series.\nD·ª± do√°n chu·ªói time series Tr∆∞·ªõc ti√™n, ch√∫ng ta s·∫Ω import m·ªôt s·ªë th∆∞ vi·ªán c·∫ßn thi·∫øt, th∆∞ vi·ªán ESN ƒë√£ c√≥ s·∫µn t·∫°i ƒë∆∞·ªùng d·∫´n pyESN, c√°c b·∫°n download v·ªÅ r·ªìi d√πng\n1 2 3import numpy as np 4import pandas as pd 5import seaborn as sns 6from matplotlib import pyplot as plt 7import warnings 8warnings.filterwarnings(\u0026#39;ignore\u0026#39;) 9 10# This is the library for the Reservoir Computing got it by: https://github.com/cknd/pyESN 11from pyESN import ESN Ti·∫øp theo ch√∫ng ta s·∫Ω ƒë·ªçc file\n1 2data = open(\u0026#34;amazon.txt\u0026#34;).read().split() 3data = np.array(data).astype(\u0026#39;float64\u0026#39;) Ch√∫ng ta s·∫Ω x√¢y d·ª±ng m·ªôt m√¥ h√¨nh ESN ƒë∆°n gi·∫£n\n1 2n_reservoir= 500 3sparsity=0.2 4rand_seed=23 5spectral_radius = 1.2 6noise = .0005 7 8 9esn = ESN(n_inputs = 1, 10 n_outputs = 1, 11 n_reservoir = n_reservoir, 12 sparsity=sparsity, 13 random_state=rand_seed, 14 spectral_radius = spectral_radius, 15 noise=noise) 16 17\t``` 18 19ƒê·ªÉ ƒë∆°n gi·∫£n, m√¨nh s·∫Ω t·∫°o m√¥ h√¨nh v·ªõi d·ªØ li·ªáu t√†o lao nh∆∞ sau:input l√† m·ªôt vector to√†n s·ªë 1, output l√† c√°c ƒëi·ªÉm d·ªØ li·ªáu c·ªßa m√¨nh. Cho m√¥ h√¨nh ESN h·ªçc v·ªõi s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ l√† 1500, sau ƒë√≥ s·∫Ω d·ª± ƒëo√°n 10 ƒëi·ªÉm d·ªØ li·ªáu ti·∫øp theo. V·ªõi b∆∞·ªõc nh·∫£y l√† 10, l·∫∑p 10 l·∫ßn. Sau qu√° tr√¨nh l·∫∑p, m√¨nh thu ƒë∆∞·ª£c 100 ƒëi·ªÉm d·ª± ƒëo√°n 20 21 22```python 23trainlen = 1500 24future = 10 25futureTotal=100 26pred_tot=np.zeros(futureTotal) 27 28for i in range(0,futureTotal,future): 29 pred_training = esn.fit(np.ones(trainlen),data[i:trainlen+i]) # d·ªØ li·ªáu t·ª´ ng√†y i ƒë·∫øn ng√†y i + trainlen 30 prediction = esn.predict(np.ones(future)) 31 pred_tot[i:i+future] = prediction[:,0] # d·ª± ƒëo√°n cho ng√†y i+ trainlen + 1 ƒë·∫øn ng√†y i + trainlen + future 32 33 34\t``` 35 36V·∫Ω m√¥ h√¨nh c√πi m√≠a c·ªßa m√¨nh m·ªõi l√†m l√™n ƒë·ªÉ xem d·ªØ li·ªáu d·ª± ƒëo√°n v√† d·ªØ li·ªáu th·ª±c t·∫ø ch√™nh l·ªách nh∆∞ th·∫ø n√†o 37 38```python 39plt.figure(figsize=(16,8)) 40plt.plot(range(1000,trainlen+futureTotal),data[1000:trainlen+futureTotal],\u0026#39;b\u0026#39;,label=\u0026#34;Data\u0026#34;, alpha=0.3) 41#plt.plot(range(0,trainlen),pred_training,\u0026#39;.g\u0026#39;, alpha=0.3) 42plt.plot(range(trainlen,trainlen+futureTotal),pred_tot,\u0026#39;k\u0026#39;, alpha=0.8, label=\u0026#39;Free Running ESN\u0026#39;) 43 44lo,hi = plt.ylim() 45plt.plot([trainlen,trainlen],[lo+np.spacing(1),hi-np.spacing(1)],\u0026#39;k:\u0026#39;, linewidth=4) 46 47plt.title(r\u0026#39;Ground Truth and Echo State Network Output\u0026#39;, fontsize=25) 48plt.xlabel(r\u0026#39;Time (Days)\u0026#39;, fontsize=20,labelpad=10) 49plt.ylabel(r\u0026#39;Price ($)\u0026#39;, fontsize=20,labelpad=10) 50plt.legend(fontsize=\u0026#39;xx-large\u0026#39;, loc=\u0026#39;best\u0026#39;) 51sns.despine() 52plt.show() ƒê·ªô ph·ª©c t·∫°p c·ªßa m√¥ h√¨nh l√† kh√° nh·ªè khi so v·ªõi m√¥ h√¨nh RNN. L√Ω do l√† v·ªÅ b·∫£n ch·∫•t, ch√∫ng ta ch·ªâ hu·∫•n luy·ªán tr√™n tr·ªçng s·ªë c·ªßa output layer, n√≥ l√† m·ªôt h√†m tuy·∫øn t√≠nh. Do v·∫≠y, ƒë·ªô ph·ª©c t·∫°p t√≠nh to√°n ch·ªâ gi·ªëng nh∆∞ l√† vi·ªác t√≠nh m·ªôt h√†m h·ªìi quy tuy·∫øn t√≠nh. Trong th·ª±c t·∫ø, ƒë·ªô ph·ª©c t·∫°p t√≠nh to√°n s·∫Ω l√† O(N) v·ªõi N l√† ·ªë l∆∞·ª£ng hidden unit trong reservoir.\nT·ªëi ∆∞u ho√° c√°c tham s·ªë Hyper parameters ·ªû ph·∫ßn tr∆∞·ªõc, ch√∫ng ta set ƒë·∫°i c√°c tham s·ªë spectral_radius = 1.2 v√† noise = .0005. Trong th·ª±c t·∫ø, ch√∫ng ta ph·∫£i t√¨m c√°c si√™u tham s·ªë n√†y b·∫±ng c√°ch t√¨m ra m√¥ h√¨nh tr·∫£ v·ªÅ MSE l√† nh·ªè nh·∫•t.\nS·ª≠ d·ª•ng k·ªπ thu·∫≠t Grid Search v·ªõi ng∆∞·ª°ng spectrum_radius n·∫±m trong ƒëo·∫°n [0.5, 1.5] v√† noise n·∫±m trong ƒëo·∫°n noise [0.0001, 0.01], ch√∫ √Ω l√† c√°c b·∫°n c√≥ th·ªÉ search ·ªü ƒëo·∫°n l·ªõn h∆°n. K·∫øt qu·∫£ thu ƒë∆∞·ª£c:\n1def MSE(yhat, y): 2 return np.sqrt(np.mean((yhat.flatten() - y)**2)) 3 4\tn_reservoir= 500 5sparsity = 0.2 6rand_seed = 23 7radius_set = [0.9, 1, 1.1] 8noise_set = [ 0.001, 0.004, 0.006] 9 10radius_set = [0.5, 0.7, 0.9, 1, 1.1,1.3,1.5] 11noise_set = [ 0.0001, 0.0003,0.0007, 0.001, 0.003, 0.005, 0.007,0.01] 12 13 14 15radius_set_size = len(radius_set) 16noise_set_size = len(noise_set) 17 18trainlen = 1500 19future = 2 20futureTotal= 100 21 22loss = np.zeros([radius_set_size, noise_set_size]) 23 24for l in range(radius_set_size): 25 rho = radius_set[l] 26 for j in range(noise_set_size): 27 noise = noise_set[j] 28 29 pred_tot=np.zeros(futureTotal) 30 31 esn = ESN(n_inputs = 1, 32 n_outputs = 1, 33 n_reservoir = n_reservoir, 34 sparsity=sparsity, 35 random_state=rand_seed, 36 spectral_radius = rho, 37 noise=noise) 38 39 for i in range(0,futureTotal,future): 40 pred_training = esn.fit(np.ones(trainlen),data[i:trainlen+i]) 41 prediction = esn.predict(np.ones(future)) 42 pred_tot[i:i+future] = prediction[:,0] 43 44 loss[l, j] = MSE(pred_tot, data[trainlen:trainlen+futureTotal]) 45 print(\u0026#39;rho = \u0026#39;, radius_set[l], \u0026#39;, noise = \u0026#39;, noise_set[j], \u0026#39;, MSE = \u0026#39;, loss[l][j] ) K·∫øt qu·∫£\n1 2(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 20.367056799629353) 3(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 22.44956008062169) 4(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 24.574909979223666) 5(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 25.862558649155638) 6(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 29.882933676750657) 7(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 32.63942614291128) 8(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 36.441245548726) 9(\u0026#39;rho = \u0026#39;, 0.5, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 44.77637915282457) 10(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 19.560517902720054) 11(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 20.12742795009036) 12(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 20.81801427735713) 13(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 21.26142619965559) 14(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 23.270880660885513) 15(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 26.061347331527354) 16(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 30.298361979419834) 17(\u0026#39;rho = \u0026#39;, 0.7, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 39.17074955771047) 18(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 18.612970860501118) 19(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 18.681815816990774) 20(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.835785386862582) 21(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.982346096338105) 22(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 20.81632098844061) 23(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 24.60968377490799) 24(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 30.231007189936882) 25(\u0026#39;rho = \u0026#39;, 0.9, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 41.28587340583505) 26(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 18.23852181110818) 27(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 18.27010615150326) 28(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.36078059388596) 29(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.47920006882226) 30(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 20.613227951906246) 31(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 25.153712109142973) 32(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 31.700838835741898) 33(\u0026#39;rho = \u0026#39;, 1, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 44.23736750779224) 34(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 17.981571756431556) 35(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 18.009398312163942) 36(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.09054736889828) 37(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.218795249276663) 38(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 20.82610561349463) 39(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 26.272452530336505) 40(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 33.91532767431614) 41(\u0026#39;rho = \u0026#39;, 1.1, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 48.22002405965967) 42(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 17.72839068197909) 43(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 17.799908079894703) 44(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 17.92917208443474) 45(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.143905288756557) 46(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 22.20343747458126) 47(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 30.05977704513729) 48(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 40.56654468067572) 49(\u0026#39;rho = \u0026#39;, 1.3, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 59.43231026660687) 50(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.0001, \u0026#39;, MSE = \u0026#39;, 17.627409489404897) 51(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.0003, \u0026#39;, MSE = \u0026#39;, 17.835052829116567) 52(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.0007, \u0026#39;, MSE = \u0026#39;, 18.100099619981393) 53(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.001, \u0026#39;, MSE = \u0026#39;, 18.481406587483956) 54(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.003, \u0026#39;, MSE = \u0026#39;, 24.887601182697498) 55(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.005, \u0026#39;, MSE = \u0026#39;, 36.34166374510305) 56(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.007, \u0026#39;, MSE = \u0026#39;, 50.99612645577753) 57(\u0026#39;rho = \u0026#39;, 1.5, \u0026#39;, noise = \u0026#39;, 0.01, \u0026#39;, MSE = \u0026#39;, 75.94229622771246) K·∫øt qu·∫£ thu ƒë∆∞·ª£c l√† gi√° tr·ªã MSE t·ªët nh·∫•t l√† spectrum radius = 1.5 v√† nnoise = 0.0001\nTh·ª≠ d·ª± ƒëo√°n gi√° c·ªï phi·∫øu c·ªßa t·∫≠p ƒëo√†n th·∫ø gi·ªõi di ƒë·ªông (M√£ c·ªï phi·∫øu MWG) xem sao\n·ªû h√¨nh tr√™n, m√¨nh kh√¥ng ti·∫øn h√†nh grid search m√† l·∫•y l·∫°i c√°c hyper parameters c≈© ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh. K·∫øt qu·∫£ nh∆∞ h√¨nh tr√™n m√¨nh th·∫•y c≈©ng kh√° t·ªët r·ªìi, n√™n m√¨nh kh√¥ng ti·∫øn h√†nh grid search l·∫°i ƒë·ªÉ t√¨m k·∫øt qu·∫£ t·ªët h∆°n.\nD·ª±a v√†o k·∫øt qu·∫£ ch√∫ng ta thu ƒë∆∞·ª£c, c√≥ th·ªÉ n√≥i r·∫±ng m√¥ h√¨nh ESN d·ª± ƒëo√°n kh√° t·ªët d·ªØ li·ªáu thu·ªôc d·∫°ng time series v·ªõi ƒë·ªô h·ªón lo·∫°n cao. ƒê√¢y l√† m·ªôt k·∫øt lu·∫≠n nh·ªè c·ªßa m√¨nh d·ª±a v√†o b·∫±ng ch·ª©ng tr√™n vi·ªác m√¨nh test tr√™n t·∫≠p d·ªØ li·ªáu ng·∫´u nhi√™n m√† m√¨nh c√≥.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Apr 4, 2019","img":"","permalink":"/blog/2019-04-04-predicting-stock-prices-with-echo-state-networks/","series":null,"tags":["machine learning","deep learning","neural network","amazone","th·∫ø gi·ªõi di ƒë·ªông","mwg"],"title":"D·ª± ƒêo√°n Gi√° C·ªï Phi·∫øu B·∫±ng M√¥ H√¨nh M·∫°ng Echo State Networks"},{"categories":null,"content":" H∆∞·ªõng d·∫´n ban ƒë·∫ßu B·∫°n hu·∫•n luy·ªán m·ªôt h√¨nh m·∫•t h∆°n 12 ti·∫øng ƒë·ªìng h·ªì. M·ªçi th·ª© kh√° ·ªïn: loss function gi·∫£m. Nh∆∞ng khi b·∫°n mang m√¥ h√¨nh ra predict th√¨ ƒëi·ªÅu t·ªìi t·ªá nh·∫•t x·∫£y ra: T·∫•t c·∫£ tr·∫£ v·ªÅ ƒë·ªÅu l√† 0, kh√¥ng c√≥ c√°i n√†o nh·∫≠n d·∫°ng ch√≠nh x√°c c·∫£. \u0026ldquo;ƒêi·ªÅu g√¨ ƒë√£ x·∫£y ra, b·∫°n ƒë√£ l√†m g√¨ sai?\u0026rdquo;. B·∫°n h·ªèi m√°y t√≠nh, n√≥ kh√¥ng tr·∫£ l·ªùi b·∫°n. B·∫°n ƒë·∫≠p b√†n, ƒë·∫≠p gh·∫ø trong c∆°n t·ª©c gi·∫≠n v√† ch·∫≥ng gi·∫£i quy·∫øt ƒë∆∞·ª£c ƒëi·ªÅu g√¨ c·∫£.\nC√≥ r·∫•t nhi·ªÅu nguy√™n nh√¢n g√¢y ra v·∫•n ƒë·ªÅ n√†y. Vi·ªác c·∫ßn l√†m c·ªßa c√°c b·∫°n l√† ph·∫£i t√¨m ra ch√≠nh x√°c nguy√™n nh√¢n v√† \u0026ldquo;s·ª≠a\u0026rdquo; n√≥, sau ƒë√≥ t·ªën h∆°n 12 ti·∫øng ƒë·ªìng h·ªì ƒë·ªÉ hu·∫•n luy·ªán l·∫°i :), r·ªìi l·∫°i s·ª≠a \u0026hellip;\nH∆∞·ªõng d·∫´n ban ƒë·∫ßu N·∫øu b·∫°n g·∫∑p t√¨nh tr·∫°ng nh∆∞ ph·∫ßn m√¥ t·∫£ ·ªü tr√™n, b·∫°n h√£y th·ª±c hi·ªán c√°c b∆∞·ªõc m√¨nh m√¥ t·∫£ b√™n d∆∞·ªõi th·ª≠ xem v·∫•n ƒë·ªÅ c·ªßa b·∫°n l√† g√¨?\nB·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh b·∫±ng m·ªôt m√¥ h√¨nh ƒë∆°n gi·∫£n m√† b·∫°n bi·∫øt ch·∫Øc r·∫±ng n√≥ ho·∫°t ƒë·ªông t·ªët v·ªõi t·∫≠p d·ªØ li·ªáu b·∫°n ƒëang c√≥. V√≠ d·ª•, trong b√†i to√°n object detection, h√£y s·ª≠ d·ª•ng m√¥ h√¨nh VGG. V√† b·∫°n h√£y c·ªë g·∫Øng s·ª≠a d·ª•ng standard loss n·∫øu c√≥ th·ªÉ.\nB·ªè qua nh·ªØng th·ª© r√¢u ria nh∆∞ l√† regularization ho·∫∑c data augmentation. H√£y t·∫≠p trung v√†o x√¢y d·ª±ng m·ªôt m√¥ h√¨nh cho m·ªôt k·∫øt qu·∫£ kh·∫£ quan c√°i ƒë√£, sau ƒë√≥ m·ªõi c·∫£i ti·∫øn b·∫±ng c√°c th·ª© r√¢u ria tr√™n sau.\nN·∫øu b·∫°n finetuning m·ªôt m√¥ h√¨nh, b·∫°n h√£y ki·ªÉm tra th·∫≠t k·ªπ qu√° tr√¨nh ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu. Ch·∫Øc ch·∫Øn r·∫±ng qu√° tr√¨nh ti·ªÅn x·ª≠ l√Ω c·ªßa b·∫°n gi·ªëng y chang qu√° tr√¨nh ti·ªÅn x·ª≠ l√Ω c·ªßa m√¥ h√¨nh g·ªëc.\nCh·∫Øc ch·∫Øn 100% r·∫±ng gi√° tr·ªã ƒë·∫ßu v√†o l√† ƒë√∫ng.\nB·∫Øt ƒë·∫ßu b·∫±ng m·ªôt t·∫≠p sample nh·ªè (t·ª´ 2 ƒë·∫øn 20 m·∫´u). Hu·∫•n luy·ªán n√≥ ƒë·∫øn khi b·ªã overfit v√† b·ªï sung th√™m m·∫´u hu·∫•n luy·ªán sau khi m√¥ h√¨nh c·ªßa b·∫°n b·ªã overfit.\nB·ªï sung th√™n c√°c y·∫øu t·ªë r√¢u ria nh∆∞ augmentation/regularization, custom loss functions, th·ª≠ v·ªõi m·ªôt m√¥ h√¨nh ph·ª©c t·∫°p h∆°n.\nN·∫øu nh·ªØng c√°ch tr√™n v·∫´n kh√¥ng th√†nh c√¥ng. M√¥ h√¨nh v·∫´n tr·∫£ v·ªÅ gi√° tr·ªã zero. B·∫°n c√≥ th·ªÉ m·∫Øc ph·∫£i m·ªôt s·ªë l·ªói ƒë∆∞·ª£c li·ªát k√™ b√™n d∆∞·ªõi.\nKi·ªÉm tra r·∫±ng d·ªØ li·ªáu c·ªßa b·∫°n ƒë∆∞a v√†o m·∫°ng neural netwok th·∫≠t s·ª± c√≥ √Ω nghƒ©a v√† ƒë√∫ng. V√≠ d·ª•, h√£y ƒë·∫£m b·∫£o r·∫±ng b·∫°n kh√¥ng nh·∫ßm l·∫´n / swap gi√° tr·ªã gi·ªØa width v√† height c·ªßa h√¨nh ·∫£nh, ho·∫∑c m·ªôt l√Ω do n√†o ƒë√≥ b·∫°n ƒë∆∞a v√†o m·ªôt zero image, ho·∫∑c b·∫°n ch·ªâ hu·∫•n luy·ªán duy nh·∫•t m·ªôt batch (v√≠ d·ª• d·ªØ li·ªáu b·∫°n l·ªõn, chia l√†m 10 batch, v√† code nh·∫ßm sao ƒë√≥ ch·ªâ ƒë∆∞a input l√† batch s·ªë 1 v√†o).\nM·ªôt tr∆∞·ªùng h·ª£p n·ªØa l√† khi input v√† output c·ªßa b·∫°n ch·∫≥ng c√≥ m·ªëi li√™n h·ªá g√¨ v·ªõi nhau, v√† kh√¥ng c√°ch n√†o nh·∫≠n bi·∫øt r·∫±ng n√≥ ph·ª• thu·ªôc nhau b·ªüi v√¨ b·∫£n ch·∫•t c·ªßa d·ªØ li·ªáu l√† nh∆∞ v·∫≠y, ho·∫∑c input c·ªßa b·∫°n ƒëang c√≥ ch∆∞a ƒë·ªß ch·ª©ng c·ª© ƒë·ªÉ suy ra output. M·ªôt v√≠ d·ª• c·ªßa tr∆∞·ªùng h·ª£p n√†y l√† gi√° ch·ª©ng kho√°ng.\nKi·ªÉm tra k·ªπ d·ªØ li·ªáu train ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng c√≥ ƒë√°nh nh√£n sai\nKi·ªÉm tra xem d·ªØ li·ªáu c√≥ b·ªã m·∫•t c√¢n b·∫±ng kh√¥ng. H√£y s·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t ƒë·ªÉ c√¢n b·∫±ng l·∫°i d·ªØ li·ªáu.\nƒê·∫£m b·∫£o r·∫±ng trong 1 batch ch·ª©a d·ªØ li·ªáu c·ªßa nhi·ªÅu h∆°n 1 nh√£n. H√£y x√°o tr·ªôn ng·∫´u nhi√™n d·ªØ li·ªáu ƒë·ªÉ tr√°nh l·ªói n√†y.\nB√†i b√°o https://arxiv.org/abs/1609.04836 ch·ªâ ra r·∫±ng khi b·∫°n hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi batch size l·ªõn c√≥ th·ªÉ l√†m gi·∫£m t√≠nh t·ªïng qu√°t c·ªßa m√¥ h√¨nh.\nKho√° h·ªçc CS231 ƒë√£ ch·ªâ ra m·ªôt l·ªói kh√° ph·ªï bi·∫øn: \u0026ldquo;B·∫•t k·ª≥ m·ªôt qu√° tr√¨nh ti·ªÅn x·ª≠ l√Ω n√†o c≈©ng ph·∫£i th·ª±c hi·ªán tr√™n t·∫≠p train, v√† sau ƒë√≥ √°p d·ª•ng v√†o t·∫≠p validation,test\u0026rdquo;. V√≠ d·ª•, ch√∫ng ta t√≠nh trung b√¨nh tr√™n to√†n b·ªô d·ªØ li·ªáu, r·ªìi sau ƒë√≥ chia t·∫≠p d·ªØ li·ªáu th√†nh train, test, predict l√† kh√¥ng ƒë√∫ng. H√†nh ƒë·ªông ƒë√∫ng l√† chia t·∫≠p d·ªØ li·ªáu th√†nh train, test, vali tr∆∞·ªõc, sau ƒë√≥ t√≠nh gi√° tr·ªã trung b√¨nh tr√™n t·ª´ng k√™nh m√†u tr√™n t·∫≠p train, r·ªìi m·ªõi l·∫•y gi√° tr·ªã trung b√¨nh ƒë√≥ √°p cho t·∫≠p test v√† t·∫≠p validate.\nM·ªôt v·∫•n ƒë·ªÅ kh√°c c√≥ th·ªÉ l√† \u0026ldquo;Look for correct loss at chance performance\u0026rdquo;:\nV√≠ d·ª•, v·ªõi t·∫≠p d·ªØ li·ªáu CIFAR-10 s·ª≠ d·ª•ng softmax classifier, ·ªü l·∫ßn ƒë·∫ßu ti√™n, gi√° tr·ªã loss mong ƒë·ª£i c·ªßa ch√∫ng ta l√† 2.303, b·ªüi v√¨ c√≥ 1 th·∫±ng ƒë√∫ng, 10 th·∫±ng sai, x√°c su·∫•t l√† 1/10 = 0.1. softmax loss l√† -ln(0.1) = 2.302.\nV·ªõi d·ªØ li·ªáu CIFAR-10 d√πng SVM, ·ªü l·∫ßn l·∫∑p ƒë·∫ßu ti√™n, gi√° tr·ªã loss ch√∫ng ta k·ª≥ v·ªçng l√† 9 (v·ªõi m·ªói l·ªõp sai, gi√° tr·ªã margin s·∫Ω l√† 1).\nN·∫øu c√°c gi√° tr·ªã tr·∫£ ra kh√¥ng gi·ªëng nh∆∞ mong ƒë·ª£i, v·∫•n ƒë·ªÅ x·∫£y ra l√† do gi√° tr·ªã init kh√¥ng ƒë√∫ng.\nM·ªôt v·∫•n ƒë·ªÅ n·ªØa l√† khi tƒÉng gi√° tr·ªã regularization th√¨ c≈©ng ƒë·ªìng th·ªùi tƒÉng gi√° tr·ªã loss. =\u0026gt; N·∫øu loss kh√¥ng tƒÉng =\u0026gt; c√≥ v·∫•n ƒë·ªÅ.\nB√†i vi·∫øt ƒë∆∞·ª£c l∆∞·ª£c d·ªãch t·ª´ https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607?fbclid=IwAR1Qj6jJW87oKi_LR7xWMDOMZDTx8xwLZEhCCMuvOw63ztwdD1MknZVjm_Q\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Apr 2, 2019","img":"","permalink":"/blog/2019-04-02-37-reason-neural-network-not-working/","series":null,"tags":["machine learning","deep learning","neural network"],"title":"C√°c L√Ω Do M·∫°ng Neural Network Kh√¥ng Ho·∫°t ƒê·ªông Kh√¥ng Ch√≠nh X√°c"},{"categories":null,"content":" Tr√≠ tu·ªá nh√¢n t·∫°o D·ªØ li·ªáu l·ªõn M√°y h·ªçc v√† m·ªëi quan h·ªá v·ªõi Tr√≠ tu·ªá nh√¢n t·∫°o c√πng D·ªØ li·ªáu l·ªõn M·ªëi quan h·ªá gi·ªØa ML v·ªõi AI v√† Big Data Trong v√†i nƒÉm tr·ªü l·∫°i ƒë√¢y (kho·∫£ng t·ª´ 2013) truy·ªÅn th√¥ng trong v√† ngo√†i n∆∞·ªõc c√≥ kh√° nhi·ªÅu b√†i vi·∫øt gi·∫≠t t√≠t v·ªÅ ‚ÄúC√°ch m·∫°ng c√¥ng nghi·ªáp l·∫ßn th·ª© t∆∞‚Äù hay ‚ÄúTh·ªùi ƒë·∫°i c√¥ng nghi·ªáp 4.0‚Äù. C√πng v·ªõi c√°c c·ª•m t·ª´ n√†y, ‚ÄúTr√≠ tu·ªá nh√¢n t·∫°o‚Äù, ‚ÄúM√°y h·ªçc‚Äù, ‚ÄúD·ªØ li·ªáu l·ªõn‚Äù l·∫°i ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn v·ªõi t·∫ßn su·∫•t cao h∆°n. V·∫≠y th√¨ nh·ªØng thu·∫≠t ng·ªØ n√†y c√≥ √Ω nghƒ©a g√¨ v√† gi·ªØa ch√∫ng c√≥ m·ªëi li√™n h·ªá n√†o v·ªõi nhau hay kh√¥ng? Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω c√πng t√¨m hi·ªÉu.\nTr√≠ tu·ªá nh√¢n t·∫°o NƒÉm 2016, trong ‚ÄúTr·∫≠n th√°ch ƒë·∫•u c·ªßa Google DeepMind‚Äù ƒë∆∞·ª£c t·ªï ch·ª©c t·∫°i H√†n Qu·ªëc, AlphaGo (m·ªôt ph·∫ßn m·ªÅm ch∆°i c·ªù v√¢y tr√™n m√°y t√≠nh ƒë∆∞·ª£c x√¢y d·ª±ng b·ªüi Google DeepMind) ƒë√£ d√†nh chi·∫øn th·∫Øng 4/5 v√°n tr∆∞·ªõc Lee Sedol (ng∆∞·ªùi t·ª´ng 18 l·∫ßn v√¥ ƒë·ªãch gi·∫£i c·ªù v√¢y th·∫ø gi·ªõi) l√† s·ª± ki·ªán quan tr·ªçng khi·∫øn con ng∆∞·ªùi c√≥ th·ªÉ tin t∆∞·ªüng v√†o t∆∞∆°ng lai v√† s·ª©c m·∫°nh c·ªßa tr√≠ tu·ªá nh√¢n t·∫°o.\nSau khi tr·∫≠n ƒë·∫•u k·∫øt th√∫c, ch√≠nh ph·ªß H√†n Qu·ªëc c√¥ng b·ªë r·∫±ng h·ªç s·∫Ω ƒë·∫ßu t·ª´ 863 tri·ªáu USD (kho·∫£ng 1 ngh√¨n t·ª∑ won) v√†o nghi√™n c·ª©u tr√≠ tu·ªá nh√¢n t·∫°o trong v√≤ng v√†i nƒÉm ti·∫øp theo.\nT√≠nh t·ªõi nay, l∆∞·ª£ng d·ªØ li·ªáu c√°c tr·∫≠n ƒë·∫•u c·ªù v√¢y ƒë∆∞·ª£c nh·∫≠n v√†o gi√∫p AlphaGO c√≥ kinh nghi·ªám t∆∞∆°ng ƒë∆∞∆°ng v·ªõi 80 nƒÉm ch∆°i c·ªù v√¢y li√™n t·ª•c. M·ªôt con s·ªë ƒë√°ng ng·∫°c nhi√™n v√† ng∆∞·ª°ng m·ªô.\nNh∆∞ v·∫≠y tr√≠ tu·ªá nh√¢n t·∫°o l√† g√¨?\nTr√≠ tu·ªá nh√¢n t·∫°o (AI - Artificial Intelligence) l√† m·ªôt nh√°nh nghi√™n c·ª©u trong lƒ©nh v·ª±c khoa h·ªçc m√°y t√≠nh v√† t·ª´ l√¢u ƒë√£ ƒë∆∞·ª£c r·∫•t nhi·ªÅu c√°c nh√† nghi√™n c·ª©u quan t√¢m. Thu·∫≠t ng·ªØ AI ƒë∆∞·ª£c ƒë·∫∑t b·ªüi nh√† khoa h·ªçc m√°y t√≠nh ng∆∞·ªùi M·ªπ - John McCarthy v√†o nƒÉm 1956 t·∫°i H·ªôi ngh·ªã Dartmouth. Cho ƒë·∫øn th·ªùi ƒëi·ªÉm hi·ªán t·∫°i th√¨ c√≥ kh√° nhi·ªÅu nh·ªØng ph√°t bi·ªÉu kh√°c nhau v·ªÅ AI b·ªüi c√°c chuy√™n gia, ch·∫≥ng h·∫°n nh∆∞:\nAI l√† khoa h·ªçc nghi√™n c·ª©u gi√∫p t·∫°o ra m√°y t√≠nh c√≥ kh·∫£ nƒÉng suy nghƒ©, ƒë·∫ßy tr√≠ tu·ªá nh∆∞ t√™n c·ªßa ch√≠nh n√≥ (Haugeland, 1985).\nAI l√† khoa h·ªçc nghi√™n c·ª©u c√°c ho·∫°t ƒë·ªông tr√≠ n√£o th√¥ng qua c√°c m√¥ h√¨nh t√≠nh to√°n (Chaniaka v√† McDemott, 1985).\nAI l√† khoa h·ªçc nghi√™n c·ª©u c√°ch ƒë·ªÉ m√°y t√≠nh c√≥ th·ªÉ th·ª±c hi·ªán ƒë∆∞·ª£c nh·ªØng c√¥ng vi·ªác m√† con ng∆∞·ªùi l√†m t·ªët h∆°n m√°y (Rich v√† Knight, 1991).\nAI l√† khoa h·ªçc nghi√™n c·ª©u c√°c m√¥ h√¨nh m√°y t√≠nh c√≥ th·ªÉ nh·∫≠n th·ª©c, l·∫≠p lu·∫≠n v√† h√†nh ƒë·ªông (Winston, 1992).\nAI l√† khoa h·ªçc nghi√™n c·ª©u c√°c h√†nh vi th√¥ng minh m√¥ ph·ªèng c√°c v·∫≠t th·ªÉ nh√¢n t·∫°o (Nilsson, 1998)\nAI l√† khoa h·ªçc nghi√™n c·ª©u c√°c h√†nh vi th√¥ng minh nh·∫±m gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ ƒë∆∞·ª£c ƒë·∫∑t ra ƒë·ªëi v·ªõi c√°c ch∆∞∆°ng tr√¨nh m√°y t√≠nh (H·ªçc vi·ªán K·ªπ thu·∫≠t Qu√¢n s·ª±).\nNh∆∞ v·∫≠y, t·ª´ nh·ªØng ƒë·ªãnh nghƒ©a tr√™n ch√∫ng ta c√≥ th·ªÉ r√∫t ra ƒë·ªãnh nghƒ©a t·ªïng qu√°t r·∫±ng tr√≠ tu·ªá nh√¢n t·∫°o hay tr√≠ th√¥ng minh nh√¢n t·∫°o l√† tr√≠ tu·ªá ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·ªüi b·∫•t k·ª≥ m·ªôt h·ªá th·ªëng nh√¢n t·∫°o n√†o. H·ªá th·ªëng ƒë√≥ s·∫Ω m√¥ ph·ªèng c√°c qu√° tr√¨nh ho·∫°t ƒë·ªông tr√≠ tu·ªá c·ªßa con ng∆∞·ªùi, bao g·ªìm qu√° tr√¨nh h·ªçc t·∫≠p, l·∫≠p lu·∫≠n v√† t·ª± s·ª≠a l·ªói. Do ƒë√≥, tr√≠ th√¥ng minh nh√¢n t·∫°o li√™n quan ƒë·∫øn c√°ch h√†nh x·ª≠, s·ª± h·ªçc h·ªèi v√† kh·∫£ nƒÉng th√≠ch ·ª©ng th√¥ng minh c·ªßa m√°y m√≥c n√≥i chung v√† m√°y t√≠nh n√≥i ri√™ng.\nC√°ch ƒë√¢y v√†i nƒÉm, ƒë·ªëi v·ªõi ph·∫ßn ƒë√¥ng ch√∫ng ta ‚Äì nh·ªØng ng∆∞·ªùi kh√¥ng nghi√™n c·ª©u chuy√™n s√¢u v·ªÅ AI s·∫Ω cho r·∫±ng AI l√† m·ªôt ph∆∞∆°ng th·ª©c ƒë·ªÉ nh√¢n b·∫£n con ng∆∞·ªùi b·∫±ng m√°y m√≥c v√† ƒë∆∞·ª£c ·ª©ng d·ª•ng trong ch·∫ø t·∫°o robot. Tuy nhi√™n AI hi·ªán t·∫°i kh√¥ng ph·∫£i ch·ªâ l√† nh·ªØng con robot m√† n√≥ c√≥ th·ªÉ bi·ªÉu hi·ªán d∆∞·ªõi b·∫•t c·ª© h√¨nh d·∫°ng n√†o, th·∫≠m ch√≠ v√¥ h√¨nh v√¥ d·∫°ng, nh·∫±m cung c·∫•p l·ªùi gi·∫£i cho c√°c v·∫•n ƒë·ªÅ c·ªßa cu·ªôc s·ªëng th·ª±c t·∫ø tr√™n h·∫ßu h·∫øt c√°c lƒ©nh v·ª±c, ch·∫≥ng h·∫°n nh∆∞:\nTrong lƒ©nh v·ª±c chƒÉm s√≥c s·ª©c kh·ªèe: AI g√≥p ph·∫ßn c·∫£i thi·ªán t√¨nh tr·∫°ng s·ª©c kh·ªèe b·ªánh nh√¢n, v√† gi√∫p gi·∫£m chi ph√≠ ƒëi·ªÅu tr·ªã. M·ªôt trong nh·ªØng h·ªá th·ªëng c√¥ng ngh·ªá chƒÉm s√≥c s·ª©c kh·ªèe t·ªët nh·∫•t ph·∫£i k·ªÉ ƒë·∫øn l√† IBM Watson, ƒë∆∞·ª£c m·ªánh danh l√† ‚ÄúB√°c sƒ© bi·∫øt tu·ªët‚Äù khi m√† h·ªá th·ªëng n√†y c√≥ kh·∫£ nƒÉng hi·ªÉu ƒë∆∞·ª£c c√°c ng√¥n ng·ªØ t·ª± nhi√™n v√† c√≥ kh·∫£ nƒÉng ph·∫£n h·ªìi c√°c c√¢u h·ªèi ƒë∆∞·ª£c y√™u c·∫ßu ho·∫∑c cho ph√©p b·ªánh nh√¢n tra c·ª©u th√¥ng tin v·ªÅ tinh h√¨nh s·ª©c kho·∫ª c·ªßa m√¨nh. IBM Watson c√≥ th·ªÉ l∆∞·ªõt duy·ªát c√πng l√∫c h√†ng tri·ªáu h·ªì s∆° b·ªánh √°n ƒë·ªÉ cung c·∫•p cho c√°c b√°c sƒ© nh·ªØng l·ª±a ch·ªçn ƒëi·ªÅu tr·ªã d·ª±a tr√™n b·∫±ng ch·ª©ng ch·ªâ trong v√≤ng v√†i gi√¢y nh·ªù kh·∫£ nƒÉng t·ªïng h·ª£p d·ªØ li·ªáu kh·ªïng l·ªì v√† t·ªëc ƒë·ªô x·ª≠ l√Ω m·∫°nh m·∫Ω. ‚ÄúB√°c sƒ© bi·∫øt tu·ªët‚Äù khai th√°c d·ªØ li·ªáu b·ªánh nh√¢n v√† c√°c ngu·ªìn d·ªØ li·ªáu s·∫µn c√≥ kh√°c nh·∫±m t·∫°o ra gi·∫£ thuy·∫øt v√† t·ª´ ƒë√≥ x·∫≠y d·ª±ng m·ªôt l∆∞·ª£c ƒë·ªì ƒëi·ªÉm tin c·∫≠y gi√∫p ‚ÄúB√°c sƒ© th·∫≠t‚Äù ƒë∆∞a ra quy·∫øt ƒë·ªãnh ƒëi·ªÅu tr·ªã cu·ªëi c√πng. Ngo√†i ra, ·ª©ng d·ª•ng AI n·ªïi b·∫≠c kh√°c trong lƒ©nh v·ª±c n√†y c·∫ßn ph·∫£i k·ªÉ ƒë·∫øn l√† chatbot - ch∆∞∆°ng tr√¨nh m√°y t√≠nh tr·ª±c tuy·∫øn ƒë·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi v√† h·ªó tr·ª£ kh√°ch h√†ng, s·∫Øp x·∫øp c√°c cu·ªôc h·∫πn ho·∫∑c tr·ª£ gi√∫p b·ªánh nh√¢n th√¥ng qua qu√° tr√¨nh thanh to√°n v√† c√°c tr·ª£ l√Ω y t·∫ø ·∫£o cung c·∫•p ph·∫£n h·ªìi y t·∫ø c∆° b·∫£n.\nTrong lƒ©nh v·ª±c kinh doanh: C√°c t√°c v·ª• m√† con ng∆∞·ªùi th·ª±c hi·ªán l·∫∑p ƒëi l·∫∑p l·∫°i gi·ªù ƒë√¢y ƒë√£ ƒë∆∞·ª£c t·ª± ƒë·ªông ho√° quy tr√¨nh b·∫±ng robot. C√°c thu·∫≠t to√°n Machine Learning ƒë∆∞·ª£c t√≠ch h·ª£p tr√™n c√°c n·ªÅn t·∫£ng ph√¢n t√≠ch v√† CRM (Customer Relationship Management - qu·∫£n l√Ω quan h·ªá kh√°ch h√†ng) ƒë·ªÉ kh√°m ph√° c√°c th√¥ng tin v·ªÅ c√°ch ph·ª•c v·ª• kh√°ch h√†ng t·ªët h∆°n. Chatbots ƒë∆∞·ª£c t√≠ch h·ª£p tr√™n c√°c trang web nh·∫±m cung c·∫•p d·ªãch v·ª• ngay l·∫≠p t·ª©c cho kh√°ch h√†ng. M·ªôt s·ªë h·ªá th·ªëng tr·ª£ l√Ω ·∫£o n·ªïi ti·∫øng gi√∫p s·∫Øp x·∫øp, nh·∫Øc cu·ªôc h·ªçp, t√¨m ki·∫øm th√¥ng tin nh∆∞ Google Assistant, Alexa, Siri. Hi·ªán nay c√°c h·ªá th·ªëng n√†y ƒë√£ b·∫Øt ƒë·∫ßu ƒë∆∞·ª£c t√≠ch h·ª£p v√†o trong c√°c thi·∫øt b·ªã gia d·ª•ng nh∆∞ m√°y gi·∫∑t, t·ªß l·∫°nh, l√≤ vi s√≥ng, ‚Ä¶ gi√∫p ng∆∞·ªùi s·ª≠ d·ª•ng c√≥ th·ªÉ ƒëi·ªÅu khi·ªÉn thi·∫øt b·ªã b·∫±ng c√¢u l·ªánh tho·∫°i.\nTrong lƒ©nh v·ª±c gi√°o d·ª•c: C√¥ng ngh·ªá th·ª±c t·∫ø ·∫£o l√†m thay ƒë·ªïi c√°ch d·∫°y v√† h·ªçc. Sinh vi√™n c√≥ th·ªÉ ƒëeo k√≠nh VR v√† c√≥ c·∫£m gi√°c nh∆∞ ƒëang ng·ªìi trong l·ªõp nghe gi·∫£ng b√†i hay nh·∫≠p vai ƒë·ªÉ ch·ª©ng ki·∫øn nh·ªØng tr·∫≠n ƒë√°nh gi·∫£ l·∫≠p, ng·∫Øm nh√¨n di t√≠ch, ƒëi·ªÅu n√†y gi√∫p mang l·∫°i c·∫£m x√∫c v√† ghi nh·ªõ s√¢u s·∫Øc n·ªôi dung h·ªçc. Ho·∫∑c khi ƒë√†o t·∫°o ngh·ªÅ phi c√¥ng, h·ªçc vi√™n ƒëeo k√≠nh s·∫Ω th·∫•y ph√≠a tr∆∞·ªõc l√† cabin v√† h·ªçc l√°i m√°y bay nh∆∞ th·∫≠t ƒë·ªÉ th·ª±c h√†nh gi√∫p gi·∫£m thi·ªÉu r·ªßi ro trong qu√° tr√¨nh bay th·∫≠t.\nTrong lƒ©nh v·ª±c t√†i ch√≠nh: AI √°p d·ª•ng cho c√°c ·ª©ng d·ª•ng t√†i ch√≠nh c√° nh√¢n nh∆∞ Mint hay Turbo Tax gi√∫p tƒÉng c∆∞·ªùng c√°c ƒë·ªãnh ch·∫ø t√†i ch√≠nh.\nTrong lƒ©nh v·ª±c ph√°p lu·∫≠t: Qu√° tr√¨nh kh√°m ph√°, ch·ªçn l·ªçc th√¥ng qua c√°c t√†i li·ªáu trong lu·∫≠t ph√°p th∆∞·ªùng √°p ƒë·∫£o ƒë·ªëi v·ªõi con ng∆∞·ªùi. T·ª± ƒë·ªông h√≥a qu√° tr√¨nh n√†y gi√∫p ti·∫øt ki·ªám th·ªùi gian v√† qu√° tr√¨nh l√†m vi·ªác hi·ªáu qu·∫£ h∆°n. C√°c tr·ª£ l√Ω ·∫£o gi√∫p tr·∫£ l·ªùi c√°c c√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c l·∫≠p tr√¨nh s·∫µn.\nTrong lƒ©nh v·ª±c s·∫£n xu·∫•t: ƒê√¢y l√† lƒ©nh v·ª±c ƒëi ƒë·∫ßu trong vi·ªác k·∫øt h·ª£p robot v√†o lu·ªìng c√¥ng vi·ªác. Robot c√¥ng nghi·ªáp ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ th·ª±c hi·ªán c√°c nhi·ªám v·ª• ƒë∆°n l·∫ª v√† ƒë√£ ƒë∆∞·ª£c t√°ch ra kh·ªèi con ng∆∞·ªùi. Xe t·ª± ƒë·ªông l√°i Tesla l√† m·ªôt ·ª©ng d·ª•ng ƒëi·ªÉn h√¨nh trong lƒ©nh v·ª±c n√†y.\nTrong lƒ©nh v·ª±c b·∫£o m·∫≠t th√¥ng tin: r·∫•t nhi·ªÅu h·ªá th·ªëng nh·∫≠n di·ªán v√† b·∫£o m·∫≠t th√¥ng minh ƒë∆∞·ª£c x√¢y d·ª±ng, ph·∫£i k·ªÉ ƒë·∫øn nh∆∞ FaceID - b·∫£o m·∫≠t th√¥ng qua nh·∫≠n di·ªán khu√¥n m·∫∑t c·ªßa Apple, Facebook v·ªõi kh·∫£ nh·∫≠n di·ªán khu√¥n m·∫∑t ƒë·ªÉ g·ª£i √Ω tag. B√™n c·∫°nh c√°c n∆∞·ªõc ph∆∞∆°ng T√¢y th√¨ Trung Qu·ªëc hi·ªán ƒëang l√† qu·ªëc gia ƒëi ƒë·∫ßu trong vi·ªác s·ª≠ d·ª•ng AI ƒë·ªÉ nh·∫≠n di·ªán v√† qu·∫£n l√Ω c√¥ng d√¢n.\nT·ª´ nh·ªØng ·ª©ng d·ª•ng tr√™n ta c√≥ th·ªÉ th·∫•y r·∫±ng n√≥i ƒë·∫øn AI l√† n√≥i v·ªÅ n√£o b·ªô ch·ª© kh√¥ng ph·∫£i l√† n√≥i v·ªÅ m·ªôt c∆° th·ªÉ, l√† ph·∫ßn m·ªÅm ch·ª© kh√¥ng ph·∫£i l√† ph·∫ßn c·ª©ng.\nD·ªØ li·ªáu l·ªõn M·ªôt c√°ch t·ªïng qu√°t th√¨ d·ªØ li·ªáu l√† th√¥ng tin d∆∞·ªõi d·∫°ng k√Ω hi·ªáu, ch·ªØ vi·∫øt, ch·ªØ s·ªë, h√¨nh ·∫£nh, √¢m thanh ho·∫∑c d·∫°ng t∆∞∆°ng t·ª±. T·ª´ th·∫ø k·ª∑ th·ª© 3 tr∆∞·ªõc CN, Th∆∞ vi·ªán Alexandria ƒë∆∞·ª£c coi l√† n∆°i ch·ª©a ƒë·ª±ng to√†n b·ªô ki·∫øn th·ª©c c·ªßa lo√†i ng∆∞·ªùi. Ng√†y nay, t·ªïng l∆∞·ª£ng d·ªØ li·ªáu tr√™n to√†n th·∫ø gi·ªõi ƒë·ªß ƒë·ªÉ chia ƒë·ªÅu cho m·ªói ƒë·∫ßu ng∆∞·ªùi m·ªôt l∆∞·ª£ng nhi·ªÅu g·∫•p 320 l·∫ßn l∆∞·ª£ng d·ªØ li·ªáu m√† c√°c s·ª≠ gia tin r·∫±ng Th∆∞ vi·ªán Alexandria t·ª´ng l∆∞u tr·ªØ ‚Äì ∆∞·ªõc t√≠nh v√†o kho·∫£ng 120 exabyte. C√°c nh√† th·ªëng k√™ cho r·∫±ng, n·∫øu t·∫•t c·∫£ nh·ªØng d·ªØ li·ªáu n√†y ƒë∆∞·ª£c ghi v√†o ƒëƒ©a CD v√† x·∫øp ch·ªìng ch√∫ng l√™n nhau th√¨ s·∫Ω c√≥ t·ªõi 5 ch·ªìng ƒëƒ©a m√† m·ªói ch·ªìng ƒë·ªÅu c√≥ ƒë·ªô cao b·∫±ng kho·∫£ng c√°ch t·ª´ Tr√°i ƒê·∫•t ƒë·∫øn M·∫∑t TrƒÉng.\nS·ª± b√πng n·ªï d·ªØ li·ªáu n√†y ch·ªâ m·ªõi xu·∫•t hi·ªán g·∫ßn ƒë√¢y. C√°ch ƒë√¢y kh√¥ng l√¢u, v√†o nƒÉm 2000, ch·ªâ m·ªôt ph·∫ßn t∆∞ l∆∞·ª£ng d·ªØ li·ªáu l∆∞u tr·ªØ tr√™n to√†n th·∫ø gi·ªõi ·ªü d·∫°ng k·ªπ thu·∫≠t s·ªë, ba ph·∫ßn t∆∞ c√≤n l·∫°i ƒë∆∞·ª£c ng∆∞·ªùi ta l∆∞u tr√™n gi·∫•y t·ªù, phim, v√† c√°c ph∆∞∆°ng ti·ªán analog kh√°c. Nh∆∞ng do l∆∞·ª£ng d·ªØ li·ªáu k·ªπ thu·∫≠t s·ªë b√πng n·ªï qu√° nhanh ‚Äì c·ª© 3 nƒÉm l·∫°i tƒÉng g·∫•p ƒë√¥i, l√†m cho t·ªâ l·ªá n√†y nhanh ch√≥ng ƒë·∫£o ng∆∞·ª£c. Hi·ªán nay, ch·ªâ d∆∞·ªõi 2% t·ªïng l∆∞·ª£ng d·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c chuy·ªÉn sang l∆∞u tr·ªØ ·ªü d·∫°ng k·ªπ thu·∫≠t s·ªë.\nD∆∞·ªõi ƒë√¢y l√† m·ªôt v√†i v√≠ d·ª• nh·ªè minh ho·∫° cho s·ª± d√πng n·ªï c·ªßa d·ªØ li·ªáu hi·ªán nay:\nTheo Forbes, l∆∞·ª£ng d·ªØ li·ªáu m√† ng∆∞·ªùi d√πng t·∫°o ra m·ªói ng√†y l√† 2.5 t·ª∑ t·ª∑ bytes, m·ªôt con s·ªë r·∫•t ƒë√°ng kinh ng·∫°c v√† d·ª± ƒëo√°n con s·ªë n√†y s·∫Ω ti·∫øp t·ª•c b√πng n·ªï n·ªØa c√πng v·ªõi s·ª± ph√°t tri·ªÉn c·ªßa Internet v·∫°n v·∫≠t (IoT ‚Äì Internet of thing), khi m√† h·ªá th·ªëng c√°c thi·∫øt b·ªã th√¥ng minh ƒë∆∞·ª£c k·∫øt n·ªëi v√† t∆∞∆°ng t√°c v·ªõi nhau c≈©ng nh∆∞ t∆∞∆°ng t√°c v·ªõi ng∆∞·ªùi d√πng, ƒë·ªìng th·ªùi thu th·∫≠p d·ªØ li·ªáu. D·ª± b√°o c√≥ kho·∫£ng 200 t·ª∑ thi·∫øt b·ªã nh∆∞ th·∫ø v√†o nƒÉm 2020. Gi·∫£ s·ª≠ ch·ªâ x√©t ƒë·∫øn thi·∫øt b·ªã t√¨m ki·∫øm b·∫±ng gi·ªçng n√≥i, hi·ªán t·∫°i:\nC√≥ 33 tri·ªáu thi·∫øt b·ªã qua gi·ªçng n√≥i ƒëang l∆∞u th√¥ng.\n8 tri·ªáu ng∆∞·ªùi d√πng ƒëi·ªÅu khi·ªÉn gi·ªçng n√≥i m·ªói th√°ng.\nC√°c c√¢u l·ªánh t√¨m ki·∫øm b·∫±ng gi·ªçng n√≥i tr√™n Google trong nƒÉm 2016 tƒÉng 35 l·∫ßn so v·ªõi nƒÉm 2008.\nTheo th·ªëng k√™, hi·ªán nay c√≥ h∆°n 7 t·ª∑ ng∆∞·ªùi s·ª≠ d·ª•ng internet. Trung b√¨nh Google x·ª≠ l√Ω h∆°n 40.000 t√¨m ki·∫øm m·ªói gi√¢y (t·ª©c kho·∫£ng 3.5 t·ª∑ t√¨m ki·∫øm m·ªói ng√†y, n·∫øu t√≠nh c·∫£ nh·ªØng c·ªï m√°y t√¨m ki·∫øm kh√°c ngo·∫°i tr·ª´ Google th√¨ con s·ªë n√†y l√™n t·ªõi 5 t·ª∑ l∆∞·ª£t/ng√†y, 100 t·ª∑ l∆∞·ª£t/th√°ng) v√† nh·ªØng con s·ªë n√†y s·∫Ω ti·∫øp t·ª•c tƒÉng l√™n theo t·ª´ng gi√¢y.\nR·∫•t ƒë√¥ng ng∆∞·ªùi y√™u th√≠ch c√°c ph∆∞∆°ng ti·ªán truy·ªÅn th√¥ng x√£ h·ªôi v√† dƒ© nhi√™n vi·ªác s·ª≠ d·ª•ng ch√∫ng c≈©ng s·∫Ω t·∫°o ra d·ªØ li·ªáu. Theo b√°o c√°o Data Never Sle√©p 5.0 c·ªßa Domo, tr√™n c√°c ph∆∞∆°ng ti·ªán truy·ªÅn th√¥ng c·ª© m·ªói m·ªôt ph√∫t s·∫Ω c√≥ (ngu·ªìn http://www.internetlivestats.com/google-search-statistics/):\n527.760 b·ª©c ·∫£nh ƒë∆∞·ª£c chia s·∫ª b·ªüi ng∆∞·ªùi s·ª≠ d·ª•ng Snapchat .\n456.000 tweet ƒë∆∞·ª£c g·ª≠i l√™n Twitter.\n46.740 b·ª©c ·∫£nh ƒë∆∞·ª£c ƒëƒÉng b·ªüi ng∆∞·ªùi d√πng Instagram.\nH∆°n 120 ng∆∞·ªùi c√≥ c√¥ng vi·ªác ·ªïn ƒë·ªãnh tham gia LinkedIn.\nV·ªõi kho·∫£ng 2 t·ª∑ ng∆∞·ªùi d√πng, Facebook v·∫´n l√† m·∫°ng x√£ h·ªôi l·ªõn nh·∫•t h√†nh tinh v√† d∆∞·ªõi ƒë√¢y l√† c√°c s·ªë li·ªáu li√™n quan ƒë·∫øn Facebook (ngu·ªìn http://newsroom.fb.com/company-info/):\nH∆°n 900 tri·ªáu ng∆∞·ªùi th·∫≠t s·ª± s·ª≠ d·ª•ng Facebook m·ªói ng√†y, 82.8% trong s·ªë ƒë√≥ ·ªü ngo√†i M·ªπ v√† Canada.\n307 tri·ªáu / 2 t·ª∑ l√† ng∆∞·ªùi Ch√¢u √Çu.\nC·ª© m·ªói gi√¢y l·∫°i c√≥ 5 t√†i kho·∫£n m·ªõi ƒë∆∞·ª£c t·∫°o ra.\n510.000 b√¨nh lu·∫≠n ƒë∆∞·ª£c ƒëƒÉng t·∫£i v√† 293.000 tr·∫°ng th√°i ƒë∆∞·ª£c c·∫≠p nh·∫≠t m·ªói ph√∫t.\nH∆°n 300 tri·ªáu b·ª©c ·∫£nh ƒë∆∞·ª£c t·∫£i l√™n m·ªói ng√†y.\n15.000 ·∫£nh GIF ƒë∆∞·ª£c g·ª≠i th√¥ng qua Facebook Messenger.\nC≈©ng thu·ªôc s·ªü h·ªØu c·ªßa Facebook, Instagram c≈©ng c√≥ nh·ªØng con s·ªë ·∫•n t∆∞·ª£ng:\n600 tri·ªáu ng∆∞·ªùi d√πng.\n400 tri·ªáu ng∆∞·ªùi ho·∫°t ƒë·ªông m·ªói ng√†y.\n100 tri·ªáu ng∆∞·ªùi s·ª≠ d·ª•ng t√≠nh nƒÉng Stories m·ªói ng√†y.\nLi√™n quan ƒë·∫øn s·ªë l∆∞·ª£ng ng∆∞·ªùi d√πng v√† d·ªØ li·ªáu ch√∫ng ta kh√¥ng th·ªÉ kh√¥ng nh·∫Øc ƒë·∫øn Youtube khi m√† c·ª© m·ªói m·ªôt ph√∫t s·∫Ω c√≥ kho·∫£ng 300 gi·ªù video ƒë∆∞·ª£c ƒëƒÉng t·∫£i tr√™n Youtube (ngu·ªìn https://www.youtube.com/yt/about/press/).\nTrong th·ªùi ƒë·∫°i c√¥ng ngh·ªá, vi·ªác th√¥ng qua c√°c trang web h·∫πn h√≤ ƒë·ªÉ t√¨m n·ª≠a c√≤n l·∫°i kh√¥ng c√≤n l√† ƒëi·ªÅu xa l·∫°. V·ªõi h∆°n 20 t·ª∑ l∆∞·ª£t k·∫øt ƒë√¥i, Tinder x·ª©ng ƒë√°ng l√† nh·ªãp c·∫ßu c√¥ng ngh·ªá th√†nh c√¥ng b·∫≠c nh·∫•t hi·ªán t·∫°i. C·ª© m·ªói ph√∫t tr√¥i qua Tinder c√≥ kho·∫£ng 990.000 l∆∞·ª£t vu·ªët v√† h∆°n 26 tri·ªáu l∆∞·ª£t h·∫πn h√≤ m·ªói ng√†y.\nNgo√†i vi·ªác li√™n k·∫øt, trao ƒë·ªïi v·ªõi nhau qua m·∫°ng x√£ h·ªôi, trong c√¥ng vi·ªác m·ªçi ng∆∞·ªùi th∆∞·ªùng s·ª≠ d·ª•ng email, skype ƒë·ªÉ th∆∞ t·ª´, li√™n l·∫°c. T√≠nh ƒë·∫øn nƒÉm 2019 c√≥ kho·∫£ng 9 t·ª∑ ng∆∞·ªùi s·ª≠ d·ª•ng email v√† d∆∞·ªõi ƒë√¢y l√† m·ªôt v√†i con s·ªë th·ªëng k√™ c√°c s·ª± ki·ªán x·∫£y ra trong m·ªôt ph√∫t:\nNg∆∞·ªùi d√πng g·ª≠i ƒëi 16 tri·ªáu vƒÉn b·∫£n.\n156 tri·ªáu email ƒë∆∞·ª£c g·ª≠i ƒëi v·ªõi kho·∫£ng 16 tri·ªáu vƒÉn b·∫£n.\n103.447.520 th∆∞ r√°c ƒë∆∞·ª£c g·ª≠i ƒëi.\n154.200 cu·ªôc g·ªçi Skype.\nKh√¥ng c√≤n qu√° kh√≥ khƒÉn trong vi·ªác l∆∞u gi·ªØ c√°c kho·∫£nh kh·∫Øc, ng√†y nay khi m√† b·∫•t c·ª© ai c≈©ng c√≥ th·ªÉ s·ªü h·ªØu m·ªôt chi·∫øc ƒëi·ªán tho·∫°i th√¥ng minh (smartphone) v√† ai c≈©ng l√† nhi·∫øp ·∫£nh gia, c·ª© nh∆∞ th·∫ø c√≥ h√†ng ngh√¨n t·ª∑ b·ª©c ·∫£nh ƒë∆∞·ª£c cho ra ƒë·ªùi v√† l∆∞u tr·ªØ tr√™n ƒëi·ªán tho·∫°i.\nTh√¥ng qua nh·ªØng v√≠ d·ª• v·ª´a n√™u c√≥ th·ªÉ ch√∫ng ta s·∫Ω nghƒ© r·∫±ng d·ªØ li·ªáu l·ªõn thu·∫ßn tu√Ω ch·ªâ l√† v·∫•n ƒë·ªÅ v·ªÅ k√≠ch c·ª°, v√† n·∫øu ƒëi·ªÅu n√†y l√† ƒë√∫ng th√¨ d·ªØ li·ªáu bao nhi√™u ƒë∆∞·ª£c cho l√† ‚Äúl·ªõn‚Äù?\nƒê·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y ta quay l·∫°i m·ªôt ch√∫t v·ªÅ l·ªãch s·ª≠ c·ªßa thu·∫≠t ng·ªØ ‚ÄúBig Data‚Äù. Kh√¥ng gi·ªëng v·ªõi AI v√† ML, Big Data kh√¥ng ph·∫£i l√† m·ªôt ng√†nh khoa h·ªçc ch√≠nh th·ªëng m√† ch·ªâ l√† m·ªôt thu·∫≠t ng·ªØ truy·ªÅn th√¥ng m·ªõi xu·∫•t hi·ªán trong v√†i nƒÉm tr·ªü l·∫°i ƒë√¢y. N√≥ kh√¥ng kh√°c g√¨ thu·∫≠t ng·ªØ ‚Äúk·ª∑ nguy√™n ph·∫ßn m·ªÅm‚Äù hay ‚Äúc√°ch m·∫°ng c√¥ng nghi·ªáp‚Äù. M·∫∑c d√π thu·∫≠t ng·ªØ n√†y m·ªõi xu·∫•t hi·ªán nh∆∞ng kh·ªëi l∆∞·ª£ng d·ªØ li·ªáu t√≠ch t·ª• k·ªÉ t·ª´ khi m·∫°ng Internet xu·∫•t hi·ªán v√†o cu·ªëi th·∫ø k·ª∑ tr∆∞·ªõc c≈©ng kh√¥ng ph·∫£i l√† nh·ªè t·ª´ v√≠ d·ª• v·ªÅ th∆∞ vi·ªán Alexandria. V·∫≠y th√¨ c√¢u h·ªèi ƒë·∫∑t ra l√† t·∫°i sao v·ªõi kh·ªëi l∆∞·ª£ng kh·ªïng l·ªì nh∆∞ th·∫ø m√† th·ªùi ƒë√≥ v·∫´n kh√¥ng g·ªçi l√† Big Data? C√¢u tr·∫£ l·ªùi l√† m·∫∑c d√π ƒë∆∞·ª£c bao quanh b·ªüi d·ªØ li·ªáu kh·ªïng l·ªì nh∆∞ng ·ªü th·ªùi ƒëi·ªÉm ƒë√≥ con ng∆∞·ªùi kh√¥ng bi·∫øt l√†m g√¨ v·ªõi ch√∫ng ngo√†i l∆∞u tr·ªØ v√† sao ch√©p. Cho ƒë·∫øn khi c√°c nh√† khoa h·ªçc nh·∫≠n ra r·∫±ng trong ƒë·ªëng d·ªØ li·ªáu n√†y ƒëang ·∫©n ch·ª©a m·ªôt kh·ªëi l∆∞·ª£ng tri th·ª©c kh·ªïng l·ªì. Nh·ªØng tri th·ª©c ·∫•y c√≥ th·ªÉ gi√∫p ta hi·ªÉu th√™m v·ªÅ con ng∆∞·ªùi v√† x√£ h·ªôi. Ch·∫≥ng h·∫°n nh∆∞ t·ª´ danh s√°ch c√°c b·ªô phim y√™u th√≠ch c·ªßa m·ªôt c√° nh√¢n, ch√∫ng ta c√≥ th·ªÉ r√∫t ra ƒë∆∞·ª£c s·ªü th√≠ch xem phem c·ªßa ng∆∞·ªùi ƒë√≥ v√† g·ª£i √Ω nh·ªØng b·ªô phim c√πng th·ªÉ lo·∫°i. Ho·∫∑c t·ª´ danh s√°ch t√¨m ki·∫øm c·ªßa c·ªông ƒë·ªìng m·∫°ng ch√∫ng ta s·∫Ω bi·∫øt ƒë∆∞·ª£c v·∫•n ƒë·ªÅ n√≥ng h·ªïi nh·∫•t ƒëang ƒë∆∞·ª£c quan t√¢m v√† s·∫Ω t·∫≠p trung ƒëƒÉng t·∫£i nhi·ªÅu tin t·ª©c h∆°n v·ªÅ v·∫•n ƒë·ªÅ ƒë√≥, ‚Ä¶\nNh∆∞ v·∫≠y, b√πng n·ªï th√¥ng tin kh√¥ng ph·∫£i l√† l√Ω do duy nh·∫•t d·∫´n ƒë·∫øn s·ª± ra ƒë·ªùi c·ªßa c·ª•m t·ª´ Big Data m√† Big Data ch·ªâ th·ª±c s·ª± b·∫Øt ƒë·∫ßu khi ch√∫ng ta hi·ªÉu ƒë∆∞·ª£c gi√° tr·ªã c·ªßa th√¥ng tin ·∫©n ch·ª©a trong d·ªØ li·ªáu v√† c√≥ ƒë·ªß t√†i nguy√™n c≈©ng nh∆∞ c√¥ng ngh·ªá ƒë·ªÉ c√≥ th·ªÉ khai t√°c ch√∫ng tr√™n quy m√¥ l·ªõn. V√† kh√¥ng c√≥ g√¨ ng·∫°c nhi√™n khi M√°y h·ªçc ch√≠nh l√† th√†nh ph·∫ßn m·∫•u ch·ªët c·ªßa c√¥ng ngh·ªá ƒë√≥.\nM√°y h·ªçc v√† m·ªëi quan h·ªá v·ªõi Tr√≠ tu·ªá nh√¢n t·∫°o c√πng D·ªØ li·ªáu l·ªõn ƒê·ªÉ m√°y t√≠nh c√≥ kh·∫£ nƒÉng suy nghƒ© v√† tr√≠ tu·ªá nh∆∞ con ng∆∞·ªùi th√¨ ƒë√≤i h·ªèi m√°y t√≠nh ph·∫£i c√≥ kh·∫£ nƒÉng ‚Äúh·ªçc‚Äù m√† kh√¥ng c·∫ßn ph·∫£i l·∫≠p tr√¨nh ƒë·ªÉ th·ª±c hi·ªán c√°c t√°c v·ª• c·ª• th·ªÉ ƒë√≥. V·ªÅ ph√≠a c√°c nh√† nghi√™n c·ª©u AI, h·ªç mu·ªën xem th·ª≠ li·ªáu m√°y t√≠nh c√≥ th·ªÉ h·ªçc d·ªØ li·ªáu nh∆∞ th·∫ø n√†o? T·ª´ ƒë√≥ thu·∫≠t ng·ªØ M√°y h·ªçc hay H·ªçc m√°y (ML ‚Äì Machine Learning) ƒë∆∞·ª£c h√¨nh th√†nh. M·∫∑c d√π kh√¥ng c√≥ nhi·ªÅu ƒë·ªãnh nghƒ©a nh∆∞ AI nh∆∞ng ML l·∫°i c√≥ 2 ƒë·ªãnh nghƒ©a kh√° t∆∞·ªùng minh nh∆∞ sau:\nM√°y h·ªçc l√† ng√†nh h·ªçc cung c·∫•p cho m√°y t√≠nh kh·∫£ nƒÉng h·ªçc h·ªèi m√† kh√¥ng c·∫ßn ƒë∆∞·ª£c l·∫≠p tr√¨nh m·ªôt c√°ch r√µ r√†ng (Arthur Samuel, 1959).\nTheo Gi√°o s∆∞ Tom Mitchell ‚Äì Carnegie Mellon University: M√°y h·ªçc l√† 1 ch∆∞∆°ng tr√¨nh m√°y t√≠nh ƒë∆∞·ª£c n√≥i l√† h·ªçc h·ªèi t·ª´ kinh nghi·ªám E t·ª´ c√°c t√°c v·ª• T v√† v·ªõi ƒë·ªô ƒëo hi·ªáu su·∫•t P n·∫øu hi·ªáu su·∫•t c·ªßa n√≥ √°p d·ª•ng tr√™n t√°c v·ª• T v√† ƒë∆∞·ª£c ƒëo l∆∞·ªùng b·ªüi ƒë·ªô ƒëo P tƒÉng t·ª´ kinh nghi·ªám E.\nM·ªôt v√†i v√≠ d·ª• minh ho·∫° cho ƒë·ªãnh nghƒ©a c·ªßa Tom Mitchell:\n‚Ä¢\tV√≠ d·ª• 1: Gi·∫£ s·ª≠ nh∆∞ ta mu·ªën m√°y t√≠nh x√°c ƒë·ªãnh m·ªôt tin nh·∫Øn c√≥ ph·∫£i l√† SPAM hay kh√¥ng th√¨:\nT√°c v·ª• T: X√°c ƒë·ªãnh 1 tin nh·∫Øn c√≥ ph·∫£i SPAM hay kh√¥ng?\nKinh nghi·ªám E: Xem l·∫°i nh·ªØng tin nh·∫Øn ƒë∆∞·ª£c ƒë√°nh d·∫•u l√† SPAM xem c√≥ nh·ªØng ƒë·∫∑c t√≠nh g√¨ ƒë·ªÉ c√≥ th·ªÉ x√°c ƒë·ªãnh n√≥ l√† SPAM.\nƒê·ªô ƒëo P: L√† ph·∫ßn trƒÉm s·ªë tin nh·∫Øn SPAM ƒë∆∞·ª£c ph√¢n lo·∫°i ƒë√∫ng.\n‚Ä¢\tV√≠ d·ª• 2: Ch∆∞∆°ng tr√¨nh nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay (bao g·ªìm c√°c ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9)\nT√°c v·ª• T: nh·∫≠n d·∫°ng ƒë∆∞·ª£c ·∫£nh ch·ª©a k√Ω t·ª± s·ªë.\nKinh nghi·ªám E: ƒê·∫∑c tr∆∞ng ƒë·ªÉ ph√¢n lo·∫°i k√Ω t·ª± s·ªë t·ª´ t·∫≠p d·ªØ li·ªáu s·ªë cho tr∆∞·ªõc.\nƒê·ªô ƒëo P: ƒê·ªô ch√≠nh x√°c c·ªßa qu√° tr√¨nh nh·∫≠n d·∫°ng.\nM·ªëi quan h·ªá gi·ªØa ML v·ªõi AI v√† Big Data Trong ph·∫ßn 1 v√† ph·∫ßn 2 ch√∫ng ta lu√¥n th·∫•y s·ª± xu·∫•t hi·ªán c·ªßa ML, ƒë√¢y l√† l√Ω do v√¨ sao m√¨nh kh√¥ng t√°ch ri√™ng m·ªëi quan h·ªá gi·ªØa c√°c kh√°i ni·ªám n√†y ra m·ªôt ph·∫ßn ri√™ng m√† ƒë·ªÉ chung trong n·ªôi dung c·ªßa ML. V·∫≠y th√¨ m·ªëi li√™n h·ªá ƒë√≥ l√† g√¨?\nM·ªôt c√°ch h√†n l√¢m th√¨ AI l√† ng√†nh khoa h·ªçc ƒë∆∞·ª£c sinh ra v·ªõi m·ª•c ti√™u l√† l√†m cho m√°y t√≠nh c√≥ ƒë∆∞·ª£c tr√≠ th√¥ng minh nh∆∞ con ng∆∞·ªùi. M·ª•c ti√™u n√†y v·∫´n kh√° m∆° h·ªì v√¨ kh√¥ng ph·∫£i ai c≈©ng ƒë·ªìng √Ω v·ªõi m·ªôt ƒë·ªãnh nghƒ©a th·ªëng nh·∫•t v·ªÅ tr√≠ th√¥ng minh. C√°c nh√† khoa h·ªçc ph·∫£i ƒë·ªãnh nghƒ©a m·ªôt s·ªë m·ª•c ti√™u c·ª• th·ªÉ h∆°n, m·ªôt trong s·ªë ƒë√≥ l√† vi·ªác l√†m cho m√°y t√≠nh l·ª´a ƒë∆∞·ª£c Turing Test. Turing Test ƒë∆∞·ª£c t·∫°o ra b·ªüi Alan Turing (1912 ‚Äì 1954), ng∆∞·ªùi ƒë∆∞·ª£c xem l√† cha ƒë·ªÉ c·ªßa ng√†nh khoa h·ªçc m√°y t√≠nh hi·ªán ƒë·∫°i, nh·∫±m ph√¢n bi·ªát xem ng∆∞·ªùi ƒë·ªëi di·ªán c√≥ ph·∫£ l√† ng∆∞·ªùi hay kh√¥ng.\nNh∆∞ v·∫≠y, AI th·ªÉ hi·ªán m·ªôt c·ªßa m·ª•c ti√™u con ng∆∞·ªùi, trong khi ML l√† m·ªôt ph∆∞∆°ng ti·ªán ƒë∆∞·ª£c k·ª≥ v·ªçng s·∫Ω gi√∫p con ng∆∞·ªùi ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u ƒë√≥. V√† tr√™n th·ª±c t·∫ø th√¨ ML ƒë√£ mang nh√¢n lo·∫°i ƒëi r·∫•t xa tr√™n qu√£ng ƒë∆∞·ªùng chinh ph·ª•c AI. D√π c√≥ m·ªëi quan h·ªá ch·∫∑c ch·∫Ω v·ªõi nhau nh∆∞ng ch√∫ng kh√¥ng h·∫≥n l√† tr√πng kh·ªõp v√¨ m√¥t b√™n l√† m·ª•c ti√™u (AI), m·ªôt b√™n l√† ph∆∞∆°ng ti·ªán (ML). Chinh ph·ª•c AI m·∫∑c d√π v·∫´n l√† m·ª•c ƒë√≠ch t·ªëi th∆∞·ª£ng c·ªßa ML, nh∆∞ng hi·ªán t·∫°i ML t·∫≠p trung v√†o nh·ªØng m·ª•c ti√™u ng·∫Øn h·∫°n h∆°n nh∆∞ l√†m cho m√°y t√≠nh c√≥ kh·∫£ nƒÉng nh·∫≠n th·ª©c c∆° b·∫£n c·ªßa con ng∆∞·ªùi nh∆∞ nghe, nh√¨n, hi·ªÉu ƒë∆∞·ª£c ng√¥n ng·ªØ, gi·∫£i to√°n, l·∫≠p tr√¨nh, ‚Ä¶, c√°c kh·∫£ nƒÉng n√†y ·ª©ng v·ªõi c√°c lƒ©nh v·ª±c c·ª• th·ªÉ trong AI nh∆∞:\nTh·ªã gi√°c m√°y t√≠nh (computer vision): m·ª•c ti√™u c·ªßa lƒ©nh v·ª±c n√†y l√† l√†m cho m√°y t√≠nh c√≥ th·ªÉ nh√¨n nh∆∞ con ng∆∞·ªùi. Nh·ªØng ·ª©ng d·ª•ng quan tr·ªçng c√≥ th·ªÉ k·ªÉ ƒë·∫øn trong lƒ©nh v·ª±c n√†y nh∆∞ l√† nh·∫≠n d·∫°ng ch·ªØ/ ch·ª© s·ªë vi·∫øt tay, nh·∫≠n d·∫°ng khu√¥n m·∫∑t, d√°ng ƒëi, c·ª≠ ch·ªâ, ph√¢n lo·∫°i lo√†i hoa, nh√£n hi·ªáu, ph√°t hi·ªán ƒë·ªì v√¢t, ‚Ä¶. T·ª´ t·∫≠p h√¨nh ·∫£nh ban ƒë·∫ßu, c√°c thu·∫≠t to√°n ML s·∫Ω ti·∫øn h√†nh x·ª≠ l√Ω, ph√¢n t√≠ch ƒë·ªÉ r√∫t ra c√°c ƒë·∫∑c tr∆∞ng ch√≠nh gi√∫p nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng ho·∫∑c ph√¢n bi·ªát c√°c ƒë·ªëi t∆∞·ª£ng v·ªõi nhau.\nX·ª≠ l√Ω Ng√¥n ng·ªØ t·ª± nhi√™n (Natural Language Processing ‚Äì NLP): M·ª•c ti√™u l√† gi√∫p cho m√°y t√≠nh c√≥ th·ªÉ hi·ªÉu nh∆∞ con ng∆∞·ªùi. D·ªãch m√°y l√† m·ªôt trong nh·ªØng ·ª©ng d·ª•ng ƒëi·ªÉn h√¨nh c·ªßa NLP, d·ªãch n·ªôi dung c·ªßa m·ªôt ƒëo·∫°n vƒÉn b·∫£n t·ª´ ng√¥n ng·ªØ n√†y sang ng√¥n ng·ªØ kh√°c (Google Translate). Xu·∫•t ph√°t t·ª´ ‚ÄúT·ª´ ƒëi·ªÉn‚Äù ho·∫∑c t·∫≠p c√°c c·∫∑p c√¢u song ng·ªØ, t·∫≠p lu·∫≠t ng·ªØ ph√°p c·ªßa m·ªói ng√¥n ng·ªØ ƒë∆∞·ª£c t·∫°o b·ªüi ng∆∞·ªùi c√≥ chuy√™n m√¥n v·ªÅ nh·ªØng ng√¥n ng·ªØ ƒë√≥, c√°c thu·∫≠t to√°n m√°y h·ªçc s·∫Ω ti·∫øn h√†nh ph√¢n t√≠ch ƒë·ªÉ t√°ch c√¢u, t√°ch t·ª´, x√°c ƒë·ªãnh t·ª´ lo·∫°i, ph√¢n t√≠ch c√∫ ph√°p ƒë·ªÉ t·ª´ ƒë√≥ l·∫•y ra ng·ªØ nghƒ©a ph√π h·ª£p r·ªìi gh√©p l·∫°i v·ªõi nhau v√† cho ra n·ªôi dung ·ªü ng√¥n ng·ªØ t∆∞∆°ng ·ª©ng. Ngo√†i ra, t√≥m t·∫Øt vƒÉn b·∫£n d·ª±a v√†o c√°c t·ª´ kho√° c·ªßa t·ª´ng lƒ©nh v·ª±c c≈©ng l√† m·ªôt b√†i to√°n ML r·∫•t ƒë∆∞·ª£c quan t√¢m trong v√†i nƒÉm tr·ªü l·∫°i ƒë√¢y, khi m√† m·ªói ng√†y l∆∞·ª£ng tin t·ª©c c·∫ßn ph·∫£i ƒë·ªçc l√† qu√° nhi·ªÅu.\nX·ª≠ l√Ω ti·∫øng n√≥i (Speech Language Processing): nh·∫±m l√†m cho m√°y t√≠nh c√≥ th·ªÉ nghe ƒë∆∞·ª£c nh∆∞ ng∆∞·ªùi. T·ªïng h·ªôp ti·∫øng n√≥i (text to speech) ƒë·ªÉ ƒë·ªçc s√°ch cho ng∆∞·ªùi khi·∫øm th·ªã, t·∫°o sub cho c√°c video (speech to text) ƒë·ªÉ h·ªó tr·ª£ cho ng∆∞·ªùi khi·∫øm th√≠nh ho·∫∑c h·ªó tr·ª£ cho vi·ªác h·ªçc ng√¥n ng·ªØ; nh·∫≠n d·∫°ng gi·ªçng n√≥i (speech recognition) gi√∫p ph√°t hi·ªán t·ªôi ph·∫°m l√† m·ªôt s·ªë ·ª©ng d·ª•ng ƒëi·ªÉn h√¨nh trong lƒ©nh v·ª±c n√†y.\nThay v√¨ c·ªë g·∫Øng ‚Äúd·∫°y‚Äù m√°y t√≠nh c√°ch l√†m m·ªôt vi·ªác g√¨ ƒë√≥, ch·∫≥ng h·∫°n nh∆∞ l√°i xe h∆°i, ƒëi·ªÅu m√† c√°c chuy√™n gia AI c·∫ßn l√†m l√† cung c·∫•p ‚Äúƒë·ªß‚Äù d·ªØ li·ªáu cho m·ªôt m√°y t√≠nh ƒë·ªÉ n√≥ c√≥ th·ªÉ t√≠nh ra x√°c su·∫•t c·ªßa t·∫•t c·∫£ m·ªçi th·ª© m√† ng∆∞·ªùi ta mu·ªën t√≠nh to√°n, v√≠ nh∆∞ x√°c su·∫•t ng∆∞·ªùi ƒëi ƒë∆∞·ªùng g·∫∑p ƒë√®n giao th√¥ng m√†u xanh, m√†u ƒë·ªè, m√†u v√†ng, ‚Ä¶ th√¨ chu·∫©n x√°c h∆°n.\nDo ƒë√≥, nhi·ªám v·ª• th·ª±c s·ª± c·ªßa ML trong AI l√† ‚Äúh·ªçc‚Äù m√† th·ª±c ch·∫•t c·ªßa vi·ªác h·ªçc n√†y l√† r√∫t tr√≠ch th√¥ng tin h·ªØu √≠ch cho t·ª´ng b√†i to√°n trong ‚Äút·∫≠p d·ªØ li·ªáu‚Äù cho tr∆∞·ªõc. L√∫c n√†y m·ªëi quan h·ªá gi·ªØa ML v√† Big Data s·∫Ω ƒë∆∞·ª£c b·ªôc l·ªô, ƒë√≥ l√† n·∫øu kh·ªëi l∆∞·ª£ng d·ªØ li·ªáu c·ªßa Big Data c√†ng gia tƒÉng th√¨ ML s·∫Ω ph√°t tri·ªÉn h∆°n, c√≥ kh·∫£ nƒÉng r√∫t tr√≠ch ƒë∆∞·ª£c nhi·ªÅu th√¥ng tin gi√° tr·ªã h∆°n hay d·ª± ƒëo√°n ch√≠nh x√°c h∆°n, ng∆∞·ª£c l·∫°i th√¨ gi√° tr·ªã c·ªßa Big Data ph·ª• thu·ªôc v√†o kh·∫£ nƒÉng khai th√°c tri th·ª©c t·ª´ d·ªØ li·ªáu c·ªßa ML, v√¨ n√≥ s·∫Ω th·ª±c s·ª± l√† Big Data khi kh·ªëi l∆∞·ª£ng d·ªØ li·ªáu ƒë√≥ mang l·∫°i th√¥ng tin h·ªØu √≠ch.\nVi·ªác s·ª≠ d·ª•ng nh·ªØng kh·ªëi l∆∞·ª£ng th√¥ng tin theo c√°ch n√†y ƒë√≤i h·ªèi ch√∫ng ta ph·∫£i c√≥ s·ª± thay ƒë·ªïi trong c√°ch ti·∫øp c·∫≠n d·ªØ li·ªáu. M·ªôt l√† thu th·∫≠p v√† s·ª≠ d·ª•ng th·∫≠t nhi·ªÅu d·ªØ li·ªáu thay v√¨ ch·∫•p nh·∫≠n l·∫•y nh·ªØng m·∫´u th·ªëng k√™ v·ªõi s·ªë l∆∞·ª£ng nh·ªè nh∆∞ c√°c nh√† th·ªëng k√™ v·∫´n l√†m t·ª´ h∆°n m·ªôt th·∫ø k·ª∑ nay. Hai l√† kh√¥ng nh·∫•t thi·∫øt ph·∫£i k√©n ch·ªçn s√†ng l·ªçc ra d·ªØ li·ªáu s·∫°ch, v√¨ kinh nghi·ªám th·ª±c ti·ªÖn cho th·∫•y r·∫±ng m·ªôt ch√∫t sai l·ªách trong th√¥ng tin v·∫´n c√≥ th·ªÉ ch·∫•p nh·∫≠n ƒë∆∞·ª£c, v√† vi·ªác s·ª≠ d·ª•ng m·ªôt l∆∞·ª£ng kh·ªïng l·ªì nh·ªØng d·ªØ li·ªáu √¥ h·ª£p ƒëem l·∫°i nhi·ªÅu √≠ch l·ª£i h∆°n l√† d·ªØ li·ªáu tuy ch√≠nh x√°c nh∆∞ng dung l∆∞·ª£ng qu√° √≠t. Ba l√† trong nhi·ªÅu tr∆∞·ªùng h·ª£p, ch√∫ng ta kh√¥ng nh·∫•t thi·∫øt ph·∫£i c·ªë t√¨m ra nguy√™n nh√¢n ƒë·∫±ng sau c√°c hi·ªán t∆∞·ª£ng.V√≠ d·ª•, kh√¥ng c·∫ßn ph·∫£i c·ªë t√¨m hi·ªÉu ch√≠nh x√°c v√¨ sao m·ªôt c·ªó m√°y b·ªã h·ªèng, thay v√†o ƒë√≥ c√°c nh√† nghi√™n c·ª©u c√≥ th·ªÉ thu th·∫≠p v√† ph√¢n t√≠ch th·∫≠t nhi·ªÅu d·ªØ li·ªáu v·ªÅ ch√∫ng c√πng t·∫•t c·∫£ m·ªçi th·ª© li√™n quan, t·ª´ ƒë√≥ r√∫t ra quy lu·∫≠t l√†m c∆° s·ªü d·ª± ƒëo√°n c√°c s·ª± v·∫≠t, s·ª± vi·ªác trong t∆∞∆°ng lai.\nD∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë t√†i li·ªáu m√¨nh ƒë√£ s·ª≠ d·ª•ng ƒë·ªÉ tham kh·∫£o trong qua tr√¨nh vi·∫øt b√†i:\nIntroduction to Machine Learning of Alex Smola and S.V.N. Vishwanathan.\nArtificial Intelligence (third edition) of The McGraw-Hill Companies, write by Elaine Rich, Kevin Knight and Shivashankar B Nair.\nhttps://i4iam.files.wordpress.com/2013/08/artificial-intelligence-by-rich-and-knight.pdf\nhttps://en.wikipedia.org/wiki/Artificial_intelligence\nhttps://searchenterpriseai.techtarget.com/definition/AI-Artificial-Intelligence\nhttp://vienthongke.vn/tin-tuc/43-tin-tuc/2176-thoi-dai-cua-du-lieu-lon-big-data\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü nh·ªØng b√†i vi·∫øt ti·∫øp theo.\n","date":"Apr 2, 2019","img":"","permalink":"/blog/2019-04-02-deep-learning-view/","series":null,"tags":["machine learning","deep learning"],"title":"Tr√≠ Tu·ªá Nh√¢n T·∫°o, M√°y H·ªçc, D·ªØ Li·ªáu L·ªõn"},{"categories":null,"content":" B·∫Øt ƒë·∫ßu Visualize d·ªØ li·ªáu Bounding Boxes Resize Images Mini Masks Anchors Prediction B·∫Øt ƒë·∫ßu ƒê·∫ßu ti√™n, ch√∫ng ta s·∫Ω download t·∫≠p dataset balloon t·∫°i https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip, gi·∫£i n√©n v√† b·ªè trong th∆∞ m·ª•c datasets. Ti·∫øp ƒë√≥, c√°c b·∫°n donwload file balloon.py v√† visualize.py v·ªÅ. File ƒë·∫ßu ti√™n h·ªó tr·ª£ ch√∫ng ta ƒë·ªçc d·ªØ li·ªáu c·ªßa dataset balloon v√† file th·ª© hai h·ªó tr·ª£ visualize h√¨nh ·∫£nh m·ªôt c√°ch tr·ª±c quan. C·∫£ hai file m√¨nh ƒë·ªÅu l·∫•y m√£ ngu·ªìn c·ªßa Matterport tr√™n https://github.com/matterport/Mask_RCNN/ Ti·∫øn h√†nh import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt v·ªÅ.\n1import os 2import sys 3import itertools 4import math 5import logging 6import json 7import re 8import random 9from collections import OrderedDict 10import numpy as np 11import matplotlib 12import matplotlib.pyplot as plt 13import matplotlib.patches as patches 14import matplotlib.lines as lines 15from matplotlib.patches import Polygon 16 17 18import balloon 19import utils 20import visualize 21 22config = balloon.BalloonConfig() 23BALLOON_DIR = \u0026#34;datasets/balloon\u0026#34; Th√¥ng tin c·ªßa t·∫≠p train bao g·ªìm\n1dataset = balloon.BalloonDataset() 2dataset.load_balloon(BALLOON_DIR, \u0026#34;train\u0026#34;) 3 4# Must call before using the dataset 5dataset.prepare() 6 7print(\u0026#34;Image Count: {}\u0026#34;.format(len(dataset.image_ids))) 8print(\u0026#34;Class Count: {}\u0026#34;.format(dataset.num_classes)) 9for i, info in enumerate(dataset.class_info): 10 print(\u0026#34;{:3}. {:50}\u0026#34;.format(i, info[\u0026#39;name\u0026#39;])) 1Image Count: 61 2Class Count: 2 3 0. BG 4 1. balloon V·∫≠y l√† c√≥ t·ªïng c·ªông 61 h√¨nh train. D·ªØ li·ªáu ƒë∆∞·ª£c ƒë√°nh l√†m 2 nh√£n, m·ªôt nh√£n l√† background, m·ªôt nh√£n l√† balloon.\nVisualize d·ªØ li·ªáu Ch√∫ng ta s·∫Ω load m·ªôt v√†i h√¨nh l√™n xem ng∆∞·ªùi ta ƒë√£ mask d·ªØ li·ªáu nh∆∞ th·∫ø n√†o. ·ªû ƒë√¢y, v·ªõi m·ªói h√¨nh ·∫£nh, m√¨nh s·∫Ω load 1 h√¨nh g·ªëc v√† 4 h√¨nh c·ªßa 4 qu·∫£ b√≥ng t∆∞∆°ng ·ª©ng trong h√¨nh, n·∫øu trong h√¨nh c√≥ nhi·ªÅu h∆°n 4 qu·∫£ b√≥ng th√¨ ch·ªâ v·∫Ω 4 qu·∫£ b√≥ng ƒë·∫ßu ti√™n\n1 2 3n_col = 5 4 5# Load and display random samples 6fig, axs = plt.subplots(nrows=4, ncols=n_col, figsize=(9.3, 6),subplot_kw={\u0026#39;xticks\u0026#39;: [], \u0026#39;yticks\u0026#39;: []}) 7fig.subplots_adjust(left=0.03, right=0.97, hspace=0.3, wspace=0.05) 8image_ids = np.random.choice(dataset.image_ids, 4) 9# for image_id in image_ids: 10# for ax, image_id in zip(axs.flat, image_ids): 11 12for index in range(0,4): 13 image_id = image_ids[index] 14 15 image = dataset.load_image(image_id) 16 mask, class_ids = dataset.load_mask(image_id) 17 print(mask.shape) 18 print(len(class_ids)) 19 20 axs.flat[index*n_col].imshow(image) 21 axs.flat[index*n_col].set_title(\u0026#39;img\u0026#39;) 22 23 for sub_index in range(0,len(class_ids)): 24 if sub_index \u0026gt;= n_col: 25 break 26 axs.flat[index*n_col +1 + sub_index].imshow(mask[:,:,sub_index]) 27 axs.flat[index*n_col + 1+sub_index].set_title(str(dataset.class_names[class_ids[sub_index]])) 28 29 30plt.tight_layout() 31plt.show() C√°c b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m display_top_masks c·ªßa t√°c gi·∫£ Mask R-CNN ƒë·ªÉ xem th·ª≠, h√†m c·ªßa h·ªç h∆°i kh√°c c·ªßa m√¨nh m·ªôt ch√∫t.\n1 2image_ids = np.random.choice(dataset.image_ids, 4) 3for image_id in image_ids: 4 image = dataset.load_image(image_id) 5 mask, class_ids = dataset.load_mask(image_id) 6 visualize.display_top_masks(image, mask, class_ids, dataset.class_names) Bounding Boxes Ch√∫ng ta c√≥ 2 c√°ch ƒë·ªÉ l·∫•y Bounding Boxes c·ªßa c√°c h√¨nh. M·ªôt l√† l·∫•y tr·ª±c ti·∫øp t·ª´ t·∫≠p dataset (ƒë·ªëi v·ªõi nh·ªØng dataset c√≥ l∆∞u bounding box), hai l√† r√∫t tr√≠ch bounding box t·ª´ c√°c to·∫° ƒë·ªô mask. Ch√∫ng ta n√™n th·ª±c hi·ªán c√°ch hai, l√Ω do l√† ch√∫ng ta s·∫Ω d√πng c√°c k·ªπ thu·∫≠t Data Generator ƒë·ªÉ sinh nhi·ªÅu ·∫£nh h∆°n cung c·∫•p cho thu·∫≠t to√°n train. L√∫c n√†y, vi·ªác t√≠nh l·∫°i bounding box s·∫Ω d·ªÖ d√†ng h∆°n.\n1 2# Load random image and mask. 3image_id = random.choice(dataset.image_ids) 4image = dataset.load_image(image_id) 5mask, class_ids = dataset.load_mask(image_id) 6 7# Compute Bounding box 8bbox = utils.extract_bboxes(mask) 9 10# Display image and additional stats 11print(\u0026#34;image_id \u0026#34;, image_id, dataset.image_reference(image_id)) 12 13# Display image and instances 14visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names) Resize Images C√°c ·∫£nh trong t·∫≠p train c√≥ c√°c k√≠ch th∆∞·ªõc kh√°c nhau. C√°c b·∫°n c√≥ th·ªÉ xem c√°c h√¨nh ·ªü tr√™n, c√≥ ·∫£nh c√≥ k√≠ch th∆∞·ªõc n√†y, c√≥ ·∫£nh c√≥ k√≠ch th∆∞·ªõc kia. Ch√∫ng ta s·∫Ω resize ch√∫ng v·ªÅ c√πng m·ªôt k√≠ch th∆∞·ªõc (v√≠ d·ª• 1024x1024) ƒë·ªÉ l√†m ƒë·∫ßu v√†o cho t·∫≠p hu·∫•n luy·ªán. V√† ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng zero padding ƒë·ªÉ l·∫•p ƒë·∫ßy nh·ªØng kho·∫£ng tr·ªëng c·ªßa nh·ªØng ·∫£nh kh√¥ng ƒë·ªß k√≠ch th∆∞·ªõc.\n1 2 3 4# Load random image and mask. 5image_id = np.random.choice(dataset.image_ids, 1)[0] 6image = dataset.load_image(image_id) 7mask, class_ids = dataset.load_mask(image_id) 8original_shape = image.shape 9# Resize 10image, window, scale, padding, _ = utils.resize_image( 11 image, 12 min_dim=config.IMAGE_MIN_DIM, 13 max_dim=config.IMAGE_MAX_DIM, 14 mode=config.IMAGE_RESIZE_MODE) 15mask = utils.resize_mask(mask, scale, padding) 16# Compute Bounding box 17bbox = utils.extract_bboxes(mask) 18 19# Display image and additional stats 20print(\u0026#34;image_id: \u0026#34;, image_id, dataset.image_reference(image_id)) 21print(\u0026#34;Original shape: \u0026#34;, original_shape) 22print(\u0026#34;Resize shape: \u0026#34;, image.shape) 23# Display image and instances 24visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names) K·∫øt qu·∫£\n1image_id: 9 datasets/balloon\\train\\15290896925_884ab33fd3_k.jpg 2Original shape: (1356, 2048, 3) 3Resize shape: (1024, 1024, 3) L∆∞u √Ω m·ªôt ƒëi·ªÅu l√† ·ªü ƒë√¢y, m√¨nh s·ª≠ d·ª•ng random image, n√™n n·∫øu c√°c b·∫°n ch·∫°y l·∫°i c√¢u l·ªánh nh∆∞ m√¨nh th√¨ k·∫øt qu·∫£ ra ph·∫ßn nhi·ªÅu s·∫Ω kh√°c m√¨nh. Tuy nhi√™n, Resize shape lu√¥n l√† (1024, 1024, 3).\nMini Masks M·ªôt v·∫•n ƒë·ªÅ kh√° nghi√™m tr·ªçng ·ªü ƒë√¢y l√† ch√∫ng ta c·∫ßn kh√° nhi·ªÅu b·ªô nh·ªõ ƒë·ªÉ l∆∞u c√°c masks. Numpy s·ª≠ d·ª•ng 1 byte ƒë·ªÉ l∆∞u 1 gi√° tr·ªã bit. Do ƒë√≥, v·ªõi k√≠ch th∆∞·ªõc ·∫£nh l√† 1024x1024, ch√∫ng ta c·∫ßn 1MB b·ªô nh·ªõ ram ƒë·ªÉ l∆∞u tr·ªØ. N·∫øu ch√∫ng ta c√≥ t·∫≠p dataset t·∫ßm 1000 b·ª©c ·∫£nh th√¨ c·∫ßn ƒë·∫øn 1GB b·ªô nh·ªõ, kh√° l√† l·ªõn. Ngo√†i vi·ªác t·ªën b·ªô nh·ªõ l·ªØu tr·ªØ, ch√∫ng c√≤n l√†m ch·∫≠m t·ªëc ƒë·ªô hu·∫•n luy·ªán m√¥ h√¨nh n·ªØa.\nƒê·ªÉ c·∫£i ti·∫øn, ch√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng m·ªôt trong hai c√°ch sau:\nC√°ch th·ª© nh·∫•t: Thay v√¨ l∆∞u to√†n b·ªô mask c·ªßa to√†n b·ª©c ·∫£nh, ch√∫ng ta ch·ªâ l∆∞u nh·ªØng pixel c·ªßa mask trong bounding box. V·ªõi vi·ªác s·ª≠ d·ª•ng c√°ch n√†y, ch√∫ng ta s·∫Ω ti·∫øt ki·ªám kha kh√° b·ªô nh·ªõ ch√≠nh. C√°ch th·ª© hai: Ch√∫ng ta c√≥ th·ªÉ resize mask v·ªÅ m·ªôt k√≠ch th∆∞·ªõc chu·∫©n n√†o ƒë√≥, v√≠ d·ª• 48x48 pixel. V·ªõi nh·ªØng mask c√≥ k√≠ch th∆∞·ªõc l·ªõn h∆°n 48x48, ch√∫ng s·∫Ω b·ªã m·∫•t th√¥ng tin. M√¨nh kh√¥ng th√≠ch c√°ch th·ª© hai cho l·∫Øm. Tuy nhi√™n, theo l√Ω gi·∫£i c·ªßa nh√≥m t√°c gi·∫£ Mask R-CNN, th√¨ h·∫ßu h·∫øt vi·ªác g√°n c√°c ƒë∆∞·ªùng bi√™n (object annotations) th∆∞·ªùng kh√¥ng ch√≠nh x√°c cho l·∫Øm (th·ª´a ho·∫∑c thi·∫øu m·ªôt v√†i ch·ªó), cho n√™n, vi·ªác m·∫•t m√°t th√¥ng tin v·ªõi l∆∞·ª£ng nh·ªè n√†y h·∫ßu nh∆∞ l√† kh√¥ng ƒë√°ng k·ªÉ.\nƒê·ªÉ ƒë√°nh gi√° hi·ªáu qu·∫£ c·ªßa h√†m mask resizing, ch√∫ng ta s·∫Ω ch·∫°y ƒëo·∫°n code b√™n d∆∞·ªõi v√† xem ·∫£nh k·∫øt qu·∫£. ƒêo·∫°n code tr√™n m√¨nh s·ª≠ d·ª•ng 2 h√†m compose_image_meta v√† load_image_gt c·ªßa t√°c gi·∫£ ·ªü ƒë∆∞·ªùng d·∫´n https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/model.py. M√¨nh c√≥ modify l·∫°i h√†m load_image_gt m·ªôt ch√∫t ƒë·ªÉ h·ª£p v·ªõi √Ω m√¨nh h∆°n.\n1############################## 2# Data Formatting 3############################## 4 5def compose_image_meta(image_id, original_image_shape, image_shape, 6 window, scale, active_class_ids): 7 \u0026#34;\u0026#34;\u0026#34;Takes attributes of an image and puts them in one 1D array. 8 image_id: An int ID of the image. Useful for debugging. 9 original_image_shape: [H, W, C] before resizing or padding. 10 image_shape: [H, W, C] after resizing and padding 11 window: (y1, x1, y2, x2) in pixels. The area of the image where the real 12 image is (excluding the padding) 13 scale: The scaling factor applied to the original image (float32) 14 active_class_ids: List of class_ids available in the dataset from which 15 the image came. Useful if training on images from multiple datasets 16 where not all classes are present in all datasets. 17 \u0026#34;\u0026#34;\u0026#34; 18 meta = np.array( 19 [image_id] + # size=1 20 list(original_image_shape) + # size=3 21 list(image_shape) + # size=3 22 list(window) + # size=4 (y1, x1, y2, x2) in image cooredinates 23 [scale] + # size=1 24 list(active_class_ids) # size=num_classes 25 ) 26 return meta 27 28 29def load_image_gt(dataset, config, image_id, augment=False, augmentation=None, 30 use_mini_mask=False): 31 \u0026#34;\u0026#34;\u0026#34;Load and return ground truth data for an image (image, mask, bounding boxes). 32 augment: (deprecated. Use augmentation instead). If true, apply random 33 image augmentation. Currently, only horizontal flipping is offered. 34 augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation. 35 For example, passing imgaug.augmenters.Fliplr(0.5) flips images 36 right/left 50% of the time. 37 use_mini_mask: If False, returns full-size masks that are the same height 38 and width as the original image. These can be big, for example 39 1024x1024x100 (for 100 instances). Mini masks are smaller, typically, 40 224x224 and are generated by extracting the bounding box of the 41 object and resizing it to MINI_MASK_SHAPE. 42 Returns: 43 image: [height, width, 3] 44 shape: the original shape of the image before resizing and cropping. 45 class_ids: [instance_count] Integer class IDs 46 bbox: [instance_count, (y1, x1, y2, x2)] 47 mask: [height, width, instance_count]. The height and width are those 48 of the image unless use_mini_mask is True, in which case they are 49 defined in MINI_MASK_SHAPE. 50 \u0026#34;\u0026#34;\u0026#34; 51 # Load image and mask 52 image = dataset.load_image(image_id) 53 mask, class_ids = dataset.load_mask(image_id) 54 original_shape = image.shape 55 image, window, scale, padding, crop = utils.resize_image( 56 image, 57 min_dim=config.IMAGE_MIN_DIM, 58 min_scale=config.IMAGE_MIN_SCALE, 59 max_dim=config.IMAGE_MAX_DIM, 60 mode=config.IMAGE_RESIZE_MODE) 61 mask = utils.resize_mask(mask, scale, padding, crop) 62 63 # Random horizontal flips. 64 # TODO: will be removed in a future update in favor of augmentation 65 if augment: 66 logging.warning(\u0026#34;\u0026#39;augment\u0026#39; is deprecated. Use \u0026#39;augmentation\u0026#39; instead.\u0026#34;) 67 if random.randint(0, 1): 68 image = np.fliplr(image) 69 mask = np.fliplr(mask) 70 71 # Augmentation 72 # This requires the imgaug lib (https://github.com/aleju/imgaug) 73 if augmentation: 74 import imgaug 75 76 # Augmenters that are safe to apply to masks 77 # Some, such as Affine, have settings that make them unsafe, so always 78 # test your augmentation on masks 79 MASK_AUGMENTERS = [\u0026#34;Sequential\u0026#34;, \u0026#34;SomeOf\u0026#34;, \u0026#34;OneOf\u0026#34;, \u0026#34;Sometimes\u0026#34;, 80 \u0026#34;Fliplr\u0026#34;, \u0026#34;Flipud\u0026#34;, \u0026#34;CropAndPad\u0026#34;, 81 \u0026#34;Affine\u0026#34;, \u0026#34;PiecewiseAffine\u0026#34;] 82 83 def hook(images, augmenter, parents, default): 84 \u0026#34;\u0026#34;\u0026#34;Determines which augmenters to apply to masks.\u0026#34;\u0026#34;\u0026#34; 85 return augmenter.__class__.__name__ in MASK_AUGMENTERS 86 87 # Store shapes before augmentation to compare 88 image_shape = image.shape 89 mask_shape = mask.shape 90 # Make augmenters deterministic to apply similarly to images and masks 91 det = augmentation.to_deterministic() 92 image = det.augment_image(image) 93 # Change mask to np.uint8 because imgaug doesn\u0026#39;t support np.bool 94 mask = det.augment_image(mask.astype(np.uint8), 95 hooks=imgaug.HooksImages(activator=hook)) 96 # Verify that shapes didn\u0026#39;t change 97 assert image.shape == image_shape, \u0026#34;Augmentation shouldn\u0026#39;t change image size\u0026#34; 98 assert mask.shape == mask_shape, \u0026#34;Augmentation shouldn\u0026#39;t change mask size\u0026#34; 99 # Change mask back to bool 100 mask = mask.astype(np.bool) 101 102 # Note that some boxes might be all zeros if the corresponding mask got cropped out. 103 # and here is to filter them out 104 _idx = np.sum(mask, axis=(0, 1)) \u0026gt; 0 105 mask = mask[:, :, _idx] 106 class_ids = class_ids[_idx] 107 # Bounding boxes. Note that some boxes might be all zeros 108 # if the corresponding mask got cropped out. 109 # bbox: [num_instances, (y1, x1, y2, x2)] 110 bbox = utils.extract_bboxes(mask) 111 112 # Active classes 113 # Different datasets have different classes, so track the 114 # classes supported in the dataset of this image. 115 active_class_ids = np.zeros([dataset.num_classes], dtype=np.int32) 116 source_class_ids = dataset.source_class_ids[dataset.image_info[image_id][\u0026#34;source\u0026#34;]] 117 active_class_ids[source_class_ids] = 1 118 119 # Resize masks to smaller size to reduce memory usage 120 if use_mini_mask: 121 if USE_MINI_MASK_SHAPE: 122 mask = utils.minimize_mask(bbox, mask, MINI_MASK_SHAPE) 123 else: 124 mask = utils.minimize_mask(bbox, mask, mask.shape[:2]) 125 126 # Image meta data 127 image_meta = compose_image_meta(image_id, original_shape, image.shape, 128 window, scale, active_class_ids) 129 130 return image, image_meta, class_ids, bbox, mask 131 132 133image_id = np.random.choice(dataset.image_ids, 1)[0] 134image, image_meta, class_ids, bbox, mask = load_image_gt( 135 dataset, config, image_id, use_mini_mask=False) 136 137 138visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))]) 139 140image, image_meta, class_ids, bbox, mask = load_image_gt( 141 dataset, config, image_id, use_mini_mask=True) 142 143 144visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))]) 145 146USE_MINI_MASK_SHAPE = True 147 148image, image_meta, class_ids, bbox, mask = load_image_gt( 149 dataset, config, image_id, use_mini_mask=True) 150 151 152visualize.display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 5))]) 153 154mask = utils.expand_mask(bbox, mask, image.shape) 155visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names) V·ªõi ·∫£nh ·ªü line 1 l√† ·∫£nh g·ªëc ban ƒë·∫ßu v√† c√°c full mask c·ªßa b·ª©c ·∫£nh, ·∫£nh ·ªü line 2 l√† ch·ªâ l·∫•y mask c·ªßa bounding box, ·∫£nh ·ªü line 3 l√† l·∫•y mask ·ªü bounding box v√† scale ·∫£nh (do scale ·∫£nh n√™n ·ªü line 3 c√°c b·∫°n s·∫Ω th·∫•y mask c√≥ h√¨nh rƒÉng c∆∞a, kh√°c v·ªõi c√°c mask line 2). Line 4 l√† ·∫£nh ·ªü line 3 ƒë∆∞·ª£c revert back l·∫°i h√¨nh g·ªëc ban ƒë·∫ßu. C√°c b·∫°n c√≥ ƒë·ªÉ √Ω th·∫•y r·∫±ng n√≥ s·∫Ω b·ªã rƒÉng c∆∞a ·ªü bi√™n c·∫°nh ch·ª© kh√¥ng ƒë∆∞·ª£c smooth nh∆∞ ·∫£nh g·ªëc. N·∫øu ch√∫ng ta kh√¥ng l√†m object annotations k·ªπ, th√¨ object c≈©ng s·∫Ω b·ªã rƒÉng c∆∞a nh∆∞ tr√™n.\nAnchors Th·ª© t·ª± c·ªßa c√°c anchor th·∫≠t s·ª± r·∫•t quan tr·ªçng. Trong qu√° tr√¨nh train, th·ª© t·ª± c·ªßa c√°c anchor nh∆∞ th·∫ø n√†o th√¨ trong qu√° tr√¨nh test, validation, prediction ph·∫£i d√πng y h·ªát v·∫≠y.\nTrong m·∫°ng FPN, c√°c anchor ph·∫£i ƒë∆∞·ª£c x·∫Øp x·∫øp theo c√°ch m√† ch√∫ng ta c√≥ th·ªÉ d·ªÖ d√†ng li√™n k·∫øt v·ªõi gi√° tr·ªã output\nX·∫Øp x·∫øp c√°c anchor theo th·ª© t·ª± c√°c l·ªõp c·ªßa pyramid. T·∫•t c·∫£ c√°c anchor c·ªßa level ƒë·∫ßu ti√™n, ti·∫øp theo l√† c√°c anchor c·ªßa c√°c l·ªõp th·ª© hai, l·ªõp th∆∞ ba\u0026hellip; Vi·ªác x·∫Øp x·∫øp theo c√°ch n√†y s·∫Ω gi√∫p ch√∫ng ta d·ªÖ d√†ng ph√¢n t√°ch c√°c l·ªõp anchor v√† d·ªÖ hi·ªÉu theo l·∫Ω t·ª± nhi√™n.\nTrong m·ªói level, x·∫Øp x·∫øp c√°c anchor trong m·ªói level b·∫±ng th·ª© t·ª± x·ª≠ l√Ω c·ªßa c√°c feature map. Th√¥ng th∆∞·ªùng, m·ªôt convolution layer s·∫Ω d·ªãch chuy·ªÉn tr√™n feature map b·∫Øt ƒë·∫ßu t·ª´ v·ªã tr√≠ tr√°i - tr√™n (top - left) ƒëi xu·ªëng ph·∫£i d∆∞·ªõi (t·ª´ tr√°i qua ph·∫£i, xu·ªëng h√†ng r·ªìi l·∫°i t·ª´ tr√°i qua ph·∫£i).\nTr√™n m·ªói cell c·ªßa feature map, ch√∫ng ta s·∫Ω x·∫Øp x·∫øp c√°c anchor theo c√°c ratios.\nAnchor Stride:\n1 2backbone_shapes = modellib.compute_backbone_shapes(config, config.IMAGE_SHAPE) 3anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES, 4 config.RPN_ANCHOR_RATIOS, 5 backbone_shapes, 6 config.BACKBONE_STRIDES, 7 config.RPN_ANCHOR_STRIDE) 8 9# Print summary of anchors 10num_levels = len(backbone_shapes) 11anchors_per_cell = len(config.RPN_ANCHOR_RATIOS) 12print(\u0026#34;Total anchors: \u0026#34;, anchors.shape[0]) 13print(\u0026#34;ANCHOR Scales: \u0026#34;, config.RPN_ANCHOR_SCALES) 14print(\u0026#34;BACKBONE STRIDE: \u0026#34;, config.BACKBONE_STRIDES) 15print(\u0026#34;ratios: \u0026#34;, config.RPN_ANCHOR_RATIOS) 16print(\u0026#34;Anchors per Cell: \u0026#34;, anchors_per_cell) 17# print(\u0026#34;Anchors stride: \u0026#34;, config.RPN_ANCHOR_STRIDE) 18print(\u0026#34;Levels: \u0026#34;, num_levels) 19anchors_per_level = [] 20for l in range(num_levels): 21 num_cells = backbone_shapes[l][0] * backbone_shapes[l][1] 22 print(\u0026#34;backbone_shapes in level \u0026#34;,l,\u0026#39; \u0026#39;,backbone_shapes[l][0],\u0026#39;x\u0026#39;,backbone_shapes[l][1]) 23 print(\u0026#34;num_cells in level \u0026#34;,l,\u0026#39; \u0026#39;,num_cells) 24 anchors_per_level.append(anchors_per_cell * num_cells // config.RPN_ANCHOR_STRIDE**2) 25 print(\u0026#34;Anchors in Level {}: {}\u0026#34;.format(l, anchors_per_level[l])) 1Total anchors: 261888 2ANCHOR Scales: (32, 64, 128, 256, 512) 3BACKBONE STRIDE: [4, 8, 16, 32, 64] 4ratios: [0.5, 1, 2] 5Anchors per Cell: 3 6Levels: 5 7backbone_shapes in level 0 256 x 256 8num_cells in level 0 65536 9Anchors in Level 0: 196608 10backbone_shapes in level 1 128 x 128 11num_cells in level 1 16384 12Anchors in Level 1: 49152 13backbone_shapes in level 2 64 x 64 14num_cells in level 2 4096 15Anchors in Level 2: 12288 16backbone_shapes in level 3 32 x 32 17num_cells in level 3 1024 18Anchors in Level 3: 3072 19backbone_shapes in level 4 16 x 16 20num_cells in level 4 256 21Anchors in Level 4: 768 Trong ki·∫øn tr·ª©c FPN, feature map t·∫°i m·ªôt s·ªë layer ƒë·∫ßu ti√™n l√† nh·ªØng feature map c√≥ ƒë·ªô ph√¢n gi·∫£i l·ªõn. V√≠ d·ª•, n·∫øu b·ª©c ·∫£nh ƒë·∫ßu v√†o c√≥ k√≠ch th∆∞·ªõc l√† 1024x1024 pixel, v√† k√≠ch th∆∞·ªõc c·ªßa m·ªói anchor l·ªõp ƒë·∫ßu ti√™n l√† 32x32 pixel (gi√° tr·ªã ƒë·∫ßu ti√™n c·ªßa RPN_ANCHOR_SCALES (32, 64, 128, 256, 512)) v√† b∆∞·ªõc nh·∫£y (STRIDE) c·ªßa l·ªõp ƒë·∫ßu ti√™n l√† 4 (gi√° tr·ªã ƒë·∫ßu ti√™n c·ªßa BACKBONE_STRIDES ([4, 8, 16, 32, 64])). T·ª´ nh·ªØng d·ªØ ki·ªán n√†y, ta c√≥ th·ªÉ suy ra ƒë∆∞·ª£c l√† s·∫Ω sinh ra backbone cell c√≥ k√≠ch th∆∞·ªõc 256x256 pixel =\u0026gt; 256x256 = 65536 anchor. V·ªõi m·ªói backbone cell, ch√∫ng ta th·ª±c hi·ªán ph√©p scale v·ªõi 3 t·ª∑ l·ªá kh√°c nhau l√† [0.5, 1, 2], v·∫≠y ch√∫ng ta c√≥ t·ªïng c·ªông l√† 65536x3 = 196608 anchor (x·∫•p x·ªâ 200k anchor). ƒê·ªÉ √Ω m·ªôt ƒëi·ªÅu l√† k√≠ch th∆∞·ªõc c·ªßa m·ªôt anchor l√† 32x32 pixel, v√† b∆∞·ªõc nh·∫£y l√† 4, cho n√™n ch√∫ng ta s·∫Ω b·ªã ch·ªëng l·∫•n (overlap) 28 pixel c·ªßa anchor 1 v√† anchor 2 ngay sau n√≥.\nM·ªôt ƒëi·ªÅu th√∫ v·ªã l√†, n·∫øu ta tƒÉng b∆∞·ªõc nh·∫£y l√™n g·∫•p 2 l·∫ßn, v√≠ d·ª• t·ª´ 4 pixel l·∫•y m·ªôt anchor l√™n 8 pixel l·∫•y m·ªôt anchor, th√¨ s·ªë l∆∞·ª£ng anchor gi·∫£m ƒëi ƒë·∫øn 4 l·∫ßn (196608 anchor ·ªü level 0 so v·ªõi 49152 anchor ·ªü level 1).\nTh·ª≠ v·∫Ω t·∫•t c·∫£ c√°c anchor c·ªßa t·∫•t c·∫£ c√°c level ·ªü ƒëi·ªÉm gi·ªØa m·ªôt b·ª©c ·∫£nh b·ª©c k·ª≥ l√™n, m·ªói m·ªôt level s·∫Ω d√πng m·ªôt m√†u kh√°c nhau, ch√∫ng ta ƒë∆∞·ª£c m·ªôt h√¨nh nh∆∞ b√™n d∆∞·ªõi.\n1# Visualize anchors of one cell at the center of the feature map of a specific level 2 3# Load and draw random image 4image_id = np.random.choice(dataset.image_ids, 1)[0] 5image, image_meta, _, _, _ = modellib.load_image_gt(dataset, config, image_id) 6fig, ax = plt.subplots(1, figsize=(10, 10)) 7ax.imshow(image) 8levels = len(backbone_shapes) 9 10kn_color =np.array( [(255,0,0),(0,255,0),(0,0,255),(128,0,0),(0,128,0),(0,0,128)])/255. 11 12for level in range(levels): 13 # colors = visualize.random_colors(levels) 14 colors = kn_color 15 # Compute the index of the anchors at the center of the image 16 level_start = sum(anchors_per_level[:level]) # sum of anchors of previous levels 17 level_anchors = anchors[level_start:level_start+anchors_per_level[level]] 18 print(\u0026#34;Level {}. Anchors: {:6} Feature map Shape: {} \u0026#34;.format(level, level_anchors.shape[0], 19 backbone_shapes[level])) 20 center_cell = backbone_shapes[level] // 2 21 center_cell_index = (center_cell[0] * backbone_shapes[level][1] + center_cell[1]) 22 level_center = center_cell_index * anchors_per_cell 23 center_anchor = anchors_per_cell * ( 24 (center_cell[0] * backbone_shapes[level][1] / config.RPN_ANCHOR_STRIDE**2) \\ 25 + center_cell[1] / config.RPN_ANCHOR_STRIDE) 26 level_center = int(center_anchor) 27 28 # Draw anchors. Brightness show the order in the array, dark to bright. 29 for i, rect in enumerate(level_anchors[level_center:level_center+anchors_per_cell]): 30 y1, x1, y2, x2 = rect 31 p = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, facecolor=\u0026#39;none\u0026#39;, 32 edgecolor=np.array(colors[level]) / anchors_per_cell) 33 print(i) 34 ax.add_patch(p) 35 36 37plt.show() Nh√¨n ·∫£nh tr√™n,c√°c b·∫°n ph·∫ßn n√†o ƒë√≥ m∆∞·ªùng t∆∞·ª£ng ra c√°c anchor s·∫Ω nh∆∞ th·∫ø n√†o r·ªìi ph·∫£i kh√¥ng.\nPrediction ƒê·ªÉ ti·∫øn h√†nh detect v·ªã tr√≠ qu·∫£ b√≥ng v√† mask c·ªßa qu·∫£ b√≥ng, ch√∫ng ta download m·ªôt ·∫£nh small party nh·ªè tr√™n internet v·ªÅ v√† ki·ªÉm ch·ª©ng.\n1 2import os 3 4import tensorflow as tf 5 6import cv2 7 8DEVICE = \u0026#34;/cpu:0\u0026#34; 9ROOT_DIR = os.path.abspath(\u0026#34;../../\u0026#34;) 10MODEL_DIR = os.path.join(ROOT_DIR, \u0026#34;logs\u0026#34;) 11# Create model in inference mode 12 13class InferenceConfig(config.__class__): 14 # Run detection on one image at a time 15 GPU_COUNT = 1 16 IMAGES_PER_GPU = 1 17 18config = InferenceConfig() 19config.display() 20 21with tf.device(DEVICE): 22 model = modellib.MaskRCNN(mode=\u0026#34;inference\u0026#34;, model_dir=MODEL_DIR, 23 config=config) 24 25 26weights_path = \u0026#34;mask_rcnn_balloon.h5\u0026#34; 27 28# Load weights 29print(\u0026#34;Loading weights \u0026#34;, weights_path) 30# model.load_weights(weights_path, by_name=True) 31 32imgpath = \u0026#34;datasets\\\\balloon\\\\test\\\\t1.png\u0026#34; 33# imgpath = \u0026#34;datasets/balloon/val/14898532020_ba6199dd22_k.jpg\u0026#34; 34 35image = cv2.imread(imgpath) 36 37image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) 38 39 40 41ds_name = [\u0026#39;BG\u0026#39;, \u0026#39;balloon\u0026#39;] 42 43 44results = model.detect([image], verbose=1) 45 46def get_ax(rows=1, cols=1, size=16): 47 \u0026#34;\u0026#34;\u0026#34;Return a Matplotlib Axes array to be used in 48 all visualizations in the notebook. Provide a 49 central point to control graph sizes. 50 51 Adjust the size attribute to control how big to render images 52 \u0026#34;\u0026#34;\u0026#34; 53 _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows)) 54 return ax 55# Display results 56ax = get_ax(1) 57r = results[0] 58visualize.display_instances(image, r[\u0026#39;rois\u0026#39;], r[\u0026#39;masks\u0026#39;], r[\u0026#39;class_ids\u0026#39;], 59 dataset.class_names, r[\u0026#39;scores\u0026#39;], ax=ax, 60 title=\u0026#34;Predictions\u0026#34;) 61plt.show() K·∫øt qu·∫£ nh·∫≠n d·∫°ng kh√° ch√≠nh x√°c ph·∫£i kh√¥ng c√°c b·∫°n.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Mar 25, 2019","img":"","permalink":"/blog/2019-03-25-mask-rcnn-balloon/","series":null,"tags":["machine learning","deep learning","Mask R-CNN","balloon","b√≥ng bay"],"title":"T√¨m Hi·ªÉu Mask R-CNN V√† V√≠ D·ª• Ph√¢n V√πng Qu·∫£ B√≥ng Bay S·ª≠ D·ª•ng Deep Learning"},{"categories":null,"content":" Th√™m d·∫•u ti·∫øng vi·ªát l√† m·ªôt trong nh·ªØng b√†i to√°n kh√° hay trong x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n. ·ªû ƒë√¢y, m√¨nh ƒë√£ ti·∫øn h√†nh thu th·∫≠p d·ªØ li·ªáu b√†i b√°o c·ªßa nhi·ªÅu ngu·ªìn kh√°c nhau nh∆∞ zing.vn, vnexpress, kenh14.vn \u0026hellip; l√†m kho ng·ªØ li·ªáu v√† x√¢y d·ª±ng m√¥ h√¨nh.\nƒê·ªÉ ti·∫øn h√†nh th·ª±c nghi·ªám, m√¨nh s·∫Ω l·∫•y m·ªôt s·ªë ƒëo·∫°n vƒÉn m·∫´u ·ªü trang tin t·ª©c c·ªßa th·∫ø gi·ªõi di ƒë·ªông (https.www.thegioididong.com) (m√¨nh kh√¥ng crawl n·ªôi dung tin t·ª©c ·ªü trang n√†y l√†m d·ªØ li·ªáu h·ªçc).\n·ªû b√†i vi·∫øt link https://www.thegioididong.com/tin-tuc/3-ngay-cuoi-tuan-mua-laptop-online-tang-them-pmh-den-400k-tra-gop-0--1151334, m√¨nh l·∫•y ƒëo·∫°n m·ªü ƒë·∫ßu \u0026ldquo;T·ª´ ng√†y 15/3 ƒë·∫øn 17/3, nhi·ªÅu m·∫´u laptop t·∫°i Th·∫ø Gi·ªõi Di ƒê·ªông s·∫Ω ƒë∆∞·ª£c ∆∞u ƒë√£i m·∫°nh, t·∫∑ng phi·∫øu mua h√†ng ƒë·∫øn 400 ng√†n ƒë·ªìng, tr·∫£ g√≥p 0% v√† nhi·ªÅu qu√† t·∫∑ng h·∫•p d·∫´n kh√°c khi mua theo h√¨nh th·ª©c ONLINE. N·∫øu ƒëang c√≥ nhu c·∫ßu mua laptop, b·∫°n h√£y nhanh ch√≥ng xem qua danh s√°ch s·∫£n ph·∫©m d∆∞·ªõi ƒë√¢y nh√©.\u0026rdquo;, b·ªè d·∫•u c·ªßa c√¢u ƒëi, th√¨ m√¨nh ƒë∆∞·ª£c c√¢u\n\u0026ldquo;Tu ngay 15/3 den 17/3, nhieu mau laptop tai The Gioi Di Dong se duoc uu dai manh, tang phieu mua hang den 400 ngan dong, tra gop 0% va nhieu qua tang hap dan khac khi mua theo hinh thuc ONLINE. Neu dang co nhu cau mua laptop, ban hay nhanh chong xem qua danh sach san pham duoi day nhe.\u0026rdquo;\nS·ª≠ d·ª•ng m√¥ h√¨nh m√¨nh ƒë√£ hu·∫•n luy·ªán, thu ƒë∆∞·ª£c k·∫øt qu·∫£ nh∆∞ sau:\n\u0026ldquo;T·ª´ ng√†y 15/3 ƒë·∫øn 17/3 m t m, nhi·ªÅu m·∫´u laptoP t·∫°I th·∫ø gi·ªöi di ƒë·ªông s·∫Ω ƒë∆∞·ª£c ∆∞u ƒë√£i m·∫°nh, tang phi·∫øu mua h√†ng ƒë·∫øn 400 ng√†n ƒë·ªìng, tr·∫£ g√≥p 0 r% v√† nhi·ªÅu qu√† t·∫∑ng h·∫•p d·∫´n kh√°c khi mua theo h√¨NH TH·ª®c Onfine. n·∫øu ƒëang c√≥ nhu c·∫ßu mua laptop, b·∫°n h√£y nhanh ch√≥ng xem qua danh s√°ch s·∫£n ph·∫©m d∆∞·ªõi\u0026rdquo;\nK·∫øt qu·∫£ kh√° kh·∫£ quan ph·∫£i kh√¥ng c√°c b·∫°n, c√≤n m·ªôt s·ªë l·ªói nh·ªè ·ªü ph·∫ßn nh·∫≠n d·∫°ng k√Ω t·ª± hoa n·ªØa. M√¨nh s·∫Ω fix l·∫°i ·ªü c√°c b√†i vi·∫øt sau.\nM√¨nh th√≠ nghi·ªám ti·∫øp v·ªõi ph·∫ßn ƒë·∫ßu b√†i vi·∫øt https://www.thegioididong.com/tin-tuc/apple-ban-ra-thi-truong-35-trieu-cap-tai-nghe-airpods-nam-2018-1155181. ƒêo·∫°n \u0026ldquo;H√¥m nay, b√°o c√°o c·ªßa Counterpoint Research cho th·∫•y, trong nƒÉm 2018 Apple ƒë√£ b√°n ƒë∆∞·ª£c kho·∫£ng 35 tri·ªáu c·∫∑p tai nghe kh√¥ng d√¢y AirPods. Theo h√£ng ph√¢n t√≠ch n√†y, AirPods hi·ªán l√† tai nghe kh√¥ng d√¢y ph·ªï bi·∫øn nh·∫•t.\u0026rdquo;, b·ªè d·∫•u ti·∫øng vi·ªát l√† thu ƒë∆∞·ª£c \u0026ldquo;Hom nay, bao cao cua Counterpoint Research cho thay, trong nam 2018 Apple da ban duoc khoang 35 trieu cap tai nghe khong day AirPods. Theo hang phan tich nay, AirPods hien la tai nghe khong day pho bien nhat.\u0026rdquo;\nK·∫øt qu·∫£ c·ªßa m√¥ h√¨nh: \u0026ldquo;H√¥m nay, b·∫°o c√°o c·ªßa Coorteenria eEeeroa c ttt, trong nƒÉm 2018 apple ƒë√£ b√°n ƒë∆∞·ª£c kho·∫£ng 35 tri·ªáu c·∫∑p t·∫°i nghe kh√¥ng ƒë·∫ßy aitcoDs. theo H√†ng ph√¢n t√≠ch n√†y, airxoDs Hi·ªán l√† tai nghe kh√¥ng d·∫°y ph·ªï bi·∫øn nh·∫•t.\u0026rdquo;\nM√¥ h√¨nh c·ªßa m√¨nh cho l·∫∑p 50 l·∫ßn. M√¨nh ti·∫øn h√†nh th√≠ nghi·ªám v√† publish m√¥ h√¨nh ·ªü l·∫ßn l·∫∑p th·ª© 10.\nM√£ ngu·ªìn file predict\n1from keras.models import load_model 2model = load_model(\u0026#39;a_best_weight.h5\u0026#39;) 3 4from collections import Counter 5 6import numpy as np 7 8import utils 9import string 10import re 11 12alphabet = set(\u0026#39;\\x00 _\u0026#39; + string.ascii_lowercase + string.digits + \u0026#39;\u0026#39;.join(utils.ACCENTED_TO_BASE_CHAR_MAP.keys())) 13 14print(\u0026#34;alphabet\u0026#34;,alphabet) 15codec = utils.CharacterCodec(alphabet, utils.MAXLEN) 16 17def guess(ngram): 18 text = \u0026#39; \u0026#39;.join(ngram) 19 text += \u0026#39;\\x00\u0026#39; * (utils.MAXLEN - len(text)) 20 if utils.INVERT: 21 text = text[::-1] 22 preds = model.predict_classes(np.array([codec.encode(text)]), verbose=0) 23 rtext = codec.decode(preds[0], calc_argmax=False).strip(\u0026#39;\\x00\u0026#39;) 24 if len(rtext)\u0026gt;0: 25 index = rtext.find(\u0026#39;\\x00\u0026#39;) 26 if index\u0026gt;-1: 27 rtext = rtext[:index] 28 return rtext 29 30 31def add_accent(text): 32 # lowercase the input text as we train the model on lowercase text only 33 # but we keep the map of uppercase characters to restore cases in output 34 is_uppercase_map = [c.isupper() for c in text] 35 text = utils.remove_accent(text.lower()) 36 37 outputs = [] 38 words_or_symbols_list = re.findall(\u0026#39;\\w[\\w ]*|\\W+\u0026#39;, text) 39 40 # print(words_or_symbols_list) 41 42 for words_or_symbols in words_or_symbols_list: 43 if utils.is_words(words_or_symbols): 44 outputs.append(_add_accent(words_or_symbols)) 45 else: 46 outputs.append(words_or_symbols) 47 # print(outputs) 48 output_text = \u0026#39;\u0026#39;.join(outputs) 49 50 # restore uppercase characters 51 output_text = \u0026#39;\u0026#39;.join(c.upper() if is_upper else c 52 for c, is_upper in zip(output_text, is_uppercase_map)) 53 return output_text 54 55def _add_accent(phrase): 56 grams = list(utils.gen_ngram(phrase.lower(), n=utils.NGRAM, pad_words=utils.PAD_WORDS_INPUT)) 57 58 guessed_grams = list(guess(gram) for gram in grams) 59 # print(\u0026#34;phrase\u0026#34;,phrase,\u0026#39;grams\u0026#39;,grams,\u0026#39;guessed_grams\u0026#39;,guessed_grams) 60 candidates = [Counter() for _ in range(len(guessed_grams) + utils.NGRAM - 1)] 61 for idx, gram in enumerate(guessed_grams): 62 for wid, word in enumerate(re.split(\u0026#39; +\u0026#39;, gram)): 63 candidates[idx + wid].update([word]) 64 output = \u0026#39; \u0026#39;.join(c.most_common(1)[0][0] for c in candidates if c) 65 return output.strip(\u0026#39;\\x00 \u0026#39;) 66 67 68 69# print(add_accent(\u0026#39;do,\u0026#39;)) 70# print(add_accent(\u0026#39;7.3 inch,\u0026#39;)) 71# print(add_accent(\u0026#39;Truoc do, tren san khau su kien SDC 2018, giam doc cao cap mang marketing san pham di dong cua Samsung, ong Justin Denison da cam tren tay nguyen mau cua thiet bi nay. Ve co ban, no chang khac gi mot chiec may tinh bang 7.3 inch, duoc cau thanh tu nhieu lop phu khac nhau nhu polyme, lop man chong soc, lop phan cuc voi do mong gan mot nua so voi the he truoc, lop kinh linh hoat va mot tam lung da nang co the bien thanh man hinh. Tat ca se duoc ket dinh bang mot loai keo cuc ben, cho phep chiec may nay co the gap lai hang tram ngan lan ma khong bi hu hong.\u0026#39;)) 72# print(add_accent(\u0026#39;man hinh. Tat ca se duoc ket dinh bang mot loai keo cuc ben, cho phep chiec may nay co the gap lai hang tram ngan lan ma khong bi hu hong.\u0026#39;)) 73print(add_accent(\u0026#39;Hom nay, bao cao cua Counterpoint Research cho thay, trong nam 2018 Apple da ban duoc khoang 35 trieu cap tai nghe khong day AirPods. Theo hang phan tich nay, AirPods hien la tai nghe khong day pho bien nhat.\u0026#39;)) M√£ ngu·ªìn file utils\n1import re 2import string 3import time 4from contextlib import contextmanager 5import numpy as np 6 7 8 9# maximum string length to train and predict 10# this is set based on our ngram length break down below 11MAXLEN = 32 12 13# minimum string length to consider 14MINLEN = 3 15 16# how many words per ngram to consider in our model 17NGRAM = 5 18 19# inverting the input generally help with accuracy 20INVERT = True 21 22# mini batch size 23BATCH_SIZE = 128 24 25# number of phrases set apart from training set to validate our model 26VALIDATION_SIZE = 100000 27 28# using g2.2xl GPU is ~5x faster than a Macbook Pro Core i5 CPU 29HAS_GPU = True 30 31PAD_WORDS_INPUT = True 32 33### √Ånh x·∫° t·ª´ kh√¥ng d·∫•u sang c√≥ d·∫•u 34 35ACCENTED_CHARS = { 36\t\u0026#39;a\u0026#39;: u\u0026#39;a √° √† ·∫£ √£ ·∫° √¢ ·∫• ·∫ß ·∫© ·∫´ ·∫≠ ƒÉ ·∫Ø ·∫± ·∫≥ ·∫µ ·∫∑\u0026#39;, 37\t\u0026#39;o\u0026#39;: u\u0026#39;o √≥ √≤ ·ªè √µ ·ªç √¥ ·ªë ·ªì ·ªï ·ªó ·ªô ∆° ·ªõ ·ªù ·ªü ·ª° ·ª£\u0026#39;, 38\t\u0026#39;e\u0026#39;: u\u0026#39;e √© √® ·∫ª ·∫Ω ·∫π √™ ·∫ø ·ªÅ ·ªÉ ·ªÖ ·ªá\u0026#39;, 39\t\u0026#39;u\u0026#39;: u\u0026#39;u √∫ √π ·ªß ≈© ·ª• ∆∞ ·ª© ·ª´ ·ª≠ ·ªØ ·ª±\u0026#39;, 40\t\u0026#39;i\u0026#39;: u\u0026#39;i √≠ √¨ ·ªâ ƒ© ·ªã\u0026#39;, 41\t\u0026#39;y\u0026#39;: u\u0026#39;y √Ω ·ª≥ ·ª∑ ·ªπ ·ªµ\u0026#39;, 42\t\u0026#39;d\u0026#39;: u\u0026#39;d ƒë\u0026#39;, 43} 44 45### √Ånh x·∫° t·ª´ c√≥ d·∫•u sang kh√¥ng d·∫•u 46ACCENTED_TO_BASE_CHAR_MAP = {} 47for c, variants in ACCENTED_CHARS.items(): 48\tfor v in variants.split(\u0026#39; \u0026#39;): 49\tACCENTED_TO_BASE_CHAR_MAP[v] = c 50 51# \\x00 k√Ω t·ª± padding 52 53### Nh·ªØng k√Ω t·ª± c∆° b·∫£n, bao g·ªìm k√Ω t·ª± padding, c√°c ch·ªØ c√°i v√† c√°c ch·ªØ s·ªë 54BASE_ALPHABET = set(\u0026#39;\\x00 _\u0026#39; + string.ascii_lowercase + string.digits) 55 56### B·ªô k√Ω t·ª± bao g·ªìm nh·ªØng k√Ω t·ª± c∆° b·∫£n v√† nh·ªØng k√Ω t·ª± c√≥ d·∫•u 57ALPHABET = BASE_ALPHABET.union(set(\u0026#39;\u0026#39;.join(ACCENTED_TO_BASE_CHAR_MAP.keys()))) 58 59 60def is_words(text): 61\treturn re.fullmatch(\u0026#39;\\w[\\w ]*\u0026#39;, text) 62 63# H√†m b·ªè d·∫•u kh·ªèi m·ªôt c√¢u 64def remove_accent(text): 65\t\u0026#34;\u0026#34;\u0026#34; remove accent from text \u0026#34;\u0026#34;\u0026#34; 66\treturn u\u0026#39;\u0026#39;.join(ACCENTED_TO_BASE_CHAR_MAP.get(char, char) for char in text) 67 68#h√†m th√™m padding v√†o m·ªôt c√¢u 69def pad(phrase, maxlen): 70\t\u0026#34;\u0026#34;\u0026#34; right pad given string with \\x00 to exact \u0026#34;maxlen\u0026#34; length \u0026#34;\u0026#34;\u0026#34; 71\treturn phrase + u\u0026#39;\\x00\u0026#39; * (maxlen - len(phrase)) 72 73 74def gen_ngram(words, n=3, pad_words=True): 75\t\u0026#34;\u0026#34;\u0026#34; gen n-grams from given phrase or list of words \u0026#34;\u0026#34;\u0026#34; 76\tif isinstance(words, str): 77\twords = re.split(\u0026#39;\\s+\u0026#39;, words.strip()) 78 79\tif len(words) \u0026lt; n: 80\tif pad_words: 81\twords += [\u0026#39;\\x00\u0026#39;] * (n - len(words)) 82\tyield tuple(words) 83\telse: 84\tfor i in range(len(words) - n + 1): 85\tyield tuple(words[i: i + n]) 86 87def extract_phrases(text): 88\t\u0026#34;\u0026#34;\u0026#34; extract phrases, i.e. group of continuous words, from text \u0026#34;\u0026#34;\u0026#34; 89\treturn re.findall(r\u0026#39;\\w[\\w ]+\u0026#39;, text, re.UNICODE) 90 91 92@contextmanager 93def timing(label): 94\tbegin = time.monotonic() 95\tprint(label, end=\u0026#39;\u0026#39;, flush=True) 96\ttry: 97\tyield 98\tfinally: 99\tduration = time.monotonic() - begin 100\tprint(\u0026#39;: took {:.2f}s\u0026#39;.format(duration)) 101 102class CharacterCodec(object): 103 def __init__(self, alphabet, maxlen): 104 self.alphabet = list(sorted(set(alphabet))) 105 self.index_alphabet = dict((c, i) for i, c in enumerate(self.alphabet)) 106 self.maxlen = maxlen 107 108 def encode(self, C, maxlen=None): 109 maxlen = maxlen if maxlen else self.maxlen 110 X = np.zeros((maxlen, len(self.alphabet))) 111 for i, c in enumerate(C[:maxlen]): 112 X[i, self.index_alphabet[c]] = 1 113 return X 114 115 def try_encode(self, C, maxlen=None): 116 try: 117 return self.encode(C, maxlen) 118 except KeyError: 119 return None 120 121 def decode(self, X, calc_argmax=True): 122 if calc_argmax: 123 X = X.argmax(axis=-1) 124 return \u0026#39;\u0026#39;.join(self.alphabet[x] for x in X) link donwnload m√¥ h√¨nh ·ªü l·∫ßn l·∫∑p th·ª© 10 ·ªü https://github.com/AlexBlack2202/alexmodel/blob/master/a_best_weight.h5?raw=true\n√Ä, k·∫øt qu·∫£ c·ªßa c√¢u n√≥i ph·∫ßn m·ªü ƒë·∫ßu l√† \u0026ldquo;m·∫π n√≥i r·∫±ng em r·∫•t ƒë·∫≠m ƒëang\u0026rdquo;. Hi hi, may qu√°.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Mar 16, 2019","img":"","permalink":"/blog/2019-03-16-vietnamese-accent/","series":null,"tags":["machine learning","nlp","th√™m d·∫•u ti·∫øng vi·ªát"],"title":"Th√™m D·∫•u Ti·∫øng Vi·ªát Cho C√¢u Kh√¥ng D·∫•u"},{"categories":null,"content":"About Us Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi website www.phamduytung.com, n∆°i b·∫°n c√≥ th·ªÉ h·ªçc v√† chia s·∫ª ki·∫øn th·ª©c v·ªÅ machine learning m·ªôt c√°ch d·ªÖ d√†ng v√† th√∫ v·ªã.\nC√¢u chuy·ªán c·ªßa ch√∫ng t√¥i website www.phamduytung.com ƒë∆∞·ª£c th√†nh l·∫≠p v√†o nƒÉm 2017 . Ch√∫ng t√¥i nh·∫≠n th·∫•y r·∫±ng machine learning l√† m·ªôt lƒ©nh v·ª±c r·∫•t quan tr·ªçng v√† ti·ªÅm nƒÉng trong th·ªùi ƒë·∫°i c√¥ng ngh·ªá s·ªë, nh∆∞ng c≈©ng r·∫•t kh√≥ ti·∫øp c·∫≠n v√† h·ªçc t·∫≠p cho nhi·ªÅu ng∆∞·ªùi, ƒë·∫∑c bi·ªát l√† c√°c h·ªçc sinh sinh vi√™n. Ch√∫ng t√¥i mu·ªën t·∫°o ra m·ªôt website n∆°i m·ªçi ng∆∞·ªùi c√≥ th·ªÉ h·ªçc machine learning m·ªôt c√°ch d·ªÖ hi·ªÉu, th·ª±c h√†nh v√† ·ª©ng d·ª•ng v√†o th·ª±c t·∫ø.\nƒê·ªôi ng≈© c·ªßa ch√∫ng t√¥i website www.phamduytung.com l√† s·ª± k·∫øt h·ª£p c·ªßa c√°c th√†nh vi√™n c√≥ kinh nghi·ªám v√† chuy√™n m√¥n v·ªÅ machine learning, gi√°o d·ª•c v√† thi·∫øt k·∫ø web. ƒê√¢y l√† nh·ªØng ng∆∞·ªùi ƒë√£ ƒë√≥ng g√≥p cho s·ª± ph√°t tri·ªÉn c·ªßa website c·ªßa ch√∫ng t√¥i:\nPh·∫°m Duy T√πng: Ng∆∞·ªùi s√°ng l·∫≠p v√† qu·∫£n l√Ω website, c√≥ b·∫±ng th·∫°c sƒ© v·ªÅ Computer Science / machine learning t·∫°i ƒê·∫°i h·ªçc Khoa h·ªçc T·ª± Nhi√™n H·ªì Ch√≠ Minh, c√≥ nhi·ªÅu nƒÉm kinh nghi·ªám l√†m vi·ªác v·ªÅ machine learning c∆° b·∫£n v√† deep learning.\nƒê·∫∑ng Th·ªã H·∫±ng: Chuy√™n gia n·ªôi dung, c√≥ b·∫±ng th·∫°c sƒ© v·ªÅ Computer Science t·∫°i ƒê·∫°i h·ªçc Khoa h·ªçc T·ª± Nhi√™n H·ªì Ch√≠ Minh.\nS·ª© m·ªánh c·ªßa ch√∫ng t√¥i S·ª© m·ªánh c·ªßa ch√∫ng t√¥i l√† mang ƒë·∫øn cho b·∫°n nh·ªØng ki·∫øn th·ª©c v√† k·ªπ nƒÉng v·ªÅ machine learning m·ªôt c√°ch hi·ªáu qu·∫£ v√† th·ª±c t·∫ø. Ch√∫ng t√¥i cung c·∫•p cho b·∫°n c√°c b√†i vi·∫øt v√† c√°c t√†i nguy√™n kh√°c v·ªÅ machine learning, t·ª´ c∆° b·∫£n ƒë·∫øn n√¢ng cao, t·ª´ l√Ω thuy·∫øt ƒë·∫øn th·ª±c h√†nh, t·ª´ ph√¢n t√≠ch ƒë·∫øn ·ª©ng d·ª•ng. Ch√∫ng t√¥i mong mu·ªën b·∫°n c√≥ th·ªÉ h·ªçc machine learning m·ªôt c√°ch t·ª± tin, s√°ng t·∫°o v√† th√†nh c√¥ng.\nLi√™n h·ªá v·ªõi ch√∫ng t√¥i Ch√∫ng t√¥i lu√¥n s·∫µn s√†ng l·∫Øng nghe v√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi, g√≥p √Ω, ph·∫£n h·ªìi v√† y√™u c·∫ßu c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ li√™n h·ªá v·ªõi ch√∫ng t√¥i qua c√°c k√™nh sau:\nEmail: alexblack2202@gmail.com LinkedIn: Ph·∫°m Duy T√πng H√£y b·∫Øt ƒë·∫ßu h·ªçc machine learning c√πng ch√∫ng t√¥i N·∫øu b·∫°n ƒë√£ s·∫µn s√†ng ƒë·ªÉ h·ªçc v√† chia s·∫ª ki·∫øn th·ª©c v·ªÅ machine learning c√πng ch√∫ng t√¥i. B·∫°n c≈©ng c√≥ th·ªÉ truy c·∫≠p c√°c trang kh√°c tr√™n website c·ªßa ch√∫ng t√¥i ƒë·ªÉ kh√°m ph√° th√™m nhi·ªÅu n·ªôi dung v√† d·ªãch v·ª• v·ªÅ machine learning. Ch√∫ng t√¥i mong ƒë∆∞·ª£c ƒë·ªìng h√†nh c√πng b·∫°n tr√™n con ƒë∆∞·ªùng h·ªçc t·∫≠p v√† nghi√™n c·ª©u machine learning.\n","date":"Feb 28, 2019","img":"","permalink":"/about/","series":null,"tags":null,"title":"About"},{"categories":null,"content":"Privacy Policy ==============\nLast updated: February 10, 2024\nThis Privacy Policy describes Our policies and procedures on the collection, use and disclosure of Your information when You use the Service and tells You about Your privacy rights and how the law protects You.\nWe use Your Personal data to provide and improve the Service. By using the Service, You agree to the collection and use of information in accordance with this Privacy Policy.\nInterpretation and Definitions Interpretation 1 2The words of which the initial letter is capitalized have meanings defined 3under the following conditions. The following definitions shall have the same 4meaning regardless of whether they appear in singular or in plural. 5 6## Definitions 7 8~~~~~~~~~~~ 9 10For the purposes of this Privacy Policy: 11 12 * Account means a unique account created for You to access our Service or 13 parts of our Service. 14 15 * Affiliate means an entity that controls, is controlled by or is under 16 common control with a party, where \u0026#34;control\u0026#34; means ownership of 50% or 17 more of the shares, equity interest or other securities entitled to vote 18 for election of directors or other managing authority. 19 20 * Company (referred to as either \u0026#34;the Company\u0026#34;, \u0026#34;We\u0026#34;, \u0026#34;Us\u0026#34; or \u0026#34;Our\u0026#34; in this 21 Agreement) refers to Ph·∫°m Duy T√πng. 22 23 * Cookies are small files that are placed on Your computer, mobile device or 24 any other device by a website, containing the details of Your browsing 25 history on that website among its many uses. 26 27 * Country refers to: Vietnam 28 29 * Device means any device that can access the Service such as a computer, a 30 cellphone or a digital tablet. 31 32 * Personal Data is any information that relates to an identified or 33 identifiable individual. 34 35 * Service refers to the Website. 36 37 * Service Provider means any natural or legal person who processes the data 38 on behalf of the Company. It refers to third-party companies or 39 individuals employed by the Company to facilitate the Service, to provide 40 the Service on behalf of the Company, to perform services related to the 41 Service or to assist the Company in analyzing how the Service is used. 42 43 * Third-party Social Media Service refers to any website or any social 44 network website through which a User can log in or create an account to 45 use the Service. 46 47 * Usage Data refers to data collected automatically, either generated by the 48 use of the Service or from the Service infrastructure itself (for example, 49 the duration of a page visit). 50 51 * Website refers to Ph·∫°m Duy T√πng, accessible from 52 \u0026lt;https://www.phamduytung.com/\u0026gt; 53 54 * You means the individual accessing or using the Service, or the company, 55 or other legal entity on behalf of which such individual is accessing or 56 using the Service, as applicable. 57 58 59# Collecting and Using Your Personal Data 60--------------------------------------- 61 62## Types of Data Collected Personal Data While using Our Service, We may ask You to provide Us with certain personally identifiable information that can be used to contact or identify You. Personally identifiable information may include, but is not limited to:\nUsage Data Usage Data Usage Data is collected automatically when using the Service.\nUsage Data may include information such as Your Device\u0026rsquo;s Internet Protocol address (e.g. IP address), browser type, browser version, the pages of our Service that You visit, the time and date of Your visit, the time spent on those pages, unique device identifiers and other diagnostic data.\nWhen You access the Service by or through a mobile device, We may collect certain information automatically, including, but not limited to, the type of mobile device You use, Your mobile device unique ID, the IP address of Your mobile device, Your mobile operating system, the type of mobile Internet browser You use, unique device identifiers and other diagnostic data.\nWe may also collect information that Your browser sends whenever You visit our Service or when You access the Service by or through a mobile device.\nInformation from Third-Party Social Media Services The Company allows You to create an account and log in to use the Service through the following Third-party Social Media Services:\nGoogle Facebook Instagram Twitter LinkedIn If You decide to register through or otherwise grant us access to a Third- Party Social Media Service, We may collect Personal data that is already associated with Your Third-Party Social Media Service\u0026rsquo;s account, such as Your name, Your email address, Your activities or Your contact list associated with that account.\nYou may also have the option of sharing additional information with the Company through Your Third-Party Social Media Service\u0026rsquo;s account. If You choose to provide such information and Personal Data, during registration or otherwise, You are giving the Company permission to use, share, and store it in a manner consistent with this Privacy Policy.\nTracking Technologies and Cookies We use Cookies and similar tracking technologies to track the activity on Our Service and store certain information. Tracking technologies used are beacons, tags, and scripts to collect and track information and to improve and analyze Our Service. The technologies We use may include:\nCookies or Browser Cookies. A cookie is a small file placed on Your Device. You can instruct Your browser to refuse all Cookies or to indicate when a Cookie is being sent. However, if You do not accept Cookies, You may not be able to use some parts of our Service. Unless you have adjusted Your browser setting so that it will refuse Cookies, our Service may use Cookies. Web Beacons. Certain sections of our Service and our emails may contain small electronic files known as web beacons (also referred to as clear gifs, pixel tags, and single-pixel gifs) that permit the Company, for example, to count users who have visited those pages or opened an email and for other related website statistics (for example, recording the popularity of a certain section and verifying system and server integrity). Cookies can be \u0026ldquo;Persistent\u0026rdquo; or \u0026ldquo;Session\u0026rdquo; Cookies. Persistent Cookies remain on Your personal computer or mobile device when You go offline, while Session Cookies are deleted as soon as You close Your web browser.\nWe use both Session and Persistent Cookies for the purposes set out below:\nNecessary / Essential Cookies\nType: Session Cookies\nAdministered by: Us\nPurpose: These Cookies are essential to provide You with services available through the Website and to enable You to use some of its features. They help to authenticate users and prevent fraudulent use of user accounts. Without these Cookies, the services that You have asked for cannot be provided, and We only use these Cookies to provide You with those services.\nCookies Policy / Notice Acceptance Cookies\nType: Persistent Cookies\nAdministered by: Us\nPurpose: These Cookies identify if users have accepted the use of cookies on the Website.\nFunctionality Cookies\nType: Persistent Cookies\nAdministered by: Us\nPurpose: These Cookies allow us to remember choices You make when You use the Website, such as remembering your login details or language preference. The purpose of these Cookies is to provide You with a more personal experience and to avoid You having to re-enter your preferences every time You use the Website.\nFor more information about the cookies we use and your choices regarding cookies, please visit our Cookies Policy or the Cookies section of our Privacy Policy.\nUse of Your Personal Data 1 2The Company may use Personal Data for the following purposes: 3 4 * To provide and maintain our Service , including to monitor the usage of 5 our Service. 6 7 * To manage Your Account: to manage Your registration as a user of the 8 Service. The Personal Data You provide can give You access to different 9 functionalities of the Service that are available to You as a registered 10 user. 11 12 * For the performance of a contract: the development, compliance and 13 undertaking of the purchase contract for the products, items or services 14 You have purchased or of any other contract with Us through the Service. 15 16 * To contact You: To contact You by email, telephone calls, SMS, or other 17 equivalent forms of electronic communication, such as a mobile 18 application\u0026#39;s push notifications regarding updates or informative 19 communications related to the functionalities, products or contracted 20 services, including the security updates, when necessary or reasonable for 21 their implementation. 22 23 * To provide You with news, special offers and general information about 24 other goods, services and events which we offer that are similar to those 25 that you have already purchased or enquired about unless You have opted 26 not to receive such information. 27 28 * To manage Your requests: To attend and manage Your requests to Us. 29 30 * For business transfers: We may use Your information to evaluate or conduct 31 a merger, divestiture, restructuring, reorganization, dissolution, or 32 other sale or transfer of some or all of Our assets, whether as a going 33 concern or as part of bankruptcy, liquidation, or similar proceeding, in 34 which Personal Data held by Us about our Service users is among the assets 35 transferred. 36 37 * For other purposes : We may use Your information for other purposes, such 38 as data analysis, identifying usage trends, determining the effectiveness 39 of our promotional campaigns and to evaluate and improve our Service, 40 products, services, marketing and your experience. 41 42 43We may share Your personal information in the following situations: 44 45 * With Service Providers: We may share Your personal information with 46 Service Providers to monitor and analyze the use of our Service, to 47 contact You. 48 * For business transfers: We may share or transfer Your personal information 49 in connection with, or during negotiations of, any merger, sale of Company 50 assets, financing, or acquisition of all or a portion of Our business to 51 another company. 52 * With Affiliates: We may share Your information with Our affiliates, in 53 which case we will require those affiliates to honor this Privacy Policy. 54 Affiliates include Our parent company and any other subsidiaries, joint 55 venture partners or other companies that We control or that are under 56 common control with Us. 57 * With business partners: We may share Your information with Our business 58 partners to offer You certain products, services or promotions. 59 * With other users: when You share personal information or otherwise 60 interact in the public areas with other users, such information may be 61 viewed by all users and may be publicly distributed outside. If You 62 interact with other users or register through a Third-Party Social Media 63 Service, Your contacts on the Third-Party Social Media Service may see 64 Your name, profile, pictures and description of Your activity. Similarly, 65 other users will be able to view descriptions of Your activity, 66 communicate with You and view Your profile. 67 * With Your consent : We may disclose Your personal information for any 68 other purpose with Your consent. 69 70## Retention of Your Personal Data The Company will retain Your Personal Data only for as long as is necessary for the purposes set out in this Privacy Policy. We will retain and use Your Personal Data to the extent necessary to comply with our legal obligations (for example, if we are required to retain your data to comply with applicable laws), resolve disputes, and enforce our legal agreements and policies.\nThe Company will also retain Usage Data for internal analysis purposes. Usage Data is generally retained for a shorter period of time, except when this data is used to strengthen the security or to improve the functionality of Our Service, or We are legally obligated to retain this data for longer time periods.\nTransfer of Your Personal Data 1 2Your information, including Personal Data, is processed at the Company\u0026#39;s 3operating offices and in any other places where the parties involved in the 4processing are located. It means that this information may be transferred to ‚Äî 5and maintained on ‚Äî computers located outside of Your state, province, country 6or other governmental jurisdiction where the data protection laws may differ 7than those from Your jurisdiction. 8 9Your consent to this Privacy Policy followed by Your submission of such 10information represents Your agreement to that transfer. 11 12The Company will take all steps reasonably necessary to ensure that Your data 13is treated securely and in accordance with this Privacy Policy and no transfer 14of Your Personal Data will take place to an organization or a country unless 15there are adequate controls in place including the security of Your data and 16other personal information. 17 18## Delete Your Personal Data 19~~~~~~~~~~~~~~~~~~~~~~~~~ 20 21You have the right to delete or request that We assist in deleting the 22Personal Data that We have collected about You. 23 24Our Service may give You the ability to delete certain information about You 25from within the Service. 26 27You may update, amend, or delete Your information at any time by signing in to 28Your Account, if you have one, and visiting the account settings section that 29allows you to manage Your personal information. You may also contact Us to 30request access to, correct, or delete any personal information that You have 31provided to Us. 32 33Please note, however, that We may need to retain certain information when we 34have a legal obligation or lawful basis to do so. 35 36## Disclosure of Your Personal Data Business Transactions If the Company is involved in a merger, acquisition or asset sale, Your Personal Data may be transferred. We will provide notice before Your Personal Data is transferred and becomes subject to a different Privacy Policy.\nLaw enforcement Under certain circumstances, the Company may be required to disclose Your Personal Data if required to do so by law or in response to valid requests by public authorities (e.g. a court or a government agency).\nOther legal requirements The Company may disclose Your Personal Data in the good faith belief that such action is necessary to:\nComply with a legal obligation Protect and defend the rights or property of the Company Prevent or investigate possible wrongdoing in connection with the Service Protect the personal safety of Users of the Service or the public Protect against legal liability Security of Your Personal Data 1 2The security of Your Personal Data is important to Us, but remember that no 3method of transmission over the Internet, or method of electronic storage is 4100% secure. While We strive to use commercially acceptable means to protect 5Your Personal Data, We cannot guarantee its absolute security. 6 7# Children\u0026#39;s Privacy 8------------------ 9 10Our Service does not address anyone under the age of 13. We do not knowingly 11collect personally identifiable information from anyone under the age of 13. 12If You are a parent or guardian and You are aware that Your child has provided 13Us with Personal Data, please contact Us. If We become aware that We have 14collected Personal Data from anyone under the age of 13 without verification 15of parental consent, We take steps to remove that information from Our 16servers. 17 18If We need to rely on consent as a legal basis for processing Your information 19and Your country requires consent from a parent, We may require Your parent\u0026#39;s 20consent before We collect and use that information. 21 22# Links to Other Websites 23----------------------- 24 25Our Service may contain links to other websites that are not operated by Us. 26If You click on a third party link, You will be directed to that third party\u0026#39;s 27site. We strongly advise You to review the Privacy Policy of every site You 28visit. 29 30We have no control over and assume no responsibility for the content, privacy 31policies or practices of any third party sites or services. 32 33# Changes to this Privacy Policy 34------------------------------ 35 36We may update Our Privacy Policy from time to time. We will notify You of any 37changes by posting the new Privacy Policy on this page. 38 39We will let You know via email and/or a prominent notice on Our Service, prior 40to the change becoming effective and update the \u0026#34;Last updated\u0026#34; date at the top 41of this Privacy Policy. 42 43You are advised to review this Privacy Policy periodically for any changes. 44Changes to this Privacy Policy are effective when they are posted on this 45page. 46 47# Contact Us 48---------- 49 50If you have any questions about this Privacy Policy, You can contact us: 51 52 * By email: alexblack2202@gmail.com 53 54 * By visiting this page on our website: 55 \u0026lt;https://www.phamduytung.com/contact/\u0026gt; ","date":"Feb 28, 2019","img":"","permalink":"/privacy/","series":null,"tags":null,"title":"Privacy Policy"},{"categories":null,"content":"Website Terms and Conditions of Use 1. Terms By accessing this Website, accessible from https://www.phamduytung.com/, you are agreeing to be bound by these Website Terms and Conditions of Use and agree that you are responsible for the agreement with any applicable local laws. If you disagree with any of these terms, you are prohibited from accessing this site. The materials contained in this Website are protected by copyright and trade mark law.\n2. Use License Permission is granted to temporarily download one copy of the materials on Ph·∫°m Duy T√πng's Website for personal, non-commercial transitory viewing only. This is the grant of a license, not a transfer of title, and under this license you may not:\nmodify or copy the materials; use the materials for any commercial purpose or for any public display; attempt to reverse engineer any software contained on Ph·∫°m Duy T√πng's Website; remove any copyright or other proprietary notations from the materials; or transferring the materials to another person or \"mirror\" the materials on any other server. This will let Ph·∫°m Duy T√πng to terminate upon violations of any of these restrictions. Upon termination, your viewing right will also be terminated and you should destroy any downloaded materials in your possession whether it is printed or electronic format. These Terms of Service has been created with the help of the Terms Of Service Generator.\n3. Disclaimer All the materials on Ph·∫°m Duy T√πng's Website are provided \"as is\". Ph·∫°m Duy T√πng makes no warranties, may it be expressed or implied, therefore negates all other warranties. Furthermore, Ph·∫°m Duy T√πng does not make any representations concerning the accuracy or reliability of the use of the materials on its Website or otherwise relating to such materials or any sites linked to this Website.\n4. Limitations Ph·∫°m Duy T√πng or its suppliers will not be hold accountable for any damages that will arise with the use or inability to use the materials on Ph·∫°m Duy T√πng's Website, even if Ph·∫°m Duy T√πng or an authorize representative of this Website has been notified, orally or written, of the possibility of such damage. Some jurisdiction does not allow limitations on implied warranties or limitations of liability for incidental damages, these limitations may not apply to you.\n5. Revisions and Errata The materials appearing on Ph·∫°m Duy T√πng's Website may include technical, typographical, or photographic errors. Ph·∫°m Duy T√πng will not promise that any of the materials in this Website are accurate, complete, or current. Ph·∫°m Duy T√πng may change the materials contained on its Website at any time without notice. Ph·∫°m Duy T√πng does not make any commitment to update the materials.\n6. Links Ph·∫°m Duy T√πng has not reviewed all of the sites linked to its Website and is not responsible for the contents of any such linked site. The presence of any link does not imply endorsement by Ph·∫°m Duy T√πng of the site. The use of any linked website is at the user's own risk.\n7. Site Terms of Use Modifications Ph·∫°m Duy T√πng may revise these Terms of Use for its Website at any time without prior notice. By using this Website, you are agreeing to be bound by the current version of these Terms and Conditions of Use.\n8. Your Privacy Please read our Privacy Policy.\n9. Governing Law Any claim related to Ph·∫°m Duy T√πng's Website shall be governed by the laws of vn without regards to its conflict of law provisions.\n","date":"Feb 28, 2019","img":"","permalink":"/teamofservices/","series":null,"tags":null,"title":"Team of Services"},{"categories":null,"content":" B√†i to√°n ng∆∞·ªùi giao h√†ng l√† g√¨ C√†i ƒë·∫∑t ch∆∞∆°ng tr√¨nh v√† th·ª±c thi X√¢y d·ª±ng vector state X√¢y d·ª±ng h√†m fitness function X√°c ƒë·ªãnh lo·∫°i b√†i to√°n X√°c ƒë·ªãnh thu·∫≠t to√°n t·ªëi ∆∞u B√†i to√°n ng∆∞·ªùi giao h√†ng l√† g√¨ Ng∆∞·ªùi giao h√†ng l√† b√†i to√°n c∆° b·∫£n trong nh√≥m b√†i to√°n t·ªëi ∆∞u. B√†i to√°n ƒë∆∞·ª£c ph√°t bi·ªÉu nh∆∞ sau: C√≥ m·ªôt ng∆∞·ªùi giao h√†ng c·∫ßn ƒëi giao h√†ng t·∫°i n th√†nh ph·ªë. Xu·∫•t ph√°t t·ª´ m·ªôt th√†nh ph·ªë n√†o ƒë√≥, ƒëi qua c√°c th√†nh ph·ªë kh√°c ƒë·ªÉ giao h√†ng v√† tr·ªü v·ªÅ th√†nh ph·ªë ban ƒë·∫ßu. M·ªói th√†nh ph·ªë ch·ªâ ƒë·∫øn m·ªôt l·∫ßn, kho·∫£ng c√°ch t·ª´ m·ªôt th√†nh ph·ªë ƒë·∫øn c√°c th√†nh ph·ªë kh√°c l√† x√°c ƒë·ªãnh ƒë∆∞·ª£c. H√£y t√¨m m·ªôt chu tr√¨nh (m·ªôt ƒë∆∞·ªùng ƒëi kh√©p k√≠n th·ªèa m√£n ƒëi·ªÅu ki·ªán tr√™n) sao cho t·ªïng ƒë·ªô d√†i c√°c c·∫°nh l√† nh·ªè nh·∫•t.\nC√≥ r·∫•t nhi·ªÅu c√°ch ƒë·ªÉ gi·∫£i b√†i to√°n n√†y, c√°c b·∫°n ƒë·ªçc c√≥ th·ªÉ search google ƒë·ªÉ t√¨m th√™m c√°ch gi·∫£i kh√°c, ·ªü ƒë√¢y, m√¨nh s·∫Ω tr√¨nh b√†y c√°ch s·ª≠ d·ª•ng th∆∞ vi·ªán mlrose c·ªßa python ƒë·ªÉ gi·∫£i quy·∫øt b√†i to√°n tr√™n.\nC√†i ƒë·∫∑t ch∆∞∆°ng tr√¨nh v√† th·ª±c thi Ch√∫ng ta gi·∫£ ƒë·ªãnh r·∫±ng ng∆∞·ªùi giao h√†ng s·∫Ω ƒëi qua 5 th√†nh ph·ªë, v√† m·ªói th√†nh ph·ªë s·∫Ω c√≥ 2 gi√° tr·ªã x v√† y t∆∞∆°ng ·ª©ng v·ªõi to·∫° ƒë·ªô c·ªßa c√°c th√†nh ph·ªë ƒë√≥ tr√™n b·∫£n ƒë·ªì.\n1input = [ 2[9, 12], 3[24, 15], 4[12 ,30], 5[4 ,3], 6[13, 27], 7] Theo ph·∫ßn tr∆∞·ªõc, ch√∫ng ta s·∫Ω x√¢y d·ª±ng 4 ph·∫ßn\nX√¢y d·ª±ng vector state ƒê∆°n gi·∫£n l√† m·ªôt vector x c√≥ s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ b·∫±ng s·ªë l∆∞·ª£ng th√†nh ph·ªë m√† ng∆∞·ªùi giao h√†ng s·∫Ω vi·∫øt thƒÉm\nx = [x0,x1,2,x3,x4], trong ƒë√≥, gi√° tr·ªã x1 l√† ch·ªâ s·ªë c·ªßa th√†nh ph·ªë ng∆∞·ªùi giao h√†ng s·∫Ω gh√© ƒë·∫ßu ti√™n, x0 l√† to·∫° ƒë·ªô th√†nh ph·ªë b·∫Øt ƒë·∫ßu\nX√¢y d·ª±ng h√†m fitness function M·ª•c ti√™u c·ªßa b√†i to√°n l√† t√¨m ƒë∆∞·ªùng ƒëi ngƒÉn nh·∫•t, n√™n ch√∫ng ta c√≥ th·ªÉ d·ªÖ d√†ng x√¢y d·ª±ng h√†n fitness b·∫±ng c√°ch t√≠nh kho·∫£ng c√°ch euclide gi·ªØa c√°c th√†nh ph·ªë.\n1 2def fitness_fun(state): 3 distance = 0 4 5 for index in range(1, len(state)): 6 dist = np.linalg.norm(input[state[index-1]]-input[state[index]]) 7 8 distance = distance + dist 9 10 dist = np.linalg.norm(input[state[0]]-input[state[len(state)-1]]) 11 distance = distance + dist 12 13 return distance 14 15fitness_cust = mlrose.CustomFitness(fitness_fun,\u0026#39;tsp\u0026#39;) X√°c ƒë·ªãnh lo·∫°i b√†i to√°n ƒê√¢y l√† b√†i to√°n r·ªùi r·∫°c kh√¥ng l·∫∑p, n√™n ta s·∫Ω s·ª≠ d·ª•ng h√†m TSPOpt, length = 5 do s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ c·ªßa state l√† 5, maximize=False do b√†i to√°n t√¨m ƒë∆∞·ªùng ƒëi ng·∫Øn nh·∫•t .\n1problem_fit = mlrose.TSPOpt(length = 5, fitness_fn = fitness_cust, 2 maximize=False) X√°c ƒë·ªãnh thu·∫≠t to√°n t·ªëi ∆∞u Ch√∫ng ta v·∫´n ti·∫øp t·ª•c s·ª≠ d·ª•ng thu·∫≠t to√°n simulated_annealing nh∆∞ tr∆∞·ªõc xem k·∫øt qu·∫£ nh∆∞ th·∫ø n√†o\n1#Define decay schedule 2schedule = mlrose.ExpDecay() 3 4# Define initial state 5init_state = np.array([0, 1, 2, 3, 4]) 6 7# Set random seed 8np.random.seed(1) 9 10# Solve problem using simulated annealing 11best_state, best_fitness = mlrose.simulated_annealing(problem, schedule = schedule, 12 max_attempts = 10, max_iters = 500, 13 init_state = init_state) 14 15print(\u0026#39;The best state found is: \u0026#39;, best_state) 16print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) K·∫øt qu·∫£\n1The best state found is: [1 4 2 0 3] 2The fitness at the best state is: 71.30882356753094 ƒê√¢y l√† k·∫øt qu·∫£ t·ªëi ∆∞u c·ªßa b√†i to√°n.\nTh·ª≠ thay b·∫±ng gi·∫£i thu·∫≠t di truy·ªÅn GA, v·ªõi t·ª∑ l·ªá ƒë·ªôt bi·∫øn l√† 0.2\n1best_state, best_fitness = mlrose.genetic_alg(problem,mutation_prob = 0.2) 2 3print(\u0026#39;The best state found is: \u0026#39;, best_state) 4print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) K·∫øt qu·∫£\n1 2The best state found is: [0 2 4 1 3] 3The fitness at the best state is: 71.30882356753094 Th·ª≠ thay ƒë·ªïi t·∫≠p d·ªØ li·ªáu input c√≥ nhi·ªÅu s·ªë ph·∫ßn t·ª≠ h∆°n\n1input =[(1, 1), (4, 2), (5, 2), (6, 4), (4, 4), (3, 6), (1, 5), (2, 3)] K·∫øt qu·∫£\n1The best state found is: [3 4 5 6 7 0 1 2] 2The fitness at the best state is: 17.34261754766733 C·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Feb 8, 2019","img":"","permalink":"/blog/2019-02-08-randomized-optimization-in-python-v1/","series":null,"tags":["ch·∫•m ƒëi·ªÉm c√¥ng d√¢n","china","China social credit system","credit system"],"title":"T·ªëi ∆Øu Ho√° Ng·∫´u Nhi√™n - B√†i To√°n Ng∆∞·ªùi Giao H√†ng"},{"categories":null,"content":" B√†i to√°n t·ªëi ∆∞u ho√° l√† g√¨ V√≠ d·ª• T·∫°i sao l·∫°i d√πng Randomized Optimization? Gi·∫£i b√†i to√°n t·ªëi ∆∞u b·∫±ng th∆∞ vi·ªán mlrose B√†i to√°n 8 h·∫≠u ƒê·ªãnh nghƒ©a state ƒê·ªãnh nghƒ©a fitness funtion X√°c ƒë·ªãnh lo·∫°i b√†i to√°n X√°c ƒë·ªãnh thu·∫≠t to√°n t·ªëi ∆∞u B√†i to√°n t·ªëi ∆∞u ho√° l√† g√¨ Theo Russell and Norvig b√†i to√°n t·ªëi ∆∞u ho√° l√† b√†i to√°n m√† \u0026ldquo;the aim is to find the best state according to an objective function\u0026rdquo; (m√¨nh xin ph√©p ƒë·ªÉ nguy√™n c√¢u ti·∫øng anh).\nTrong ƒë√≥, state trong t·ª´ best state ph·ª• thu·ªôc v√†o ng·ªØ c·∫£nh c·ªßa b√†i to√°n. V√≠ d·ª•c\nTrong ng·ªØ c·∫£nh l√† m·∫°ng neural network, state ch√≠nh l√† c√°c tr·ªçng s·ªë (weight), best state l√† t√¨m c√°c tr·ªçng s·ªë t·ªëi ∆∞u Trong b√†i to√°n 8 h·∫≠u, state l√† v·ªã tr√≠ c·ªßa c√°c con h·∫≠u, best state l√† v·ªã tr√≠ t·ªët nh·∫•t tho·∫£ y√™u c·∫ßu, c≈©ng ch√≠nh l√† l·ªùi gi·∫£i. Trong b√†i to√°n ng∆∞·ªùi giao h√†ng, state l√† c√°c th√†nh ph·ªë ng∆∞·ªùi giao h√†ng ƒëi qua. Trong b√†i to√°n t√¥ m√†u cho m·ªói qu·ªëc gia tr√™n b·∫£n ƒë·ªì, state l√† m√†u ƒë∆∞·ª£c t√¥ cho m·ªói qu·ªëc gia N√≥i ƒë·∫øn ƒë√¢y, c√°c b·∫°n ch·∫Øc c≈©ng ƒë√£ hi·ªÉu ƒë∆∞·ª£c kh√°i ni·ªám state l√† g√¨ r·ªìi. ƒêi·ªÅu quan tr·ªçng ·ªü ƒë√¢y l√† ch√∫ng ta c√≥ th·ªÉ bi·ªÉu di·ªÖn state d∆∞·ªõi d·∫°ng m·ªôt con s·ªë, ho·∫∑c m·ªôt m·∫£ng c√°c gi√° tr·ªã s·ªë. (nghƒ©a l√† ch√∫ng ta ph·∫£i chuy·ªÉn ƒë·ªïi m√†u, th√†nh ph·ªë, \u0026hellip; d∆∞·ªõi d·∫°ng s·ªë) th√¨ m·ªõi c√≥ th·ªÉ t√≠nh to√°n ƒë∆∞·ª£c.\nT·ª´ best trong ch·ªØ best state ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·ªüi m·ªôt h√†m to√°n h·ªçc (m√† ch√∫ng ta quen thu·ªôc v·ªõi c√°c t·ª´ nh∆∞ l√† objective funtion, fitness funtion, cost funtion, loss function , v.v). C√°i m√† ch√∫ng ta mu·ªën l√† c·ª±c ƒë·∫°i ho·∫∑c c·ª±c ti·ªÉu ho√° n√≥ (ƒë·ªÉ c√≥ ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªët nh·∫•t). H√†m n√†y nh·∫≠n ƒë·∫ßu v√†o l√† state array v√† tr·∫£ v·ªÅ \u0026ldquo;fitness\u0026rdquo; value.\nCho n√™n, ch√∫ng ta c√≥ th·ªÉ ƒë·ªãnh nghƒ©a ƒë∆°n gi·∫£n b√†i to√°n t·ªëi ∆∞u l√† vi·ªác t√¨m c√°c gi√° tr·ªã t·ªëi ∆∞u ƒë·ªÉ c·ª±c ƒë·∫°i/ c·ª±c ti·ªÉu ho√° m·ªôt h√†m to√°n h·ªçc.\nV√≠ d·ª• M·ªôt v√≠ d·ª• x√†m x√†m nh∆∞ sau\nTa c√≥ m·ªôt (state) vector x = [x0,x1,x2,x3,x4] thu·ªôc ƒëo·∫°n [0,1] m·ªôt h√†m f(x) = x0 + x1 + x2 + x3 + x4, t√¨m c√°c gi√° tr·ªã x ƒë·ªÉ f ƒë·∫°t c·ª±c ƒë·∫°i.\nR√µ r√†ng, b·∫±ng vi·ªác t√≠nh nh·∫©m, ch√∫ng ta bi·∫øt ƒë∆∞·ª£c r·∫±ng gi√° tr·ªã c·ª±c ƒë·∫°i c·ªßa h√†m tr√™n l√† 5, v√† l·ªùi gi·∫£i cho b√†i to√°n tr√™n l√† x = [1,1,1,1,1].\nC√≤n theo to√°n h·ªçc c·∫•p 3, ta s·∫Ω t√≠nh ƒë·∫°o h√†m ri√™ng ph·∫ßn c·ªßa t·ª´ng ph·∫ßn t·ª≠ (c√°i n√†y ƒë∆°n gi·∫£n, m√¨nh kh√¥ng nh·∫Øc l·∫°i), v√† c≈©ng ƒë·∫°t ƒë∆∞·ª£c x = [1,1,1,1,1]\nT·∫°i sao l·∫°i d√πng Randomized Optimization? Trong b√†i to√°n ·ªü tr√™n, ch√∫ng ta c√≥ th·ªÉ d·ªÖ d√†ng nh·∫©m ƒë∆∞·ª£c gi√° tr·ªã t·ªëi ∆∞u m·ªôt c√°ch nhanh ch√≥ng. Tuy nhi√™n, trong th·ª±c t·∫ø, b√†i to√°n s·∫Ω kh√≥ h∆°n m·ªôt ch√∫t, v√† c√≥ nhi·ªÅu h√†m ch√∫ng ta kh√¥ng th·ªÉ d·ªÖ d√†ng t√¨m ƒë∆∞·ª£c gi√° tr·ªã ƒë·∫°o h√†m m·ªôt c√°ch nhanh ch√≥ng ƒë∆∞·ª£c (t·ªën th·ªùi gian r·∫•t l√¢u ƒë·ªÉ gi·∫£i b√†i to√°n ). L√∫c n√†y, ch√∫ng ta s·∫Ω d√πng Randomized optimization.\nRandomized optimization s·∫Ω b·∫Øt ƒë·∫ßu t·∫°i m·ªôt ƒëi·ªÉm ng·∫´u nhi√™n \u0026ldquo;best\u0026rdquo; state n√†o ƒë√≥, sau ƒë√≥ s·∫Ω sinh ng·∫´u nhi√™n m·ªôt state kh√°c (th∆∞·ªùng l√† l√°ng gi·ªÅng c·ªßa \u0026ldquo;best\u0026rdquo; state hi·ªán t·∫°i). N·∫øu state m·ªõi ƒë·∫°t gi√° tr·ªã finest t·ªët h∆°n \u0026ldquo;best\u0026rdquo; state hi·ªán t·∫°i th√¨ g√°n \u0026ldquo;best\u0026rdquo; state b·∫±ng state m·ªõi. Qu√° tr√¨nh n√†y l·∫∑p ƒëi l·∫∑p l·∫°i cho ƒë·∫øn khi kh√¥ng th·ªÉ t√¨m ƒë∆∞·ª£c state m·ªõi n√†y t·ªët h∆°n \u0026ldquo;best\u0026rdquo; state hi·ªán t·∫°i.\nKh√¥ng c√≥ g√¨ b·∫£o ƒë·∫£m r·∫±ng randomized optimization s·∫Ω t√¨m ƒë∆∞·ª£c l·ªùi gi·∫£i t·ªëi ∆∞u. V√≠ d·ª• nh∆∞ h√¨nh tr√™n, thu·∫≠t to√°n ch·ªâ c√≥ th·ªÉ d·ª´ng ·ªü local maximin, r·ªìi ƒë·ª©ng y√™n ·ªü ƒë√≥. Tuy nhi√™n, n·∫øu ch√∫ng ta thi·∫øt l·∫≠p s·ªë l·∫ßn l·∫∑p ƒë·ªß l·ªõn, thu·∫≠t to√°n th√¥ng th∆∞·ªùng s·∫Ω tr·∫£ v·ªÅ k·∫øt qu·∫£ t·ªët h∆°n.\n·ªû ƒë√¢y, ch√∫ng ta c√≥ m·ªôt s·ª± ƒë√°nh ƒë·ªïi trade-off gi·ªØa th·ªùi gian t√¨m ra l·ªùi gi·∫£i t·ªëi ∆∞u v√† ch·∫•t l∆∞·ª£ng c·ªßa l·ªùi gi·∫£i.\nGi·∫£i b√†i to√°n t·ªëi ∆∞u b·∫±ng th∆∞ vi·ªán mlrose ƒê·ªÉ gi·∫£i b√†i to√°n t·ªëi ∆∞u b·∫±ng th∆∞ vi·ªán mlrose, ch√∫ng ta s·∫Ω ph·∫£i ƒë·ªãnh nghƒ©a 4 th·ª©:\nƒê·ªãnh nghƒ©a state vector ƒê·ªãnh nghƒ©a h√†m fitness function X√°c ƒë·ªãnh lo·∫°i b√†i to√°n Ch·ªçn m·ªôt thu·∫≠t to√°n t·ªëi ∆∞u ho√° ng·∫´u nhi√™n ƒë·ªÉ ch·∫°y. ƒê·ªÉ ƒë∆°n gi·∫£n, ch√∫ng ta s·∫Ω gi·∫£i quy·∫øt b√†i to√°n 8 h·∫≠u b·∫±ng th∆∞ vi·ªán mlrose.\nB√†i to√°n 8 h·∫≠u Nh·∫Øc l·∫°i m·ªôt ch√∫t v·ªÅ b√†i to√°n 8 h·∫≠u. Trong b√†n c·ªù vua c√≥ k√≠ch th∆∞·ªõc 8x8, ch√∫ng ta ph·∫£i ch·ªçn v·ªã tr√≠ ƒë·∫∑t 8 con h·∫≠u sao cho tr√™n m·ªói d√≤ng, c·ªôt v√† ƒë∆∞·ªùng ch√©o c·ªßa m·ªôt con h·∫≠u b·∫•t k·ª≥ ƒëang ƒë·ª©ng kh√¥ng gi√°p m·∫∑t v·ªõi con h·∫≠u kh√°c.\nƒê·ªãnh nghƒ©a state ƒê√¢y r√µ r√†ng l√† b√†i to√°n t·ªëi ∆∞u, v√† b∆∞·ªõc ƒë·∫ßu ti√™n ta s·∫Ω ƒë·ªãnh nghƒ©a m·ªôt vector tr·∫°ng th√°i x = [x0, x1, x2, x3, x4, x5, x6, x7], quy ∆∞·ªõc to·∫° ƒë·ªô 0,0 l√† v·ªã tr√≠ tr√°i d∆∞·ªõi. Gi√° tr·ªã c·ªßa xi l√† v·ªã tr·ªã c·ªôt c·ªßa con h·∫≠u d√≤ng i ƒëang ƒë·ª©ng.\nV√≠ d·ª•, ·ªü h√¨nh tr√™n, ta c√≥ x = [6, 1, 7, 5, 0, 2, 3, 4], v·ªõi x0 = 6 nghƒ©a l√† con h·∫≠u ƒëang ·ªü c·ªôt 0 d√≤ng 6 (g√≥c to·∫° ƒë·ªô ch√∫ng ta kh·∫£o s√°t l√† tr√°i d∆∞·ªõi)\nH√¨nh tr√™n kh√¥ng ph·∫£i l√† l·ªùi gi·∫£i t·ªëi ∆∞u cho b√†i to√°n, v√¨ con h·∫≠u ·ªü c·ªôt 5, c·ªôt 6 v√† c·ªôt 7 gi√°p m·∫∑t nhau theo ƒë∆∞·ªùng ch√©o.\nƒê·ªãnh nghƒ©a fitness funtion Trong th∆∞ vi·ªán mlrose ƒë√£ ƒë·ªãnh nghƒ©a s·∫µn h√†m fitness function cho m·ªôt s·ªë b√†i to√°n ƒë∆°n gi·∫£n, v√≠ d·ª• nh∆∞ trong b√†i to√°n 8 h·∫≠u v·ª´a r·ªìi. Tuy nhi√™n, ch√∫ng ta s·∫Ω kh√¥ng s·ª≠ d·ª•ng h√†m c√≥ s·∫µn ƒë√≥, m√† s·∫Ω t·ª± vi·∫øt m·ªôt h√†m fitness ri√™ng. C√≥ nhi·ªÅu c√°ch ƒë·ªÉ ƒë·ªãnh nghƒ©a h√†m fitness kh√°c nhau cho b√†i to√°n n√†y. ·ªû ƒëay, ch√∫ng ta s·∫Ω x√¢y d·ª±ng m·ªôt h√†m c√≥ input l√† v·ªã tr√≠ c·ªßa c√°c con h·∫≠u output l√† m·ªôt con s·ªë th√¥ng b√°o s·ªë l∆∞·ª£ng con h·∫≠u kh√¥ng gi√°p nhau. N·∫øu s·ªë l∆∞·ª£ng l√† 8 th√¨ input ch√≠nh l√† l·ªùi gi·∫£i c·ªßa b√†i to√°n.\n1# Define alternative N-Queens fitness function for maximization problem 2def queens_max(state): 3 4 # Initialize counter 5 fitness = 0 6 7 # For all pairs of queens 8 for i in range(len(state) - 1): 9 for j in range(i + 1, len(state)): 10 11 # Check for horizontal, diagonal-up and diagonal-down attacks 12 if (state[j] == state[i]) \\ 13 or (state[j] == state[i] + (j - i)) \\ 14 or (state[j] == state[i] - (j - i)): 15 16 # If no attacks, then increment counter 17 fitness += 1 18 break 19 20 21 return fitness 22 23fitness_cust = mlrose.CustomFitness(queens_max) X√°c ƒë·ªãnh lo·∫°i b√†i to√°n Th∆∞ vi·ªán mlrose cung c·∫•p cho ch√∫ng ta c√°c l·ªõp ƒë·ªÉ ƒë·ªãnh nghƒ©a 3 lo·∫°i b√†i to√°n t·ªëi ∆∞u:\nDiscreteOpt: L·ªõp n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ gi·∫£i c√°c b√†i to√°n c√≥ gi√° tr·ªã tr·∫°ng th√°i l√† r·ªùi r·∫°c. V√† t·∫≠p c√°c tr·∫°ng th√°i s·∫Ω ƒë∆∞·ª£c cung c·∫•p tr∆∞·ªõc. M·ªói ph·∫ßn t·ª≠ trong state ch·ªâ nh·∫≠n m·ªôt gi√° tr·ªã trong t·∫≠p tr·∫°ng th√°i. v√† m·ªói ph·∫ßn t·ª≠ trong t·∫≠p tr·∫°ng th√°i ch·ªâ thu·ªôc v·ªÅ m·ªôt ph·∫ßn t·ª≠ trong state.\nContinuousOpt: L·ªõp n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ gi·∫£i c√°c b√†i to√°n c√≥ gi√° tr·ªã tr·∫°ng th√°i l√† li√™n t·ª•c.\nTSPOpt: L·ªõp n√†y ƒë∆∞·ª£c d√πng ƒë·ªÉ gi·∫£i c√°c b√†i to√°n v·ªÅ travelling. V√≠ d·ª• b√†i to√°n ng∆∞·ªùi giao h√†ng. B√†i to√°n n√†y kh√°c b√†i to√°n Discrete ·ªü ch·ªó ch√∫ng ta s·∫Ω ph·∫£i t√¨m ra th·ª© t·ª± t·ªëi ∆∞u c·ªßa c√°c con s·ªë.\nB√†i to√°n 8 h·∫≠u ƒë∆∞·ª£c x·∫øp v√†o d·∫°ng b√†i to√°n t·ªëi ∆∞u r·ªùi r·∫°c. Trong ƒë√≥, m·ªói ph·∫ßn t·ª≠ trong state vector ch·ªâ mang m·ªôt con s·ªë t·ª´ 0 ƒë·∫øn 7.\n1 2problem = mlrose.DiscreteOpt(length = 8, fitness_fn = fitness, 3 maximize = False, max_val = 8) length ch√≠nh l√† s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ trong state vector ( ch√∫ng ta c√≥ 8 c·ªôt n√™n length = 8), max_val = 8 (ƒë√£ n√≥i ·ªü tr√™n, gi√° tr·ªã t·ªëi ∆∞u l√† khi 8 con h·∫≠u kh√¥ng gi√°p m·∫∑t nhau). Do b√†i to√°n c·ªßa m√¨nh l√† c·ª±c ti·ªÉu (l√Ω do l√† fitness = 0 th√¨ kh√¥ng c√≥ con h·∫≠u n√†o gi√°p m·∫∑t nhau, n√™n ch√∫ng ta set maximize = False)\nX√°c ƒë·ªãnh thu·∫≠t to√°n t·ªëi ∆∞u Th∆∞ vi·ªán mlrose cung c·∫•p cho ch√∫ng ta c√°c thu·∫≠t to√°n nh∆∞ leo ƒë·ªìi (hill climbing), leo ƒë·ªìi ng·∫´u nhi√™n (stochastic hill climbing),simulated annealing, thu·∫≠t gi·∫£i di truy·ªÅn (genetic algorithm), MIMIC (Mutual-Information-Maximizing Input Clustering). V·ªõi d·∫°ng b√†i to√°n r·ªùi r·∫°c v√† travelling, ch√∫ng ta c√≥ th·ªÉ ch·ªçn b·∫•t k·ª≥ thu·∫≠t to√°n t·ªëi ∆∞u n√†o. V·ªõi b√†i to√°n li√™n t·ª•c, th√¨ thu·∫≠t to√°n MIMIC kh√¥ng h·ªó tr·ª£.\nV√≠ d·ª•, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng simulated annealing ƒë·ªÉ m√¥ ph·ªèng h√†m t·ªëi ∆∞u, v·ªõi tr·∫°ng th√°i init l√† x = [1,2,3,4,5,6,7], l·∫∑p 1000 l·∫ßn ƒë·ªÉ t√¨m tr·∫°ng th√°i t·ªët nh·∫•t. C√≥ 10 l·∫ßn th·ª≠. ƒë·ªÉ t√¨m h√†ng x√≥m t·ªët nh·∫•t trong m·ªói l·∫ßn l·∫∑p.\n1# Define decay schedule 2schedule = mlrose.ExpDecay() 3 4# Define initial state 5init_state = np.array([0, 1, 2, 3, 4, 5, 6, 7]) 6 7# Set random seed 8np.random.seed(1) 9 10# Solve problem using simulated annealing 11best_state, best_fitness = mlrose.simulated_annealing(problem, schedule = schedule, 12 max_attempts = 10, max_iters = 1000, 13 init_state = init_state) 14 15print(\u0026#39;The best state found is: \u0026#39;, best_state) 16print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) K·∫øt qu·∫£\n1The best state found is: [0 7 6 4 7 1 3 5] 2The fitness at the best state is: 1.0 Do best state =1 , n√™n c√≥ 2 con h·∫≠u c√≥ th·ªÉ nh√¨n th·∫•y v√† t·∫•n c√¥ng nhau, Ch√∫ng ta s·∫Ω th·ª≠ thay d·ªïi s·ªë max_attempts =10 th√†nh max_attempts = 50 xem sao.\n1 2The best state found is: [2 0 6 4 7 1 3 5] 3The fitness at the best state is: 0.0 Th·ª≠ thay b·∫±ng b√†i to√°n 12 h·∫≠u\n1import mlrose 2 3import numpy as np 4 5# Define alternative N-Queens fitness function for maximization problem 6def queens_max(state): 7 8 # Initialize counter 9 fitness = 0 10 11 # For all pairs of queens 12 for i in range(len(state) - 1): 13 for j in range(i + 1, len(state)): 14 15 # Check for horizontal, diagonal-up and diagonal-down attacks 16 if (state[j] == state[i]) \\ 17 or (state[j] == state[i] + (j - i)) \\ 18 or (state[j] == state[i] - (j - i)): 19 20 # If no attacks, then increment counter 21 fitness += 1 22 break 23 24 25 return fitness 26 27fitness_cust = mlrose.CustomFitness(queens_max) 28 29problem = mlrose.DiscreteOpt(length = 12, fitness_fn = fitness_cust, maximize = False, max_val = 12) 30 31 32# Define decay schedule 33schedule = mlrose.ExpDecay() 34 35# Define initial state 36init_state = np.array([0, 1, 2, 3, 4, 5, 6, 7,8,9,10,11]) 37 38# Set random seed 39np.random.seed(1) 40 41# Solve problem using simulated annealing 42best_state, best_fitness = mlrose.simulated_annealing(problem, schedule = schedule, 43 max_attempts = 100, max_iters = 5000, 44 init_state = init_state) 45 46print(\u0026#39;The best state found is: \u0026#39;, best_state) 47print(\u0026#39;The fitness at the best state is: \u0026#39;, best_fitness) 48`` 49 50K·∫øt qu·∫£ 51 52```python 53The best state found is: [ 8 10 3 6 0 9 1 5 2 11 7 4] 54The fitness at the best state is: 0.0 T·∫•t nhi√™n, ·ªü tr√™n ch·ªâ l√† 1 trong s·ªë c√°c l·ªùi gi·∫£i c·ªßa b√†i to√°n tr√™n, ch√∫ng ta c√≤n c√≥ nhi·ªÅu l·ªùi gi·∫£i kh√°c, do b√†i to√°n c√≥ nhi·ªÅu nghi·ªám.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Feb 8, 2019","img":"","permalink":"/blog/2019-02-08-getting-started-with-randomized-optimization-in-python/","series":null,"tags":["t·ªëi ∆∞u h√≥a ng·∫´u nhi√™n","mlrose"],"title":"T·ªëi ∆Øu Ho√° Ng·∫´u Nhi√™n"},{"categories":null,"content":" 1. C·∫•m bay m√°y bay ho·∫∑c ƒëi t√†u ƒëi·ªán ng·∫ßm 2. ƒêi·ªÅu ch·ªânh t·ªëc ƒë·ªô internet 3. C·∫•m b·∫°n, ho·∫∑c con c√°i c·ªßa b·∫°n ƒë∆∞·ª£c h·ªçc ·ªü nh·ªØng tr∆∞·ªùng t·ªët 4. Kh√¥ng cho b·∫°n c√≥ m·ªôt c√¥ng vi·ªác t·ªët 5. Kh√¥ng ƒë∆∞·ª£c thu√™ nh·ªØng kh√°ch s·∫°n t·ªët 6. C·∫•m nu√¥i ch√≥ 7. B·ªã b√™u t√™n tr∆∞·ªõc c√¥ng ch√∫ng Ch√≠nh quy·ªÅn Trung Qu·ªëc ƒëang x√¢y d·ª±ng m·ªôt h·ªá th·ªëng x·∫øp h·∫°ng c√≥ t√™n l√† \u0026quot; H·ªá th·ªëng t√≠n d·ª•ng x√£ h·ªôi - social credit system\u0026quot;. H·ªá th·ªëng ƒë∆∞·ª£c x√¢y d·ª±ng nh·∫±m m·ª•c ƒë√≠ch theo d√µi h√†nh vi c·ªßa c√¥ng d√¢n v√† x·∫øp h·∫°ng t·∫•t c·∫£ c√°c h√†nh vi tr√™n.\nTheo m·ªôt t√†i li·ªáu cho bi·∫øt,\u0026ldquo;H·ªá th·ªëng t√≠n d·ª•ng x√£ h·ªôi\u0026rdquo;, l·∫ßn ƒë·∫ßu ti√™n ƒë∆∞·ª£c c√¥ng b·ªë v√†o nƒÉm 2014, nh·∫±m m·ª•c ƒë√≠ch c·ªßng c·ªë √Ω t∆∞·ªüng r·∫±ng \u0026ldquo;gi·ªØ ni·ªÅm tin l√† vinh quang v√† ph√° v·ª° ni·ªÅm tin l√† √¥ nh·ª•c\u0026rdquo;.\nH·ªá th·ªëng s·∫Ω ƒë∆∞·ª£c v·∫≠n h√†nh ho√†n to√†n tr√™n to√†n qu·ªëc v√†o nƒÉm 2020, nh∆∞ng ƒë√£ ƒë∆∞·ª£c th√≠ ƒëi·ªÉm ·ªü m·ªôt s·ªë v√πng tr√™n ƒë·∫•t n∆∞·ªõc, v√† mang l·∫°i k·∫øt qu·∫£ kh√° kh·∫£ quan.\nT·∫°i th·ªùi ƒëi·ªÉm hi·ªán t·∫°i, h·ªá th·ªëng ƒëang ƒë∆∞·ª£c ƒëi·ªÅu h√†nh b·ªüi ch√≠nh ph·ªß, m·ªôt s·ªë c√¥ng ty t∆∞ nh√¢n c≈©ng ƒë∆∞·ª£c c·∫•p ph√©p tham gia x√¢y d·ª±ng v√† ph√°t tri·ªÉn h·ªá th·ªëng, nh∆∞ alibaba, tencent.\nGi·ªëng nh∆∞ ƒëi·ªÉm t√≠n d·ª•ng t∆∞ nh√¢n, ƒëi·ªÉm x√£ h·ªôi c·ªßa m·ªôt ng∆∞·ªùi c√≥ th·ªÉ ƒëi l√™n xu·ªëng t√πy theo h√†nh vi c·ªßa h·ªç. C√°ch th·ª©c t√≠nh ƒëi·ªÉm v√† c√°c h√†nh vi ƒë∆∞·ª£c cho l√† t·ªët/x·∫•u hi·ªán th·ªùi v·∫´n ch∆∞a ƒë∆∞·ª£c c√¥ng b·ªë. Nh∆∞ng c√°c v√≠ d·ª• v·ªÅ vi ph·∫°m ƒë√£ b·ªã tr·ª´ ƒëi·ªÉm bao g·ªìm l√°i xe ·∫©u, h√∫t thu·ªëc trong khu v·ª±c c·∫•m h√∫t thu·ªëc, mua qu√° nhi·ªÅu tr√≤ ch∆°i video v√† ƒëƒÉng tin t·ª©c gi·∫£ l√™n m·∫°ng.\n1. C·∫•m bay m√°y bay ho·∫∑c ƒëi t√†u ƒëi·ªán ng·∫ßm Ch√≠nh ph·ªß Trung Qu·ªëc ƒë√£ b·∫Øt ƒë·∫ßu tr·ª´ng ph·∫°t ng∆∞·ªùi d√¢n b·∫±ng c√°ch h·∫°n ch·∫ø vi·ªác ƒëi l·∫°i c·ªßa h·ªç.\nCh√≠n tri·ªáu ng∆∞·ªùi c√≥ ƒëi·ªÉm th·∫•p ƒë√£ b·ªã ch·∫∑n mua v√© cho c√°c chuy·∫øn bay n·ªôi ƒë·ªãa, Channel News Asia ƒë∆∞a tin v√†o 16/Mar/2018 ngu·ªìn https://www.channelnewsasia.com/news/asia/china-bad-social-credit-barred-from-buying-train-plane-tickets-10050390.\nNg∆∞·ªùi d√¢n c≈©ng c√≥ th·ªÉ b·ªã gi·ªõi h·∫°n s·ª≠ d·ª•ng c√°c d·ªãch v·ª• n√¢ng cao, v√≠ d·ª• ba tri·ªáu ng∆∞·ªùi kh√¥ng ƒë∆∞·ª£c mua v√© h·∫°ng th∆∞∆°ng gia (tr√≠ch c√πng ngu·ªìn tr√™n).\nHere\u0026#39;s a dystopian vision of the future: A real announcement I recorded on the Beijing-Shanghai bullet train. (I\u0026#39;ve subtitled it so you can watch in silence.) pic.twitter.com/ZoRWtdcSMy\n\u0026mdash; James O\u0026#39;Malley (@Psythor) October 29, 2018 video tr√™n, ƒë∆∞·ª£c ƒëƒÉng b·ªüi nh√† b√°o James O\u0026rsquo;Malley, cho th·∫•y m·ªôt th√¥ng b√°o tr√™n m·ªôt chuy·∫øn t√†u cao t·ªëc t·ª´ B·∫Øc Kinh ƒë·∫øn Th∆∞·ª£ng H·∫£i c·∫£nh b√°o m·ªçi ng∆∞·ªùi kh√¥ng n√™n c√≥ nh·ªØng h√†nh vi sai tr√°i - n·∫øu kh√¥ng th√¨ \u0026ldquo;h√†nh vi c·ªßa h·ªç s·∫Ω ƒë∆∞·ª£c ghi l·∫°i trong h·ªá th·ªëng th√¥ng tin t√≠n d·ª•ng c√° nh√¢n\u0026rdquo;.\n2. ƒêi·ªÅu ch·ªânh t·ªëc ƒë·ªô internet Theo nghi√™n c·ª©u c·ªßa Rachel Botsman (ngu·ªìn https://www.wired.co.uk/article/chinese-government-social-credit-score-privacy-invasion) ch√≠nh quy·ªÅn s·∫Ω gi·ªõi h·∫°n t·ªëc ƒë·ªô, bƒÉng th√¥ng c·ªßa c√°c d·ªãch v·ª• internet, 3G, 4G, \u0026hellip; c·ªßa nh·ªØng c√¥ng d√¢n c√≥ ƒëi·ªÉm t√≠nh d·ª•ng x√£ h·ªôi th·∫•p.\nTrong nghi√™n c·ª©u c·ªßa t√°c gi·∫£, m·ªôt s·ªë h√†nh vi s·∫Ω b·ªã tr·ª´ng ph·∫°t, bao g·ªìm:\nC√¥ng d√¢n c√≥ thanh to√°n h√≥a ƒë∆°n ƒë√∫ng h·∫°n hay kh√¥ng. D√†nh qu√° nhi·ªÅu th·ªùi gian ƒë·ªÉ ch∆°i tr√≤ ch∆°i video L√£ng ph√≠ ti·ªÅn mua h√†ng t√†o lao v√† ƒëƒÉng l√™n ph∆∞∆°ng ti·ªán truy·ªÅn th√¥ng x√£ h·ªôi (d·∫°ng nh∆∞ t·ª± s∆∞·ªõng ·ªü Vi·ªát Nam m√¨nh √°). Truy·ªÅn b√° tin t·ª©c gi·∫£ m·∫°o, c·ª• th·ªÉ l√† v·ªÅ c√°c cu·ªôc t·∫•n c√¥ng kh·ªßng b·ªë ho·∫∑c an ninh s√¢n bay. 3. C·∫•m b·∫°n, ho·∫∑c con c√°i c·ªßa b·∫°n ƒë∆∞·ª£c h·ªçc ·ªü nh·ªØng tr∆∞·ªùng t·ªët Theo Beijing News reported(ngu·ªìn http://www.bjnews.com.cn/news/2018/03/19/479533.html), 17 ng∆∞·ªùi ƒë√£ t·ª´ ch·ªëi th·ª±c hi·ªán nghƒ©a v·ª• qu√¢n s·ª± v√†o nƒÉm ngo√°i (2017) ƒë√£ b·ªã c·∫•m ƒëƒÉng k√Ω v√†o gi√°o d·ª•c ƒë·∫°i h·ªçc, n·ªôp ƒë∆°n v√†o tr∆∞·ªùng trung h·ªçc ho·∫∑c ti·∫øp t·ª•c vi·ªác h·ªçc t·∫≠p c·ªßa h·ªç.\nTheo ngu·ªìn https://www.businessinsider.com/china-social-credit-affects-childs-university-enrolment-2018-7?r=UK, v√†o th√°ng 7/2018, m·ªôt tr∆∞·ªùng ƒë·∫°i h·ªçc ·ªü Trung Qu·ªëc, ƒë√£ c·∫•m m·ªôt sinh vi√™n nh·∫≠p h·ªçc (d√π anh ·∫•y ƒë√£ thi ƒë·∫≠u), v√¨ l√Ω do l√† ƒëi·ªÉm t√≠n d·ª•ng x√£ h·ªôi c·ªßa b·ªë anh ·∫•y \u0026ldquo;x·∫•u\u0026rdquo;.\n4. Kh√¥ng cho b·∫°n c√≥ m·ªôt c√¥ng vi·ªác t·ªët Theo ngu·ªìn c·ªßa Botsman, c√°c c√° nh√¢n c√≥ ƒëi·ªÉm t√≠n nhi·ªám th·∫•p s·∫Ω b·ªã c·∫•m l√†m qu·∫£n l√Ω ·ªü c√°c c√¥ng ty nh√† n∆∞·ªõc, c√°c ng√¢n h√†ng l·ªõn.\nC√°c h√†nh vi nh∆∞ gian l·∫≠n thu·∫ø, tham √¥, \u0026hellip; c≈©ng ·∫£nh h∆∞·ªüng ƒë·∫øn ƒëi·ªÉm x√£ h·ªôi.\n5. Kh√¥ng ƒë∆∞·ª£c thu√™ nh·ªØng kh√°ch s·∫°n t·ªët Theo Botsman, nh·ªØng ng∆∞·ªùi gian l·∫≠n nghƒ©a v·ª• qu√¢n s·ª± s·∫Ω b·ªã c·∫•m thu√™ kh√°ch s·∫°n t·ªët khi ƒëi du l·ªãch.\nNh·ªØng c√¥ng d√¢n c√≥ ƒëi·ªÉm t√≠n d·ª•ng t·ªët s·∫Ω ƒë∆∞·ª£c thu√™ kh√°ch s·∫°n m√† kh√¥ng c·∫ßn ph·∫£i ƒë·∫∑t c·ªçc, c√≥ th·ªÉ k√©o d√†i th·ªùi gian du l·ªãch h∆°n.\n6. C·∫•m nu√¥i ch√≥ Th√†nh ph·ªë T·∫ø Nam ƒë√£ b·∫Øt ƒë·∫ßu th·ª±c thi m·ªôt h·ªá th·ªëng t√≠n d·ª•ng x√£ h·ªôi cho c√°c ch·ªß s·ªü h·ªØu ch√≥ v√†o nƒÉm 2017. Theo ƒë√≥, ch·ªß v·∫≠t nu√¥i s·∫Ω b·ªã tr·ª´ ƒëi·ªÉm n·∫øu nu√¥i ch√≥ m√† kh√¥ng x√≠ch, kh√¥ng r·ªç m√µm, ho·∫∑c ƒë·ªÉ cho ch√≥ ƒëi b·∫≠y n∆°i c√¥ng c·ªông.\nNh·ªØng ng∆∞·ªùi b·ªã zero ƒëi·ªÉm s·∫Ω b·ªã c·∫•m nu√¥i ch√≥, con v·∫≠t s·∫Ω b·ªã t·ªãch thu, ng∆∞·ªùi s·ªü h·ªØu ph·∫£i l√†m b√†i ki·ªÉm tra. Ngu·ªìn http://uk.businessinsider.com/china-dog-owners-social-credit-score-2018-10\n7. B·ªã b√™u t√™n tr∆∞·ªõc c√¥ng ch√∫ng Ch√≠nh ph·ªß ƒë√£ v√† ƒëang x√¢y d·ª±ng m·ªôt danh s√°ch c√°c c√° nh√¢n c√≥ ƒëi·ªÉm t√≠n nhi·ªám x·∫•u v√† s·∫µn s√†ng ƒëƒÉng t√™n k√®m h√¨nh ·∫£nh c·ªßa h·ªç tr√™n c√°c ph∆∞∆°ng ti·ªán th√¥ng tin ƒë·∫°i ch√∫ng. C√°c c√¥ng ty c≈©ng ƒë∆∞·ª£c khuy·∫øn kh√≠ch tham kh·∫£o c√°c th√¥ng tin c·ªßa c√¥ng d√¢n trong h·ªá th·ªëng tr∆∞·ªõc khi thu√™ h·ªç.\nƒê∆∞·ª£c bi·∫øt, to√† √°n s·∫Ω th√¥ng b√°o cho c√¥ng d√¢n v·ªÅ h√†nh vi c·ªßa h·ªç tr∆∞·ªõc khi t√™n c·ªßa h·ªç ƒë∆∞·ª£c ƒë∆∞a v√†o danh s√°ch ƒëen. C√¥ng d√¢n c√≥ 10 ng√†y kh√°ng c√°o k·ªÉ t·ª´ khi nh·∫≠n ƒë∆∞·ª£c th√¥ng b√°o.\nNgu·ªìn https://www.hrw.org/news/2017/12/12/chinas-chilling-social-credit-blacklist, http://zxgk.court.gov.cn/\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Feb 7, 2019","img":"","permalink":"/blog/2019-02-07-china-social-creadit-system/","series":null,"tags":["ch·∫•m ƒëi·ªÉm c√¥ng d√¢n","china","China social credit system","credit system"],"title":"H·ªá Th·ªëng T√≠n D·ª•ng X√£ H·ªôi C·ªßa Trung Qu·ªëc - Nh·ªØng ·∫¢nh H∆∞·ªüng Khi B·∫°n C√≥ ƒêi·ªÉm X√£ H·ªôi Th·∫•p"},{"categories":null,"content":" M·ªü ƒë·∫ßu Ch·∫©n b·ªã d·ªØ li·ªáu X√¢y d·ª±ng m√¥ h√¨nh M·ªü ƒë·∫ßu Ch·∫©n b·ªã d·ªØ li·ªáu X√¢y d·ª±ng m√¥ h√¨nh M·ªü ƒë·∫ßu Vi·ªác x√¢y d·ª±ng m·ªôt m√¥ h√¨nh machine learning ch∆∞a bao gi·ªù th·∫≠t s·ª± d·ªÖ d√†ng. R·∫•t nhi·ªÅu b√†i b√°o ch·ªâ \u0026ldquo;show h√†ng\u0026rdquo; nh·ªØng th·ª© cao si√™u, nh·ªØng th·ª© ch·ªâ n·∫±m trong s·ª± t∆∞·ªüng t∆∞·ª£ng c·ªßa ch√≠nh c√°c nh√† b√°o. C√≤n khi ƒë·ªçc c√°c b√†i b√°o khoa h·ªçc v·ªÅ machine learning, t√°c gi·∫£ c√¥ng b·ªë cho ch√∫ng ta nh·ªØng m√¥ h√¨nh r·∫•t t·ªët, gi·∫£i quy·∫øt m·ªôt domain nh·ªè v·∫•n ƒë·ªÅ c·ªßa h·ªç. Tuy nhi√™n, c√≥ m·ªôt th·ª© h·ªç kh√¥ng/ ch∆∞a c√¥ng b·ªë. ƒê√≥ l√† c√°ch th·ª©c h·ªç l·ª±a ch·ªçn s·ªë l∆∞·ª£ng note ·∫©n, s·ªë l∆∞·ª£ng layer trong m√¥ h√¨nh neural network. Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω x√¢y d·ª±ng m√¥ h√¨nh LSTM ƒë∆°n gi·∫£n ƒë·ªÉ d·ª± ƒëo√°n gi·ªõi t√≠nh khi bi·∫øt t√™n m·ªôt ng∆∞·ªùi, v√† th·ª≠ t√¨m xem c√¥ng th·ª©c ƒë·ªÉ ch·ªçn ra tham s·ªë \u0026ldquo;ƒë·ªß t·ªët\u0026rdquo; l√† nh∆∞ th·∫ø n√†o.\nCh·∫©n b·ªã d·ªØ li·ªáu T·∫≠p d·ªØ li·ªáu ·ªü ƒë√¢y c√≥ kho·∫£ng 500000 t√™n k√®m gi·ªõi t√≠nh. ƒê·∫ßu ti√™n m√¨nh s·∫Ω l√†m s·∫°ch d·ªØ li·ªáu b·∫±ng c√°ch ch·ªâ l·∫•y gi·ªõi t√≠nh l√† \u0026rsquo;m\u0026rsquo; v√† \u0026lsquo;f\u0026rsquo;, lo·∫°i b·ªè nh·ªØng t√™n qu√° ng·∫Øn (c√≥ √≠t h∆°n 3 k√Ω t·ª±)\n1filepath = \u0026#39;firstnames.csv\u0026#39; 2max_rows = 500000 # Reduction due to memory limitations 3 4df = (pd.read_csv(filepath, usecols=[\u0026#39;name\u0026#39;, \u0026#39;gender\u0026#39;],sep=\u0026#34;;\u0026#34;) 5 .dropna(subset=[\u0026#39;name\u0026#39;, \u0026#39;gender\u0026#39;]) 6 .assign(name = lambda x: x.name.str.strip()) 7 .assign(gender = lambda x: x.gender.str.lower()) 8 .head(max_rows)) 9 10df= df[df.gender.isin([\u0026#39;m\u0026#39;,\u0026#39;f\u0026#39;])] 11 12# In the case of a middle name, we will simply use the first name only 13df[\u0026#39;name\u0026#39;] = df[\u0026#39;name\u0026#39;].apply(lambda x: str(x).split(\u0026#39; \u0026#39;, 1)[0]) 14 15# Sometimes people only but the first letter of their name into the field, so we drop all name where len \u0026lt;3 16df.drop(df[df[\u0026#39;name\u0026#39;].str.len() \u0026lt; 3].index, inplace=True) Ti·∫øp theo, ch√∫ng ta s·ª≠ d·ª•ng m·ªôt k·ªπ thu·∫≠t kh√° c≈© trong NLP l√† one-hot encoding. M·ªói k√Ω t·ª± ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·ªüi m·ªôt vector nh·ªã ph√¢n. V√≠ d·ª• c√≥ 26 k√Ω t·ª± trong b·∫£ng ch·ªØ c√°i ti·∫øng anh, vector ƒë·∫°i di·ªán cho ch·ªØ a l√† [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], k√Ω t·ª± b ƒë∆∞·ª£c bi·ªÉu di·ªÖn l√† [0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], \u0026hellip; t∆∞∆°ng t·ª± cho ƒë·∫øn z.\nM·ªôt t·ª´ ƒë∆∞·ª£c encode l√† m·ªôt t·∫≠p c√°c vector. V√≠ d·ª• ch·ªØ hello ƒë∆∞·ª£c bi·ªÉu di·ªÖn l√†\n1[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #h, 2 [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #e, 3 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #l, 4 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #l, 5 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] #o] ƒê·ªçc ƒë·∫øn ƒë√¢y, ch·∫Øc c√°c b·∫°n ƒë√£ m∆∞·ªùn t∆∞·ª£ng ra r·∫±ng m·ªôt t·ª´ s·∫Ω ƒë∆∞·ª£c encode nh∆∞ th·∫ø n√†o r·ªìi ph·∫£i kh√¥ng. Ti·∫øp theo, ch√∫ng ta s·∫Ω x√¢y d·ª±ng h√†m encode cho t·∫≠p d·ªØ li·ªáu\n1# Define a mapping of chars to integers 2char_to_int = dict((c, i) for i, c in enumerate(accepted_chars)) 3int_to_char = dict((i, c) for i, c in enumerate(accepted_chars)) 4 5# Removes all non accepted characters 6def normalize(line): 7 return [c.lower() for c in line if c.lower() in accepted_chars] 8 9# Returns a list of n lists with n = word_vec_length 10def name_encoding(name): 11 12 # Encode input data to int, e.g. a-\u0026gt;1, z-\u0026gt;26 13 integer_encoded = [char_to_int[char] for i, char in enumerate(name) if i \u0026lt; word_vec_length] 14 15 # Start one-hot-encoding 16 onehot_encoded = list() 17 18 for value in integer_encoded: 19 # create a list of n zeros, where n is equal to the number of accepted characters 20 letter = [0 for _ in range(char_vec_length)] 21 letter[value] = 1 22 onehot_encoded.append(letter) 23 24 # Fill up list to the max length. Lists need do have equal length to be able to convert it into an array 25 for _ in range(word_vec_length - len(name)): 26 onehot_encoded.append([0 for _ in range(char_vec_length)]) 27 28 return onehot_encoded 29 30# Encode the output labels 31def lable_encoding(gender_series): 32 labels = np.empty((0, 2)) 33 for i in gender_series: 34 if i == \u0026#39;m\u0026#39;: 35 labels = np.append(labels, [[1,0]], axis=0) 36 else: 37 labels = np.append(labels, [[0,1]], axis=0) 38 return labels V√† ti·∫øn h√†nh chia t·∫≠p d·ªØ li·ªáu th√†nh train, val, v√† test set\n1 2# Split dataset in 60% train, 20% test and 20% validation 3train, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))]) 4 5# Convert both the input names as well as the output lables into the discussed machine readable vector format 6train_x = np.asarray([np.asarray(name_encoding(normalize(name))) for name in train[predictor_col]]) 7train_y = lable_encoding(train.gender) 8 9validate_x = np.asarray([name_encoding(normalize(name)) for name in validate[predictor_col]]) 10validate_y = lable_encoding(validate.gender) 11 12test_x = np.asarray([name_encoding(normalize(name)) for name in test[predictor_col]]) 13test_y = lable_encoding(test.gender) V·∫≠y l√† ch√∫ng ta ƒë√£ c√≥ chu·∫©n b·ªã xong d·ªØ li·ªáu ƒë·∫ßy ƒë·ªß r·ªìi ƒë√≥. B√¢y gi·ªù ch√∫ng ta x√¢y d·ª±ng m√¥ h√¨nh th√¥i.\nX√¢y d·ª±ng m√¥ h√¨nh C√≥ r·∫•t nhi·ªÅu c√°ch ƒë·ªÉ ch·ªçn tham s·ªë cho m√¥ h√¨nh, v√≠ d·ª• nh∆∞ ·ªü https://stats.stackexchange.com/questions/95495/guideline-to-select-the-hyperparameters-in-deep-learning li·ªát k√™ ra 4 c√°ch l√† Manual Search, Grid Search, Random Search, Bayesian Optimization. Tuy nhi√™n, nh·ªØng c√°ch tr√™n ƒë·ªÅu kh√° t·ªën th·ªùi gian v√† ƒë√≤i h·ªèi ng∆∞·ªùi k·ªπ s∆∞ ph·∫£i c√≥ am hi·ªÉu nh·∫•t ƒë·ªãnh.\n·ªû ƒë√¢y, ch√∫ng ta s·ª≠ d·ª•ng m·ªôt c√¥ng th·ª©c ƒë∆∞·ª£c ƒë∆∞a ra trong link https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw/136542#136542, c·ª• th·ªÉ\n$$ N_h = \\frac{N_s}{(\\alpha * (N_i + N_o))}$$\nTrong ƒë√≥ Ni l√† s·ªë l∆∞·ª£ng input neural, No l√† s·ªë l∆∞·ª£ng output neural, Ns l√† s·ªë l∆∞·ª£ng element trong t·∫≠p d·ªØ li·ªáu train. alpha l√† m·ªôt con s·ªë trade-off ƒë·∫°i di·ªán cho t·ª∑ l·ªá thu·ªôc ƒëo·∫°n [2-10].\nM·ªôt l∆∞u √Ω ·ªü ƒë√¢y l√† b·∫°n c√≥ th·ªÉ d·ª±a v√†o c√¥ng th·ª©c v√† s·ªë alpha m√† ∆∞·ªõc l∆∞·ª£ng xem r·∫±ng b·∫°n ƒë√£ c√≥ ƒë·ªß d·ªØ li·ªáu m·∫´u hay ch∆∞a. M·ªôt v√≠ d·ª• ƒë∆°n gi·∫£n l√† gi·∫£ s·ª≠ b·∫°n c√≥ 10,000 m·∫´u d·ªØ li·ªáu, input s·ªë t·ª´ 0 ƒë·∫øn 9, output l√† 64, ch·ªçn alpha ·ªü m·ª©c nh·ªè nh·∫•t l√† 2, v·∫≠y theo c√¥ng th·ª©c s·ªë neural ·∫©n l√† 10000/(26410) = 7.8 ~ 8. N·∫øu b·∫°n tƒÉng s·ªë alpha l√™n th√¨ s·ªë hidden layer c√≤n √≠t n·ªØa. ƒêi·ªÅu tr√™n ch·ª©ng t·ªè r·∫±ng s·ªë l∆∞·ª£ng m·∫´u c·ªßa b·∫°n ch∆∞a ƒë·ªß, c√≤n thi·∫øu qu√° nhi·ªÅu. N·∫øu b·∫°n tƒÉng g·∫•p 100 l·∫ßn s·ªë d·ªØ li·ªáu m·∫´u, th√¨ con s·ªë c√≥ v·∫ª h·ª£p l√Ω h∆°n.\nTrong t·∫≠p d·ªØ li·ªáu, m√¨nh c√≥:\n1The input vector will have the shape {17} x {82} 2Train len: (21883, 17, 82) 36473 T·ªïng c·ªông N_s l√† 21883, Ni l√† 17, No l√† 82, ch·ªçn alpha l√† 2 th√¨ m√¨nh c√≥ 21883/(21782) = 7.8 ~ 8. M·ªôt con s·ªë kh√° nh·ªè, ch·ª©ng t·ªè d·ªØ li·ªáu c·ªßa m√¨nh c√≤n qu√° √≠t.\nƒê·ªëi v·ªõi t·∫≠p d·ªØ li·ªáu nh·ªè nh∆∞ th·∫ø n√†y, m√¨nh th∆∞·ªùng s·∫Ω √°p d·ª•ng c√¥ng th·ª©c sau:\n$$ N_h= \\beta* (N_i + N_o) $$\nV·ªõi beta l√† m·ªôt con s·ªë th·ª±c thu·ªôc n·ª≠a ƒëo·∫°n (0,1]. Th√¥ng th∆∞·ªùng s·∫Ω l√† 2/3. K·∫øt qu·∫£ l√† s·ªë l∆∞·ª£ng neural c·ªßa m√¨nh kho·∫£ng 929.333 node. Th√¥ng th∆∞·ªùng, m√¨nh s·∫Ω ch·ªçn s·ªë neural l√† m·ªôt con s·ªë l√† b·ªôi s·ªë c·ªßa 2, ·ªü ƒë√¢y 929 g·∫ßn v·ªõi 2^10 nh·∫•t, n√™n m√¨nh ch·ªçn s·ªë neural l√† 2^10.\nT√≥m l·∫°i, m√¨nh s·∫Ω theo quy t·∫Øc\nN·∫øu d·ªØ li·ªáu nhi·ªÅu:\n$$ N_h = \\frac{N_s}{(\\alpha * (N_i + N_o))}$$\nN·∫øu d·ªØ li·ªáu √≠t\n$$ N_h= \\frac{2}{3}* (N_i + N_o) $$\nL√†m tr√≤n l√™n b·∫±ng v·ªõi b·ªôi s·ªë c·ªßa 2 m≈© g·∫ßn nh·∫•t.\nM·ªôt l∆∞u √Ω nh·ªè l√† s·ªë l∆∞·ª£ng node c√†ng nhi·ªÅu th√¨ t·ª∑ l·ªá overfit c√†ng cao, v√† th·ªùi gian hu·∫•n luy·ªán c√†ng l√¢u. Do ƒë√≥, b·∫°n n√™n trang b·ªã m√°y c√≥ c·∫•u h√¨nh kha kh√° m·ªôt ch√∫t, t·ªët h∆°n h·∫øt l√† n√™n c√≥ GPU ƒëi k√®m. Ngo√†i ra, b·∫°n n√™n chu·∫©n b·ªã c√†ng nhi·ªÅu d·ªØ li·ªáu c√†ng t·ªët. M·ªôt kinh nghi·ªám c·ªßa m√¨nh r√∫t ra trong qu√° tr√¨nh l√†m Machine Learning l√† n·∫øu kh√¥ng c√≥ nhi·ªÅu d·ªØ li·ªáu, th√¨ ƒë·ª´ng c·ªë th·ª≠ √°p d·ª•ng c√°c ph∆∞∆°ng ph√°p ML tr√™n n√≥.\nM√¥ h√¨nh m√¨nh x√¢y d·ª±ng nh∆∞ sau:\n1 2hidden_nodes = 1024 3 4 5# Build the model 6print(\u0026#39;Build model...\u0026#39;) 7model = Sequential() 8model.add(LSTM(hidden_nodes, return_sequences=False, input_shape=(word_vec_length, char_vec_length))) 9model.add(Dropout(0.2)) 10model.add(Dense(units=output_labels)) 11model.add(Activation(\u0026#39;softmax\u0026#39;)) 12model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;acc\u0026#39;]) 13 14batch_size=1000 15model.fit(train_x, train_y, batch_size=batch_size, epochs=50, validation_data=(validate_x, validate_y)) Do b√†i vi·∫øt ch·ªâ t·∫≠p trung v√†o v·∫•n ƒë·ªÅ l·ª±a ch·ªçn s·ªë l∆∞·ª£ng node, n√™n m√¨nh s·∫Ω b·ªè qua nh·ªØng ph·∫ßn ph·ª• nh∆∞ l√† early stoping, save each epochs \u0026hellip;, C√°c v·∫•n ƒë·ªÅ tr√™n √≠t nhi·ªÅu m√¨nh ƒë√£ ƒë·ªÅ c·∫≠p ·ªü c√°c b√†i vi·∫øt tr∆∞·ªõc.\nK·∫øt qu·∫£ c·ªßa vi·ªác hu·∫•n luy·ªán m√¥ h√¨nh\n121883/21883 [==============================] - 34s 2ms/step - loss: 0.6602 - acc: 0.6171 - val_loss: 0.6276 - val_acc: 0.7199 2Epoch 2/50 321883/21883 [==============================] - 30s 1ms/step - loss: 0.5836 - acc: 0.7056 - val_loss: 0.5625 - val_acc: 0.7193 4Epoch 3/50 521883/21883 [==============================] - 30s 1ms/step - loss: 0.5531 - acc: 0.7353 - val_loss: 0.5506 - val_acc: 0.7389 6Epoch 4/50 721883/21883 [==============================] - 31s 1ms/step - loss: 0.5480 - acc: 0.7446 - val_loss: 0.5664 - val_acc: 0.7313 8Epoch 5/50 921883/21883 [==============================] - 30s 1ms/step - loss: 0.5406 - acc: 0.7420 - val_loss: 0.5247 - val_acc: 0.7613 10Epoch 6/50 1121883/21883 [==============================] - 30s 1ms/step - loss: 0.5077 - acc: 0.7686 - val_loss: 0.4918 - val_acc: 0.7790 12Epoch 7/50 1321883/21883 [==============================] - 30s 1ms/step - loss: 0.4825 - acc: 0.7837 - val_loss: 0.4939 - val_acc: 0.7740 14Epoch 8/50 1521883/21883 [==============================] - 31s 1ms/step - loss: 0.4611 - acc: 0.7887 - val_loss: 0.4407 - val_acc: 0.8037 16Epoch 9/50 1721883/21883 [==============================] - 30s 1ms/step - loss: 0.4421 - acc: 0.7987 - val_loss: 0.4657 - val_acc: 0.8005 18Epoch 10/50 1921883/21883 [==============================] - 30s 1ms/step - loss: 0.4293 - acc: 0.8055 - val_loss: 0.4183 - val_acc: 0.8141 20Epoch 11/50 2121883/21883 [==============================] - 31s 1ms/step - loss: 0.4129 - acc: 0.8128 - val_loss: 0.4171 - val_acc: 0.8212 22Epoch 12/50 2321883/21883 [==============================] - 30s 1ms/step - loss: 0.4153 - acc: 0.8141 - val_loss: 0.4031 - val_acc: 0.8188 24Epoch 13/50 2521883/21883 [==============================] - 30s 1ms/step - loss: 0.3978 - acc: 0.8191 - val_loss: 0.3918 - val_acc: 0.8280 26Epoch 14/50 2721883/21883 [==============================] - 30s 1ms/step - loss: 0.3910 - acc: 0.8268 - val_loss: 0.3831 - val_acc: 0.8276 28Epoch 15/50 2921883/21883 [==============================] - 30s 1ms/step - loss: 0.3848 - acc: 0.8272 - val_loss: 0.3772 - val_acc: 0.8314 30Epoch 16/50 3121883/21883 [==============================] - 30s 1ms/step - loss: 0.3751 - acc: 0.8354 - val_loss: 0.3737 - val_acc: 0.8363 32Epoch 17/50 3321883/21883 [==============================] - 30s 1ms/step - loss: 0.3708 - acc: 0.8345 - val_loss: 0.3717 - val_acc: 0.8374 34Epoch 18/50 3521883/21883 [==============================] - 31s 1ms/step - loss: 0.3688 - acc: 0.8375 - val_loss: 0.3768 - val_acc: 0.8330 36Epoch 19/50 3721883/21883 [==============================] - 30s 1ms/step - loss: 0.3704 - acc: 0.8375 - val_loss: 0.3621 - val_acc: 0.8392 38Epoch 20/50 3921883/21883 [==============================] - 31s 1ms/step - loss: 0.3608 - acc: 0.8444 - val_loss: 0.3656 - val_acc: 0.8422 40Epoch 21/50 4121883/21883 [==============================] - 31s 1ms/step - loss: 0.3548 - acc: 0.8459 - val_loss: 0.3670 - val_acc: 0.8417 42Epoch 22/50 4321883/21883 [==============================] - 30s 1ms/step - loss: 0.3521 - acc: 0.8452 - val_loss: 0.3555 - val_acc: 0.8462 44Epoch 23/50 4521883/21883 [==============================] - 30s 1ms/step - loss: 0.3432 - acc: 0.8504 - val_loss: 0.3591 - val_acc: 0.8402 46Epoch 24/50 4721883/21883 [==============================] - 31s 1ms/step - loss: 0.3415 - acc: 0.8524 - val_loss: 0.3471 - val_acc: 0.8470 48Epoch 25/50 4921883/21883 [==============================] - 30s 1ms/step - loss: 0.3355 - acc: 0.8555 - val_loss: 0.3577 - val_acc: 0.8436 50Epoch 26/50 5121883/21883 [==============================] - 30s 1ms/step - loss: 0.3320 - acc: 0.8552 - val_loss: 0.3602 - val_acc: 0.8430 52Epoch 27/50 5321883/21883 [==============================] - 30s 1ms/step - loss: 0.3294 - acc: 0.8578 - val_loss: 0.3565 - val_acc: 0.8485 54Epoch 28/50 5521883/21883 [==============================] - 30s 1ms/step - loss: 0.3235 - acc: 0.8602 - val_loss: 0.3427 - val_acc: 0.8514 56Epoch 29/50 5721883/21883 [==============================] - 31s 1ms/step - loss: 0.3138 - acc: 0.8651 - val_loss: 0.3523 - val_acc: 0.8470 58Epoch 30/50 5921883/21883 [==============================] - 30s 1ms/step - loss: 0.3095 - acc: 0.8683 - val_loss: 0.3457 - val_acc: 0.8487 60Epoch 31/50 6121883/21883 [==============================] - 31s 1ms/step - loss: 0.3064 - acc: 0.8701 - val_loss: 0.3538 - val_acc: 0.8531 62Epoch 32/50 6321883/21883 [==============================] - 30s 1ms/step - loss: 0.2985 - acc: 0.8717 - val_loss: 0.3555 - val_acc: 0.8455 64Epoch 33/50 6521883/21883 [==============================] - 30s 1ms/step - loss: 0.2930 - acc: 0.8741 - val_loss: 0.3430 - val_acc: 0.8525 66Epoch 34/50 6721883/21883 [==============================] - 30s 1ms/step - loss: 0.2901 - acc: 0.8786 - val_loss: 0.3457 - val_acc: 0.8503 68Epoch 35/50 6921883/21883 [==============================] - 30s 1ms/step - loss: 0.2852 - acc: 0.8776 - val_loss: 0.3458 - val_acc: 0.8510 70Epoch 36/50 7121883/21883 [==============================] - 30s 1ms/step - loss: 0.2817 - acc: 0.8811 - val_loss: 0.3445 - val_acc: 0.8568 72Epoch 37/50 7321883/21883 [==============================] - 30s 1ms/step - loss: 0.2780 - acc: 0.8816 - val_loss: 0.3356 - val_acc: 0.8540 74Epoch 38/50 7521883/21883 [==============================] - 30s 1ms/step - loss: 0.2734 - acc: 0.8852 - val_loss: 0.3442 - val_acc: 0.8559 76Epoch 39/50 7721883/21883 [==============================] - 31s 1ms/step - loss: 0.2579 - acc: 0.8904 - val_loss: 0.3552 - val_acc: 0.8540 78Epoch 40/50 7921883/21883 [==============================] - 30s 1ms/step - loss: 0.2551 - acc: 0.8927 - val_loss: 0.3677 - val_acc: 0.8532 80Epoch 41/50 8121883/21883 [==============================] - 30s 1ms/step - loss: 0.2558 - acc: 0.8921 - val_loss: 0.3496 - val_acc: 0.8588 82Epoch 42/50 8321883/21883 [==============================] - 30s 1ms/step - loss: 0.2472 - acc: 0.8963 - val_loss: 0.3534 - val_acc: 0.8587 84Epoch 43/50 8521883/21883 [==============================] - 31s 1ms/step - loss: 0.2486 - acc: 0.8948 - val_loss: 0.3490 - val_acc: 0.8537 86Epoch 44/50 8721883/21883 [==============================] - 31s 1ms/step - loss: 0.2503 - acc: 0.8965 - val_loss: 0.3594 - val_acc: 0.8552 88Epoch 45/50 8921883/21883 [==============================] - 30s 1ms/step - loss: 0.2391 - acc: 0.8993 - val_loss: 0.3793 - val_acc: 0.8566 90Epoch 46/50 9121883/21883 [==============================] - 31s 1ms/step - loss: 0.2244 - acc: 0.9048 - val_loss: 0.3815 - val_acc: 0.8543 92Epoch 47/50 9321883/21883 [==============================] - 30s 1ms/step - loss: 0.2203 - acc: 0.9095 - val_loss: 0.3848 - val_acc: 0.8554 94Epoch 48/50 9521883/21883 [==============================] - 30s 1ms/step - loss: 0.2221 - acc: 0.9051 - val_loss: 0.3892 - val_acc: 0.8558 96Epoch 49/50 9721883/21883 [==============================] - 30s 1ms/step - loss: 0.2117 - acc: 0.9124 - val_loss: 0.3654 - val_acc: 0.8544 98Epoch 50/50 9921883/21883 [==============================] - 30s 1ms/step - loss: 0.2141 - acc: 0.9118 - val_loss: 0.3726 - val_acc: 0.8547 ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p train l√† h∆°n 90%, tr√™n t·∫≠p val l√† h∆°n 85%. Nh√¨n k·ªπ h∆°n v√†o nh·ªØng t·ª´ sai ta th·∫•y r·∫±ng\n1 name gender predicted_gender 26750 Chiaki f m 328599 Naheed f m 411448 Espiridi√≥n m f 5895 Akmaral f m 633778 Ros f m C√≥ m·ªôt s·ª± nh·∫≠p nh·∫±ng ·ªü ng√¥n ng·ªØ gi·ªØa t√™n nam v√† t√™n n·ªØ ·ªü nh·ªØng t·ª´ n√†y. C√≥ l·∫Ω m·ªôt t·∫≠p d·ªØ li·ªáu v·ªõi ƒë·∫ßy ƒë·ªß h·ªç v√† t√™n s·∫Ω cho ra m·ªôt k·∫øt qu·∫£ c√≥ ƒë·ªô ch√≠nh x√°c cao h∆°n. V√≠ d·ª•, ·ªü Vi·ªát Nam, t√™n Ng·ªçc th√¨ c√≥ th·ªÉ ƒë·∫∑t ƒë∆∞·ª£c cho c·∫£ Nam l·∫´n N·ªØ.\nM√¨nh s·∫Ω c·ªë g·∫Øng ki·∫øm m·ªôt b·ªô dataset t√™n ti·∫øng vi·ªát v√† th·ª±c hi·ªán vi·ªác x√¢y d·ª±ng m√¥ h√¨nh x√°c ƒë·ªãnh gi·ªõi t√≠nh th√¥ng qua t√™n ng∆∞·ªùi d·ª±a v√†o m√¥ h√¨nh LSTM.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Feb 6, 2019","img":"","permalink":"/blog/2019-02-06-choosing-the-right-hyperparameters-for-a-simple-lstm-using-keras/","series":null,"tags":["Machine learning","Deeplearning","python"],"title":"L·ª±a Ch·ªçn Si√™u Tham S·ªë Cho M√¥ H√¨nh LSTM ƒê∆°n Gi·∫£n S·ª≠ D·ª•ng Keras"},{"categories":null,"content":" M·ªü ƒë·∫ßu Gi·∫£m b·ªô nh·ªõ ti√™u th·ª• c·ªßa m·ªôt ƒë·ªëi t∆∞·ª£ng trong python M·ªü ƒë·∫ßu B·∫Øt ƒë·∫ßu b·∫±ng m·ªôt class ƒë∆°n gi·∫£n nh∆∞ sau:\n1class DataItem(object): 2 def __init__(self, name, age, address): 3 self.name = name 4 self.age = age 5 self.address = address B·∫°n nghƒ© m·ªôt ƒë·ªëi t∆∞·ª£ng c·ªßa class tr√™n s·∫Ω chi·∫øm bao nhi√™u b·ªô nh·ªõ. Ch√∫ng ta c√πng ti·∫øn h√†nh m·ªôt v√†i th√≠ nghi·ªám nho nh·ªè b√™n d∆∞·ªõi.\n1dx = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;-\u0026#34;) 2print (\u0026#34;sys.getsizeof(dx):\u0026#34;, sys.getsizeof(dx)) 3\u0026gt;\u0026gt; sys.getsizeof(dx): 56 K·∫øt qu·∫£ ra l√† 56 bytes, kh√° h·ª£p l√Ω ph·∫£i kh√¥ng c√°c b·∫°n. Th·ª≠ v·ªõi m·ªôt v√≠ d·ª• kh√°c xem sao nh·ªâ.\n1dy = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;I am working at MWG\u0026#34;) 2print (\u0026#34;sys.getsizeof(dy):\u0026#34;, sys.getsizeof(dy)) 3\u0026gt;\u0026gt; sys.getsizeof(dy): 56 K·∫øt qu·∫£ v·∫´n l√† 56 bytes. C√≥ c√°i g√¨ ƒë√≥ sai sai ·ªü ƒë√¢y kh√¥ng nh·ªâ?\nCh√∫ng ta th·ª±c nghi·ªám m·ªôt v√†i th√≠ nghi·ªám kh√°c ƒë·ªÉ ch·ª©ng th·ª±c.\n1print (sys.getsizeof(\u0026#34;\u0026#34;)) 2\u0026gt;\u0026gt; 49 3print (sys.getsizeof(\u0026#34;1\u0026#34;)) 4\u0026gt;\u0026gt; 50 5print (sys.getsizeof(1)) 6\u0026gt;\u0026gt; 28 7print (sys.getsizeof(dict())) 8\u0026gt;\u0026gt; 240 9print (sys.getsizeof({})) 10\u0026gt;\u0026gt; 240 11print (sys.getsizeof(list())) 12\u0026gt;\u0026gt; 64 13print (sys.getsizeof([])) 14\u0026gt;\u0026gt; 64 15print (sys.getsizeof(())) 16\u0026gt;\u0026gt; 48 M·ªôt ƒëi·ªÅu c·ª±c k·ª≥ b·∫•t ng·ªù ƒë√£ xu·∫•t hi·ªán ·ªü ƒë√¢y. M·ªôt chu·ªói r·ªóng chi·∫øm ƒë·∫øn t·∫≠n 49 bytes, m·ªôt dictionary r·ªóng, kh√¥ng ch·ª©a ph·∫ßn t·ª≠ n√†o chi·∫øm ƒë·∫øn 240 bytes, v√† m·ªôt list r·ªóng chi·∫øm t·ªõi 64 bytes. R√µ r√†ng, python ƒë√£ l∆∞u m·ªôt s·ªë th·ª© g√¨ ƒë√≥ ngo√†i d·ªØ li·ªáu c·ªßa m√¨nh.\nƒêi s√¢u v√†o th·ª≠ t√¨m hi·ªÉu nh·ªØng th·ª© \u0026rsquo;linh ki·ªán\u0026rsquo; linh tinh m√† python ƒë√£ k√®m theo cho ch√∫ng ta l√† g√¨ nh√©.\nƒê·∫ßu ti√™n, ch√∫ng ta s·∫Ω c·∫ßn m·ªôt h√†m in ra nh·ªØng th·ª© m√† python ƒë√£ \u0026rsquo;nh√∫ng\u0026rsquo; th√™m v√†o class DataItem ch√∫ng ta khai b√°o ·ªü tr√™n.\n1def dump(obj): 2 for attr in dir(obj): 3 print(\u0026#34; obj.%s = %r\u0026#34; % (attr, getattr(obj, attr))) v√† dump bi·∫øn dy ra th√¥i\n1dump(dy) 2 3obj.__class__ = \u0026lt;class \u0026#39;__main__.DataItem\u0026#39;\u0026gt; 4 obj.__delattr__ = \u0026lt;method-wrapper \u0026#39;__delattr__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 5 obj.__dict__ = {\u0026#39;name\u0026#39;: \u0026#39;Alex Black\u0026#39;, \u0026#39;age\u0026#39;: 42, \u0026#39;address\u0026#39;: \u0026#39;i am working at MWG\u0026#39;} 6 obj.__dir__ = \u0026lt;built-in method __dir__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 7 obj.__doc__ = None 8 obj.__eq__ = \u0026lt;method-wrapper \u0026#39;__eq__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 9 obj.__format__ = \u0026lt;built-in method __format__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 10 obj.__ge__ = \u0026lt;method-wrapper \u0026#39;__ge__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 11 obj.__getattribute__ = \u0026lt;method-wrapper \u0026#39;__getattribute__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 12 obj.__gt__ = \u0026lt;method-wrapper \u0026#39;__gt__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 13 obj.__hash__ = \u0026lt;method-wrapper \u0026#39;__hash__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 14 obj.__init__ = \u0026lt;bound method DataItem.__init__ of \u0026lt;__main__.DataItem object at 0x000001A64A6DD0F0\u0026gt;\u0026gt; 15 obj.__init_subclass__ = \u0026lt;built-in method __init_subclass__ of type object at 0x000001A64A5DE738\u0026gt; 16 obj.__le__ = \u0026lt;method-wrapper \u0026#39;__le__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 17 obj.__lt__ = \u0026lt;method-wrapper \u0026#39;__lt__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 18 obj.__module__ = \u0026#39;__main__\u0026#39; 19 obj.__ne__ = \u0026lt;method-wrapper \u0026#39;__ne__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 20 obj.__new__ = \u0026lt;built-in method __new__ of type object at 0x000000005C2DC580\u0026gt; 21 obj.__reduce__ = \u0026lt;built-in method __reduce__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 22 obj.__reduce_ex__ = \u0026lt;built-in method __reduce_ex__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 23 obj.__repr__ = \u0026lt;method-wrapper \u0026#39;__repr__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 24 obj.__setattr__ = \u0026lt;method-wrapper \u0026#39;__setattr__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 25 obj.__sizeof__ = \u0026lt;built-in method __sizeof__ of DataItem object at 0x000001A64A6DD0F0\u0026gt; 26 obj.__str__ = \u0026lt;method-wrapper \u0026#39;__str__\u0026#39; of DataItem object at 0x000001A64A6DD0F0\u0026gt; 27 obj.__subclasshook__ = \u0026lt;built-in method __subclasshook__ of type object at 0x000001A64A5DE738\u0026gt; 28 obj.__weakref__ = None 29 obj.address = \u0026#39;i am working at MWG\u0026#39; 30 obj.age = 42 31 obj.name = \u0026#39;Alex Black\u0026#39; Wow, c√≥ v·∫ª kh√° l√† ƒë·ªì s·ªô nh·ªâ.\nTr√™n github, c√≥ m·ªôt h√†m c√≥ s·∫µn t√≠nh to√°n s·ªë l∆∞·ª£ng b·ªô nh·ªõ m√† object chi·∫øm ƒë∆∞·ª£c d·ª±a v√†o c√°ch truy xu·∫•t tr·ª±c ti·∫øp t·ª´ng tr∆∞·ªùng d·ªØ li·ªáu c·ªßa ƒë·ªëi t∆∞·ª£ng v√† t√≠nh to√°n k√≠ch th∆∞·ªõc\n1import sys 2 3def get_size(obj, seen=None): 4 \u0026#34;\u0026#34;\u0026#34;Recursively finds size of objects\u0026#34;\u0026#34;\u0026#34; 5 size = sys.getsizeof(obj) 6 if seen is None: 7 seen = set() 8 obj_id = id(obj) 9 if obj_id in seen: 10 return 0 11 # Important mark as seen *before* entering recursion to gracefully handle 12 # self-referential objects 13 seen.add(obj_id) 14 if isinstance(obj, dict): 15 size += sum([get_size(v, seen) for v in obj.values()]) 16 size += sum([get_size(k, seen) for k in obj.keys()]) 17 elif hasattr(obj, \u0026#39;__dict__\u0026#39;): 18 size += get_size(obj.__dict__, seen) 19 elif hasattr(obj, \u0026#39;__iter__\u0026#39;) and not isinstance(obj, (str, bytes, bytearray)): 20 size += sum([get_size(i, seen) for i in obj]) 21 return size th·ª≠ v·ªõi 2 bi·∫øn dx v√† dy c·ªßa ch√∫ng ta xem sao\n1\u0026gt;\u0026gt;\u0026gt; print (\u0026#34;get_size(d1):\u0026#34;, get_size(dx)) 2get_size(d1): 466 3\u0026gt;\u0026gt;\u0026gt; print (\u0026#34;get_size(d1):\u0026#34;, get_size(dy)) 4get_size(d1): 484 Ch√∫ng t·ªën l·∫ßn l∆∞·ª£t l√† 466 v√† 484 bytes. C√≥ v·∫ª ƒë√∫ng ƒë√≥ nh·ªâ.\nƒêi·ªÅu ch√∫ng ta quan t√¢m l√∫c n√†y l√† c√≥ c√°ch n√†o ƒë·ªÉ gi·∫£m b·ªô nh·ªõ ti√™u th·ª• c·ªßa m·ªôt object hay kh√¥ng?\nGi·∫£m b·ªô nh·ªõ ti√™u th·ª• c·ªßa m·ªôt ƒë·ªëi t∆∞·ª£ng trong python T·∫•t nhi√™n l√† s·∫Ω c√≥ c√°ch gi·∫£m. Python l√† m·ªôt ng√¥n ng·ªØ th√¥ng d·ªãch, v√† n√≥ cho ph√©p ch√∫ng ta m·ªü r·ªông l·ªõp b·∫•t k·ªÉ l√∫c n√†o b·∫±ng c√°ch th√™m m·ªôt/ nhi·ªÅu tr∆∞·ªùng d·ªØ li·ªáu.\n1dz = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;-\u0026#34;) 2dz.height = 1.80 3print ( get_size(dz)) 4\u0026gt;\u0026gt; 484 Ch√≠nh v√¨ l√Ω do n√†y, tr√¨nh bi√™n d·ªãch s·∫Ω t·ªën th√™m m·ªôt ƒë·ªëng b·ªô nh·ªõ t·∫°m ƒë·ªÉ ch√∫ng ta c√≥ th·ªÉ d·ªÖ d√†ng m·ªü r·ªông m·ªôt l·ªõp trong t∆∞∆°ng lai. N·∫øu ch√∫ng ta \u0026ldquo;√©p bu·ªôc\u0026rdquo; tr√¨nh bi√™n d·ªãch, n√≥i r·∫±ng ch√∫ng ta ch·ªâ c√≥ nhi√™u ƒë√≥ tr∆∞·ªùng, v√† b·ªè ph·∫ßn d∆∞ th·ª´a ƒëi.\n1class DataItem(object): 2 __slots__ = [\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;address\u0026#39;] 3 def __init__(self, name, age, address): 4 self.name = name 5 self.age = age 6 self.address = address V√† th·ª≠ l·∫°i\n1 2dz = DataItem(\u0026#34;Alex Black\u0026#34;, 42, \u0026#34;i am working at MWG\u0026#34;) 3print (\u0026#34;sys.getsizeof(dz):\u0026#34;, get_size(dz)) 4 5\u0026gt;\u0026gt;sys.getsizeof(dz): 64 C√°c b·∫°n th·∫•y g√¨ kh√¥ng, b·ªô nh·ªõ ti√™u th·ª• ch·ªâ l√† \u0026ldquo;64 bytes\u0026rdquo;. Dung l∆∞·ª£ng ƒë√£ gi·∫£m ƒëi h∆°n \u0026ldquo;7 l·∫ßn\u0026rdquo; so v·ªõi model class ban ƒë·∫ßu. Tuy nhi√™n, ch√∫ng ta s·∫Ω kh√¥ng th·ªÉ m·ªü r·ªông class d·ªÖ d√†ng nh∆∞ x∆∞a n·ªØa.\n1\u0026gt;\u0026gt;\u0026gt; dz.height = 1.80 2Traceback (most recent call last): 3 File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; 4AttributeError: \u0026#39;DataItem\u0026#39; object has no attribute \u0026#39;height\u0026#39; Th·ª≠ t·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng c√≥ 1000 ph·∫ßn t·ª≠ v√† ki·ªÉm tra th·ª≠.\n1class DataItem(object): 2 __slots__ = [\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;address\u0026#39;] 3 def __init__(self, name, age, address): 4 self.name = name 5 self.age = age 6 self.address = address 7 8 9data = [] 10 11tracemalloc.start() 12start =datetime.datetime.now() 13for p in range(100000): 14 data.append(DataItem(\u0026#34;Alex\u0026#34;, 42, \u0026#34;middle of nowhere\u0026#34;)) 15 16end =datetime.datetime.now() 17snapshot = tracemalloc.take_snapshot() 18top_stats = snapshot.statistics(\u0026#39;lineno\u0026#39;) 19total = sum(stat.size for stat in top_stats) 20print(\u0026#34;Total allocated size: %.1f MB\u0026#34; % (total / (1024*1024))) 21print(\u0026#34;Total execute time:\u0026#34;,(end-start).microseconds) 22 23\u0026gt;\u0026gt; Total allocated size: 6.9 MB 24\u0026gt;\u0026gt; Total execute time: 232565 B·ªè d√≤ng slots = [\u0026rsquo;name\u0026rsquo;, \u0026lsquo;age\u0026rsquo;, \u0026lsquo;address\u0026rsquo;] ƒëi th·ª≠\n1 2class DataItem(object): 3 def __init__(self, name, age, address): 4 self.name = name 5 self.age = age 6 self.address = address 7 8 9data = [] 10 11tracemalloc.start() 12start =datetime.datetime.now() 13for p in range(100000): 14 data.append(DataItem(\u0026#34;Alex\u0026#34;, 42, \u0026#34;middle of nowhere\u0026#34;)) 15end =datetime.datetime.now() 16snapshot = tracemalloc.take_snapshot() 17top_stats = snapshot.statistics(\u0026#39;lineno\u0026#39;) 18total = sum(stat.size for stat in top_stats) 19print(\u0026#34;Total allocated size: %.1f MB\u0026#34; % (total / (1024*1024))) 20print(\u0026#34;Total execute time:\u0026#34;,(end-start).microseconds) 21 22\u0026gt;\u0026gt; Total allocated size: 16.8 MB 23\u0026gt;\u0026gt; Total execute time: 240772 So s√°nh th·ª≠, ch√∫ng ta th·∫•y r·∫±ng s·ªë l∆∞·ª£ng RAM gi·∫£m ƒëi kh√° nhi·ªÅu, th·ªùi gian th·ª±c thi kh√° t∆∞∆°ng ƒë∆∞∆°ng nhau (c√≥ gi·∫£m m·ªôt ch√∫t).\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Feb 6, 2019","img":"","permalink":"/blog/2019-02-06-how-to-reduce-memory-consumption-by-half-by-adding-just-one-line-of-code/","series":null,"tags":["Machine learning","Deeplearning","python"],"title":"Gi·∫£m B·ªô Nh·ªõ S·ª≠ D·ª•ng Trong Python"},{"categories":null,"content":" M·ªü ƒë·∫ßu M·∫πo s·ªë 1: S·ª©c m·∫°nh c·ªßa m·ªôt d√≤ng M·∫πo 2: C√°c thao t√°c nhanh tr√™n chu·ªói M·∫πo s·ªë 3: Chu·ªói l·ªìng nhau M·∫πo 4: C·∫•u tr√∫c d·ªØ li·ªáu ƒë∆°n gi·∫£n. M·∫πo 5: Xu·∫•t d·ªØ li·ªáu ra command line d·ªÖ d√†ng M·ªü ƒë·∫ßu Hi·ªán nay, c√≥ r·∫•t nhi·ªÅu th∆∞ vi·ªán do c·ªông ƒë·ªìng ƒë√≥ng g√≥p v√† x√¢y d·ª±ng. V√≠ d·ª• nh∆∞ biopython trong tin sinh h·ªçc, pandas (data science), keras/tensorflow (machine learning), astropy ( cho thi√™n vƒÉn h·ªçc - astronomy). Tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu ƒë·ªçc b√†i vi·∫øt n√†y, b·∫°n ƒë√™n ƒë·ªçc \u0026ldquo;Python Tricks Book\u0026rdquo; c·ªßa Dan Bader tr∆∞·ªõc (https://dbader.org/products/python-tricks-book/). Trong s√°ch, anh ·∫•y ƒë√£ chia s·∫ª m·ªôt s·ªë l·ªùi khuy√™n v√† m·∫πo v·ªÅ c√°c code python hi·ªáu qu·∫£ h∆°n.\nM·∫πo s·ªë 1: S·ª©c m·∫°nh c·ªßa m·ªôt d√≤ng Khi b·∫°n ƒë·ªçc m·ªôt ƒëo·∫°n gi·∫£i thu·∫≠t v·ªõi nhi·ªÅu d√≤ng code, c√≥ th·ªÉ b·∫°n s·∫Ω b·ªã qu√™n th√¥ng tin nh·ªØng d√≤ng tr∆∞·ªõc ƒë√≥ ƒë√£ vi·∫øt g√¨, ƒë·∫∑c bi·ªát l√† trong nh·ªØng c√¢u l·ªánh ƒëi·ªÅu ki·ªán. V√≠ d·ª•:\n1 2if alpha \u0026gt; 7: 3 beta = 999 4elif alpha == 7: 5 beta = 99 6else: 7 beta =0 Ch√≥ng ta c√≥ th·ªÉ vi·∫øt ƒë∆°n gi·∫£n h∆°n ch·ªâ v·ªõi m·ªôt d√≤ng code nh∆∞ sau.\n1beta = 999 if alpha \u0026gt; 7 else 99 if alpha == 7 else 0 th·∫≠t ƒë∆°n gi·∫£n ph·∫£i kh√¥ng. B·∫°n ch·ªâ c·∫ßn nh√¨n ƒë√∫ng m·ªôt d√≤ng l√† n·∫±m ƒë∆∞·ª£c n·ªôi dung √Ω nghƒ©a c·ªßa ƒëo·∫°n code b·∫°n c·∫ßn. M·ªôt v√≠ d·ª• kh√°c v·ªÅ v√≤ng l·∫∑p for.\n1lst = [1, 2, 3, 4] 2lst_double = [] 3 4for num in lst: 5 lst_double.append(num * 2) ƒêo·∫°n code tr√™n c√≥ th·ªÉ vi·∫øt l·∫°i d∆∞·ªõi d·∫°ng 1 d√≤ng nh∆∞ sau.\n1lst_double = [num * 2 for num in lst] T·∫•t nhi√™n, b·∫°n kh√¥ng n√™n \u0026ldquo;l·∫°m d·ª•ng\u0026rdquo; one line m·ªôt c√°ch th√°i qu√°, v√≠ d·ª•\n1import pprint; pprint.pprint(zip((\u0026#39;Byte\u0026#39;, \u0026#39;KByte\u0026#39;, \u0026#39;MByte\u0026#39;, \u0026#39;GByte\u0026#39;, \u0026#39;TByte\u0026#39;), (1 \u0026lt;\u0026lt; 10*i for i in xrange(5)))) Tr√¥ng n√≥ c√≥ v·∫ª h∆°i \u0026ldquo;l·ªë b·ªãch\u0026rdquo; ph·∫£i kh√¥ng.\nM·∫πo 2: C√°c thao t√°c nhanh tr√™n chu·ªói Python cung c·∫•p cho ch√∫ng ta m·ªôt s·ªë c√°ch vi·∫øt ng·∫Øn g·ªçn gi√∫p ch√∫ng ta c√≥ th·ªÉ d·ªÉ d√†ng thao t√°c tr√™n chu·ªói. ƒê·ªÉ reverse m·ªôt chu·ªói, ch√∫ng ta s·ª≠ d·ª•ng to√°n t·ª≠ ::-1\n1 2str = \u0026#39;i am alex\u0026#39; 3print(str[::-1]) 4\u0026gt;\u0026gt; xela ma i M·∫πo tr√™n c≈©ng c√≥ th·ªÉ s·ª≠ d·ª•ng ƒë·ªëi v·ªõi list s·ªë nguy√™n.\nƒê·ªÉ n·ªëi c√°c ph·∫ßn t·ª≠ trong m·ªôt list th√†nh m·ªôt chu·ªói, ch√∫ng ta c√≥ th·ªÉ d√πng h√†m join()\n1 2str1 = [\u0026#34;pig\u0026#34;, \u0026#34;year\u0026#34; , \u0026#34;2019\u0026#34;] 3str2 = \u0026#34;happy \u0026#34; 4str3 = \u0026#34;new \u0026#34; 5 6 7print( \u0026#39; \u0026#39;.join(str1)) 8\u0026gt;\u0026gt; pig year 2019 9 10print(str2+str3+\u0026#39; \u0026#39;.join(str1)) 11\u0026gt;\u0026gt; happy new year 2019 Th·∫≠t tuy·ªát v·ªùi ph·∫£i kh√¥ng c√°c b·∫°n.\nNgo√†i ra c√°c b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng bi·∫øu th·ª©c ch√≠nh quy ƒë·ªÉ t√¨m ki·∫øm chu·ªói v√† pattern. V·ªÅ bi·ªÉu th·ª©c ch√≠nh quy trong python, c√°c b·∫°n c√≥ th·ªÉ t√¨m hi·ªÉu ·ªü https://docs.python.org/3/library/re.html.\nM·∫πo s·ªë 3: Chu·ªói l·ªìng nhau Th·ª≠ t∆∞·ªüng t∆∞·ª£ng r·∫±ng b·∫°n c√≥ h√†ng t√° c√°c list, v√† sau m·ªôt m·ªõ c√°c thao t√°c, k·∫øt qu·∫£ c·ªßa b·∫°n l√† m·ªôt list c√°c list. Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng itertools - m·ªôt th∆∞ vi·ªán ƒë∆∞·ª£c cung c·∫•p s·∫µn trong python ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y gi√∫p ch√∫ng ta.\n1 2import itertools 3flatten = lambda x: list(itertools.chain.from_iterable(x)) 4s =[[\u0026#34;this\u0026#34;,\u0026#34;is\u0026#34;],[\u0026#34;the\u0026#34;,\u0026#34;year\u0026#34;], [\u0026#34;of\u0026#34;, \u0026#34;pig\u0026#34;], [\u0026#34;in\u0026#34;], [\u0026#34;Vi·ªát\u0026#34;, \u0026#34;Nam\u0026#34;]] 5 6print(\u0026#39; \u0026#39;,join(flatten(s))) 7\u0026gt;\u0026gt; this is the year of pig in Vi·ªát Nam N·∫øu b·∫°n ch·∫°y d√≤ng code tr√™n b·ªã l·ªói, r·∫•t c√≥ th·ªÉ l√† do terminal c·ªßa b·∫°n kh√¥ng h·ªó tr·ª£ ti·∫øng vi·ªát font unicode. H√£y chuy·ªÉn qua font unicode tr√™n terminal ho·∫∑c d√πng terminal c·ªßa ubuntu, bash (tr√™n window 10).\nNgo√†i ra, itertools c√≤n h·ªó tr·ª£ r·∫•t nhi·ªÅu h√†m kh√°c ƒë·ªÉ gi√∫p ch√∫ng ta thao t√°c tr√™n chu·ªói l·ªìng d·ªÖ d√†ng h∆°n. C√°c b·∫°n c√≥ th·ªÉ tham kh·∫£o th√™m ·ªü https://docs.python.org/2/library/itertools.html.\nM·∫πo 4: C·∫•u tr√∫c d·ªØ li·ªáu ƒë∆°n gi·∫£n. Ch√∫ng ta c√≥ th·ªÉ x√¢y d·ª±ng m·ªôt c√¢y ƒë∆°n gi·∫£n ch·ªâ v·ªõi m·ªôt d√≤ng m√£ l·ªánh:\n1def tree(): return defaultdict(tree) M·ªôt v√≠ d·ª• ƒë∆°n gi·∫£n kh√°c l√† h√†m t·∫°o s·ªë nguy√™n ch·ªâ v·ªõi 1 d√≤ng code ng·∫Øn g·ªçn\n1reduce( (lambda r,x: r-set(range(x**2,N,x)) if (x in r) else r), 2 range(2,N), set(range(2,N))) Python c√≥ h·ªó tr·ª£ nhi·ªÅu th∆∞ vi·ªán r·∫•t m·∫°nh trong vi·ªác gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ trong th·∫ø gi·ªõi th·ª±c. V√≠ d·ª• th∆∞ vi·ªán Collections\n1from collections import Counter 2myList = [1,1,2,3,4,5,3,2,3,4,2,1,2,3] 3print(Counter(myList)) 4Counter({2: 4, 3: 4, 1: 3, 4: 2, 5: 1}) M·ªôt l∆∞u √Ω nh·ªè l√† c√°c th∆∞ vi·ªán n√†y ch·ªâ n√™n s·ª≠ d·ª•ng khi t·∫≠p d·ªØ li·ªáu c·ªßa b·∫°n nh·ªè, n·∫øu t·∫≠p d·ªØ li·ªáu l·ªõn, v√≠ d·ª• b·∫°n c·∫ßn ƒë·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa c√°c t·ª´ trong t·∫≠p vƒÉn b·∫£n v·ªõi 100GB d·ªØ li·ªáu. B·∫°n h√£y d√πng c√°ch kh√°c, v√≠ d·ª• hadoop, ho·∫∑c tƒÉng b·ªô nh·ªõ ram c·ªßa b·∫°n l√™n, v√≠ d·ª• 1 Tb ch·∫≥ng h·∫°n :)\nM·∫πo 5: Xu·∫•t d·ªØ li·ªáu ra command line d·ªÖ d√†ng ƒê·ªÉ xu·∫•t d·ªØ li·ªáu c·ªßa m·ªôt list int ra command line, theo nh∆∞ m·∫πo ·ªü tr√™n, ta s·∫Ω d√πng h√†m .join() v√† v√≤ng l·∫∑p.\n```python` lst_row = [1,2,3,4,5] print(\u0026rsquo;,\u0026rsquo;.join([str(x) for x in lst_row]) 1,2,3,4,5\n1 2C√°ch ƒë∆°n gi·∫£n h∆°n ch·ªâ v·ªõi m·ªôt d√≤ng code (∆Ø·ªõc g√¨ m√¨nh bi·∫øt c√°ch n√†y s·ªõm h∆°n, hix). 3 4```python 5print(*lst_row, sep=\u0026#39;,\u0026#39;) 61,2,3,4,5 M·ªôt m·∫πo kh√°c l√† trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p duy·ªát m·∫£ng, b·∫°n c·∫ßn l·∫•y gi√° tr·ªã v√† ch·ªâ s·ªë c·ªßa m·∫£ng ƒë√≥ ƒë·ªÉ l√†m m·ªôt s·ªë thao t√°c kh√°c\n1 2lst_arr = [\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;d\u0026#39;] 3 4int_index = 0 5 6for item in lst_arr: 7 print(int_index, item) 8\tint_index = int_index + 1 9 10\u0026gt;\u0026gt; 0 a 111 b 122 c 133 d ho·∫∑c c√°ch vi·∫øt gi·ªëng c/c++\n1 2for int_index in len(lst_arr): 3 print(int_index, lst_arr[int_index]) 4 5\u0026gt;\u0026gt; 0 a 61 b 72 c 83 d M·ªôt c√°ch kh√°c l√† s·ª≠ d·ª•ng h√†m c√≥ s·∫µn enumerate c·ªßa python\n1for int_index, item in enumerate(lst_arr): 2 print(int_index, item) 3 4\u0026gt;\u0026gt; 0 a 51 b 62 c 73 d C√≥ r·∫•t nhi·ªÅu m·∫πo hay ƒë·ªÉ ƒë∆°n gi·∫£n ho√° vi·ªác xu·∫•t d·ªØ li·ªáu ra terminal. H√£y th√¥ng tin cho m√¨nh bi·∫øt n·∫øu b·∫°n c√≥ nhi·ªÅu m·∫πo hay kh√°c c·∫ßn chia s·∫ª nh√©.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Feb 5, 2019","img":"","permalink":"/blog/2019-02-05-5-python-tricks-you-need-to-know-today/","series":null,"tags":["Machine learning","Deeplearning","python"],"title":"5 M·∫πo Hay S·ª≠ D·ª•ng Python"},{"categories":null,"content":" ƒê·∫∑t v·∫•n ƒë·ªÅ Ph√¢n t√≠ch d·ªØ li·ªáu X√¢y d·ª±ng chi·∫øn l∆∞·ª£c ti·∫øp c·∫≠n b√†i to√°n 1. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu 2. X√¢y d·ª±ng m√¥ h√¨nh Content-Based Filtering a. X√¢y d·ª±ng t·∫≠p ƒë·∫∑c tr∆∞ng b. X√¢y d·ª±ng m√¥ h√¨nh 3. Collaborative Filtering Model a. X√¢y d·ª±ng ma tr·∫≠n donor - project b. Singular Value Decomposition c. X√¢y d·ª±ng Collaborative Filtering Model 4. Hybrid Method 5. ƒê√°nh gi√° m√¥ h√¨nh ƒê·∫∑t v·∫•n ƒë·ªÅ DonorsChoose.org ƒë∆∞·ª£c th√†nh l·∫≠p v√†o nƒÉm 2000 b·ªüi m·ªôt gi√°o vi√™n l·ªãch s·ª≠ t·∫°i M·ªπ t√™n l√† Bronx v√† ƒë√£ huy ƒë·ªông ƒë∆∞·ª£c 685 tri·ªáu ƒë√¥ la cho c√°c l·ªõp h·ªçc. 3/4 c√°c gi√°o vi√™n ·ªü c√°c tr∆∞·ªùng c√¥ng l·∫≠p ·ªü Hoa K·ª≥ ƒë√£ s·ª≠ d·ª•ng Donor ƒë·ªÉ g·ª≠i c√°c y√™u c·∫ßu b√†i t·∫≠p cho h·ªçc sinh. T·ª´ ƒë√≥, Donor tr·ªü th√†nh n·ªÅn t·∫£ng gi√°o d·ª•c h√†ng ƒë·∫ßu h·ªó tr·ª£ cho c√°c v·∫•n ƒë·ªÅ gi√°o d·ª•c c√¥ng c·ªông.\nƒê·∫øn nay, h∆°n 3 tri·ªáu ng∆∞·ªùi d√πng v√† ƒë·ªëi t√°c ƒë√£ ƒë√≥ng g√≥p h∆°n 1,1 tri·ªáu d·ª± √°n cho Donor. Nh∆∞ng c√°c gi√°o vi√™n v·∫´n ph·∫£i t·ªën h√†ng t·ª∑ ƒë√¥ ti·ªÅn t√∫i ƒë·ªÉ chu·∫©n b·ªã c√°c d·ª•ng c·ª• h·ªçc t·∫≠p tr√™n l·ªõp (ƒë·ªÉ truy·ªÅn t·∫£i ki·∫øn th·ª©c cho h·ªçc sinh).\nGi·∫£i ph√°p ƒë∆∞·ª£c ƒë∆∞a ra ·ªü ƒë√¢y l√† x√¢y d·ª±ng m·ªôt chi·∫øn d·ªãch g·ª£i √Ω cho c√°c nh√† t·∫°i tr·ª£.\nPh√¢n t√≠ch d·ªØ li·ªáu Ch√∫ng ta c√≥ c√°c file sau:\nFile Donations.csv. V·ªõi m·ªói d·ª± √°n (Project ID), s·∫Ω c√≥ 1 ho·∫∑c nhi·ªÅu nh√† quy√™n g√≥p (Donor ID) m·ªói c·∫∑p (d·ª± √°n - nh√† quy√™n g√≥p s·∫Ω ƒë·ªãnh dang b·∫±ng 1 m√£ chung (Donation ID) v√† c√≥ c√°c c·ªôt th√¥ng tin li√™n quan ƒë·∫øn vi·ªác quy√™n g√≥p ƒë√≥). File c√≥ x·∫•p x·ªâ 4.67 tri·ªáu d√≤ng (ch√≠nh x√°c l√† 4687844 d√≤ng) v√† 7 c·ªôt. (Project ID - ƒê·ªãnh danh d·ª± √°n, Donation ID - ƒê·ªãnh danh kho·∫£ng ƒë√≥ng g√≥p (t∆∞·ªüng t∆∞·ª£ng nh∆∞ kho√° t·ª± tƒÉng c·ªßa b·∫£ng n√†y ƒë√≥ c√°c b·∫°n), Donor ID - M√£ ƒë·ªãnh danh ng∆∞·ªùi ƒë√≥ng g√≥p, Donation Included Option - h·ªó tr·ª£ website donoschoose 15% gi√° tr·ªã quy√™n g√≥p, Donation Amount - S·ªë ti·ªÅn quy√™n g√≥p, Donor Cart Sequence - Th·ª© t·ª± c·ªßa d·ª± √°n tr·ªçng b·∫£ng danh s√°ch quy√™n g√≥p,Donation Received Date - Ng√†y gi·ªù quy√™n g√≥p).\nFile Donors.csv. File ƒë·ªãnh danh ng∆∞·ªùi quy√™n g√≥p. Ch·ª©a t·ªïng c·ªông h∆°n 2 tri·ªáu d√≤ng( ch√≠nh x√°c l√† 2122640 d√≤ng) File c√≥ k√≠ch th∆∞·ªõc 2122640 x 5 v·ªõi c√°c th√¥ng tin c·ªôt l√† Donor ID (kho√° ch√≠nh, kh√¥ng tr√πng), Donor City (t√™n th√†nh ph·ªë nh√† ƒë·∫ßu t∆∞ ƒëang sinh s·ªëng), Donor State (ti·ªÉu bang m√† ng∆∞·ªùi quy√™n g√≥p ƒëang s·ªëng), Donor is teacher, Donor Zip (3 k√Ω t·ª± ƒë·∫ßu c·ªßa m√£ b∆∞u ƒëi·ªán nh√† t·ª´ thi·ªán).\nFile Teacher.csv. File c√≥ t·ªïng c·ªông 402900 d√≤ng v·ªõi c√°c c·ªôt TeachId, Teacher Prefix (Mr, Mrs, Ms), Teacher First Project Posted Date.\nFile Schools.csv. File c√≥ t·ªïng c·ªông 72994 d√≤ng v·ªõi c√°c c·ªôt l√† SchoolID, SchoolName (t√™n tr∆∞·ªùng c√≥ th·ªÉ tr√πng nhau), School Metro Type ( ph√¢n lo·∫°i tr∆∞·ªùng thu·ªôc 1 trong 5 nh√≥m : suburnban - ngo·∫°i √¥, rural - n√¥ng th√¥n, uban - th√†nh th·ªã, town - th·ªã tr·∫•n, unknow), School Percentage Free Lunch ( S·ªë nguy√™n, m√¥ t·∫£ t·ª∑ l·ªá ph·∫ßn trƒÉm s·ªë h·ªçc sinh ƒë·ªß ƒëi·ªÅu ki·ªán ƒÉn tr∆∞a mi·ªÖn ph√≠ ho·∫∑c ƒÉn tr∆∞a gi·∫£m ph√≠. D·ªØ li·ªáu thu ƒë∆∞·ª£c cung c·∫•p b·ªüi m·ªôt ƒë·ªëi t√°c th·ªëng k√™ ƒë·ªôc l·∫≠p l√† NCES. N·∫øu tr∆∞·ªùng n√†o kh√¥ng c√≥ gi√° tr·ªã do NCES cung c·∫•p, ch√∫ng ta s·∫Ω l·∫•y s·ªë ph·∫ßn trƒÉm n√†y l√† trung b√¨nh ph·∫ßn trƒÉm c·ªßa c√°c tr∆∞·ªùng c√πng huy·ªán), School State (Tr∆∞·ªùng ƒëang to·∫° l·∫°c ·ªü bang n√†o (vd cali, Florida, Virginia, \u0026hellip;)), School Zip (m√£ b∆∞u ch√≠nh), School City, School County\nFile Resources.csv. V·ªõi m·ªói d·ª± √°n, ch√∫ng ta c·∫ßn c√°c lo·∫°i t√†i nguy√™n kh√°c nhau. C√°c c·ªôt l√† Project ID (m√£ d·ª± √°n), Resource Item Name (t√™n t√†i nguy√™n c·∫ßn cho d·ª± √°n ƒë√≥ vd project 000009891526c0ade7180f8423792063 c·∫ßn \u0026lsquo;chair move and store cart\u0026rsquo;), Resource Quantity (s·ªë l∆∞·ª£ng t√†i nguy√™n c·∫ßn, vd c·∫ßn 1 c√°i gh·∫ø, 2 c√°i b·∫£ng v.v), Resource Unit Price (ƒë∆°n gi√° cho 1 ƒë∆°n v·ªã t√†i nguy√™n, vd c√°i gh·∫ø gi√° 7 ng√†n, c√°i b·∫£ng gi√° 10 ng√†n, n·∫øu 1 unit l√† gh·∫ø + b·∫£ng th√¨ l√† 17 ng√†n), Resource Vendor Name(nh√† cung c·∫•p, vd: Amazon Business, Woodwind and Brasswind).\nFile Projects.csv\nX√¢y d·ª±ng chi·∫øn l∆∞·ª£c ti·∫øp c·∫≠n b√†i to√°n H√£y xem ƒë√¢y nh∆∞ l√† b√†i to√°n g·ª£i √Ω. V√† Donors ch√≠nh l√† h·ªá th·ªëng cung c·∫•p c√°c s·∫£n ph·∫©m. V√≠ d·ª• ƒë∆°n gi·∫£n l√† b·∫°n c√≥ website nghe nh·∫°c mp3.zing.vn, alice v√†o nghe m·ªôt ho·∫∑c m·ªôt v√†i b√†i nh·∫°c. Ch√∫ng ta s·∫Ω x√¢y d·ª±ng m·ªôt h·ªá g·ª£i √Ω nh·ªØng b√†i nh·∫°c ti·∫øp theo alice n√™n nghe d·ª±a v√†o nh·ªØng b√†i nh·∫°c ƒë√£ nghe tr∆∞·ªõc ƒë√≥ c·ªßa alice. T∆∞∆°ng t·ª± v·∫≠y, h·ªá th·ªëng Donor nh∆∞ l√† website mp3.zing, b√†i nh·∫°c t∆∞∆°ng t·ª± nh∆∞ c√°c project ƒëang c√≥, ng∆∞·ªùi d√πng t∆∞∆°ng t·ª± nh∆∞ c√°c nh√† t·ª± thi·ªán. M·ªôt khi m·ªôt nh√† t·ª´ thi·ªán ƒë√£ quy√™n g√≥p cho 1 ho·∫∑c 1 nh√≥n c√°c d·ª± √°n, ch√∫ng ta s·∫Ω l√™n k·∫ø ho·∫°ch v√† g·ª£i √Ω cho kh√°c h√†ng d·ª± √°n ti·∫øp theo kh√°ch h√†ng n√™n t√¨m hi·ªÉu k·ªπ ƒë·ªÉ x√©t xem c√≥ n√™n donate hay kh√¥ng.\nD·ª±a v√†o c√°c chi·∫øn l∆∞·ª£c tr√™n, ch√∫ng ta c√≥ 3 c√°ch c√≥ th·ªÉ ti·∫øp c·∫≠n v·∫•n ƒë·ªÅ:\nContent-based filltering. Collaborative Filtering Hybrid methods 1. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu Tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu x√¢y d·ª±ng ch∆∞∆°ng tr√¨nh g·ª£i √Ω, ch√∫ng ta c·∫ßn ph·∫£i load d·ªØ li·ªáu l√™n b·ªô nh·ªõ ch√≠nh v√† l√†m s·∫°ch d·ªØ li·ªáu.\nTr∆∞·ªõc ti√™n, ch√∫ng ta s·∫Ω import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt. N·∫øu thi·∫øu c√°c th∆∞ vi·ªán n√†o, c√°c b·∫°n c·ª© pip install t√™n th∆∞ vi·ªán trong cmd/terminal l√† ƒë∆∞·ª£c\n1 2import numpy as np 3import scipy 4import pandas as pd 5import math 6import random 7import sklearn 8from nltk.corpus import stopwords 9from sklearn.model_selection import train_test_split 10from sklearn.feature_extraction.text import TfidfVectorizer 11from sklearn.metrics.pairwise import cosine_similarity 12from scipy.sparse.linalg import svds 13import matplotlib.pyplot as plt 14import os Ti·∫øp theo, ch√∫ng ta s·∫Ω load 3 file Projects.csv, Donations.csv, Donors.csv l√™n v√† merge donations v·ªõi donors.\n1# Set up test mode to save some time 2test_mode = True 3 4# Read datasets 5projects = pd.read_csv(\u0026#39;../input/Projects.csv\u0026#39;) 6donations = pd.read_csv(\u0026#39;../input/Donations.csv\u0026#39;) 7donors = pd.read_csv(\u0026#39;../input/Donors.csv\u0026#39;) 8 9#this piece of code converts Project_ID which is a 32-bit Hex int digits 10-1010 10# create column \u0026#34;project_id\u0026#34; with sequential integers 11f=len(projects) 12projects[\u0026#39;project_id\u0026#39;] = np.nan 13g = list(range(10,f+10)) 14g = pd.Series(g) 15projects[\u0026#39;project_id\u0026#39;] = g.values 16 17# Merge datasets 18donations = donations.merge(donors, on=\u0026#34;Donor ID\u0026#34;, how=\u0026#34;left\u0026#34;) 19df = donations.merge(projects,on=\u0026#34;Project ID\u0026#34;, how=\u0026#34;left\u0026#34;) 20 21# only load a few lines in test mode 22if test_mode: 23 df = df.head(10000) 24 25donations_df = df ·ªû giai ƒëo·∫°n x√¢y d·ª±ng code v√† debug, m√¨nh ch·ªâ load 10000 d·ªØ li·ªáu l√™n ƒë·ªÉ test th·ª≠ (ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng m√¨nh code ƒë√∫ng - b·∫±ng c√°ch set test_mode = True). Khi ch·∫°y th·∫≠t m√¨nh s·∫Ω set l·∫°i test_mode = False.\nTh·ª±c hi·ªán m·ªôt v√†i b∆∞·ªõc ph√¢n t√≠ch k·ªπ thu·∫≠t ƒë∆°n gi·∫£n ƒë·ªÉ n·∫Øm r√µ h∆°n v·ªÅ d·ªØ li·ªáu.\nTh·ª≠ ƒëo m·ªëi quan h·ªá gi·ªØa c√°c d·ª± √°n v√† c√°c \u0026ldquo;m·∫°nh th∆∞·ªùng qu√¢n\u0026rdquo;\n1# Deal with missing values 2donations[\u0026#34;Donation Amount\u0026#34;] = donations[\u0026#34;Donation Amount\u0026#34;].fillna(0) 3 4# Define event strength as the donated amount to a certain project 5donations_df[\u0026#39;eventStrength\u0026#39;] = donations_df[\u0026#39;Donation Amount\u0026#39;] 6 7def smooth_donor_preference(x): 8 return math.log(1+x, 2) 9 10donations_full_df = donations_df \\ 11 .groupby([\u0026#39;Donor ID\u0026#39;, \u0026#39;Project ID\u0026#39;])[\u0026#39;eventStrength\u0026#39;].sum() \\ 12 .apply(smooth_donor_preference).reset_index() 13 14# Update projects dataset 15project_cols = projects.columns 16projects = df[project_cols].drop_duplicates() 17 18print(\u0026#39;# of projects: %d\u0026#39; % len(projects)) 19print(\u0026#39;# of unique user/project donations: %d\u0026#39; % len(donations_full_df)) 1# of projects: 1889 2# of unique user/project donations: 8648 D·ª±a v√†o k·∫øt qu·∫£ tr√™n t·∫≠p test, ch√∫ng ta c√≥ th·ªÉ ƒë∆∞a ra m·ªôt v√†i nh·∫≠n x√©t nh∆∞ sau:\nH·∫ßu h·∫øt c√°c m·∫°nh th∆∞·ªùng qu√¢n ch·ªâ donate cho 1 project (t·ª∑ l·ªá 86,48%) S·∫Ω c√≥ tr∆∞·ªùng h·ª£p 1 m·∫°nh th∆∞·ªùng qu√¢n s·∫Ω donate cho nhi·ªÅu d·ª± √°n, v√† c≈©ng c√≥ tr∆∞·ªùng h·ª£p 1 m·∫°nh th∆∞·ªùng qu√¢n donate nhi·ªÅu l·∫ßn cho 1 d·ª± √°n. Tr∆∞·ªùng h·ª£p n√†y chi·∫øm ph·∫ßn √≠t. ƒê·ªÉ ƒë√°nh gi√° m√¥ h√¨nh, ch√∫ng ta s·∫Ω chia t·∫≠p d·ªØ li·ªáu th√†nh 2 ph·∫ßn l√† train v√† test. ·ªû ƒë√¢y, ch√∫ng ta s·∫Ω set t·ª∑ l·ªá train/test l√† 20%.\n2. X√¢y d·ª±ng m√¥ h√¨nh Content-Based Filtering C√°ch ti·∫øp c·∫≠n ƒë·∫ßu ti√™n, ch√∫ng ta s·∫Ω t√¨m nh·ªØng project g·∫ßn gi·ªëng v·ªõi nh·ªØng project m√† donor ƒë√£ donated. ƒê∆°n gi·∫£n nh·∫•t l√† v·ªõi m·ªói project, ch√∫ng ta s·∫Ω ƒë·ªãnh nghƒ©a c√°c vector ƒë·∫∑c tr∆∞ng c·ªßa ch√∫ng v√† ƒëo ƒë·ªô gi·ªëng nhau gi·ªØa hai vector ƒë√≥. Vector ƒë·∫∑c tr∆∞ng ch√∫ng ta c√≥ th·ªÉ x√¢y d·ª±ng tr√™n c√°c thu·ªôc t√≠nh nh∆∞ project type, project catefory, grade level, resource category, cost, school zip code, \u0026hellip; ho·∫∑c c√°c b·∫°n c√≥ th·ªÉ t·ª´ c√°c vector c∆° b·∫£n do t·∫≠p d·ªØ li·ªáu cung c·∫•p b·ªï sung th√™m c√°c vector c·∫•p cao h∆°n, v√≠ d·ª• nh∆∞ l√† r√∫t tr√≠ch c√°c feature t·ª´ t√™n project ho·∫∑c m√¥ t·∫£ c·ªßa project, lo·∫°i b·ªè stopwords \u0026hellip;\n·ªû ƒë√¢y, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng k·ªπ thu·∫≠t TF-IDF ƒë·ªÉ r√∫t tr√≠ch th√¥ng tin ƒë·∫∑c tr∆∞ng c·ªßa d·ª± √°n d·ª±a tr√™n project tittle v√† description. V·ªÅ TF-IDF, c√°c b·∫°n c√≥ th·ªÉ ƒë·ªçc ·ªü m·ªôt b√†i vi·∫øt n√†o ƒë√≥ c·ªßa google, m√¨nh kh√¥ng ti·ªán nh·∫Øc ƒë·∫øn n√≥ chi ti·∫øt ·ªü b√†i vi·∫øt n√†y.\na. X√¢y d·ª±ng t·∫≠p ƒë·∫∑c tr∆∞ng 1 2# Preprocessing of text data 3textfeats = [\u0026#34;Project Title\u0026#34;,\u0026#34;Project Essay\u0026#34;] 4for cols in textfeats: 5 projects[cols] = projects[cols].astype(str) 6 projects[cols] = projects[cols].astype(str).fillna(\u0026#39;\u0026#39;) # FILL NA 7 projects[cols] = projects[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently 8 9text = projects[\u0026#34;Project Title\u0026#34;] + \u0026#39; \u0026#39; + projects[\u0026#34;Project Essay\u0026#34;] 10vectorizer = TfidfVectorizer(strip_accents=\u0026#39;unicode\u0026#39;, 11 analyzer=\u0026#39;word\u0026#39;, 12 lowercase=True, # Convert all uppercase to lowercase 13 stop_words=\u0026#39;english\u0026#39;, # Remove commonly found english words (\u0026#39;it\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;the\u0026#39;) which do not typically contain much signal 14 max_df = 0.9, # Only consider words that appear in fewer than max_df percent of all documents 15 # max_features=5000 # Maximum features to be extracted 16 ) 17project_ids = projects[\u0026#39;Project ID\u0026#39;].tolist() 18tfidf_matrix = vectorizer.fit_transform(text) 19tfidf_feature_names = vectorizer.get_feature_names() 20 21 22# build profile 23 24def get_project_profile(project_id): 25 idx = project_ids.index(project_id) 26 project_profile = tfidf_matrix[idx:idx+1] 27 return project_profile 28 29def get_project_profiles(ids): 30 project_profiles_list = [get_project_profile(x) for x in np.ravel([ids])] 31 project_profiles = scipy.sparse.vstack(project_profiles_list) 32 return project_profiles 33 34def build_donors_profile(donor_id, donations_indexed_df): 35 donations_donor_df = donations_indexed_df.loc[donor_id] 36 donor_project_profiles = get_project_profiles(donations_donor_df[\u0026#39;Project ID\u0026#39;]) 37 donor_project_strengths = np.array(donations_donor_df[\u0026#39;eventStrength\u0026#39;]).reshape(-1,1) 38 #Weighted average of project profiles by the donations strength 39 donor_project_strengths_weighted_avg = np.sum(donor_project_profiles.multiply(donor_project_strengths), axis=0) / (np.sum(donor_project_strengths)+1) 40 donor_profile_norm = sklearn.preprocessing.normalize(donor_project_strengths_weighted_avg) 41 return donor_profile_norm 42 43from tqdm import tqdm 44 45def build_donors_profiles(): 46 donations_indexed_df = donations_full_df[donations_full_df[\u0026#39;Project ID\u0026#39;].isin(projects[\u0026#39;Project ID\u0026#39;])].set_index(\u0026#39;Donor ID\u0026#39;) 47 donor_profiles = {} 48 for donor_id in tqdm(donations_indexed_df.index.unique()): 49 donor_profiles[donor_id] = build_donors_profile(donor_id, donations_indexed_df) 50 return donor_profiles 51 52donor_profiles = build_donors_profiles() 53print(\u0026#34;# of donors with profiles: %d\u0026#34; % len(donor_profiles)) 54 55mydonor1 = \u0026#34;6d5b22d39e68c656071a842732c63a0c\u0026#34; 56mydonor2 = \u0026#34;0016b23800f7ea46424b3254f016007a\u0026#34; 57mydonor1_profile = pd.DataFrame(sorted(zip(tfidf_feature_names, 58 donor_profiles[mydonor1].flatten().tolist()), 59 key=lambda x: -x[1])[:10], 60 columns=[\u0026#39;token\u0026#39;, \u0026#39;relevance\u0026#39;]) 61mydonor2_profile = pd.DataFrame(sorted(zip(tfidf_feature_names, 62 donor_profiles[mydonor2].flatten().tolist()), 63 key=lambda x: -x[1])[:10], 64 columns=[\u0026#39;token\u0026#39;, \u0026#39;relevance\u0026#39;]) 65 66print(\u0026#39;feature of user \u0026#39; + str(mydonor1)) 67print(mydonor1_profile) 68 69print(\u0026#39;feature of user \u0026#39; + str(mydonor2)) 70print(mydonor2_profile) M√£ ngu·ªìn ·ªü tr√™n c≈©ng c√≥ ch√∫ th√≠ch ƒë·∫ßy ƒë·ªß, v√† ƒë·ªçc c≈©ng d·ªÖ hi·ªÉu, n√™n m√¨nh kh√¥ng n√≥i th√™m g√¨ nhi·ªÅu. M√¨nh t√≥m g·ªçn m·ªôt ch√∫t l√† ch√∫ng ta s·∫Ω convert to√†n b·ªô project tittle v√† description v·ªÅ d·∫°ng ch·ªØ th∆∞·ªùng, t√°ch t·ª´ d·ª±a v√†o kho·∫£ng tr·∫Øng, lo·∫°i b·ªè nh·ªØng english stopwords. Sau ƒë√≥ x√¢y d·ª±ng profile cho t·ª´ng donor.\nK·∫øt qu·∫£\n1feature of user 6d5b22d39e68c656071a842732c63a0c 2 token relevance 30 music 0.450057 41 auditorium 0.355256 52 cart 0.272809 63 chair 0.223861 74 equipment 0.211338 85 musicians 0.179244 96 time 0.172908 107 moving 0.137749 118 ohms 0.134065 129 prepare 0.131274 13feature of user 0016b23800f7ea46424b3254f016007a 14 token relevance 150 pollinators 0.670222 161 plants 0.305398 172 module 0.223407 183 pollination 0.211870 194 seeds 0.180609 205 writing 0.166816 216 books 0.137455 227 reading 0.115003 238 weaved 0.111704 249 bees 0.101842 Nh√¨n k·∫øt qu·∫£ tr√™n, ta th·∫•y r·∫±ng donor 1 c√≥ v·∫ª th√≠ch nh·ªØng th·ª© li√™n quan ƒë·∫øn √¢m nh·∫°c (music, auditorim), trong khi ƒë√≥ donor 2 th√≠ch nh·ªØng th·ª© li√™n quan ƒë·∫øn tr·ªìng tr·ªçt (pollinators - th·ª• ph·∫•n, plants - c√¢y c·ªëi)\nb. X√¢y d·ª±ng m√¥ h√¨nh Vi·ªác x√¢y d·ª±ng m√¥ h√¨nh ƒë·∫øn ƒë√¢y l√† kh√° ƒë∆°n gi·∫£n. Ch√∫ng ta ch·ªâ vi·ªác t√≠nh kho·∫£ng c√°ch cosin gi·ªØa vector c·∫ßn d·ª± ƒëo√°n v√† to√†n b·ªô vector c√≥ trong t·∫≠p train r·ªìi show top K prject c√≥ li√™n quan cao nh·∫•t\n1 2 3class ContentBasedRecommender: 4 5 MODEL_NAME = \u0026#39;Content-Based\u0026#39; 6 7 def __init__(self, projects_df=None): 8 self.project_ids = project_ids 9 self.projects_df = projects_df 10 11 def get_model_name(self): 12 return self.MODEL_NAME 13 14 def _get_similar_projects_to_donor_profile(self, donor_id, topn=1000): 15 #Computes the cosine similarity between the donor profile and all project profiles 16 cosine_similarities = cosine_similarity(donor_profiles[donor_id], tfidf_matrix) 17 #Gets the top similar projects 18 similar_indices = cosine_similarities.argsort().flatten()[-topn:] 19 #Sort the similar projects by similarity 20 similar_projects = sorted([(project_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1]) 21 return similar_projects 22 23 def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10, verbose=False): 24 similar_projects = self._get_similar_projects_to_donor_profile(donor_id) 25 #Ignores projects the donor has already donated 26 similar_projects_filtered = list(filter(lambda x: x[0] not in projects_to_ignore, similar_projects)) 27 28 recommendations_df = pd.DataFrame(similar_projects_filtered, columns=[\u0026#39;Project ID\u0026#39;, \u0026#39;recStrength\u0026#39;]).head(topn) 29 30 recommendations_df = recommendations_df.merge(self.projects_df, how = \u0026#39;left\u0026#39;, 31 left_on = \u0026#39;Project ID\u0026#39;, 32 right_on = \u0026#39;Project ID\u0026#39;)[[\u0026#39;recStrength\u0026#39;, \u0026#39;Project ID\u0026#39;, \u0026#39;Project Title\u0026#39;, \u0026#39;Project Essay\u0026#39;]] 33 34 35 return recommendations_df 36 37 38cbr_model = ContentBasedRecommender(projects) 39 40 41print(\u0026#39;recommend for user \u0026#39; + str(mydonor1)) 42print(cbr_model.recommend_projects(mydonor1)) 43 44print(\u0026#39;recommend for user \u0026#39; + str(mydonor2)) 45print(cbr_model.recommend_projects(mydonor2)) K·∫øt qu·∫£\n1recommend for user 6d5b22d39e68c656071a842732c63a0c 2 recStrength ... Project Essay 30 1.000000 ... the music students in our classes perform freq... 41 0.390997 ... i have spent 12 years as an educator rebuildin... 52 0.338676 ... \u0026#34;music is what feelings sound like.\u0026#34; -g. cates... 63 0.331034 ... true music is created not by the teacher but b... 74 0.324355 ... every morning my first grade students come to ... 85 0.322923 ... in today\u0026#39;s fast paced environment, students ne... 96 0.315910 ... \u0026#34;music is a moral law. it gives soul to the u... 107 0.314845 ... i walk in the door so excited to get the stude... 118 0.310103 ... some students have never put their hands on a ... 129 0.297516 ... my students do not have money, but they do hav... 13 14[10 rows x 4 columns] 15recommend for user 0016b23800f7ea46424b3254f016007a 16 recStrength ... Project Essay 170 1.000000 ... my students are creative, curious, and excited... 181 0.211962 ... our school is a title 1 school. 100% of stude... 192 0.189111 ... my students are active and eager learners who ... 203 0.188095 ... being a small rural school we do a lot of trad... 214 0.173520 ... \u0026#34;science is a way of life...science is the pro... 225 0.159015 ... my second grade students love to come to schoo... 236 0.158071 ... i teach 28 fourth graders in a neighborhood sc... 247 0.150389 ... in my classroom we are working hard to become ... 258 0.144724 ... as a teacher in a diverse, low-income, high-po... 269 0.139937 ... have you ever been told you need to read, but ... 27 28[10 rows x 4 columns] M√¨nh d√πng cmd n√™n b·ªã gi·ªõi h·∫°n k·∫øt qu·∫£, c√°c b·∫°n c√≥ th·ªÉ write log v√†o file ho·∫∑c d√πng jupiter ƒë·ªÉ show k·∫øt qu·∫£ r√µ h∆°n.\n·ªû ƒë√¢y, ch√∫ng ta nh·∫≠n th·∫•y r·∫±ng c√°c recommend cho donor 1 th∆∞·ªùng l√† nh·ªØng project li√™n quan t·ªõi √¢m nh·∫°c (nh√¨n t·∫≠p feature ta c≈©ng c√≥ th·ªÉ ƒëo√°n ƒë∆∞·ª£c). V√† recommend cho donor 2 l√† nh·ªØng th·ª© li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ l√†m v∆∞·ªùn v√† reading.\n3. Collaborative Filtering Model L√Ω thuy·∫øt v·ªÅ Collaborative Filtering Model c√°c b·∫°n c√≥ th·ªÉ xem ·ªü c√°c b√†i vi·∫øt kh√°c c·ªßa m√¨nh ho·∫∑c tham kh·∫£o th√™m tr√™n m·∫°ng. ·ªû ƒë√¢y, m√¨nh s·∫Ω s·ª≠ d·ª•ng Singular Value Decomposition (SVD) ƒë·ªÉ x√¢y d·ª±ng ma tr·∫≠n ƒë·∫∑c tr∆∞ng.\na. X√¢y d·ª±ng ma tr·∫≠n donor - project ƒê·∫ßu ti√™n, ch√∫ng ta s·∫Ω x√¢y d·ª±ng ma tr·∫≠n m·ªëi quan h·ªá gi·ªØa donor v√† project. N·∫øu donor i c√≥ donated cho 1 project j th√¨ d√≤ng i c·ªôt j c·ªßa ma tr·∫≠n s·∫Ω ƒë∆∞·ª£c ƒë√°nh d·∫•u l√† 1, ng∆∞·ª£c l·∫°i l√† 0.\n1## create matrix 2#Creating a sparse pivot table with donors in rows and projects in columns 3donors_projects_pivot_matrix_df = donations_full_df.pivot(index=\u0026#39;Donor ID\u0026#39;, 4 columns=\u0026#39;Project ID\u0026#39;, 5 values=\u0026#39;eventStrength\u0026#39;).fillna(0) 6 7# Transform the donor-project dataframe into a matrix 8donors_projects_pivot_matrix = donors_projects_pivot_matrix_df.as_matrix() 9 10# Get donor ids 11donors_ids = list(donors_projects_pivot_matrix_df.index) 12 13print(donors_projects_pivot_matrix[:5]) # print first 5 row 1 2array([[ 0., 0., 0., ..., 0., 0., 0.], 3 [ 0., 0., 0., ..., 0., 0., 0.], 4 [ 0., 0., 0., ..., 0., 0., 0.], 5 [ 0., 0., 0., ..., 0., 0., 0.], 6 [ 0., 0., 0., ..., 0., 0., 0.]]) b. Singular Value Decomposition Sau khi c√≥ ma tr·∫≠n tr√™n, ta c√≥ m·ªôt nh·∫≠n x√©t r·∫±ng n√≥ r·∫•t th∆∞a, s·ªë l∆∞·ª£ng 0 th√¨ nhi·ªÅu m√† 1 th√¨ √≠t. Sau khi √°p d·ª•ng SVD, ma tr·∫≠n k·∫øt qu·∫£ s·∫Ω √≠t th∆∞a h∆°n (c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c ƒë·∫øn m·ª©c kh√¥ng c√≤n th∆∞a n·ªØa).\n1# Performs matrix factorization of the original donor-project matrix 2# Here we set k = 20, which is the number of factors we are going to get 3# In the definition of SVD, an original matrix A is approxmated as a product A ‚âà UŒ£V 4# where U and V have orthonormal columns, and Œ£ is non-negative diagonal. 5U, sigma, Vt = svds(donors_projects_pivot_matrix, k = 20) 6sigma = np.diag(sigma) 7 8# Reconstruct the matrix by multiplying its factors 9all_donor_predicted_ratings = np.dot(np.dot(U, sigma), Vt) 10 11#Converting the reconstructed matrix back to a Pandas dataframe 12cf_preds_df = pd.DataFrame(all_donor_predicted_ratings, 13 columns = donors_projects_pivot_matrix_df.columns, 14 index=donors_ids).transpose() 15 16print(cf_preds_df.head()) 1 0003aba06ccf49f8c44fc2dd3b582411 ... ffff088c35d3455779a30898d1327b76 2Project ID ... 3 4000009891526c0ade7180f8423792063 -3.423182e-34 ...-4.577244e-34 500000ce845c00cbf0686c992fc369df4 -3.061322e-36 ...-6.492305e-36 600002d44003ed46b066607c5455a999a 1.368936e-33 ...-2.239156e-32 700002eb25d60a09c318efbd0797bffb5 1.784576e-33 ...1.163684e-32 80000300773fe015f870914b42528541b 4.314216e-34 ...-4.666110e-34 9 10[5 rows x 8015 columns] c. X√¢y d·ª±ng Collaborative Filtering Model 1 2 3class CFRecommender: 4 5 MODEL_NAME = \u0026#39;Collaborative Filtering\u0026#39; 6 7 def __init__(self, cf_predictions_df, projects_df=None): 8 self.cf_predictions_df = cf_predictions_df 9 self.projects_df = projects_df 10 11 def get_model_name(self): 12 return self.MODEL_NAME 13 14 def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10): 15 # Get and sort the donor\u0026#39;s predictions 16 sorted_donor_predictions = self.cf_predictions_df[donor_id].sort_values(ascending=False) \\ 17 .reset_index().rename(columns={donor_id: \u0026#39;recStrength\u0026#39;}) 18 19 # Recommend the highest predicted projects that the donor hasn\u0026#39;t donated to 20 recommendations_df = sorted_donor_predictions[~sorted_donor_predictions[\u0026#39;Project ID\u0026#39;].isin(projects_to_ignore)] \\ 21 .sort_values(\u0026#39;recStrength\u0026#39;, ascending = False) \\ 22 .head(topn) 23 24 25 recommendations_df = recommendations_df.merge(self.projects_df, how = \u0026#39;left\u0026#39;, 26 left_on = \u0026#39;Project ID\u0026#39;, 27 right_on = \u0026#39;Project ID\u0026#39;)[[\u0026#39;recStrength\u0026#39;, \u0026#39;Project ID\u0026#39;, \u0026#39;Project Title\u0026#39;, \u0026#39;Project Essay\u0026#39;]] 28 29 30 return recommendations_df 31 32cfr_model = CFRecommender(cf_preds_df, projects) 33print(cfr_model.recommend_projects(mydonor1)) 34 35print(cfr_model.recommend_projects(mydonor2)) 1[5 rows x 8015 columns] 2 recStrength ... Project Essay 30 3.015461e-17 ... Our students are some of the hardest working k... 41 2.237275e-17 ... As Service Learning Coordinators at our elemen... 52 2.188501e-17 ... We are trying to engage more students in scien... 63 1.768711e-17 ... We are a brand new charter school that has onl... 74 1.344489e-17 ... Sitting at a desk for a sustained period of ti... 85 9.957278e-18 ... Our students come from a Title I school in Jer... 96 6.932330e-18 ... In my school 50% of the students are socioecon... 107 8.589640e-19 ... Have you ever been told you need to read, but ... 118 6.698040e-19 ... \u0026#34;I cannot say good-bye to those whom I have gr... 129 5.733941e-19 ... I have students in class who are squinting and... 13 14[10 rows x 4 columns] 15 recStrength ... Project Essay 160 3.015461e-17 ... Our students are some of the hardest working k... 171 2.237275e-17 ... As Service Learning Coordinators at our elemen... 182 2.188501e-17 ... We are trying to engage more students in scien... 193 1.768711e-17 ... We are a brand new charter school that has onl... 204 1.344489e-17 ... Sitting at a desk for a sustained period of ti... 215 9.957278e-18 ... Our students come from a Title I school in Jer... 226 6.932330e-18 ... In my school 50% of the students are socioecon... 237 8.589640e-19 ... Have you ever been told you need to read, but ... 248 6.698040e-19 ... \u0026#34;I cannot say good-bye to those whom I have gr... 259 5.733941e-19 ... I have students in class who are squinting and... K·∫øt qu·∫£ tr·∫£ v·ªÅ c√≥ v·∫ª kh√¥ng ƒë∆∞·ª£c ƒë·∫πp nh∆∞ ·ªü ph∆∞∆°ng ph√°p tr√™n. ·ªû ƒë√¢y, thu·∫≠t to√°n d·ª±a v√†o h√†nh vi donated c·ªßa nh·ªØng ng∆∞·ªùi kh√°c c√≥ ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng v·ªõi user donor 1 v√† 2. B·ªüi v·∫≠y g·ª£i √Ω nh·ªØng project s·∫Ω kh√°c nh·ªØng g·ª£i √Ω ·ªü ph∆∞∆°ng ph√°p 1.\n4. Hybrid Method Ph∆∞∆°ng ph√°p lai n√†y k·∫øt h·ª£p c·∫£ 2 h∆∞·ªõng ti·∫øp c·∫≠n c·ªßa hai ph∆∞∆°ng ph√°p ·ªü tr√™n. ·ªû ƒë√¢y, ch√∫ng ta s·∫Ω x√¢y d·ª±ng m·ªôt m√¥ h√¨nh nh·ªè, nh√¢n ƒëi·ªÉm c·ªßa content based v√† collaborative filtering l·∫°i v·ªõi nhau, sau ƒë√≥ x·∫øp h·∫°ng ƒë·ªÉ ƒë∆∞·ª£c ƒëi·ªÉm hybrid. ƒê√¢y l√† 1 c√°ch ƒë∆°n gi·∫£n, c√°c b·∫°n c√≥ th·ªÉ t√¨m ƒë·ªçc nhi·ªÅu c√°ch ti·∫øp c·∫≠n kh√°c v√† ·ª©ng d·ª•ng v√†o b√†i to√°n.\n1class HybridRecommender: 2 3 MODEL_NAME = \u0026#39;Hybrid\u0026#39; 4 5 def __init__(self, cb_rec_model, cf_rec_model, projects_df): 6 self.cb_rec_model = cb_rec_model 7 self.cf_rec_model = cf_rec_model 8 self.projects_df = projects_df 9 10 def get_model_name(self): 11 return self.MODEL_NAME 12 13 def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10): 14 #Getting the top-1000 Content-based filtering recommendations 15 cb_recs_df = self.cb_rec_model.recommend_projects(donor_id, projects_to_ignore=projects_to_ignore, 16 topn=1000).rename(columns={\u0026#39;recStrength\u0026#39;: \u0026#39;recStrengthCB\u0026#39;}) 17 18 #Getting the top-1000 Collaborative filtering recommendations 19 cf_recs_df = self.cf_rec_model.recommend_projects(donor_id, projects_to_ignore=projects_to_ignore, 20 topn=1000).rename(columns={\u0026#39;recStrength\u0026#39;: \u0026#39;recStrengthCF\u0026#39;}) 21 22 #Combining the results by Project ID 23 recs_df = cb_recs_df.merge(cf_recs_df, 24 how = \u0026#39;inner\u0026#39;, 25 left_on = \u0026#39;Project ID\u0026#39;, 26 right_on = \u0026#39;Project ID\u0026#39;) 27 28 #Computing a hybrid recommendation score based on CF and CB scores 29 recs_df[\u0026#39;recStrengthHybrid\u0026#39;] = recs_df[\u0026#39;recStrengthCB\u0026#39;] * recs_df[\u0026#39;recStrengthCF\u0026#39;] 30 31 #Sorting recommendations by hybrid score 32 recommendations_df = recs_df.sort_values(\u0026#39;recStrengthHybrid\u0026#39;, ascending=False).head(topn) 33 34 recommendations_df = recommendations_df.merge(self.projects_df, how = \u0026#39;left\u0026#39;, 35 left_on = \u0026#39;Project ID\u0026#39;, 36 right_on = \u0026#39;Project ID\u0026#39;)[[\u0026#39;recStrengthHybrid\u0026#39;, 37 \u0026#39;Project ID\u0026#39;, \u0026#39;Project Title\u0026#39;, 38 \u0026#39;Project Essay\u0026#39;]] 39 40 41 return recommendations_df 42 43hybrid_model = HybridRecommender(cbr_model, cfr_model, projects) 44 45 46print(hybrid_model.recommend_projects(mydonor1)) 47 48print(hybrid_model.recommend_projects(mydonor2)) 1 recStrengthHybrid ... Project Essay 20 1.574375e-18 ... we are trying to engage more students in scien... 31 1.221807e-18 ... in my school 50% of the students are socioecon... 42 1.214293e-18 ... our students are some of the hardest working k... 53 4.037232e-19 ... sitting at a desk for a sustained period of ti... 64 6.661794e-20 ... ‚Äúmusic expresses that which cannot be put into... 75 4.872264e-20 ... i walk in the door so excited to get the stude... 86 4.410098e-20 ... i have spent 12 years as an educator rebuildin... 97 2.907349e-20 ... \u0026#34;music is what feelings sound like.\u0026#34; -g. cates... 108 2.121616e-20 ... \u0026#34;i cannot say good-bye to those whom i have gr... 119 1.353927e-20 ... our band program is one of the largest in our ... 12 13[10 rows x 4 columns] 14 recStrengthHybrid ... Project Essay 150 2.811124e-18 ... in this modern, digital age, i would like to u... 161 1.249967e-18 ... we are a brand new charter school that has onl... 172 6.055628e-19 ... my students are african american and hispanic.... 183 5.912367e-19 ... the a. community and its students are a very s... 194 2.541749e-19 ... do you want to go on an adventure and learn ab... 205 2.494812e-19 ... the average day in my class involves students ... 216 2.323313e-19 ... i teach ela (reading component) to self-contai... 227 1.271629e-19 ... hi there! do you want to help to instill a lif... 238 1.044990e-19 ... having writing utensils is essential for stude... 249 1.004780e-19 ... there\u0026#39;s no such thing as a kid who hates readi... 25 26[10 rows x 4 columns] K·∫øt qu·∫£ tr·∫£ ra t·ªët h∆°n nhi·ªÅu so v·ªõi c√°ch 2, donor1 c√≥ music, donor2 c√≥ c√¢y tr·ªìng v√† s√°ch.\n5. ƒê√°nh gi√° m√¥ h√¨nh C√≥ r·∫•t nhi·ªÅu c√°ch kh√°c nhau ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh recommend system. M·ªôt trong c√°c c√°ch m√¨nh s·ª≠ d·ª•ng ·ªü ƒë√¢y l√† s·ª≠ d·ª•ng ƒë·ªô ƒëo top K accuracy. ƒê·ªô ƒëo n√†y ƒë∆∞·ª£c t√≠nh nh∆∞ sau:\nV·ªõi m·ªói user: V·ªõi m·ªói item user ƒë√£ pick trong test set L·∫•y m·∫´u 1000 item kh√°c m√† ng∆∞·ªùi d√πng ch∆∞a bao gi·ªù pick\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo. C·ªë l√™n.\n","date":"Dec 11, 2018","img":"","permalink":"/blog/2019-01-03-donor-project-matching-with-recommender-systems/","series":null,"tags":["Machine learning","Deeplearning","recommender system"],"title":"H·ªá Th·ªëng G·ª£i √ù Kho√° H·ªçc Cho Website DonorChoose.org"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu Ki·ªÉm tra d·ªØ li·ªáu L·ªùi m·ªü ƒë·∫ßu Vi·ªác hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh neural network kh√° ƒë∆°n gi·∫£n, ch·ªâ vi·ªác download code m·∫´u v·ªÅ, quƒÉng t·∫≠p data c·ªßa m√¨nh v√†o, r·ªìi cho ch·∫°y, xong. Nh∆∞ng kh√≥ khƒÉn ·ªü ƒë√¢y l√† l√†m c√°ch n√†o ƒë·ªÉ n√¢ng ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh l√™n. ·ªû b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu m·ªôt s·ªë c√°ch gi√∫p tƒÉng ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh.\nKi·ªÉm tra d·ªØ li·ªáu Th·ª±c ch·∫•t, ch√∫ng ta ph·∫£i hi·ªÉu r√µ k·ªπ ch√∫ng ta ƒëang c√≥ nh·ªØng g√¨ trong tay, th√¨ ch√∫ng ta m·ªõi d·∫°y cho m√°y h·ªçc ƒë·ªß v√† ƒë√∫ng ƒë∆∞·ª£c. C√°c b·∫°n h√£y ki·ªÉm tra th·∫≠t k·ªπ ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng t·∫≠p nh√£n ƒë∆∞·ª£c g√°n ch√≠nh x√°c, bouding box c·ªßa ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c v·∫Ω kh√¥ng qu√° d∆∞ th·ª´a, kh√¥ng c√≥ missing value, v.v. M·ªôt v√≠ d·ª• nh·ªè l√† t·∫≠p MNIST, c√≥ nhi·ªÅu h√¨nh b·ªã nh·∫≠p nh·∫±ng gi·ªØa nh·ªØng con s·ªë, ch√∫ng ta kh√¥ng th·ªÉ ph√¢n bi·ªát ƒë∆∞·ª£c ch√≠nh x√°c h√¨nh ƒë√≥ l√† con s·ªë n√†o b·∫±ng m·∫Øt th∆∞·ªùng.\nTi·∫øp theo, c√°c b·∫°n h√£y quy·∫øt ƒë·ªãnh xem r·∫±ng m√¨nh c√≥ n√™n s·ª≠ d·ª•ng c√°c pre-train model hay kh√¥ng.\nN·∫øu t·∫≠p d·ªØ li·ªáu c·ªßa b·∫°n g·∫ßn gi·ªëng v·ªõi t·∫≠p d·ªØ li·ªáu ImageNet, h√£y d√πng pre-train model. C√≥ c√°c m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán s·∫µn l√† VGG net, ResNet, DenseNet, Xception. V·ªõi c√°c ki·∫øn tr√∫c kh√°c nhau nh∆∞ VGG(16 v√† 19 layer), ResNet (50, 101, 152 layer), DenseNet(201,169,121 layer). Ban ƒë·∫ßu, ƒë·ª´ng s·ª≠ d·ª•ng c√°c ki·∫øn tr√∫c c√≥ s·ªë l∆∞·ª£ng nhi·ªÅu (ResNet152, DenseNet201) b·ªüi v√¨ n√≥ r·∫•t t·ªën chi ph√≠ t√≠nh to√°n. Ch√∫ng ta n√™n b·∫Øt ƒë·∫ßu b·ªüi c√°c m√¥ h√¨nh nh·ªè nh∆∞ VGG16, ResNet50. H√£y ch·ªçn m·ªôt m√¥ h√¨nh m√† b·∫°n nghƒ© l√† s·∫Ω c√≥ k·∫øt qu·∫£ t·ªët. Sau khi hu·∫•n luy·ªán, n·∫øu k·∫øt qu·∫£ kh√¥ng ƒë∆∞·ª£c nh∆∞ √Ω mu·ªën, h√£y tƒÉng s·ªë l·ªõp l√™n (v√≠ d·ª• ban ƒë·∫ßu ch·ªçn Resnet50, sau ƒë√≥ n√¢ng l√™n Resnet101, \u0026hellip;).\nN·∫øu b·∫°n c√≥ √≠t d·ªØ li·ªáu, b·∫°n n√£y \u0026ldquo;ƒë√≥ng bƒÉng\u0026rdquo; l·∫°i tr·ªçng s·ªë c·ªßa pre-train model, ch·ªâ hu·∫•n luy·ªán ph·∫ßn ph√¢n l·ªõp. B·∫°n c≈©ng c√≥ th·ªÉ th√™m ph·∫ßn Dropout ƒë·ªÉ tr√°nh overfit.\nN·∫øu t·∫≠p d·ªØ li·ªáu c·ªßa b·∫°n kh√¥ng gi·ªëng m·ªôt t√≠ n√†o so v·ªõi taapk ImageNet, kh√¥ng n√™n d√πng pre-train model.\nLu√¥n lu√¥n s·ª≠ d·ª•ng l·ªõp chu·∫©n ho√° trong m√¥ h√¨nh. N·∫øu b·∫°n hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi batch-size l·ªõn ( v√≠ d·ª• l·ªõn h∆°n 10), h√£y s·ª≠ d·ª•ng BatchNormalization Layer trong keras. N·∫øu b·∫°n s·ª≠ d·ª•ng batch-size nh·ªè (v√≠ d·ª• 1), th√¨ h√£y s·ª≠ d·ª•ng InstanceNormalization. Hai layer n√†y ƒë√£ c√≥ s·∫µn trong Keras, trong c√°c framework kh√°c th√¨ m√¨nh kh√¥ng r√µ l·∫Øm. C√≥ nhi·ªÅu t√°c gi·∫£ ƒë√£ ch·ªâ ra r·∫±ng s·ª≠ d·ª•ng BatchNormalization s·∫Ω cho k·∫øt qu·∫£ t·ªët h∆°n n·∫øu tƒÉng batch-size v√† hi·ªáu nƒÉng s·∫Ω gi·∫£m khi batch-size nh·ªè, v√† trong tr∆∞·ªùng h·ª£p batch-size nh·ªè th√¨ k·∫øt qu·∫£ s·∫Ω t·ªët h∆°n m·ªôt t√≠ khi s·ª≠ d·ª•ng InstanceNormalization thay cho BatchNormalization. Ngo√†i ra, c√°c b·∫°n c≈©ng c√≥ th·ªÉ s·ª≠ d·ª•ng GroupNormalization (m√¨nh ch∆∞a ki·ªÉm ch·ª©ng GroupNormalization c√≥ l√†m tƒÉng ƒë·ªô ch√≠nh x√°c hay kh√¥ng).\nN·∫øu b·∫°n s·ª≠ d·ª•ng concatenation layer ƒë·ªÉ k·∫øt h·ª£p c√°c feature t·ª´ nhi·ªÅu convolution layers (Li), v√† nh·ªØng Li tr√™n r√∫t tr√≠ch th√¥ng tin t·ª´ c√πng m·ªôt input (F), th√¨ b·∫°n jay s·ª≠ d·ª•ng SpatialDropout ngay sau concatenation layer tr√™n (Xem h√¨nh b√™n d∆∞·ªõi). Khi c√°c convolution layer r√∫t tr√≠ch th√¥ng tin t·ª´ c√πng m·ªôt ngu·ªìn, c√°c ƒë·∫∑c tr∆∞ng c·ªßa ch√∫ng th∆∞·ªùng s·∫Ω c√≥ m·ª©c t∆∞∆°ng quan v·ªõi nhau r·∫•t l·ªõn. SpatialDropout s·∫Ω lo·∫°i b·ªè nh·ªØng ƒë·∫∑c tr∆∞ng c√≥ m·ª©c ƒë·ªô li√™n quan cao n√†y v√† gi√∫p b·∫°n ch·ªëng l·∫°i hi·ªán t∆∞·ª£ng overfiting. Th√¥ng th∆∞·ªùng ng∆∞·ªùi ta ch·ªâ s·ª≠ d·ª•ng SpatialDropout ·ªü c√°c l·ªõp g·∫ßn input layer, v√† kh√¥ng s·ª≠ d·ª•ng ch√∫ng ·ªü c√°c l·ªõp cao b√™n tr√™n.\nTheo andrej Karpathy, ƒë·ªÉ x√°c ƒë·ªãnh kh·∫£ nƒÉng l∆∞u tr·ªØ th√¥ng tin c·ªßa m√¥ h√¨nh, h√£y r√∫t m·ªôt ph·∫ßn nh·ªè d·ªØ li·ªáu trong t·∫≠p train c·ªßa b·∫°n ƒëem ƒëi hu·∫•n luy·ªán. N·∫øu m√¥ h√¨nh kh√¥ng overfit, ch√∫ng ta tƒÉng s·ªë l∆∞·ª£ng node/layer l√™n. N·∫øu m√¥ h√¨nh b·ªã overfit, s·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t nh∆∞ L1, L2, Dropout hoƒÉc c√°c k·ªπ thu·∫≠t kh√°c ƒë·ªÉ ch·ªëng l·∫°i vi·ªác overfit.\nC√°c k·ªπ thu·∫≠t chu·∫©n ho√° th∆∞·ªùng s·∫Ω r√†ng bu·ªôc ho·∫∑c tinh g·ªçn c√°c tr·ªçng s·ªë c·ªßa m√¥ h√¨nh. N√≥ c≈©ng ƒë·ªìng th·ªùi gi√∫p ch√∫ng ta ch·ªëng l·∫°i vi·ªác gradient explosion (gradient mang gi√° tr·ªã l·ªõn khi t√≠nh backpropagation) (l√Ω do l√† c√°c tr·ªçng s·ªë s·∫Ω b·ªã gi·ªõi h·∫°n trong ƒëo·∫°n n√†o ƒë√≥, v√≠ d·ª• L2 gi·ªõi h·∫°n cƒÉn b·∫≠c 2 t·ªïng b√¨nh ph∆∞∆°ng c√°c tr·ªçng s·ªë =1 ch·∫≥ng h·∫°n). V√≠ d·ª• d∆∞·ªõi s·ª≠ d·ª•ng kares v√† gi·ªõi h·∫°n max c·ªßa L2 l√† 2.\n1from keras.constraints import max_norm 2# add to Dense layers 3model.add(Dense(64, kernel_constraint=max_norm(2.))) 4# or add to Conv layers 5model.add(Conv2D(64, kernel_constraint=max_norm(2.))) Vi·ªác s·ª≠ d·ª•ng mean subtraction ƒë√¥i khi cho k·∫øt qu·∫£ kh√° t·ªá, ƒë·∫∑c bi·ªát l√† khi s·ª≠ d·ª•ng trong ·∫£nh x√°m (grayscale image), ho·∫∑c c√°c b√†i to√°n ph√¢n ƒëo·∫°n ·∫£nh.\nLu√¥n nh·ªõ ƒë·∫øn vi·ªác x√°o tr·ªôn d·ªØ li·ªáu (n·∫øu b·∫°n c√≥ th·ªÉ). N·∫øu ƒë∆∞·ª£c, h√£y th·ª±c hi·ªán x√°o tr·ªôn d·ªØ li·ªáu trong qu√° tr√¨nh hu·∫•n luy·ªán. Vi·ªác x√°o tr·ªôn ·∫£nh s·∫Ω gi√∫p b·∫°n c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c.\nN·∫øu b√†i to√°n c·ªßa b·∫°n thu·ªôc nh√≥m dense prediction (v√≠ d·ª• ph√¢n ƒëo·∫°n ng·ªØ nghƒ©a - semantic segmentation). H√£y s·ª≠ d·ª•ng pre-train model l√† Dilated Residual Networks. M√¥ h√¨nh tr√™n c·ª±c k·ª≥ hi·ªáu qu·∫£ cho b√†i to√°n n√†y.\nƒê·ªÉ x√°c ƒë·ªãnh th√¥ng tin ng·ªØ c·∫£nh xung quanh c√°c ƒë·ªëi t∆∞·ª£ng, h√£y s·ª≠ d·ª•ng module multi-scale feature pooling. Module n√†y s·∫Ω gi√∫p b·∫°n tƒÉng ƒë·ªô ch√≠nh x√°c v√† th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong b√†i to√°n ph√¢n ƒëo·∫°n ng·ªØ nghƒ©a (semantic segmentation) ho·∫∑c b√†i to√°n ph√¢n ƒëo·∫°n n·ªÅn (foreground segmentation).\nKhi b·∫°n t√≠nh ƒë·ªô l·ªói ho·∫∑c ƒë·ªô ch√≠nh x√°c, n·∫øu c√≥ v√πng n√†o kh√¥ng tr·∫£ v·ªÅ nh√£n, ho·∫∑c nh√£n tr·∫£ v·ªÅ kh√¥ng ch·∫Øc ch·∫Øn, h√£y b·ªè qua vi·ªác t√≠nh to√°n ch√∫ng ƒëi. H√†nh ƒë·ªông n√†y s·∫Ω gi√∫p m√¥ h√¨nh c·ªßa b·∫°n ch·∫Øc ch·∫Øn h∆°n khi ƒë∆∞a ra quy·∫øt ƒë·ªãnh.\nS·ª≠ d·ª•ng tr·ªçng s·ªë cho t·ª´ng class trong qu√° tr√¨nh training n·∫øu d·ªØ li·ªáu c·ªßa b·∫°n c√≥ t√≠nh b·∫•t c√¢n b·∫±ng cao. H√£y ƒë·∫∑t tr·ªçng s·ªë l·ªõn cho nh·ªØng l·ªõp c√≥ √≠t d·ªØ li·ªáu, v√† tr·ªçng s·ªë nh·ªè cho nh·ªØng l·ªõp c√≥ nhi·ªÅu d·ªØ li·ªáu. Tr·ªçng s·ªë c·ªßa c√°c l·ªõp c√≥ th·ªÉ ƒë∆∞·ª£c t√≠nh to√°n m·ªôt c√°ch d·ªÖ d√†ng b·∫±ng c√°c s·ª≠ d·ª•ng th∆∞ vi·ªán skearn trong python. Ngo√†i ra, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t nh∆∞ OverSampling ho·∫∑c UnderSampling ƒë·ªëi v·ªõi t·∫≠p d·ªØ li·ªáu nh·ªè.\nCh·ªçn ƒë√∫ng h√†m t·ªëi ∆∞u. C√≥ r·∫•t nhi·ªÅu h√†m t·ªëi ∆∞u nh∆∞ Adam, Adagrad, Adadellta, RMSprop, \u0026hellip; Trong c√°c paper ng∆∞·ªùi ta th∆∞·ªùng s·ª≠ d·ª•ng t·ªï h·ª£p SGD + momentun. C√≥ hai v·∫•n ƒë·ªÅ c·∫ßn ƒë∆∞·ª£c xem x√©t ·ªü ƒë√¢y: M·ªôt l√† n·∫øu b·∫°n mu·ªën m√¥ h√¨nh c√≥ ƒë·ªô h·ªôi t·ª• nhanh, h√£y d√πng Adam ( v√† c√≥ kh·∫£ nƒÉng cao l√† m√¥ h√¨nh s·∫Ω b·ªã k·∫πt ·ªü ƒëi·ªÉm c·ª±c ti·ªÉu c·ª•c b·ªô -\u0026gt; kh√¥ng c√≥ t√≠nh t·ªïng qu√°t ho√° cao). Hai l√† s·ª≠ dujg SGD + momentun ƒë·ªÉ t√¨m c·ª±c ti·ªÉu to√†n c·ª•c, m√¥ h√¨nh n√†y ph·ª• thu·ªôc r·∫•t nhi·ªÅu v√†o gi√° tr·ªã kh·ªüi t·∫°o ban ƒë·∫ßu v√† m√¥ h√¨nh th∆∞·ªùng s·∫Ω h·ªôi t·ª• r·∫•t ch·∫≠m. (Xem h√¨nh b√™n d∆∞·ªõi)\nTh√¥ng th∆∞·ªùng, ch√∫ng ta s·∫Ω ch·ªçn learning-rate l√† (1e-1, 1e-3, 1e-6). N·∫øu b·∫°n s·ª≠ d·ª•ng pre-train model, h√£y s·ª≠ d·ª•ng learning rate nh·ªè h∆°n 1e-3 (v√≠ d·ª• 1e-4). N·∫øu b·∫°n kh√¥ng s·ª≠ d·ª•ng pre-train model, h√£y s·ª≠ d·ª•ng learning-rate l·ªõn h∆°n 1e-3. B·∫°n c√≥ th·ªÉ grid search gi√° tr·ªã learning-rate v√† ch·ªçn ra m√¥ h√¨nh cho k·∫øt qu·∫£ t·ªët nh·∫•t. B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng Learing Rate Schedulers gi·∫£m gi√° tr·ªãn learning rate trong qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh.\nB√™n c·∫°nh vi·ªác s·ª≠ d·ª•ng Learing Rate Schedulers ƒë·ªÉ gi·∫£m gi√° tr·ªã learning rate, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng m·ªôt k·ªπ thu·∫≠t kh√°c ƒë·ªÉ gi·∫£m gi√° tr·ªã learning-rate. V√≠ d·ª• sau 5 epochs, ƒë·ªô l·ªói tr√™n t·∫≠p validation kh√¥ng thay ƒë·ªïi, b·∫°n gi·∫£m learning-rate ƒëi 10 l·∫ßn (vd t·ª´ 1e-3 th√†nh 1e-4). Trong keras, b·∫°n c√≥ th·ªÉ d·ªÖ d√†ng implement c√¥ng th·ª©c tr√™n b·∫±ng vi·ªác s·ª≠ d·ª•ng callbacs ReduceLROnPlateau.\n1reduce = keras.callbacks.ReduceLROnPlateau(monitor=\u0026#39;val_loss\u0026#39;, factor=0.1, patience=5, mode=\u0026#39;auto\u0026#39;) 2early = keras.callbacks.EarlyStopping(monitor=\u0026#39;val_loss\u0026#39;, min_delta=1e-4, patience=10, mode=\u0026#39;auto\u0026#39;) 3model.fit(X, Y, callbacks=[reduce, early]) V√≠ d·ª• tr√™n, ch√∫ng ta s·∫Ω gi·∫£m learning-rate ƒëi 10 l·∫ßn khi ƒë·ªô l·ªói tr√™n t·∫≠p validation kh√¥ng thay ƒë·ªïi qua 5 l·∫ßn l·∫∑p li√™n ti·∫øp, v√† s·∫Ω d·ª´ng vi·ªác hu·∫•n luy·ªán khi ƒë·ªô l·ªói kh√¥ng gi·∫£m qua 10 l·∫ßn l·∫∑p li√™n ti·∫øp.\nN·∫øu b√†i to√°n c·ªßa b·∫°n thu·ªôc nh√≥m dense prediction nh∆∞ ph√¢n ƒëo·∫°n ·∫£nh, ph√¢n ƒëo·∫°n ng·ªØ nghƒ©a, b·∫°n n√™n s·ª≠ d·ª•ng skip connection ƒë·ªÉ ch·ªëng l·∫°i vi·ªác c√°c bi√™n c·ªßa ƒë·ªëi t∆∞·ª£ng ho·∫∑c c√°c th√¥ng tin ƒë·∫∑c tr∆∞ng h·ªØu √≠ch c·ªßa ƒë·ªëi t∆∞·ª£ng b·ªã m·∫•t trong max-pooling ho·∫∑c strided convolution. Skip connection c≈©ng gi√∫p m√¥ h√¨nh h·ªçc features map t·ª´ feature space v√† image space d·ªÖ d√†ng h∆°n, v√† n√≥ c≈©ng gi√∫p cho b·∫°n gi·∫£m b·ªã vanish gradient ( gi√° tr·ªã gradient nh·ªè d·∫ßn v√† g·∫ßn x·∫•p x·ªâ b·∫±ng 0, n√™n tr·ªçng s·ªë kh√¥ng thay ƒë·ªïi nhi·ªÅu, d·∫´n ƒë·∫øn kh√¥ng h·ªôi t·ª•).\nN√™n s·ª≠ d·ª•ng data augmentation, nh∆∞ l√† horizontally flipping, rotating, zoom-croping\u0026hellip; ƒë·ªÉ tƒÉng d·ªØ li·ªáu c·ªßa b·∫°n l√™n. Vi·ªác c√≥ nhi·ªÅu d·ªØ li·ªáu s·∫Ω gi√∫p m√¥ h√¨nh c√≥ m·ª©c t·ªïng qu√°t ho√° cao h∆°n.\nS·ª≠ d·ª•ng Max-pooling tr∆∞·ªõc Relu ƒë·ªÉ gi·∫£m thi·ªÉu m·ª©c ƒë·ªô t√≠nh to√°n thay v√¨ l√†m ng∆∞·ª£c l·∫°i. ch√∫ng ta bi·∫øt r·∫±ng ReLU tr·∫£ ra gi√° tr·ªã c√≥ ng∆∞·ª°ng c·ª±c ti·ªÉu l√† 0 do f(x)=max(0,x), v√† max-pooling t√≠nh max cho c√°c ƒë·∫∑c tr∆∞ng f(x) = max(x1,x2,\u0026hellip;,xi). N·∫øu ta s·ª≠ d·ª•ng Conv \u0026gt; ReLU \u0026gt; Max-pooling, ta s·∫Ω t·ªën i l·∫ßn t√≠nh ReLu, v√† 1 l·∫ßn t√≠nh max. N·∫øu ta s·ª≠ d·ª•ng Conv -\u0026gt; max-pooling \u0026gt; ReLU, ta t·ªën 1 l·∫ßn t√≠nh max, 1 l·∫ßn t√≠nh ReLU.\nN·∫øu c√≥ th·ªÉ, h√£y th·ª≠ s·ª≠ d·ª•ng Depthwise Separable Convolution. N√≥ gi√∫p m√¥ h√¨nh gi·∫£m s·ªë l∆∞·ª£ng tham s·ªë so v·ªõi c√°c convolution kh√°c, ngo√†i ra n√≥ gi√∫p m√¥ h√¨nh ch·∫°y nhanh h∆°n.\nƒêi·ªÅu cu·ªëi c√πng l√† ƒë·ª´ng bao gi·ªù t·ª´ b·ªè. H√£y tin t∆∞·ªüng r·∫±ng b·∫°n c√≥ th·ªÉ l√†m ƒë∆∞·ª£c. N·∫øu b·∫°n v·∫´n kh√¥ng th·ªÉ ƒë·∫°t ƒë∆∞·ª£c ƒë·ªô ch√≠nh x√°c nh∆∞ mong ƒë·ª£i, h√£y ƒëi·ªÅu ch·ªânh l·∫°i c√°c tham s·ªë, ki·∫øn tr√∫c m√¥ h√¨nh, t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán ƒë·∫øn khi b·∫°n ƒë·∫°t ƒë∆∞·ª£c m√¥ h√¨nh v·ªõi ƒë·ªô ch√≠nh x√°c nh∆∞ b·∫°n ƒë·ªÅ ra.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo. C·ªë l√™n.\n","date":"Dec 11, 2018","img":"","permalink":"/blog/2018-12-11-a-bunch-of-tips-and-tricks-for-training-deep-neural-networks/","series":null,"tags":["Machine learning","Deeplearning","object detector","single shot"],"title":"M·ªôt S·ªë M·∫πo ƒê·ªÉ L·ª±a Ch·ªçn M√¥ H√¨nh Object Detection"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu Box encoding v√† loss function Feature extraction Feature extractor accuracy Non-max suppression (nms) Data augmentation Feature map strides Speed v.s. accuracy Object size Input image resolution Number of proposals ƒêi·ªÉm danh danh l·∫°i c√°c b∆∞·ªõc ph√°t tri·ªÉn c·ªßa object detection Lesson learned L·ªùi m·ªü ƒë·∫ßu C√°c thu·∫≠t to√°n ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng, nh∆∞ c√°c thu·∫≠t to√°n thu·ªôc nh√≥m region proposal ho·∫∑c single shot ƒë·∫ßu b·∫Øt ƒë·∫ßu b·ªüi nh·ªØng √Ω t∆∞·ªüng kh√°c nhau, nh∆∞ng sau qua m·ªôt v√†i qu√° tr√¨nh c·∫≠p nh·∫≠t v√† n√¢ng c·∫•p cho ƒë·∫øn th·ªùi ƒëi·ªÉm hi·ªán t·∫°i, m√¥ h√¨nh chung c·ªßa ch√∫ng ƒë√£ g·∫ßn g·∫ßn gi·ªëng nhau h∆°n. V√† hai thu·∫≠t to√°n tr√™n l√† hai thu·∫≠t to√°n ti√™u bi·ªÉu c·∫°nh tranh nhau danh hi·ªáu thu·∫≠t to√°n ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng nhanh nh·∫•t v√† thu·∫≠t to√°n nh·∫≠n di·ªán ch√≠nh x√°c nh·∫•t. Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω ƒë·ªÅ c·∫≠p ƒë·∫øn m·ªôt s·ªë chi·∫øn l∆∞·ª£c l·ª±a ch·ªçn m√¥ h√¨nh cho b√†i to√°n object detector v√† m·ªôt s·ªë benchmarks do team Google Research th·ª±c hi·ªán.\nBox encoding v√† loss function C√≥ r·∫•t nhi·ªÅu h√†m l·ªói v√† box encoding ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c thu·∫≠t to√°n ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng. V√≠ d·ª•, SSD tr·∫£ ra cƒÉn b·∫≠c hai c·ªßa Width v√† height ƒë·ªÉ gi·∫£m t·ª∑ l·ªá ƒë·ªô l·ªói.\nC√°c b·∫°n c√≥ th·ªÉ ƒë·ªÉ √Ω k·ªπ h∆°n SSD phi√™n b·∫£n custom kh√¥ng s·ª≠ d·ª•ng c·∫∑p to·∫° ƒë·ªô tr√°i tr√™n - ph·∫£i d∆∞·ªõi m√† l√† c·∫∑p t√¢m - cƒÉn b·∫≠c hai c·ªßa with, cƒÉn b·∫≠c hai c·ªßa height. M·ªôt s·ªë thu·∫≠t to√°n l·∫°i d√πng log width, log height, m·ªôt s·ªë l·∫°i d√πng t√¢m l√† Wc/Wa, Wy/ha, v·ªõi Wc v√† Wy l√† to·∫° ƒë·ªô t√¢m c·ªßa ƒë·ªëi t∆∞·ª£ng, wa v√† ha l√† chi·ªÅu d√†i v√† r·ªông c·ªßa anchor kh·ªõp nh·∫•t (matching anchor). C√°c b·∫°n c√≥ th·ªÉ tham kh·∫£o th√™m ·ªü https://arxiv.org/pdf/1611.10012.pdf.\nƒê·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh t·ªët h∆°n, C√°c nh√† nghi√™n c·ª©u s·ª≠ d·ª•ng c√°c tr·ªçng s·ªë kh√°c nhau cho c√°c h√†m l·ªói, YOLO v√† m·ªôt v√≠ d·ª• minh ho·∫°.\nFeature extraction Trong th·ª±c t·∫ø, Feature extraction ·∫£nh h∆∞·ªüng l·ªõn tr√™n 2 ph·∫ßn tradeoff l√† ƒë·ªô ch√≠nh x√°c v√† t·ªëc ƒë·ªô. Nh√≥m thu·∫≠t to√°n ResNet v√† Inception ƒëi theo ti√™u ch√≠ l√† ƒë·ªô ch√≠nh x√°c quan tr·ªçng h∆°n t·ªëc ƒë·ªô (v√† qu·∫£ th·∫≠t nh√≥m thu·∫≠t to√°n thu·ªôc h·ªç n√†y c√≥ ƒë·ªô ch√≠nh x√°c kh√° cao). MobileNet cung c·∫•p cho ch√∫ng ta m·ªôt m√¥ h√¨nh kh√° nh·ªè g·ªçn, s·ª≠ d·ª•ng SSD, m·ª•c ti√™u c·ªßa nh√≥m n√†y l√† c√≥ th·ªÉ x·ª≠ l√Ω ƒë∆∞·ª£c tr√™n c√°c thi·∫øt b·ªã di ƒë·ªông v√† th·ªùi gian x·ª≠ l√Ω l√† realtime.\nFeature extractor accuracy Nh√¨n v√†o h√¨nh tr√™n, ch√∫ng ta c√≥ th·ªÉ th·∫•y r√µ r√†ng r·∫±ng Faster R-CNN v√† R-FCN ƒë·ªÅu cho ƒë·ªô ch√≠nh x√°c kh√° t·ªët tr√™n feature extraction. Ng∆∞·ª£c l·∫°i SSD c√≥ k·∫øt qu·∫£ kh√° t·ªá.\nNon-max suppression (nms) Sau khi thu ƒë∆∞·ª£c v·ªã tr√≠ c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng, ch√∫ng ta s·∫Ω merge l·∫°i c√°c v·ªã tr√≠ b·ªã ph√°t hi·ªán tr√πng l·∫Øp. C√°c thu·∫≠t to√°n thu·ªôc nh√≥m single shot th∆∞·ªùng cho ra output overlap kh√° nhi·ªÅu.\nData augmentation Ng√†y nay, h·∫ßu h·∫øt c√°c thu·∫≠t to√°n ƒë·ªÅu s·ª≠ d·ª•ng Data augmentation. Vi·ªác augment data b·∫±ng c√°ch c·∫Øt x√©t ·∫£nh, quay ·∫£nh m·ªôt g√≥c ng·∫´u nhi√™n n√†o ƒë√≥, gi√∫p cho tr√°nh ƒë∆∞·ª£c overfit trong qu√° tr√¨nh hu·∫•n luy·ªán, do ƒë√≥ gi√°n ti·∫øp tƒÉng ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh.\nFeature map strides Thu·∫≠t to√°n thu·ªôc nh√≥m single shot th∆∞·ªùng c√≥ tu·ª≥ ch·ªçn layter feature map n√†o ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng. Feature map c√≥ stride l√† 2 n·∫øu ch√∫ng ta th·ª±c hi·ªán gi·∫£m 2 l·∫ßn ƒë·ªô ph√¢n gi·∫£i. Feature map c√≥ ƒë·ªô ph√¢n gi·∫£i th·∫•p th∆∞·ªùng gi·ªØ l·∫°i nh·ªØng th√¥ng tin ƒë·∫∑c tr∆∞ng t·ªët c·ªßa ƒë·ªëi t∆∞·ª£ng v√† gi√∫p cho detector th·ª±c hi·ªán t·ªët h∆°n. Tuy nhi√™n, nh·ªØng ƒë·ªëi t∆∞·ª£ng c√≥ k√≠nh th∆∞·ªõc nh·ªè s·∫Ω b·ªã m·∫•t th√¥ng tin tr·∫ßm tr·ªçng v√† kh√≥ ƒë·ªÉ ph√°t hi·ªán ra ch√∫ng.\nSpeed v.s. accuracy Th·∫≠t kh√≥ ƒë·ªÉ tr·∫£ l·ªùi r·∫±ng thu·∫≠t to√°n nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng n√†o t·ªët h∆°n, m√† c√¢u tr·∫£ l·ªùi ph·ª• thu·ªôc v√†o b√†i to√°n c·ªßa b·∫°n ƒëang g·∫∑p. N·∫øu b√†i to√°n c·∫ßn ƒë·ªô ch√≠nh x√°c cao, h√£y s·ª≠ d·ª•ng ResNet ho·∫∑c Inception, n·∫øu b·∫°n c·∫ßn ch·∫°y realtime v√† ƒë·ªô ch√≠nh x√°c t·∫°m ch·∫•p nh·∫≠n, h√£y s·ª≠ d·ª•ng MobileNet ho·∫∑c YOLO. Kh√¥ng c√≥ (ch∆∞a c√≥ - √≠t nh·∫•t ƒë·∫øn th·ªùi ƒëi·ªÉm hi·ªán t·∫°i) c√≥ thu·∫≠t to√°n n√†o ƒë√°p ·ª©ng c·∫£ 2 ti√™u ch√≠ l√† v·ª´a c√≥ ƒë·ªô ch√≠nh x√°c cao, v·ª´a ch·∫°y nhanh c·∫£. ƒê√≥ l√† m·ªôt tradeoff gi·ªØa Speed v√† Accuracy.\nObject size V·ªõi nh·ªØng h√¨nh ·∫£nh c√≥ k√≠ch th∆∞·ªõc l·ªõn, SSD th·ª±c hi·ªán r√∫t tr√≠ch ƒë·∫∑c tr∆∞ng r·∫•t t·ªët (n√™n nh·ªõ r·∫±ng m√¥ h√¨nh r√∫t tr√≠ch ƒë·∫∑c tr∆∞ng c·ªßa SSD r·∫•t ƒë∆°n gi·∫£n). V·ªõi nh·ªØng h√¨nh ·∫£nh d·∫°ng n√†y, SSD c√≥ th·ªÉ so s√°nh v·ªõi c√°c thu·∫≠t to√°n kh√°c kh√°c v·ªÅ ƒë·ªô ch√≠nh x√°c.\nV·ªõi nh∆∞ng h√¨nh ·∫£nh c√≥ k√≠ch th∆∞·ªõc nh·ªè, ch√∫ng ta kh√¥ng n√™n/kh√¥ng bao gi·ªù x√†i SSD.\nNh√¨n h√¨nh ·ªü tr√™n, ch√∫ng ta th·∫•y r√µ ƒë·ªô ch√≠nh x√°c c·ªßa SSD v√† c√°c thu·∫≠t o√°n kh√°c tr√™n c√°c t·∫≠p d·ªØ li·ªáu c√≥ k√≠ch th∆∞·ªõc kh√°c nhau. V√† ph·ª• thu·ªôc v√†o k√≠ch th∆∞·ªõc d·ªØ li·ªáu c·ªßa b·∫°n ƒë·ªÉ ch·ªçn ra m√¥ h√¨nh t·ªëi ∆∞u nh·∫•t.\nInput image resolution Nh√¨n h√¨nh tr√™n c√°c b·∫°n c≈©ng c√≥ th·ªÉ nh√¨n th·∫•y r√µ. ·∫¢nh c√≥ ƒë·ªô ph√¢n gi·∫£i l·ªõn gi√∫p nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng t·ªët h∆°n r·∫•t nhi·ªÅu so v·ªõi ·∫£nh c√≥ ƒë·ªô ph√¢n gi·∫£i nh·ªè. Khi gi·∫£m 2 l·∫ßn ƒë·ªô ph√¢n gi·∫£i tr√™n m·ªói chi·ªÅu (t·ª´ 600x600 xu·ªëng c√≤n 300x300), trung b√¨nh ƒë·ªô ch√≠nh x√°c gi·∫£m 15.88% trong qu√° tr√¨nh hu·∫•n luy·ªán, v√† trung b√¨nh gi·∫£m 27.4% trong inference.\nNumber of proposals S·ªë l∆∞·ª£ng proposal ƒë∆∞·ª£c sinh ra ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn t·ªëc ƒë·ªô c·ªßa nh√≥m R-CNN. V√≠ d·ª•, Faster R-CNN c√≥ th·ªÉ tƒÉng t·ªëc ƒë·ªô nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng g·∫•p 3 l·∫ßn n·∫øu ta ch·ªâ s·ª≠ d·ª•ng 50 proposal thay v√¨ 300 proposal. ƒê·ªô ch√≠nh x√°c ch·ªâ gi·∫£m 4%\nH√¨nh tr√™n, ƒë∆∞·ªùng n√©t li·ªÅn m√¥ t·∫£ ƒë·ªô ch√≠nh x√°c khi tƒÉng s·ªë l∆∞·ª£ng proposal. ƒê∆∞·ªùng n√©t ƒë·ª©t th·ªÉ hi·ªán th·ªùi gian x·ª≠ l√°y tƒÉng khi tƒÉng s·ªë l∆∞·ª£ng proposal.\nƒêi·ªÉm danh danh l·∫°i c√°c b∆∞·ªõc ph√°t tri·ªÉn c·ªßa object detection C√°c thu·∫≠t to√°n object detection ƒë√£ ph√°t tri·ªÉn trong m·ªôt kho·∫£ng th·ªùi gian d√†i. √ù t∆∞·ªüng ƒë·∫ßu ti√™n, ƒë∆°n gi·∫£n nh·∫•t l√† ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng c·ª≠a s·ªï tr∆∞·ª£t.\n1 2# Sliding windows 3for window in windows 4 patch = get_patch(image, window) 5 results = detector(patch) ƒê·ªÉ tƒÉng t·ªëc, ch√∫ng ta s·∫Ω\nGi·∫£m s·ªë l∆∞·ª£ng windows (R-CNN gi·∫£m c√≤n kho·∫£ng 2000) Gi·∫£m c√°c ph√©p t√≠nh trong vi·ªác t√¨m ROI (Fast R-CNN s·ª≠ d·ª•ng feature map thay v√¨ to√†n b·ªô image patchs). 1# Fast R-CNN 2feature_maps = process(image) 3ROIs = region_proposal(feature_maps) 4for ROI in ROIs 5 patch = roi_pooling(feature_maps, ROI) 6 results = detector2(patch) Vi·ªác t√¨m region_proposal c≈©ng t·ªën kh√° nhi·ªÅu th·ªùi gian. Faster R-CNN s·ª≠ d·ª•ng m·ªôt convolution network thay th·∫ø cho region proposal ·ªü b∆∞·ªõc n√†y (l√†m gi·∫£m th·ªùi gian t·ª´ 2.3s xu·ªëng c√≤n 0.3 gi√¢y). Faster R-CNN c≈©ng gi·ªõi thi·ªáu 1 kh√°i nhi·ªám l√† anchor gi√∫p c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c v√† vi·ªác hu·∫•n luy·ªán tr·ªü n√™n d·ªÖ d√†ng h∆°n.\nR-FCN ƒë∆∞a ra m·ªôt ƒëi·ªÅu ch·ªânh nh·ªè, l√† ti·∫øn h√†nh t√¨m position v√† sensitive score map tr√™n m·ªói ROIS ƒë·ªôc l·∫≠p. V√† t√≠nh trung b√¨nh x√°c su·∫•t xu·∫•t hi·ªán ƒë·ªëi t∆∞·ª£ng\n1# R-FCN 2feature_maps = process(image) 3ROIs = region_proposal(feature_maps) 4score_maps = compute_score_map(feature_maps) 5for ROI in ROIs 6 V = pool(score_maps, ROI) 7 class_scores = average(V) 8 class_probabilities = softmax(class_scores) R-FCN ch·∫°y kh√° nhanh, nh∆∞ng ƒë·ªô ch√≠nh x√°c th√¨ th·∫•p h∆°n m·ªôt h√∫t so v·ªõi Faster R-CNN. ƒê·ªÉ √Ω k·ªπ ƒëo·∫°n m√£ gi·∫£ ·ªü tr√™n, ch√∫ng ta ph·∫£i tr·∫£i qua 2 l·∫ßn t√≠nh to√°n, m·ªôt l·∫ßn l√† t√¨m c√°c ROIs, m·ªôt l·∫ßn l√† object detection. Thu·∫≠t to√°n Single shot detector ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t ƒë·ªÉ s·ª≠ d·ª•ng 1 l·∫ßn t√≠nh to√°n.\n1feature_maps = process(image) 2results = detector3(feature_maps) # No more separate step for ROIs Thu·∫≠t to√°n SSD v√† YOLO ƒë·ªÅu thu·ªôc nh√≥m single shot detectors. C·∫£ hai ƒë·ªÅu s·ª≠ d·ª•ng convolution layer ƒë·ªÉ r√∫t tr√≠ch ƒë·∫∑c tr∆∞ng v√† m·ªôt convolution filter ƒë·ªÉ ƒë∆∞a quy·∫øt ƒë·ªãnh. C·∫£ hai ƒë·ªÅu d√πng feature map c√≥ ƒë·ªô ph√¢n gi·∫£i th·∫•p (low resolution feature map) ƒë·ªÉ d√≤ t√¨m ƒë·ªëi t∆∞·ª£ng =\u0026gt; ch·ªâ ph√°t hi·ªán ƒë∆∞·ª£c c√°c ƒë·ªëi t∆∞·ª£ng c√≥ k√≠ch th∆∞·ªõc l·ªõn. M·ªôt c√°ch ti·∫øp c·∫≠n l√† s·ª≠ d·ª•ng c√°c feature map c√≥ ƒë·ªô ph√¢n gi·∫£i cao (higher resolution feature map). Nh∆∞ng ƒë·ªô ch√≠nh x√°c s·∫Ω gi·∫£m do th√¥ng tin ƒë·∫∑c tr∆∞ng c·ªßa ƒë·ªëi t∆∞·ª£ng qu√° h·ªón lo·∫°n. FPN ƒë∆∞a ra √Ω t∆∞·ªüng s·ª≠ d·ª•ng feature map trung gian merge gi·ªØa feature map high resolution v√† low resolution. Vi·ªác n√†y gi√∫p cho ch√∫ng ta v·∫´n gi·ªØ ƒë∆∞·ª£c th√¥ng tin ƒë·∫∑c tr∆∞ng h·ªØu √≠ch c·ªßa ƒë·ªëi t∆∞·ª£ng, ƒë·ªìng th·ªùi c≈©ng gi·ªØ ƒë∆∞·ª£c th√¥ng tin c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng c√≥ k√≠ch th∆∞·ªõc nh·ªè. Do ƒë√≥, ƒë·ªô ch√≠nh x√°c c≈©ng tƒÉng l√™n v√† ph√°t hi·ªán c√°c ƒë·ªëi t∆∞·ª£ng c√≥ c√°c t·ª∑ l·ªá kh√°c nhau (different scale) t·ªët h∆°n.\nTrong qu√° tr√¨nh hu·∫•n luy·ªán, ch√∫ng ta s·∫Ω nh·∫≠n ra 1 v·∫•n ƒë·ªÅ r·∫±ng backgroup s·∫Ω chi·∫øm 1 ph·∫ßn r·∫•t l·ªõn trong b·ª©c ·∫£nh. Ho·∫∑c m·ªôt ƒë·ªëi t∆∞·ª£ng n√†o ƒë√≥ c√≥ s·ªë m·∫´u nhi·ªÅu h∆°n so v·ªõi c√°c ƒë·ªëi t∆∞·ª£ng kh√°c. Thu·∫≠t to√°n Focal loss ƒë∆∞·ª£c sinh ra ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y.\nLesson learned Feature Pyramid Networks s·ª≠ d·ª•ng c√°c feature map nhi·ªÅu th√¥ng tin h∆°n ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c.\nS·ª≠ d·ª•ng c√°c m√¥ h√¨nh nh∆∞ ResNet ho·∫∑c Inception ResNet n·∫øu m√¥ h√¨nh b·∫°n c·∫ßn ƒë·ªô ch√≠nh x√°c v√† kh√¥ng quan t√¢m l·∫Øm v·ªÅ t·ªëc ƒë·ªô.\nS·ª≠ d·ª•ng c√°c thu·∫≠t to√°n thu·ªôc nh√≥m Single shot detectors nh∆∞ MobileNet n·∫øu b·∫°n c·∫ßn t·ªëc ƒë·ªô t√≠nh to√°n v√† c√≥ th·ªÉ ch·∫°y ƒë∆∞·ª£c tr√™n mobilenet, y√™u c·∫ßu v·ªÅ ƒë·ªô ch√≠nh x√°c t·∫°m ch·∫•p nh·∫≠n ƒë∆∞·ª£c.\nS·ª≠ d·ª•ng batch normaliation, n√≥i chung l√† ƒë·ªÅu ph·∫£i chu·∫©n ho√° d·ªØ li·ªáu tr∆∞·ªõc khi s·ª≠ d·ª•ng.\nL·ª±a ch·ªçn anchors c·∫©n th·∫≠n (C√°i n√†y kh√° kh√≥, ƒë√≤i h·ªèi b·∫°n ph·∫£i am hi·ªÉu kh√° k·ªπ v·ªÅ d·ªØ li·ªáu, v√† n·∫øu set nh·∫ßm th√¨ s·∫Ω ƒëi tong).\nS·ª≠ d·ª•ng data augmentation.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\nB√†i vi·∫øt ƒë∆∞·ª£c l∆∞·ª£c d·ªãch v√† tham kh·∫£o t·ª´ ngu·ªìn https://medium.com/@jonathan_hui/design-choices-lessons-learned-and-trends-for-object-detections-4f48b59ec5ff\n","date":"Dec 10, 2018","img":"","permalink":"/blog/2018-12-10-design-choices-lessons-learned-and-trends-for-object-detections/","series":null,"tags":["Machine learning","Deeplearning","object detector","single shot"],"title":"L·ª±a Ch·ªçn M√¥ H√¨nh Object Detectors"},{"categories":null,"content":" Single Shot detectors SSD YOLO YOLOv3 Feature Pyramid Networks (FPN) So s√°nh Feature Pyramid Networks v·ªõi Region Proposal Network S·ª≠ d·ª•ng Feature Pyramid Networks trong Fast R-CNN v√† Faster R-CNN Focal loss (RetinaNet) Single Shot detectors ·ªû b√†i tr∆∞·ªõc, ch√∫ng ta ƒë√£ t√¨m hi·ªÉu v·ªÅ region proposal v√† ·ª©ng d·ª•ng c·ªßa n√≥ v√†o Faster R-CNN. C√°c thu·∫≠t to√°n thu·ªôc nh√≥m region proposal tuy cho k·∫øt qu·∫£ c√≥ ƒë·ªô ch√≠nh x√°c cao, nh∆∞ng ch√∫ng c√≥ m·ªôt nh∆∞·ª£c ƒëi·ªÉm r·∫•t l·ªõn l√† th·ªùi gian hu·∫•n luy·ªán v√† ƒë∆∞a quy·∫øt ƒë·ªãnh r·∫•t ch·∫≠m. Faster R-CNN x·ª≠ l√Ω kho·∫£ng 7 FPS tr√™n t·∫≠p d·ªØ li·ªáu PASCAL VOC 2007. M·ªôt c√°ch ƒë·ªÉ tƒÉng t·ªëc qu√° tr√¨nh t√≠nh to√°n l√† gi·∫£m s·ªë l∆∞·ª£ng t√≠nh to√°n tr√™n m·ªói ROI.\n1feature_maps = process(image) 2ROIs = region_proposal(feature_maps) 3for ROI in ROIs 4 patch = roi_align(feature_maps, ROI) 5 results = detector2(patch) # Gi·∫£m kh·ªëi l∆∞·ª£ng t√≠nh to√°n ·ªü ƒë√¢y M·ªôt √Ω t∆∞·ªüng kh√°c, l√† ch√∫ng ta s·∫Ω b·ªè qua b∆∞·ªõc t√¨m region proposal, m√† tr·ª±c ti·∫øp r√∫t tr√≠ch boundary boxes v√† classes tr·ª±c ti·∫øp t·ª´ feature map.\n1feature_maps = process(image) 2results = detector3(feature_maps) # Kh√¥ng c·∫ßn t√¨m ROI D·ª±a tr√™n √Ω t∆∞·ªüng s·ª≠ d·ª•ng c·ª≠a s·ªï tr∆∞·ª£t. Ch√∫ng ta s·∫Ω tr∆∞·ª£t tr√™n feature m√°p ƒë·ªÉ nh·∫≠n di·ªán c√°c ƒë·ªëi t∆∞·ª£ng. V·ªõi m·ªói lo·∫°i ƒë·ªëi t∆∞·ª£ng kh√°c nhau, ch√∫ng ta s·ª≠a d·ª•ng c√°c c·ª≠a s·ªï tr∆∞·ª£t c√≥ k√≠ch th∆∞·ªõc kh√°c nhau. C√°ch n√†y tho·∫°t ƒë·∫ßu tr√¥ng c√≥ v·∫ª kh√° t·ªët, nh∆∞ng ƒëi·ªÉm y·∫øu c·ªßa n√≥ l√† ƒë√£ s·ª≠ d·ª•ng c·ª≠a s·ªï tr∆∞·ª£t l√†m final boundary box. Do ƒë√≥, gi·∫£ s·ª≠ ch√∫ng ta c√≥ nhi·ªÅu ƒë·ªëi t∆∞·ª£ng, v√† m·ªói ƒë·ªëi t∆∞·ª£ng c√≥ k√≠ch th∆∞·ªõc kh√°c nhau, ch√∫ng ta s·∫Ω c√≥ r·∫•t nhi·ªÅu c·ª≠a s·ªï tr∆∞·ª£t ƒë·ªÉ bao ph·ªß h·∫øt to√†n b·ªô ƒë·ªëi t∆∞·ª£ng.\nM·ªôt √Ω t∆∞·ªüng c·∫£i ti·∫øn l√† ch√∫ng ta s·∫Ω ƒë·ªãnh nghƒ©a tr∆∞·ªõc c√°c c·ª≠a s·ªï tr∆∞·ª£t, sau ƒë√≥ s·∫Ω ti·∫øn h√†nh d·ª± ƒëo√°n l·ªõp v√† boundary box ( v√† √ù t∆∞·ªüng n√†y, nh√≥m nghi√™n c·ª©u ph√°t tri·ªÉn thu·∫≠t to√°n v√† ƒë·∫∑t t√™n thu·∫≠t to√°n l√† single shot detectors). √ù t∆∞·ªüng n√†y t∆∞∆°ng t·ª± nh∆∞ vi·ªác s·ª≠ d·ª•ng anchors trong Faster R-CNN, nh∆∞ng single shot detectors th·ª±c hi·ªán d·ª± ƒëo√°n boundary box v√† class ƒë·ªìng th·ªùi c√πng nhau.\nV√≠ d·ª•, gi·∫£ s·ª≠ ch√∫ng ta c√≥ m·ªôt feature map 8x8 v√† ch√∫ng ta ƒë∆∞a ra k = 4 d·ª± ƒëo√°n. V·∫≠y ta c√≥ t·ªïng c·ªông 8x8x4 = 256 d·ª± ƒëo√°n.\nX√©t h√¨nh b√™n tr√™n, ta c√≥ 4 anchors ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a tr∆∞·ªõc ( m√†u xanh l√° c√¢y), v√† c√≥ 4 prediction( m√†u xanh n∆∞·ªõc bi·ªÉn) t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng anchor tr√™n.\nV·ªõi thu·∫≠t to√°n Faster R-CNN, ch√∫ng ta s·ª≠ d·ª•ng m·ªôt convolution filter tr·∫£ ra 5 k·∫øt qu·∫£ d·ª± ƒëo√°n: 4 gi√° tr·ªã l√† to·∫° ƒë·ªô c·ªßa boundary box, v√† gi√° tr·ªã c√≤n l·∫°i l√† x√°c su·∫•t xu·∫•t hi·ªán ƒë·ªëi t∆∞·ª£ng. T·ªïng qu√°t h∆°n, ta c√≥ input l√† D feature map 8x8, output l√† 8x8x5, s·ªë convolution filter trong Faster R-CNN l√† 3x3xDx8.\nV·ªõi single shot detector, input c·ªßa ta c≈©ng t∆∞∆°ng t·ª± l√† 8x8xD, output l√† 8x8x (4 + C) ( v·ªõi 4 t∆∞∆°ng ·ª©ng v·ªõi 4 ƒëi·ªÉm boundary box, v√† C l√† s·ªë l∆∞·ª£ng l·ªõp ƒë·ªëi t∆∞·ª£ng), v·∫≠y ta c·∫ßn m·ªôt convolution filter l√† 3x3xDx(4+C)\nThu·∫≠t to√°n Single shot detect ch·∫°y kh√° nhanh, nh∆∞ng ƒë·ªô ch√≠nh x√°c c·ªßa n√≥ kh√¥ng cao l·∫Øm (kh√¥ng b·∫±ng region proposal). Thu·∫≠t to√°n c√≥ v·∫•n ƒë·ªÅ v·ªÅ vi·ªác nh·∫≠n d·∫°ng c√°c ƒë·ªëi t∆∞·ª£ng c√≥ k√≠ch th∆∞·ªõc nh·ªè. V√≠ d·ª• nh∆∞ h√¨nh b√™n d∆∞·ªõi, ch√∫ng ta c√≥ t·ªïng c·ªông 9 √¥ng gi√† noel, nh∆∞ng thu·∫≠t to√°n ch·ªâ nh·∫≠n di·ªán ƒë∆∞·ª£c c√≥ 5 √¥ng.\nSSD SSD l√† m√¥ h√¨nh single shot detector s·ª≠ d·ª•ng m·∫°ng VGG16 ƒë·ªÉ r√∫t tr√≠ch ƒë·∫∑c tr∆∞ng. M√¥ h√¨nh nh∆∞ h√¨nh b√™n d∆∞·ªõi. Trong ƒë√≥, nh·ªØng conv c√≥ m√†u xanh n∆∞·ªõc bi·ªÉn nh·∫°t l√† nh·ªØng custom convolution layter (ta c√≥ th·ªÉ th√™m b·ªõt bao nhi√™u tu·ª≥ th√≠ch). Convolutional filter layter (l√† c·ª•c m√†u xanh l√° c√¢y) c√≥ nhi·ªám v·ª• t·ªïng h·ª£p c√°c th√¥ng tin l·∫°i ƒë·ªÉ ƒë∆∞a quy·∫øt ƒë·ªãnh.\nKhi s·ª≠ d·ª•ng m√¥ h√¨nh nh∆∞ h√¨nh ·ªü tr√™n, ch√∫ng ta th·∫•y r·∫±ng c√°c custom convolution layter c√≥ nhi·ªám v·ª• l√†m gi·∫£m chi·ªÅu v√† gi·∫£m ƒë·ªô ph√¢n gi·∫£i c·ªßa b·ª©c ·∫£nh. Cho n√™n, m√¥ h√¨nh ch·ªâ c√≥ kh·∫£ nƒÉng nh·∫≠n ra c√°c ƒë·ªëi t∆∞·ª£ng c√≥ k√≠ch th∆∞·ªõc l·ªõn. ƒê·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng c√°c object detector kh√°c nhau tr√™n m·ªói feature maps (xem output c·ªßa m·ªói custom convolution l√† m·ªôt feature map).\n·∫¢nh b√™n d∆∞·ªõi l√† s∆° ƒë·ªì s·ªë chi·ªÅu c·ªßa c√°c feature maps.\nSSD s·ª≠ d·ª•ng c√°c layter c√≥ k√≠ch th∆∞·ªõc gi·∫£m d·∫ßn theo ƒë·ªô s√¢u ƒë·ªÉ nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng. Nh√¨n v√†o h√¨nh v·∫Ω s∆° ƒë·ªì b√™n d∆∞·ªõi c·ªßa SSD, ch√∫ng ra d·ªÖ d√†ng nh·∫≠n th·∫•y r·∫±ng ƒë·ªô ph√¢n gi·∫£i gi·∫£m ƒë√°ng k·ªÉ qua m·ªói layer v√† c√≥ l·∫Ω (ch·∫Øc ch·∫Øn) s·∫Ω b·ªè s√≥t nh·ªØng ƒë·ªëi t∆∞·ª£ng c√≥ k√≠ch th∆∞·ªõc nh·ªè ·ªü nh·ªØng l·ªõp c√≥ ƒë·ªô ph√¢n gi·∫£i th·∫•p. N·∫øu trong d·ª± √°n th·ª±c t·∫ø c·ªßa b·∫°n c√≥ x·∫£y ra v·∫•n ƒë·ªÅ n√†y, b·∫°n n√™n tƒÉng ƒë·ªô ph√¢n gi·∫£i c·ªßa ·∫£nh ƒë·∫ßu v√†o.\nYOLO YOLO c≈©ng l√† m·ªôt thu·∫≠t to√°n s·ª≠ d·ª•ng single shot detector ƒë·ªÉ d√≤ t√¨m v·ªã tr√≠ c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng trong ·∫£nh. YOLO s·ª≠ d·ª•ng DarkNet ƒë·ªÉ t·∫°o c√°c feature cho b·ª©c ·∫£nh (SSD s·ª≠ d·ª•ng VGG16). M√¥ h√¨nh c·ªßa YOLLO nh∆∞ ·∫£nh ·ªü b√™n d∆∞·ªõi.\nKh√°c v·ªõi ki·∫øn tr√∫c m·∫°ng SSD ·ªü tr√™n, YOLLO kh√¥ng s·ª≠ d·ª•ng multiple scale feature map (SSD s·ª≠ d·ª•ng c√°c custom convolution layter, qua m·ªói layter th√¨ feature maps s·∫Ω c√≥ k√≠ch th∆∞·ªõc gi·∫£m xu·ªëng - c√°c output c·ªßa custom convolution layer ch√≠nh l√† c√°c feature map ch√∫ng ta thu ƒë∆∞·ª£c). Thay v√†o ƒë√≥, YOLLO s·∫Ω l√†m ph·∫≥ng ho√° (flatten - vd ma tr·∫≠n 3x3 s·∫Ω bi·∫øn th√†nh vector 1x9, ma tr·∫≠n 4x5 s·∫Ω bi·∫øn th√†nh vector 1x20 \u0026hellip;, l√†m ph·∫≥ng nghƒ©a l√† ch√∫ng ta s·∫Ω kh√¥ng d√πng b·ªô l·ªçc n√†o h·∫øt, m√† s·ª≠ d·ª•ng c√°c ph√©p bi·∫øn ƒë·ªïi, n√™n kh√¥ng l√†m thay ƒë·ªïi gi√° tr·ªã, ch·ªâ l√†m thay ƒë·ªïi h√¨nh d·∫°ng) m·ªôt ph·∫ßn output c·ªßa convolution layer v√† k·∫øt h·ª£p v·ªõi convolution layer ·ªü trong DarkNet t·∫°o th√†nh feature map (Xem h√¨nh ·ªü tr√™n s·∫Ω r√µ h∆°n). V√≠ d·ª• ·ªü custom convolution layer ch√∫ng ta thu ƒë∆∞·ª£c output c√≥ k√≠ch th∆∞·ªõc 28x28x512, ch√∫ng ta s·∫Ω flatten th√†nh layter c√≥ k√≠ch th∆∞·ªõc 14x14x2048, k·∫øt h·ª£p v·ªõi 1 layter c√≥ k√≠ch th∆∞·ªõc 14x14x1024 ·ªü trong darknet, ch√∫ng ta thu ƒë∆∞·ª£c feature maps c√≥ k√≠ch th∆∞·ªõc l√† 14x14x3072. ƒêem feature maps n√†y ƒëi ƒë·ª± ƒëo√°n.\nYOLOv2 ƒë√£ th√™m v√†o r·∫•t nhi·ªÅu c√°c c·∫£i ti·ªÅn ƒë·ªÉ c·∫£i tƒÉng mAP t·ª´ 63.4 trong m√¥ h√¨nh ƒë·∫ßu ti√™n (YOLOv1) l√™n 78.6. C√°c c·∫£i ti·ªÅn bao g·ªìm th√™m batch norm, anchor boxes, hi-res classifier \u0026hellip; C√°c b·∫°n c√≥ th·ªÉ xem ·ªü h√¨nh b√™n d∆∞·ªõi. YOLO9000 c√≥ th·ªÉ nh·∫≠n d·∫°ng 9000 ƒë·ªëi t∆∞·ª£ng kh√°c nhau.\nYOLOv2 c√≥ th·ªÉ nh·∫≠n di·ªán c√°c ƒë·ªëi t∆∞·ª£ng v·ªõi ·∫£nh ƒë·∫ßu v√†o c√≥ ƒë·ªô ph√¢n gi·∫£i b·∫•t k·ª≥. V·ªõi ·∫£nh c√≥ ƒë·ªô ph√¢n gi·∫£i th·∫•p th√¨ m√¥ h√¨nh ch·∫°y kh√° nhanh, c√≥ FPS cao nh∆∞ng mAP l·∫°i th·∫•p (tradeoff gi·ªØa FPS v√† mAP).\nYOLOv3 YOLOv3 s·ª≠ d·ª•ng darknet v·ªõi ki·∫øn tr√∫c ph·ª©c h∆°n ƒë·ªÉ r√∫t tr√≠ch ƒë·∫∑c tr∆∞ng c·ªßa b·ª©c ·∫£nh. YOLOv3 th√™m v√†o ƒë·∫∑c tr∆∞ng Pyramid ƒë·ªÉ d√≤ t√¨m c√°c ƒë·ªëi t∆∞·ª£ng c√≥ k√≠ch th∆∞·ªõc nh·ªè.\nH√¨nh b√™n d∆∞·ªõi so s√°nh tradeoff gi·ªØa th·ªùi gian th·ª±c thi v√† ƒë·ªô ch√≠nh x√°c gi·ªØa c√°c m√¥ h√¨nh. Ta th·∫•y r·∫±ng th·ªùi gian th·ª±c thi c·ªßa YOLOv3 r·∫•t nhanh, c√πng ph√¢n m·ª©c mAP 28.8, th·ªùi gian YOLOv3 th·ª±c thi ch·ªâ t·ªën 22ms, trong khi ƒë√≥ SSD321 t·ªën ƒë·∫øn 61ms - g·∫•p 3 l·∫ßn.\nFeature Pyramid Networks (FPN) D√≤ t√¨m c√°c ƒë·ªëi t∆∞·ª£ng c√≥ k√≠ch th∆∞·ªõc nh·ªè l√† m·ªôt v·∫•n ƒë·ªÅ ƒë√°ng ƒë∆∞·ª£c gi·∫£i quy·∫øt ƒë·ªÉ n√¢ng cao ƒë·ªô ch√≠nh x√°c. V√† FPN l√† m√¥ h√¨nh m·∫°ng ƒë∆∞·ª£c thi·∫øt k·∫ø ra d·ª±a tr√™n kh√°i ni·ªám pyramid ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y.\nM√¥ h√¨nh FPN k·∫øt h·ª£p th√¥ng tin c·ªßa m√¥ h√¨nh theo h∆∞·ªõng bottom-up k·∫øt h·ª£p v·ªõi top-down ƒë·ªÉ d√≤ t√¨m ƒë·ªëi t∆∞·ª£ng (trong khi ƒë√≥, c√°c thu·∫≠t to√°n kh√°c ch·ªâ th∆∞·ªùng s·ª≠ d·ª•ng bottom-up). Khi ch√∫ng ta ·ªü bottom v√† ƒëi l√™n (up), ƒë·ªô ph√¢n gi·∫£i s·∫Ω gi·∫£m, nh∆∞ng gi√° tr·ªã ng·ªØ nghƒ©a s·∫Ω tƒÉng l√™n. Xem h√¨nh m√¥ ph·ªèng b√™n d∆∞·ªõi.\nSSD ƒë∆∞a ra quy·∫øt ƒë·ªãnh d·ª±a v√†o nhi·ªÅu feature map. Nh∆∞ng layer ·ªü bottom kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng. V√¨ nh·ªØng layter n√†y c√≥ ƒë·ªô ph√¢n gi·∫£i cao nh∆∞ng gi√° tr·ªã ng·ªØ nghƒ©a c·ªßa ch√∫ng l·∫°i kh√¥ng ƒë·ªß cao (th·∫•p) n√™n nh·ªØng nh√† nghi√™n c·ª©u b·ªè ch√∫ng ƒëi ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω. C√°c nh√† nghi√™ng c·ª©u bi·ªán minh r·∫±ng c√°c layer ·ªü bottom ch∆∞a ƒë·ªß m·ª©c √Ω nghƒ©a c·∫ßn thi·∫øt ƒë·ªÉ n√¢ng cao ƒë·ªô ch√≠nh x√°c, th√™m c√°c layer ƒë√≥ v√†o s·∫Ω kh√¥ng n√¢ng ƒë·ªô ch√≠nh x√°c cao th√™m bao nhi√™u v√† h·ªç b·ªè ch√∫ng ƒëi ƒë·ªÉ c√≥ t·ªëc ƒë·ªô t·ªët h∆°n. Cho n√™n, SSD ch·ªâ s·ª≠ d·ª•ng c√°c layer ·ªü l·ªõp tr√™n , v√† do ƒë√≥ s·∫Ω kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c c√°c ƒë·ªëi t∆∞·ª£ng c√≥ k√≠ch th∆∞·ªõc nh·ªè.\nTrong khi ƒë√≥, FPN x√¢y d·ª±ng th√™m m√¥ h√¨nh top-down, nh·∫±m m·ª•c ƒë√≠ch x√¢y d·ª±ng c√°c layer c√≥ ƒë·ªô ph√¢n gi·∫£i cao t·ª´ c√°c layer c√≥ ng·ªØ nghƒ©a cao.\nTrong qu√° tr√¨nh x√¢y d·ª±ng l·∫°i c√°c layer t·ª´ top xu·ªëng bottom, ch√∫ng ta s·∫Ω g·∫∑p m·ªôt v·∫•n ƒë·ªÅ kh√° nghi√™m tr·ªçng l√† b·ªã m·∫•t m√°t th√¥ng tin c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng. V√≠ d·ª• m·ªôt ƒë·ªëi t∆∞·ª£ng nh·ªè khi l√™n top s·∫Ω kh√¥ng th·∫•y n√≥, v√† t·ª´ top ƒëi ng∆∞·ª£c l·∫°i s·∫Ω kh√¥ng th·ªÉ t√°i t·∫°o l·∫°i ƒë·ªëi t∆∞·ª£ng nh·ªè ƒë√≥. ƒê·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y, ch√∫ng ta s·∫Ω t·∫°o c√°c k·∫øt n·ªëi (skip connection) gi·ªØa c√°c reconstruction layter v√† c√°c feature map ƒë·ªÉ gi√∫p qu√° tr√¨nh detector d·ª± ƒëo√°n c√°c v·ªã tr√≠ c·ªßa ƒë·ªëi t∆∞·ª£ng th·ª±c hi·ªán t·ªët h∆°n (h·∫°n ch·∫ø t·ªët nh·∫•t vi·ªác m·∫•t m√°t th√¥ng tin).\nTh√™m c√°c skip connection gi·ªØa feature map v√† reconstruction layer\nƒê·ªì h√¨nh b√™n d∆∞·ªõi di·ªÖn ta chi ti·∫øt ƒë∆∞·ªùng ƒëi theo bottom-up v√† top-down. P2, P3, P4, P5 l√† c√°c pyramid c·ªßa c√°c feature map.\nSo s√°nh Feature Pyramid Networks v·ªõi Region Proposal Network FPN kh√¥ng ph·∫£i l√† m√¥ h√¨nh ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng. N√≥ l√† m√¥ h√¨nh ph√°t hi·ªán ƒë·∫∑c tr∆∞ng v√† ƒë∆∞·ª£c s·ª≠ d·ª•ng trong ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng. C√°c feature map t·ª´ P2 ƒë·∫øn P5 trong h√¨nh b√™n d∆∞·ªõi ƒë·ªôc l·∫≠p v·ªõi nhau v√† c√°c ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng.\nS·ª≠ d·ª•ng Feature Pyramid Networks trong Fast R-CNN v√† Faster R-CNN Ch√∫ng ta ho√†n to√†n c√≥ th·ªÉ s·ª≠ d·ª•ng FPN trong Fast v√† Faster R-CNN. Ch√∫ng ta s·∫Ω t·∫°o ra c√°c feature map s·ª≠ d·ª•ng FPN, k·∫øt qu·∫£ l√† ta thu ƒë∆∞·ª£c c√°c puramid (feature map). Sau ƒë√≥, ch√∫ng ta s·∫Ω r√∫t tr√≠ch c√°c ROIs tr√™n c√°c feature map ƒë√≥. D·ª±a tr√™n k√≠ch th∆∞·ªõc c·ªßa c√°c ROI, ch√∫ng ta s·∫Ω ch·ªçn feature map n√†o t·ªët nh·∫•t ƒë·ªÉ t·∫°o c√°c feature patches (c√°c h√¨nh ch·ªØ nh·∫≠t nh·ªè). C√°c b·∫°n c√≥ th·ªÉ xem chi ti·∫øt ·ªü h√¨nh b√™n d∆∞·ªõi.\nFocal loss (RetinaNet) Trong th·ª±c t·∫ø, ch√∫ng ta s·∫Ω g·∫∑p t√¨nh tr·∫°ng t·ª∑ l·ªá di·ªán t√≠ch c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng trong ·∫£nh nh·ªè h∆°n nhi·ªÅu so v·ªõi ph·∫ßn background c√≤n l·∫°i, v√≠ d·ª• ch√∫ng ta c·∫ßn nh·∫≠n d·∫°ng m·ªôt qu·∫£ cam c√≥ k√≠ch th∆∞·ªõc 100x100 trong ·∫£nh 1920x1080. V√¨ ph·∫ßn background qu√° l·ªõn n√™n ch√∫ng s·∫Ω l√† th√†nh ph·∫ßn \u0026ldquo;th·ªëng tr·ªã\u0026rdquo; v√† l√†m sai l·ªách k·∫øt qu·∫£. SSD s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p l·∫•y m·∫´u t·ª∑ l·ªá c·ªßa object class v√† background class trong qu√° tr√¨nh train (n√™n background s·∫Ω kh√¥ng c√≤n th·ªëng tr·ªã n·ªØa).\nNgo√†i ra, ch√∫ng ta s·∫Ω c√≤n g·∫∑p t√¨nh tr·∫°ng l√† s·ªë l∆∞·ª£ng t·ª∑ l·ªá object trong ·∫£nh kh√¥ng ƒë·ªÅu nhau, v√≠ d·ª• trong t·∫≠p hu·∫•n luy·ªát c√≥ 1000 qu·∫£ cam v√† 10 qu·∫£ t√°o.\nFocal loss (FL) ƒë∆∞·ª£c sinh ra ƒë·ªÉ gi·∫£i quy·∫øt t√¨nh tr·∫°ng n√†y. ƒê·ªÉ ƒëi v√†o chi ti·∫øt h∆°n, ch√∫ng ta nh·∫Øc l·∫°i h√†m l·ªói cross entropy.\n$$ \\begin{equation} CE(p,y) = \\begin{cases} -\\log(p) \u0026amp; \\text{if y=1} \\\\\\\\ -\\log(1-p) \u0026amp; \\text{otherwise} \\end{cases} \\end{equation} $$\nTrong h√†m tr√™n th√¨ y nh·∫≠n gi√° tr·ªã 1 ho·∫∑c -1. Gi√° tr·ªã x√°c xu·∫•t n·∫±m trong kho·∫£ng (0,1) l√† x√°c su·∫•t d·ª± ƒëo√°n cho l·ªõp c√≥ y=1.\nƒê·ªÉ r√µ r√†ng h∆°n, ta c√≥ th·ªÉ vi·∫øt l·∫°i h√†m tr√™n nh∆∞ sau:\n$$ \\begin{equation} p_t = \\begin{cases} p \u0026amp; \\text{if y=1} \\\\\\\\ 1-p \u0026amp; \\text{otherwise} \\end{cases} \\end{equation} $$\n$$ \\begin{equation} CE(p,y) = CE(p_t) = -\\log(p_t) \\end{equation} $$\nTa c√≥ nh·∫≠n x√©t r·∫±ng ƒë·ªëi v·ªõi c√°c tr∆∞·ªùng h·ª£p ƒë∆∞·ª£c ph√¢n lo·∫°i t·ªët (c√≥ x√°c su·∫•t l·ªõn h∆°n 0.6) th√¨ h√†m loss nh·∫≠n g√°i tr·ªã v·ªõi ƒë·ªô l·ªõn l·ªõn h∆°n 0. V√† trong tr∆∞·ªùng h·ª£p d·ªØ li·ªáu c√≥ t·ª∑ l·ªá l·ªách cao th√¨ t·ªïng c√°c gi√° tr·ªã n√†y s·∫Ω cho ra k·∫øt qu·∫£ loss v·ªõi m·ªôt con s·ªë r·∫•t l·ªõn so v·ªõi loss c·ªßa c√°c tr∆∞·ªùng h·ª£p kh√≥ ph√¢m lo·∫°i. V√† n√≥ ·∫£nh h∆∞·ªüng ƒë·∫øn qu√° tr√¨nh hu·∫•n luy·ªán.\n√ù t∆∞·ªüng ch√≠nh c·ªßa focal-lost l√† ƒë·ªëi v·ªõi c√°c tr∆∞·ªùng h·ª£p ƒë∆∞·ª£c ph√¢n lo·∫°i t·ªët ( x√°c su·∫•t l·ªõn h∆°n 0.5) th√¨ focal lost s·∫Ω l√†m gi·∫£m gi√° tr·ªã cross-entropy c·ªßa n√≥ xu·ªëng nh·ªè h∆°n so v·ªõi th√¥ng th∆∞·ªùng. Do ƒë√≥, ta s·∫Ω th√™m tr·ªçng s·ªë cho h√†m cross-entropy ƒë·ªÉ bi·∫øn th√†nh h√†m focal lost.\n$$ FL(p_t) = -(1-p_t)^\\gamma\\log(p_t) $$\nV·ªõi nh√¢n t·ª≠ ƒë∆∞·ª£c th√™m v√†o ƒë∆∞·ª£c g·ªçi l√† modulating factor, gamma l·ªõn h∆°n ho·∫∑c b·∫±ng 0 ƒë∆∞·ª£c g·ªçi l√† tham s·ªë focusing.\nNh√¨n h√¨nh ·ªü tr√™n, ta th·∫•y r·∫±ng khi gamma = 0 th√¨ h√†m focal lost ch√≠nh l√† cross-entropy.\nƒê·∫∑c ƒëi·ªÉm c·ªßa h√†m lost tr√™n nh∆∞ sau:\nKhi m·∫´u b·ªã ph√¢n lo·∫°i sai, pt nh·ªè, nh√¢n t·ªë modulating factor g·∫ßn v·ªõi 1 v√† h√†m lost √≠t b·ªã ·∫£nh h∆∞·ªüng. Khi pt ti·∫øn g·∫ßn t·ªõi 1 (m·∫´u ph√¢n lo·∫°i t·ªët), moduling factor s·∫Ω ti·∫øn g·∫ßn t·ªõi 0 v√† h√†m loss trong tr∆∞·ªùng h·ª£p n√†y s·∫Ω b·ªã gi·∫£m tr·ªçng s·ªë xu·ªëng.\nTham s·ªë focusing s·∫Ω ƒëi·ªÅu ch·ªânh t·ª∑ l·ªá c√°c tr∆∞·ªùng h·ª£p ƒë∆∞·ª£c ph√¢n lo·∫°i t·ªët ƒë∆∞·ª£c gi·∫£m tr·ªçng s·ªë. Khi gamma c√†ng tƒÉng th√¨ ·∫£nh h∆∞·ªüng c·ªßa modulating factor c≈©ng tƒÉng. Trong c√°c th√≠ nghi·ªám cho th·∫•y v·ªõi gamma = 2 h√¨ k·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c s·∫Ω t·ªët nh·∫•t.\nH√¨nh b√™n d∆∞·ªõi l√† ƒë·ªì h√¨nh c·ªßa RetinaNet ƒë∆∞·ª£c x√¢y d·ª±ng d·ª±a tr√™n FPN v√† ResNet s·ª≠ dung Focal loss.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\nB√†i vi·∫øt ƒë∆∞·ª£c l∆∞·ª£c d·ªãch v√† tham kh·∫£o t·ª´ ngu·ªìn https://medium.com/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d\n","date":"Dec 6, 2018","img":"","permalink":"/blog/2018-12-06-what-do-we-learn-from-single-shot-object-detection/","series":null,"tags":["Machine learning","Deeplearning","object detector","single shot"],"title":"T√¨m Hi·ªÉu Single Shot Object Detectors"},{"categories":null,"content":" Sliding-window detectors Selective Search M·∫°ng R-CNN M·∫°ng Fast R-CNN ROI Pooling Faster R-CNN Region proposal network Hi·ªáu nƒÉng c·ªßa m√¥ h√¨nh R-CNN Region-based Fully Convolutional Networks Sliding-window detectors B·∫Øt ƒë·∫ßu t·ª´ nƒÉm 2012, sau khi m·∫°ng AlexNet gi√†nh gi·∫£i nh·∫•t cu·ªôc thi 2012 ILSVRC, m·ªçi nghi√™n c·ª©u v·ªÅ ph√¢n l·ªõp d·ªØ li·ªáu ƒë·ªÅu s·ª≠ d·ª•ng m·∫°ng CNN. K·ªÉ t·ª´ ƒë√≥ ƒë·∫øn ƒë√¢y, CNN ƒë∆∞·ª£c coi nh∆∞ l√† thu·∫≠t to√°n th·ªëng tr·ªã tr√™n m·ªçi publish paper v·ªÅ c√°c b√†i to√°n ph√¢n l·ªõp ƒë·ªëi t∆∞·ª£ng. Trong khi ƒë√≥, ƒë·ªÉ nh·∫≠n d·∫°ng 1 ƒë·ªëi t∆∞·ª£ng trong ·∫£nh, c√°c ƒë∆°n gi·∫£n nh·∫•t l√† thi·∫øt l·∫≠p m·ªôt c·ª≠a s·ªï tr∆∞·ª£t c√≥ k√≠ch th∆∞·ªõc l√† window size tr∆∞·ª£t t·ª´ tr√°i qua ph·∫£i, t·ª´ tr√™n xu·ªëng d∆∞·ªõi, qu√©t qua to√†n b·ªô b·ª©c ·∫£nh. ƒê·ªÉ ph√°t hi·ªán c√°c ƒë·ªëi t∆∞·ª£ng kh√°c nhau ·ªü c√°c g√≥c nh√¨n kh√°c nhau, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng c·ª≠a s·ªï tr∆∞·ª£t c√≥ k√≠ch th∆∞·ªõc thay ƒë·ªïi v√† ·∫£nh ƒë·∫ßu v√†o c√≥ k√≠ch th∆∞·ªõc thay ƒë·ªïi.\nD·ª±a v√†o windowsize, ch√∫ng ta c√≥ th·ªÉ c·∫Øt t·∫•m h√¨nh b·ª± th√†nh c√°c t·∫•m h√¨nh nh·ªè, sau ƒë√≥ s·∫Ω rescale c√°c ph·∫ßn nh·ªè c·ªßa b·ª©c ·∫£nh th√†nh c√°c b·ª©c ·∫£nh c√≥ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh.\nC√°c ph·∫ßn c·ªßa b·ª©c ·∫£nh sau ƒë√≥ s·∫Ω ƒë∆∞·ª£c ƒëem qua b·ªô ph√¢n l·ªõp CNN ƒë·ªÉ r√∫t tr√≠ch c√°c ƒë·∫∑c tr∆∞ng, sau ƒë√≥ s·ª≠ d·ª•ng m·ªôt h√†m ph√¢n l·ªõp (nh∆∞ svm, logictic regression) ƒë·ªÉ x√°c ƒë·ªãnh l·ªõp c·ªßa b·ª©c h√¨nh v√† s·ª≠ d·ª•ng linear regressor ƒë·ªÉ t√¨m bao ƒë√≥ng c·ªßa ƒë·ªëi t∆∞·ª£ng.\nM√£ gi·∫£ c·ªßa m√¥ h√¨nh\n1for window in windows 2 patch = get_patch(image, window) 3 results = detector(patch) C√°ch d·ªÖ d√†ng nh·∫•t ƒë·ªÉ c·∫£i ti·∫øn hi·ªáu nƒÉng c·ªßa ph∆∞∆°ng ph√°p n√†y l√† gi·∫£m s·ªë l∆∞·ª£ng t·∫•m h√¨nh nh·ªè xu·ªëng (v√≠ d·ª• tƒÉng k√≠ch th∆∞·ªõc window size). C√°ch n√†y c√≤n ƒë∆∞·ª£c giang h·ªì g·ªçi l√† brute force.\nSelective Search Thay v√¨ h∆∞·ªõng ti·∫øp c·∫≠n brute force ·ªü tr√™n, ch√∫ng ta s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p region proposal ƒë·ªÉ t·∫°o c√°c region of interest (ROIs) ƒë·ªÉ ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng. Selective search l√† m·ªôt ph∆∞∆°ng ph√°p n·∫±m trong nh√≥m region proposal. Trong ph∆∞∆°ng ph√°p selective search(SS), ch√∫ng ta b·∫Øt ƒë·∫ßu b·∫±ng c√°ch xem c√°c pixel l√† m·ªói nh√≥m, c√°c l·∫ßn l·∫∑p ti·∫øp theo, ch√∫ng ta s·∫Ω t√≠nh kho·∫£ng c√°ch ng·ªØ nghƒ©a (v√≠ d·ª• nh∆∞ l√† m√†u s·∫Øc, c∆∞·ªùng ƒë·ªô √°nh s√°ng) gi·ªØa c√°c nh√≥m v√† gom c√°c nh√≥m c√≥ kho·∫£ng c√°ch g·∫ßn nhau v·ªÅ chung 1 nh√≥m ƒë·ªÉ t√¨m ra ph√¢n v√πng c√≥ kh·∫£ nƒÉng cao nh·∫•t ch·ª©a ƒë·ªëi t∆∞·ª£ng (∆∞u ti√™n gom nh·ªØng nh√≥m nh·ªè tr∆∞·ªõc).\nNh∆∞ h√¨nh b√™n d∆∞·ªõi, d√≤ng ƒë·∫ßu ti√™n, b·ª©c ·∫£nh ƒë√¢u ti√™n l√† ta c√≥ m·ªôt v√†i nh√≥m nh·ªè ·ªü th·ªùi ƒëi·ªÉm X n√†o ƒë√≥, ·ªü h√¨nh th·ª© 2 l√† th·ª±c hi·ªán gom nh·ªõm theo c∆∞·ªùng ƒë·ªô m√†u s·∫Øc c·ªßa h√¨nh s·ªë 1, v√† ·ªü b∆∞·ªõc cu·ªëi c√πng, ta thu ƒë∆∞·ª£c h√¨nh s·ªë 3. Nh·ªØng h√¨nh ch·ªØ nh·∫≠t m√†u xanh ·ªü d√≤ng th·ª© 2 l√† nh·ªØng ROIS m√¥ ph·ªèng qu√° tr√¨nh gom nh√≥m ƒë·ªÉ t√¨m ph√¢n v√πng c√≥ kh·∫£ nƒÉng ch·ª©a ƒë·ªëi t∆∞·ª£ng.\nselective search\nM·∫°ng R-CNN M·∫°ng R-CNN s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p region proposal ƒë·ªÉ t·∫°o ra kho·∫£ng 2000 ROIs. C√°c v√πng sau ƒë√≥ s·∫Ω ƒë∆∞·ª£c rescale theo m·ªôt k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh n√†o ƒë√≥ v√† ƒë∆∞·ª£c ƒë∆∞a v√†o m√¥ h√¨nh CNN c√≥ l·ªõp cu·ªëi c√πng k√† m·ªôt full conected layer ƒë·ªÉ ph√¢n l·ªõp ƒë·ªëi t∆∞·ª£ng v√† ƒë·ªÉ l·ªçc ra boundary box (bao ƒë√≥ng) c·ªßa ƒë·ªëi t∆∞·ª£ng.\nM√¥ ph·ªèng vi·ªác s·ª≠ d·ª•ng region proposal\nM√¥ ph·ªèng vi·ªác s·ª≠ d·ª•ng region proposal c·ªßa RCNN\nM√£ gi·∫£ c·ªßa m√¥ h√¨nh\n1ROIs = region_proposal(image) 2for ROI in ROIs 3 patch = get_patch(image, ROI) 4 results = detector(patch) V·ªõi vi·ªác s·ª≠ d·ª•ng √≠t t·∫•m ·∫£nh nh·ªè h∆°n, v√† ch·∫•t l∆∞·ª£ng c·ªßa m·ªói t·∫•m ·∫£nh nh·ªè t·ªët h∆°n, M·∫°ng R-CNN ch·∫°y nhanh h∆°n v√† c√≥ ƒë·ªô ch√≠nh x√°c cao h∆°n so v·ªõi m√¥ h√¨nh s·ª≠ d·ª•ng c·ª≠a s·ªï tr∆∞·ª£t.\nM·∫°ng Fast R-CNN Trong th·ª±c t·∫ø, c√°c ph√¢n v√πng c·ªßa m·∫°ng R-CNN b·ªã ch·ªìng l·∫•p m·ªôt ph·∫ßn / to√†n b·ªô v·ªõi c√°c ph√¢n v√πng kh√°c. Do ƒë√≥, vi·ªác hu·∫•n luy·ªán v√† th·ª±c thi ( inference ) m·∫°ng R-CNN di·ªÖn ra kh√° ch·∫≠m. N·∫øu ch√∫ng ta c√≥ 2000 proposal c·ªßa m·∫°ng R-CNN, ch√∫ng ta ph·∫£i th·ª±c hi·ªán 2000 l·∫ßn vi·ªác r√∫t tr√≠ch ƒë·∫∑c tr∆∞ng, m·ªôt con s·ªë kh√°c l·ªõn.\nThay v√¨ ph·∫£i r√∫t tr√≠ch ƒë·∫∑c tr∆∞ng c·ªßa m·ªói proposal, ch√∫ng ta c√≥ th·ªÉ d√πng CNN r√∫t tr√≠ch ƒë·∫∑c tr∆∞ng c·ªßa to√†n b·ªô b·ª©c ·∫£nh tr∆∞·ªõc (ƒë∆∞·ª£c feature map), ƒë·ªìng th·ªùi r√∫t tr√≠ch c√°c proposal, l·∫•y c√°c proposal t∆∞∆°ng ·ª©ng tr√™n feature map, rescale v√† cu·ªëi c√πng l√† ph√¢n l·ªõp v√† t√¨m v·ªã tr√≠ c·ªßa object. V·ªõi vi·ªác kh√¥ng ph·∫£i l·∫∑p l·∫°i 2000 l·∫ßn vi·ªác r√∫t tr√≠ch ƒë·∫∑c tr∆∞ng, Fast R-CNN gi·∫£m th·ªùi gian x·ª≠ l√Ω m·ªôt c√°ch ƒë√°ng k·ªÉ.\nM√¥ ph·ªèngvi·ªác s·ª≠ d·ª•ng propoxal tr√™n feature map v√† c√°c b∆∞·ªõc ti·∫øp theo c·ªßa Fast R-CNN\nƒê·ªì h√¨nh c·ªßa Fast R-CNN\nM√£ gi·∫£ c·ªßa m√¥ h√¨nh\n1feature_maps = process(image) 2ROIs = region_proposal(image) 3for ROI in ROIs 4 patch = roi_pooling(feature_maps, ROI) 5 results = detector2(patch) V·ªõi vi·ªác kh√¥ng ph·∫£i l·∫∑p ƒëi l·∫∑p l·∫°i qu√° tr√¨nh t√¨m ra c√°c proposal, t·ªëc ƒë·ªô c·ªßa thu·∫≠t to√°n tƒÉng l√™n kha kh√°. Trong th·ª±c nghi·ªám, m√¥ h√¨nh Fast R-CNN ch·∫°y nhanh h∆°n g·∫•p 10 l·∫ßn so v·ªõi R-CNN trong qu√° tr√¨nh hu·∫•n luy·ªán. V√† nhanh h∆°n 150 l·∫ßn trong inferencing.\nM·ªôt kh√°c bi·ªát l·ªõn nh·∫•t c·ªßa Fast R-CNN l√† to√†n b·ªô network (feature extractior, classifier, boundary box regressor) c√≥ th·ªÉ hu·∫•n luy·ªán end-to end (nghƒ©a l√† t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi) v·ªõi 2 h√†m ƒë·ªô l·ªói (loss funtion) kh√°c nhau c√πng l√∫c (classification loss v√† localization loss). ƒêi·ªÅu n√†y l√†m tƒÉng ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh.\nROI Pooling V√¨ Fast R-CNN s·ª≠ d·ª•ng full connected layter ·ªü l·ªõp cu·ªëi, n√™n ƒë√≤i h·ªèi input c·ªßa ch√∫ng ph·∫£i c√≥ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh, n√™n ta ph·∫£i resize l·∫°i feature v·ªÅ 1 k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh (do 2000 proposal c√≥ k√≠ch th∆∞·ªõc kh√¥ng c·ªë ƒë·ªãnh). ·ªû ƒë√¢y, c√°c t√°c gi·∫£ s·ª≠ d·ª•ng ROI pooling ƒë·ªÉ resize. Thu·∫≠t to√°n ·ªü ƒë√¢y ƒë∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ sau:\nGi·∫£ s·ª≠ ƒë∆°n gi·∫£n l√† ch√∫ng ta c√≥ m·ªôt proposal c√≥ k√≠ch th∆∞·ªõc 5x7, v√† ch√∫ng ta c·∫ßn resize v·ªÅ h√¨nh d·∫°ng 2x2. Ch√∫ng ta xem k·ªπ h√¨nh b√™n d∆∞·ªõi.\nH√¨nh ·∫£nh m√¥ ph·ªèng ROI pooling\nH√¨nh ·ªü b√™n tr√°i l√† feature map c·ªßa ch√∫ng ta.\nH√¨nh s·ªë 2, v√πng h√¨nh ch·ªØ nh·∫≠t xanh l√† v√πng proposal 5x7.\nV√¨ ch√∫ng ta c·∫ßn resize v·ªÅ v√πng c√≥ k√≠ch th∆∞·ªõc 2x2 (4 ph·∫ßn), n√™n ta chia v√πng proposal 5x7 th√†nh 4 ph·∫ßn (5/2 =2 d∆∞ 3, v·∫≠y c√≥ 1 ph·∫ßn l√† 2, 1 ph·∫ßn l√† 3. T∆∞∆°ng t·ª± 7/2 = 3 d∆∞ 4, v·∫≠y c√≥ 1 ph·∫ßn 3, m·ªôt ph·∫ßn 4. Cu·ªëi c√πng ta c√≥ 4 h√¨nh ch·ªØ nh·∫≠t c√≥ k√≠ch th∆∞·ªõc t∆∞∆°ng ·ª©ng l√† 2x3, 2x4, 3x3, 3x4) (H√¨nh s·ªë 3).\nH√¨nh s·ªë 4, t·ª´ 4 ph·∫ßn c·ªßa v√πng s·ªë 3, ta s·∫Ω l·∫•y gi√° tr·ªã l·ªõn nh·∫•t c·ªßa m·ªói v√πng.\nV·∫≠y l√† ta thu ƒë∆∞·ª£c feature proposal c√≥ k√≠ch th∆∞·ªõc 2x2 r·ªìi.\nFaster R-CNN Nh√¨n k·ªπ l·∫°i v√†o thu·∫≠t to√°n F-CNN, ch√∫ng ta c·∫ßn ph·∫£i r√∫t r√≠ch 2000 ROIs, v√† n√≥ l√† nguy√™n nh√¢n l·ªõn g√¢y n√™n s·ª± ch·∫≠m tr·ªÉ c·ªßa m√¥ h√¨nh\n1feature_maps = process(image) 2ROIs = region_proposal(image) # Expensive, slow 3for ROI in ROIs 4 patch = roi_pooling(feature_maps, ROI) 5 results = detector2(patch) Thu·∫≠t to√°n Faster R-CNN s·ª≠ d·ª•ng m√¥ h√¨nh g·∫ßn nh∆∞ t∆∞∆°ng t·ª± Fast R-CNN, ngo√†i vi·ªác s·ª≠ d·ª•ng thu·∫≠t to√°n interal deep network thay cho selective search ƒë·ªÉ t√¨m region proposal. Thu·∫≠t to√°n m·ªõi ch·∫°y hi·ªáu qu·∫£ h∆°n khi t√¨m t·∫•t c·∫£ c√°c ROIs tr√™n m·ªói b·ª©c ·∫£nh v·ªõi t·ªëc ƒë·ªô 10ms/\nM√¥ h√¨nh c·ªßa Faster R-CNN\nƒê·ªì h√¨nh c·ªßa Faster R-CNN\nRegion proposal network M·∫°ng region proposal s·ª≠ d·ª•ng feature map l√†m input ƒë·∫ßu v√†o (nh∆∞ h√¨nh tr√™n ƒë√£ m√¥ ph·ªèng). M·∫°ng s·ª≠ d·ª•ng 1 b·ªô l·ªçc 3x3, sau ƒë√≥ l√† m·ªôt m√¥ h√¨nh CNN nh∆∞ ZF ho·∫∑c VGG ho·∫∑c ResNet ( m√¥ h√¨nh c√†ng ph·ª©c t·∫°p th√¨ ƒë·ªô ch√≠nh x√°c cao, nh∆∞ng b√π l·∫°i th·ªùi gian t√¨m ki·∫øm s·∫Ω l√¢u h∆°n) ƒë·ªÉ d·ª± ƒëo√°n boundary box v√† object score (ƒë·ªÉ x√©t xem trong bodary box tr√™n c√≥ ch·ª©a ƒë·ªëi t∆∞·ª£ng hay kh√¥ng. Trong th·ª±c t·∫ø, m·∫°ng Faster R-CNN tr·∫£ v·ªÅ 2 l·ªõp, l·ªõp th·ª© nh·∫•t l√† c√≥ ch·ª©a object, l·ªõp th·ª© 2 l√† kh√¥ng ch·ª©a object ( v√≠ d·ª• l·ªõp m√†u n·ªÅn - background, l·ªõp abc g√¨ g√¨ ƒë√≥)) .\nV√≠ d·ª• Region proposal network\nM√¥ h√¨nh Region proposal network s·ª≠ d·ª•ng ZF network\nGi·∫£ s·ª≠ t·∫°i 1 ƒëi·ªÉm n√†o ƒë√≥ tr√™n feature map, RPN c√≥ k d·ª± ƒëo√°n, v·∫≠y l√† ch√∫ng ta c√≥ t·ªïng c·ªông 4xk to·∫° ƒë·ªô ƒëi·ªÉm v√† 2xk ƒëi·ªÉm cho ƒëi·ªÉm ƒë√≥. Nh√¨n v√≠ d·ª• ·ªü h√¨nh b√™n d∆∞·ªõi.\nH√¨nh 1: ta c√≥ feature map v·ªõi k√≠ch th∆∞·ªõc 8x8, v√πng h√¨nh vu√¥ng ƒë∆∞·ª£c t√¥ l√† filter ƒëang x√©t c√≥ k√≠ch th∆∞·ªõc 3x3. H√¨nh 2: Gi·∫£ s·ª≠ x√©t ƒëi·ªÉm c√≥ ch·∫•m xanh. T·∫°i ƒëi·ªÉm ƒë√≥, ta c√≥ k=3 sau khi ch·∫°y RPN, v√† ta ƒë∆∞·ª£c 3 h√¨nh ch·ªØ nh·∫≠t nh∆∞ h√¨nh.\nTuy nhi√™n, t·∫°i m·ªói ƒëi·ªÉm, ta ch·ªâ c·∫ßn 1 boundary box t·ªët nh·∫•t. C√°ch ƒë∆°n gi·∫£n nh·∫•t l√† ch·ªçn ng·∫´u nhi√™n 1 c√°i. Nh∆∞ng nh∆∞ v·∫≠y th√¨ ngay t·ª´ ƒë·∫ßu ta ch·ªçn k=1 lu√¥n cho kho·∫ª, m·∫Øc c√¥ng g√¨ ph·∫£i ch·ªçn k=3. Trong th·ª±c t·∫ø, Faster R-CNN kh√¥ng s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p random select. Thay v√†o ƒë√≥, thu·∫≠t to√°n m·ªôt reference boxs hay c√≤n ƒë∆∞·ª£c g·ªçi v·ªõi t√™n l√† anchors v√† t√¨m m·ª©c ƒë·ªô li√™n quan c·ªßa k boundary box v·ªõi k reference boxs v√† ch·ªçn ra boundary box c√≥ ƒë·ªô li√™n quan l·ªõn nh·∫•t.\nV√≠ d·ª• anchors box\nC√°c anchors n√†y ƒë∆∞·ª£c l·ª±a ch·ªçn tr∆∞·ªõc ƒë√≥ v√† ƒë∆∞·ª£c xem l√† config c·ªßa m√¥ h√¨nh. Faster R-CNN s·ª≠ d·ª•ng 9 anchor boxs (t∆∞∆°ng ·ª©ng v·ªõi k =3) v·ªõi 3 box ƒë·∫ßu ti√™n c√≥ t·ª∑ l·ªá width, height kh√°c nhau (v√≠ d·ª• 2x3, 3x3, 3x2), ti·∫øp ƒë√≥ s·∫Ω scale c√°c box tr√™n v·ªõi c√°c t·ª∑ l·ªá kh√°c khau (v√≠ d·ª• 1.5,3,7) ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c 9 anchor boxs.\nV√¨ m·ªói ƒëi·ªÉm s·ª≠ d·ª•ng 9 anchors, n√™n ta c√≥ t·ªïng c·ªông 2x9 score v√† 4x9 location (to·∫° ƒë·ªô)\nAnchor box c√≥ th·ªÉ ƒë∆∞·ª£c goijlaf priors ho·∫∑c default boundary boxes trong m·ªói b√†i b√°o kh√°c nhau.\nHi·ªáu nƒÉng c·ªßa m√¥ h√¨nh R-CNN H√¨nh b√™n d∆∞·ªõi m√¥ t·∫£ benchmark c·ªßa c√°c m√¥ h√¨nh d·∫´n xu·∫•t t·ª´ R-CNN, ta th·∫•y Faster R-CNN c√≥ t·ªëc ƒë·ªô t·ªët nh·∫•t.\nRegion-based Fully Convolutional Networks Gi·∫£ s·ª≠ ch√∫ng ta ch·ªâ c√≥ to·∫° ƒë·ªô c·ªßa m·∫Øt ph·∫£i trong khu√¥n m·∫∑t, ch√∫ng ta c√≥ th·ªÉ n·ªôi suy ra ƒë∆∞·ª£c v·ªã tr√≠ c·ªßa khu√¥n m·∫∑t. V√¨ ta bi·∫øt r·∫±ng m·∫Øt ph·∫£i n·∫±m ·ªü v·ªã tr√≠ tr√°i tr√°i trong b·ª©c h√¨nh, v√† ta t·ª´ ƒë√≥ suy ra v·ªã tr√≠ c·ªßa c√°c ph·∫ßn c√≤n l·∫°i (xem h√¨nh).\nN·∫øu ch√∫ng ta c√≥ th√™m th√¥ng tin kh√°c, v√≠ nh∆∞ to·∫° ƒë·ªô c·ªßa m·∫Øt tr√°i, m≈©i, mi·ªáng, \u0026hellip; th√¨ ch√∫ng ta c√≥ th·ªÉ k·∫øt h·ª£p ch√∫ng ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c c·ªßa ph√¢n v√πng khu√¥n m·∫∑t.\nTrong Faster R-CNN, ch√∫ng ta ph·∫£i t√¨m proposal s·ª≠ d·ª•ng m·ªôt m√¥ h√¨nh CNN, v·ªõi kho·∫£ng 2000 ROI, ch√∫ng ta s·∫Ω ti√™u t·ªën m·ªôt kho·∫£ng th·ªùi gian kh√° l·ªõn ƒë·ªÉ t√¨m ch√∫ng.\n1feature_maps = process(image) 2ROIs = region_proposal(feature_maps) 3for ROI in ROIs 4 patch = roi_pooling(feature_maps, ROI) 5 class_scores, box = detector(patch) # Expensive, slow 6 class_probabilities = softmax(class_scores) Trong khi ƒë√≥, v·ªõi Fast R-CNN, ch√∫ng ta ch·ªâ c·∫ßn ph·∫£i t√≠nh max ho·∫∑c average, n√™n Fast R-CNN nhanh h∆°n Faster R-CNN ·ªü ƒë√¢y.\n1feature_maps = process(image) 2ROIs = region_proposal(feature_maps) 3score_maps = compute_score_map(feature_maps) 4for ROI in ROIs 5 V = region_roi_pool(score_maps, ROI) 6 class_scores, box = average(V) # Much simpler, faster. 7 class_probabilities = softmax(class_scores) X√©t feature map M c√≥ k√≠ch th∆∞·ªõc 5x5, trong ƒë√≥ c√≥ ch·ª©a m·ªôt h√¨nh vu√¥ng m√†u xanh, h√¨nh vu√¥ng xanh l√† ƒë·ªëi t∆∞·ª£ng th·ª±c t·∫ø ta c·∫ßn t√¨m.\nTa chia h√¨nh vu√¥ng th√†nh ph√¢n v√πng c√≥ k√≠ch th∆∞·ªõc 3x3 (h√¨nh 2). Sau ƒë√≥, ch√∫ng ta t·∫°o m·ªôt feature m·ªõi ƒë·ªÉ t·ª´ M ƒë·ªÉ t√¨m ra g√≥c tr√°i tr√™n c·ªßa h√¨nh vu√¥ng (ch·ªâ t√¨m g√≥c tr√°i tr√™n) (h√¨nh 3). Feature map m·ªõi gi·ªëng h√¨nh th·ª© 3, ch·ªâ c√≥ √¥ ƒë∆∞·ª£c t√¥ m√†u v√†ng ·ªü v·ªã tr√≠ [2,2] ƒë∆∞·ª£c b·∫≠t.\nV·ªõi m·ªói 9 ph·∫ßn c·ªßa h√¨nh vu√¥ng, ch√∫ng ta c√≥ 9 feature map cho m·ªói ph·∫ßn, nh·∫≠n d·∫°ng 9 v√πng t∆∞∆°ng ·ª©ng cho m·ªôt ƒë·ªëi t∆∞·ª£ng. Nh·ªØng feature map n√†y ƒë∆∞·ª£c g·ªçi l√† position sensitive score map, b·ªüi v√¨ ch√∫ng detect ra ƒëi·ªÉm (score) v√† sub region c·ªßa m·ªôt ƒë·ªëi t∆∞·ª£ng (Xem h√¨nh b√™n d∆∞·ªõi).\nX√©t ·∫£nh b√™n d∆∞·ªõi, gi·∫£ s·ª≠ v√πng ƒë∆∞·ª£c t√¥ g·∫°ch ƒë·ªè l√† proposal (h√¨nh 1). Ch√∫ng ta c≈©ng chia n√≥ th√†nh nh·ªØng ph√¢n v√πng con c√≥ k√≠ch th∆∞·ªõc 3x3 (h√¨nh 2). V√† t√¨m xem m·ª©c ƒë·ªô gi·ªëng nhau c·ªßa m·ªói v√πng con c·ªßa proposal v√† v√πng con c·ªßa feature map nh∆∞ th·∫ø n√†o. K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o m·ªôt ma tr·∫≠n 3x3 nh∆∞ h√¨nh s·ªë 3.\nQu√° tr√¨nh √°nh x·∫° ƒëi·ªÉm t·ª´ score maps v√† ROIS v√†o m·∫£ng vote_array ƒë∆∞·ª£c g·ªçi l√† position sensitive ROI pool.\nSau khi t√≠nh to√°n h·∫øt c√°c gi√° tr·ªã c·ªßa position-sensitive ROI pool, ch√∫ng ta s·∫Ω t√≠nh trung b√¨nh c·ªßa vote_array ƒë·ªÉ l·∫•y ƒëi·ªÉm c·ªßa l·ªõp (class score).\nGi·∫£ s·ª≠ m√¥ h√¨nh ch√∫ng ta ph·∫£i nh·∫≠n d·∫°ng k l·ªõp, do c√≥ th√™m l·ªõp background n√™n ch√∫ng ta c√≥ t·ªïng c·ªông k+1 l·ªõp. V·ªõi m·ªói l·ªõp ch√∫ng ta c√≥ 3x3 score map, suy ra ch√∫ng ta c√≥ t·ªïng c·ªông l√† (k+1)x3x3 score maps, (k+1) ƒëi·ªÉm, v√† d√πng softmax ta s·∫Ω thu ƒë∆∞·ª£c x√°c su·∫•t c·ªßa m·ªói l·ªõp.\nLu·ªìng d·ªØ li·ªáu c·ªßa m√¥ h√¨nh\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\nB√†i vi·∫øt ƒë∆∞·ª£c l∆∞·ª£c d·ªãch v√† tham kh·∫£o t·ª´ ngu·ªìn https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9\n","date":"Dec 5, 2018","img":"","permalink":"/blog/2018-12-05-what-do-we-learn-from-object-detection-p1/","series":null,"tags":["Machine learning","Deeplearning","object detector","region base"],"title":"T√¨m Hi·ªÉu Region Based Object Detectors"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu D·∫´n nh·∫≠p Ph√¢n t√≠ch d·ªØ li·ªáu Th·ª±c h√†nh X√¢y d·ª±ng t·∫≠p ƒë·∫∑c tr∆∞ng ƒê·∫∑c tr∆∞ng s·∫£n ph·∫©m ƒê·∫∑c tr∆∞ng ng∆∞·ªùi d√πng ƒê·∫∑c tr∆∞ng m·ªëi t∆∞∆°ng quan gi·ªØa ng∆∞·ªùi d√πng v√† s·∫£n ph·∫©m B·ªï sung th√™m ƒë·∫∑c tr∆∞ng Hu·∫•n luy·ªán m√¥ h√¨nh L·ªùi m·ªü ƒë·∫ßu Instacart l√† m·ªôt startup cung ·ª©ng ƒë·ªì t·∫°p h√≥a qua website v√† ·ª©ng d·ª•ng di ƒë·ªông. Ng∆∞·ªùi d√πng ch·ªâ c·∫ßn ch·ªçn ƒë·ªì mu·ªën mua t·∫°i c√°c chu·ªói b√°n l·∫ª v√† ƒë·∫∑t ƒë·ªì, Instacart s·∫Ω ƒëi mua v√† giao ƒë·∫øn t·∫≠n tay h·ªç. ƒê·∫øn nay, Instacart ho·∫°t ƒë·ªông t·∫°i 15.000 c·ª≠a h√†ng t·∫°p ho√° t·∫°i 4.000 th√†nh ph·ªë v·ªõi kho·∫£ng 50.000 ‚Äútr·ª£ l√Ω mua s·∫Øm‚Äù. Team data science c·ªßa instacart ƒë√≥ng vai tr√≤ r·∫•t quan tr·ªçng trong vi·ªác cung c·∫•p tr·∫£i nghi·ªám ng∆∞·ªùi d√πng trong vi·ªác s·ª≠ d·ª•ng app ƒë·ªÉ mua h√†ng. Hi·ªán t·∫°i, h·ªç ƒëang s·ª≠ d·ª•ng c√°c d·ªØ li·ªáu c·ªßa kh√°ch h√†ng ƒë·ªÉ t·∫°o n√™n m√¥ h√¨nh d·ª± ƒëo√°n s·∫£n ph·∫©m n√†o ng∆∞·ªùi d√πng s·∫Ω mua l·∫°i, s·∫Ω mua th·ª≠ l·∫ßn ƒë·∫ßu ti√™n, ho·∫∑c s·∫Ω th√™m v√†o gi·ªè h√†ng. Hi·ªán h·ªç ƒë√£ publish kho·∫£ng 3 tri·ªáu ƒë∆°n h√†ng c·ªßa h·ªç ƒë·ªÉ c√°c nh√† khoa h·ªçc d·ªØ li·ªáu kh√°c s·ª≠ d·ª•ng v√† nghi√™n c·ª©u.\nD·∫´n nh·∫≠p Ph√¢n t√≠ch d·ªØ li·ªáu C√°c b·∫°n c√≥ th·ªÉ download d·ªØ li·ªáu ·ªü https://www.instacart.com/datasets/grocery-shopping-2017.\nC√°c file bao g·ªìm:\nFile aisles.csv (134 d√≤ng) c√≥ 2 c·ªôt l√† aisle_id,aisle\n1aisle_id,aisle 21,prepared soups salads 32,specialty cheeses 43,energy granola bars 5 ... File departments.csv (21 d√≤ng) g·ªìm 2 c·ªôt l√† department_id,department\n1department_id,department 21,frozen 32,other 43,bakery 5 ... File order_products__(prior|train).csv (tr√™n 30 tri·ªáu d√≤ng)\nT·∫≠p n√†y ch·ª©a danh s√°ch s·∫£n ph·∫©m ƒë∆∞·ª£c mua trong m·ªói ƒë∆°n h√†ng. File order_products__prior.csv ch·ª©a s·∫£n ph·∫©m c·ªßa ƒë∆°n h√†ng tr∆∞·ªõc ƒë√≥ c·ªßa kh√°ch h√†ng. \u0026lsquo;reordered\u0026rsquo; n√≥i r·∫±ng s·∫£n ph·∫©m n√†y trong ƒë∆°n h√†ng hi·ªán t·∫°i ƒë√£ ƒë∆∞·ª£c mua ·ªü ƒë∆°n h√†ng tr∆∞·ªõc ƒë√≥. V√¨ v·∫≠y, s·∫Ω c√≥ ƒë∆°n h√†ng kh√¥ng ƒë∆∞·ª£c g√°n l√† \u0026lsquo;reordered\u0026rsquo; (ch√∫ng ta c√≥ th·ªÉ g√°n nh√£n l√† None ho·∫∑c c√°i g√¨ ƒë√≥ c≈©ng ƒë∆∞·ª£c ƒë·ªÉ ch·ªâ c√°c s·∫£n ph·∫©m n√†y). \u0026lsquo;add_to_cart_order\u0026rsquo; l√† th·ª© t·ª± c·ªßa sp ƒë∆∞·ª£c th√™m v√†o gi·ªè h√†ng.\n1order_id,product_id,add_to_cart_order,reordered 2 1,49302,1,1 3 1,11109,2,1 4 1,10246,3,0 5 ... File orders.csv (3.4 tri·ªáu d√≤ng, 206k users): ch·ª©a th√¥ng tin c·ªßa ƒë∆°n h√†ng, trong ƒë√≥, order_dow l√† ng√†y trong tu·∫ßn, eval_set thu·ªôc m·ªôt trong 3 lo·∫°i l√† prior, train, test. order_number l√† th·ª© t·ª± c·ªßa ƒë∆°n h√†ng c·ªßa user n√†y.\n1order_id,user_id,eval_set,order_number,order_dow,order_hour_of_day,days_since_prior_order 2 2539329,1,prior,1,2,08, 3 2398795,1,prior,2,3,07,15.0 4 473747,1,prior,3,3,12,21.0 5 ... File products.csv ((50k d√≤ng) ch·ª©a th√¥ng tin s·∫£n ph·∫©m:\n1 product_id,product_name,aisle_id,department_id 2 1,Chocolate Sandwich Cookies,61,19 3 2,All-Seasons Salt,104,13 4 3,Robust Golden Unsweetened Oolong Tea,94,7 5 ... V·ªõi m·ªói order_id trong t·∫≠p test ·ªü file orders.csv, ch√∫ng ta ph·∫£i d·ª± ƒëo√°n c√°c s·∫£n ph·∫©m n√†o ng∆∞·ªùi d√πng s·∫Ω mua l·∫°i (\u0026ldquo;reorder\u0026rdquo;) thu·ªôc ƒë∆°n h√†ng ƒë√≥. N·∫øu b·∫°n d·ª± ƒëo√°n ƒë√≥ l√† ƒë∆°n h√†ng kh√¥ng c√≥ s·∫£n ph·∫©m n√†o ƒë∆∞·ª£c mua l·∫°i, th√¨ ta s·∫Ω ƒëi·ªÅn v√†o gi√° tr·ªã \u0026lsquo;None\u0026rsquo;\nV√≠ d·ª• v·ªÅ k·∫øt qu·∫£ d·ª± ƒëo√°n:\n1order_id,products 217,1 2 334,None 4137,1 2 3 Th·ª±c h√†nh ƒê·∫ßu ti√™n, ta s·∫Ω import m·ªôt s·ªë th∆∞ vi·ªán c∆° b·∫£n ƒë·ªÉ s·ª≠ d·ª•ng, v√† load t·∫•t c·∫£ c√°c file l√™n. L∆∞u √Ω m·ªôt ch√∫t l√† ·ªü ƒë√¢y, m√¨nh ƒë·ªÉ t·∫•t c·∫£ c√°c file trong th∆∞ m·ª•c data\n1import pandas as pd 2import numpy as np 3from collections import OrderedDict 4 5from sklearn.linear_model import LogisticRegression 6from sklearn.metrics import f1_score 7 8from sklearn import metrics, cross_validation 9from sklearn.metrics import f1_score 10from sklearn.preprocessing import MinMaxScaler 11 12#Import the files 13aisles_df = pd.read_csv(\u0026#39;data/aisles.csv\u0026#39;) 14products_df = pd.read_csv(\u0026#39;data/products.csv\u0026#39;) 15orders_df = pd.read_csv(\u0026#39;data/orders.csv\u0026#39;) 16order_products_prior_df = pd.read_csv(\u0026#39;data/order_products__prior.csv\u0026#39;) 17departments_df = pd.read_csv(\u0026#39;data/departments.csv\u0026#39;) 18order_products_train_df = pd.read_csv(\u0026#39;data/order_products__train.csv\u0026#39;) Sau ƒë√≥, m√¨nh s·∫Ω merge ƒë∆°n h√†ng v√†o chi ti·∫øt ƒë∆°n h√†ng c·ªßa t·∫≠p train v√† t·∫≠p prior\n1order_products_train_df = order_products_train_df.merge(orders_df.drop(\u0026#39;eval_set\u0026#39;, axis=1), on=\u0026#39;order_id\u0026#39;) 2order_products_prior_df = order_products_prior_df.merge(orders_df.drop(\u0026#39;eval_set\u0026#39;, axis=1), on=\u0026#39;order_id\u0026#39;) show ra 5 d√≤ng ƒë·∫ßu ti√™n c·ªßa order_products_train_df\n1print(order_products_train_df.head()) 1 order_id product_id add_to_cart_order reordered user_id order_number order_dow order_hour_of_day days_since_prior_order 20 1 49302 1 1 112108 4 4 10 9.0 31 1 11109 2 1 112108 4 4 10 9.0 42 1 10246 3 0 112108 4 4 10 9.0 53 1 49683 4 0 112108 4 4 10 9.0 64 1 43633 5 1 112108 4 4 10 9.0 7 8[5 rows x 9 columns] T·ªïng c·ªông m√¨nh c√≥ 9 c·ªôt, √Ω nghƒ©a c√°c c·ªôt m√¨nh c√≥ gi·∫£i th√≠ch ·ªü tr√™n r·ªìi nha.\nTi·∫øp theo, ch√∫ng ta t·∫°o t·∫≠p t·∫≠p d·ªØ li·ªáu ƒë·∫øm s·ªë l∆∞·ª£ng s·∫£n ph·∫©m c·ªßa t·ª´ng ng∆∞·ªùi mua\n1user_product_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;],as_index=False) 2 .agg({\u0026#39;order_id\u0026#39;:\u0026#39;count\u0026#39;}) 3 .rename(columns={\u0026#39;order_id\u0026#39;:\u0026#39;user_product_total_orders\u0026#39;})) 4 5train_ids = order_products_train_df[\u0026#39;user_id\u0026#39;].unique() 6df_X = user_product_df[user_product_df[\u0026#39;user_id\u0026#39;].isin(train_ids)] 7print(df_X.head()) 1 product_id user_id user_product_total_orders 20 1 138 2 31 1 709 1 43 1 777 1 56 1 1052 2 69 1 1494 3 ·ªû ƒë√¢y, ng∆∞·ªùi 138 mua s·∫£n ph·∫©m 1 2 l·∫ßn, ng∆∞·ªùi 709 mua s·∫£n ph·∫©m 1 1 l·∫ßn, \u0026hellip; t∆∞∆°ng t·ª± nh∆∞ v·∫≠y cho c√°c user v√† product kh√°c.\nB∆∞·ªõc ti·∫øp theo, ch√∫ng ta s·∫Ω li·ªát k√™ c√°c s·∫£n ph·∫©m ng∆∞·ªùi d√πng ƒë√£ mua:\n1train_carts = (order_products_train_df.groupby(\u0026#39;user_id\u0026#39;,as_index=False) 2 .agg({\u0026#39;product_id\u0026#39;:(lambda x: set(x))}) 3 .rename(columns={\u0026#39;product_id\u0026#39;:\u0026#39;latest_cart\u0026#39;})) print(train_carts.head())\n1 user_id latest_cart 20 1 {196, 26405, 27845, 46149, 13032, 39657, 26088... 31 2 {24838, 11913, 45066, 31883, 48523, 38547, 248... 42 5 {40706, 21413, 20843, 48204, 21616, 19057, 201... 53 7 {17638, 29894, 47272, 45066, 13198, 37999, 408... 64 8 {27104, 15937, 5539, 41540, 31717, 48230, 2224... M·ªëi t∆∞∆°ng quan gi·ªØa s·∫£n ph·∫©m ƒë∆∞·ª£c add to card v√† s·∫£n ph·∫©m ƒë∆∞·ª£c mua\n1df_X = df_X.merge(train_carts, on=\u0026#39;user_id\u0026#39;) 2df_X[\u0026#39;in_cart\u0026#39;] = (df_X.apply(lambda row: row[\u0026#39;product_id\u0026#39;] in row[\u0026#39;latest_cart\u0026#39;], axis=1).astype(int)) 3 4print(df_X.head()) 5 6print(df_X[\u0026#39;in_cart\u0026#39;].value_counts()) 1# df_X.head() 2 product_id user_id user_product_total_orders latest_cart in_cart 30 1 138 2 {42475} 0 41 907 138 2 {42475} 0 52 1000 138 1 {42475} 0 63 3265 138 1 {42475} 0 74 4913 138 1 {42475} 0 8 9# df_X[\u0026#39;in_cart\u0026#39;].value_counts() 100 7645837 111 828824 12Name: in_cart, dtype: int64 T·ª∑ l·ªá kho·∫£ng 9.7%. ƒêi·ªÅu n√†y n√≥i l√™n r·∫±ng, ng∆∞·ªùi d√πng trong 1 phi√™n mua h√†ng c√≥ th·ªÉ add r·∫•t nhi·ªÅu s·∫£n ph·∫©m v√†o gi·ªè, nh∆∞ng ch·ªâ kho·∫£ng 10% s·∫£n ph·∫©m h·ªç mua th·∫≠t s·ª±, h∆°n 90% s·∫£n ph·∫©m c√≤n l·∫°i s·∫Ω b·ªã remove tr∆∞·ªõc khi n·ªç nh·∫•n n√∫t thanh to√°n.\nX√¢y d·ª±ng t·∫≠p ƒë·∫∑c tr∆∞ng ƒê·∫∑c tr∆∞ng s·∫£n ph·∫©m V·ªõi ƒë·∫∑c tr∆∞ng s·∫£n ph·∫©m, ch√∫ng ta s·∫Ω r√∫t tr√≠ch 2 ƒë·∫∑c tr∆∞ng ƒë∆°n gi·∫£n l√† t·ªïng s·ªë l∆∞·ª£ng ƒë∆°n h√†ng c·ªßa m·ªôt s·∫£n ph·∫©m v√† trung b√¨nh s·ªë l∆∞·ª£ng ƒë∆°n h√†ng c√≥ ch·ª©a s·∫£n ph·∫©m.\n1prod_features = [\u0026#39;product_total_orders\u0026#39;,\u0026#39;product_avg_add_to_cart_order\u0026#39;] 2 3prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;],as_index=False) 4 .agg(OrderedDict( 5 [(\u0026#39;order_id\u0026#39;,\u0026#39;nunique\u0026#39;), 6 (\u0026#39;add_to_cart_order\u0026#39;,\u0026#39;mean\u0026#39;)]))) 7prod_features_df.columns = [\u0026#39;product_id\u0026#39;] + prod_features 8print(prod_features_df.head()) 1 2 product_id product_total_orders product_avg_add_to_cart_order 30 1 1852 5.801836 41 2 90 9.888889 52 3 277 6.415162 63 4 329 9.507599 74 5 15 6.466667 Add th√™m ƒë·∫∑c tr∆∞ng s·∫£n ph·∫©m v√†o trong t·∫≠p hu·∫•n luy·ªán\n1 2df_X = df_X.merge(prod_features_df, on=\u0026#39;product_id\u0026#39;) 3 4#note that dropping rows with NA product_avg_days_since_prior_order is likely a naive choice 5df_X = df_X.dropna() 6print(df_X.head()) 1 product_id user_id ... product_total_orders product_avg_add_to_cart_order 20 1 138 ... 1852 5.801836 31 1 709 ... 1852 5.801836 42 1 777 ... 1852 5.801836 53 1 1052 ... 1852 5.801836 64 1 1494 ... 1852 5.801836 ƒê·∫∑c tr∆∞ng ng∆∞·ªùi d√πng V·ªõi ng∆∞·ªùi d√πng, ch√∫ng sa s·ª≠ d·ª•ng c√°c ƒë·∫∑c tr∆∞ng l√†: T·ªïng s·ªë l∆∞·ª£ng ƒë∆°n h√†ng, trung b√¨nh s·ªë s·∫£n ph·∫©m trong 1 ƒë∆°n h√†ng, t·ªïng s·ªë l∆∞·ª£ng s·∫£n ph·∫©m ng∆∞·ªùi d√πng mua, Trung b√¨nh s·ªë ng√†y user s·∫Ω mua ƒë∆°n h√†ng ti·∫øp theo\n1user_features = [\u0026#39;user_total_orders\u0026#39;,\u0026#39;user_avg_cartsize\u0026#39;,\u0026#39;user_total_products\u0026#39;,\u0026#39;user_avg_days_since_prior_order\u0026#39;] 2 3user_features_df = (order_products_prior_df.groupby([\u0026#39;user_id\u0026#39;],as_index=False) 4 .agg(OrderedDict( 5 [(\u0026#39;order_id\u0026#39;,[\u0026#39;nunique\u0026#39;, (lambda x: x.shape[0] / x.nunique())]), 6 (\u0026#39;product_id\u0026#39;,\u0026#39;nunique\u0026#39;), 7 (\u0026#39;days_since_prior_order\u0026#39;,\u0026#39;mean\u0026#39;)]))) 8 9user_features_df.columns = [\u0026#39;user_id\u0026#39;] + user_features 10print(user_features_df.head()) V√† ch√∫ng ta merge ti·∫øp ƒë·∫∑c tr∆∞ng user v√†o trong t·∫≠p hu·∫•n luy·ªán.\n1 2df_X = df_X.merge(user_features_df, on=\u0026#39;product_id\u0026#39;) 3 4#note that dropping rows with NA product_avg_days_since_prior_order is likely a naive choice 5df_X = df_X.dropna() ƒê·∫∑c tr∆∞ng m·ªëi t∆∞∆°ng quan gi·ªØa ng∆∞·ªùi d√πng v√† s·∫£n ph·∫©m ·ªû ƒë√¢y, ch√∫ng ta s·ª≠ d·ª•ng ƒë·∫∑c tr∆∞ng trung b√¨nh s·ªë s·∫£n ph·∫©m c·ªßa 1 ng∆∞·ªùi ƒë∆∞·ª£c th√™m v√†o ƒë∆°n h√†ng v√† t·∫ßn su·∫•t 1 s·∫£n ph·∫©m 1 user add v√†o ƒë∆°n h√†ng.\n1user_prod_features = [\u0026#39;user_product_avg_add_to_cart_order\u0026#39;] 2 3user_prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;],as_index=False) \\ 4 .agg(OrderedDict( 5 [(\u0026#39;add_to_cart_order\u0026#39;,\u0026#39;mean\u0026#39;)]))) 6 7user_prod_features_df.columns = [\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;] + user_prod_features 8df_X = df_X.merge(user_prod_features_df,on=[\u0026#39;user_id\u0026#39;,\u0026#39;product_id\u0026#39;]) 9df_X[\u0026#39;user_product_order_freq\u0026#39;] = df_X[\u0026#39;user_product_total_orders\u0026#39;] / df_X[\u0026#39;user_total_orders\u0026#39;] B·ªï sung th√™m ƒë·∫∑c tr∆∞ng Ngo√†i c√°c ƒë·∫∑c tr∆∞ng c∆° b·∫£n ·ªü tr√™n, ta s·∫Ω b·ªï sung th√™m m·ªôt s·ªë ƒë·∫∑c tr∆∞ng kh√°c:\nƒê·∫∑c tr∆∞ng s·∫£n ph·∫©m: b·ªï sung th√™m 3 ƒë·∫∑c tr∆∞ng trung b√¨nh ng√†y trong tu·∫ßn ƒë∆∞·ª£c ƒë·∫∑t h√†ng (c·ªôt order_down), trung b√¨nh gi·ªù ƒë·∫∑t h√†ng (c·ªôt order_hour_of_day), trung b√¨nh ng√†y ƒë·∫∑t h√†ng k·ªÉ t·ª´ l·∫ßn ƒë·∫∑t tr∆∞·ªõc ƒë√≥ (c·ªôt days_since_prior_order) theo s·∫£n ph·∫©m.\n1prod_features = [\u0026#39;product_avg_order_dow\u0026#39;, \u0026#39;product_avg_order_hour_of_day\u0026#39;, \u0026#39;product_avg_days_since_prior_order\u0026#39;] 2 3prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;], as_index=False) 4 .agg(OrderedDict( 5 [(\u0026#39;order_dow\u0026#39;,\u0026#39;mean\u0026#39;), 6 (\u0026#39;order_hour_of_day\u0026#39;, \u0026#39;mean\u0026#39;), 7 (\u0026#39;days_since_prior_order\u0026#39;, \u0026#39;mean\u0026#39;)]))) 8 9prod_features_df.columns = [\u0026#39;product_id\u0026#39;] + prod_features 10 11df_X = df_X.merge(prod_features_df, on=\u0026#39;product_id\u0026#39;) 12df_X = df_X.dropna() ƒê·∫∑c tr∆∞ng ng∆∞·ªùi d√πng: b·ªï sung th√™m 2 c·ªôt ƒë·∫∑c trung trung b√¨nh ng√†y trong tu·∫ßn ƒë∆∞·ª£c ƒë·∫∑t h√†ng (c·ªôt order_down) v√† trung b√¨nh gi·ªù ƒë·∫∑t h√†ng (c·ªôt order_hour_of_day) theo ng∆∞·ªùi d√πng\n1user_features = [\u0026#39;user_avg_order_dow\u0026#39;,\u0026#39;user_avg_order_hour_of_day\u0026#39;] 2 3user_features_df = (order_products_prior_df.groupby([\u0026#39;user_id\u0026#39;],as_index=False) 4 .agg(OrderedDict( 5 [(\u0026#39;order_dow\u0026#39;,\u0026#39;mean\u0026#39;), 6 (\u0026#39;order_hour_of_day\u0026#39;,\u0026#39;mean\u0026#39;)]))) 7 8user_features_df.columns = [\u0026#39;user_id\u0026#39;] + user_features 9df_X = df_X.merge(user_features_df, on=\u0026#39;user_id\u0026#39;) 10df_X = df_X.dropna() ƒê·∫∑c trung ng∆∞·ªùi d√πng - s·∫£n ph·∫©m: B·ªï sung th√™m ƒë·∫∑c tr∆∞ng tung b√¨nh tr√™n c·ªôt order_down, order_hour_of_day, days_since_prior_order theo ng∆∞·ªùi d√πng v√† s·∫£n ph·∫©m\n1 2user_prod_features = [\u0026#39;user_product_avg_days_since_prior_order\u0026#39;, 3 \u0026#39;user_product_avg_order_dow\u0026#39;, 4 \u0026#39;user_product_avg_order_hour_of_day\u0026#39;] 5 6user_prod_features_df = (order_products_prior_df.groupby([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;],as_index=False) \\ 7 .agg(OrderedDict( 8 [(\u0026#39;days_since_prior_order\u0026#39;,\u0026#39;mean\u0026#39;), 9 (\u0026#39;order_dow\u0026#39;,\u0026#39;mean\u0026#39;), 10 (\u0026#39;order_hour_of_day\u0026#39;,\u0026#39;mean\u0026#39;)]))) 11 12user_prod_features_df.columns = [\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;] + user_prod_features 13 14df_X = df_X.merge(user_prod_features_df, on=[\u0026#39;user_id\u0026#39;, \u0026#39;product_id\u0026#39;]) 15df_X = df_X.dropna() ƒê·∫∑c tr∆∞ng ƒë·ªô l·ªách: T√≠nh ƒë·ªô l·ªách c·ªßa c·ªßa m·ªôt s·ªë ƒë·∫∑c tr∆∞ng so v·ªõi trung b√¨nh c·ªßa ch√∫ng\n1#Create delta columns to compare how users perform against averages 2df_X[\u0026#39;product_total_orders_delta_per_user\u0026#39;] = df_X[\u0026#39;product_total_orders\u0026#39;] - df_X[\u0026#39;user_product_total_orders\u0026#39;] 3 4df_X[\u0026#39;product_avg_add_to_cart_order_delta_per_user\u0026#39;] = df_X[\u0026#39;product_avg_add_to_cart_order\u0026#39;] - \\ 5 df_X[\u0026#39;user_product_avg_add_to_cart_order\u0026#39;] 6 7df_X[\u0026#39;product_avg_order_dow_per_user\u0026#39;] = df_X[\u0026#39;product_avg_order_dow\u0026#39;] - df_X[\u0026#39;user_product_avg_order_dow\u0026#39;] 8 9df_X[\u0026#39;product_avg_order_hour_of_day_per_user\u0026#39;] = df_X[\u0026#39;product_avg_order_hour_of_day\u0026#39;] - \\ 10 df_X[\u0026#39;user_product_avg_order_hour_of_day\u0026#39;] 11 12df_X[\u0026#39;product_avg_days_since_prior_order_per_user\u0026#39;] = df_X[\u0026#39;product_avg_days_since_prior_order\u0026#39;] - \\ 13 df_X[\u0026#39;user_product_avg_days_since_prior_order\u0026#39;] B·ªï sung th√™m ƒë·∫∑c tr∆∞ng department name\n1f_departments_df = products_df.merge(departments_df, on = \u0026#39;department_id\u0026#39;) 2f_departments_df = f_departments_df[[\u0026#39;product_id\u0026#39;, \u0026#39;department\u0026#39;]] 3 4df_X = df_X.merge(f_departments_df, on = \u0026#39;product_id\u0026#39;) 5df_X = df_X.dropna() 6df_X = pd.concat([df_X, pd.get_dummies(df_X[\u0026#39;department\u0026#39;])], axis=1) 7del df_X[\u0026#39;department\u0026#39;] Ch√∫ng ta c√≥ t·ªïng c·ªông 21 department name, v·∫≠y ch√∫ng ta th√™m 21 c·ªôt, m·ªôt c·ªôt t∆∞∆°ng ·ª©ng v·ªõi m·ªôt department name, v√≠ d·ª•: alcohol,babies ,bakery, \u0026hellip; S·∫£n ph·∫©m thu·ªôc department name th√¨ s·∫Ω ƒë∆∞·ª£c ƒë√°nh s·ªë 1, kh√¥ng thu·ªôc department name th√¨ ƒë√°nh s·ªë 0.\nHu·∫•n luy·ªán m√¥ h√¨nh Chia t·∫≠p d·ªØ li·ªáu th√†nh 80/20 trong ƒë√≥ 80% l√† t·∫≠p train, 20% l√† t·∫≠p test. S·ª≠ d·ª•ng k-fold-cross_validation v·ªõi k=10\n1 2np.random.seed(99) 3total_users = df_X[\u0026#39;user_id\u0026#39;].unique() 4test_users = np.random.choice(total_users, size=int(total_users.shape[0] * .20), replace=False) 5 6 7 8test_user_sets = [] 9length = len(test_users) 10cv = 10 11 12 13for x in range (0, cv): 14 start = int(x/cv*length) 15 finish = int((x+1)/cv*length) 16 test_user_sets.append(test_users[start:finish]) 17 18cv_f1_scores = [] 19cv_f1_scores_balanced = [] 20cv_f1_scores_10fit = [] 21 22for test_user_set in test_user_sets: 23 df_X_tr, df_X_te = df_X[~df_X[\u0026#39;user_id\u0026#39;].isin(test_user_set)], df_X[df_X[\u0026#39;user_id\u0026#39;].isin(test_user_set)] 24 25 y_tr, y_te = df_X_tr[\u0026#39;in_cart\u0026#39;], df_X_te[\u0026#39;in_cart\u0026#39;] 26 X_tr, X_te = df_X_tr.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 27 df_X_te.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 28 29 scaler = MinMaxScaler() 30 X_tr = pd.DataFrame(scaler.fit_transform(X_tr), columns=X_tr.columns) 31 X_te = pd.DataFrame(scaler.fit_transform(X_te), columns=X_te.columns) 32 33 lr = LogisticRegression(C=10000000) 34 lr_balanced = LogisticRegression(class_weight=\u0026#39;balanced\u0026#39;, C=10000000) 35 lr_10x = LogisticRegression(class_weight={1 : 6, 0 : 1}, C=10000000) 36 37 lr.fit(X_tr, y_tr) 38 cv_f1_scores.append(f1_score(lr.predict(X_te), y_te)) 39 40 lr_balanced.fit(X_tr, y_tr) 41 cv_f1_scores_balanced.append(f1_score(lr_balanced.predict(X_te), y_te)) 42 43 lr_10x.fit(X_tr, y_tr) 44 cv_f1_scores_10fit.append(f1_score(lr_10x.predict(X_te), y_te)) 45 46print(\u0026#34;cv_f1_scores: \u0026#34; +str( np.mean(cv_f1_scores))) 47print(\u0026#34;cv_f1_scores_balanced: \u0026#34;+str(np.mean(cv_f1_scores_balanced))) 48print(\u0026#34;cv_f1_scores_10fit: \u0026#34;+str(np.mean(cv_f1_scores_10fit))) 49 50df_X_tr, df_X_te = df_X[~df_X[\u0026#39;user_id\u0026#39;].isin(test_users)], df_X[df_X[\u0026#39;user_id\u0026#39;].isin(test_users)] 51 52y_tr, y_te = df_X_tr[\u0026#39;in_cart\u0026#39;], df_X_te[\u0026#39;in_cart\u0026#39;] 53X_tr, X_te = df_X_tr.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 54 df_X_te.drop([\u0026#39;product_id\u0026#39;,\u0026#39;user_id\u0026#39;,\u0026#39;latest_cart\u0026#39;,\u0026#39;in_cart\u0026#39;],axis=1), \\ 55 56lr_10x = LogisticRegression(class_weight={1 : 6, 0 : 1}, C=10000000) 57lr_10x.fit(X_tr, y_tr) 58print(\u0026#34;F1 store all: \u0026#34;+str(f1_score(lr_10x.predict(X_te), y_te))) 1cv_f1_scores: 0.2026889989037295 2cv_f1_scores_balanced: 0.3816810646496983 3cv_f1_scores_10fit: 0.3899595078917494 4 5F1 store all: 0.3808374055616213 Th·ª≠ in ra h·ªá s·ªë c·ªßa h√†m h·ªìi quy\n1coefficients = pd.DataFrame(lr_10x.coef_, columns = X_tr.columns) 2coefficients = np.exp(coefficients) 3print(coefficients.T) 1user_product_total_orders 1.160475 2product_total_orders 1.077254 3product_avg_add_to_cart_order 0.915343 4user_total_orders 0.983272 5user_avg_cartsize 1.059655 6user_total_products 0.993839 7user_avg_days_since_prior_order 0.993513 8user_product_avg_add_to_cart_order 0.950418 9user_product_order_freq 1.051246 10product_avg_order_dow 0.994744 11product_avg_order_hour_of_day 1.010971 12product_avg_days_since_prior_order 0.994498 13user_avg_order_dow 0.997298 14user_avg_order_hour_of_day 1.012958 15user_product_avg_days_since_prior_order 1.003382 16user_product_avg_order_dow 0.994477 17user_product_avg_order_hour_of_day 1.003457 18product_total_orders_delta_per_user 0.928288 19product_avg_add_to_cart_order_delta_per_user 0.963095 20product_avg_order_dow_per_user 1.000268 21product_avg_order_hour_of_day_per_user 1.007489 22product_avg_days_since_prior_order_per_user 0.991147 23alcohol 0.998866 24babies 1.000313 25bakery 1.003098 26beverages 1.007733 27breakfast 1.000117 28bulk 0.999980 29canned goods 0.995017 30dairy eggs 1.018069 31deli 1.002720 32dry goods pasta 0.997379 33frozen 1.000752 34household 0.992164 35international 0.996822 36meat seafood 1.000340 37missing 1.001953 38other 0.999607 39pantry 0.972038 40personal care 0.992072 41pets 1.000466 42produce 1.017809 43snacks 1.004893 Th·ª≠ show confusion matrix c·ªßa d·ªØ li·ªáu:\n1from sklearn.metrics import confusion_matrix 2import seaborn as sns 3import matplotlib.pyplot as plt 4%matplotlib inline 5plt.style.use(\u0026#39;fivethirtyeight\u0026#39;) 6 7def plot_confusion_matrix(cm,title=\u0026#39;Confusion matrix\u0026#39;, cmap=plt.cm.Reds): 8 plt.imshow(cm, interpolation=\u0026#39;nearest\u0026#39;,cmap=cmap) 9 plt.title(title) 10 plt.colorbar() 11 plt.tight_layout() 12 plt.ylabel(\u0026#39;True label\u0026#39;) 13 plt.xlabel(\u0026#39;Predicted label\u0026#39;) 14 15#y_tr=np.ravel(y_tr) 16 17train_acc=lr_10x.score(X_tr, y_tr) 18test_acc=lr_10x.score(X_te, y_te) 19print(\u0026#34;Training Data Accuracy: %0.2f\u0026#34; %(train_acc)) 20print(\u0026#34;Test Data Accuracy: %0.2f\u0026#34; %(test_acc)) 21 22y_true = y_te 23y_pred = lr_10x.predict(X_te) 24 25 26conf = confusion_matrix(y_true, y_pred) 27print(conf) 28 29print (\u0026#39;\\n\u0026#39;) 30print (\u0026#34;Precision: %0.2f\u0026#34; %(conf[1, 1] / (conf[1, 1] + conf[0, 1]))) 31print (\u0026#34;Recall: %0.2f\u0026#34;% (conf[1, 1] / (conf[1, 1] + conf[1, 0]))) 32 33cm=confusion_matrix(y_true, y_pred, labels=[0, 1]) 34 35plt.figure() 36plot_confusion_matrix(cm) K·∫øt qu·∫£\n1Training Data Accuracy: 0.83 2Test Data Accuracy: 0.83 3[[1236979 190126] 4 [ 78107 82493]] 5 6 7Precision: 0.30 8Recall: 0.51 Show ƒë∆∞·ªùng cong ROC c·ªßa d·ªØ li·ªáu\n1 2from sklearn.metrics import roc_curve, auc 3 4y_score = lr_10x.predict_proba(X_te)[:,1] 5 6fpr, tpr,_ = roc_curve(y_te, y_score) 7roc_auc = auc(fpr, tpr) 8 9plt.figure() 10# Plotting our Baseline.. 11plt.plot([0,1],[0,1], linestyle=\u0026#39;--\u0026#39;, color = \u0026#39;black\u0026#39;) 12plt.plot(fpr, tpr, color = \u0026#39;green\u0026#39;) 13plt.xlabel(\u0026#39;False Positive Rate\u0026#39;) 14plt.ylabel(\u0026#39;True Positive Rate\u0026#39;) 15plt.gca().set_aspect(\u0026#39;equal\u0026#39;, adjustable=\u0026#39;box\u0026#39;) C·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Nov 13, 2018","img":"","permalink":"/blog/2018-11-13-instacart-market-basket-analysis/","series":null,"tags":["Machine learning","Deeplearning","instacart","Gi·ªè h√†ng","ƒê∆°n h√†ng"],"title":"Ph√¢n T√≠ch Gi·ªè H√†ng C·ªßa Website Instacart"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu D·∫´n nh·∫≠p Ph√¢n t√≠ch d·ªØ li·ªáu Scale d·ªØ li·ªáu Ph√¢n chia t·∫≠p train v√† test. X√¢y d·ª±ng m√¥ h√¨nh s·ª≠ d·ª•ng keras L·ªùi m·ªü ƒë·∫ßu ·ªû b√†i vi·∫øt n√†y, m√¨nh s·∫Ω x√¢y d·ª±ng m√¥ h√¨nh h∆°n gi·∫£n ƒë·ªÉ √°p d·ª•ng v√†o t·∫≠p d·ªØ li·ªáu gi√° ch·ª©ng kho√°ng. M·ª•c ti√™u c·ªßa b√†i n√†y l√† ch√∫ng ta s·∫Ω d·ª± ƒëo√°n ch·ªâ s·ªë S\u0026amp;P 500 s·ª≠ d·ª•ng LSTM. C√°c b·∫°n c√≥ nhu c·∫ßu t√¨m hi·ªÉu th√™m v·ªÅ ch·ªâ s·ªë sp 500 c√≥ th·ªÉ ƒë·ªçc th√™m ·ªü https://vi.wikipedia.org/wiki/S%26P_500. ƒê√¢y l√† m·ªôt ·ª©ng d·ª•ng nh·ªè, kh√¥ng c√≥ √Ω nghƒ©a nhi·ªÅu ·ªü th·ª±c t·∫ø do khi ph√¢n t√≠ch ch·ª©ng kho√°n, ta c√≤n x√©t th√™m r·∫•t nhi·ªÅu y·∫øu t·ªë ph·ª• n·ªØa. M√¥ h√¨nh n√†y th·ª±c ch·∫•t ch·ªâ l√† m·ªôt trong nh·ªØng m√¥ h√¨nh ch∆°i ch∆°i.\nD·∫´n nh·∫≠p Ph√¢n t√≠ch d·ªØ li·ªáu C√°c b·∫°n c√≥ th·ªÉ download d·ªØ li·ªáu ·ªü https://github.com/AlexBlack2202/alexmodel/blob/master/GSPC.csv\nƒê·∫ßu ti√™n, nh∆∞ th∆∞·ªùng l·ªá, ch√∫ng ta s·∫Ω import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt ƒë·ªÉ s·ª≠ d·ª•ng.\n1import numpy as np # linear algebra 2import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) 3 4from subprocess import check_output 5from keras.layers.core import Dense, Activation, Dropout 6from keras.layers.recurrent import LSTM 7from keras.models import Sequential 8from sklearn.cross_validation import train_test_split 9import time #helper libraries 10from sklearn.preprocessing import MinMaxScaler 11import matplotlib.pyplot as plt 12from numpy import newaxis ƒê·ªçc d·ªØ li·ªáu l√™n:\n1 2file_name =\u0026#39;GSPC.csv\u0026#39; 3 4prices_dataset = pd.read_csv(file_name, header=0) 5 6`` 7 8Xem k√≠ch th∆∞·ªõc c·ªßa d·ªØ li·ªáu: 9 10```python 11print(prices_dataset.shape) 1(17114, 7) K·∫øt qu·∫£ l√† ta c√≥ 17114 ng√†n d√≤ng v√† 7 c·ªôt. Th·ª≠ show 10 row ƒë·∫ßu ti√™n c·ªßa d·ªØ li·ªáu l√™n xem nh∆∞ th·∫ø n√†o.\n1print(prices_dataset.head()) 1 Date Open High Low Close Adj Close Volume 20 1950-11-09 19.790001 19.790001 19.790001 19.790001 19.790001 1760000 31 1950-11-10 19.940001 19.940001 19.940001 19.940001 19.940001 1640000 42 1950-11-13 20.010000 20.010000 20.010000 20.010000 20.010000 1630000 53 1950-11-14 19.860001 19.860001 19.860001 19.860001 19.860001 1780000 64 1950-11-15 19.820000 19.820000 19.820000 19.820000 19.820000 1620000 C·ªôt ƒë·∫ßu ti√™n l√† ng√†y, sau ƒë√≥ l√† gi√° m·ªü c·ª≠a, gi√° giao d·ªãch cao nh·∫•t, gi√° giao d·ªãch th·∫•p nh√¢t, gi√° ƒë√≥ng c·ª≠, gi√° ƒë√≥ng c·ª≠a ƒë√£ ƒëi·ªÅu ch·ªânh, kh·ªëi l∆∞·ª£ng giao d·ªãch.\nPlot ƒë·ªì th·ªã c·ªßa m√£ SP500 l√™n:\n1import matplotlib.pyplot as plt 2 3plt.plot(prices_dataset.Open.values, color=\u0026#39;red\u0026#39;, label=\u0026#39;open\u0026#39;) 4plt.plot(prices_dataset.Close.values, color=\u0026#39;green\u0026#39;, label=\u0026#39;close\u0026#39;) 5plt.plot(prices_dataset.Low.values, color=\u0026#39;blue\u0026#39;, label=\u0026#39;low\u0026#39;) 6plt.plot(prices_dataset.High.values, color=\u0026#39;black\u0026#39;, label=\u0026#39;high\u0026#39;) 7plt.title(\u0026#39;stock price\u0026#39;) 8plt.xlabel(\u0026#39;time [days]\u0026#39;) 9plt.ylabel(\u0026#39;price\u0026#39;) 10plt.legend(loc=\u0026#39;best\u0026#39;) 11plt.show() H√¨nh v·ªõi s·ªë l∆∞·ª£ng h∆°i nhi·ªÅu n√™n kh√≥ ph√¢n bi·ªát ƒë∆∞·ª£c gi√° tr·ªã c·ªßa d·ªØ li·ªáu, ch√∫ng ta th·ª≠ show ƒë·ªì th·ªã c·ªßa 50 ng√†y cu·ªëi c√πng trong d·ªØ li·ªáu.\n1prices_dataset_tail_50 = prices_dataset.tail(50) 2 3plt.plot(prices_dataset_tail_50.Open.values, color=\u0026#39;red\u0026#39;, label=\u0026#39;open\u0026#39;) 4plt.plot(prices_dataset_tail_50.Close.values, color=\u0026#39;green\u0026#39;, label=\u0026#39;close\u0026#39;) 5plt.plot(prices_dataset_tail_50.Low.values, color=\u0026#39;blue\u0026#39;, label=\u0026#39;low\u0026#39;) 6plt.plot(prices_dataset_tail_50.High.values, color=\u0026#39;black\u0026#39;, label=\u0026#39;high\u0026#39;) 7plt.title(\u0026#39;stock price\u0026#39;) 8plt.xlabel(\u0026#39;time [days]\u0026#39;) 9plt.ylabel(\u0026#39;price\u0026#39;) 10plt.legend(loc=\u0026#39;best\u0026#39;) 11plt.show() H√¨nh ·∫£nh tr√¥ng kh√° r√µ r√†ng v√† tr·ª±c quan h∆°n r·∫•t nhi·ªÅu.\nCh√∫ng ta s·∫Ω b·ªè ƒëi c·ªôt DATE,Adj Close,Volume ƒëi. C√°c c·ªôt ƒë√≥ kh√¥ng c·∫ßn thi·∫øt cho qu√° tr√¨nh d·ª± ƒëo√°n.\n1 2prices_dataset_dropout = prices_dataset.drop([\u0026#39;Date\u0026#39;,\u0026#39;Adj Close\u0026#39;,\u0026#39;Volume\u0026#39;], 1) Scale d·ªØ li·ªáu Khi s·ª≠ d·ª•ng ANN, ch√∫ng ta th√¥ng th∆∞·ªùng s·∫Ω scale d·ªØ li·ªáu input v·ªÅ ƒëo·∫°n [-1,1]. Trong python, th∆∞ vi·ªán sklearn ƒë√£ h·ªó tr·ª£ cho ch√∫ng ta s·∫µn c√°c h√†m scale d·ªØ li·ªáu c·∫ßn thi·∫øt.\n1# Scale data 2def normalize_data(df): 3 min_max_scaler = MinMaxScaler() 4 df[\u0026#39;Open\u0026#39;] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1)) 5 df[\u0026#39;High\u0026#39;] = min_max_scaler.fit_transform(df.High.values.reshape(-1,1)) 6 df[\u0026#39;Low\u0026#39;] = min_max_scaler.fit_transform(df.Low.values.reshape(-1,1)) 7 df[\u0026#39;Close\u0026#39;] = min_max_scaler.fit_transform(df.Close.values.reshape(-1,1)) 8 return df 9 10prices_dataset_norm = normalize_data(prices_dataset_dropout) Ph√¢n chia t·∫≠p train v√† test. Ch√∫ng ta s·∫Ω chia d·ªØ li·ªáu th√†nh 2 ph·∫ßn v·ªõi 80% l√† train v√† 20% c√≤n l·∫°i l√† test. Ch·ªçn seq_len=20, c√°c b·∫°n c√≥ th·ªÉ test v·ªõi c√°c seq len kh√°c, v√† sau ƒë√≥ chuy·ªÉn d·ªØ li·ªáu v·ªÅ d·∫°ng numpy array ƒë·ªÉ d·ªÖ d√†ng th·ª±c hi·ªán c√°c ph√©p chuy·ªÉn ƒë·ªïi.\n1 2def generate_data(stock_ds, seq_len): 3 data_raw = stock_ds.as_matrix() 4 data = [] 5 6 # create all possible sequences of length seq_len 7 for index in range(len(data_raw) - seq_len): 8 data.append(data_raw[index: index + seq_len]) 9 return data 10 11#data as numpy array 12def generate_train_test(data_ds,split_percent=0.8): 13 print(len(data_ds)) 14 data = np.asarray(data_ds) 15 16 data_size = len(data) 17 train_end = int(np.floor(split_percent*data_size)) 18 19 x_train = data[:train_end,:-1,:] 20 y_train = data[:train_end,-1,:] 21 22 23 24 x_test = data[train_end:,:-1,:] 25 y_test = data[train_end:,-1,:] 26 27 return [x_train, y_train, x_test, y_test] 28 29 30 31seq_len = 20 # choose sequence length 32 33seq_prices_dataset = generate_data(prices_dataset_norm,seq_len) 34 35x_train, y_train, x_test, y_test = generate_train_test(seq_prices_dataset, 0.8) 36 37print(\u0026#39;x_train.shape = \u0026#39;,x_train.shape) 38print(\u0026#39;y_train.shape = \u0026#39;, y_train.shape) 39print(\u0026#39;x_test.shape = \u0026#39;, x_test.shape) 40print(\u0026#39;y_test.shape = \u0026#39;,y_test.shape) K·∫øt qu·∫£:\n1x_train.shape = (13675, 19, 4) 2y_train.shape = (13675, 4) 3x_test.shape = (3419, 19, 4) 4y_test.shape = (3419, 4) X√¢y d·ª±ng m√¥ h√¨nh s·ª≠ d·ª•ng keras ·ªû ƒë√¢y m√¨nh s·ª≠ d·ª•ng keras x√¢y d·ª±ng m√¥ h√¨nh ANN. M√¥ h√¨nh c·ªßa m√¨nh x√¢y d·ª±ng g·ªìm:\n1model = Sequential() 2 3model.add(LSTM( 4 input_dim=4, 5 output_dim=50, 6 return_sequences=True)) 7model.add(Dropout(0.2)) 8 9model.add(LSTM( 10 100, 11 return_sequences=False)) 12model.add(Dropout(0.2)) 13 14model.add(Dense( 15 output_dim=4)) 16model.add(Activation(\u0026#39;linear\u0026#39;)) 17 18 19 20model.compile(loss=\u0026#39;mean_squared_error\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) 21checkpoint = ModelCheckpoint(filepath=\u0026#39;sp500_stockperdict.h5\u0026#39;, verbose=1, save_best_only=True) 22hist = model.fit(x_train, y_train, epochs=300, batch_size=128, verbose=1, callbacks=[checkpoint], validation_split=0.2) Sau m·ªôt th·ªùi gian ch·∫°y, m√¨nh c≈©ng thu ƒë∆∞·ª£c model. C√°c b·∫°n quan t√¢m c√≥ th·ªÉ download model c·ªßa m√¨nh hu·∫•n luy·ªán ƒë∆∞·ª£c t·∫°i https://drive.google.com/open?id=1ImHQM9yWmOjpF5tjmSI9oqAi5BORa9Rs . Ti·∫øn h√†nh plot d·ªØ li·ªáu t·∫≠p test l√™n xem k·∫øt qu·∫£ nh∆∞ th·∫ø n√†o.\n1 2model =load_model(\u0026#39;sp500_stockperdict.h5\u0026#39;) 3 4 5y_hat = model.predict(x_test) 6 7ft = 3 # 0 = open, 1 = highest, 2 =lowest , 3 = close 8 9plt.plot( y_test[:,ft], color=\u0026#39;blue\u0026#39;, label=\u0026#39;target\u0026#39;) 10 11plt.plot( y_hat[:,ft], color=\u0026#39;red\u0026#39;, label=\u0026#39;prediction\u0026#39;) 12 13plt.title(\u0026#39;future stock prices\u0026#39;) 14plt.xlabel(\u0026#39;time [days]\u0026#39;) 15plt.ylabel(\u0026#39;normalized price\u0026#39;) 16plt.legend(loc=\u0026#39;best\u0026#39;) 17 18plt.show() 19 20from sklearn.metrics import mean_squared_error 21 22# 0 = open, 1 = highest, 2 =lowest , 3 = close 23print(\u0026#34;open error: \u0026#34;) 24print(mean_squared_error(y_test[:,0], y_hat[ :,0])) 25 26print(\u0026#34;highest error: \u0026#34;) 27print(mean_squared_error(y_test[:,1], y_hat[ :,1])) 28 29print(\u0026#34;lowest error: \u0026#34;) 30print(mean_squared_error(y_test[:,2], y_hat[ :,2])) 31 32print(\u0026#34;close error: \u0026#34;) 33print(mean_squared_error(y_test[:,3], y_hat[ :,3])) 1open error: 20.0009739211460315127 3highest error: 40.0010539412808401607 5lowest error: 60.0010066509540756113 7close error: 80.0010840500965408758 Hi·ªán ƒë√£ c√≥ b·∫£n tensorflow 2 c√≥ t√≠ch h·ª£p keras, m√¨nh update l·∫°i code\n1 2from re import T 3import numpy as np 4# linear algebra 5import pandas as pd 6from tensorflow.keras.models import Sequential 7from tensorflow.keras.layers import Dense 8from tensorflow.keras.layers import LSTM 9from sklearn.preprocessing import MinMaxScaler 10import tensorflow as tf 11import joblib 12 13import matplotlib 14matplotlib.use(\u0026#39;TkAgg\u0026#39;) 15import matplotlib.pyplot as plt 16 17 18file_name =\u0026#39;GSPC.csv\u0026#39; 19 20 21prices_dataset = pd.read_csv(file_name, header=0) 22 23 24# prices_dataset_dropout = prices_dataset.drop([\u0026#39;Date\u0026#39;,\u0026#39;Adj Close\u0026#39;,\u0026#39;Volume\u0026#39;], 1) 25prices_dataset_dropout=prices_dataset.reset_index()[\u0026#39;Close\u0026#39;] 26 27 28scaler=MinMaxScaler(feature_range=(0,1)) 29prices_dataset_norm=scaler.fit_transform(np.array(prices_dataset_dropout).reshape(-1,1)) 30joblib.dump(scaler, \u0026#39;scaler.alex\u0026#39;) 31 32 33print(prices_dataset_norm[:10]) 34 35 36def generate_data(stock_ds, seq_len,predict_next_t): 37 dataX, dataY = [], [] 38 for i in range(len(stock_ds)-seq_len-1): 39 dataX.append(stock_ds[i:(i+seq_len)]) 40 dataY.append(stock_ds[i + seq_len+predict_next_t]) 41 return np.array(dataX), np.array(dataY) 42 43#data as numpy array 44def generate_train_test(data_x,data_y,split_percent=0.8): 45 46 train_end = int(np.floor(split_percent*data_x.shape[0])) 47 48 x_train,x_test=data_x[:train_end,:],data_x[train_end:,:] 49 y_train,y_test = data_y[:train_end],data_y[train_end:] 50 return x_train,y_train,x_test,y_test 51 52 53 54seq_len = 100 # choose sequence length 55predict_next_t = 1 # 0 is next date, 1 is 2 next date 56 57data_x, data_y = generate_data(prices_dataset_norm,seq_len,predict_next_t) 58 59x_train,y_train,x_test,y_test = generate_train_test(data_x,data_y, 0.8) 60 61 62x_train =x_train.reshape(x_train.shape[0],x_train.shape[1] , 1) 63x_test = x_test.reshape(x_test.shape[0],x_test.shape[1] , 1) 64print(\u0026#39;x_train.shape = \u0026#39;,x_train.shape) 65print(\u0026#39;y_train.shape = \u0026#39;, y_train.shape) 66print(\u0026#39;x_test.shape = \u0026#39;, x_test.shape) 67print(\u0026#39;y_test.shape = \u0026#39;,y_test.shape) 68 69 70 71model = Sequential() 72 73 # input_dim=4, 74 # output_dim=50, 75model.add(LSTM(units=100,input_shape=x_train.shape[1:], 76 return_sequences=True)) 77 78model.add(LSTM( 79 100, 80 return_sequences=False)) 81model.add(Dense(1)) 82 83 84model.compile(loss=\u0026#39;mean_squared_error\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) 85checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=\u0026#39;my_model_stock.h5\u0026#39;, verbose=1, save_best_only=True) 86hist = model.fit(x_train, y_train, epochs=3, batch_size=64, verbose=1, callbacks=[checkpoint], validation_split=0.2) 87 88from tensorflow.keras.models import load_model 89print(\u0026#39;load model\u0026#39;) 90model =load_model(\u0026#39;my_model_stock.h5\u0026#39;) 91 92print(\u0026#39;predict\u0026#39;) 93y_test = y_test.reshape(y_test.shape[0]) 94# train_predict=model.predict(x_train) 95test_predict=model.predict(x_test) 96print(\u0026#39;invert\u0026#39;) 97print(y_test.shape) 98# train_predict=scaler.inverse_transform(train_predict) 99 100# scaler = joblib.load(\u0026#39;scaler.alex\u0026#39;) 101 102y_hat=scaler.inverse_transform(test_predict) 103y_test=scaler.inverse_transform(y_test.reshape(-1, 1)) 104print(y_hat.shape) 105# y_hat = model.predict(x_test) 106# import matplotlib 107# matplotlib.use(\u0026#39;GTKAgg\u0026#39;) 108# print(\u0026#39;plot\u0026#39;) 109 110plt.plot( y_test, color=\u0026#39;blue\u0026#39;, label=\u0026#39;target\u0026#39;) 111 112plt.plot( y_hat, color=\u0026#39;red\u0026#39;, label=\u0026#39;prediction\u0026#39;) 113print(\u0026#39;plot complete\u0026#39;) 114plt.title(\u0026#39;future stock prices\u0026#39;) 115plt.xlabel(\u0026#39;time [days]\u0026#39;) 116plt.ylabel(\u0026#39;normalized price\u0026#39;) 117plt.legend(loc=\u0026#39;best\u0026#39;) 118print(\u0026#39;plot show\u0026#39;) 119plt.savefig(\u0026#34;mygraph.png\u0026#34;) 120plt.show() K·∫øt qu·∫£ c·ªßa m√¥ h√¨nh tr√¥ng kh√° t·ªët, v·ªÅ h√¨nh d·∫°ng th√¨ kh√° t∆∞∆°ng ƒë·ªìng v·ªõi k·∫øt qu·∫£. Ch√∫ng ta c√≥ th·ªÉ c·∫£i ti·∫øn model b·∫±ng c√°ch n√¢ng s·ªë l∆∞·ª£ng layer/ hidden node.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Nov 10, 2018","img":"","permalink":"/blog/2018-11-10-stock-prediction_lsmt/","series":null,"tags":["Machine learning","Deeplearning","stock prediction","ch·ª©ng kho√°n"],"title":"D·ª± ƒêo√°n Gi√° Ch·ª©ng Kho√°n SP500 S·ª≠ D·ª•ng LSTM"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu D·∫´n nh·∫≠p Ph√¢n t√≠ch d·ªØ li·ªáu Ph√¢n chia t·∫≠p train v√† test. Scale d·ªØ li·ªáu X√¢y d·ª±ng m√¥ h√¨nh s·ª≠ d·ª•ng keras L·ªùi m·ªü ƒë·∫ßu ·ªû b√†i vi·∫øt n√†y, m√¨nh s·∫Ω x√¢y d·ª±ng m√¥ h√¨nh h∆°n gi·∫£n ƒë·ªÉ √°p d·ª•ng v√†o t·∫≠p d·ªØ li·ªáu gi√° ch·ª©ng kho√°n. M·ª•c ti√™u c·ªßa b√†i n√†y l√† ch√∫ng ta s·∫Ω d·ª± ƒëo√°n ch·ªâ s·ªë S\u0026amp;P 500 d·ª±a tr√™n ch·ªâ s·ªë c·ªßa 500 m√£ ch·ª©ng kho√°n. C√°c b·∫°n c√≥ nhu c·∫ßu t√¨m hi·ªÉu th√™m v·ªÅ ch·ªâ s·ªë sp 500 c√≥ th·ªÉ ƒë·ªçc th√™m ·ªü https://vi.wikipedia.org/wiki/S%26P_500. ƒê√¢y l√† m·ªôt ·ª©ng d·ª•ng nh·ªè, kh√¥ng c√≥ √Ω nghƒ©a nhi·ªÅu ·ªü th·ª±c t·∫ø do khi ph√¢n t√≠ch ch·ª©ng kho√°n, ta c√≤n x√©t th√™m r·∫•t nhi·ªÅu y·∫øu t·ªë ph·ª• n·ªØa. M√¥ h√¨nh n√†y th·ª±c ch·∫•t ch·ªâ l√† m·ªôt trong nh·ªØng m√¥ h√¨nh ch∆°i ch∆°i.\nD·∫´n nh·∫≠p Ph√¢n t√≠ch d·ªØ li·ªáu C√°c b·∫°n c√≥ th·ªÉ download d·ªØ li·ªáu ·ªü https://drive.google.com/open?id=1UTlj5Ced-yj6RBRVc6bBM6IWMjfQR3GR.\nƒê·∫ßu ti√™n, ch√∫ng ta s·∫Ω d√πng pandas ƒë·ªÉ load m√¥ h√¨nh l√™n:\n1import pandas as pd 2 3# Import data 4data = pd.read_csv(\u0026#39;data_stocks.csv\u0026#39;) Xem k√≠ch th∆∞·ªõc c·ªßa d·ªØ li·ªáu:\n1print(data.shape) 1(41266, 502) K·∫øt qu·∫£ l√† ta c√≥ h∆°n 40 ng√†n d√≤ng v√† 502 c·ªôt. Th·ª≠ show 10 row ƒë·∫ßu ti√™n c·ªßa d·ªØ li·ªáu l√™n xem nh∆∞ th·∫ø n√†o.\n1print(data.head()) 1 DATE SP500 NASDAQ.AAL NASDAQ.AAPL NASDAQ.ADBE NASDAQ.ADI \\ 20 1491226200 2363.6101 42.3300 143.6800 129.6300 82.040 31 1491226260 2364.1001 42.3600 143.7000 130.3200 82.080 42 1491226320 2362.6799 42.3100 143.6901 130.2250 82.030 53 1491226380 2364.3101 42.3700 143.6400 130.0729 82.000 64 1491226440 2364.8501 42.5378 143.6600 129.8800 82.035 7 8 NASDAQ.ADP NASDAQ.ADSK NASDAQ.AKAM NASDAQ.ALXN ... NYSE.WYN \\ 90 102.2300 85.2200 59.760 121.52 ... 84.370 101 102.1400 85.6500 59.840 121.48 ... 84.370 112 102.2125 85.5100 59.795 121.93 ... 84.585 123 102.1400 85.4872 59.620 121.44 ... 84.460 134 102.0600 85.7001 59.620 121.60 ... 84.470 14 15 NYSE.XEC NYSE.XEL NYSE.XL NYSE.XOM NYSE.XRX NYSE.XYL NYSE.YUM \\ 160 119.035 44.40 39.88 82.03 7.36 50.22 63.86 171 119.035 44.11 39.88 82.03 7.38 50.22 63.74 182 119.260 44.09 39.98 82.02 7.36 50.12 63.75 193 119.260 44.25 39.99 82.02 7.35 50.16 63.88 204 119.610 44.11 39.96 82.03 7.36 50.20 63.91 21 22 NYSE.ZBH NYSE.ZTS 230 122.000 53.350 241 121.770 53.350 252 121.700 53.365 263 121.700 53.380 274 121.695 53.240 C·ªôt ƒë·∫ßu ti√™n l√† ng√†y, sau ƒë√≥ l√† m√£ ch·ª©ng kho√°n. Ch√∫ng ta c√≥ t·ªïng c·ªông 500 m√£ ch·ª©ng kho√°n v√† 1 ch·ªâ s·ªë. ƒê·ªÉ √Ω c·ªôt Date, ta th·∫•y gi√° tr·ªã ƒë·∫ßu ti√™n l√† 1491226200, gi√° tr·ªã th·ª© 2 l√† 1491226260, gi√° tr·ªã th·ª© 3 l√† 1491226320, m·ªói gi√° tr·ªã c√°ch nhau 60. Chuy·ªÉn ƒë·ªïi s·ªë 1491226200 sang d·∫°ng datetime th√¨ ra gi√° tr·ªã Monday, April 3, 2017 1:30:00 PM gi·ªù GMT, t∆∞∆°ng t·ª± s·ªë 1491226260 ra Monday, April 3, 2017 1:31:00 PM gi·ªù GMT. Ta c√≥ th·ªÉ suy lu·∫≠n ra l√† gi√° tr·ªã giao d·ªãch l∆∞u theo t·ª´ng ph√∫t m·ªôt (kho·∫£ng interval l√† 60 gi√¢y), v√† d·ªØ li·ªáu ch√∫ng ta c√≥ b·∫Øt ƒë·∫ßu v√†o 3 th√°ng 4 nƒÉm 2017.\nPlot ƒë·ªì th·ªã c·ªßa m√£ SP500 l√™n:\n1import matplotlib.pyplot as plt 2 3plt.plot(data[\u0026#39;SP500\u0026#39;]) 4plt.show() 1Notes: ·ªû ƒë√¢y c√≥ m·ªôt l∆∞u √Ω nh·ªè nh∆∞ng r·∫•t quan tr·ªçng. ƒê√≥ l√† t·∫°i th·ªùi ƒëi·ªÉm ph√∫t th·ª© t l∆∞u tr·ªØ gi√° tr·ªã sp500 c·ªßa th·ªùi ƒëi·ªÉm ph√∫t th·ª© t+1. V√≠ d·ª• v·ªõi ch·ªâ s·ªë sp500, d√≤ng ƒë·∫ßu ti√™n ta th·∫•y l√† 1491226200 2363.6101, nghƒ©a l√† gi√° th·ª±c t·∫ø c·ªßa th·ªùi ƒëi·ªÉm 1491226260 l√† 2363.6101. Do b√†i to√°n c·ªßa ch√∫ng ta l√† d·ªØ ƒëo√°n gi√° t∆∞∆°ng l·∫°i, n√™n t·∫°i th·ªùi ƒëi·ªÉm hi·ªán t·∫°i ta s·∫Ω d·ª± ƒëo√°n gi√° 1 ph√∫t sau s·∫Ω b·∫±ng bao nhi√™u. V√† t·∫≠p d·ªØ li·ªáu ƒë√£ t·ª± ƒë·ªông d·ªãch chuy·ªÉn gi√° tr·ªã l√™n 1 ph√∫t cho ch√∫ng ta ƒë·ª° m·∫•t c√¥ng l√†m. C√≤n gi√° c·ªßa 500 c·ªó phi·∫øu c√≤n l·∫°i v·∫´n l√† gi√° t·∫°i th·ªùi ƒëi·ªÉm t Ph√¢n chia t·∫≠p train v√† test. Ch√∫ng ta s·∫Ω chia d·ªØ li·ªáu th√†nh 2 ph·∫ßn v·ªõi 80% l√† train v√† 20% c√≤n l·∫°i l√† test. Do t√≠ch ch·∫•t c·ªßa d·ªØ li·ªáu l√† time serial n√™n ch√∫ng ta kh√¥ng th·ªÉ l√†m thay ƒë·ªïi th·ª© t·ª± d·ªØ li·ªáu.\nCh√∫ng ta s·∫Ω b·ªè ƒëi c·ªôt DATE ƒë·∫ßu ti√™n, v√† sau ƒë√≥ chuy·ªÉn d·ªØ li·ªáu v·ªÅ d·∫°ng numpy array ƒë·ªÉ d·ªÖ d√†ng th·ª±c hi·ªán c√°c ph√©p chuy·ªÉn ƒë·ªïi.\n1data_ = data_raw.drop([\u0026#39;DATE\u0026#39;], 1) 2 3data = data_.values 4# Training and test data 5train_start = 0 6train_end = int(np.floor(0.8*n)) 7test_start = train_end 8test_end = n 9data_train = data[ :train_end] 10data_test = data[train_end:] Scale d·ªØ li·ªáu Khi s·ª≠ d·ª•ng ANN, ch√∫ng ta th√¥ng th∆∞·ªùng s·∫Ω scale d·ªØ li·ªáu input v·ªÅ ƒëo·∫°n [-1,1]. Trong python, th∆∞ vi·ªán sklearn ƒë√£ h·ªó tr·ª£ cho ch√∫ng ta s·∫µn c√°c h√†m scale d·ªØ li·ªáu c·∫ßn thi·∫øt.\n1# Scale data 2from sklearn.preprocessing import MinMaxScaler 3scaler = MinMaxScaler() 4data_train = scaler.fit_transform(data_train) 5data_test = scaler.transform(data_test) 6# Build X and y 7X_train = data_train[:, 1:] 8y_train = data_train[:, 0] 9X_test = data_test[:, 1:] 10y_test = data_test[:, 0] M√¨nh c·∫ßn d·ª± ƒëo√°n gi√° tr·ªã c·ªßa ch·ªâ s·ªë sp 500, n√™n gi√° tr·ªã c·ªßa sp500 s·∫Ω l√† c√°i m√¨nh c·∫ßn d·ª± ƒëo√°n, ch√≠nh l√† c·ªôt ƒë·∫ßu ti√™n, c√≤n 500 c√°i c√≤n l·∫°i l√† input c·ªßa m√¨nh.\nX√¢y d·ª±ng m√¥ h√¨nh s·ª≠ d·ª•ng keras ·ªû ƒë√¢y m√¨nh s·ª≠ d·ª•ng keras x√¢y d·ª±ng m√¥ h√¨nh ANN. M√¥ h√¨nh c·ªßa m√¨nh x√¢y d·ª±ng g·ªìm\n1from keras.models import Sequential 2from keras.layers.core import Dense, Dropout, Activation 3from keras.callbacks import ModelCheckpoint 4from keras.optimizers import SGD 5 6import os 7os.environ[\u0026#34;CUDA_DEVICE_ORDER\u0026#34;]=\u0026#34;PCI_BUS_ID\u0026#34; 8# The GPU id to use, usually either \u0026#34;0\u0026#34; or \u0026#34;1\u0026#34; 9os.environ[\u0026#34;CUDA_VISIBLE_DEVICES\u0026#34;]=\u0026#34;0\u0026#34; 10# create model 11model = Sequential() 12model.add(Dense(2048, input_dim=input_dim,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 13model.add(Dense(1024,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 14model.add(Dense(512,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 15model.add(Dense(256,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 16model.add(Dense(128,kernel_initializer=\u0026#39;normal\u0026#39;, activation=\u0026#39;relu\u0026#39;)) 17model.add(Dense(1,kernel_initializer=\u0026#39;normal\u0026#39;)) 18 19 20 21model.compile(loss=\u0026#39;mse\u0026#39;, optimizer=\u0026#39;rmsprop\u0026#39;) 22checkpoint = ModelCheckpoint(filepath=\u0026#39;my_model3.h5\u0026#39;, verbose=1, save_best_only=True) 23model.fit(X_train, y_train, epochs=100, batch_size=256, verbose=1, callbacks=[checkpoint], validation_split=0.2) Sau m·ªôt th·ªùi gian ch·∫°y, m√¨nh c≈©ng thu ƒë∆∞·ª£c model. C√°c b·∫°n quan t√¢m c√≥ th·ªÉ download model c·ªßa m√¨nh hu·∫•n luy·ªán ƒë∆∞·ª£c t·∫°i https://drive.google.com/open?id=1BLQZbcADfnLqzIHlkgpsqZBlhljBp1Eb . Ti·∫øn h√†nh plot d·ªØ li·ªáu t·∫≠p test l√™n xem k·∫øt qu·∫£ nh∆∞ th·∫ø n√†o.\n1 2yhat = model.predict(X_test) 3 4 5x = np.arange(len(yhat)) 6 7plt.plot(x, y_test) 8plt.plot(x, yhat) 9plt.legend([\u0026#39;real\u0026#39;, \u0026#39;test\u0026#39;], loc=\u0026#39;upper right\u0026#39;) 10plt.show() 11 12 13from sklearn.metrics import mean_squared_error 14 15print(\u0026#34;mse: \u0026#34;+ str(mean_squared_error(y_test, yhat))) 1mse: 0.0014582120695331884 K·∫øt qu·∫£ c·ªßa m√¥ h√¨nh t·∫°m ch·∫•p nh·∫≠n ƒë∆∞·ª£c, v·ªÅ h√¨nh d·∫°ng th√¨ kh√° t∆∞∆°ng ƒë·ªìng v·ªõi k·∫øt qu·∫£. Ch√∫ng ta c√≥ th·ªÉ c·∫£i ti·∫øn model b·∫±ng c√°ch n√¢ng s·ªë l∆∞·ª£ng layter/ hidden node, ho·∫∑c th√™m dropout. Ho·∫∑c c√≥ th·ªÉ thay th·∫ø m√¥ h√¨nh b·∫±ng RNN. Ch√∫ng ta s·∫Ω ƒë·ªÅ c·∫≠p ƒë·∫øn m√¥ h√¨nh RNN trong b√†i vi·∫øt sau.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Nov 3, 2018","img":"","permalink":"/blog/2018-11-03-stock-prediction/","series":null,"tags":["Machine learning","Deep learning","stock prediction"],"title":"D·ª± ƒêo√°n Ch·ª©ng Kho√°n S·ª≠ D·ª•ng Tensorflow"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu D·∫´n nh·∫≠p L·ªùi m·ªü ƒë·∫ßu Sau khi th·ª±c hi·ªán b√†i ph√¢n lo·∫°i ch√≥ m√®o b·∫±ng keras, m√¨nh ph√°t hi·ªán r·∫±ng keras c√≥ h·ªó tr·ª£ r·∫•t nhi·ªÅu thu·∫≠t to√°n t·ªëi ∆∞u ho√° https://keras.io/optimizers/. Nh√¢n d·ªãp r√£nh r·ªói, m√¨nh s·∫Ω t·ªïng h·ª£p l·∫°i m·ªôt v√†i thu·∫≠t to√°n m√† keras h·ªó tr·ª£.\nD·∫´n nh·∫≠p T·∫°i th·ªùi ƒëi·ªÉm hi·ªán t·∫°i, Gradient descent l√† m·ªôt trong nh·ªØng thu·∫≠t to√°n ph·ªï bi·∫øn ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·ªëi ∆∞u ho√° m·∫°ng neural networks. C√°c th∆∞ vi·ªán DNN s·∫Ω implement k√®m theo m·ªôt v√†i bi·∫øn th·ªÉ c·ªßa gradient descent gi√∫p ng∆∞·ªùi d√πng d·ªÖ d√†ng s·ª≠ d·ª•ng c√¥ng c·ª• h∆°n.\nB√†i vi·∫øt n√†y m√¨nh s·∫Ω c·∫≠p nh·∫≠t d·∫ßn ƒë·∫øn khi ho√†n thi·ªán.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Oct 29, 2018","img":"","permalink":"/blog/2018-11-01-overview-of-gradient-descent-optimization-algorithm/","series":null,"tags":["Machine learning","Deeplearning"],"title":"Overview of Gradient Descent Optimization Algorithm"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu Th·ª±c hi·ªán Qu·∫≠y ph√° m√¥ h√¨nh Qu·∫≠y ph√° 1: M·ªü ƒë√≥ng bƒÉng m·ªôt s·ªë l·ªõp cu·ªëi v√† train tr√™n ch√∫ng. Qu·∫≠y ph√° 2: Ch·ªâ s·ª≠ d·ª•ng 72 l·ªõp ƒë·∫ßu ti√™n c·ªßa inception. L·ªùi m·ªü ƒë·∫ßu B√†i to√°n ph√¢n lo·∫°i ch√≥ m√®o l√† b√†i to√°n kh√° c≈© t·∫°i th·ªùi ƒëi·ªÉm hi·ªán t·∫°i. Tuy nhi√™n, ƒë·ªëi v·ªõi c√°c b·∫°n m·ªõi b∆∞·ªõc ch√¢n v√†o con ƒë∆∞·ªùng machine learning th√¨ ƒë√¢y l√† m·ªôt trong nh·ªØng b√†i to√°n c∆° b·∫£n ƒë·ªÉ c√°c b·∫°n th·ª±c h√†nh s·ª≠ d·ª•ng v√† t√¨m hi·ªÉu th∆∞ vi·ªán m√† m√¨nh ƒëang c√≥. ·ªû ƒë√¢y, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng pretrain model c√≥ s·∫µn c·ªßa kares √°p d·ª•ng tr√™n t·∫≠p d·ªØ li·ªáu. C√°c b·∫°n c√≥ th·ªÉ download t·∫≠p d·ªØ li·ªáu train v√† test ·ªü ƒë·ªãa ch·ªâ https://www.kaggle.com/c/dogs-vs-cats/download/train.zip v√† https://www.kaggle.com/c/dogs-vs-cats/download/test1.zip ƒë·ªÉ b·∫Øt ƒë·∫ßu th·ª±c hi·ªán.\nTh·ª±c hi·ªán Sau khi gi·∫£i n√©n d·ªØ li·ªáu, ta th·∫•y r·∫±ng th∆∞ m·ª•c train c√≥ c·∫•u tr√∫c ƒë·∫∑t tr√™n s·∫Ω l√† label.s·ªë th·ª© t·ª±.jpg. Trong ƒë√≥ label c√≥ th·ªÉ l√† dog ho·∫∑c cat, s·ªë th·ª© t·ª± tƒÉng d·∫ßn t·ª´ 0 ƒë·∫øn \u0026hellip;. 12499. ƒê·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng v·ªõi m√¥ h√¨nh, ta ph·∫£i c·∫•u tr√∫c l·∫°i d·ªØ li·ªáu th√†nh d·∫°ng.\n1data_dir/classname1/*.* 2data_dir/classname2/*.* 3... V√¨ v·∫≠y, ta t·∫°o ra th∆∞ m·ª•c cat v√† copy nh·ªØng file b·∫Øt ƒë·∫ßu b·∫±ng cat.* v√†o th∆∞ m·ª•c cat. L√†m t∆∞∆°ng t·ª± v·ªõi th∆∞ m·ª•c dog.\nƒê·∫ßu ti√™n, c√°c b·∫°n download file pretrain model, gi·∫£i n√©n ra v√† ƒë·ªÉ ·ªü ƒë√¢u ƒë√≥ trong ·ªï c·ª©ng c·ªßa m√°y b·∫°n. ƒê∆∞·ªùng d·∫´n file pretrain model c√°c b·∫°n c√≥ th·ªÉ download ·ªü http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz. C√°c b·∫°n c√≥ th·ªÉ download c√°c file pretrain kh√°c n·∫øu c√≥ h·ª©ng th√∫ t√¨m hi·ªÉu.\nTi·∫øp theo, ch√∫ng ta s·∫Ω load dataset l√™n v√† tranform n√≥ ƒë·ªÉ ƒë∆∞a v√†o hu·∫•n luy·ªán.\n1import sys 2import os 3from collections import defaultdict 4import numpy as np 5import scipy.misc 6 7 8def preprocess_input(x0): 9 x = x0 / 255. 10 x -= 0.5 11 x *= 2. 12 return x 13 14 15def reverse_preprocess_input(x0): 16 x = x0 / 2.0 17 x += 0.5 18 x *= 255. 19 return x 20 21 22def dataset(base_dir, n): 23 print(\u0026#34;base dir: \u0026#34;+base_dir) 24 print(\u0026#34;n: \u0026#34;+str(n)) 25 n = int(n) 26 d = defaultdict(list) 27 for root, subdirs, files in os.walk(base_dir): 28 for filename in files: 29 file_path = os.path.join(root, filename) 30 assert file_path.startswith(base_dir) 31 32 suffix = file_path[len(base_dir):] 33 34 suffix = suffix.lstrip(\u0026#34;/\u0026#34;) 35 suffix = suffix.lstrip(\u0026#34;\\\\\u0026#34;) 36 if(suffix.find(\u0026#39;/\u0026#39;)\u0026gt;-1): #linux 37 label = suffix.split(\u0026#34;/\u0026#34;)[0] 38 else: #window 39 label = suffix.split(\u0026#34;\\\\\u0026#34;)[0] 40 d[label].append(file_path) 41 print(\u0026#34;walk directory complete\u0026#34;) 42 tags = sorted(d.keys()) 43 44 processed_image_count = 0 45 useful_image_count = 0 46 47 X = [] 48 y = [] 49 50 for class_index, class_name in enumerate(tags): 51 filenames = d[class_name] 52 for filename in filenames: 53 processed_image_count += 1 54 if processed_image_count%100 ==0: 55 print(class_name+\u0026#34;\\tprocess: \u0026#34;+str(processed_image_count)+\u0026#34;\\t\u0026#34;+str(len(d[class_name]))) 56 img = scipy.misc.imread(filename) 57 height, width, chan = img.shape 58 assert chan == 3 59 aspect_ratio = float(max((height, width))) / min((height, width)) 60 if aspect_ratio \u0026gt; 2: 61 continue 62 # We pick the largest center square. 63 centery = height // 2 64 centerx = width // 2 65 radius = min((centerx, centery)) 66 img = img[centery-radius:centery+radius, centerx-radius:centerx+radius] 67 img = scipy.misc.imresize(img, size=(n, n), interp=\u0026#39;bilinear\u0026#39;) 68 X.append(img) 69 y.append(class_index) 70 useful_image_count += 1 71 print(\u0026#34;processed %d, used %d\u0026#34; % (processed_image_count, useful_image_count)) 72 73 X = np.array(X).astype(np.float32) 74 #X = X.transpose((0, 3, 1, 2)) 75 X = preprocess_input(X) 76 y = np.array(y) 77 78 perm = np.random.permutation(len(y)) 79 X = X[perm] 80 y = y[perm] 81 82 print(\u0026#34;classes:\u0026#34;,end=\u0026#34; \u0026#34;) 83 for class_index, class_name in enumerate(tags): 84 print(class_name, sum(y==class_index),end=\u0026#34; \u0026#34;) 85 print(\u0026#34;X shape: \u0026#34;,X.shape) 86 87 return X, y, tags ƒêo·∫°n code tr√™n kh√° ƒë∆°n gi·∫£n v√† d·ªÖ hi·ªÉu. L∆∞u √Ω ·ªü ƒë√¢y l√† v·ªõi nh·ªØng b·ª©c ·∫£nh c√≥ t·ª∑ l·ªá width v√† height \u0026gt; 2 th√¨ m√¨nh s·∫Ω lo·∫°i ch√∫ng ra kh·ªèi t·∫≠p d·ªØ li·ªáu.\nTi·∫øp theo, ch√∫ng ta s·∫Ω x√¢y d·ª±ng m√¥ h√¨nh d·ª±a tr√™n m√¥ h√¨nh InceptionV3 c√≥ s·∫µn, th√™m m·ªôt l·ªõp softmax ·ªü cu·ªëi ƒë·ªÉ ph√¢n l·ªõp d·ªØ li·ªáu, ch√∫ng ta s·∫Ω hu·∫•n luy·ªán l·ªõp softmax n√†y. C√°c l·ªõp tr∆∞·ªõc l·ªõp softmax n√†y s·∫Ω b·ªã ƒë√≥ng bƒÉng (kh√¥ng c·∫≠p nh·∫≠t tr·ªçng s·ªë trong qu√° tr√¨nh hu·∫•n luy·ªán ).\n1 2# create the base pre-trained model 3def build_model(nb_classes): 4 base_model = InceptionV3(weights=\u0026#39;imagenet\u0026#39;, include_top=False) 5 6 # add a global spatial average pooling layer 7 x = base_model.output 8 x = GlobalAveragePooling2D()(x) 9 # let\u0026#39;s add a fully-connected layer 10 x = Dense(1024, activation=\u0026#39;relu\u0026#39;)(x) 11 # and a logistic layer 12 predictions = Dense(nb_classes, activation=\u0026#39;softmax\u0026#39;)(x) 13 14 # this is the model we will train 15 model = Model(inputs=base_model.input, outputs=predictions) 16 17 # first: train only the top layers (which were randomly initialized) 18 # i.e. freeze all convolutional InceptionV3 layers 19 for layer in base_model.layers: 20 layer.trainable = False 21 22 # compile the model (should be done *after* setting layers to non-trainable) 23 print(\u0026#34;starting model compile\u0026#34;) 24 compile(model) 25 print(\u0026#34;model compile done\u0026#34;) 26 return model Visualize m·ªôt ch√∫t x√≠u v·ªÅ ki·∫øn tr√∫c inceptionV3 m√¨nh ƒëang d√πng.\n1__________________________________________________________________________________________________ 2Layer (type) Output Shape Param # Connected to 3================================================================================================== 4input_1 (InputLayer) (None, None, None, 3 0 5__________________________________________________________________________________________________ 6conv2d_1 (Conv2D) (None, None, None, 3 864 input_1[0][0] 7__________________________________________________________________________________________________ 8batch_normalization_1 (BatchNor (None, None, None, 3 96 conv2d_1[0][0] 9__________________________________________________________________________________________________ 10activation_1 (Activation) (None, None, None, 3 0 batch_normalization_1[0][0] 11__________________________________________________________________________________________________ 12conv2d_2 (Conv2D) (None, None, None, 3 9216 activation_1[0][0] 13__________________________________________________________________________________________________ 14batch_normalization_2 (BatchNor (None, None, None, 3 96 conv2d_2[0][0] 15__________________________________________________________________________________________________ 16activation_2 (Activation) (None, None, None, 3 0 batch_normalization_2[0][0] 17__________________________________________________________________________________________________ 18conv2d_3 (Conv2D) (None, None, None, 6 18432 activation_2[0][0] 19__________________________________________________________________________________________________ 20batch_normalization_3 (BatchNor (None, None, None, 6 192 conv2d_3[0][0] 21__________________________________________________________________________________________________ 22activation_3 (Activation) (None, None, None, 6 0 batch_normalization_3[0][0] 23__________________________________________________________________________________________________ 24max_pooling2d_1 (MaxPooling2D) (None, None, None, 6 0 activation_3[0][0] 25__________________________________________________________________________________________________ 26conv2d_4 (Conv2D) (None, None, None, 8 5120 max_pooling2d_1[0][0] 27__________________________________________________________________________________________________ 28batch_normalization_4 (BatchNor (None, None, None, 8 240 conv2d_4[0][0] 29__________________________________________________________________________________________________ 30activation_4 (Activation) (None, None, None, 8 0 batch_normalization_4[0][0] 31__________________________________________________________________________________________________ 32conv2d_5 (Conv2D) (None, None, None, 1 138240 activation_4[0][0] 33__________________________________________________________________________________________________ 34batch_normalization_5 (BatchNor (None, None, None, 1 576 conv2d_5[0][0] 35__________________________________________________________________________________________________ 36activation_5 (Activation) (None, None, None, 1 0 batch_normalization_5[0][0] 37__________________________________________________________________________________________________ 38max_pooling2d_2 (MaxPooling2D) (None, None, None, 1 0 activation_5[0][0] 39__________________________________________________________________________________________________ 40conv2d_9 (Conv2D) (None, None, None, 6 12288 max_pooling2d_2[0][0] 41__________________________________________________________________________________________________ 42batch_normalization_9 (BatchNor (None, None, None, 6 192 conv2d_9[0][0] 43__________________________________________________________________________________________________ 44activation_9 (Activation) (None, None, None, 6 0 batch_normalization_9[0][0] 45__________________________________________________________________________________________________ 46conv2d_7 (Conv2D) (None, None, None, 4 9216 max_pooling2d_2[0][0] 47__________________________________________________________________________________________________ 48conv2d_10 (Conv2D) (None, None, None, 9 55296 activation_9[0][0] 49__________________________________________________________________________________________________ 50batch_normalization_7 (BatchNor (None, None, None, 4 144 conv2d_7[0][0] 51__________________________________________________________________________________________________ 52batch_normalization_10 (BatchNo (None, None, None, 9 288 conv2d_10[0][0] 53__________________________________________________________________________________________________ 54activation_7 (Activation) (None, None, None, 4 0 batch_normalization_7[0][0] 55__________________________________________________________________________________________________ 56activation_10 (Activation) (None, None, None, 9 0 batch_normalization_10[0][0] 57__________________________________________________________________________________________________ 58average_pooling2d_1 (AveragePoo (None, None, None, 1 0 max_pooling2d_2[0][0] 59__________________________________________________________________________________________________ 60conv2d_6 (Conv2D) (None, None, None, 6 12288 max_pooling2d_2[0][0] 61__________________________________________________________________________________________________ 62conv2d_8 (Conv2D) (None, None, None, 6 76800 activation_7[0][0] 63__________________________________________________________________________________________________ 64conv2d_11 (Conv2D) (None, None, None, 9 82944 activation_10[0][0] 65__________________________________________________________________________________________________ 66conv2d_12 (Conv2D) (None, None, None, 3 6144 average_pooling2d_1[0][0] 67__________________________________________________________________________________________________ 68batch_normalization_6 (BatchNor (None, None, None, 6 192 conv2d_6[0][0] 69__________________________________________________________________________________________________ 70batch_normalization_8 (BatchNor (None, None, None, 6 192 conv2d_8[0][0] 71__________________________________________________________________________________________________ 72batch_normalization_11 (BatchNo (None, None, None, 9 288 conv2d_11[0][0] 73__________________________________________________________________________________________________ 74batch_normalization_12 (BatchNo (None, None, None, 3 96 conv2d_12[0][0] 75__________________________________________________________________________________________________ 76activation_6 (Activation) (None, None, None, 6 0 batch_normalization_6[0][0] 77__________________________________________________________________________________________________ 78activation_8 (Activation) (None, None, None, 6 0 batch_normalization_8[0][0] 79__________________________________________________________________________________________________ 80activation_11 (Activation) (None, None, None, 9 0 batch_normalization_11[0][0] 81__________________________________________________________________________________________________ 82activation_12 (Activation) (None, None, None, 3 0 batch_normalization_12[0][0] 83__________________________________________________________________________________________________ 84mixed0 (Concatenate) (None, None, None, 2 0 activation_6[0][0] 85 activation_8[0][0] 86 activation_11[0][0] 87 activation_12[0][0] 88__________________________________________________________________________________________________ 89conv2d_16 (Conv2D) (None, None, None, 6 16384 mixed0[0][0] 90__________________________________________________________________________________________________ 91batch_normalization_16 (BatchNo (None, None, None, 6 192 conv2d_16[0][0] 92__________________________________________________________________________________________________ 93activation_16 (Activation) (None, None, None, 6 0 batch_normalization_16[0][0] 94__________________________________________________________________________________________________ 95conv2d_14 (Conv2D) (None, None, None, 4 12288 mixed0[0][0] 96__________________________________________________________________________________________________ 97conv2d_17 (Conv2D) (None, None, None, 9 55296 activation_16[0][0] 98__________________________________________________________________________________________________ 99batch_normalization_14 (BatchNo (None, None, None, 4 144 conv2d_14[0][0] 100__________________________________________________________________________________________________ 101batch_normalization_17 (BatchNo (None, None, None, 9 288 conv2d_17[0][0] 102__________________________________________________________________________________________________ 103activation_14 (Activation) (None, None, None, 4 0 batch_normalization_14[0][0] 104__________________________________________________________________________________________________ 105activation_17 (Activation) (None, None, None, 9 0 batch_normalization_17[0][0] 106__________________________________________________________________________________________________ 107average_pooling2d_2 (AveragePoo (None, None, None, 2 0 mixed0[0][0] 108__________________________________________________________________________________________________ 109conv2d_13 (Conv2D) (None, None, None, 6 16384 mixed0[0][0] 110__________________________________________________________________________________________________ 111conv2d_15 (Conv2D) (None, None, None, 6 76800 activation_14[0][0] 112__________________________________________________________________________________________________ 113conv2d_18 (Conv2D) (None, None, None, 9 82944 activation_17[0][0] 114__________________________________________________________________________________________________ 115conv2d_19 (Conv2D) (None, None, None, 6 16384 average_pooling2d_2[0][0] 116__________________________________________________________________________________________________ 117batch_normalization_13 (BatchNo (None, None, None, 6 192 conv2d_13[0][0] 118__________________________________________________________________________________________________ 119batch_normalization_15 (BatchNo (None, None, None, 6 192 conv2d_15[0][0] 120__________________________________________________________________________________________________ 121batch_normalization_18 (BatchNo (None, None, None, 9 288 conv2d_18[0][0] 122__________________________________________________________________________________________________ 123batch_normalization_19 (BatchNo (None, None, None, 6 192 conv2d_19[0][0] 124__________________________________________________________________________________________________ 125activation_13 (Activation) (None, None, None, 6 0 batch_normalization_13[0][0] 126__________________________________________________________________________________________________ 127activation_15 (Activation) (None, None, None, 6 0 batch_normalization_15[0][0] 128__________________________________________________________________________________________________ 129activation_18 (Activation) (None, None, None, 9 0 batch_normalization_18[0][0] 130__________________________________________________________________________________________________ 131activation_19 (Activation) (None, None, None, 6 0 batch_normalization_19[0][0] 132__________________________________________________________________________________________________ 133mixed1 (Concatenate) (None, None, None, 2 0 activation_13[0][0] 134 activation_15[0][0] 135 activation_18[0][0] 136 activation_19[0][0] 137__________________________________________________________________________________________________ 138conv2d_23 (Conv2D) (None, None, None, 6 18432 mixed1[0][0] 139__________________________________________________________________________________________________ 140batch_normalization_23 (BatchNo (None, None, None, 6 192 conv2d_23[0][0] 141__________________________________________________________________________________________________ 142activation_23 (Activation) (None, None, None, 6 0 batch_normalization_23[0][0] 143__________________________________________________________________________________________________ 144conv2d_21 (Conv2D) (None, None, None, 4 13824 mixed1[0][0] 145__________________________________________________________________________________________________ 146conv2d_24 (Conv2D) (None, None, None, 9 55296 activation_23[0][0] 147__________________________________________________________________________________________________ 148batch_normalization_21 (BatchNo (None, None, None, 4 144 conv2d_21[0][0] 149__________________________________________________________________________________________________ 150batch_normalization_24 (BatchNo (None, None, None, 9 288 conv2d_24[0][0] 151__________________________________________________________________________________________________ 152activation_21 (Activation) (None, None, None, 4 0 batch_normalization_21[0][0] 153__________________________________________________________________________________________________ 154activation_24 (Activation) (None, None, None, 9 0 batch_normalization_24[0][0] 155__________________________________________________________________________________________________ 156average_pooling2d_3 (AveragePoo (None, None, None, 2 0 mixed1[0][0] 157__________________________________________________________________________________________________ 158conv2d_20 (Conv2D) (None, None, None, 6 18432 mixed1[0][0] 159__________________________________________________________________________________________________ 160conv2d_22 (Conv2D) (None, None, None, 6 76800 activation_21[0][0] 161__________________________________________________________________________________________________ 162conv2d_25 (Conv2D) (None, None, None, 9 82944 activation_24[0][0] 163__________________________________________________________________________________________________ 164conv2d_26 (Conv2D) (None, None, None, 6 18432 average_pooling2d_3[0][0] 165__________________________________________________________________________________________________ 166batch_normalization_20 (BatchNo (None, None, None, 6 192 conv2d_20[0][0] 167__________________________________________________________________________________________________ 168batch_normalization_22 (BatchNo (None, None, None, 6 192 conv2d_22[0][0] 169__________________________________________________________________________________________________ 170batch_normalization_25 (BatchNo (None, None, None, 9 288 conv2d_25[0][0] 171__________________________________________________________________________________________________ 172batch_normalization_26 (BatchNo (None, None, None, 6 192 conv2d_26[0][0] 173__________________________________________________________________________________________________ 174activation_20 (Activation) (None, None, None, 6 0 batch_normalization_20[0][0] 175__________________________________________________________________________________________________ 176activation_22 (Activation) (None, None, None, 6 0 batch_normalization_22[0][0] 177__________________________________________________________________________________________________ 178activation_25 (Activation) (None, None, None, 9 0 batch_normalization_25[0][0] 179__________________________________________________________________________________________________ 180activation_26 (Activation) (None, None, None, 6 0 batch_normalization_26[0][0] 181__________________________________________________________________________________________________ 182mixed2 (Concatenate) (None, None, None, 2 0 activation_20[0][0] 183 activation_22[0][0] 184 activation_25[0][0] 185 activation_26[0][0] 186__________________________________________________________________________________________________ 187conv2d_28 (Conv2D) (None, None, None, 6 18432 mixed2[0][0] 188__________________________________________________________________________________________________ 189batch_normalization_28 (BatchNo (None, None, None, 6 192 conv2d_28[0][0] 190__________________________________________________________________________________________________ 191activation_28 (Activation) (None, None, None, 6 0 batch_normalization_28[0][0] 192__________________________________________________________________________________________________ 193conv2d_29 (Conv2D) (None, None, None, 9 55296 activation_28[0][0] 194__________________________________________________________________________________________________ 195batch_normalization_29 (BatchNo (None, None, None, 9 288 conv2d_29[0][0] 196__________________________________________________________________________________________________ 197activation_29 (Activation) (None, None, None, 9 0 batch_normalization_29[0][0] 198__________________________________________________________________________________________________ 199conv2d_27 (Conv2D) (None, None, None, 3 995328 mixed2[0][0] 200__________________________________________________________________________________________________ 201conv2d_30 (Conv2D) (None, None, None, 9 82944 activation_29[0][0] 202__________________________________________________________________________________________________ 203batch_normalization_27 (BatchNo (None, None, None, 3 1152 conv2d_27[0][0] 204__________________________________________________________________________________________________ 205batch_normalization_30 (BatchNo (None, None, None, 9 288 conv2d_30[0][0] 206__________________________________________________________________________________________________ 207activation_27 (Activation) (None, None, None, 3 0 batch_normalization_27[0][0] 208__________________________________________________________________________________________________ 209activation_30 (Activation) (None, None, None, 9 0 batch_normalization_30[0][0] 210__________________________________________________________________________________________________ 211max_pooling2d_3 (MaxPooling2D) (None, None, None, 2 0 mixed2[0][0] 212__________________________________________________________________________________________________ 213mixed3 (Concatenate) (None, None, None, 7 0 activation_27[0][0] 214 activation_30[0][0] 215 max_pooling2d_3[0][0] 216__________________________________________________________________________________________________ 217conv2d_35 (Conv2D) (None, None, None, 1 98304 mixed3[0][0] 218__________________________________________________________________________________________________ 219batch_normalization_35 (BatchNo (None, None, None, 1 384 conv2d_35[0][0] 220__________________________________________________________________________________________________ 221activation_35 (Activation) (None, None, None, 1 0 batch_normalization_35[0][0] 222__________________________________________________________________________________________________ 223conv2d_36 (Conv2D) (None, None, None, 1 114688 activation_35[0][0] 224__________________________________________________________________________________________________ 225batch_normalization_36 (BatchNo (None, None, None, 1 384 conv2d_36[0][0] 226__________________________________________________________________________________________________ 227activation_36 (Activation) (None, None, None, 1 0 batch_normalization_36[0][0] 228__________________________________________________________________________________________________ 229conv2d_32 (Conv2D) (None, None, None, 1 98304 mixed3[0][0] 230__________________________________________________________________________________________________ 231conv2d_37 (Conv2D) (None, None, None, 1 114688 activation_36[0][0] 232__________________________________________________________________________________________________ 233batch_normalization_32 (BatchNo (None, None, None, 1 384 conv2d_32[0][0] 234__________________________________________________________________________________________________ 235batch_normalization_37 (BatchNo (None, None, None, 1 384 conv2d_37[0][0] 236__________________________________________________________________________________________________ 237activation_32 (Activation) (None, None, None, 1 0 batch_normalization_32[0][0] 238__________________________________________________________________________________________________ 239activation_37 (Activation) (None, None, None, 1 0 batch_normalization_37[0][0] 240__________________________________________________________________________________________________ 241conv2d_33 (Conv2D) (None, None, None, 1 114688 activation_32[0][0] 242__________________________________________________________________________________________________ 243conv2d_38 (Conv2D) (None, None, None, 1 114688 activation_37[0][0] 244__________________________________________________________________________________________________ 245batch_normalization_33 (BatchNo (None, None, None, 1 384 conv2d_33[0][0] 246__________________________________________________________________________________________________ 247batch_normalization_38 (BatchNo (None, None, None, 1 384 conv2d_38[0][0] 248__________________________________________________________________________________________________ 249activation_33 (Activation) (None, None, None, 1 0 batch_normalization_33[0][0] 250__________________________________________________________________________________________________ 251activation_38 (Activation) (None, None, None, 1 0 batch_normalization_38[0][0] 252__________________________________________________________________________________________________ 253average_pooling2d_4 (AveragePoo (None, None, None, 7 0 mixed3[0][0] 254__________________________________________________________________________________________________ 255conv2d_31 (Conv2D) (None, None, None, 1 147456 mixed3[0][0] 256__________________________________________________________________________________________________ 257conv2d_34 (Conv2D) (None, None, None, 1 172032 activation_33[0][0] 258__________________________________________________________________________________________________ 259conv2d_39 (Conv2D) (None, None, None, 1 172032 activation_38[0][0] 260__________________________________________________________________________________________________ 261conv2d_40 (Conv2D) (None, None, None, 1 147456 average_pooling2d_4[0][0] 262__________________________________________________________________________________________________ 263batch_normalization_31 (BatchNo (None, None, None, 1 576 conv2d_31[0][0] 264__________________________________________________________________________________________________ 265batch_normalization_34 (BatchNo (None, None, None, 1 576 conv2d_34[0][0] 266__________________________________________________________________________________________________ 267batch_normalization_39 (BatchNo (None, None, None, 1 576 conv2d_39[0][0] 268__________________________________________________________________________________________________ 269batch_normalization_40 (BatchNo (None, None, None, 1 576 conv2d_40[0][0] 270__________________________________________________________________________________________________ 271activation_31 (Activation) (None, None, None, 1 0 batch_normalization_31[0][0] 272__________________________________________________________________________________________________ 273activation_34 (Activation) (None, None, None, 1 0 batch_normalization_34[0][0] 274__________________________________________________________________________________________________ 275activation_39 (Activation) (None, None, None, 1 0 batch_normalization_39[0][0] 276__________________________________________________________________________________________________ 277activation_40 (Activation) (None, None, None, 1 0 batch_normalization_40[0][0] 278__________________________________________________________________________________________________ 279mixed4 (Concatenate) (None, None, None, 7 0 activation_31[0][0] 280 activation_34[0][0] 281 activation_39[0][0] 282 activation_40[0][0] 283__________________________________________________________________________________________________ 284conv2d_45 (Conv2D) (None, None, None, 1 122880 mixed4[0][0] 285__________________________________________________________________________________________________ 286batch_normalization_45 (BatchNo (None, None, None, 1 480 conv2d_45[0][0] 287__________________________________________________________________________________________________ 288activation_45 (Activation) (None, None, None, 1 0 batch_normalization_45[0][0] 289__________________________________________________________________________________________________ 290conv2d_46 (Conv2D) (None, None, None, 1 179200 activation_45[0][0] 291__________________________________________________________________________________________________ 292batch_normalization_46 (BatchNo (None, None, None, 1 480 conv2d_46[0][0] 293__________________________________________________________________________________________________ 294activation_46 (Activation) (None, None, None, 1 0 batch_normalization_46[0][0] 295__________________________________________________________________________________________________ 296conv2d_42 (Conv2D) (None, None, None, 1 122880 mixed4[0][0] 297__________________________________________________________________________________________________ 298conv2d_47 (Conv2D) (None, None, None, 1 179200 activation_46[0][0] 299__________________________________________________________________________________________________ 300batch_normalization_42 (BatchNo (None, None, None, 1 480 conv2d_42[0][0] 301__________________________________________________________________________________________________ 302batch_normalization_47 (BatchNo (None, None, None, 1 480 conv2d_47[0][0] 303__________________________________________________________________________________________________ 304activation_42 (Activation) (None, None, None, 1 0 batch_normalization_42[0][0] 305__________________________________________________________________________________________________ 306activation_47 (Activation) (None, None, None, 1 0 batch_normalization_47[0][0] 307__________________________________________________________________________________________________ 308conv2d_43 (Conv2D) (None, None, None, 1 179200 activation_42[0][0] 309__________________________________________________________________________________________________ 310conv2d_48 (Conv2D) (None, None, None, 1 179200 activation_47[0][0] 311__________________________________________________________________________________________________ 312batch_normalization_43 (BatchNo (None, None, None, 1 480 conv2d_43[0][0] 313__________________________________________________________________________________________________ 314batch_normalization_48 (BatchNo (None, None, None, 1 480 conv2d_48[0][0] 315__________________________________________________________________________________________________ 316activation_43 (Activation) (None, None, None, 1 0 batch_normalization_43[0][0] 317__________________________________________________________________________________________________ 318activation_48 (Activation) (None, None, None, 1 0 batch_normalization_48[0][0] 319__________________________________________________________________________________________________ 320average_pooling2d_5 (AveragePoo (None, None, None, 7 0 mixed4[0][0] 321__________________________________________________________________________________________________ 322conv2d_41 (Conv2D) (None, None, None, 1 147456 mixed4[0][0] 323__________________________________________________________________________________________________ 324conv2d_44 (Conv2D) (None, None, None, 1 215040 activation_43[0][0] 325__________________________________________________________________________________________________ 326conv2d_49 (Conv2D) (None, None, None, 1 215040 activation_48[0][0] 327__________________________________________________________________________________________________ 328conv2d_50 (Conv2D) (None, None, None, 1 147456 average_pooling2d_5[0][0] 329__________________________________________________________________________________________________ 330batch_normalization_41 (BatchNo (None, None, None, 1 576 conv2d_41[0][0] 331__________________________________________________________________________________________________ 332batch_normalization_44 (BatchNo (None, None, None, 1 576 conv2d_44[0][0] 333__________________________________________________________________________________________________ 334batch_normalization_49 (BatchNo (None, None, None, 1 576 conv2d_49[0][0] 335__________________________________________________________________________________________________ 336batch_normalization_50 (BatchNo (None, None, None, 1 576 conv2d_50[0][0] 337__________________________________________________________________________________________________ 338activation_41 (Activation) (None, None, None, 1 0 batch_normalization_41[0][0] 339__________________________________________________________________________________________________ 340activation_44 (Activation) (None, None, None, 1 0 batch_normalization_44[0][0] 341__________________________________________________________________________________________________ 342activation_49 (Activation) (None, None, None, 1 0 batch_normalization_49[0][0] 343__________________________________________________________________________________________________ 344activation_50 (Activation) (None, None, None, 1 0 batch_normalization_50[0][0] 345__________________________________________________________________________________________________ 346mixed5 (Concatenate) (None, None, None, 7 0 activation_41[0][0] 347 activation_44[0][0] 348 activation_49[0][0] 349 activation_50[0][0] 350__________________________________________________________________________________________________ 351conv2d_55 (Conv2D) (None, None, None, 1 122880 mixed5[0][0] 352__________________________________________________________________________________________________ 353batch_normalization_55 (BatchNo (None, None, None, 1 480 conv2d_55[0][0] 354__________________________________________________________________________________________________ 355activation_55 (Activation) (None, None, None, 1 0 batch_normalization_55[0][0] 356__________________________________________________________________________________________________ 357conv2d_56 (Conv2D) (None, None, None, 1 179200 activation_55[0][0] 358__________________________________________________________________________________________________ 359batch_normalization_56 (BatchNo (None, None, None, 1 480 conv2d_56[0][0] 360__________________________________________________________________________________________________ 361activation_56 (Activation) (None, None, None, 1 0 batch_normalization_56[0][0] 362__________________________________________________________________________________________________ 363conv2d_52 (Conv2D) (None, None, None, 1 122880 mixed5[0][0] 364__________________________________________________________________________________________________ 365conv2d_57 (Conv2D) (None, None, None, 1 179200 activation_56[0][0] 366__________________________________________________________________________________________________ 367batch_normalization_52 (BatchNo (None, None, None, 1 480 conv2d_52[0][0] 368__________________________________________________________________________________________________ 369batch_normalization_57 (BatchNo (None, None, None, 1 480 conv2d_57[0][0] 370__________________________________________________________________________________________________ 371activation_52 (Activation) (None, None, None, 1 0 batch_normalization_52[0][0] 372__________________________________________________________________________________________________ 373activation_57 (Activation) (None, None, None, 1 0 batch_normalization_57[0][0] 374__________________________________________________________________________________________________ 375conv2d_53 (Conv2D) (None, None, None, 1 179200 activation_52[0][0] 376__________________________________________________________________________________________________ 377conv2d_58 (Conv2D) (None, None, None, 1 179200 activation_57[0][0] 378__________________________________________________________________________________________________ 379batch_normalization_53 (BatchNo (None, None, None, 1 480 conv2d_53[0][0] 380__________________________________________________________________________________________________ 381batch_normalization_58 (BatchNo (None, None, None, 1 480 conv2d_58[0][0] 382__________________________________________________________________________________________________ 383activation_53 (Activation) (None, None, None, 1 0 batch_normalization_53[0][0] 384__________________________________________________________________________________________________ 385activation_58 (Activation) (None, None, None, 1 0 batch_normalization_58[0][0] 386__________________________________________________________________________________________________ 387average_pooling2d_6 (AveragePoo (None, None, None, 7 0 mixed5[0][0] 388__________________________________________________________________________________________________ 389conv2d_51 (Conv2D) (None, None, None, 1 147456 mixed5[0][0] 390__________________________________________________________________________________________________ 391conv2d_54 (Conv2D) (None, None, None, 1 215040 activation_53[0][0] 392__________________________________________________________________________________________________ 393conv2d_59 (Conv2D) (None, None, None, 1 215040 activation_58[0][0] 394__________________________________________________________________________________________________ 395conv2d_60 (Conv2D) (None, None, None, 1 147456 average_pooling2d_6[0][0] 396__________________________________________________________________________________________________ 397batch_normalization_51 (BatchNo (None, None, None, 1 576 conv2d_51[0][0] 398__________________________________________________________________________________________________ 399batch_normalization_54 (BatchNo (None, None, None, 1 576 conv2d_54[0][0] 400__________________________________________________________________________________________________ 401batch_normalization_59 (BatchNo (None, None, None, 1 576 conv2d_59[0][0] 402__________________________________________________________________________________________________ 403batch_normalization_60 (BatchNo (None, None, None, 1 576 conv2d_60[0][0] 404__________________________________________________________________________________________________ 405activation_51 (Activation) (None, None, None, 1 0 batch_normalization_51[0][0] 406__________________________________________________________________________________________________ 407activation_54 (Activation) (None, None, None, 1 0 batch_normalization_54[0][0] 408__________________________________________________________________________________________________ 409activation_59 (Activation) (None, None, None, 1 0 batch_normalization_59[0][0] 410__________________________________________________________________________________________________ 411activation_60 (Activation) (None, None, None, 1 0 batch_normalization_60[0][0] 412__________________________________________________________________________________________________ 413mixed6 (Concatenate) (None, None, None, 7 0 activation_51[0][0] 414 activation_54[0][0] 415 activation_59[0][0] 416 activation_60[0][0] 417__________________________________________________________________________________________________ 418conv2d_65 (Conv2D) (None, None, None, 1 147456 mixed6[0][0] 419__________________________________________________________________________________________________ 420batch_normalization_65 (BatchNo (None, None, None, 1 576 conv2d_65[0][0] 421__________________________________________________________________________________________________ 422activation_65 (Activation) (None, None, None, 1 0 batch_normalization_65[0][0] 423__________________________________________________________________________________________________ 424conv2d_66 (Conv2D) (None, None, None, 1 258048 activation_65[0][0] 425__________________________________________________________________________________________________ 426batch_normalization_66 (BatchNo (None, None, None, 1 576 conv2d_66[0][0] 427__________________________________________________________________________________________________ 428activation_66 (Activation) (None, None, None, 1 0 batch_normalization_66[0][0] 429__________________________________________________________________________________________________ 430conv2d_62 (Conv2D) (None, None, None, 1 147456 mixed6[0][0] 431__________________________________________________________________________________________________ 432conv2d_67 (Conv2D) (None, None, None, 1 258048 activation_66[0][0] 433__________________________________________________________________________________________________ 434batch_normalization_62 (BatchNo (None, None, None, 1 576 conv2d_62[0][0] 435__________________________________________________________________________________________________ 436batch_normalization_67 (BatchNo (None, None, None, 1 576 conv2d_67[0][0] 437__________________________________________________________________________________________________ 438activation_62 (Activation) (None, None, None, 1 0 batch_normalization_62[0][0] 439__________________________________________________________________________________________________ 440activation_67 (Activation) (None, None, None, 1 0 batch_normalization_67[0][0] 441__________________________________________________________________________________________________ 442conv2d_63 (Conv2D) (None, None, None, 1 258048 activation_62[0][0] 443__________________________________________________________________________________________________ 444conv2d_68 (Conv2D) (None, None, None, 1 258048 activation_67[0][0] 445__________________________________________________________________________________________________ 446batch_normalization_63 (BatchNo (None, None, None, 1 576 conv2d_63[0][0] 447__________________________________________________________________________________________________ 448batch_normalization_68 (BatchNo (None, None, None, 1 576 conv2d_68[0][0] 449__________________________________________________________________________________________________ 450activation_63 (Activation) (None, None, None, 1 0 batch_normalization_63[0][0] 451__________________________________________________________________________________________________ 452activation_68 (Activation) (None, None, None, 1 0 batch_normalization_68[0][0] 453__________________________________________________________________________________________________ 454average_pooling2d_7 (AveragePoo (None, None, None, 7 0 mixed6[0][0] 455__________________________________________________________________________________________________ 456conv2d_61 (Conv2D) (None, None, None, 1 147456 mixed6[0][0] 457__________________________________________________________________________________________________ 458conv2d_64 (Conv2D) (None, None, None, 1 258048 activation_63[0][0] 459__________________________________________________________________________________________________ 460conv2d_69 (Conv2D) (None, None, None, 1 258048 activation_68[0][0] 461__________________________________________________________________________________________________ 462conv2d_70 (Conv2D) (None, None, None, 1 147456 average_pooling2d_7[0][0] 463__________________________________________________________________________________________________ 464batch_normalization_61 (BatchNo (None, None, None, 1 576 conv2d_61[0][0] 465__________________________________________________________________________________________________ 466batch_normalization_64 (BatchNo (None, None, None, 1 576 conv2d_64[0][0] 467__________________________________________________________________________________________________ 468batch_normalization_69 (BatchNo (None, None, None, 1 576 conv2d_69[0][0] 469__________________________________________________________________________________________________ 470batch_normalization_70 (BatchNo (None, None, None, 1 576 conv2d_70[0][0] 471__________________________________________________________________________________________________ 472activation_61 (Activation) (None, None, None, 1 0 batch_normalization_61[0][0] 473__________________________________________________________________________________________________ 474activation_64 (Activation) (None, None, None, 1 0 batch_normalization_64[0][0] 475__________________________________________________________________________________________________ 476activation_69 (Activation) (None, None, None, 1 0 batch_normalization_69[0][0] 477__________________________________________________________________________________________________ 478activation_70 (Activation) (None, None, None, 1 0 batch_normalization_70[0][0] 479__________________________________________________________________________________________________ 480mixed7 (Concatenate) (None, None, None, 7 0 activation_61[0][0] 481 activation_64[0][0] 482 activation_69[0][0] 483 activation_70[0][0] 484__________________________________________________________________________________________________ 485conv2d_73 (Conv2D) (None, None, None, 1 147456 mixed7[0][0] 486__________________________________________________________________________________________________ 487batch_normalization_73 (BatchNo (None, None, None, 1 576 conv2d_73[0][0] 488__________________________________________________________________________________________________ 489activation_73 (Activation) (None, None, None, 1 0 batch_normalization_73[0][0] 490__________________________________________________________________________________________________ 491conv2d_74 (Conv2D) (None, None, None, 1 258048 activation_73[0][0] 492__________________________________________________________________________________________________ 493batch_normalization_74 (BatchNo (None, None, None, 1 576 conv2d_74[0][0] 494__________________________________________________________________________________________________ 495activation_74 (Activation) (None, None, None, 1 0 batch_normalization_74[0][0] 496__________________________________________________________________________________________________ 497conv2d_71 (Conv2D) (None, None, None, 1 147456 mixed7[0][0] 498__________________________________________________________________________________________________ 499conv2d_75 (Conv2D) (None, None, None, 1 258048 activation_74[0][0] 500__________________________________________________________________________________________________ 501batch_normalization_71 (BatchNo (None, None, None, 1 576 conv2d_71[0][0] 502__________________________________________________________________________________________________ 503batch_normalization_75 (BatchNo (None, None, None, 1 576 conv2d_75[0][0] 504__________________________________________________________________________________________________ 505activation_71 (Activation) (None, None, None, 1 0 batch_normalization_71[0][0] 506__________________________________________________________________________________________________ 507activation_75 (Activation) (None, None, None, 1 0 batch_normalization_75[0][0] 508__________________________________________________________________________________________________ 509conv2d_72 (Conv2D) (None, None, None, 3 552960 activation_71[0][0] 510__________________________________________________________________________________________________ 511conv2d_76 (Conv2D) (None, None, None, 1 331776 activation_75[0][0] 512__________________________________________________________________________________________________ 513batch_normalization_72 (BatchNo (None, None, None, 3 960 conv2d_72[0][0] 514__________________________________________________________________________________________________ 515batch_normalization_76 (BatchNo (None, None, None, 1 576 conv2d_76[0][0] 516__________________________________________________________________________________________________ 517activation_72 (Activation) (None, None, None, 3 0 batch_normalization_72[0][0] 518__________________________________________________________________________________________________ 519activation_76 (Activation) (None, None, None, 1 0 batch_normalization_76[0][0] 520__________________________________________________________________________________________________ 521max_pooling2d_4 (MaxPooling2D) (None, None, None, 7 0 mixed7[0][0] 522__________________________________________________________________________________________________ 523mixed8 (Concatenate) (None, None, None, 1 0 activation_72[0][0] 524 activation_76[0][0] 525 max_pooling2d_4[0][0] 526__________________________________________________________________________________________________ 527conv2d_81 (Conv2D) (None, None, None, 4 573440 mixed8[0][0] 528__________________________________________________________________________________________________ 529batch_normalization_81 (BatchNo (None, None, None, 4 1344 conv2d_81[0][0] 530__________________________________________________________________________________________________ 531activation_81 (Activation) (None, None, None, 4 0 batch_normalization_81[0][0] 532__________________________________________________________________________________________________ 533conv2d_78 (Conv2D) (None, None, None, 3 491520 mixed8[0][0] 534__________________________________________________________________________________________________ 535conv2d_82 (Conv2D) (None, None, None, 3 1548288 activation_81[0][0] 536__________________________________________________________________________________________________ 537batch_normalization_78 (BatchNo (None, None, None, 3 1152 conv2d_78[0][0] 538__________________________________________________________________________________________________ 539batch_normalization_82 (BatchNo (None, None, None, 3 1152 conv2d_82[0][0] 540__________________________________________________________________________________________________ 541activation_78 (Activation) (None, None, None, 3 0 batch_normalization_78[0][0] 542__________________________________________________________________________________________________ 543activation_82 (Activation) (None, None, None, 3 0 batch_normalization_82[0][0] 544__________________________________________________________________________________________________ 545conv2d_79 (Conv2D) (None, None, None, 3 442368 activation_78[0][0] 546__________________________________________________________________________________________________ 547conv2d_80 (Conv2D) (None, None, None, 3 442368 activation_78[0][0] 548__________________________________________________________________________________________________ 549conv2d_83 (Conv2D) (None, None, None, 3 442368 activation_82[0][0] 550__________________________________________________________________________________________________ 551conv2d_84 (Conv2D) (None, None, None, 3 442368 activation_82[0][0] 552__________________________________________________________________________________________________ 553average_pooling2d_8 (AveragePoo (None, None, None, 1 0 mixed8[0][0] 554__________________________________________________________________________________________________ 555conv2d_77 (Conv2D) (None, None, None, 3 409600 mixed8[0][0] 556__________________________________________________________________________________________________ 557batch_normalization_79 (BatchNo (None, None, None, 3 1152 conv2d_79[0][0] 558__________________________________________________________________________________________________ 559batch_normalization_80 (BatchNo (None, None, None, 3 1152 conv2d_80[0][0] 560__________________________________________________________________________________________________ 561batch_normalization_83 (BatchNo (None, None, None, 3 1152 conv2d_83[0][0] 562__________________________________________________________________________________________________ 563batch_normalization_84 (BatchNo (None, None, None, 3 1152 conv2d_84[0][0] 564__________________________________________________________________________________________________ 565conv2d_85 (Conv2D) (None, None, None, 1 245760 average_pooling2d_8[0][0] 566__________________________________________________________________________________________________ 567batch_normalization_77 (BatchNo (None, None, None, 3 960 conv2d_77[0][0] 568__________________________________________________________________________________________________ 569activation_79 (Activation) (None, None, None, 3 0 batch_normalization_79[0][0] 570__________________________________________________________________________________________________ 571activation_80 (Activation) (None, None, None, 3 0 batch_normalization_80[0][0] 572__________________________________________________________________________________________________ 573activation_83 (Activation) (None, None, None, 3 0 batch_normalization_83[0][0] 574__________________________________________________________________________________________________ 575activation_84 (Activation) (None, None, None, 3 0 batch_normalization_84[0][0] 576__________________________________________________________________________________________________ 577batch_normalization_85 (BatchNo (None, None, None, 1 576 conv2d_85[0][0] 578__________________________________________________________________________________________________ 579activation_77 (Activation) (None, None, None, 3 0 batch_normalization_77[0][0] 580__________________________________________________________________________________________________ 581mixed9_0 (Concatenate) (None, None, None, 7 0 activation_79[0][0] 582 activation_80[0][0] 583__________________________________________________________________________________________________ 584concatenate_1 (Concatenate) (None, None, None, 7 0 activation_83[0][0] 585 activation_84[0][0] 586__________________________________________________________________________________________________ 587activation_85 (Activation) (None, None, None, 1 0 batch_normalization_85[0][0] 588__________________________________________________________________________________________________ 589mixed9 (Concatenate) (None, None, None, 2 0 activation_77[0][0] 590 mixed9_0[0][0] 591 concatenate_1[0][0] 592 activation_85[0][0] 593__________________________________________________________________________________________________ 594conv2d_90 (Conv2D) (None, None, None, 4 917504 mixed9[0][0] 595__________________________________________________________________________________________________ 596batch_normalization_90 (BatchNo (None, None, None, 4 1344 conv2d_90[0][0] 597__________________________________________________________________________________________________ 598activation_90 (Activation) (None, None, None, 4 0 batch_normalization_90[0][0] 599__________________________________________________________________________________________________ 600conv2d_87 (Conv2D) (None, None, None, 3 786432 mixed9[0][0] 601__________________________________________________________________________________________________ 602conv2d_91 (Conv2D) (None, None, None, 3 1548288 activation_90[0][0] 603__________________________________________________________________________________________________ 604batch_normalization_87 (BatchNo (None, None, None, 3 1152 conv2d_87[0][0] 605__________________________________________________________________________________________________ 606batch_normalization_91 (BatchNo (None, None, None, 3 1152 conv2d_91[0][0] 607__________________________________________________________________________________________________ 608activation_87 (Activation) (None, None, None, 3 0 batch_normalization_87[0][0] 609__________________________________________________________________________________________________ 610activation_91 (Activation) (None, None, None, 3 0 batch_normalization_91[0][0] 611__________________________________________________________________________________________________ 612conv2d_88 (Conv2D) (None, None, None, 3 442368 activation_87[0][0] 613__________________________________________________________________________________________________ 614conv2d_89 (Conv2D) (None, None, None, 3 442368 activation_87[0][0] 615__________________________________________________________________________________________________ 616conv2d_92 (Conv2D) (None, None, None, 3 442368 activation_91[0][0] 617__________________________________________________________________________________________________ 618conv2d_93 (Conv2D) (None, None, None, 3 442368 activation_91[0][0] 619__________________________________________________________________________________________________ 620average_pooling2d_9 (AveragePoo (None, None, None, 2 0 mixed9[0][0] 621__________________________________________________________________________________________________ 622conv2d_86 (Conv2D) (None, None, None, 3 655360 mixed9[0][0] 623__________________________________________________________________________________________________ 624batch_normalization_88 (BatchNo (None, None, None, 3 1152 conv2d_88[0][0] 625__________________________________________________________________________________________________ 626batch_normalization_89 (BatchNo (None, None, None, 3 1152 conv2d_89[0][0] 627__________________________________________________________________________________________________ 628batch_normalization_92 (BatchNo (None, None, None, 3 1152 conv2d_92[0][0] 629__________________________________________________________________________________________________ 630batch_normalization_93 (BatchNo (None, None, None, 3 1152 conv2d_93[0][0] 631__________________________________________________________________________________________________ 632conv2d_94 (Conv2D) (None, None, None, 1 393216 average_pooling2d_9[0][0] 633__________________________________________________________________________________________________ 634batch_normalization_86 (BatchNo (None, None, None, 3 960 conv2d_86[0][0] 635__________________________________________________________________________________________________ 636activation_88 (Activation) (None, None, None, 3 0 batch_normalization_88[0][0] 637__________________________________________________________________________________________________ 638activation_89 (Activation) (None, None, None, 3 0 batch_normalization_89[0][0] 639__________________________________________________________________________________________________ 640activation_92 (Activation) (None, None, None, 3 0 batch_normalization_92[0][0] 641__________________________________________________________________________________________________ 642activation_93 (Activation) (None, None, None, 3 0 batch_normalization_93[0][0] 643__________________________________________________________________________________________________ 644batch_normalization_94 (BatchNo (None, None, None, 1 576 conv2d_94[0][0] 645__________________________________________________________________________________________________ 646activation_86 (Activation) (None, None, None, 3 0 batch_normalization_86[0][0] 647__________________________________________________________________________________________________ 648mixed9_1 (Concatenate) (None, None, None, 7 0 activation_88[0][0] 649 activation_89[0][0] 650__________________________________________________________________________________________________ 651concatenate_2 (Concatenate) (None, None, None, 7 0 activation_92[0][0] 652 activation_93[0][0] 653__________________________________________________________________________________________________ 654activation_94 (Activation) (None, None, None, 1 0 batch_normalization_94[0][0] 655__________________________________________________________________________________________________ 656mixed10 (Concatenate) (None, None, None, 2 0 activation_86[0][0] 657 mixed9_1[0][0] 658 concatenate_2[0][0] 659 activation_94[0][0] 660__________________________________________________________________________________________________ 661global_average_pooling2d_1 (Glo (None, 2048) 0 mixed10[0][0] 662__________________________________________________________________________________________________ 663dense_1 (Dense) (None, 1024) 2098176 global_average_pooling2d_1[0][0] 664__________________________________________________________________________________________________ 665dense_2 (Dense) (None, 2) 2050 dense_1[0][0] 666================================================================================================== 667Total params: 23,903,010 668Trainable params: 2,100,226 669Non-trainable params: 21,802,784 670__________________________________________________________________________________________________ Ph·∫ßn train l·∫°i s·∫Ω c√≥ kho·∫£ng h∆°n 2 tri·ªáu tham s·ªë, ph·∫ßn layter ·ªü tr∆∞·ªõc ƒë√≥ kh√¥ng train l√† kho·∫£ng 21 tri·ªáu tham s·ªë.\nƒê·ªì h√¨nh c·ªßa model (c√°c b·∫°n c√≥ th·ªÉ download v·ªÅ r·ªìi zoom b·ª± l√™n ƒë·ªÉ xem r√µ h∆°n).\nChia t·∫≠p d·ªØ li·ªáu ra th√†nh 5 ph·∫ßn, 4 ph·∫ßn l√†m t·∫≠p train, 1 ph·∫ßn l√†m t·∫≠p validation.\n1X, y, tags = dataset.dataset(data_directory, n) 2nb_classes = len(tags) 3 4 5sample_count = len(y) 6train_size = sample_count * 4 // 5 7X_train = X[:train_size] 8y_train = y[:train_size] 9Y_train = np_utils.to_categorical(y_train, nb_classes) 10X_test = X[train_size:] 11y_test = y[train_size:] 12Y_test = np_utils.to_categorical(y_test, nb_classes) ƒê·ªÉ ch·ªëng overfit, ch√∫ng ta s·∫Ω th√™m m·ªôt s·ªë y·∫øu t·ªë nh∆∞ th·ª±c hi·ªán c√°c ph√©p bi·∫øn ƒë·ªïi affine tr√™n ·∫£nh g·ªëc.\n1datagen = ImageDataGenerator( 2 featurewise_center=False, 3 samplewise_center=False, 4 featurewise_std_normalization=False, 5 samplewise_std_normalization=False, 6 zca_whitening=False, 7 rotation_range=45, 8 width_shift_range=0.25, 9 height_shift_range=0.25, 10 horizontal_flip=True, 11 vertical_flip=False, 12 zoom_range=0.5, 13 channel_shift_range=0.5, 14 fill_mode=\u0026#39;nearest\u0026#39;) 15 16datagen.fit(X_train) Cu·ªëi c√πng, ch√∫ng ta s·∫Ω x√¢y d·ª±ng m√¥ h√¨nh v√† ti·∫øn h√†nh hu·∫•n luy·ªán, l∆∞u m√¥ h√¨nh. Qu√° tr√¨nh n√†y t·ªën h∆°i nhi·ªÅu th·ªùi gian.\n1 2model = net.build_model(nb_classes) 3model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#34;accuracy\u0026#34;]) 4 5# train the model on the new data for a few epochs 6 7print(\u0026#34;training the newly added dense layers\u0026#34;) 8 9samples_per_epoch = X_train.shape[0]//batch_size*batch_size 10steps_per_epoch = samples_per_epoch//batch_size 11validation_steps = X_test.shape[0]//batch_size*batch_size 12 13model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True), 14 samples_per_epoch=samples_per_epoch, 15 epochs=nb_epoch, 16 steps_per_epoch = steps_per_epoch, 17 validation_data=datagen.flow(X_test, Y_test, batch_size=batch_size), 18 validation_steps=validation_steps, 19 ) 20 21 22net.save(model, tags, model_file_prefix) ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p train.\n1Y_pred = model.predict(X_test, batch_size=batch_size) 2y_pred = np.argmax(Y_pred, axis=1) 3 4accuracy = float(np.sum(y_test==y_pred)) / len(y_test) 5print(\u0026#34;accuracy: \u0026#34;, accuracy) 6 7confusion = np.zeros((nb_classes, nb_classes), dtype=np.int32) 8for (predicted_index, actual_index, image) in zip(y_pred, y_test, X_test): 9 confusion[predicted_index, actual_index] += 1 10 11print(\u0026#34;rows are predicted classes, columns are actual classes\u0026#34;) 12for predicted_index, predicted_tag in enumerate(tags): 13 print(predicted_tag[:7], end=\u0026#39;\u0026#39;, flush=True) 14 for actual_index, actual_tag in enumerate(tags): 15 print(\u0026#34;\\t%d\u0026#34; % confusion[predicted_index, actual_index], end=\u0026#39;\u0026#39;) 16 print(\u0026#34;\u0026#34;, flush=True) 1accuracy: 0.9907213167661771 2rows are predicted classes, columns are actual classes 3cat 12238 106 4dog 124 12320 K·∫øt qu·∫£ ƒë·∫°t 0.99 tr√™n t·∫≠p train, kh√° t·ªët ph·∫£i kh√¥ng c√°c b·∫°n.\nC√°c b·∫°n c√≥ th·ªÉ download m√¥ h√¨nh m√¨nh ƒë√£ hu·∫•n luy·ªán ·ªü https://drive.google.com/open?id=1qQo8gj3KA6c1rPmJMVS_FZkVDcDmRgSf.\nTh·ª≠ show ra k·∫øt qu·∫£ tr√™n t·∫≠p test xem nh∆∞ th·∫ø n√†o.\n1Y_pred = model.predict(X_test, batch_size=batch_size) 2y_pred = np.argmax(Y_pred, axis=1) 3 4lst_img = [] 5 6columns = 5 7rows = 5 8# fig,= plt.figure(rows) 9for idx, val in enumerate(X_test): 10 pred =y_pred[idx] 11 label = \u0026#34;{}: {:.2f}%\u0026#34;.format(tags[pred], Y_pred[idx][pred] * 100) 12 image = dataset.reverse_preprocess_input(val) 13 image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) 14 cv2.putText(image,label , (10, 25), cv2.FONT_HERSHEY_SIMPLEX,0.7, (255, 000, 0), 2) 15 16 plt.subplot(rows,rows,idx+1) 17 plt.imshow(image) 18 plt.title(label) 19 plt.axis(\u0026#39;off\u0026#39;) 20 21plt.show() K·∫øt qu·∫£ c√≥ m·ªôt s·ªë h√¨nh m√®o b·ªã nh·∫≠n nh·∫ßm l√† ch√≥, v√† m·ªôt s·ªë h√¨nh kh√¥ng ph·∫£i m√®o, kh√¥ng ph·∫£i ch√≥. Nh√¨n chung k·∫øt qu·∫£ c≈©ng kh√¥ng ƒë·∫øn n·ªói n√†o qu√° t·ªá.\nQu·∫≠y ph√° m√¥ h√¨nh M√¥ h√¨nh InceptionV3 ch√∫ng ta ƒëang x√†i c√≥ t·ªïng c·ªông 311 l·ªõp, ch√∫ng ta s·∫Ω ti·∫øn h√†nh m·ªôt s·ªë pha qu·∫≠y ph√° m√¥ h√¨nh xem k·∫øt qu·∫£ nh∆∞ tr·∫£ ra nh∆∞ th·∫ø n√†o\nQu·∫≠y ph√° 1: M·ªü ƒë√≥ng bƒÉng m·ªôt s·ªë l·ªõp cu·ªëi v√† train tr√™n ch√∫ng. N·∫øu c√°c b·∫°n ƒë·ªÉ √Ω k·ªπ, trong ƒëo·∫°n m√£ ngu·ªìn c·ªßa m√¨nh c√≥ ƒëo·∫°n\n1# first: train only the top layers (which were randomly initialized) 2 # i.e. freeze all convolutional InceptionV3 layers 3 for layer in base_model.layers: 4 layer.trainable = False Nghƒ©a l√† m√¨nh ƒë√≥ng bƒÉng to√†n b·ªô 311 l·ªõp, kh√¥ng cho n√≥ train m√† ch·ªâ l·∫•y k·∫øt qu·∫£ c·ªßa n√≥ train l·ªõp softmax cu·ªëi c√πng. B√¢y gi·ªù m√¨nh s·∫Ω th·ª≠ nghi·ªám v·ªõi vi·ªác l√† ƒë·ªÉ 299 l·ªõp ban ƒë·∫ßu v·∫´n ƒë√≥ng bƒÉng, v√† train l·∫°i to√†n b·ªô c√°c l·ªõp c√≤n l·∫°i (C√°c b·∫°n ƒë·ª´ng th·∫Øc m·∫Øc v√¨ sao l·∫°i l√† 299 nha, do m√¨nh th√≠ch th√¥i).\n1for layer in model.layers[:299]: 2 layer.trainable = False 3for layer in model.layers[299:]: 4 layer.trainable = True ƒê·ªì h√¨nh c·ªßa m√¥ ƒë·ªì kh√° gi·ªëng ·ªü tr√™n, m√¨nh ch·ªâ post l·∫°i k·∫øt qu·∫£ c·ªßa s·ªë param.\n1================================================================================================== 2Total params: 23,903,010 3Trainable params: 2,493,954 4Non-trainable params: 21,409,056 5__________________________________________________________________________________________________ Nh∆∞ v·∫≠y l√† c√≥ kho·∫£ng 2 tri·ªáu 5 tham s·ªë ƒë∆∞·ª£c hu·∫•n luy·ªán l·∫°i\nModel c·ªßa m√¨nh hu·∫•n luy·ªán ƒë∆∞·ª£c c√°c b·∫°n c√≥ th·ªÉ download ·ªü https://drive.google.com/open?id=1Ts18LICUAh6gcOnXcmuVr7PUG5IxpCdt.\nK·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c:\n1accuracy: 0.9834610730133119 2rows are predicted classes, columns are actual classes 3cat 2429 69 4dog 13 2447 K·∫øt qu·∫£ 25 h√¨nh ng·∫´u nhi√™n c≈©ng kh√° gi·ªëng k·∫øt qu·∫£ ·ªü tr∆∞·ªõc ƒë√≥. M·ªôt s·ªë h√¨nh kh√¥ng c√≥ con v·∫≠t b·ªã nh·∫≠n nh·∫ßm nh∆∞ h√¨nh c√≤n m√®o ·ªü g√≥c ph·∫£i tr√™n b·ªã nh·∫≠n nh·∫ßm l√† ch√≥. Tuy nhi√™n, v·ªõi ch·∫•t l∆∞·ª£ng h√¨nh ·∫£nh nh∆∞ th·∫ø n√†y th√¨ m√¨nh th·∫•y k·∫øt qu·∫£ nh∆∞ v·∫≠y l√† kh√° tuy·ªát v·ªùi.\nQu·∫≠y ph√° 2: Ch·ªâ s·ª≠ d·ª•ng 72 l·ªõp ƒë·∫ßu ti√™n c·ªßa inception. ·ªû l·∫ßn th√≠ nghi·ªám n√†y, m√¨nh s·∫Ω ch·ªâ s·ª≠ d·ª•ng 72 l·ªõp ƒë·∫ßu ti√™n c·ªßa inception ƒë·ªÉ hu·∫•n luy·ªán. M√¨nh s·∫Ω s·ª≠a l·∫°i m·ªôt x√≠u ·ªü h√†m build model nh∆∞ sau:\n1x = base_model.layers[72].output M·ªôt l∆∞u √Ω nh·ªè l√† do inception kh√¥ng c√≥ t√≠nh tu·∫ßn t·ª± gi·ªØa c√°c l·ªõp (c√°c b·∫°n c√≥ th·ªÉ nh√¨n h√¨nh ·ªü tr√™n s·∫Ω th·∫•y r√µ), n√™n index s·∫Ω kh√¥ng ph·∫£i l√† 72 nh∆∞ th√¥ng th∆∞·ªùng.\nTi·∫øp theo, ch√∫ng ta s·∫Ω th·ª±c hi·ªán vi·ªác hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh v√† k·∫øt qu·∫£ l√†:\n1accuracy: 0.5494150867285196 2rows are predicted classes, columns are actual classes 3cat 339 131 4dog 2103 2385 K·∫øt qu·∫£ kh√° t·ªá, l√Ω do l√† m√¥ h√¨nh c√°c layer kh√¥ng theo sequence, m√¨nh l·∫•y ng·∫´u nhi√™u 72 l·ªõp l√†m th√¥ng tin feature c·ªßa c√°c h√¨nh b·ªã m·∫•t m√°t nhi·ªÅu (v√≠ d·ª• tr∆∞·ªùng h·ª£p layey 80 l√† t·ªïng h·ª£p th√¥ng tin c·ªßa layter 79 + layter 4 + layer 48, m√† m√¨nh ch·ªâ l·∫•y 72 layter ƒë·∫ßu, n√™n s·∫Ω m·∫•t ƒëi ph·∫ßn ƒë√≥ng g√≥p c·ª±c k·ª≥ quan tr·ªçng c·ªßa layter 4 v√† 48 ·ªü l·ªõp cao h∆°n).\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Oct 29, 2018","img":"","permalink":"/blog/2018-10-29-phan-loai-cho-meo/","series":null,"tags":["Machine learning","Deeplearning","dog cat"],"title":"Ph√¢n Lo·∫°i Ch√≥ M√®o S·ª≠ D·ª•ng Pretrain Model"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu S·ª≠ d·ª•ng pretrain model L·ªùi m·ªü ƒë·∫ßu Ph√¢n v√πng ƒë·ªëi t∆∞·ª£ng l√† m·ªôt b√†i to√°n kh√° ph·ªï bi·∫øn trong lƒ©nh v·ª±c computer vision. Trong open cv c√≥ h·ªó tr·ª£ cho ch√∫ng ta m·ªôt s·ªë h√†m ƒë·ªÉ ph√¢n v√πng ƒë·ªëi t∆∞·ª£ng r·∫•t d·ªÖ s·ª≠ d·ª•ng. ƒê·∫∑c ƒëi·ªÉm chung c·ªßa c√°c h√†m n√†y l√† ƒë·ªô ch√≠nh x√°c kh√¥ng ƒë∆∞·ª£c cao cho l·∫Øm. ·ªû b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu c√°ch s·ª≠ d·ª•ng m√¥ h√¨nh pretrain c·ªßa DNN ƒë·ªÉ ph√¢n v√πng c√°c ƒë·ªëi t∆∞·ª£ng trong ·∫£nh.\nS·ª≠ d·ª•ng pretrain model ƒê·∫ßu ti√™n, c√°c b·∫°n download file pretrain model, gi·∫£i n√©n ra v√† ƒë·ªÉ ·ªü ƒë√¢u ƒë√≥ trong ·ªï c·ª©ng c·ªßa m√°y b·∫°n. ƒê∆∞·ªùng d·∫´n file pretrain model c√°c b·∫°n c√≥ th·ªÉ download ·ªü http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz. C√°c b·∫°n c√≥ th·ªÉ download c√°c file pretrain kh√°c n·∫øu c√≥ h·ª©ng th√∫ t√¨m hi·ªÉu.\nTi·∫øp theo, ch√∫ng ta s·∫Ω load m√¥ h√¨nh l√™n:\n1import numpy as np 2import os 3import sys 4import tarfile 5import tensorflow as tf 6 7from collections import defaultdict 8from io import StringIO 9from matplotlib import pyplot as plt 10from PIL import Image 11import PIL.ImageDraw as ImageDraw 12import PIL.ImageFont as ImageFont 13import cv2 14 15import pprint 16 17import PIL.Image as Image 18import PIL.ImageColor as ImageColor 19 20# Model preparation 21 22 23# Path to frozen detection graph. This is the actual model that is used for the object detection. 24PATH_TO_CKPT = \u0026#39;mask_rcnn_inception_v2_coco_2018_01_28\u0026#39; + \u0026#39;/frozen_inference_graph.pb\u0026#39; 25 26# List of the strings that is used to add correct label for each box. 27#PATH_TO_LABELS = \u0026#39;mscoco_label_map.pbtxt\u0026#39; 28 29NUM_CLASSES = 1 30 31 32# categories 33 34category_index = {1: {\u0026#39;id\u0026#39;: 1, \u0026#39;name\u0026#39;: \u0026#39;person\u0026#39;}, 35# 3: {\u0026#39;id\u0026#39;: 3, \u0026#39;name\u0026#39;: \u0026#39;car\u0026#39;}, 36 } 37 38detection_graph = tf.Graph() 39with detection_graph.as_default(): 40 od_graph_def = tf.GraphDef() 41 with tf.gfile.GFile(PATH_TO_CKPT, \u0026#39;rb\u0026#39;) as fid: 42 serialized_graph = fid.read() 43 od_graph_def.ParseFromString(serialized_graph) 44 tf.import_graph_def(od_graph_def, name=\u0026#39;\u0026#39;) ·ªû ƒë√¢y, m√¨nh ch·ªâ demo detect ng∆∞·ªùi trong h√¨nh, n√™n m√¨nh ch·ªâ ƒë·ªÉ category_index ch·ªâ l√† \u0026ldquo;person\u0026rdquo;. Th·ª±c t·∫ø, m√¥ h√¨nh COCO h·ªó tr·ª£ cho ch√∫ng ta nh·∫≠n d·∫°ng 90 lo·∫°i ƒë·ªëi t∆∞·ª£ng kh√°c nhau, c√°c b·∫°n c√≥ nhu c·∫ßu t√¨m hi·ªÉu th√¨ thay b·∫±ng ƒëo·∫°n m√£ sau:\n1category_index = {1: {\u0026#39;id\u0026#39;: 1, \u0026#39;name\u0026#39;: \u0026#39;person\u0026#39;}, 2 2: {\u0026#39;id\u0026#39;: 2, \u0026#39;name\u0026#39;: \u0026#39;bicycle\u0026#39;}, 3 3: {\u0026#39;id\u0026#39;: 3, \u0026#39;name\u0026#39;: \u0026#39;car\u0026#39;}, 4 4: {\u0026#39;id\u0026#39;: 4, \u0026#39;name\u0026#39;: \u0026#39;motorcycle\u0026#39;}, 5 5: {\u0026#39;id\u0026#39;: 5, \u0026#39;name\u0026#39;: \u0026#39;airplane\u0026#39;}, 6 6: {\u0026#39;id\u0026#39;: 6, \u0026#39;name\u0026#39;: \u0026#39;bus\u0026#39;}, 7 7: {\u0026#39;id\u0026#39;: 7, \u0026#39;name\u0026#39;: \u0026#39;train\u0026#39;}, 8 8: {\u0026#39;id\u0026#39;: 8, \u0026#39;name\u0026#39;: \u0026#39;truck\u0026#39;}, 9 9: {\u0026#39;id\u0026#39;: 9, \u0026#39;name\u0026#39;: \u0026#39;boat\u0026#39;}, 10 10: {\u0026#39;id\u0026#39;: 10, \u0026#39;name\u0026#39;: \u0026#39;traffic light\u0026#39;}, 11 11: {\u0026#39;id\u0026#39;: 11, \u0026#39;name\u0026#39;: \u0026#39;fire hydrant\u0026#39;}, 12 13: {\u0026#39;id\u0026#39;: 13, \u0026#39;name\u0026#39;: \u0026#39;stop sign\u0026#39;}, 13 14: {\u0026#39;id\u0026#39;: 14, \u0026#39;name\u0026#39;: \u0026#39;parking meter\u0026#39;}, 14 15: {\u0026#39;id\u0026#39;: 15, \u0026#39;name\u0026#39;: \u0026#39;bench\u0026#39;}, 15 16: {\u0026#39;id\u0026#39;: 16, \u0026#39;name\u0026#39;: \u0026#39;bird\u0026#39;}, 16 17: {\u0026#39;id\u0026#39;: 17, \u0026#39;name\u0026#39;: \u0026#39;cat\u0026#39;}, 17 18: {\u0026#39;id\u0026#39;: 18, \u0026#39;name\u0026#39;: \u0026#39;dog\u0026#39;}, 18 19: {\u0026#39;id\u0026#39;: 19, \u0026#39;name\u0026#39;: \u0026#39;horse\u0026#39;}, 19 20: {\u0026#39;id\u0026#39;: 20, \u0026#39;name\u0026#39;: \u0026#39;sheep\u0026#39;}, 20 21: {\u0026#39;id\u0026#39;: 21, \u0026#39;name\u0026#39;: \u0026#39;cow\u0026#39;}, 21 22: {\u0026#39;id\u0026#39;: 22, \u0026#39;name\u0026#39;: \u0026#39;elephant\u0026#39;}, 22 23: {\u0026#39;id\u0026#39;: 23, \u0026#39;name\u0026#39;: \u0026#39;bear\u0026#39;}, 23 24: {\u0026#39;id\u0026#39;: 24, \u0026#39;name\u0026#39;: \u0026#39;zebra\u0026#39;}, 24 25: {\u0026#39;id\u0026#39;: 25, \u0026#39;name\u0026#39;: \u0026#39;giraffe\u0026#39;}, 25 27: {\u0026#39;id\u0026#39;: 27, \u0026#39;name\u0026#39;: \u0026#39;backpack\u0026#39;}, 26 28: {\u0026#39;id\u0026#39;: 28, \u0026#39;name\u0026#39;: \u0026#39;umbrella\u0026#39;}, 27 31: {\u0026#39;id\u0026#39;: 31, \u0026#39;name\u0026#39;: \u0026#39;handbag\u0026#39;}, 28 32: {\u0026#39;id\u0026#39;: 32, \u0026#39;name\u0026#39;: \u0026#39;tie\u0026#39;}, 29 33: {\u0026#39;id\u0026#39;: 33, \u0026#39;name\u0026#39;: \u0026#39;suitcase\u0026#39;}, 30 34: {\u0026#39;id\u0026#39;: 34, \u0026#39;name\u0026#39;: \u0026#39;frisbee\u0026#39;}, 31 35: {\u0026#39;id\u0026#39;: 35, \u0026#39;name\u0026#39;: \u0026#39;skis\u0026#39;}, 32 36: {\u0026#39;id\u0026#39;: 36, \u0026#39;name\u0026#39;: \u0026#39;snowboard\u0026#39;}, 33 37: {\u0026#39;id\u0026#39;: 37, \u0026#39;name\u0026#39;: \u0026#39;sports ball\u0026#39;}, 34 38: {\u0026#39;id\u0026#39;: 38, \u0026#39;name\u0026#39;: \u0026#39;kite\u0026#39;}, 35 39: {\u0026#39;id\u0026#39;: 39, \u0026#39;name\u0026#39;: \u0026#39;baseball bat\u0026#39;}, 36 40: {\u0026#39;id\u0026#39;: 40, \u0026#39;name\u0026#39;: \u0026#39;baseball glove\u0026#39;}, 37 41: {\u0026#39;id\u0026#39;: 41, \u0026#39;name\u0026#39;: \u0026#39;skateboard\u0026#39;}, 38 42: {\u0026#39;id\u0026#39;: 42, \u0026#39;name\u0026#39;: \u0026#39;surfboard\u0026#39;}, 39 43: {\u0026#39;id\u0026#39;: 43, \u0026#39;name\u0026#39;: \u0026#39;tennis racket\u0026#39;}, 40 44: {\u0026#39;id\u0026#39;: 44, \u0026#39;name\u0026#39;: \u0026#39;bottle\u0026#39;}, 41 46: {\u0026#39;id\u0026#39;: 46, \u0026#39;name\u0026#39;: \u0026#39;wine glass\u0026#39;}, 42 47: {\u0026#39;id\u0026#39;: 47, \u0026#39;name\u0026#39;: \u0026#39;cup\u0026#39;}, 43 48: {\u0026#39;id\u0026#39;: 48, \u0026#39;name\u0026#39;: \u0026#39;fork\u0026#39;}, 44 49: {\u0026#39;id\u0026#39;: 49, \u0026#39;name\u0026#39;: \u0026#39;knife\u0026#39;}, 45 50: {\u0026#39;id\u0026#39;: 50, \u0026#39;name\u0026#39;: \u0026#39;spoon\u0026#39;}, 46 51: {\u0026#39;id\u0026#39;: 51, \u0026#39;name\u0026#39;: \u0026#39;bowl\u0026#39;}, 47 52: {\u0026#39;id\u0026#39;: 52, \u0026#39;name\u0026#39;: \u0026#39;banana\u0026#39;}, 48 53: {\u0026#39;id\u0026#39;: 53, \u0026#39;name\u0026#39;: \u0026#39;apple\u0026#39;}, 49 54: {\u0026#39;id\u0026#39;: 54, \u0026#39;name\u0026#39;: \u0026#39;sandwich\u0026#39;}, 50 55: {\u0026#39;id\u0026#39;: 55, \u0026#39;name\u0026#39;: \u0026#39;orange\u0026#39;}, 51 56: {\u0026#39;id\u0026#39;: 56, \u0026#39;name\u0026#39;: \u0026#39;broccoli\u0026#39;}, 52 57: {\u0026#39;id\u0026#39;: 57, \u0026#39;name\u0026#39;: \u0026#39;carrot\u0026#39;}, 53 58: {\u0026#39;id\u0026#39;: 58, \u0026#39;name\u0026#39;: \u0026#39;hot dog\u0026#39;}, 54 59: {\u0026#39;id\u0026#39;: 59, \u0026#39;name\u0026#39;: \u0026#39;pizza\u0026#39;}, 55 60: {\u0026#39;id\u0026#39;: 60, \u0026#39;name\u0026#39;: \u0026#39;donut\u0026#39;}, 56 61: {\u0026#39;id\u0026#39;: 61, \u0026#39;name\u0026#39;: \u0026#39;cake\u0026#39;}, 57 62: {\u0026#39;id\u0026#39;: 62, \u0026#39;name\u0026#39;: \u0026#39;chair\u0026#39;}, 58 63: {\u0026#39;id\u0026#39;: 63, \u0026#39;name\u0026#39;: \u0026#39;couch\u0026#39;}, 59 64: {\u0026#39;id\u0026#39;: 64, \u0026#39;name\u0026#39;: \u0026#39;potted plant\u0026#39;}, 60 65: {\u0026#39;id\u0026#39;: 65, \u0026#39;name\u0026#39;: \u0026#39;bed\u0026#39;}, 61 67: {\u0026#39;id\u0026#39;: 67, \u0026#39;name\u0026#39;: \u0026#39;dining table\u0026#39;}, 62 70: {\u0026#39;id\u0026#39;: 70, \u0026#39;name\u0026#39;: \u0026#39;toilet\u0026#39;}, 63 72: {\u0026#39;id\u0026#39;: 72, \u0026#39;name\u0026#39;: \u0026#39;tv\u0026#39;}, 64 73: {\u0026#39;id\u0026#39;: 73, \u0026#39;name\u0026#39;: \u0026#39;laptop\u0026#39;}, 65 74: {\u0026#39;id\u0026#39;: 74, \u0026#39;name\u0026#39;: \u0026#39;mouse\u0026#39;}, 66 75: {\u0026#39;id\u0026#39;: 75, \u0026#39;name\u0026#39;: \u0026#39;remote\u0026#39;}, 67 76: {\u0026#39;id\u0026#39;: 76, \u0026#39;name\u0026#39;: \u0026#39;keyboard\u0026#39;}, 68 77: {\u0026#39;id\u0026#39;: 77, \u0026#39;name\u0026#39;: \u0026#39;cell phone\u0026#39;}, 69 78: {\u0026#39;id\u0026#39;: 78, \u0026#39;name\u0026#39;: \u0026#39;microwave\u0026#39;}, 70 79: {\u0026#39;id\u0026#39;: 79, \u0026#39;name\u0026#39;: \u0026#39;oven\u0026#39;}, 71 80: {\u0026#39;id\u0026#39;: 80, \u0026#39;name\u0026#39;: \u0026#39;toaster\u0026#39;}, 72 81: {\u0026#39;id\u0026#39;: 81, \u0026#39;name\u0026#39;: \u0026#39;sink\u0026#39;}, 73 82: {\u0026#39;id\u0026#39;: 82, \u0026#39;name\u0026#39;: \u0026#39;refrigerator\u0026#39;}, 74 84: {\u0026#39;id\u0026#39;: 84, \u0026#39;name\u0026#39;: \u0026#39;book\u0026#39;}, 75 85: {\u0026#39;id\u0026#39;: 85, \u0026#39;name\u0026#39;: \u0026#39;clock\u0026#39;}, 76 86: {\u0026#39;id\u0026#39;: 86, \u0026#39;name\u0026#39;: \u0026#39;vase\u0026#39;}, 77 87: {\u0026#39;id\u0026#39;: 87, \u0026#39;name\u0026#39;: \u0026#39;scissors\u0026#39;}, 78 88: {\u0026#39;id\u0026#39;: 88, \u0026#39;name\u0026#39;: \u0026#39;teddy bear\u0026#39;}, 79 89: {\u0026#39;id\u0026#39;: 89, \u0026#39;name\u0026#39;: \u0026#39;hair drier\u0026#39;}, 80 90: {\u0026#39;id\u0026#39;: 90, \u0026#39;name\u0026#39;: \u0026#39;toothbrush\u0026#39;}} Ti·∫øp theo, ch√∫ng ta s·∫Ω load m·ªôt s·ªë h√†m gi√∫p h·ªó tr·ª£ vi·ªác h·∫≠u x·ª≠ l√Ω ·∫£nh ƒë·ªÉ v·∫Ω c√°c mask cho ch√∫ng ta xem tr·ª±c quan h∆°n.\n1 2 draw = ImageDraw.Draw(image) 3 im_width, im_height = image.size 4 if use_normalized_coordinates: 5 (left, right, top, bottom) = (xmin * im_width, xmax * im_width, 6 ymin * im_height, ymax * im_height) 7 else: 8 (left, right, top, bottom) = (xmin, xmax, ymin, ymax) 9 draw.line([(left, top), (left, bottom), (right, bottom), 10 (right, top), (left, top)], width=thickness, fill=color) 11 try: 12 font = ImageFont.truetype(\u0026#39;arial.ttf\u0026#39;, 24) 13 except IOError: 14 font = ImageFont.load_default() 15 16 # If the total height of the display strings added to the top of the bounding 17 # box exceeds the top of the image, stack the strings below the bounding box 18 # instead of above. 19 display_str_heights = [font.getsize(ds)[1] for ds in display_str_list] 20 # Each display_str has a top and bottom margin of 0.05x. 21 total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights) 22 23 if top \u0026gt; total_display_str_height: 24 text_bottom = top 25 else: 26 text_bottom = bottom + total_display_str_height 27 # Reverse list and print from bottom to top. 28 for display_str in display_str_list[::-1]: 29 text_width, text_height = font.getsize(display_str) 30 margin = np.ceil(0.05 * text_height) 31 draw.rectangle( 32 [(left, text_bottom - text_height - 2 * margin), (left + text_width, 33 text_bottom)], 34 fill=color) 35 draw.text( 36 (left + margin, text_bottom - text_height - margin), 37 display_str, 38 fill=\u0026#39;black\u0026#39;, 39 font=font) 40 text_bottom -= text_height - 2 * margin 41 42 43 44def visualize_boxes_and_labels_on_image_array( 45 image, 46 boxes, 47 classes, 48 scores, 49 category_index, 50 instance_masks=None, 51 instance_boundaries=None, 52 keypoints=None, 53 use_normalized_coordinates=False, 54 max_boxes_to_draw=20, 55 min_score_thresh=.5, 56 agnostic_mode=False, 57 line_thickness=4, 58 groundtruth_box_visualization_color=\u0026#39;black\u0026#39;, 59 skip_scores=False, 60 skip_labels=False): 61 62 box_to_display_str_map = collections.defaultdict(list) 63 box_to_color_map = collections.defaultdict(str) 64 box_to_instance_masks_map = {} 65 box_to_instance_boundaries_map = {} 66 box_to_keypoints_map = collections.defaultdict(list) 67 if not max_boxes_to_draw: 68 max_boxes_to_draw = boxes.shape[0] 69 #print(boxes) 70 for i in range(min(max_boxes_to_draw, boxes.shape[0])): 71 if scores is None or scores[i] \u0026gt; min_score_thresh: 72 box = tuple(boxes[i].tolist()) 73 if instance_masks is not None: 74 box_to_instance_masks_map[box] = instance_masks[i] 75 if instance_boundaries is not None: 76 box_to_instance_boundaries_map[box] = instance_boundaries[i] 77 if keypoints is not None: 78 box_to_keypoints_map[box].extend(keypoints[i]) 79 if scores is None: 80 box_to_color_map[box] = groundtruth_box_visualization_color 81 else: 82 display_str = \u0026#39;\u0026#39; 83 if not skip_labels: 84 if not agnostic_mode: 85 if classes[i] in category_index.keys(): 86 class_name = category_index[classes[i]][\u0026#39;name\u0026#39;] 87 else: 88 class_name = \u0026#39;N/A\u0026#39; 89 display_str = str(class_name) 90 if not skip_scores: 91 if not display_str: 92 display_str = \u0026#39;{}%\u0026#39;.format(int(100 * scores[i])) 93 else: 94 display_str = \u0026#39;{}: {}%\u0026#39;.format( 95 display_str, int(100 * scores[i])) 96 box_to_display_str_map[box].append(display_str) 97 if agnostic_mode: 98 box_to_color_map[box] = \u0026#39;DarkOrange\u0026#39; 99 else: 100 box_to_color_map[box] = STANDARD_COLORS[classes[i] % 101 len(STANDARD_COLORS)] 102 103 # Draw all boxes onto image. 104 for box, color in box_to_color_map.items(): 105 ymin, xmin, ymax, xmax = box 106 if instance_masks is not None: 107 draw_mask_on_image_array(image, box_to_instance_masks_map[box], color=color) 108 109 draw_bounding_box_on_image_array( 110 image, 111 ymin, 112 xmin, 113 ymax, 114 xmax, 115 color=color, 116 thickness=line_thickness, 117 display_str_list=box_to_display_str_map[box], 118 use_normalized_coordinates=use_normalized_coordinates) 119 120 return image 121 122 123def reframe_box_masks_to_image_masks(box_masks, boxes, image_height, 124 image_width): 125 \u0026#34;\u0026#34;\u0026#34;Transforms the box masks back to full image masks. 126 127 Embeds masks in bounding boxes of larger masks whose shapes correspond to 128 image shape. 129 130 Args: 131 box_masks: A tf.float32 tensor of size [num_masks, mask_height, mask_width]. 132 boxes: A tf.float32 tensor of size [num_masks, 4] containing the box 133 corners. Row i contains [ymin, xmin, ymax, xmax] of the box 134 corresponding to mask i. Note that the box corners are in 135 normalized coordinates. 136 image_height: Image height. The output mask will have the same height as 137 the image height. 138 image_width: Image width. The output mask will have the same width as the 139 image width. 140 141 Returns: 142 A tf.float32 tensor of size [num_masks, image_height, image_width]. 143 \u0026#34;\u0026#34;\u0026#34; 144 # TODO(rathodv): Make this a public function. 145 def reframe_box_masks_to_image_masks_default(): 146 \u0026#34;\u0026#34;\u0026#34;The default function when there are more than 0 box masks.\u0026#34;\u0026#34;\u0026#34; 147 def transform_boxes_relative_to_boxes(boxes, reference_boxes): 148 boxes = tf.reshape(boxes, [-1, 2, 2]) 149 min_corner = tf.expand_dims(reference_boxes[:, 0:2], 1) 150 max_corner = tf.expand_dims(reference_boxes[:, 2:4], 1) 151 transformed_boxes = (boxes - min_corner) / \\ 152 (max_corner - min_corner) 153 return tf.reshape(transformed_boxes, [-1, 4]) 154 155 box_masks_expanded = tf.expand_dims(box_masks, axis=3) 156 num_boxes = tf.shape(box_masks_expanded)[0] 157 unit_boxes = tf.concat( 158 [tf.zeros([num_boxes, 2]), tf.ones([num_boxes, 2])], axis=1) 159 reverse_boxes = transform_boxes_relative_to_boxes(unit_boxes, boxes) 160 return tf.image.crop_and_resize( 161 image=box_masks_expanded, 162 boxes=reverse_boxes, 163 box_ind=tf.range(num_boxes), 164 crop_size=[image_height, image_width], 165 extrapolation_value=0.0) 166 image_masks = tf.cond( 167 tf.shape(box_masks)[0] \u0026gt; 0, 168 reframe_box_masks_to_image_masks_default, 169 lambda: tf.zeros([0, image_height, image_width, 1], dtype=tf.float32)) 170 return tf.squeeze(image_masks, axis=3) Cho h√¨nh ·∫£nh v√†o v√† r√∫t ra k·∫øt qu·∫£.\n1 2def detect_frame(image_np, sess, detection_graph): 3 4 with detection_graph.as_default(): 5 6 ops = tf.get_default_graph().get_operations() 7 all_tensor_names = {output.name for op in ops for output in op.outputs} 8 tensor_dict = {} 9 for key in [ 10 \u0026#39;num_detections\u0026#39;, \u0026#39;detection_boxes\u0026#39;, \u0026#39;detection_scores\u0026#39;, 11 \u0026#39;detection_classes\u0026#39;, \u0026#39;detection_masks\u0026#39; 12 ]: 13 tensor_name = key + \u0026#39;:0\u0026#39; 14 if tensor_name in all_tensor_names: 15 tensor_dict[key] = tf.get_default_graph( 16 ).get_tensor_by_name(tensor_name) 17 if \u0026#39;detection_masks\u0026#39; in tensor_dict: 18 # The following processing is only for single image 19 detection_boxes = tf.squeeze(tensor_dict[\u0026#39;detection_boxes\u0026#39;], [0]) 20 detection_masks = tf.squeeze(tensor_dict[\u0026#39;detection_masks\u0026#39;], [0]) 21 # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size. 22 real_num_detection = tf.cast( 23 tensor_dict[\u0026#39;num_detections\u0026#39;][0], tf.int32) 24 25 detection_boxes = tf.slice(detection_boxes, [0, 0], [ 26 real_num_detection, -1]) 27 detection_masks = tf.slice(detection_masks, [0, 0, 0], [ 28 real_num_detection, -1, -1]) 29 detection_masks_reframed = reframe_box_masks_to_image_masks( 30 detection_masks, detection_boxes, image_np.shape[0], image_np.shape[1]) 31 detection_masks_reframed = tf.cast( 32 tf.greater(detection_masks_reframed, 0.5), tf.uint8) 33 # Follow the convention by adding back the batch dimension 34 tensor_dict[\u0026#39;detection_masks\u0026#39;] = tf.expand_dims( 35 detection_masks_reframed, 0) 36 image_tensor = tf.get_default_graph().get_tensor_by_name(\u0026#39;image_tensor:0\u0026#39;) 37 38 # Run inference 39 output_dict = sess.run(tensor_dict, 40 feed_dict={image_tensor: np.expand_dims(image_np, 0)}) 41 42 # all outputs are float32 numpy arrays, so convert types as appropriate 43 output_dict[\u0026#39;num_detections\u0026#39;] = int(output_dict[\u0026#39;num_detections\u0026#39;][0]) 44 #print(\u0026#34;num detect \u0026#34;+str(output_dict[\u0026#39;num_detections\u0026#39;])) 45 output_dict[\u0026#39;detection_classes\u0026#39;] = output_dict[\u0026#39;detection_classes\u0026#39;][0].astype( 46 np.uint8) 47 output_dict[\u0026#39;detection_boxes\u0026#39;] = output_dict[\u0026#39;detection_boxes\u0026#39;][0] 48 output_dict[\u0026#39;detection_scores\u0026#39;] = output_dict[\u0026#39;detection_scores\u0026#39;][0] 49 if \u0026#39;detection_masks\u0026#39; in output_dict: 50 output_dict[\u0026#39;detection_masks\u0026#39;] = output_dict[\u0026#39;detection_masks\u0026#39;][0] 51 52 visualize_boxes_and_labels_on_image_array( 53 image_np, 54 output_dict[\u0026#39;detection_boxes\u0026#39;], 55 output_dict[\u0026#39;detection_classes\u0026#39;], 56 output_dict[\u0026#39;detection_scores\u0026#39;], 57 category_index, 58 instance_masks=output_dict.get(\u0026#39;detection_masks\u0026#39;), 59 use_normalized_coordinates=True, 60 line_thickness=1, 61 max_boxes_to_draw=min(output_dict[\u0026#39;num_detections\u0026#39;],20) 62 ) 63 64 return image_np 1image = cv2.imread(\u0026#39;img2.jpg\u0026#39;) 2with detection_graph.as_default(): 3 with tf.Session(graph=detection_graph) as sess: 4 image_np = detect_frame(image, sess, detection_graph) 5 6cv2.imwrite(\u0026#39;output.jpg\u0026#39;, image) K·∫øt qu·∫£ file output.jpg c·ªßa ch√∫ng ta l√†:\nTh·ª≠ v·ªõi b·ª©c ·∫£nh ng∆∞·ªùi v√† xe h∆°i.\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi. H·∫πn g·∫∑p b·∫°n ·ªü c√°c b√†i vi·∫øt ti·∫øp theo.\n","date":"Oct 8, 2018","img":"","permalink":"/blog/2018-10-08-mask-rnn/","series":null,"tags":["Machine learning","Deeplearning","Spark"],"title":"Mask R-CNN Trong B√†i To√°n Nh·∫≠n D·∫°ng V√† Ph√¢n V√πng ƒê·ªëi T∆∞·ª£ng"},{"categories":null,"content":"L·ªùi m·ªü ƒë·∫ßu L∆∞u √Ω: ƒê·ªÉ s·ª≠ d·ª•ng ƒë∆∞·ª£c c√°c m√¥ h√¨nh trong b√†i vi·∫øt n√†y, b·∫°n ph·∫£i s·ª≠ d·ª•ng phi√™n b·∫£n opencv \u0026gt; 3.4.1.\n·ªû b√†i vi·∫øt tr∆∞·ªõc, ch√∫ng ta ƒë√£ t√¨m hi·ªÉu c√°ch th·ª©c r√∫t tr√≠ch khung x∆∞∆°ng s·ª≠ d·ª•ng DNN v√† ƒë√£ √°p d·ª•ng th√†nh c√¥ng tr√™n ·∫£nh c√≥ ch·ª©a 1 ƒë·ªëi t∆∞·ª£ng ng∆∞·ªùi. Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω th·ª±c hi·ªán √°p d·ª•ng m√¥ h√¨nh cho b√†i to√°n c√≥ nhi·ªÅu ng∆∞·ªùi trong c√πng 1 b·ª©c ·∫£nh.\nS·ª≠ d·ª•ng pretrain model trong b√†i to√°n multiple Pose Estimation Trong b√†i vi·∫øt n√†y, ch√∫ng ta ti·∫øp t·ª•c s·ª≠ d·ª•ng m√¥ h√¨nh MPI ƒë·ªÉ d√≤ t√¨m c√°c ƒëi·ªÉm ƒë·∫∑c tr∆∞ng c·ªßa con ng∆∞·ªùi v√† r√∫t ra m√¥ h√¨nh khung x∆∞∆°ng. K·∫øt qu·∫£ tr·∫£ v·ªÅ c·ªßa thu·∫≠t to√°n g·ªìm 15 ƒë·∫∑c tr∆∞ng nh∆∞ b√™n d∆∞·ªõi.\n1Head ‚Äì 0, Neck ‚Äì 1, Right Shoulder ‚Äì 2, Right Elbow ‚Äì 3, Right Wrist ‚Äì 4, 2Left Shoulder ‚Äì 5, Left Elbow ‚Äì 6, Left Wrist ‚Äì 7, Right Hip ‚Äì 8, 3Right Knee ‚Äì 9, Right Ankle ‚Äì 10, Left Hip ‚Äì 11, Left Knee ‚Äì 12, 4Left Ankle ‚Äì 13, Chest ‚Äì 14, Background ‚Äì 15 √Åp d·ª•ng m√¥ h√¨nh v·ªõi ·∫£nh c·ªßa nh√≥m T-ARA.\n1import cv2 2 3nPoints = 15 4POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ] 5 6protoFile = \u0026#34;pose/mpi/pose_deploy_linevec.prototxt\u0026#34; 7weightsFile = \u0026#34;pose/mpi/pose_iter_160000.caffemodel\u0026#34; 8 9net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile) 10 11frame = cv2.imread(\u0026#34;tara1.jpg\u0026#34;) 12 13inWidth = 368 14inHeight = 368 15 16# Prepare the frame to be fed to the network 17inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False) 18 19# Set the prepared object as the input blob of the network 20net.setInput(inpBlob) 21 22output = net.forward() Th·ª≠ show l√™n v·ªã tr√≠ v√πng c·ªï trong h√¨nh.\n1 2i = 0 3probMap = output[0, i, :, :] 4probMap = cv2.resize(probMap, (frameWidth, frameHeight)) 5 6import matplotlib.pyplot as plt 7 8plt.imshow(cv2.cvtColor(frameCopy, cv2.COLOR_BGR2RGB)) 9plt.imshow(probMap, alpha=0.5) 10plt.show() Th·ª≠ show l√™n h√¨nh ƒëi·ªÉm ƒë·∫∑c tr∆∞ng v√πng c·ªï\n1i = 1 2probMap = output[0, i, :, :] 3probMap = cv2.resize(probMap, (frameWidth, frameHeight)) 4 5import matplotlib.pyplot as plt 6 7plt.imshow(cv2.cvtColor(frameCopy, cv2.COLOR_BGR2RGB)) 8plt.imshow(probMap, alpha=0.5) 9plt.show() B·∫±ng m·ªôt s·ªë ph√©p bi·∫øn ƒë·ªïi quen thu·ªôc c√≥ s·∫µn trong opencv, ch√∫ng ta ho√†n to√†n c√≥ th·ªÉ l·∫•y ƒë∆∞·ª£c to·∫° ƒë·ªô c·ªßa c√°c ƒëi·ªÉm keypoint m·ªôt c√°ch d·ªÖ d√†ng.\n1 2# Find the Keypoints using Non Maximum Suppression on the Confidence Map 3def getKeypoints(probMap, threshold=0.1): 4 5 mapSmooth = cv2.GaussianBlur(probMap,(3,3),0,0) 6 7 mapMask = np.uint8(mapSmooth\u0026gt;threshold) 8 keypoints = [] 9 10 #find the blobs 11 _, contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) 12 13 #for each blob find the maxima 14 for cnt in contours: 15 blobMask = np.zeros(mapMask.shape) 16 blobMask = cv2.fillConvexPoly(blobMask, cnt, 1) 17 maskedProbMap = mapSmooth * blobMask 18 _, maxVal, _, maxLoc = cv2.minMaxLoc(maskedProbMap) 19 keypoints.append(maxLoc + (probMap[maxLoc[1], maxLoc[0]],)) 20 21 return keypoints 22 23 24detected_keypoints = [] 25keypoints_list = np.zeros((0,3)) 26keypoint_id = 0 27threshold = 0.1 28for i in range(nPoints): 29 probMap = output[0, i, :, :] 30 probMap = cv2.resize(probMap, (frameWidth, frameHeight)) 31 32 keypoints = getKeypoints(probMap, threshold) 33 keypoints_with_id = [] 34 for j in range(len(keypoints)): 35 keypoints_with_id.append(keypoints[j] + (keypoint_id,)) 36 keypoints_list = np.vstack([keypoints_list, keypoints[j]]) 37 keypoint_id += 1 38 39 detected_keypoints.append(keypoints_with_id) 40 41 42 43frameClone = cv2.cvtColor(frameCopy,cv2.COLOR_BGR2RGB) 44for i in range(nPoints): 45 for j in range(len(detected_keypoints[i])): 46 cv2.circle(frameClone, detected_keypoints[i][j][0:2], 3, [0,0,255], -1, cv2.LINE_AA) 47 48plt.imshow(frameClone) 49plt.show() Cu·ªëi c√πng, ch√∫ng ta s·∫Ω n·ªëi c√°c ƒëi·ªÉm ƒë·∫∑c tr∆∞ng c·ªßa c√°c nh√¢n v·∫≠t th√¥ng qua thu·∫≠t to√°n Part Affinity Heatmaps. Thu·∫≠t to√°n n√†y ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t b·ªüi nh√≥m t√°c gi·∫£ Zhe Cao, Tomas Simon,Shih-En Wei, Yaser Sheikh thu·ªôc ph√≤ng th√≠ nghi·ªám The Robotics Institute tr∆∞·ªùng ƒë·∫°i h·ªçc Carnegie Mellon. C√°c b·∫°n c√≥ nhu c·∫ßu c√≥ th·ªÉ t√¨m hi·ªÉu ·ªü https://arxiv.org/pdf/1611.08050.pdf.\n1 2mapIdx = [[16,17], [18,19], [20,21], [22,23], [24,25], [26,27], [28,29], [30,31], [32,33], [34,35], [36,37], [38,39], [40,41], [42,43]] 3 4 5 6colors = [ [0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255], 7 [0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255], 8 [0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]] 9# Find valid connections between the different joints of a all persons present 10def getValidPairs(output): 11 valid_pairs = [] 12 invalid_pairs = [] 13 n_interp_samples = 10 14 paf_score_th = 0.1 15 conf_th = 0.5 16 # loop for every POSE_PAIR 17 for k in range(len(mapIdx)): 18 # A-\u0026gt;B constitute a limb 19 pafA = output[0, mapIdx[k][0], :, :] 20 pafB = output[0, mapIdx[k][1], :, :] 21 pafA = cv2.resize(pafA, (frameWidth, frameHeight)) 22 pafB = cv2.resize(pafB, (frameWidth, frameHeight)) 23 24 25 # Find the keypoints for the first and second limb 26 candA = detected_keypoints[POSE_PAIRS[k][0]] 27 candB = detected_keypoints[POSE_PAIRS[k][1]] 28 nA = len(candA) 29 nB = len(candB) 30 31 # fig=plt.figure(figsize=(8, 8)) 32 33 # interp_coord = list(zip(np.linspace(candA[0][0], candB[0][0], num=n_interp_samples), 34 # np.linspace(candA[0][1], candB[0][1], num=n_interp_samples))) 35 36 # frameClone1 = frameClone.copy() 37 # fig.add_subplot(1, 2, 1) 38 39 # for xx in interp_coord: 40 # cv2.circle(frameClone1,(int(xx[0]),int(xx[1])), 3, [0,0,255], -1, cv2.LINE_AA) 41 42 43 # plt.imshow(cv2.cvtColor(frameClone1, cv2.COLOR_BGR2RGB)) 44 # plt.imshow(pafA, alpha=0.5) 45 46 # frameClone1 = frameClone.copy() 47 # fig.add_subplot(1, 2, 2) 48 49 50 51 52 # for xx in interp_coord: 53 # cv2.circle(frameClone1,(int(xx[0]),int(xx[1])), 3, [0,0,255], -1, cv2.LINE_AA) 54 55 # plt.imshow(cv2.cvtColor(frameClone1, cv2.COLOR_BGR2RGB)) 56 # plt.imshow(pafB, alpha=0.5) 57 # plt.show() 58 59 60 61 62 63 # If keypoints for the joint-pair is detected 64 # check every joint in candA with every joint in candB 65 # Calculate the distance vector between the two joints 66 # Find the PAF values at a set of interpolated points between the joints 67 # Use the above formula to compute a score to mark the connection valid 68 69 if( nA != 0 and nB != 0): 70 valid_pair = np.zeros((0,3)) 71 for i in range(nA): 72 max_j=-1 73 maxScore = -1 74 found = 0 75 for j in range(nB): 76 # Find d_ij 77 d_ij = np.subtract(candB[j][:2], candA[i][:2]) 78 norm = np.linalg.norm(d_ij) 79 if norm: 80 d_ij = d_ij / norm 81 else: 82 continue 83 # Find p(u) 84 interp_coord = list(zip(np.linspace(candA[i][0], candB[j][0], num=n_interp_samples), 85 np.linspace(candA[i][1], candB[j][1], num=n_interp_samples))) 86 # Find L(p(u)) 87 paf_interp = [] 88 for k in range(len(interp_coord)): 89 paf_interp.append([pafA[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))], 90 pafB[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))] ]) 91 # Find E 92 paf_scores = np.dot(paf_interp, d_ij) 93 avg_paf_score = sum(paf_scores)/len(paf_scores) 94 95 # Check if the connection is valid 96 # If the fraction of interpolated vectors aligned with PAF is higher then threshold -\u0026gt; Valid Pair 97 if ( len(np.where(paf_scores \u0026gt; paf_score_th)[0]) / n_interp_samples ) \u0026gt; conf_th : 98 if avg_paf_score \u0026gt; maxScore: 99 max_j = j 100 maxScore = avg_paf_score 101 found = 1 102 # Append the connection to the list 103 if found: 104 valid_pair = np.append(valid_pair, [[candA[i][3], candB[max_j][3], maxScore]], axis=0) 105 106 # Append the detected connections to the global list 107 valid_pairs.append(valid_pair) 108 109 pprint(valid_pair) 110 else: # If no keypoints are detected 111 print(\u0026#34;No Connection : k = {}\u0026#34;.format(k)) 112 invalid_pairs.append(k) 113 valid_pairs.append([]) 114 pprint(valid_pairs) 115 return valid_pairs, invalid_pairs 116 117# This function creates a list of keypoints belonging to each person 118# For each detected valid pair, it assigns the joint(s) to a person 119# It finds the person and index at which the joint should be added. This can be done since we have an id for each joint 120def getPersonwiseKeypoints(valid_pairs, invalid_pairs): 121 # the last number in each row is the overall score 122 personwiseKeypoints = -1 * np.ones((0, 19)) 123 124 for k in range(len(mapIdx)): 125 if k not in invalid_pairs: 126 partAs = valid_pairs[k][:,0] 127 partBs = valid_pairs[k][:,1] 128 indexA, indexB = np.array(POSE_PAIRS[k]) 129 130 for i in range(len(valid_pairs[k])): 131 found = 0 132 person_idx = -1 133 for j in range(len(personwiseKeypoints)): 134 if personwiseKeypoints[j][indexA] == partAs[i]: 135 person_idx = j 136 found = 1 137 break 138 139 if found: 140 personwiseKeypoints[person_idx][indexB] = partBs[i] 141 personwiseKeypoints[person_idx][-1] += keypoints_list[partBs[i].astype(int), 2] + valid_pairs[k][i][2] 142 143 # if find no partA in the subset, create a new subset 144 elif not found and k \u0026lt; 17: 145 row = -1 * np.ones(19) 146 row[indexA] = partAs[i] 147 row[indexB] = partBs[i] 148 # add the keypoint_scores for the two keypoints and the paf_score 149 row[-1] = sum(keypoints_list[valid_pairs[k][i,:2].astype(int), 2]) + valid_pairs[k][i][2] 150 personwiseKeypoints = np.vstack([personwiseKeypoints, row]) 151 return personwiseKeypoints 152 153valid_pairs, invalid_pairs = getValidPairs(output) 154 155personwiseKeypoints = getPersonwiseKeypoints(valid_pairs, invalid_pairs) 156 157 158for i in range(nPoints-1): 159 for n in range(len(personwiseKeypoints)): 160 161 index = personwiseKeypoints[n][np.array(POSE_PAIRS[i])] 162 if -1 in index: 163 continue 164 B = np.int32(keypoints_list[index.astype(int), 0]) 165 A = np.int32(keypoints_list[index.astype(int), 1]) 166 cv2.line(frameClone, (B[0], A[0]), (B[1], A[1]), colors[i], 3, cv2.LINE_AA) 167 168 169 170plt.imshow(frameClone) 171 # plt.imshow(mapMask, alpha=0.5) 172plt.show() H·∫πn g·∫∑p l·∫°i c√°c b·∫°n ·ªü nh·ªØng b√†i vi·∫øt ti·∫øp theo.\nB√†i vi·∫øt n√†y ƒë∆∞·ª£c vi·∫øt d·ª±a v√†o ngu·ªìn https://www.learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/ c·ªßa t√°c gi·∫£ VIKAS GUPTA. T√¥i s·ª≠ d·ª•ng t·∫≠p model v√† h√¨nh ·∫£nh kh√°c v·ªõi b√†i vi·∫øt nguy√™n g·ªëc c·ªßa t√°c gi·∫£.\n","date":"Oct 5, 2018","img":"","permalink":"/blog/2018-10-05-deep-learning-base-multiple-human-pose-estimation/","series":null,"tags":["Machine learning","Deeplearning","multiple pose estimation"],"title":"Deep Learning Based Multiple Human Pose Estimation Using OpenCV"},{"categories":null,"content":"L·ªùi m·ªü ƒë·∫ßu ƒê·ªÉ s·ª≠ d·ª•ng ƒë∆∞·ª£c c√°c m√¥ h√¨nh trong b√†i vi·∫øt n√†y, b·∫°n ph·∫£i s·ª≠ d·ª•ng phi√™n b·∫£n opencv \u0026gt; 3.4.1.\nPose Estimation l√† g√¨? Post Estimation ( ƒë√¥i khi ƒë∆∞·ª£c d√πng v·ªõi thu·∫≠t ng·ªØ Keypoint Detection) l√† m·ªôt v·∫•n ƒë·ªÅ kh√° ph·ªï bi·∫øn trong lƒ©nh v·ª±c x·ª≠ l√Ω ·∫£nh khi ch√∫ng ta c·∫ßn x√°c ƒë·ªãnh v·ªã tr√≠ v√† h∆∞·ªõng c·ªßa m·ªôt ƒë·ªëi t∆∞·ª£ng. M·ª©c √Ω nghƒ©a ·ªü ƒë√¢y l√† ch√∫ng ta ph·∫£i r√∫t ra ƒë∆∞·ª£c nh·ªØng ƒë·∫∑c ƒëi·ªÉm ch√≠nh, nh·ªØng ƒë·∫∑c ƒëi·ªÉm ƒë√≥ l√† nh·ªØng ƒë·∫∑c tr∆∞ng c·ªßa ƒë·ªëi t∆∞·ª£ng ( c√≥ th·ªÉ m√¥ t·∫£ ƒë∆∞·ª£c ƒë·ªëi t∆∞·ª£ng).\nV√≠ d·ª•, trong b√†i to√°n face pose estimation ( c√≥ t√™n kh√°c l√† facial landmark detection), ch√∫ng ta c·∫ßn x√°c ƒë·ªãnh ƒë∆∞·ª£c ƒë√¢u l√† v·ªã tr√≠ c·ªßa nh·ªØng ƒëi·ªÉm landmark tr√™n khu√¥n m·∫∑t ng∆∞·ªùi.\nM·ªôt b√†i to√°n c√≥ li√™n quan ƒë·∫øn b√†i to√°n tr√™n l√† head pose estimation. Ch√∫ng ta c·∫ßn x√°c ƒë·ªãnh nh·ªØng ƒëi·ªÉm landmark ƒë·ªÉ m√¥ h√¨nh ho√° l·∫°i ƒë∆∞·ª£c m√¥ h√¨nh 3D c·ªßa ƒë·∫ßu ng∆∞·ªùi.\n·ªû trong b√†i vi·∫øt n√†y, ch√∫ng ta ƒë·ªÅ c·∫≠p ƒë·∫øn b√†i to√°n human pose estimation, c√¥ng vi·ªác ch√≠nh l√† x√°c ƒë·ªãnh v√† ch·ªâ ra ƒë∆∞·ª£c m·ªôt ph·∫ßn/ to√†n b·ªô c√°c ph·∫ßn ch√≠nh c·ªßa c∆° th·ªÉ con ng∆∞·ªùi (vd vai, khu·ª∑u tay, c·ªï tay, ƒë·∫ßu g·ªëi v.v).\nTrong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán s·∫µn ƒë·ªÉ ch·ªâ ra c√°c ph·∫ßn ch√≠nh c·ªßa c∆° th·ªÉ con ng∆∞·ªùi. K·∫øt qu·∫£ c∆° b·∫£n c·ªßa ph·∫ßn nh·∫≠n di·ªán n√†y s·∫Ω g·∫ßn gi·ªëng nh∆∞ h√¨nh b√™n d∆∞·ªõi.\nS·ª≠ d·ª•ng pretrain model trong b√†i to√°n Pose Estimation V√†o n·∫±m 2016, 2017, Ph√≤ng th√≠ nghi·ªám Perceptual Computing c·ªßa tr∆∞·ªùng ƒë·∫°i h·ªçc Carnegie Mellon University ƒë√£ c√¥ng b·ªë m·ªôt b√†i b√°o c√≥ li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ Multi-Person Pose Estimation. V√† ƒë·∫øn nay, h·ªç ƒë√£ c√¥ng b·ªë m√¥ h√¨nh hu·∫•n luy·ªán cho ch√∫ng ta s·ª≠ d·ª•ng. C√°c b·∫°n c√≥ nhu c·∫ßu t√¨m hi·ªÉu s√¢u h∆°n c√≥ th·ªÉ ƒë·ªçc k·ªπ ngu·ªìn d·ªØ li·ªáu c·ªßa h·ªç c√¥ng b·ªë ·ªü link https://github.com/CMU-Perceptual-Computing-Lab/openpose.\nTrong b√†i post n√†y, m√¨nh s·∫Ω kh√¥ng ƒë·ªÅ c·∫≠p k·ªπ ƒë·∫øn ph·∫ßn ki·∫øn tr√∫c m·∫°ng neural net h·ªç s·ª≠ d·ª•ng b√™n d∆∞·ªõi, thay v√†o ƒë√≥, m√¨nh s·∫Ω t·∫≠p trung h∆°n v√†o c√°ch th·ª©c s·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ thu ƒë∆∞·ª£c k·∫øt qu·∫£ c·∫ßn thi·∫øt.\nTr∆∞·ªõc khi b·∫Øt ƒë·∫ßu v√†o th·ª±c h√†nh, m√¨nh s·∫Ω m√¥ t·∫£ m·ªôt ch√∫t v·ªÅ m√¥ h√¨nh pretrain c√≥ s·∫µn. ·ªû ƒë√¢y, h·ªç cung c·∫•p cho ch√∫ng ta 2 m√¥ h√¨nh l√† MPII model v√† COCO model. ƒê√≥ ch√≠nh l√† t√™n c·ªßa hai b·ªô database m√† h·ªç s·ª≠ d·ª•ng ƒë·ªÉ ƒë√†o t·∫°o m√¥ h√¨nh. K·∫øt qu·∫£ tr·∫£ v·ªÅ c·ªßa m·ªó b·ªô database l√† kh√°c nhau ho√†n to√†n.\nV·ªõi b·ªô COCO dataset, k·∫øt qu·∫£ tr·∫£ v·ªÅ l√† 18 ƒë·∫∑c tr∆∞ng g·ªìm c√°c th√¥ng tin:\n1Nose ‚Äì 0, Neck ‚Äì 1, Right Shoulder ‚Äì 2, Right Elbow ‚Äì 3, Right Wrist ‚Äì 4, 2Left Shoulder ‚Äì 5, Left Elbow ‚Äì 6, Left Wrist ‚Äì 7, Right Hip ‚Äì 8, 3Right Knee ‚Äì 9, Right Ankle ‚Äì 10, Left Hip ‚Äì 11, Left Knee ‚Äì 12, 4LAnkle ‚Äì 13, Right Eye ‚Äì 14, Left Eye ‚Äì 15, Right Ear ‚Äì 16, 5Left Ear ‚Äì 17, Background ‚Äì 18 V·ªõi b·ªô MPII, k·∫øt qu·∫£ tr·∫£ v·ªÅ l√† 15 ƒë·∫∑c tr∆∞ng g·ªìm c√°c th√¥ng tin:\n1Head ‚Äì 0, Neck ‚Äì 1, Right Shoulder ‚Äì 2, Right Elbow ‚Äì 3, Right Wrist ‚Äì 4, 2Left Shoulder ‚Äì 5, Left Elbow ‚Äì 6, Left Wrist ‚Äì 7, Right Hip ‚Äì 8, 3Right Knee ‚Äì 9, Right Ankle ‚Äì 10, Left Hip ‚Äì 11, Left Knee ‚Äì 12, 4Left Ankle ‚Äì 13, Chest ‚Äì 14, Background ‚Äì 15 Trong ph·∫ßn n√†y, ch√∫ng ta s·∫Ω t·∫≠p trung v√†o m√¥ h√¨nh MPII, m√¥ h√¨nh COCO s·ª≠ d·ª•ng t∆∞∆°ng t·ª±, ch·ªâ vi·ªác thay l·∫°i ƒë∆∞·ªùng d·∫´n file m√¥ h√¨nh l√† ƒë∆∞·ª£c.\nB·∫Øt ƒë·∫ßu code. B∆∞·ªõc 1: Download m√¥ h√¨nh.\nNh√≥m t√°c gi·∫£ s·ª≠ d·ª•ng caffe ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh, do ƒë√≥, ƒë·ªÉ s·ª≠ d·ª•ng ƒë∆∞·ª£c, ch√∫ng ta c·∫ßn download file m√¥ h√¨nh ·ªü ƒë∆∞·ªùng d·∫´n http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_iter_160000.caffemodel v√† file c·∫•u h√¨nh ·ªü ƒë∆∞·ªùng d·∫´n http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_deploy_linevec.prototxt. C√°c b·∫°n c√≥ th·ªÉ ƒë·ªÉ ƒë√¢u ƒë√≥ tu·ª≥ th√≠ch, ·ªü ƒë√¢y t√¥i ƒë·ªÉ trong th∆∞ m·ª•c pose/mpi ƒë·ªÉ d·ªÖ d√†ng nh·∫≠n bi·∫øt v·ªõi c√°c m√¥ h√¨nh kh√°c.\nB∆∞·ªõc 2: Load m√¥ h√¨nh.\nƒê·ªÉ load m√¥ h√¨nh l√™n b·ªô nh·ªõ ch√≠nh, ƒë∆°n gi·∫£n l√† ch√∫ng ta th·ª±c hi·ªán c√¢u l·ªánh sau trong python\n1import cv2 2# Specify the paths for the 2 files 3protoFile = \u0026#34;pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\u0026#34; 4weightsFile = \u0026#34;pose/mpi/pose_iter_160000.caffemodel\u0026#34; 5 6# Read the network into Memory 7net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile) ƒê∆°n gi·∫£n qu√° ph·∫£i kh√¥ng c√°c b·∫°n :).\nB∆∞·ªõc 3: ƒê·ªçc ·∫£nh v√† ƒë∆∞a ·∫£nh v√†o trong m√¥ h√¨nh.\n1 2# Read image 3frame = cv2.imread(\u0026#34;img2.jpg\u0026#34;) 4 5frameCopy = np.copy(frame) 6frameWidth = frame.shape[1] 7frameHeight = frame.shape[0] 8t = time.time() 9# Specify the input image dimensions 10inWidth = 368 11inHeight = 368 12 13# Prepare the frame to be fed to the network 14inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False) 15 16# Set the prepared object as the input blob of the network 17net.setInput(inpBlob) Ch·∫Øc kh√¥ng c·∫ßn ph·∫£i n√≥i g√¨ th√™m, ph·∫ßn comment ch√∫ th√≠ch ƒë√£ m√¥ t·∫£ kh√° ƒë·∫ßy ƒë·ªß ch·ª©c nƒÉng c·ªßa t·ª´ng ph·∫ßn trong n√†y r·ªìi.\nB∆∞·ªõc 4: Thu th·∫≠p k·∫øt qu·∫£ v√† tr√≠ch xu·∫•t ƒëi·ªÉm ƒë·∫∑c tr∆∞ng\n1 2frameCopy = frame.copy() 3 4output = net.forward() 5print(\u0026#34;time taken by network : {:.3f}\u0026#34;.format(time.time() - t)) 6H = output.shape[2] 7W = output.shape[3] 8 9nPoints = 15 10POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ] 11 12 13threshold = 0.01 14# Empty list to store the detected keypoints 15points = [] 16for i in range(nPoints): 17 # confidence map of corresponding body\u0026#39;s part. 18 probMap = output[0, i, :, :] 19 20 # Find global maxima of the probMap. 21 minVal, prob, minLoc, point = cv2.minMaxLoc(probMap) 22 23 # Scale the point to fit on the original image 24 x = (frameWidth * point[0]) / W 25 y = (frameHeight * point[1]) / H 26 27 print(prob) 28 29 if prob \u0026gt; threshold : 30 cv2.circle(frame, (int(x), int(y)), 15, (0, 255, 255), thickness=-1, lineType=cv2.FILLED) 31 cv2.putText(frame, \u0026#34;{}\u0026#34;.format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 2, lineType=cv2.LINE_AA) 32 33 # Add the point to the list if the probability is greater than the threshold 34 points.append((int(x), int(y))) 35 else : 36 points.append(None) 37 38# cv2.imshow(\u0026#34;Output-Keypoints\u0026#34;,frame) 39# cv2.waitKey(0) 40# cv2.destroyAllWindows() 41 42cv2.imwrite(\u0026#34;dot_keypoint.png\u0026#34;,frame) 43 44# Draw Skeleton 45for pair in POSE_PAIRS: 46 partA = pair[0] 47 partB = pair[1] 48 49 if points[partA] and points[partB]: 50 cv2.line(frameCopy, points[partA], points[partB], (0, 255, 255), 2) 51 cv2.circle(frameCopy, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED) 52 cv2.circle(frameCopy, points[partB], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED) 53 54 55cv2.imwrite(\u0026#34;line_keypoint.png\u0026#34;,frameCopy) K·∫øt qu·∫£ c·ªßa gi√° tr·ªã output l√† m·ªôt ma tr·∫≠n 4D, v·ªõi √Ω nghƒ©a c·ªßa m·ªói chi·ªÅu nh∆∞ sau:\nChi·ªÅu ƒë·∫ßu ti√™n l√† image ID (ƒë·ªãnh danh ·∫£nh trong tr∆∞·ªùng h·ª£p b·∫°n truy·ªÅn nhi·ªÅu ·∫£nh v√†o m·∫°ng) Chi·ªÅu th·ª© 2 l√† ch·ªâ s·ªë c·ªßa c√°c ƒëi·ªÉm ƒë·∫∑c tr∆∞ng. T·∫≠p MPI tr·∫£ v·ªÅ t·∫≠p g·ªìm 44 ƒëi·ªÉm d·ªØ li·ªáu, ta ch·ªâ s·ª≠ d·ª•ng m·ªôt v√†i ƒëi·ªÉm d·ªØ li·ªáu t∆∞∆°ng ·ª©ng v·ªõi v·ªã tr√≠ c√°c ƒëi·ªÉm ƒë·∫∑c tr∆∞ng m√† ch√∫ng ta quan t√¢m. Chi·ªÅu th·ª© 3 l√† height c·ªßa output map. Chi·ªÅu th·ª© 4 l√† width c·ªßa output map. M·ªôt l∆∞u √Ω ·ªü ƒë√¢y l√† t√¥i c√≥ s·ª≠ d·ª•ng ƒë·∫∑t gi√° tr·ªã ch·∫∑n d∆∞·ªõi threshold ƒë·ªÉ gi·∫£m thi·ªÉu s·ª± sai s√≥t do nh·∫≠n di·ªán sai. V√† k·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c l√† hai h√¨nh b√™n d∆∞·ªõi: H·∫πn g·∫∑p l·∫°i c√°c b·∫°n ·ªü nh·ªØng b√†i vi·∫øt ti·∫øp theo.\n","date":"Oct 4, 2018","img":"","permalink":"/blog/2018-10-04-deep-learning-base-human-pose-estimation/","series":null,"tags":["Machine learning","Deeplearning","pose estimation"],"title":"Deep Learning Based Human Pose Estimation Using OpenCV"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu Kh√°i ni·ªán Epoch Batch Size Iterations T·∫°i sao ph·∫£i d√πng h∆°n 1 Epoch. S·ªë l·∫ßn l·∫∑p t·ªëi ∆∞u l√† bao nhi√™u? Repeat Regularization Images L·ªùi m·ªü ƒë·∫ßu Khi m·ªõi b·∫Øt ƒë·∫ßu b∆∞·ªõc v√†o th·∫ø gi·ªõi c·ªßa ML/DL ch√∫ng ta s·∫Ω b·∫Øt g·∫∑p c√°c thu·∫≠t ng·ªØ Epoch - Batch size v√† Iterations. V√† s·∫Ω c·∫£m th·∫•y b·ªëi r·ªëi v√¨ ch√∫ng kh√° gi·ªëng nhau, nh∆∞ng th·ª±c t·∫ø l√† ch√∫ng kh√°c xa nhau.\nƒê·ªÉ cho d·ªÖ h√¨nh dung, m√¨nh l·∫•y v√≠ d·ª• v·ªÅ vi·ªác ƒÉn c∆°m. Ch√∫ng ta kh√¥ng th·ªÉ ƒÉn m·ªôt l·∫ßn h·∫øt m·ªôt ch√©n c∆°m ƒë∆∞·ª£c, m√† ph·∫£i m·ªói l·∫ßn ƒÉn ph·∫£i x√∫c t·ª´ng mu·ªón ƒÉn. X√∫c l·∫ßn l∆∞·ª£t khi h·∫øt b√°t th·ª© nh·∫•t, ch√∫ng ta l·∫°i ƒÉn ti·∫øp b√°t th·ª© 2, b√°t th·ª© 3 \u0026hellip; ƒë·∫øn khi no, k·∫øt th√∫c b·ªØa ƒÉn.\nLi√™n t∆∞·ªüng gi·ªØa vi·ªát ƒÉn c∆°m v√† c√°c thu·∫≠t ng·ªØ epoch, batch size, iteration nh∆∞ sau:\nbatch size: S·ªë h·∫°t c∆°m trong 1 l·∫ßn x√∫c.\nIteration : S·ªë l·∫ßn x√∫c c∆°m h·∫øt 1 b√°t.\nepoch : S·ªë b√°t c∆°m b·∫°n ƒÉn trong 1 b·ªØa ƒÉn.\nH·∫øt ph·∫ßn di·ªÖn gi·∫£i b·∫±ng v√≠ d·ª•. ƒê·∫øn ph·∫ßn vi·∫øt h√†n l√¢m b√™n d∆∞·ªõi, n·∫øu b·∫°n n√†o ƒë√£ hi·ªÉu r·ªìi th√¨ c√≥ th·ªÉ b·ªè qua, b·∫°n n√†o mu·ªën ƒë√†o s√¢u th√™m l√Ω do th√¨ xem m√¨nh di·ªÖn gi·∫£i b√™n d∆∞·ªõi.\nƒê·ªÉ hi·ªÉu r√µ s·ª± kh√°c bi·ªát gi·ªØa ch√∫ng, c√°c b·∫°n c·∫ßn t√¨m hi·ªÉu m·ªôt kh√°i ni·ªám v√¥ c√πng quan tr·ªçng trong machine learning - Gradient Descent.\nƒê·ªãnh nghƒ©a ng·∫Øn g·ªçn c·ªßa Gradient Descent:\nGradient Descent l√† thu·∫≠t to√°n l·∫∑p t·ªëi ∆∞u (iteractive optimization algorithm) ƒë∆∞·ª£c s·ª≠ d·ª•ng trong machine learning ƒë·ªÉ t√¨m k·∫øt qu·∫£ t·ªët nh·∫•t (minima of a curve).\nTrong ƒë√≥:\n..* Gradient c√≥ nghƒ©a l√† t·ª∑ l·ªá c·ªßa ƒë·ªô nghi√™ng c·ªßa ƒë∆∞·ªùng d·ªëc.\n..* Descent l√† t·ª´ vi·∫øt t·∫Øt c·ªßa decending - nghƒ©a l√† gi·∫£m.\nThu·∫≠t to√°n s·∫Ω l·∫∑p ƒëi l·∫∑p l·∫°i nhi·ªÅu l·∫ßn ƒë·ªÉ t√¨m ra ƒë∆∞·ª£c c·ª±c ti·ªÉu.\nhttps://medium.com/onfido-tech/machine-learning-101-be2e0a86c96a Ngu·ªìn ·∫£nh\nC√°c b·∫°n quan s√°t h√¨nh ph√≠a tr√™n b√™n tr√°i, ban ƒë·∫ßu, b∆∞·ªõc nh·∫£y kh√° l·ªõn, nghƒ©a l√† gi√° tr·ªã cost l·ªõn, v√† sau m·ªôt v√†i l·∫ßn l·∫∑p, ƒëi·ªÉm ch·∫•m ƒëen ƒëi xu·ªëng d·∫ßn, v√† gi√° tr·ªã cost nh·ªè d·∫ßn theo. M√¥ h√¨nh h·ªôi t·ª• d·∫ßn d·∫ßn ƒë·∫øn khi cost \u0026lt;= epselon\nCh√∫ng ta s·ª≠ d·ª•ng thu·∫≠t ng·ªØ epochs, batch size, iterations khi ch√∫ng ta c·∫ßn ph·∫£i trainning m√¥ h√¨nh machine learning, m√† t·∫≠p trainset c·ªßa ch√∫ng ta qu√° (r·∫•t) l·ªõn (vd 10 tri·ªáu m·∫´u, v√≠ d·ª• train m√¥ h√¨nh nh·∫≠n d·∫°ng khu√¥n m·∫∑t v·ªõi t·∫≠p ms-celeb-1m). L√∫c n√†y c√°c kh√°i ni·ªám tr√™n m·ªõi tr·ªü n√™n r√µ r√†ng, c√≤n v·ªõi tr∆∞·ªùng h·ª£p d·ªØ li·ªáu nh·ªè th√¨ ch√∫ng kh√° t∆∞∆°ng t·ª± nhau.\nKh√°i ni·ªán Epoch M·ªôt Epoch ƒë∆∞·ª£c t√≠nh l√† khi ch√∫ng ta ƒë∆∞a t·∫•t c·∫£ d·ªØ li·ªáu trong t·∫≠p train v√†o m·∫°ng neural network 1 l·∫ßn. V√≠ d·ª•, b·∫°n c√≥ 10 b·ª©c h√¨nh trong t·∫≠p train, b·∫°n ƒëem h·∫øt to√†n b·ªô 10 b·ª©c h√¨nh ƒë√≥ cho m√¥ h√¨nh h·ªçc ·ªü l·∫ßn th·ª© nh·∫•t, b·∫°n ƒë√£ train ƒë∆∞·ª£c m·ªôt epoch. Sau ƒë√≥, b·∫°n l·∫°i quay l·∫°i v·ªã tr√≠ h√¨nh ban ƒë·∫ßu r·ªìi cho to√†n b·ªô 10 b·ª©c h√¨nh ƒë√≥ h·ªçc, b·∫°n c√≥ th√™m 1 epoch n·ªØa, v·∫≠y l√† b·∫°n ƒë√£ train 2 epoch, b·∫°n l·∫∑p l·∫°i vi·ªác n√†y 100 l·∫ßn , suy ra b·∫°n ƒë√£ train 100 epoch.\nKhi d·ªØ li·ªáu qu√° l·ªõn, ch√∫ng ta kh√¥ng th·ªÉ ƒë∆∞a h·∫øt t·∫•t c·∫£ t·∫≠p d·ªØ li·ªáu v√†o ƒë·ªÉ hu·∫•n luy·ªán trong 1 l·∫ßn train ƒë∆∞·ª£c, v√¨ b·∫°n c·∫ßn m·ªôt si√™u m√°y t√≠nh c√≥ l∆∞·ª£ng RAM v√† GPU RAM c·ª±c l·ªõn ƒë·ªÉ l∆∞u tr·ªØ to√†n b·ªô h√¨nh ·∫£nh tr√™n, ƒëi·ªÅu n√†y l√† b·∫•t kh·∫£ thi ƒë·ªëi v·ªõi ng∆∞·ªùi d√πng b√¨nh th∆∞·ªùng, ph√≤ng lab nh·ªè, ho·∫∑c c√°c h·ªá th·ªëng m√°y t√≠nh hi·ªán t·∫°i. Bu·ªôc l√≤ng ch√∫ng ta ph·∫£i chia nh·ªè t·∫≠p d·ªØ li·ªáu ra, v√† kh√°i ni·ªám batch h√¨nh th√†nh.\nBatch Size Batch size l√† s·ªë l∆∞·ª£ng m·∫´u d·ªØ li·ªáu trong m·ªôt l·∫ßn train. V√≠ d·ª•, trong b√†i to√°n ph√¢n lo·∫°i ch√≥ m√®o, ch·ªçn batch size =32, nghƒ©a l√† 1 l·∫ßn train ta s·∫Ω cho ng·∫´u nhi√™n 32 b·ª©c nh√¨n ch√≥ ho·∫∑c m√®o ch·∫°y lan truy·ªÅn ti·∫øn trong m·∫°ng neural network. Ti·∫øp theo b·∫°n quƒÉng ti·∫øp 32 h√¨nh ng·∫´u nhi√™n, kh√¥ng l·∫∑p v·ªõi c√°c h√¨nh tr∆∞·ªõc ƒë√≥, v√†o m·∫°ng, quƒÉng ƒë·∫øn khi n√†o kh√¥ng c√≤n h√¨nh n√†o c√≥ th·ªÉ quƒÉng v√†o n·ªØa -\u0026gt; b·∫°n ho√†n th√†nh 1 epoch.\nIterations Iterations l√† s·ªë l∆∞·ª£ng batchs c·∫ßn ƒë·ªÉ ho√†n th√†nh 1 epoch.\n$$Iterations = data size / batch size$$\nV√≠ d·ª• ch√∫ng ta c√≥ t·∫≠p d·ªØ li·ªáu c√≥ 20,000 m·∫´u, batch size l√† 500, v·∫≠y ch√∫ng ta c·∫ßn 40 l·∫ßn l·∫∑p (iteration) ƒë·ªÉ ho√†n th√†nh 1 epoch.\nT·∫°i sao ph·∫£i d√πng h∆°n 1 Epoch. C√¢u tr·∫£ l·ªùi ·ªü ƒë√¢y l√† t·∫°i v√¨ ch√∫ng ta ƒëang d√πng thu·∫≠t to√°n t·ªëi ∆∞u l√† Gradient Descent. Thu·∫≠t to√°n n√†y ƒë√≤i h·ªèi ch√∫ng ta ph·∫£i ƒëem to√†n b·ªô d·ªØ li·ªáu qua m·∫°ng m·ªôt v√†i l·∫ßn ƒë·ªÉ t√¨m ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªëi ∆∞u. V√¨ v·∫≠y, d√πng 1 epoch th·∫≠t s·ª± kh√¥ng ƒë·ªß ƒë·ªÉ t√¨m ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªët nh·∫•t.\nV·ªõi vi·ªác ch·ªâ s·ª≠ d·ª•ng 1 l·∫ßn l·∫∑p, x√°c su·∫•t r·∫•t cao l√† d·ªØ li·ªáu s·∫Ω b·ªã underfitting(nh∆∞ h√¨nh m√¥ t·∫£ b√™n d∆∞·ªõi).\nKhi s·ªë l·∫ßn l·∫∑p tƒÉng d·∫ßn, tr·∫°ng th√°i c·ªßa m√¥ h√¨nh s·∫Ω chuy·ªÉn d·∫ßn t·ª´ underfitting sang optimal v√† sau ƒë√≥ l√† overfitting (th√¥ng th∆∞·ªùng l√† v·∫≠y, tr·ª´ khi m√¥ h√¨nh hu·∫•n luy·ªán c·ªßa b·∫°n ƒëang s·ª≠ d·ª•ng qu√° ƒë∆°n gi·∫£n, qu√° √≠t tr·ªçng s·ªë th√¨ ch√∫ng kh√¥ng th·ªÉ n√†o overfitting n·ªïi).\nCh√∫ng ta c√≥ th·ªÉ d√πng 1 epoch ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh, v·ªõi ƒëi·ªÅu ki·ªán l√† ta s·ª≠ d·ª•ng thu·∫≠t to√°n t·ªëi ∆∞u kh√¥ng ph·∫£i l√† gradient descent.\nS·ªë l·∫ßn l·∫∑p t·ªëi ∆∞u l√† bao nhi√™u? Ti·∫øc r·∫±ng kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi cho c√¢u h·ªèi n√†y. Ph·ª• thu·ªôc ho√†n to√†n v√†o nhi·ªÅu y·∫øu t·ªë. M·ª•c ti√™u chung l√† ta s·∫Ω l·∫∑p ƒë·∫øn khi n√†o h·ªôi t·ª•. C√≥ m·ªôt s·ªë ph∆∞∆°ng ph√°p gi√∫p ch√∫ng ta x√°c ƒë·ªãnh m√¥ h√¨nh ƒë√£ ƒë·ª©ng ·ªü ng∆∞·ª°ng c·ª±c ti·ªÉu c·ª•c b·ªô r·ªìi, kh√¥ng th·ªÉ xu·ªëng h∆°n ƒë∆∞·ª£c n·ªØa.\nC√°c b·∫°n c√≥ th·ªÉ t√¨m hi·ªÉu v·ªõi t·ª´ kh√≥a early stopping.\nRepeat update 13/01/2025\nG·∫ßn ƒë√¢y, v·ªõi s·ª± ph√°t tri·ªÉn c·ªßa stable diffusion v√† flux, ch√∫ng ta c√≥ th√™m tham s·ªë Repeat, ƒë∆∞·ª£c hi·ªÉu l√† s·ªë l·∫ßn 1 h√¨nh s·∫Ω ƒë∆∞·ª£c l·∫∑p l·∫°i trong qu√° tr√¨nh train.\nHi·ªÉu ƒë∆°n gi·∫£n l√† khi train lora, trong 1 batch, 1 h√¨nh trong batch ƒë√≥ s·∫Ω Repeat x l·∫ßn\nM·ª•c ti√™u c·ªßa Repeat trong stable diffusion\nBalance the number of training images to the regularization images. The number of regularization images is larger than the training, so it is required to repeat training images for using all regularization images in the epoch.\nControl \u0026lsquo;weight\u0026rsquo; over folders. If you have high quality images and low quality images, you can set higher number of repeats for high quality images, and lower for low quality.\nRegularization Images H√¨nh ·∫£nh ƒëi·ªÅu ch·ªânh (Regularization images) l√† c√°c h√¨nh ·∫£nh ƒë∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ m·ªôt ph·∫ßn c·ªßa qu√° tr√¨nh ƒëi·ªÅu ch·ªânh nh·∫±m c·∫£i thi·ªán s·ª± ·ªïn ƒë·ªãnh v√† hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh h·ªçc s√¢u (deep learning).\nQu√° tr√¨nh n√†y gi√∫p ngƒÉn m√¥ h√¨nh h·ªçc qu√° m·ª©c t·ª´ d·ªØ li·ªáu hu·∫•n luy·ªán, duy tr√¨ s·ª± c√¢n b·∫±ng gi·ªØa c√°c l·ªõp, v√† b·∫£o to√†n t√≠nh linh ho·∫°t trong vi·ªác t·∫°o ra h√¨nh ·∫£nh m·ªõi.\nRegularization gi√∫p gi·∫£i quy·∫øt hai v·∫•n ƒë·ªÅ ch√≠nh: qu√° kh·ªõp (overfitting) v√† b·∫£o to√†n l·ªõp (class preservation).\nB·∫£o To√†n L·ªõp (Class Preservation):\nKhi t·∫°o ra c√°c h√¨nh ·∫£nh ƒëi·ªÅu ch·ªânh, b·∫°n ƒëang ƒë·ªãnh nghƒ©a m·ªôt \u0026ldquo;l·ªõp\u0026rdquo; c·ªßa nh·ªØng g√¨ b·∫°n mu·ªën ngh·ªãch ƒë·∫£o. V√≠ d·ª•, n·∫øu b·∫°n ƒëang c·ªë ngh·ªãch ƒë·∫£o m·ªôt chi·∫øc m√°y bay m·ªõi, b·∫°n c√≥ th·ªÉ t·∫°o m·ªôt lo·∫°t h√¨nh ·∫£nh v·ªÅ m√°y bay ƒë·ªÉ l√†m h√¨nh ·∫£nh ƒëi·ªÅu ch·ªânh. ƒêi·ªÅu n√†y gi√∫p ƒë·∫£m b·∫£o r·∫±ng qu√° tr√¨nh hu·∫•n luy·ªán kh√¥ng b·ªã l·ªách sang m·ªôt l·ªõp kh√°c, ch·∫≥ng h·∫°n nh∆∞ \u0026ldquo;√¥ t√¥\u0026rdquo; ho·∫∑c \u0026ldquo;xe ƒë·∫°p\u0026rdquo;. Th·∫≠m ch√≠, n√≥ c√≤n gi√∫p ngƒÉn vi·ªác m√¥ h√¨nh b·ªã nghi√™ng v·ªÅ h∆∞·ªõng \u0026ldquo;m√°y bay ƒë·ªì ch∆°i\u0026rdquo; n·∫øu b·∫°n s·ª≠ d·ª•ng c√°c tham chi·∫øu th·ª±c t·∫ø thay v√¨ c√°c di·ªÖn gi·∫£i tr·ª´u t∆∞·ª£ng. Ch·ªëng Qu√° Kh·ªõp (Overfitting):\nNh·ªØng h√¨nh ·∫£nh ƒëi·ªÅu ch·ªânh n√†y c≈©ng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong qu√° tr√¨nh hu·∫•n luy·ªán ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng c√°c h√¨nh ·∫£nh b·∫°n ƒëang c·ªë ngh·ªãch ƒë·∫£o kh√¥ng b·ªã qu√° kh·ªõp. N·∫øu qu√° kh·ªõp x·∫£y ra, c√°c h√¨nh ·∫£nh ƒë∆∞·ª£c t·∫°o ra c√≥ th·ªÉ gi·ªëng h·ªát v·ªõi t·∫≠p hu·∫•n luy·ªán, l√†m m·∫•t kh·∫£ nƒÉng ch·ªânh s·ª≠a c·ªßa ch√∫ng. M·ªôt trong nh·ªØng v·∫•n ƒë·ªÅ c·ªßa ngh·ªãch ƒë·∫£o vƒÉn b·∫£n (textual inversion) l√† b·∫°n c√≥ th·ªÉ m·∫•t kh·∫£ nƒÉng ch·ªânh s·ª≠a h√¨nh ·∫£nh trong qu√° tr√¨nh ngh·ªãch ƒë·∫£o, ƒë·∫∑c bi·ªát khi hu·∫•n luy·ªán qu√° l√¢u. Vi·ªác th√™m h√¨nh ·∫£nh ƒëi·ªÅu ch·ªânh v√†o qu√° tr√¨nh hu·∫•n luy·ªán gi√∫p ngƒÉn ch·∫∑n v·∫•n ƒë·ªÅ n√†y. Hi·ªán Tr·∫°ng C·ªßa Dreambooth:\nV·ªõi c√°ch tri·ªÉn khai hi·ªán t·∫°i c·ªßa Dreambooth, m·ªôt s·ªë hi·ªán t∆∞·ª£ng l·ªách h∆∞·ªõng (drifting) v·∫´n c√≥ th·ªÉ x·∫£y ra. V√≠ d·ª•: n·∫øu b·∫°n ngh·ªãch ƒë·∫£o h√¨nh ·∫£nh m·ªôt con ·∫øch, c√°c th·∫ø h·ªá m·ªõi c√≥ th·ªÉ c√≥ ƒë·∫∑c ƒëi·ªÉm gi·ªëng ·∫øch. Tuy nhi√™n, m√¥ h√¨nh v·∫´n ho·∫°t ƒë·ªông kh√° t·ªët mi·ªÖn l√† b·∫°n gi·ªØ m·ªçi th·ª© h·ª£p l√Ω v·ªõi d·ªØ li·ªáu ƒë√£ hu·∫•n luy·ªán. T√≥m l·∫°i, h√¨nh ·∫£nh ƒëi·ªÅu ch·ªânh kh√¥ng ch·ªâ gi√∫p duy tr√¨ t√≠nh nguy√™n b·∫£n c·ªßa l·ªõp m√† b·∫°n ƒëang l√†m vi·ªác, m√† c√≤n gi·∫£m nguy c∆° qu√° kh·ªõp, c·∫£i thi·ªán kh·∫£ nƒÉng ch·ªânh s·ª≠a v√† t√≠nh linh ho·∫°t c·ªßa c√°c h√¨nh ·∫£nh ƒë∆∞·ª£c t·∫°o ra.\nNgu·ªìn c·ªßa ph·∫ßn Regularization Images https://www.reddit.com/r/StableDiffusion/comments/xu1ill/comment/iqu81m7/\nC·∫£m ∆°n c√°c b·∫°n ƒë√£ theo d√µi b√†i vi·∫øt.\nNgu·ªìn: https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9\n","date":"Oct 2, 2018","img":"https://unsplash.it/1920/1080?image=99","permalink":"/blog/2018-10-02-understanding-epoch-batchsize-iterations/","series":null,"tags":["Machine learning","Deeplearning","Epoch","Batch Size","Iteration"],"title":"Ph√¢n Bi·ªát Epoch - Batch Size V√† Iterations"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu Chu·∫©n b·ªã d·ªØ li·ªáu Loading v√† parsing d·ªØ li·ªáu. Collaborative Filtering Ch·ªçn c√°c tham s·ªë cho ALS X√¢y d·ª±ng m√¥ h√¨nh v·ªõi t·∫≠p d·ªØ li·ªáu large X√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n phim D·ª± ƒëo√°n rating c·ªßa 1 c√° nh√¢n L∆∞u tr·ªØ m√¥ h√¨nh L·ªùi m·ªü ƒë·∫ßu MovieLens l√† m·ªôt t·∫≠p d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i c√°ch ƒë√¢y nhi·ªÅu nƒÉm. H√¥m nay, m√¨nh s·∫Ω s·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu n√†y v√† m√¥ h√¨nh ALS c·ªßa spark ƒë·ªÉ x√¢y d·ª±ng ch∆∞∆°ng tr√¨nh d·ª± ƒëo√°n phim cho ng∆∞·ªùi d√πng.\nChu·∫©n b·ªã d·ªØ li·ªáu C√°c b·∫°n c√≥ th·ªÉ download t·∫≠p d·ªØ li·ªáu MovieLens ·ªü link https://grouplens.org/datasets/movielens/. C√°c b·∫°n c√≥ th·ªÉ download tr·ª±c ti·∫øp 2 file n√©n ·ªü link http://files.grouplens.org/datasets/movielens/ml-latest-small.zip v√† link http://files.grouplens.org/datasets/movielens/ml-latest.zip.\n·ªû tr√™n bao g·ªìm 2 t·∫≠p d·ªØ li·ªáu. ch√∫ng ta t·∫°o th∆∞ m·ª•c datasets v√† download r·ªìi b·ªè ch√∫ng v√†o trong th∆∞ m·ª•c ƒë·∫•y.\n1complete_dataset_url = \u0026#39;http://files.grouplens.org/datasets/movielens/ml-latest.zip\u0026#39; 2small_dataset_url = \u0026#39;http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\u0026#39; 3 4import os 5 6datasets_path = \u0026#39;datasets\u0026#39; 7if not os.path.exists(datasets_path): 8 os.makedirs(datasets_path)) 9 10complete_dataset_path = os.path.join(datasets_path, \u0026#39;ml-latest.zip\u0026#39;) 11small_dataset_path = os.path.join(datasets_path, \u0026#39;ml-latest-small.zip\u0026#39;) 12 13import urllib 14import zipfile 15 16if not os.path.exists(small_dataset_url): 17\tsmall_f = urllib.urlretrieve (small_dataset_url, small_dataset_path)#Download 18\twith zipfile.ZipFile(small_dataset_path, \u0026#34;r\u0026#34;) as z:#Gi·∫£i n√©n 19\tz.extractall(datasets_path) 20if not os.path.exists(small_dataset_url): 21\tcomplete_f = urllib.urlretrieve (complete_dataset_url, complete_dataset_path)#Download 22\twith zipfile.ZipFile(complete_dataset_path, \u0026#34;r\u0026#34;) as z:#Gi·∫£i n√©n 23\tz.extractall(datasets_path) Trong th∆∞ m·ª•c gi·∫£i n√©n, ch√∫ng ta s·∫Ω c√≥ c√°c file ratings.csv, movies.csv, tags.csv, links.csv, README.txt.\nLoading v√† parsing d·ªØ li·ªáu. M·ªói d√≤ng trong t·∫≠p ratings.csv c√≥ ƒë·ªãnh d·∫°ng \u0026quot;userId,movieId,rating,timestamp\u0026quot;.\nM·ªói d√≤ng trong t·∫≠p movies.csv c√≥ ƒë·ªãnh d·∫°ng \u0026quot;movieId,title,genres\u0026quot;.\nM·ªói d√≤ng trong t·∫≠p tags.csv c√≥ ƒë·ªãnh d·∫°ng \u0026quot;userId,movieId,tag,timestamp\u0026quot;.\nM·ªói d√≤ng trong t·∫≠p links.csv c√≥ ƒë·ªãnh d·∫°ng \u0026quot;movieId,imdbId,tmdbId\u0026quot;.\nT√≥m l·∫°i, c√°c tr∆∞·ªùng d·ªØ li·ªáu trong c√°c file csv ƒë·ªÅu ngƒÉn c√°ch nhau b·ªüi d·∫•u ph·∫©y (,). Trong python, ta c√≥ th·ªÉ d√πng h√†m split ƒë·ªÉ c·∫Øt ch√∫ng ra. Sau ƒë√≥ s·∫Ω load to√†n b·ªô d·ªØ li·ªáu l√™n RDDs.\nL∆∞u √Ω nh·ªè:\n·ªû t·∫≠p d·ªØ li·ªáu ratings, ch√∫ng ta ch·ªâ gi·ªØ l·∫°i c√°c tr∆∞·ªùng (UserID, MovieID, Rating) b·ªè ƒëi tr∆∞·ªùng timestamp v√¨ kh√¥ng c·∫ßn thi·∫øt. ·ªû t·∫≠p d·ªØ li·ªáu movies ch√∫ng ta gi·ªØ l·∫°i tr∆∞·ªùng (MovieID, Title) v√† b·ªè ƒëi tr∆∞·ªùng genres v√¨ l√Ω do t∆∞∆°ng t·ª±. 1small_ratings_file = os.path.join(datasets_path, \u0026#39;ml-latest-small\u0026#39;, \u0026#39;ratings.csv\u0026#39;) 2small_ratings_raw_data = sc.textFile(small_ratings_file) 3small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0] 4small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header).map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache() 5print(small_ratings_data.take(3)) #Hi·ªán th·ªã top 3 ratting ƒë·∫ßu ti√™n 6 7small_movies_file = os.path.join(datasets_path, \u0026#39;ml-latest-small\u0026#39;, \u0026#39;movies.csv\u0026#39;) 8 9small_movies_raw_data = sc.textFile(small_movies_file) 10small_movies_raw_data_header = small_movies_raw_data.take(1)[0] 11 12small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\ 13 .map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (tokens[0],tokens[1])).cache() 14 15small_movies_data.take(3) #Hi·ªán th·ªã top 3 movie ƒë·∫ßu ti√™n Ph·∫ßn ti·∫øp theo, ch√∫ng ta s·∫Ω t√¨m hi·ªÉu l·ªçc c·ªông t√°c (Collaborative Filtering) v√† c√°ch s·ª≠ d·ª•ng Spark MLlib ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o.\nCollaborative Filtering ·ªû ƒë√¢y, t√¥i s·∫Ω kh√¥ng ƒë·ªÅ c·∫≠p ƒë·∫øn l·ªçc c·ªông t√°c l√† g√¨, c√°c b·∫°n c√≥ nhu c·∫ßu t√¨m hi·ªÉu c√≥ th·ªÉ xem ·ªü b√†i post kh√°c ho·∫∑c tham kh·∫£o tr√™n wiki. Ch√∫ng ta s·∫Ω t·∫≠p trung v√†o t√¨m hi·ªÉu c√°ch s·ª≠ d·ª•ng ALS trong th∆∞ vi·ªán MLlib c·ªßa Spark. C√°c tham s·ªë c·ªßa thu·∫≠t to√°n n√†y bao g·ªìm:\nnumBlocks: s·ªë l∆∞·ª£ng block ƒë∆∞·ª£c s·ª≠ d·ª•ng trong t√≠nh to√°n song song (-1 v·ªõi √Ω nghƒ©a l√† auto configure).\nrank: s·ªë l∆∞·ª£ng nh√¢n t·ªë ·∫©n (latent factor) trong m√¥ h√¨nh.\niterations: s·ªë l·∫ßn l·∫∑p.\nlambda: tham s·ªë c·ªßa chu·∫©n ho√°(regularization ) trong ALS.\nimplicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\nalpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations.\nCh·ªçn c√°c tham s·ªë cho ALS ƒê·ªÉ ch·ªçn ƒë∆∞·ª£c c√°c tham s·ªë t·ªët nh·∫•t cho m√¥ h√¨nh ALS, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng t·∫≠p small ƒë·ªÉ grid search. ƒê·∫ßu ti√™n, ch√∫ng ta chia t·∫≠p d·ªØ li·ªáu th√†nh 3 ph·∫ßn l√† t·∫≠p train, t·∫≠p vali v√† t·∫≠p test. Sau ƒë√≥ ti·∫øn h√†nh hu·∫•n luy·ªán tr√™n t·∫≠p train v√† predict tr√™n t·∫≠p valid ƒë·ªÉ t√¨m ƒë∆∞·ª£c tham s·ªë t·ªët nh·∫•t. Cu·ªëi c√πng ƒë√°nh gi√° k·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c tr√™n t·∫≠p test.\n1training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0) 2validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1])) 3test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1])) 4 5from pyspark.mllib.recommendation import ALS 6import math 7 8seed = 5L 9iterations = 10 10regularization_parameter = 0.1 11ranks = [4, 8, 12] 12errors = [0, 0, 0] 13err = 0 14tolerance = 0.02 15 16min_error = float(\u0026#39;inf\u0026#39;) 17best_rank = -1 18best_iteration = -1 19for rank in ranks: 20 model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations, 21 lambda_=regularization_parameter) 22 predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2])) 23 rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions) 24 error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) 25 errors[err] = error 26 err += 1 27 print(\u0026#39;For rank %s the RMSE is %s\u0026#39; % (rank, error)) 28 if error \u0026lt; min_error: 29 min_error = error 30 best_rank = rank 31 32print(\u0026#39;The best model was trained with rank %s\u0026#39; % best_rank) K·∫øt qu·∫£ sau khi th·ª±c hi·ªán ƒëo·∫°n code tr√™n l√†:\n1For rank 4 the RMSE is 0.963681878574 2For rank 8 the RMSE is 0.96250475933 3For rank 12 the RMSE is 0.971647563632 4The best model was trained with rank 8 Ti·∫øn h√†nh th·ª±c hi·ªán test.\n1model_test = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations, 2 lambda_=regularization_parameter) 3predictions = model_test.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2])) 4rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions) 5error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) 6 7print(\u0026#39;For testing data the RMSE is %s\u0026#39; % (error)) 1For testing data the RMSE is 0.972342381898 Xem k·ªπ h∆°n m·ªôt ch√∫t v·ªÅ d·ªØ li·ªáu m√† spark tr·∫£ v·ªÅ cho ch√∫ng ta. V·ªõi predictions v√† rates_and_preds, ta c√≥:\n1print(predictions.take(3)) 1[((32, 4018), 3.280114696166238), 2 ((375, 4018), 2.7365714977314086), 3 ((674, 4018), 2.510684514310653)] T·∫≠p d·ªØ li·ªáu tr·∫£ v·ªÅ bao g·ªìm c·∫∑p (UserID, MovieID) v√† Rating (t∆∞∆°ng ·ª©ng v·ªõi colum 0, column 1 v√† column 2 ·ªü tr√™n),ƒë∆∞·ª£c hi·ªÉu ·ªü ƒë√¢y l√† v·ªõi ng∆∞·ªùi d√πng UserID v√† phim MovieID th√¨ m√¥ h√¨nh s·∫Ω d·ª± ƒëo√°n ng∆∞·ªùi d√πng s·∫Ω rating k·∫øt qu·∫£ Rating.\nSau ƒë√≥ ch√∫ng ta s·∫Ω n·ªëi(join) ch√∫ng v·ªõi t·∫≠p valid t∆∞∆°ng ·ª©ng theo c·∫∑p (UserID, MovieID), k·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c l√†:\n1rates_and_preds.take(3) 1[((558, 788), (3.0, 3.0419325487471403)), 2 ((176, 3550), (4.5, 3.3214065001580986)), 3 ((302, 3908), (1.0, 2.4728711204440765))] Vi·ªác c√≤n l·∫°i l√† ch√∫ng ta s·∫Ω t√≠nh trung b√¨nh ƒë·ªô l·ªói b·∫±ng h√†m mean() v√† sqlt().\nX√¢y d·ª±ng m√¥ h√¨nh v·ªõi t·∫≠p d·ªØ li·ªáu large Ti·∫øp theo, ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng t·∫≠p d·ª± li·ªáu b·ª± h∆°n ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh. C√°ch th·ª±c hi·ªán y chang nh∆∞ t·∫≠p d·ªØ li·ªáu nh·ªè ƒë√£ ƒë∆∞·ª£c tr√¨nh b√†y ·ªü tr√™n, n√™n t√¥i s·∫Ω b·ªè qua m·ªôt s·ªë gi·∫£i th√≠ch kh√¥ng c·∫ßn thi·∫øt ƒë·ªÉ tr√°nh l·∫∑p l·∫°i.\n1# Load the complete dataset file 2complete_ratings_file = os.path.join(datasets_path, \u0026#39;ml-latest\u0026#39;, \u0026#39;ratings.csv\u0026#39;) 3complete_ratings_raw_data = sc.textFile(complete_ratings_file) 4complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0] 5 6# Parse 7complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\ 8 .map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache() 9 10print(\u0026#34;There are %s recommendations in the complete dataset\u0026#34; % (complete_ratings_data.count())) 1There are 21063128 recommendations in the complete dataset Ti·∫øn h√†nh train v√† test.\n1training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0) 2 3complete_model = ALS.train(training_RDD, best_rank, seed=seed,iterations=iterations, lambda_=regularization_parameter) 4 5test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1])) 6 7predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2])) 8rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions) 9error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()) 10 11print(\u0026#39;For testing data the RMSE is %s\u0026#39; % (error)) 1For testing data the RMSE is 0.82183583368 X√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n phim 1complete_movies_file = os.path.join(datasets_path, \u0026#39;ml-latest\u0026#39;, \u0026#39;movies.csv\u0026#39;) 2complete_movies_raw_data = sc.textFile(complete_movies_file) 3complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0] 4 5# Parse 6complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\ 7 .map(lambda line: line.split(\u0026#34;,\u0026#34;)).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache() 8 9complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1])) 10 11print(\u0026#34;There are %s movies in the complete dataset\u0026#34; % (complete_movies_titles.count())) 1There are 27303 movies in the complete dataset 1def get_counts_and_averages(ID_and_ratings_tuple): 2 nratings = len(ID_and_ratings_tuple[1]) 3 return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings) 4 5movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey()) 6movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages) 7movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0])) Gi·∫£ s·ª≠ ch√∫ng ta c√≥ 1 ng∆∞·ªùi d√πng m·ªõi, v·ªõi c√°c ratting nh∆∞ sau:\n1new_user_ID = 0 2 3# The format of each line is (userID, movieID, rating) 4new_user_ratings = [ 5 (0,260,4), # Star Wars (1977) 6 (0,1,3), # Toy Story (1995) 7 (0,16,3), # Casino (1995) 8 (0,25,4), # Leaving Las Vegas (1995) 9 (0,32,4), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995) 10 (0,335,1), # Flintstones, The (1994) 11 (0,379,1), # Timecop (1994) 12 (0,296,3), # Pulp Fiction (1994) 13 (0,858,5) , # Godfather, The (1972) 14 (0,50,4) # Usual Suspects, The (1995) 15 ] 16new_user_ratings_RDD = sc.parallelize(new_user_ratings) 17print(\u0026#39;New user ratings: %s\u0026#39; % new_user_ratings_RDD.take(10)) 1New user ratings: [(0, 260, 9), (0, 1, 8), (0, 16, 7), (0, 25, 8), (0, 32, 9), (0, 335, 4), (0, 379, 3), (0, 296, 7), (0, 858, 10), (0, 50, 8)] Ch√∫ng ta ti·∫øn h√†nh hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh khi c√≥ th√™m ng∆∞·ªùi m·ªõi:\n1complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD) 2 3from time import time 4 5t0 = time() 6new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, 7 iterations=iterations, lambda_=regularization_parameter) 8tt = time() - t0 9 10print(\u0026#34;New model trained in %s seconds\u0026#34; % round(tt,3)) 1New model trained in 56.61 seconds Ti·∫øn h√†nh d·ª± ƒëo√°n ratting c·ªßa ng∆∞·ªùi d√πng m·ªõi cho to√†n b·ªô c√°c phim ng∆∞·ªùi d√πng ƒë√≥ ch∆∞a xem.\n1new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs 2# keep just those not on the ID list (thanks Lei Li for spotting the error!) 3new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0]))) 4 5# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies 6new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD) V√† show ra top 3 k·∫øt qu·∫£ :\n1# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating) 2new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating)) 3new_user_recommendations_rating_title_and_count_RDD = \\ 4 new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD) 5new_user_recommendations_rating_title_and_count_RDD.take(3) Hi·ªÉn th·ªã top recommend (·ªû ƒë√¢y s·∫Ω flat d·ªØ li·ªáu hi·ªÉn th·ªã th√†nh d√†ng ((Title, Rating, Ratings Count)) ra cho d·ªÖ nh√¨n).\n1new_user_recommendations_rating_title_and_count_RDD = new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1])) 2 3top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]\u0026gt;=25).takeOrdered(25, key=lambda x: -x[1]) 4 5print (\u0026#39;TOP recommended movies (with more than 25 reviews):\\n%s\u0026#39; % 6 \u0026#39;\\n\u0026#39;.join(map(str, top_movies))) 1TOP recommended movies (with more than 25 reviews): 2 (u\u0026#39;\u0026#34;Godfather: Part II\u0026#39;, 8.503749129186701, 29198) 3 (u\u0026#39;\u0026#34;Civil War\u0026#39;, 8.386497469089297, 257) 4 (u\u0026#39;Frozen Planet (2011)\u0026#39;, 8.372705479107108, 31) 5 (u\u0026#39;\u0026#34;Shawshank Redemption\u0026#39;, 8.258510064442426, 67741) 6 (u\u0026#39;Cosmos (1980)\u0026#39;, 8.252254825768972, 948) 7 (u\u0026#39;Band of Brothers (2001)\u0026#39;, 8.225114960311624, 4450) 8 (u\u0026#39;Generation Kill (2008)\u0026#39;, 8.206487040524653, 52) 9 (u\u0026#34;Schindler\u0026#39;s List (1993)\u0026#34;, 8.172761674773625, 53609) 10 (u\u0026#39;Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\u0026#39;, 8.166229786764168, 23915) 11 (u\u0026#34;One Flew Over the Cuckoo\u0026#39;s Nest (1975)\u0026#34;, 8.15617022970577, 32948) 12 (u\u0026#39;Casablanca (1942)\u0026#39;, 8.141303207981174, 26114) 13 (u\u0026#39;Seven Samurai (Shichinin no samurai) (1954)\u0026#39;, 8.139633165142612, 11796) 14 (u\u0026#39;Goodfellas (1990)\u0026#39;, 8.12931139039048, 27123) 15 (u\u0026#39;Star Wars: Episode V - The Empire Strikes Back (1980)\u0026#39;, 8.124225700242096, 47710) 16 (u\u0026#39;Jazz (2001)\u0026#39;, 8.078538221315313, 25) 17 (u\u0026#34;Long Night\u0026#39;s Journey Into Day (2000)\u0026#34;, 8.050176820606127, 34) 18 (u\u0026#39;Lawrence of Arabia (1962)\u0026#39;, 8.041331489948814, 13452) 19 (u\u0026#39;Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\u0026#39;, 8.0399424815528, 45908) 20 (u\u0026#39;12 Angry Men (1957)\u0026#39;, 8.011389274280754, 13235) 21 (u\u0026#34;It\u0026#39;s Such a Beautiful Day (2012)\u0026#34;, 8.007734839026181, 35) 22 (u\u0026#39;Apocalypse Now (1979)\u0026#39;, 8.005094327199552, 23905) 23 (u\u0026#39;Paths of Glory (1957)\u0026#39;, 7.999379786394267, 3598) 24 (u\u0026#39;Rear Window (1954)\u0026#39;, 7.9860865203540214, 17996) 25 (u\u0026#39;State of Play (2003)\u0026#39;, 7.981582126801772, 27) 26 (u\u0026#39;Chinatown (1974)\u0026#39;, 7.978673289692703, 16195) D·ª± ƒëo√°n rating c·ªßa 1 c√° nh√¢n M·ªôt tr∆∞·ªùng h·ª£p kh√°c l√† ch√∫ng ta c·∫ßn d·ª± ƒëo√°n gi√° tr·ªã ratting c·ªßa 1 ng∆∞·ªùi d√πng v·ªõi 1 b·ªô phim c·ª• th·ªÉ n√†o ƒë√≥.\n1my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994) 2individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD) 3individual_movie_rating_RDD.take(1) 1[Rating(user=0, product=122880, rating=4.955831875971526)] L∆∞u tr·ªØ m√¥ h√¨nh Sau khi c√≥ ƒë∆∞·ª£c m√¥ h√¨nh. Ch√∫ng ta c·∫ßn ph·∫£i l∆∞u tr·ªØ ch√∫ng l·∫°i ƒë·ªÉ sau n√†y d√πng.\n1from pyspark.mllib.recommendation import MatrixFactorizationModel 2 3model_path = os.path.join(\u0026#39;models\u0026#39;, \u0026#39;movie_lens_als\u0026#39;) 4 5# Save and load model 6model.save(sc, model_path) 7same_model = MatrixFactorizationModel.load(sc, model_path) ","date":"Oct 1, 2018","img":"https://unsplash.it/1920/1080?image=100","permalink":"/blog/2018-10-01-buiding-a-movie-model/","series":null,"tags":["Machine learning","Deeplearning","Spark"],"title":"X√¢y D·ª±ng Ch∆∞∆°ng Tr√¨nh G·ª£i √ù Phim D·ª±a V√†o T·∫≠p D·ªØ Li·ªáu Movie Len"},{"categories":null,"content":" L·ªùi m·ªü ƒë·∫ßu ƒê·∫ßu v√†o Ki·∫øn tr√∫c AlexNet Overlapping Max Pooling ReLu Nonlinearity Reducing overfitting Overfitting l√† g√¨? Data Augmentation Dropout L·ªùi m·ªü ƒë·∫ßu T·ª∑ ph√∫ Peter Thiel ƒë√£ t·ª´ng ƒë∆∞a ra c√¢u h·ªèi tr√©o ngoe nh∆∞ th·∫ø n√†y: \u0026ldquo;What important truth do very few people agree with you on?\u0026rdquo;\nN·∫øu b·∫°n ƒëem c√¢u n√†y h·ªèi gi√°o s∆∞ Geoffrey Hinton v√†o nƒÉm 2010, √¥ng ·∫•y s·∫Ω tr·∫£ l·ªùi r·∫±ng m·∫°ng Convolutional Neural Networks (CNN) s·∫Ω c√≥ b∆∞·ªõc ƒë·ªôt ph√° l·ªõn v√† gi√∫p ch√∫ng ta gi·∫£i quy·∫øt ho√†n to√†n b√†i to√°n ph√¢n lo·∫°i ·∫£nh. T·∫°i th·ªùi ƒëi·ªÉm nƒÉm 2010, c√°c nh√† nghi√™n c·ª©u trong lƒ©nh v·ª±c ph√¢n lo·∫°i ·∫£nh ƒë·ªÅu kh√¥ng nghƒ© nh∆∞ gi√°o s∆∞ Geoffrey Hinton. V√† Deep Learning t·∫°i th·ªùi ƒëi·ªÉm ƒë√≥ ch∆∞a th·∫≠t s·ª± gi·∫£i quy·∫øt ƒë∆∞·ª£c b√†i to√°n n√†y.\nNƒÉm 2010 c≈©ng l√† nƒÉm ra ƒë·ªùi c·ªßa cu·ªôc thi ImageNet Large Scale Visual Recognition Challenge. T·∫≠p d·ªØ li·ªáu ·∫£nh trong cu·ªôc thi bao g·ªìm kho·∫£ng 1.2 tri·ªáu ·∫£nh thu·ªôc 1000 l·ªõp kh√°c nhau, ng∆∞·ªùi th·∫Øng cu·ªôc l√† ng∆∞·ªùi t·∫°o ra m√¥ h√¨nh l√†m cho ƒë·ªô l·ªói tr√™n t·∫≠p d·ªØ li·ªáu tr√™n l√† nh·ªè nh·∫•t.\nHai nƒÉm sau, trong b√†i b√°o \u0026ldquo;ImageNet Classification with Deep Convolutional Neural Networks\u0026rdquo; c·ªßa nh√≥m t√°c gi·∫£ Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton, Geoffrey v√† c√°c c·ªông s·ª± c·ªßa m√¨nh ƒë√£ ch·ª©ng minh ƒëi·ªÅu √¥ng ·∫•y n√≥i hai nƒÉm tr∆∞·ªõc l√† ho√†n to√†n ch√≠nh x√°c. ·ªû b√†i b√°o n√†y, nh√≥m t√°c gi·∫£ ƒë√£ hu·∫•n luy·ªán m·∫°ng CNN v√† v√† ƒë·∫°t ƒë·ªô l·ªói top-5 error rate l√† 15.3% (nh√≥m t√°c gi·∫£ ƒë√£ gi√†nh h·∫°ng nh·∫•t), c√°ch bi·ªát kh√° xa so v·ªõi k·∫øt qu·∫£ c·ªßa nh√≥m ƒë·ª©ng th·ª© hai(ƒë·ªô l·ªói 26.2%). Trong c√°c nƒÉm ti·∫øp theo, r·∫•t nhi·ªÅu nh√≥m ƒë√£ nghi√™n c·ª©u, c·∫£i ti·∫øn ki·∫øn tr√∫c c·ªßa m√¥ h√¨nh CNN ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c k·∫øt qu·∫£ t·ªët h∆°n, th·∫≠m ch√≠ h∆°n lu√¥n kh·∫£ nƒÉng nh·∫≠n bi·∫øt c·ªßa con ng∆∞·ªùi.\nKi·∫øn tr√∫c m·∫°ng CNN ƒë∆∞·ª£c s·ª≠ d·ª•ng v√†o nƒÉm 2012 ƒë∆∞·ª£c c·ªông ƒë·ªìng nghi√™n c·ª©u g·ªçi v·ªõi t√™n g·ªçi th√¢n th∆∞∆°ng l√† AlexNet do t√°c gi·∫£ ch√≠nh c·ªßa nh√≥m nghi√™n c·ª©u l√† Alex Krizhevsky. ·ªû trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω ƒëi s√¢u v√†o t√¨m hi·ªÉu ki·∫øn tr√∫c AlexNet v√† ƒë√≥ng g√≥p ch√≠nh c·ªßa n√≥ trong CNN.\nƒê·∫ßu v√†o Nh∆∞ ƒë√£ ƒë·ªÅ c·∫≠p ·ªü ph·∫ßn tr√™n, m·∫°ng AlexNet ƒë√£ th·∫Øng h·∫°ng nh·∫•t trong cu·ªôc thi ILSVRC nƒÉm 2012. M√¥ h√¨nh gi·∫£i quy·∫øt b√†i to√°n ph√¢n l·ªõp m·ªôt b·ª©c ·∫£nh v√†o 1 l·ªõp trong 1000 l·ªõp kh√°c nhau (vd g√†, ch√≥, m√®o \u0026hellip; ). ƒê·∫ßu ra c·ªßa m√¥ h√¨nh l√† m·ªôt vector c√≥ 1000 ph·∫ßn t·ª≠. Ph·∫ßn t·ª≠ th·ª© i c·ªßa vector ƒë·∫°i di·ªán cho x√°c su·∫•t b·ª©c ·∫£nh thu·ªôc v·ªÅ l·ªõp th·ª© i. Do ƒë√≥, t·ªïng c·ªßa c√°c ph·∫ßn t·ª≠ trong vector l√† 1.\nƒê·∫ßu v√†o c·ªßa m·∫°ng AlexNet l√† m·ªôt b·ª©c ·∫£nh RGB c√≥ k√≠ch th∆∞·ªõc 256x256 pixel. To√†n b·ªô c√°c b·ª©c ·∫£nh c·ªßa t·∫≠p train v√† t·∫≠p test ƒë·ªÅu c√≥ c√πng k√≠ch th∆∞·ªõc l√† 256x256. N·∫øu m·ªôt b·ª©c ·∫£nh n√†o ƒë√≥ kh√¥ng c√≥ k√≠ch th∆∞·ªõc 256x256, b·ª©c ·∫£nh ƒë√≥ s·∫Ω ƒë∆∞·ª£c chuy·ªÉn v·ªÅ k√≠ch th∆∞·ªõc ƒë√∫ng 256x256. Nh·ªØng b·ª©c h√¨nh c√≥ k√≠ch th∆∞·ªõc nh·ªè h∆°n 256 th√¨ s·∫Ω ƒë∆∞·ª£c ph√≥ng b·ª± l√™n ƒë·∫øn k√≠ch th∆∞·ªõc 256, nh·ªØng b·ª©c h√¨nh n√†o c√≥ k√≠ch th∆∞·ªõc l·ªõn h∆°n 256 th√¨ s·∫Ω ƒë∆∞·ª£c c·∫Øt lo·∫°i ph·∫ßn th·ª´a ƒë·ªÉ nh·∫≠n ƒë∆∞·ª£c b·ª©c h√¨nh c√≥ k√≠ch th∆∞·ªõc 256x256. H√¨nh ·∫£nh ·ªü d∆∞·ªõi l√† m·ªôt v√≠ d·ª• v·ªÅ vi·ªác ƒëi·ªÅu ch·ªânh b·ª©c ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc 256x256.\nN·∫øu ·∫£nh ƒë·∫ßu v√†o l√† ·∫£nh x√°m (grayscale), b·ª©c ·∫£nh tr√™n s·∫Ω ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi th√†nh ƒë·ªãnh d·∫°ng RGB b·∫±ng c√°ch t·∫°o ra 3 layer k√™nh m√†u gi·ªëng nhau t·ª´ ·∫£nh x√°m.\nSau khi chu·∫©n ho√° h·∫øt t·∫•t c·∫£ c√°c ·∫£nh v·ªÅ d·∫°ng 256x256x3, nh√≥m t√°c gi·∫£ ch·ªâ s·ª≠ d·ª•ng m·ªôt ph·∫ßn c·ªßa b·ª©c ·∫£nh c√≥ k√≠ch th∆∞·ªõc 227x227x3 c·ªßa m·ªôt b·ª©c ·∫£nh l√†m ƒë·∫ßu v√†o cho m·∫°ng neural network. Trong b√†i b√°o nh√≥m t√°c gi·∫£ ghi l√† 224x224, nh∆∞ng ƒë√¢y l√† m·ªôt l·ªói nh·ªè c·ªßa nh√≥m t√°c gi·∫£, v√† k√≠ch th∆∞·ªõc th·ª±c t·∫ø ƒë·∫ßu v√†o c·ªßa b·ª©c ·∫£nh l√† 227x227.\nKi·∫øn tr√∫c AlexNet Ki·∫øn tr√∫c AlexNet l·ªõn h∆°n nhi·ªÅu so v·ªõi c√°c ki·∫øn tr√∫c CNNs ƒë∆∞·ª£c s·ª≠ d·ª•ng trong th·ªã gi√°c m√°y t√≠nh tr∆∞·ªõc kia (tr∆∞·ªõc nƒÉm 2010), vd ki·∫øn tr√∫c LeNet c·ªßa Yann LeCun nƒÉm 1998. N√≥ c√≥ 60 tri·ªáu tham s·ªë v√† 650000 neural v√† t·ªën kho·∫£ng t·ª´ nƒÉm ƒë·∫øn s√°u ng√†y hu·∫•n luy·ªán tr√™n hai GPU GTX 580 3GB. Ng√†y nay, v·ªõi s·ª± ti·∫øn b·ªô v∆∞·ª£t b·∫≠t c·ªßa GPU, ch√∫ng ta c√≥ nhi·ªÅu ki·∫øn tr√∫c CNN c√≥ c·∫•u tr√∫c ph·ª©c t·∫°p h∆°n, v√† ho·∫°t ƒë·ªông r·∫•t hi·ªáu qu·∫£ tr√™n nh·ªØng t·∫≠p d·ªØ li·ªáu ph·ª©c t·∫°p. Nh∆∞ng t·∫°i th·ªùi ƒëi·ªÉm nƒÉm 2012 th√¨ vi·ªác hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi l∆∞·ª£ng tham s·ªë v√† neural l·ªõn nh∆∞ v·∫≠y l√† m·ªôt v·∫•n ƒë·ªÅ c·ª±c k·ª≥ kh√≥ khƒÉn. Nh√¨n k·ªπ v√†o h√¨nh b√™n d∆∞·ªõi ƒë·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ ki·∫øn tr√∫c AlexNet. AlexNet bao g·ªìm 5 convolution Layer v√† 3 Fully connected Layers.\nNh·ªØng convolution layer ( hay c√≤n g·ªçi v·ªõi t√™n kh√°c l√† c√°c filter) r√∫t tr√≠ch c√°c th√¥ng tin h·ªØu √≠ch trong c√°c b·ª©c ·∫£nh. Trong m·ªôt convolution layer b·∫•t k·ª≥ th∆∞·ªùng bao g·ªìm nhi·ªÅu kernel c√≥ c√πng k√≠ch th∆∞·ªõc. V√≠ d·ª• nh∆∞ convolution layer ƒë·∫ßu ti√™n c·ªßa AlexNet ch·ª©a 96 kernel c√≥ k√≠ch th∆∞·ªõc 11x11x3. Th√¥ng th∆∞·ªùng th√¨ width v√† height c·ªßa m·ªôt kernel b·∫±ng nhau, v√† ƒë·ªô s√¢u (depth) th∆∞·ªùng b·∫±ng s·ªë l∆∞·ª£ng k√™nh m√†u.\nConvolutional 1 v√† convolution 2 k·∫øt n·ªëi v·ªõi nhau qua m·ªôt Overlapping Max Pooling ·ªü gi·ªØa. T∆∞∆°ng t·ª± nh∆∞ v·∫≠y gi·ªØa convolution 2 v√† convolution 3. Convolutional 3, convolution 4, convolution 5 k·∫øt n·ªëi tr·ª±c ti·∫øp v·ªõi nhau, kh√¥ng th√¥ng qua trung gian. Convolutional 5 k·∫øt n·ªëi fully connected layter 1 th√¥ng qua m·ªôt Overlapping Max pooling, ti·∫øp theo m√† m·ªôt fully connected layter n·ªØa. V√† cu·ªëi c√πng l√† m·ªôt b·ªô ph√¢n l·ªõp softmax v·ªõi 1000 l·ªõp nh√£n (c√°c b·∫°n c√≥ th·ªÉ xem h√¨nh ki·∫øn tr√∫c m·∫°ng AlexNet ·ªü tr√™n ƒë·ªÉ c√≥ c√°i nh√¨n t·ªïng qu√°t h∆°n).\nReLU nonlinerity ƒë∆∞·ª£c s·ª≠ d·ª•ng sau t·∫•t c√°c c√°c convolution v√† fully connected layer. Tr∆∞·ªõc ƒë√¢y, ReLU nonlinerity c·ªßa l·ªõp convolution 1 v√† 2 th∆∞·ªùng theo sau b·ªüi m·ªôt b∆∞·ªõc chu·∫©n ho√° c·ª•c b·ªô (local normalization) r·ªìi m·ªõi th·ª±c hi·ªán pooling. Tuy nhi√™n, c√°c nghi√™n c·ª©u sau ƒë√≥ nh·∫≠n th·∫•y r·∫±ng vi·ªác s·ª≠ d·ª•ng normalization kh√¥ng th·∫≠t s·ª± h·ªØu √≠ch. Do v·∫≠y ch√∫ng ta s·∫Ω kh√¥ng ƒëi chi ti·∫øt v·ªÅ v·∫•n ƒë·ªÅ ƒë√≥.\nOverlapping Max Pooling Max Pooling layer th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ gi·∫£m chi·ªÅu r·ªông v√† chi·ªÅu d√†i c·ªßa m·ªôt tensor nh∆∞ng v·∫´n gi·ªØ nguy√™n chi·ªÅu s√¢u. Overlapping Max Pool layter c≈©ng t∆∞∆°ng t·ª± nh∆∞ Max Pool layter, ngo·∫°i tr·ª´ vi·ªác l√† m·ªôt window c·ªßa b∆∞·ªõc n√†y s·∫Ω c√≥ m·ªôt ph·∫ßn ch·ªìng l√™n window c·ªßa b∆∞·ªõc ti·∫øp theo. T√°c gi·∫£ s·ª≠ d·ª•ng pooling c√≥ k√≠ch th∆∞·ªõc 3x3 v√† b∆∞·ªõc nh·∫£y l√† 2 gi·ªØa c√°c pooling. Nghƒ©a l√† gi·ªØa pooling n√†y v√† pooling kh√°c s·∫Ω overlapping v·ªõi nhau 1 pixel. C√°c th√≠ nghi·ªám th·ª±c t·∫ø ƒë√£ ch·ª©ng minh r·∫±ng vi·ªác s·ª≠ d·ª•ng overlapping gi·ªØa c√°c pooling gi√∫p gi·∫£m ƒë·ªô l·ªói top-1 error 0.4% v√† top-5 error l√† 0.3% khi so v·ªõi vi·ªác s·ª≠ d·ª•ng pooling c√≥ k√≠ch th∆∞·ªõc 2x2 v√† b∆∞·ªõc nh·∫£y 2 (vector output c·ªßa c·∫£ hai ƒë·ªÅu c√≥ s·ªë chi·ªÅu b·∫±ng nhau).\nReLu Nonlinearity M·ªôt c·∫£i ti·∫øn quan tr·ªçng kh√°c c·ªßa AlexNet l√† vi·ªác s·ª≠ d·ª•ng h√†m phi tuy·∫øn ReLU. Tr∆∞·ªõc ƒë√¢y, c√°c nh√≥m nghi√™n c·ª©u kh√°c th∆∞·ªùng s·ª≠ d·ª•ng h√†m k√≠ch ho·∫°t l√† h√†m Tanh ho·∫∑c h√†m Sigmoid ƒë·ªÉ hu·∫•n luy√™n m√¥ h√¨nh neural network. AlexNet ch·ªâ ra r·∫±ng, khi s·ª≠ d·ª•ng ReLU, m√¥ h√¨nh deep CNN s·∫Ω hu·∫•n luy·ªán nhanh h∆°n so v·ªõi vi√™c s·ª≠ d·ª•ng tanh ho·∫∑c sigmoid. H√¨nh b√™n d∆∞·ªõi ƒë∆∞·ª£c r√∫t ra t·ª´ b√†i b√°o ch·ªâ ra r·∫±ng v·ªõi vi·ªác s·ª≠ d·ª•ng ReLU (ƒë∆∞·ªùng n√©t li·ªÅn trong h√¨nh), AlexNet ƒë·∫°t ƒë·ªô l·ªói 25% tr√™n t·∫≠p hu·∫•n luy·ªán v√† nhanh h∆°n g·∫•p 6 l·∫ßn so v·ªõi m√¥ h√¨nh t∆∞∆°ng t·ª± nh∆∞ng s·ª≠ d·ª•ng Tanh (ƒë∆∞·ªùng n√©t ƒë·ª©t trong h√¨nh). Th√≠ nghi·ªám tr√™n s·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu CIFAR-10 ƒë·ªÉ hu·∫•n luy·ªán.\nƒê·ªÉ hi·ªÉu r√µ h∆°n l√Ω do v√¨ sao ReLU l·∫°i nhanh h∆°n so v·ªõi c√°c h√†m kh√°c, ch√∫ng ta h√£y ƒë·ªëi s√°nh h√¨nh d·∫°ng gi√° tr·ªã output c·ªßa c√°c h√†m tr√™n.\nC√¥ng th·ª©c c·ªßa ReLU l√†: f(X) = max(0,x)\nNh√¨n k·ªπ v√†o h√¨nh tr√™n, ta c√≥ nh·∫≠n x√©t r·∫±ng: h√†m tanh ƒë·∫°t gi√° tr·ªã b√£o ho√† khi gi√° tr·ªã z \u0026gt;2.5 v√† z \u0026lt; -2.5 (s·ªë 2.5 l√† s·ªë c·∫£m t√≠nh c·ªßa m√¨nh). V√† t·∫°i v√πng |z|\u0026gt;2.5, th√¨ ƒë·ªô d·ªëc c·ªßa h√†m h·∫ßu nh∆∞ g·∫ßn nh∆∞ b·∫±ng 0, |z| c√†ng l·ªõn th√¨ ƒë·ªô d·ªëc c√†ng g·∫ßn 0 h∆°n. V√¨ l√Ω do n√†y n√™n gradient descent s·∫Ω h·ªôi t·ª• ch·∫≠m. C√≤n ƒë·ªëi v·ªõi h√†m ReLU, v·ªõi gi√° tr·ªã z d∆∞∆°ng th√¨ ƒë·ªô d·ªëc c·ªßa h√†m kh√¥ng g·∫ßn b·∫±ng 0 nh∆∞ h√†m tanh. ƒêi·ªÅu n√†y gi√∫p cho vi·ªác h·ªôi t·ª• x·∫£y ra nhanh h∆°n. V·ªõi gi√° tr·ªã z √¢m, ƒë·ªô d·ªëc b·∫±ng 0, tuy nhi√™n, h·∫ßu h·∫øt c√°c gi√° tr·ªã c·ªßa c√°c neural trong m·∫°ng th∆∞·ªùng c√≥ gi√° tr·ªã d∆∞∆°ng, n√™n tr∆∞·ªùng h·ª£p √¢m √≠t (hi·∫øm) khi x·∫£y ra. ReLU hu·∫•n luy·ªán nhanh h∆°n so v·ªõi sigmoid c≈©ng b·ªüi l√Ω do t∆∞∆°ng t·ª±.\nReducing overfitting Overfitting l√† g√¨? Khi b·∫°n d·∫°y m·ªôt ƒë·ª©a tr·∫ª t·ª´ 2-5 tu·ªïi v·ªÅ vi·ªác c·ªông hai s·ªë, ch√∫ng s·∫Ω h·ªçc r·∫•t nhanh v√† tr·∫£ l·ªùi ƒë√∫ng h·∫ßu h·∫øt c√°c c√¢u h·ªèi m√† ch√∫ng ta ƒë√£ d·∫°y ch√∫ng. Tuy nhi√™n, ch√∫ng s·∫Ω tr·∫£ l·ªùi sai ƒë·ªëi v·ªõi nh·ªØng c√¢u h·ªèi h∆°i l·∫Øc l√©o m·ªôt ch√∫t (c√¢u h·ªèi t∆∞∆°ng t·ª± c√¢u ch√∫ng ta ƒë√£ d·∫°y, nh∆∞ng th√™m m·ªôt x√≠u th√¥ng tin ƒë√≤i h·ªèi tr·∫ª ph·∫£i suy nghƒ©), ho·∫∑c c√°c c√¢u h·ªèi ch∆∞a ƒë∆∞·ª£c d·∫°y. L√Ω do ch√∫ng tr·∫£ l·ªùi sai nh·ªØng c√¢u h·ªèi ƒë√≥ l√† khi tr·∫£ l·ªùi nh·ªØng c√¢u h·ªèi ƒë∆∞·ª£c d·∫°y, ch√∫ng th∆∞·ªùng nh·ªõ l·∫°i c√¢u tr·∫£ l·ªùi, ch·ª© kh√¥ng th·ª±c s·ª± hi·ªÉu c√¢u h·ªèi. C√°i n√†y ·ªü Vi·ªát Nam ta g·ªçi l√† h·ªçc v·∫πt.\nT∆∞∆°ng t·ª± v·∫≠y, Neural network ch√≠nh b·∫£n th√¢n n√≥ c√≥ kh·∫£ nƒÉng h·ªçc ƒë∆∞·ª£c nh·ªØng g√¨ ƒë∆∞·ª£c d·∫°y, tuy nhi√™n, n·∫øu qu√° tr√¨nh hu·∫•n luy·ªán c·ªßa b·∫°n kh√¥ng t·ªët, m√¥ h√¨nh c√≥ kh·∫£ nƒÉng s·∫Ω gi·ªëng nh∆∞ nh·ªØng ƒë·ª©a tr·∫ª tr√™n kia, h·ªìi t∆∞·ªüng l·∫°i nh·ªØng g√¨ ƒë√£ d·∫°y cho ch√∫ng m√† kh√¥ng hi·ªÉu b·∫£n ch·∫•t. V√† k·∫øt qu·∫£ Neural Network s·∫Ω ho·∫°t ƒë·ªông t·ªët tr√™n t·∫≠p hu·∫•n luy·ªán ( nh∆∞ng ch√∫ng kh√¥ng r√∫t ra ƒë∆∞·ª£c b·∫£n ch·∫•t ch√≠nh c·ªßa v·∫•n ƒë·ªÅ), v√† k·∫øt qu·∫£ tr√™n t·∫≠p test t·ªá. Ng∆∞·ªùi ta g·ªçi tr∆∞·ªùng h·ª£p tr√™n l√† overfitting.\nNh√≥m nghi√™n c·ª©u AlexNet s·ª≠ d·ª•ng nhi·ªÅu ph∆∞∆°ng ph√°p kh√°c nhau ƒë·ªÉ gi·∫£m overfitting.\nData Augmentation Vi·ªác s·ª≠ d·ª•ng nhi·ªÅu bi·∫øn th·ªÉ kh√°c nhau c·ªßa m·ªôt b·ª©c h√¨nh c√≥ th·ªÉ gi√∫p ngƒÉn m√¥ h√¨nh kh√¥ng b·ªã overfitting. V·ªõi vi·ªác s·ª≠ d·ª•ng nhi·ªÅu bi·∫øn th·ªÉ c·ªßa 1 b·ª©c h√¨nh, b·∫°n b·∫Øt √©p m√¥ h√¨nh kh√¥ng h·ªçc v·∫πt d·ªØ li·ªáu. C√≥ nhi·ªÅu c√°ch kh√°c nhau ƒë·ªÉ sinh ra d·ªØ li·ªáu m·ªõi d·ª±a v√†o d·ªØ li·ªáu c√≥ s·∫µn. M·ªôt v√†i c√°c m√† nh√≥m AlexNet ƒë√£ s·ª≠ d·ª•ng l√†.\nData Augmentation by Mirroring √ù t∆∞·ªüng c·ªßa vi·ªác n√†y l√† l·∫•y ·∫£nh trong g∆∞∆°ng c·ªßa m·ªôt b·ª©c h√¨nh (·∫£nh ·∫£o). Nh√¨n v√†o ·∫£nh b√™n d∆∞·ªõi, b√™n tr√°i l√† h√¨nh g·ªëc c·ªßa con m√®o trong t·∫≠p hu·∫•n luy·ªán, b√™n ph·∫£i l√† ·∫£nh c·ªßa con m√®o khi th√™m hi·ªáu ·ª©ng h√¨nh qua g∆∞∆°ng (ƒë∆°n gi·∫£n l√† xoay qua tr·ª•c y l√† ƒë∆∞·ª£c ) Data Augmentation by Random Crops Vi·ªác l·ª±a ch·ªçn v·ªã tr√≠ ·∫£nh g·ªëc m·ªôt c√°ch ng·∫´u nhi√™n c≈©ng gi√∫p ch√∫ng ta c√≥ th√™m m·ªôt ·∫£nh kh√°c so v·ªõi ·∫£nh g·ªëc ban ƒë·∫ßu.\nNh√≥m t√°c gi·∫£ c·ªßa AlexNet r√∫t tr√≠ch ng·∫´u nhi√™n b·ª©c ·∫£nh c√≥ k√≠ch th∆∞·ªõc 227x227 t·ª´ b·ª©c ·∫£nh 256x256 ban ƒë·∫ßu l√†m input d·∫ßu v√†o cho m√¥ h√¨nh. B·∫±ng c√°ch n√†y, ch√∫ng ta c√≥ th·ªÉ tƒÉng s·ªë l∆∞·ª£ng d·ªØ li·ªáu l√™n g·∫•p 2048 l·∫ßn b·∫±ng vi·ªác s·ª≠ d·ª•ng c√°ch n√†y.\nB·ªën b·ª©c ·∫£nh ƒë∆∞·ª£c crop ng·∫´u nhi√™n ·ªü tr√™n tho·∫°t nh√¨n c√≥ v·∫ª gi·ªëng nhau, nh∆∞ng th·ª±c ch·∫•t kh√¥ng ph·∫£i nh∆∞ v·∫≠y.\nV·ªõi vi·ªác s·ª≠ d·ª•ng Data Augmentation, ch√∫ng ta ƒëang b·ªë g·∫Øng d·∫°y cho m√¥ h√¨nh r·∫±ng v·ªõi vi·ªác nh√¨n h√¨nh con m√®o qua g∆∞∆°ng, n√≥ v·∫´n l√† con m√®o, ho·∫∑c h√¨nh h√¨nh con m√®o ·ªü b·∫•t k·ª≥ g√≥c ƒë·ªô n√†o th√¨ n√≥ v·∫´n l√† n√≥.\nDropout V·ªõi g·∫ßn 60 tri·ªáu tham s·ªë trong t·∫≠p hu·∫•n luy·ªán, vi·ªác overfitting x·∫£y ra l√† ƒëi·ªÅu d·ªÖ hi·ªÉu. C√°c t√°c gi·∫£ c·ªßa AlexNet ƒë√£ th·ª±c nghi·ªám nhi·ªÅu c√°ch n·ªØa ƒë·ªÉ gi·∫£m overfitting. H·ªç s·ª≠ d·ª•ng m·ªôt k·ªπ thu·∫≠t g·ªçi l√† dropout - k·ªπ thu·∫≠t n√†y ƒë∆∞·ª£c gi·ªõi thi·ªáu ·ªü b√†i b√°o kh√°c c·ªßa G.E. Hintol v√†o nƒÉm 2012. K·ªπ thu·∫≠t n√†y kh√° ƒë∆°n gi·∫£n, m·ªôt neural s·∫Ω c√≥ x√°c su·∫•t b·ªã lo·∫°i kh·ªèi m√¥ h√¨nh l√† 0.5. Khi m·ªôt neural b·ªã lo·∫°i kh·ªèi m√¥ h√¨nh, n√≥ s·∫Ω kh√¥ng ƒë∆∞·ª£c tham qia v√†o qu√° tr√¨nh lan truy·ªÅn ti·∫øn ho·∫∑c lan truy·ªÅn ng∆∞·ª£c. Cho n√™n, m·ªói gi√° tr·ªã input s·∫Ω ƒëi qua m·ªôt ki·∫øn tr√∫c m·∫°ng kh√°c nhau. Nh∆∞ m√¥ t·∫£ ·ªü h√¨nh ƒë·ªông ·ªü d∆∞·ªõi, k·∫øt qu·∫£ l√† gi√° tr·ªã c·ªßa tham s·ªë tr·ªçng s·ªë s·∫Ω t·ªët h∆°n v√† kh√≥ b·ªã overfitting h∆°n. Trong qu√° tr√¨nh test, to√†n b·ªô network ƒë∆∞·ª£c s·ª≠ d·ª•ng, kh√¥ng c√≥ dropout, tuy nhi√™n, gi√° tr·ªã output s·∫Ω scaled b·ªüi tham s·ªë 0.5 t∆∞∆°ng ·ª©ng v·ªõi nh·ªØng neural kh√¥ng s·ª≠ d·ª•ng trong qu√° tr√¨nh trainning. V·ªõi vi·ªác s·ª≠ d·ª•ng dropout, ch√∫ng ta s·∫Ω tƒÉng g·∫•p ƒë√¥i l·∫ßn l·∫∑p c·∫ßn thi·∫øt ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c ƒë·ªô h·ªôi t·ª•, nh∆∞ng khi kh√¥ng s·ª≠ d·ª•ng dropout, m·∫°ng AlexNet r·∫•t d·ªÖ b·ªã overfitting.\nNg√†y nay, chu·∫©n ho√° dropout l√† m·ªôt y·∫øu t·ªë kh√¥ng th·ªÉ thi·∫øu v√† c√°c m√¥ h√¨nh s·ª≠ d·ª•ng n√≥ th∆∞·ªùng c√≥ k·∫øt qu·∫£ t·ªët h∆°n so v·ªõi m√¥ h√¨nh t∆∞∆°ng t·ª± kh√¥ng s·ª≠ d·ª•ng dropout. Ch√∫ng ta s·∫Ω b√†n s√¢u h∆°n v·ªÅ dropout ·ªü m·ªôt b√†i kh√°c trong t∆∞∆°ng lai.\nTham kh·∫£o\nImageNet Classification with Deep Convolutional Neural Networks by Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton, 2012\nhttps://www.learnopencv.com/understanding-alexnet/\n","date":"Jun 15, 2018","img":"https://unsplash.it/1920/1080?image=35","permalink":"/blog/2018-06-15-understanding-alexnet/","series":null,"tags":["Machine learning","Deeplearning","AlexNet"],"title":"T√¨m Hi·ªÉu V·ªÅ M·∫°ng Neural Network AlexNet"},{"categories":null,"content":"Chapter 9: References Introduction to References Declaring and using references Comparing pointers and references References and const\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/10_references/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 10: Character Manipulation and Strings Introduction to Strings Character Manipulation C-string manipulation C-String concatenation and copy Introducing std::string Declaring and using std::string\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/11_string/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 11: Functions The One Definition Rule First Hand on C++ Functions Function Declaration and Function Definitions Multiple Files - Compilation Model Revisited Pass by value Pass by pointer Pass by reference\nChapter 12: Getting Things out of functions Introduction to getting things out of functions Input and output parameters Returning from functions by value\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/12_function/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 13: Function Overloading Function Overloading Introduction Overloading with different parameters\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/13_function_overloading/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 14: Lambda functions Introduction to Lambda Functions Declaring and using lambda functions Capture lists Capture all in context Summary\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/14_lambda_function/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 15: Function Templates Introduction to function templates Trying out function templates Template type deduction and explicit arguments Template parameters by reference Template specialization\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/15_function_template/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 16: C++20 Concepts Crash course Introduction to C++20 Concepts Using C++20 Concepts Building your own C++20 Concepts Zooming in on the requires clause Combining C++20 Concepts C++20 Concepts and auto\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/16_concept/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 17: Classes Introduction to classes Your First Class C++ Constructors Defaulted constructors Setters and Getters Class Across Multiple Files Arrow pointer call notation Destructors Order of Constructor Destructor Calls The this Pointer struct Size of objects\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/17_class/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 18: Inheritance Introduction to Inheritance First try on Inheritance Protected members Base class access specifiers : Zooming in Base class access specifiers - A demo Closing in on Private Inheritance Resurrecting Members Back in Context Default Constructors with Inheritance Custom Constructors With Inheritance Copy Constructors with Inheritance Inheriting Base Constructors Inheritance and Destructors Reused Symbols in Inheritance\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/18_inheritance/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 19: Polymorphism Introduction to Polymorphism Static Binding with Inheritance Dynamic binding with virtual functions Size of polymorphic objects and slicing Polymorphic objects stored in collections (array) Override Overloading, overriding and function hiding Inheritance and Polymorphism at different levels Inheritance and polymorphism with static members Final Virtual functions with default arguments Virtual Destructors Dynamic casts Polymorphic Functions and Destructors Pure virtual functions and abstract classes Abstract Classes as Interfaces\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/19_polymorphism/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 3: Variables and data types Variables and data types Introduction Number Systems Integer types : Decimals and Integers Integer Modifiers Fractional Numbers Booleans Characters And Text Auto Assignments Variables and data types summary\nB√†i 3: X√¢y d·ª±ng ch∆∞∆°ng tr√¨nh C++ ƒë·∫ßu ti√™n v·ªõi Visual Studio 2015\nM·ªôt s·ªë ki·∫øn th·ª©c c·∫ßn l∆∞u √Ω C√°ch t·∫°o v√† bi√™n d·ªãch ch∆∞∆°ng tr√¨nh C++ ƒë·∫ßu ti√™n tr√™n Visual Studio M·ªôt s·ªë v·∫•n ƒë·ªÅ th∆∞·ªùng g·∫∑p ƒë·ªëi v·ªõi l·∫≠p tr√¨nh vi√™n m·ªõi B√†i 4: C·∫•u tr√∫c m·ªôt ch∆∞∆°ng tr√¨nh C++ (Structure of a program)\nC·∫•u tr√∫c c·ªßa m·ªôt ch∆∞∆°ng tr√¨nh C++ C√∫ ph√°p v√† l·ªói c√∫ ph√°p trong C++ (Syntax and syntax errors) B√†i 5: Ghi ch√∫ trong C++ (Comments in C++)\nC√∫ ph√°p comment trong C++ M·ªôt s·ªë kinh nghi·ªám khi comment trong l·∫≠p tr√¨nh B√†i 6: Bi·∫øn trong C++ (Variables in C++)\nBi·∫øn trong C++ Kh·ªüi t·∫°o bi·∫øn trong C++ (Defining a variable) ƒê·ªãnh nghƒ©a bi·∫øn ·ªü ƒë√¢u (Where to define variables) B√†i 7: S·ªë t·ª± nhi√™n v√† S·ªë ch·∫•m ƒë·ªông trong C++ (Integer, Floating point)\nT·ªïng quan v·ªÅ ki·ªÉu d·ªØ li·ªáu c∆° b·∫£n trong C++ Ki·ªÉu s·ªë nguy√™n (Integer) S·ªë ch·∫•m ƒë·ªông (Floating point numbers) B√†i 8: Ki·ªÉu k√Ω t·ª± trong C++ (Character)\nT·ªïng quan v·ªÅ ki·ªÉu k√Ω t·ª± (Character) Khai b√°o, kh·ªüi t·∫°o v√† g√°n gi√° tr·ªã m·ªôt bi·∫øn k√Ω t·ª± In k√Ω t·ª± ra m√†n h√¨nh In k√Ω t·ª± t·ª´ s·ªë nguy√™n v√† ng∆∞·ª£c l·∫°i (Casting) Escape sequences Newline ‚Äò\\n‚Äô v√† std::endl D·∫•u nh√°y ƒë∆°n ‚ÄòK‚Äô v√† d·∫•u nh√°y k√©p ‚ÄúKteam‚Äù B√†i 9: Ki·ªÉu lu·∫≠n l√Ω v√† c∆° b·∫£n v·ªÅ C√¢u ƒëi·ªÅu ki·ªán If (Boolean and If statements)\nT·ªïng quan v·ªÅ ki·ªÉu lu·∫≠n l√Ω (Boolean) C∆° b·∫£n v·ªÅ c√¢u ƒëi·ªÅu ki·ªán If v√† Boolean B√†i 10: Nh·∫≠p, Xu·∫•t v√† ƒê·ªãnh d·∫°ng d·ªØ li·ªáu trong C++ (Input and Output)\nXu·∫•t d·ªØ li·ªáu v·ªõi std::cout trong C++ Nh·∫≠p d·ªØ li·ªáu v·ªõi std::cin trong C++ ƒê·ªãnh d·∫°ng d·ªØ li·ªáu nh·∫≠p xu·∫•t trong C++ B√†i 11: H·∫±ng s·ªë trong C++ (Constants)\nT·ªïng quan h·∫±ng s·ªë (Constants) H·∫±ng s·ªë v·ªõi t·ª´ kh√≥a const H·∫±ng s·ªë v·ªõi ch·ªâ th·ªã ti·ªÅn x·ª≠ l√Ω #define N√™n ƒë·ªãnh nghƒ©a h·∫±ng s·ªë ·ªü ƒë√¢u B√†i 12: To√°n t·ª≠ s·ªë h·ªçc, to√°n t·ª≠ tƒÉng gi·∫£m, to√°n t·ª≠ g√°n s·ªë h·ªçc trong C++ (Operators)\nT·ªïng quan v·ªÅ to√°n t·ª≠ To√°n t·ª≠ s·ªë h·ªçc trong C++ (Arithmetic operators) To√°n t·ª≠ g√°n s·ªë h·ªçc trong C++ (Arithmetic assignment operators) B√†i 13: To√°n t·ª≠ quan h·ªá, logic, bitwise, misc v√† ƒë·ªô ∆∞u ti√™n to√°n t·ª≠ trong C++\nTo√°n t·ª≠ quan h·ªá trong C++ (Relational operators) To√°n t·ª≠ logic trong C++ (Logical operators) To√°n t·ª≠ tr√™n bit trong C++ (Bitwise operators) C√°c to√°n t·ª≠ h·ªón h·ª£p trong C++ (Misc Operators) ƒê·ªô ∆∞u ti√™n v√† quy t·∫Øc k·∫øt h·ª£p to√°n t·ª≠ trong C++ B√†i 14: C∆° b·∫£n v·ªÅ chu·ªói k√Ω t·ª± trong C++ (An introduction to std::string)\nT·ªïng quan v·ªÅ chu·ªói k√Ω t·ª± (std::string) Khai b√°o, kh·ªüi t·∫°o v√† g√°n gi√° tr·ªã m·ªôt chu·ªói k√Ω t·ª± Xu·∫•t m·ªôt chu·ªói k√Ω t·ª± (string output): Nh·∫≠p m·ªôt chu·ªói k√Ω t·ª± (string input) M·ªôt s·ªë thao t√°c c∆° b·∫£n v·ªõi chu·ªói k√Ω t·ª± B√†i 15: Bi·∫øn c·ª•c b·ªô trong C++ (Local variables in C++)\nT·ªïng quan v·ªÅ t·∫ßm v·ª±c c·ªßa bi·∫øn Bi·∫øn c·ª•c b·ªô (Local variables) B√†i 16: Bi·∫øn to√†n c·ª•c trong C++ (Global variables in C++)\nT·ªïng quan v·ªÅ t·∫ßm v·ª±c c·ªßa bi·∫øn Bi·∫øn to√†n c·ª•c (Global variables) S·ª≠ d·ª•ng bi·∫øn to√†n c·ª•c l√† nguy hi·ªÉm Khi n√†o c·∫ßn s·ª≠ d·ª•ng bi·∫øn to√†n c·ª•c (non-const) B√†i 17: Bi·∫øn tƒ©nh trong C++ (Static variables in C++)\nT·ªïng quan v·ªÅ bi·∫øn tƒ©nh (static variables) Khi n√†o n√™n s·ª≠ d·ª•ng bi·∫øn tƒ©nh B√†i 18: √âp ki·ªÉu ng·∫ßm ƒë·ªãnh trong C++ (Implicit type conversion in C++)\nT·ªïng quan v·ªÅ √©p ki·ªÉu d·ªØ li·ªáu √âp ki·ªÉu ng·∫ßm ƒë·ªãnh trong C++ (Implicit type conversion) B√†i 19: √âp ki·ªÉu t∆∞·ªùng minh trong C++ (Explicit type conversion in C++)\n√âp ki·ªÉu t∆∞·ªùng minh trong C++ (Explicit type conversion) B√†i 20: C∆° b·∫£n v·ªÅ H√†m v√† Gi√° tr·ªã tr·∫£ v·ªÅ (Basic of functions and return values)\nT·ªïng quan v·ªÅ h√†m (functions overview) Gi√° tr·ªã tr·∫£ v·ªÅ (return values) Gi√° tr·ªã tr·∫£ v·ªÅ c·ªßa ki·ªÉu void (return values of type void) B√†i 21: Truy·ªÅn Gi√° Tr·ªã cho H√†m (Passing Arguments by Value)\nTham s·ªë v√† ƒë·ªëi s·ªë c·ªßa h√†m (Function parameters and arguments) Truy·ªÅn gi√° tr·ªã cho h√†m (Passing arguments by value) T·ªïng k·∫øt v·ªÅ ph∆∞∆°ng ph√°p truy·ªÅn gi√° tr·ªã cho h√†m (Passing argument by value) B√†i 22: Truy·ªÅn Tham Chi·∫øu cho H√†m (Passing Arguments by Reference)\nTruy·ªÅn tham chi·∫øu cho h√†m (Passing arguments by reference) Truy·ªÅn tham chi·∫øu h·∫±ng (Pass by const reference) T·ªïng k·∫øt v·ªÅ ph∆∞∆°ng ph√°p truy·ªÅn tham chi·∫øu cho h√†m (Passing arguments by reference) B√†i 23: Ti·ªÅn khai b√°o v√† ƒê·ªãnh nghƒ©a H√†m (Forward declarations and Definitions of Functions)\nL·ªói ‚Äúidentifier not found‚Äù Ti·ªÅn khai b√°o v√† nguy√™n m·∫´u h√†m (Forward declaration and function prototypes) Khai b√°o v√† ƒë·ªãnh nghƒ©a trong C++ (Declarations and definitions in C++) B√†i 24: Gi·ªõi thi·ªáu v·ªÅ c·∫•u tr√∫c ƒëi·ªÅu khi·ªÉn (Control flow introduction)\nT·ªïng quan v·ªÅ c·∫•u tr√∫c ƒëi·ªÅu khi·ªÉn trong C++ C√¢u l·ªánh d·ª´ng (halt) C√¢u l·ªánh nh·∫£y (Jumps) C·∫•u tr√∫c r·∫Ω nh√°nh c√≥ ƒëi·ªÅu ki·ªán (Conditional branches) C·∫•u tr√∫c v√≤ng l·∫∑p (Loops) X·ª≠ l√Ω ngo·∫°i l·ªá (Exceptions handling) B√†i 25: C√¢u ƒëi·ªÅu ki·ªán If v√† To√°n t·ª≠ ƒëi·ªÅu ki·ªán (If statements and Conditional operator)\nC√¢u ƒëi·ªÅu ki·ªán If To√°n t·ª≠ ƒëi·ªÅu ki·ªán (Conditional operator) B√†i 26: C√¢u ƒëi·ªÅu ki·ªán Switch trong C++ (Switch statements)\nC√¢u ƒëi·ªÅu ki·ªán Switch (Switch statements) Khai b√°o v√† kh·ªüi t·∫°o bi·∫øn b√™n trong case statement B√†i 27: C√¢u l·ªánh Goto trong C++ (Goto statements)\nT·ªïng quan v·ªÅ c√¢u l·ªánh Goto trong C++ M·ªôt s·ªë v·∫•n ƒë·ªÅ c·ªßa c√¢u l·ªánh Goto B√†i 28: V√≤ng l·∫∑p While trong C++ (While statements)\nT·ªïng quan v·ªÅ c·∫•u tr√∫c v√≤ng l·∫∑p V√≤ng l·∫∑p while (while statements) B√†i 29: V√≤ng l·∫∑p Do while trong C++ (Do while statements)\nV√≤ng l·∫∑p do while (do while statements) B√†i 30: V√≤ng l·∫∑p For trong C++ (For statements)\nV√≤ng l·∫∑p for (for statements) B√†i 31: T·ª´ kh√≥a Break and continue trong C++\nT·ª´ kh√≥a break T·ª´ kh√≥a continue B√†i 32: Ph√°t sinh s·ªë ng·∫´u nhi√™n trong C++ (Random number generation)\nT·ªïng quan v·ªÅ ph√°t sinh s·ªë ng·∫´u nhi√™n Ph√°t sinh s·ªë ng·∫´u nhi√™n trong C++ Ph√°t sinh s·ªë ng·∫´u nhi√™n trong C++ 11 B√†i 33: M·∫£ng 1 chi·ªÅu trong C++ (Arrays)\nT·∫°i sao l·∫°i s·ª≠ d·ª•ng m·∫£ng? T·ªïng quan v·ªÅ m·∫£ng 1 chi·ªÅu Khai b√°o v√† kh·ªüi t·∫°o m·∫£ng 1 chi·ªÅu Xu·∫•t c√°c ph·∫ßn t·ª≠ m·∫£ng 1 chi·ªÅu Nh·∫≠p d·ªØ li·ªáu cho m·∫£ng 1 chi·ªÅu Ph√°t sinh d·ªØ li·ªáu ng·∫´u nhi√™n cho m·∫£ng 1 chi·ªÅu B√†i 34: C√°c thao t√°c tr√™n M·∫£ng m·ªôt chi·ªÅu\nTruy·ªÅn m·∫£ng v√†o h√†m (passing arrays to functions) Nh·∫≠p v√† xu·∫•t m·∫£ng 1 chi·ªÅu Sao ch√©p m·∫£ng 1 chi·ªÅu T√¨m ki·∫øm ph·∫ßn t·ª≠ trong m·∫£ng S·∫Øp x·∫øp m·∫£ng 1 chi·ªÅu Th√™m v√† x√≥a m·ªôt ph·∫ßn t·ª≠ trong m·∫£ng B√†i 35: M·∫£ng 2 chi·ªÅu trong C++ (Two-dimensional arrays)\nM·∫£ng 2 chi·ªÅu l√† g√¨? Khai b√°o v√† kh·ªüi t·∫°o m·∫£ng 2 chi·ªÅu Xu·∫•t c√°c ph·∫ßn t·ª≠ m·∫£ng 2 chi·ªÅu Nh·∫≠p c√°c ph·∫ßn t·ª≠ m·∫£ng 2 chi·ªÅu B√†i 36: C√°c thao t√°c tr√™n M·∫£ng 2 chi·ªÅu\nTruy·ªÅn m·∫£ng v√†o h√†m (passing arrays to functions) Nh·∫≠p v√† xu·∫•t m·∫£ng 2 chi·ªÅu T√≠nh t·ªïng c√°c ph·∫ßn t·ª≠ trong m·∫£ng T√¨m gi√° tr·ªã l·ªõn nh·∫•t c·ªßa m·∫£ng 2 chi·ªÅu B√†i 37: M·∫£ng k√Ω t·ª± trong C++ (C-style strings)\nM·∫£ng k√Ω t·ª± (C-style strings) l√† g√¨? Khai b√°o v√† kh·ªüi t·∫°o m·∫£ng k√Ω t·ª± (C-style strings) Xu·∫•t m·∫£ng k√Ω t·ª± (C-style strings) v·ªõi std::cout Nh·∫≠p m·∫£ng k√Ω t·ª± (C-style strings) v·ªõi std::cin B√†i 38: C√°c thao t√°c tr√™n M·∫£ng k√Ω t·ª± (C-style strings)\nM·ªôt s·ªë thao t√°c v·ªõi m·∫£ng k√Ω t·ª± (C-style strings)\nhttps://www.freecodecamp.org/news/learn-c-with-free-31-hour-course/\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/4_variable_and_datatype/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 4: Operations on Data Introduction on Data operations Basic Operations Precedence and Associativity Prefix/Postfix Increment \u0026amp; Decrement Compound Assignment Operators Relational Operators Logical Operators Output formatting Numeric Limits Math Functions Weird Integral Types Data Operations Summary\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/5_operator_on_data/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 5: Flow Control Flow Control Introduction If Statements Else If Switch Ternary Operators Flow Control Summary\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/6_flow_control/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 6: Loops Loops Introduction For Loop While Loop Do While Loop\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/7_loop/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 7: Arrays Introduction to Arrays Declaring and using arrays Size of an array Arrays of characters Array Bounds\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/8_array/","series":null,"tags":null,"title":""},{"categories":null,"content":"Chapter 8: Pointers Introduction to Pointers Declaring and using pointers Pointer to char Program Memory Map Revisited Dynamic Memory Allocation Dangling Pointers When new Fails Null Pointer Safety Memory Leaks Dynamically allocated arrays\n","date":"Jan 1, 0001","img":"","permalink":"/courses/cplusplus/9_array/","series":null,"tags":null,"title":""},{"categories":null,"content":"‚å®Ô∏è (0:00:00) Introduction to data structures ‚å®Ô∏è (0:06:33) Data Structures: List as abstract data type ‚å®Ô∏è (0:19:40) Introduction to linked list ‚å®Ô∏è (0:36:50) Arrays vs Linked Lists ‚å®Ô∏è (0:49:05) Linked List - Implementation in C/C++ ‚å®Ô∏è (1:03:02) Linked List in C/C++ - Inserting a node at beginning ‚å®Ô∏è (1:15:50) Linked List in C/C++ - Insert a node at nth position ‚å®Ô∏è (1:31:04) Linked List in C/C++ - Delete a node at nth position ‚å®Ô∏è (1:43:32) Reverse a linked list - Iterative method ‚å®Ô∏è (1:57:21) Print elements of a linked list in forward and reverse order using recursion ‚å®Ô∏è (2:11:43) Reverse a linked list using recursion ‚å®Ô∏è (2:20:38) Introduction to Doubly Linked List ‚å®Ô∏è (2:27:50) Doubly Linked List - Implementation in C/C++ ‚å®Ô∏è (2:43:09) Introduction to stack ‚å®Ô∏è (2:51:34) Array implementation of stacks ‚å®Ô∏è (3:04:42) Linked List implementation of stacks ‚å®Ô∏è (3:15:39) Reverse a string or linked list using stack. ‚å®Ô∏è (3:32:03) Check for balanced parentheses using stack ‚å®Ô∏è (3:46:14) Infix, Prefix and Postfix ‚å®Ô∏è (3:59:14) Evaluation of Prefix and Postfix expressions using stack ‚å®Ô∏è (4:14:00) Infix to Postfix using stack ‚å®Ô∏è (4:32:17) Introduction to Queues ‚å®Ô∏è (4:41:35) Array implementation of Queue ‚å®Ô∏è (4:56:33) Linked List implementation of Queue ‚å®Ô∏è (5:10:48) Introduction to Trees ‚å®Ô∏è (5:26:37) Binary Tree ‚å®Ô∏è (5:42:51) Binary Search Tree ‚å®Ô∏è (6:02:17) Binary search tree - Implementation in C/C++ ‚å®Ô∏è (6:20:52) BST implementation - memory allocation in stack and heap ‚å®Ô∏è (6:33:55) Find min and max element in a binary search tree ‚å®Ô∏è (6:39:41) Find height of a binary tree ‚å®Ô∏è (6:46:50) Binary tree traversal - breadth-first and depth-first strategies ‚å®Ô∏è (6:58:43) Binary tree: Level Order Traversal ‚å®Ô∏è (7:10:05) Binary tree traversal: Preorder, Inorder, Postorder ‚å®Ô∏è (7:24:33) Check if a binary tree is binary search tree or not ‚å®Ô∏è (7:41:01) Delete a node from Binary Search Tree ‚å®Ô∏è (7:59:27) Inorder Successor in a binary search tree ‚å®Ô∏è (8:17:23) Introduction to graphs ‚å®Ô∏è (8:34:05) Properties of Graphs ‚å®Ô∏è (8:49:19) Graph Representation part 01 - Edge List ‚å®Ô∏è (9:03:03) Graph Representation part 02 - Adjacency Matrix ‚å®Ô∏è (9:17:46) Graph Representation part 03 - Adjacency List\n","date":"Jan 1, 0001","img":"","permalink":"/courses/data_structures/","series":null,"tags":null,"title":""},{"categories":null,"content":"Th√¥ng th∆∞·ªùng, ch√∫ng ta ƒë·ªçc n·ªôi dung c·ªßa file sau khi m·ªü file.\nGi·∫£ s·ª≠ ch√∫ng ta c√≥ file \u0026ldquo;test.txt\u0026rdquo; c√≥ n·ªôi dung nh∆∞ b√™n d∆∞·ªõi:\n1This file is testing. 2Good Luck! H√†m m·ªü file ra ƒë∆∞·ª£c vi·∫øt nh∆∞ th·∫ø n√†y:\nf = open(\u0026ldquo;test.txt\u0026rdquo;,\u0026lsquo;r\u0026rsquo;,encoding = \u0026lsquo;utf-8\u0026rsquo;)\nƒê·ªÉ ƒë·ªçc n·ªôi dung file, python h·ªó tr·ª£ c√°c h√†m l√† read, readline, readlines, m·ªói h√†m s·∫Ω c√≥ t√°c d·ª•ng kh√°c nhau\nh√†m read s·∫Ω tr·∫£ v·ªÅ to√†n b·ªô n·ªôi dung c·ªßa file f.read()\n'This file is testing.\\nGood Luck!\\n'\nh√†m readline, m·ªói l·∫ßn ƒë·ªçc s·∫Ω tr·∫£ v·ªÅ 1 d√≤ng trong file f.readline()\n\u0026lsquo;This file is testing.\\n\u0026rsquo;\nKhi g·ªçi readline m·ªôt l·∫ßn n·ªØa, ch∆∞∆°ng tr√¨nh s·∫Ω tr·∫£ v·ªÅ d√≤ng ti·∫øp theo\nf.readline()\n\u0026lsquo;Good Luck!\\n\u0026rsquo;\nh√†m readlines s·∫Ω tr·∫£ v·ªÅ m·ªôt m·∫£ng c√°c chu·ªói, m·ªói chu·ªói t∆∞∆°ng ·ª©ng m·ªôt d√≤ng trong file f.readlines()\n[\u0026lsquo;This file is testing.\\n\u0026rsquo;, \u0026lsquo;Good Luck!\\n\u0026rsquo;]\n","date":"Jan 1, 0001","img":"","permalink":"/courses/python/io/","series":null,"tags":null,"title":""},{"categories":null,"content":"","date":"Jan 1, 0001","img":"","permalink":"/contact/","series":null,"tags":null,"title":"Contact Us"},{"categories":null,"content":"","date":"Jan 1, 0001","img":"","permalink":"/faq/","series":null,"tags":null,"title":"FAQs"},{"categories":null,"content":"","date":"Jan 1, 0001","img":"","permalink":"/offline/","series":null,"tags":null,"title":"Offline"},{"categories":null,"content":"Tools sinh password\nTools sinh s·ªë ng·∫´u nhi√™n\n","date":"Jan 1, 0001","img":"","permalink":"/tools/","series":null,"tags":null,"title":"Tools"}]